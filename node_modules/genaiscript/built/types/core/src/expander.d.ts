import { Project, PromptScript } from "./ast";
import { MarkdownTrace } from "./trace";
import { PromptImage } from "./promptdom";
import { GenerationOptions } from "./promptcontext";
import { ChatCompletionMessageParam } from "./chat";
export interface GenerationResult extends GenerationOutput {
    /**
     * The env variables sent to the prompt
     */
    vars: Partial<ExpansionVariables>;
    /**
     * Expanded prompt text
     */
    messages: ChatCompletionMessageParam[];
    /**
     * Zero or more edits to apply.
     */
    edits: Edits[];
    /**
     * Parsed source annotations
     */
    annotations: Diagnostic[];
    /**
     * ChangeLog sections
     */
    changelogs: string[];
    /**
     * Error message if any
     */
    error?: unknown;
    /**
     * Run status
     */
    status: GenerationStatus;
    /**
     * Status message if any
     */
    statusText?: string;
    /**
     * Run label if provided
     */
    label?: string;
    /**
     * GenAIScript version
     */
    version: string;
}
export interface GenerationStats {
    toolCalls: number;
    repairs: number;
    turns: number;
}
export type GenerationStatus = "success" | "error" | "cancelled" | undefined;
export declare function resolveSystems(prj: Project, template: PromptScript): string[];
export declare function expandTemplate(prj: Project, template: PromptScript, options: GenerationOptions, env: ExpansionVariables, trace: MarkdownTrace): Promise<{
    status: string;
    statusText: string;
    messages?: undefined;
    images?: undefined;
    schemas?: undefined;
    functions?: undefined;
    model?: undefined;
    temperature?: undefined;
    topP?: undefined;
    max_tokens?: undefined;
    maxToolCalls?: undefined;
    seed?: undefined;
    responseType?: undefined;
    responseSchema?: undefined;
    fileMerges?: undefined;
    outputProcessors?: undefined;
    chatParticipants?: undefined;
    fileOutputs?: undefined;
} | {
    messages: ChatCompletionMessageParam[];
    images: PromptImage[];
    schemas: Record<string, JSONSchema>;
    functions: ToolCallback[];
    status: GenerationStatus;
    statusText: string;
    model: string;
    temperature: number;
    topP: number;
    max_tokens: number;
    maxToolCalls: number;
    seed: number;
    responseType: "json_object";
    responseSchema: JSONSchemaObject;
    fileMerges: FileMergeHandler[];
    outputProcessors: PromptOutputProcessorHandler[];
    chatParticipants: ChatParticipant[];
    fileOutputs: FileOutput[];
}>;
//# sourceMappingURL=expander.d.ts.map