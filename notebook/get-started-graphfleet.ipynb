{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started quickly \n",
    "First make sure to :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "git clone https://github.com/Qredence/GraphFleet.git\n",
    "\n",
    "\n",
    "cd GraphFleet\n",
    "poetry shell\n",
    "poetry install\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch import your PDF right from this notebook ! \n",
    "Run the script below, an \"Upload\" button should have appeared, click on it and add your pdfs, it will automaticly convert and add them in a .txt in the right folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define the directory to save the .txt files\n",
    "txt_directory = '../graphfleet/input'\n",
    "if not os.path.exists(txt_directory):\n",
    "    os.makedirs(txt_directory)\n",
    "\n",
    "json_file_path = '../graphfleet/input/json'\n",
    "if not os.path.exists(json_file_path):\n",
    "    os.makedirs(json_file_path)\n",
    "\n",
    "\n",
    "# Create upload button\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.json',  # Accept only PDF files\n",
    "    multiple=True   # Allow uploading multiple files\n",
    ")\n",
    "\n",
    "# Create output area\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "\n",
    "def json_to_txt(json_file_path, txt_directory):\n",
    "    # Load JSON data\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Write data to TXT file\n",
    "    with open(txt_directory, 'w', newline='') as txt_file:\n",
    "        writer = csv.DictWriter(txt_file, fieldnames=data[0].keys(), delimiter='\\t')\n",
    "        writer.writeheader()\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Usage\n",
    "json_to_txt('input.json', 'output.txt')\n",
    "\n",
    "\n",
    "\n",
    "# Observe changes in the upload widget\n",
    "uploader.observe(json_to_txt, names='value')\n",
    "\n",
    "# Display the upload button and output area\n",
    "display(uploader)\n",
    "display(output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great! Now that your PDF is formatted correctly and in the right location (graphfleet/input), we can initialize your workspace. Just execute the following command to get started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "git clone https://github.com/Qredence/GraphFleet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd GraphFleet\n",
    "poetry shell\n",
    "poetry install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m graphrag.index --init --root ../graphfleet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your GraphRAG Pipeline\n",
    "\n",
    "This notebook guides you through configuring your GraphRAG pipeline using either OpenAI or Azure OpenAI.\n",
    "\n",
    "### 1. Environment Variables and Settings Files\n",
    "\n",
    "GraphRAG relies on two crucial files for configuration:\n",
    "\n",
    "- **.env:** This file stores environment variables. The most important one is GRAPHRAG_API_KEY, which holds your API key for either OpenAI or Azure OpenAI.\n",
    "- **settings.yaml:** This file contains settings that fine-tune the behavior of the GraphRAG pipeline.\n",
    "\n",
    "Here's a breakdown of how to configure each file for OpenAI and Azure OpenAI:\n",
    "\n",
    "### 2. OpenAI Configuration\n",
    "\n",
    "1. **Update .env:**\n",
    "   - Open the .env file located in your ./graphfleet directory.\n",
    "   - Find the line GRAPHRAG_API_KEY=<API_KEY>.\n",
    "   - Replace <API_KEY> with your actual OpenAI API key.\n",
    "\n",
    "2. **(Optional) Customize settings.yaml:**\n",
    "   - Open the settings.yaml file in the same directory.\n",
    "   - You can customize various aspects of the pipeline here, like which language model to use or how many results to return. Refer to the [configuration documentation](link-to-configuration-docs) for detailed options.\n",
    "\n",
    "### 3. Azure OpenAI Configuration\n",
    "\n",
    "1. **Update .env:**\n",
    "   - Open the .env file.\n",
    "   - Set the GRAPHRAG_API_KEY to your Azure OpenAI API key.\n",
    "\n",
    "2. **Configure settings.yaml:**\n",
    "   - Open the settings.yaml file.\n",
    "   - Search for the llm configuration section. You'll find two: one for chat and one for embeddings.\n",
    "   - **Chat Endpoint Example:**\n",
    "     ```yaml\n",
    "     llm:\n",
    "       type: azure_openai_chat \n",
    "       api_base: https://<your-instance>.openai.azure.com \n",
    "       api_version: your version  # Adjust if needed\n",
    "       deployment_name: <your-azure-model-deployment-name> \n",
    "     ```\n",
    "\n",
    "   - **Embeddings Endpoint Example:** \n",
    "     ```yaml\n",
    "     llm:\n",
    "       type: azure_openai_embedding\n",
    "       api_base: https://<your-instance>.openai.azure.com \n",
    "       api_version: your version  # Adjust if needed\n",
    "       deployment_name: <your-azure-model-deployment-name> \n",
    "     ```\n",
    "\n",
    "   - **Replace the placeholders:**\n",
    "     - <your-instance>: Your Azure OpenAI instance name.\n",
    "     - <your-azure-model-deployment-name>: The deployment name of your Azure OpenAI model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Your Data:\n",
    " Now, let's index your data to make it searchable. This is the final step!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m graphrag.index --root ../graphfleet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing in Progress!\n",
    "\n",
    "Running the indexing pipeline might take a while ‚Äì don't worry, that's normal! ‚è≥ \n",
    "!\n",
    "**Factors that influence indexing time:**\n",
    "\n",
    "* **Size of your data:**  Larger datasets naturally take longer to process.\n",
    "* **Model selection:** Different models have varying processing speeds.\n",
    "* **Text chunk size:** This setting (configurable in your `.env` file) impacts how the data is broken down and indexed.\n",
    "\n",
    "**What to expect:**\n",
    "\n",
    "Once the indexing process is complete, you'll find a new folder in your project directory:\n",
    "\n",
    "   `./graphfleet/output/<timestamp>/artifacts` \n",
    "\n",
    "Inside this folder, you'll see a collection of `parquet` files. These files contain your indexed data, ready for GraphRAG to use! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to Query! üöÄ\n",
    "\n",
    "Now that your data is indexed, the real fun begins: **asking questions!**  \n",
    "\n",
    "Let's explore how to use GraphRAG's query engine to extract insights from your dataset. \n",
    "\n",
    "### Global Search: Uncovering High-Level Themes\n",
    "\n",
    "Use global search to get a bird's-eye view of the main ideas in your data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m graphrag.query \\\n",
    "--root ../graphfleet \\\n",
    "--method global \\\n",
    "\"Why should I use GraphRAG over other kind of solution for my company  ?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "python -m graphrag.query: Runs the GraphRAG query engine.\n",
    "--root ./graphfleet: Specifies the root directory of your GraphRAG project.\n",
    "--method global: Tells GraphRAG to perform a global search across all your data.\n",
    "\"What are the top themes in this story?\": Your natural language query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m graphrag.query --root ../graphfleet --method local \"What is the main features of GraphRAG  ?\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "--method local: Instructs GraphRAG to focus on a specific part of your data relevant to the query.\n",
    "\"Who is Scrooge, and what are his main relationships?\": This query focuses on a character (Scrooge) and their relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment! üß™\n",
    "\n",
    "Go ahead and ask your own questions! Try different query types, phrasings, and explore the power of GraphRAG to unlock insights from your indexed data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphfleet-bVb82vZ5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
