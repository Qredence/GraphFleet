{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCopyright (c) Microsoft Corporation.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.indexer_adapters import read_indexer_entities, read_indexer_reports\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.structured_search.global_search.community_context import (\n",
    "    GlobalCommunityContext,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.search import GlobalSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Search example\n",
    "\n",
    "Global search method generates answers by searching over all AI-generated community reports in a map-reduce fashion. This is a resource-intensive method, but often gives good responses for questions that require an understanding of the dataset as a whole (e.g. What are the most significant values of the herbs mentioned in this notebook?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"GRAPHRAG_API_KEY\"]\n",
    "llm_model = os.environ[\"GRAPHRAG_LLM_MODEL\"]\n",
    "embedding_model = os.environ[\"GRAPHRAG_EMBEDDING_MODEL\"]\n",
    "api_base = os.environ[\"GRAPHRAG_API_BASE\"]\n",
    "api_version = os.environ[\"GRAPHRAG_API_VERSION\"]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_base=api_base,\n",
    "    api_version=api_version,\n",
    "    model=llm_model,\n",
    "    api_type=OpenaiApiType.AzureOpenAI,  # OpenaiApiType.OpenAI or OpenaiApiType.AzureOpenAI\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load community reports as context for global search\n",
    "\n",
    "- Load all community reports in the `create_final_community_reports` table from the ire-indexing engine, to be used as context data for global search.\n",
    "- Load entities from the `create_final_nodes` and `create_final_entities` tables from the ire-indexing engine, to be used for calculating community weights for context ranking. Note that this is optional (if no entities are provided, we will not calculate community weights and only use the `rank` attribute in the community reports table for context ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet files generated from indexing pipeline\n",
    "INPUT_DIR = \"../graphfleet/output/graphindex/artifacts\"\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "\n",
    "# community level in the Leiden community hierarchy from which we will load the community reports\n",
    "# higher value means we use reports from more fine-grained communities (at the cost of higher computation cost)\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total report count: 102\n",
      "Report count after filtering by community level 2: 83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "      <th>full_content</th>\n",
       "      <th>level</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>full_content_json</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td># Natural Language Processing and Information ...</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Natural Language Processing and Information Re...</td>\n",
       "      <td>The rating is high due to the significant impa...</td>\n",
       "      <td>The community of 'Natural Language Processing ...</td>\n",
       "      <td>[{'explanation': 'Community summaries play a p...</td>\n",
       "      <td>{\\n    \"title\": \"Natural Language Processing a...</td>\n",
       "      <td>8c20fd3b-1450-4841-a64a-18429d05d5d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td># Natural Language Processing and Information ...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Natural Language Processing and Information Re...</td>\n",
       "      <td>The text is highly significant and impactful i...</td>\n",
       "      <td>The community of Natural Language Processing (...</td>\n",
       "      <td>[{'explanation': 'Recent advancements in trans...</td>\n",
       "      <td>{\\n    \"title\": \"Natural Language Processing a...</td>\n",
       "      <td>cea459eb-b1cf-46cd-aabb-0ce4f3c184b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td># Natural Language Processing and Information ...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Natural Language Processing and Information Re...</td>\n",
       "      <td>The text is highly significant and impactful i...</td>\n",
       "      <td>The community of 'Natural Language Processing ...</td>\n",
       "      <td>[{'explanation': 'The 'NEWS ARTICLES' dataset ...</td>\n",
       "      <td>{\\n    \"title\": \"Natural Language Processing a...</td>\n",
       "      <td>1458f6ef-6da1-486e-94d1-3070e4e280ff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td># Natural Language Processing and Information ...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Natural Language Processing and Information Re...</td>\n",
       "      <td>The text is highly significant and impactful i...</td>\n",
       "      <td>The community of 'Natural Language Processing ...</td>\n",
       "      <td>[{'explanation': 'The 'PODCAST TRANSCRIPTS' da...</td>\n",
       "      <td>{\\n    \"title\": \"Natural Language Processing a...</td>\n",
       "      <td>bcb2afbf-6b77-4e7c-ad5f-845d873cd10d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td># Graph RAG and Community Summarization in NLP...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Graph RAG and Community Summarization in NLP a...</td>\n",
       "      <td>The rating is high due to the significant impa...</td>\n",
       "      <td>The community revolves around the Graph RAG sy...</td>\n",
       "      <td>[{'explanation': 'Graph RAG is a pivotal syste...</td>\n",
       "      <td>{\\n    \"title\": \"Graph RAG and Community Summa...</td>\n",
       "      <td>6a14f684-f45d-4563-88f7-18a2cac9b5cb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  community                                       full_content  level  rank  \\\n",
       "0       100  # Natural Language Processing and Information ...      2   8.5   \n",
       "1       101  # Natural Language Processing and Information ...      2   9.0   \n",
       "2        71  # Natural Language Processing and Information ...      2   9.0   \n",
       "3        72  # Natural Language Processing and Information ...      2   9.0   \n",
       "4        73  # Graph RAG and Community Summarization in NLP...      2   9.0   \n",
       "\n",
       "                                               title  \\\n",
       "0  Natural Language Processing and Information Re...   \n",
       "1  Natural Language Processing and Information Re...   \n",
       "2  Natural Language Processing and Information Re...   \n",
       "3  Natural Language Processing and Information Re...   \n",
       "4  Graph RAG and Community Summarization in NLP a...   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The rating is high due to the significant impa...   \n",
       "1  The text is highly significant and impactful i...   \n",
       "2  The text is highly significant and impactful i...   \n",
       "3  The text is highly significant and impactful i...   \n",
       "4  The rating is high due to the significant impa...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The community of 'Natural Language Processing ...   \n",
       "1  The community of Natural Language Processing (...   \n",
       "2  The community of 'Natural Language Processing ...   \n",
       "3  The community of 'Natural Language Processing ...   \n",
       "4  The community revolves around the Graph RAG sy...   \n",
       "\n",
       "                                            findings  \\\n",
       "0  [{'explanation': 'Community summaries play a p...   \n",
       "1  [{'explanation': 'Recent advancements in trans...   \n",
       "2  [{'explanation': 'The 'NEWS ARTICLES' dataset ...   \n",
       "3  [{'explanation': 'The 'PODCAST TRANSCRIPTS' da...   \n",
       "4  [{'explanation': 'Graph RAG is a pivotal syste...   \n",
       "\n",
       "                                   full_content_json  \\\n",
       "0  {\\n    \"title\": \"Natural Language Processing a...   \n",
       "1  {\\n    \"title\": \"Natural Language Processing a...   \n",
       "2  {\\n    \"title\": \"Natural Language Processing a...   \n",
       "3  {\\n    \"title\": \"Natural Language Processing a...   \n",
       "4  {\\n    \"title\": \"Graph RAG and Community Summa...   \n",
       "\n",
       "                                     id  \n",
       "0  8c20fd3b-1450-4841-a64a-18429d05d5d3  \n",
       "1  cea459eb-b1cf-46cd-aabb-0ce4f3c184b7  \n",
       "2  1458f6ef-6da1-486e-94d1-3070e4e280ff  \n",
       "3  bcb2afbf-6b77-4e7c-ad5f-845d873cd10d  \n",
       "4  6a14f684-f45d-4563-88f7-18a2cac9b5cb  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "print(f\"Total report count: {len(report_df)}\")\n",
    "print(\n",
    "    f\"Report count after filtering by community level {COMMUNITY_LEVEL}: {len(reports)}\"\n",
    ")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build global context based on community reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = GlobalCommunityContext(\n",
    "    community_reports=reports,\n",
    "    entities=entities,  # default to None if you don't want to use community weights for ranking\n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform global search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder_params = {\n",
    "    \"use_community_summary\": False,  # False means using full community reports. True means using community short summaries.\n",
    "    \"shuffle_data\": True,\n",
    "    \"include_community_rank\": True,\n",
    "    \"min_community_rank\": 0,\n",
    "    \"community_rank_name\": \"rank\",\n",
    "    \"include_community_weight\": True,\n",
    "    \"community_weight_name\": \"occurrence weight\",\n",
    "    \"normalize_community_weight\": True,\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    \"context_name\": \"Reports\",\n",
    "}\n",
    "\n",
    "map_llm_params = {\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.0,\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "}\n",
    "\n",
    "reduce_llm_params = {\n",
    "    \"max_tokens\": 2000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000-1500)\n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = GlobalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    max_data_tokens=12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    map_llm_params=map_llm_params,\n",
    "    reduce_llm_params=reduce_llm_params,\n",
    "    allow_general_knowledge=False,  # set this to True will add instruction to encourage the LLM to incorporate general knowledge in the response, which may increase hallucinations, but could be useful in some use cases.\n",
    "    json_mode=True,  # set this to False if your LLM model does not support JSON mode.\n",
    "    context_builder_params=context_builder_params,\n",
    "    concurrent_coroutines=32,\n",
    "    response_type=\"multiple paragraphs\",  # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Purpose of GraphRAG\n",
      "\n",
      "GraphRAG (Graph-based Retrieval-Augmented Generation) is designed to enhance the capabilities of retrieval-augmented generation tasks by integrating retrieval mechanisms with generation models. This approach allows for more comprehensive and contextually relevant summaries by retrieving pertinent information from large datasets before generating the final summary [Data: Reports (57, 22, 70, 68, 71)].\n",
      "\n",
      "### Key Features and Benefits\n",
      "\n",
      "1. **Graph-Based Text Indexing**:\n",
      "   GraphRAG leverages graph-based text indexing to partition data, facilitating global summarization. This method enhances the efficiency and effectiveness of text data processing and summarization by utilizing the natural modularity of graphs [Data: Reports (26)].\n",
      "\n",
      "2. **Comprehensive and Diverse Responses**:\n",
      "   By employing graph-based indexing and summarization techniques, GraphRAG ensures that the generated responses are both comprehensive and diverse, outperforming traditional summarization methods [Data: Reports (17, 22, 70, 71)].\n",
      "\n",
      "3. **Integration with Large Language Models (LLMs)**:\n",
      "   GraphRAG utilizes LLMs to construct a graph-based text index, enabling the generation of summaries and the answering of queries. This integration enhances the system's ability to process and synthesize complex text data, making it a powerful tool for information retrieval and natural language processing tasks [Data: Reports (77, 87)].\n",
      "\n",
      "4. **Hierarchical Community Summaries**:\n",
      "   The system uses hierarchical community structures to answer user questions over entire datasets. This approach is designed for situations where answers are contained locally within regions of text whose retrieval provides sufficient grounding for the generation task [Data: Reports (65, 73)].\n",
      "\n",
      "5. **Efficiency and Scalability**:\n",
      "   GraphRAG demonstrates significant scalability and efficiency advantages compared to traditional source text summarization. The system requires fewer context tokens for community summaries, particularly at the root level (C0), making it a resource-efficient approach [Data: Reports (73, 22)].\n",
      "\n",
      "### Applications\n",
      "\n",
      "GraphRAG is particularly useful for answering user questions over large datasets by leveraging graph-based indexing and summarization techniques. This method ensures that the generated responses are both comprehensive and diverse, outperforming traditional summarization methods [Data: Reports (17, 22, 70, 71)]. It is also employed to enhance the capabilities of large language models (LLMs) by enabling them to retrieve pertinent information from external knowledge sources, thereby generating and assessing text more effectively [Data: Reports (26)].\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "In summary, GraphRAG is a pivotal system in the NLP and IR community, utilizing graph-based text indexing and hierarchical community summaries to enhance the retrieval and generation of information. Its ability to provide comprehensive, diverse, and contextually relevant summaries makes it a valuable tool for handling large datasets and answering complex user queries efficiently [Data: Reports (57, 22, 70, 68, 71, +more)].\n"
     ]
    }
   ],
   "source": [
    "result = await search_engine.asearch(\n",
    "    \"What is the purpose of GraphRAG?\"\n",
    ")\n",
    "\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>occurrence weight</th>\n",
       "      <th>content</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>Natural Language Processing and Information Re...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td># Natural Language Processing and Information ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>Graph RAG and Community Summarization in NLP a...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td># Graph RAG and Community Summarization in NLP...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>Few-Shot Examples and Their Role in Enhancing ...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td># Few-Shot Examples and Their Role in Enhancin...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>Natural Language Processing and Information Re...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td># Natural Language Processing and Information ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>Natural Language Processing and Information Re...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td># Natural Language Processing and Information ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>82</td>\n",
       "      <td>Retrieval-Generation Synergy in Large Language...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td># Retrieval-Generation Synergy in Large Langua...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>40</td>\n",
       "      <td>LLAMA and Its Impact on Natural Language Proce...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td># LLAMA and Its Impact on Natural Language Pro...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>30</td>\n",
       "      <td>Natural Language Processing and Information Re...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td># Natural Language Processing and Information ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>101</td>\n",
       "      <td>Natural Language Processing and Information Re...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td># Natural Language Processing and Information ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>Natural Language Processing and Information Re...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td># Natural Language Processing and Information ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              title  occurrence weight  \\\n",
       "0    23  Natural Language Processing and Information Re...           0.444444   \n",
       "1    73  Graph RAG and Community Summarization in NLP a...           0.333333   \n",
       "2    78  Few-Shot Examples and Their Role in Enhancing ...           0.166667   \n",
       "3    35  Natural Language Processing and Information Re...           0.111111   \n",
       "4    80  Natural Language Processing and Information Re...           0.111111   \n",
       "..  ...                                                ...                ...   \n",
       "78   82  Retrieval-Generation Synergy in Large Language...           0.055556   \n",
       "79   40  LLAMA and Its Impact on Natural Language Proce...           0.055556   \n",
       "80   30  Natural Language Processing and Information Re...           0.055556   \n",
       "81  101  Natural Language Processing and Information Re...           0.055556   \n",
       "82    1  Natural Language Processing and Information Re...           0.055556   \n",
       "\n",
       "                                              content  rank  \n",
       "0   # Natural Language Processing and Information ...   9.0  \n",
       "1   # Graph RAG and Community Summarization in NLP...   9.0  \n",
       "2   # Few-Shot Examples and Their Role in Enhancin...   9.0  \n",
       "3   # Natural Language Processing and Information ...   9.0  \n",
       "4   # Natural Language Processing and Information ...   9.0  \n",
       "..                                                ...   ...  \n",
       "78  # Retrieval-Generation Synergy in Large Langua...   9.0  \n",
       "79  # LLAMA and Its Impact on Natural Language Pro...   9.0  \n",
       "80  # Natural Language Processing and Information ...   9.0  \n",
       "81  # Natural Language Processing and Information ...   9.0  \n",
       "82  # Natural Language Processing and Information ...   9.0  \n",
       "\n",
       "[83 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the data used to build the context for the LLM responses\n",
    "result.context_data[\"reports\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM calls: 7. LLM tokens: 75225\n"
     ]
    }
   ],
   "source": [
    "# inspect number of LLM calls and tokens\n",
    "print(f\"LLM calls: {result.llm_calls}. LLM tokens: {result.prompt_tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
