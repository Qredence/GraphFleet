{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCopyright (c) Microsoft Corporation.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.indexer_adapters import read_indexer_entities, read_indexer_reports\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.structured_search.global_search.community_context import (\n",
    "    GlobalCommunityContext,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.search import GlobalSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Search example\n",
    "\n",
    "Global search method generates answers by searching over all AI-generated community reports in a map-reduce fashion. This is a resource-intensive method, but often gives good responses for questions that require an understanding of the dataset as a whole (e.g. What are the most significant values of the herbs mentioned in this notebook?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"GRAPHRAG_API_KEY\"]\n",
    "llm_model = os.environ[\"GRAPHRAG_LLM_MODEL\"]\n",
    "embedding_model = os.environ[\"GRAPHRAG_EMBEDDING_MODEL\"]\n",
    "api_base = os.environ[\"GRAPHRAG_API_BASE\"]\n",
    "api_version = os.environ[\"GRAPHRAG_API_VERSION\"]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_base=api_base,\n",
    "    api_version=api_version,\n",
    "    model=llm_model,\n",
    "    api_type=OpenaiApiType.AzureOpenAI,  # OpenaiApiType.OpenAI or OpenaiApiType.AzureOpenAI\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load community reports as context for global search\n",
    "\n",
    "- Load all community reports in the `create_final_community_reports` table from the ire-indexing engine, to be used as context data for global search.\n",
    "- Load entities from the `create_final_nodes` and `create_final_entities` tables from the ire-indexing engine, to be used for calculating community weights for context ranking. Note that this is optional (if no entities are provided, we will not calculate community weights and only use the `rank` attribute in the community reports table for context ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet files generated from indexing pipeline\n",
    "INPUT_DIR = \"../graphfleet/output/20240828-113421/artifacts\"\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "\n",
    "# community level in the Leiden community hierarchy from which we will load the community reports\n",
    "# higher value means we use reports from more fine-grained communities (at the cost of higher computation cost)\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total report count: 263\n",
      "Report count after filtering by community level 2: 208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "      <th>full_content</th>\n",
       "      <th>level</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>full_content_json</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td># LATS and its Impact on AI and ML Benchmarks\\...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LATS and its Impact on AI and ML Benchmarks</td>\n",
       "      <td>The report provides a comprehensive and insigh...</td>\n",
       "      <td>The community revolves around the LATS (Langua...</td>\n",
       "      <td>[{'explanation': 'LATS (Language Agent Tree Se...</td>\n",
       "      <td>{\\n    \"title\": \"LATS and its Impact on AI and...</td>\n",
       "      <td>7df98cc7-daf6-401b-9dcf-ae5c8f5f607c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td># Search Algorithms in AI and ML: A*, DFS, and...</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Search Algorithms in AI and ML: A*, DFS, and LATS</td>\n",
       "      <td>The rating is high due to the significant impa...</td>\n",
       "      <td>The community revolves around the study and ap...</td>\n",
       "      <td>[{'explanation': 'A* is a search algorithm tha...</td>\n",
       "      <td>{\\n    \"title\": \"Search Algorithms in AI and M...</td>\n",
       "      <td>db392895-4869-439a-b953-337446d24da6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td># LATS Algorithm and Its Action Space\\n\\nThe c...</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>LATS Algorithm and Its Action Space</td>\n",
       "      <td>The rating is high due to the detailed insight...</td>\n",
       "      <td>The community revolves around the LATS algorit...</td>\n",
       "      <td>[{'explanation': 'The LATS algorithm is a pivo...</td>\n",
       "      <td>{\\n    \"title\": \"LATS Algorithm and Its Action...</td>\n",
       "      <td>f6f9c187-6d63-4775-a0ff-9b42259b3235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td># Monte Carlo Tree Search (MCTS) and its Role ...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Monte Carlo Tree Search (MCTS) and its Role in...</td>\n",
       "      <td>The rating is high due to the significant impa...</td>\n",
       "      <td>The community revolves around Monte Carlo Tree...</td>\n",
       "      <td>[{'explanation': 'Monte Carlo Tree Search (MCT...</td>\n",
       "      <td>{\\n    \"title\": \"Monte Carlo Tree Search (MCTS...</td>\n",
       "      <td>7eed378a-8347-4466-9180-88d87cbfb6bc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td># Sampling and Stochastic Nature in Language M...</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Sampling and Stochastic Nature in Language Mod...</td>\n",
       "      <td>The rating is high due to the critical role th...</td>\n",
       "      <td>The community focuses on the interplay between...</td>\n",
       "      <td>[{'explanation': 'Sampling is a crucial proces...</td>\n",
       "      <td>{\\n    \"title\": \"Sampling and Stochastic Natur...</td>\n",
       "      <td>24afb751-6e1d-4143-8b3d-ef0e3768ef2e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  community                                       full_content  level  rank  \\\n",
       "0       149  # LATS and its Impact on AI and ML Benchmarks\\...      2   9.0   \n",
       "1       150  # Search Algorithms in AI and ML: A*, DFS, and...      2   8.5   \n",
       "2       151  # LATS Algorithm and Its Action Space\\n\\nThe c...      2   8.5   \n",
       "3       152  # Monte Carlo Tree Search (MCTS) and its Role ...      2   9.0   \n",
       "4       153  # Sampling and Stochastic Nature in Language M...      2   8.5   \n",
       "\n",
       "                                               title  \\\n",
       "0        LATS and its Impact on AI and ML Benchmarks   \n",
       "1  Search Algorithms in AI and ML: A*, DFS, and LATS   \n",
       "2                LATS Algorithm and Its Action Space   \n",
       "3  Monte Carlo Tree Search (MCTS) and its Role in...   \n",
       "4  Sampling and Stochastic Nature in Language Mod...   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The report provides a comprehensive and insigh...   \n",
       "1  The rating is high due to the significant impa...   \n",
       "2  The rating is high due to the detailed insight...   \n",
       "3  The rating is high due to the significant impa...   \n",
       "4  The rating is high due to the critical role th...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The community revolves around the LATS (Langua...   \n",
       "1  The community revolves around the study and ap...   \n",
       "2  The community revolves around the LATS algorit...   \n",
       "3  The community revolves around Monte Carlo Tree...   \n",
       "4  The community focuses on the interplay between...   \n",
       "\n",
       "                                            findings  \\\n",
       "0  [{'explanation': 'LATS (Language Agent Tree Se...   \n",
       "1  [{'explanation': 'A* is a search algorithm tha...   \n",
       "2  [{'explanation': 'The LATS algorithm is a pivo...   \n",
       "3  [{'explanation': 'Monte Carlo Tree Search (MCT...   \n",
       "4  [{'explanation': 'Sampling is a crucial proces...   \n",
       "\n",
       "                                   full_content_json  \\\n",
       "0  {\\n    \"title\": \"LATS and its Impact on AI and...   \n",
       "1  {\\n    \"title\": \"Search Algorithms in AI and M...   \n",
       "2  {\\n    \"title\": \"LATS Algorithm and Its Action...   \n",
       "3  {\\n    \"title\": \"Monte Carlo Tree Search (MCTS...   \n",
       "4  {\\n    \"title\": \"Sampling and Stochastic Natur...   \n",
       "\n",
       "                                     id  \n",
       "0  7df98cc7-daf6-401b-9dcf-ae5c8f5f607c  \n",
       "1  db392895-4869-439a-b953-337446d24da6  \n",
       "2  f6f9c187-6d63-4775-a0ff-9b42259b3235  \n",
       "3  7eed378a-8347-4466-9180-88d87cbfb6bc  \n",
       "4  24afb751-6e1d-4143-8b3d-ef0e3768ef2e  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "print(f\"Total report count: {len(report_df)}\")\n",
    "print(\n",
    "    f\"Report count after filtering by community level {COMMUNITY_LEVEL}: {len(reports)}\"\n",
    ")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build global context based on community reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = GlobalCommunityContext(\n",
    "    community_reports=reports,\n",
    "    entities=entities,  # default to None if you don't want to use community weights for ranking\n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform global search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder_params = {\n",
    "    \"use_community_summary\": False,  # False means using full community reports. True means using community short summaries.\n",
    "    \"shuffle_data\": True,\n",
    "    \"include_community_rank\": True,\n",
    "    \"min_community_rank\": 0,\n",
    "    \"community_rank_name\": \"rank\",\n",
    "    \"include_community_weight\": True,\n",
    "    \"community_weight_name\": \"occurrence weight\",\n",
    "    \"normalize_community_weight\": True,\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    \"context_name\": \"Reports\",\n",
    "}\n",
    "\n",
    "map_llm_params = {\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.0,\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "}\n",
    "\n",
    "reduce_llm_params = {\n",
    "    \"max_tokens\": 2000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000-1500)\n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = GlobalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    max_data_tokens=12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    map_llm_params=map_llm_params,\n",
    "    reduce_llm_params=reduce_llm_params,\n",
    "    allow_general_knowledge=True,  # set this to True will add instruction to encourage the LLM to incorporate general knowledge in the response, which may increase hallucinations, but could be useful in some use cases.\n",
    "    json_mode=True,  # set this to False if your LLM model does not support JSON mode.\n",
    "    context_builder_params=context_builder_params,\n",
    "    concurrent_coroutines=32,\n",
    "    response_type=\"multiple paragraphs\",  # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Multi-Agent System Incorporating Tree Search Algorithm and GraphRAG\n",
      "\n",
      "A multi-agent system that incorporates both the tree search algorithm and GraphRAG can be designed to perform complex data retrieval, reasoning, and knowledge graph construction tasks. Below is an example of such a system:\n",
      "\n",
      "#### System Overview\n",
      "\n",
      "1. **Data Retrieval Agent**: This agent uses a tree search algorithm, such as Depth-First Search (DFS) or Breadth-First Search (BFS), to explore and retrieve relevant data from a large dataset. The tree search algorithm helps in efficiently navigating through the data to find the most pertinent information [Data: Reports (217, 231, 92)].\n",
      "\n",
      "2. **Data Processing Agent**: Once the data is retrieved, this agent processes the data to ensure it is clean and structured. It may use various data preprocessing techniques to handle missing values, normalize data, and remove duplicates.\n",
      "\n",
      "3. **Knowledge Graph Construction Agent**: This agent employs GraphRAG (Graph-based Retrieval-Augmented Generation) to organize and structure the processed data into a coherent knowledge graph. GraphRAG ensures that the retrieved data is accurately represented in the knowledge graph by creating and reasoning over graph structures [Data: Reports (225, 216)].\n",
      "\n",
      "4. **Meta Agent Search**: This component iteratively discovers and evaluates high-performance agents using tree search algorithms like A* or DFS. It ensures that the most efficient and effective agents are selected for the task, optimizing the overall system performance [Data: Reports (255, 49, 42)].\n",
      "\n",
      "#### Example: Language Agent Tree Search (LATS)\n",
      "\n",
      "The Language Agent Tree Search (LATS) framework is a prime example of a multi-agent system that incorporates the tree search algorithm. LATS leverages Monte Carlo Tree Search (MCTS) to enhance performance across various domains by sampling nodes and using trajectories. It combines internal reasoning and external retrieval strategies, significantly improving performance on tasks such as HotPotQA, programming challenges, and the Game of 24 [Data: Reports (149)].\n",
      "\n",
      "### Agent for Creating a Knowledge Graph\n",
      "\n",
      "An agent designed to help create a knowledge graph can leverage the capabilities of GraphRAG and other supporting tools. Here is an example of such an agent:\n",
      "\n",
      "#### Knowledge Graph Construction Agent\n",
      "\n",
      "1. **GraphRAG Method**: This agent uses the GraphRAG method to process and generate text based on retrieved information. It assesses the comprehensiveness and relevance of the generated content and constructs a graph index that organizes the information into a coherent structure [Data: Reports (225, 216)].\n",
      "\n",
      "2. **LangChain and LlamaIndex**: The agent can leverage LangChain, an open-source agent framework that supports various graph databases and graph-based RAG applications. LangChain provides functions for building context-aware reasoning applications, which are essential for creating and managing knowledge graphs. LlamaIndex, known for its development of the LlamaIndex Knowledge Graph Index project, can collaborate with LangChain to enhance the capabilities of graph-based RAG applications [Data: Reports (219)].\n",
      "\n",
      "3. **Iterative Retrieval and Generation**: The agent iteratively retrieves relevant data and generates responses, organizing this information into a graph structure. This process involves using graph elements such as entity nodes and relationship edges to represent the data accurately [Data: Reports (231, 92)].\n",
      "\n",
      "4. **Community Summaries**: To enhance the retrieval process, the agent can use community summaries, ensuring that the knowledge graph is both accurate and comprehensive [Data: Reports (225, 216)].\n",
      "\n",
      "By integrating these components, the multi-agent system can efficiently create and manage a knowledge graph, providing a powerful tool for complex data retrieval and reasoning tasks.\n"
     ]
    }
   ],
   "source": [
    "result = await search_engine.asearch(\n",
    "    \"Write an example of multi-agent system that incorporates the tree search algorithm? and GraphRAG?Show me an agent that can help me create a knowledge graph\"\n",
    ")\n",
    "\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>occurrence weight</th>\n",
       "      <th>content</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169</td>\n",
       "      <td>MGSM and Verified Multimodal Agent in AI and ML</td>\n",
       "      <td>0.307692</td>\n",
       "      <td># MGSM and Verified Multimodal Agent in AI and...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239</td>\n",
       "      <td>META AGENT and Advanced Driver Assistance Syst...</td>\n",
       "      <td>0.307692</td>\n",
       "      <td># META AGENT and Advanced Driver Assistance Sy...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>Search and Lookup Actions in HotPotQA and Webshop</td>\n",
       "      <td>0.230769</td>\n",
       "      <td># Search and Lookup Actions in HotPotQA and We...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "      <td>Microsoft and AI/ML Research Community</td>\n",
       "      <td>0.192308</td>\n",
       "      <td># Microsoft and AI/ML Research Community\\n\\nTh...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>FM_Module and TaskInfo in AI and ML</td>\n",
       "      <td>0.192308</td>\n",
       "      <td># FM_Module and TaskInfo in AI and ML\\n\\nThe c...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>230</td>\n",
       "      <td>Hierarchical Clustering and Community Structur...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td># Hierarchical Clustering and Community Struct...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>138</td>\n",
       "      <td>FunSearch and Foundation Models</td>\n",
       "      <td>0.076923</td>\n",
       "      <td># FunSearch and Foundation Models\\n\\nThe commu...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>156</td>\n",
       "      <td>LATS and UCT Algorithm in AI and ML</td>\n",
       "      <td>0.076923</td>\n",
       "      <td># LATS and UCT Algorithm in AI and ML\\n\\nThe c...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>91</td>\n",
       "      <td>Hierarchical Index in AI and ML</td>\n",
       "      <td>0.038462</td>\n",
       "      <td># Hierarchical Index in AI and ML\\n\\nThe commu...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>95</td>\n",
       "      <td>Self-Memory in Generation-Augmented Retrieval</td>\n",
       "      <td>0.038462</td>\n",
       "      <td># Self-Memory in Generation-Augmented Retrieva...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0    169    MGSM and Verified Multimodal Agent in AI and ML   \n",
       "1    239  META AGENT and Advanced Driver Assistance Syst...   \n",
       "2     55  Search and Lookup Actions in HotPotQA and Webshop   \n",
       "3    142             Microsoft and AI/ML Research Community   \n",
       "4    125                FM_Module and TaskInfo in AI and ML   \n",
       "..   ...                                                ...   \n",
       "203  230  Hierarchical Clustering and Community Structur...   \n",
       "204  138                    FunSearch and Foundation Models   \n",
       "205  156                LATS and UCT Algorithm in AI and ML   \n",
       "206   91                    Hierarchical Index in AI and ML   \n",
       "207   95      Self-Memory in Generation-Augmented Retrieval   \n",
       "\n",
       "     occurrence weight                                            content  \\\n",
       "0             0.307692  # MGSM and Verified Multimodal Agent in AI and...   \n",
       "1             0.307692  # META AGENT and Advanced Driver Assistance Sy...   \n",
       "2             0.230769  # Search and Lookup Actions in HotPotQA and We...   \n",
       "3             0.192308  # Microsoft and AI/ML Research Community\\n\\nTh...   \n",
       "4             0.192308  # FM_Module and TaskInfo in AI and ML\\n\\nThe c...   \n",
       "..                 ...                                                ...   \n",
       "203           0.076923  # Hierarchical Clustering and Community Struct...   \n",
       "204           0.076923  # FunSearch and Foundation Models\\n\\nThe commu...   \n",
       "205           0.076923  # LATS and UCT Algorithm in AI and ML\\n\\nThe c...   \n",
       "206           0.038462  # Hierarchical Index in AI and ML\\n\\nThe commu...   \n",
       "207           0.038462  # Self-Memory in Generation-Augmented Retrieva...   \n",
       "\n",
       "     rank  \n",
       "0     9.0  \n",
       "1     9.0  \n",
       "2     8.5  \n",
       "3     9.0  \n",
       "4     9.0  \n",
       "..    ...  \n",
       "203   8.5  \n",
       "204   8.5  \n",
       "205   8.5  \n",
       "206   8.5  \n",
       "207   8.5  \n",
       "\n",
       "[208 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the data used to build the context for the LLM responses\n",
    "result.context_data[\"reports\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM calls: 14. LLM tokens: 161803\n"
     ]
    }
   ],
   "source": [
    "# inspect number of LLM calls and tokens\n",
    "print(f\"LLM calls: {result.llm_calls}. LLM tokens: {result.prompt_tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
