{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCopyright (c) Microsoft Corporation.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.indexer_adapters import read_indexer_entities, read_indexer_reports\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.structured_search.global_search.community_context import (\n",
    "    GlobalCommunityContext,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.search import GlobalSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Search example\n",
    "\n",
    "Global search method generates answers by searching over all AI-generated community reports in a map-reduce fashion. This is a resource-intensive method, but often gives good responses for questions that require an understanding of the dataset as a whole (e.g. What are the most significant values of the herbs mentioned in this notebook?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"GRAPHRAG_API_KEY\"]\n",
    "llm_model = os.environ[\"GRAPHRAG_LLM_MODEL\"]\n",
    "embedding_model = os.environ[\"GRAPHRAG_EMBEDDING_MODEL\"]\n",
    "api_base = os.environ[\"GRAPHRAG_API_BASE\"]\n",
    "api_version = os.environ[\"GRAPHRAG_API_VERSION\"]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_base=api_base,\n",
    "    api_version=api_version,\n",
    "    model=llm_model,\n",
    "    api_type=OpenaiApiType.AzureOpenAI,  # OpenaiApiType.OpenAI or OpenaiApiType.AzureOpenAI\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load community reports as context for global search\n",
    "\n",
    "- Load all community reports in the `create_final_community_reports` table from the ire-indexing engine, to be used as context data for global search.\n",
    "- Load entities from the `create_final_nodes` and `create_final_entities` tables from the ire-indexing engine, to be used for calculating community weights for context ranking. Note that this is optional (if no entities are provided, we will not calculate community weights and only use the `rank` attribute in the community reports table for context ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet files generated from indexing pipeline\n",
    "INPUT_DIR = \"../graphfleet/output/20240827-012901/artifacts\"\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "\n",
    "# community level in the Leiden community hierarchy from which we will load the community reports\n",
    "# higher value means we use reports from more fine-grained communities (at the cost of higher computation cost)\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/GraphFleet/.venv/lib/python3.11/site-packages/graphrag/query/indexer_adapters.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].fillna(-1)\n",
      "/workspaces/GraphFleet/.venv/lib/python3.11/site-packages/graphrag/query/indexer_adapters.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total report count: 239\n",
      "Report count after filtering by community level 2: 185\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "      <th>full_content</th>\n",
       "      <th>level</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>full_content_json</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237</td>\n",
       "      <td># AGIEval and AI Model Performance Evaluation\\...</td>\n",
       "      <td>3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>AGIEval and AI Model Performance Evaluation</td>\n",
       "      <td>The rating is high due to AGIEval's significan...</td>\n",
       "      <td>The community revolves around AGIEval, a human...</td>\n",
       "      <td>[{'explanation': 'AGIEval is a pivotal benchma...</td>\n",
       "      <td>{\\n    \"title\": \"AGIEval and AI Model Performa...</td>\n",
       "      <td>c32ecac8-6dea-4fd4-817d-1cd6518f98de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td># Orca-3 and its Ecosystem\\n\\nThe community re...</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Orca-3 and its Ecosystem</td>\n",
       "      <td>The report is highly significant due to the de...</td>\n",
       "      <td>The community revolves around the Orca-3 langu...</td>\n",
       "      <td>[{'explanation': 'Orca-3 has shown notable enh...</td>\n",
       "      <td>{\\n    \"title\": \"Orca-3 and its Ecosystem\",\\n ...</td>\n",
       "      <td>99902b15-234c-4514-b9db-e04c7ac0f595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td># Agents and Reading Comprehension in AI\\n\\nTh...</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Agents and Reading Comprehension in AI</td>\n",
       "      <td>The rating is high due to the significant impa...</td>\n",
       "      <td>The community focuses on the development and o...</td>\n",
       "      <td>[{'explanation': 'AGENT is a central entity in...</td>\n",
       "      <td>{\\n    \"title\": \"Agents and Reading Comprehens...</td>\n",
       "      <td>86999f2f-567c-43ac-809d-d85f8df8092c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135</td>\n",
       "      <td># Seed Instruction Generation Flow and Compreh...</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Seed Instruction Generation Flow and Comprehen...</td>\n",
       "      <td>The rating is high due to the significant impa...</td>\n",
       "      <td>The community centers around the 'Seed Instruc...</td>\n",
       "      <td>[{'explanation': 'The Seed Instruction Generat...</td>\n",
       "      <td>{\\n    \"title\": \"Seed Instruction Generation F...</td>\n",
       "      <td>73aeb516-a05a-4069-9bed-0f365a739667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td># Instruction Refinement Flow in AgentInstruct...</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Instruction Refinement Flow in AgentInstruct</td>\n",
       "      <td>The rating is high due to the significant impa...</td>\n",
       "      <td>The community centers around the Instruction R...</td>\n",
       "      <td>[{'explanation': 'The Instruction Refinement F...</td>\n",
       "      <td>{\\n    \"title\": \"Instruction Refinement Flow i...</td>\n",
       "      <td>054de93a-962b-4a11-8c95-44ac2c350e15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  community                                       full_content  level  rank  \\\n",
       "0       237  # AGIEval and AI Model Performance Evaluation\\...      3   8.5   \n",
       "1       238  # Orca-3 and its Ecosystem\\n\\nThe community re...      3   9.0   \n",
       "2       134  # Agents and Reading Comprehension in AI\\n\\nTh...      2   8.5   \n",
       "3       135  # Seed Instruction Generation Flow and Compreh...      2   8.5   \n",
       "4       136  # Instruction Refinement Flow in AgentInstruct...      2   8.5   \n",
       "\n",
       "                                               title  \\\n",
       "0        AGIEval and AI Model Performance Evaluation   \n",
       "1                           Orca-3 and its Ecosystem   \n",
       "2             Agents and Reading Comprehension in AI   \n",
       "3  Seed Instruction Generation Flow and Comprehen...   \n",
       "4       Instruction Refinement Flow in AgentInstruct   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The rating is high due to AGIEval's significan...   \n",
       "1  The report is highly significant due to the de...   \n",
       "2  The rating is high due to the significant impa...   \n",
       "3  The rating is high due to the significant impa...   \n",
       "4  The rating is high due to the significant impa...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The community revolves around AGIEval, a human...   \n",
       "1  The community revolves around the Orca-3 langu...   \n",
       "2  The community focuses on the development and o...   \n",
       "3  The community centers around the 'Seed Instruc...   \n",
       "4  The community centers around the Instruction R...   \n",
       "\n",
       "                                            findings  \\\n",
       "0  [{'explanation': 'AGIEval is a pivotal benchma...   \n",
       "1  [{'explanation': 'Orca-3 has shown notable enh...   \n",
       "2  [{'explanation': 'AGENT is a central entity in...   \n",
       "3  [{'explanation': 'The Seed Instruction Generat...   \n",
       "4  [{'explanation': 'The Instruction Refinement F...   \n",
       "\n",
       "                                   full_content_json  \\\n",
       "0  {\\n    \"title\": \"AGIEval and AI Model Performa...   \n",
       "1  {\\n    \"title\": \"Orca-3 and its Ecosystem\",\\n ...   \n",
       "2  {\\n    \"title\": \"Agents and Reading Comprehens...   \n",
       "3  {\\n    \"title\": \"Seed Instruction Generation F...   \n",
       "4  {\\n    \"title\": \"Instruction Refinement Flow i...   \n",
       "\n",
       "                                     id  \n",
       "0  c32ecac8-6dea-4fd4-817d-1cd6518f98de  \n",
       "1  99902b15-234c-4514-b9db-e04c7ac0f595  \n",
       "2  86999f2f-567c-43ac-809d-d85f8df8092c  \n",
       "3  73aeb516-a05a-4069-9bed-0f365a739667  \n",
       "4  054de93a-962b-4a11-8c95-44ac2c350e15  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "print(f\"Total report count: {len(report_df)}\")\n",
    "print(\n",
    "    f\"Report count after filtering by community level {COMMUNITY_LEVEL}: {len(reports)}\"\n",
    ")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build global context based on community reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = GlobalCommunityContext(\n",
    "    community_reports=reports,\n",
    "    entities=entities,  # default to None if you don't want to use community weights for ranking\n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform global search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder_params = {\n",
    "    \"use_community_summary\": False,  # False means using full community reports. True means using community short summaries.\n",
    "    \"shuffle_data\": True,\n",
    "    \"include_community_rank\": True,\n",
    "    \"min_community_rank\": 0,\n",
    "    \"community_rank_name\": \"rank\",\n",
    "    \"include_community_weight\": True,\n",
    "    \"community_weight_name\": \"occurrence weight\",\n",
    "    \"normalize_community_weight\": True,\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    \"context_name\": \"Reports\",\n",
    "}\n",
    "\n",
    "map_llm_params = {\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.0,\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "}\n",
    "\n",
    "reduce_llm_params = {\n",
    "    \"max_tokens\": 2000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000-1500)\n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = GlobalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    max_data_tokens=12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    map_llm_params=map_llm_params,\n",
    "    reduce_llm_params=reduce_llm_params,\n",
    "    allow_general_knowledge=True,  # set this to True will add instruction to encourage the LLM to incorporate general knowledge in the response, which may increase hallucinations, but could be useful in some use cases.\n",
    "    json_mode=True,  # set this to False if your LLM model does not support JSON mode.\n",
    "    context_builder_params=context_builder_params,\n",
    "    concurrent_coroutines=32,\n",
    "    response_type=\"multiple paragraphs\",  # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Multi-Agent System Incorporating Tree Search Algorithm and GraphRAG\n",
      "\n",
      "A multi-agent system that incorporates both the tree search algorithm and GraphRAG can be designed to enhance decision-making and knowledge graph creation. This system leverages the strengths of Monte Carlo Tree Search (MCTS) for exploring decision paths and GraphRAG for organizing and retrieving information.\n",
      "\n",
      "#### Language Agent Tree Search (LATS)\n",
      "\n",
      "One example of such a system is the Language Agent Tree Search (LATS) framework. LATS integrates MCTS to enable language models to act as agents, facilitating proficient exploration and enhanced decision-making. The system uses MCTS to construct the best trajectory from sampled actions, making it a powerful tool for model-based reinforcement learning and decision-making environments. LATS has demonstrated high performance in tasks such as HotPotQA, HumanEval, and the Game of 24 [Data: Reports (62, 140, 156, 182, +more)].\n",
      "\n",
      "### GraphRAG for Knowledge Graph Creation\n",
      "\n",
      "GraphRAG (Graph-based Retrieval-Augmented Generation) is a technique that enhances the performance of language models by incorporating external data into their responses. In a multi-agent system, GraphRAG can be used to retrieve relevant information from external data sources and incorporate it into the context window of the language model, significantly boosting model performance. This technique is particularly useful in agentic systems within the LangChain framework and is employed for query-focused summarization tasks [Data: Reports (108, 110, 190, 236, +more)].\n",
      "\n",
      "### Agent for Creating a Knowledge Graph\n",
      "\n",
      "An agent designed to help create a knowledge graph can leverage various techniques, including natural language processing (NLP) and machine learning. The agent can extract entities and relationships from unstructured text data, such as documents or web pages, and use this information to build a knowledge graph. For instance, the agent can identify key entities like people, organizations, and locations, and determine the relationships between them. Tools like GPT-4 can be used to enhance the extraction process, ensuring high-quality and diverse data for the knowledge graph [Data: Reports (26, 68, 132)].\n",
      "\n",
      "#### Integration of MCTS and GraphRAG\n",
      "\n",
      "An advanced agent can integrate both MCTS and GraphRAG to dynamically build and refine the knowledge graph. The agent uses MCTS to explore different paths and make decisions on how to structure the knowledge graph efficiently. Meanwhile, GraphRAG retrieves relevant information and organizes it into graph communities, ensuring that the knowledge graph is both comprehensive and well-structured [Data: Reports (142, 189)].\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "By combining the capabilities of tree search algorithms like MCTS and the GraphRAG approach, a multi-agent system can significantly enhance decision-making and knowledge graph creation. This integration allows for efficient exploration of decision paths and the organization of complex information into structured knowledge graphs, making it a powerful tool for various applications, including information retrieval, decision-making, and data analysis.\n"
     ]
    }
   ],
   "source": [
    "result = await search_engine.asearch(\n",
    "    \"Write an example of multi-agent system that incorporates the tree search algorithm? and GraphRAG?Show me an agent that can help me create a knowledge graph\"\n",
    ")\n",
    "\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>occurrence weight</th>\n",
       "      <th>content</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Quality-Diversity and Lu's Contributions in AI...</td>\n",
       "      <td>0.464286</td>\n",
       "      <td># Quality-Diversity and Lu's Contributions in ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153</td>\n",
       "      <td>Tree-of-Thought Prompting and Search Algorithm...</td>\n",
       "      <td>0.214286</td>\n",
       "      <td># Tree-of-Thought Prompting and Search Algorit...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168</td>\n",
       "      <td>LLM Debate and Key AI Techniques</td>\n",
       "      <td>0.214286</td>\n",
       "      <td># LLM Debate and Key AI Techniques\\n\\nThe comm...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>GSM-Hard Dataset and Key Contributors</td>\n",
       "      <td>0.214286</td>\n",
       "      <td># GSM-Hard Dataset and Key Contributors\\n\\nThe...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>Graph-Based RAG Applications and Key Technologies</td>\n",
       "      <td>0.142857</td>\n",
       "      <td># Graph-Based RAG Applications and Key Technol...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>75</td>\n",
       "      <td>MIRAGE Benchmark and Medical QA Datasets</td>\n",
       "      <td>0.107143</td>\n",
       "      <td># MIRAGE Benchmark and Medical QA Datasets\\n\\n...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>141</td>\n",
       "      <td>Zhuang and Search Algorithms in AI</td>\n",
       "      <td>0.107143</td>\n",
       "      <td># Zhuang and Search Algorithms in AI\\n\\nThe co...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>51</td>\n",
       "      <td>LM Agent and Sequential Decision-Making in AI</td>\n",
       "      <td>0.071429</td>\n",
       "      <td># LM Agent and Sequential Decision-Making in A...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>137</td>\n",
       "      <td>Suggester Agent and Genetic Predisposition in ...</td>\n",
       "      <td>0.035714</td>\n",
       "      <td># Suggester Agent and Genetic Predisposition i...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>211</td>\n",
       "      <td>Safe-ADAS and Caldwell</td>\n",
       "      <td>0.035714</td>\n",
       "      <td># Safe-ADAS and Caldwell\\n\\nThe community revo...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0     40  Quality-Diversity and Lu's Contributions in AI...   \n",
       "1    153  Tree-of-Thought Prompting and Search Algorithm...   \n",
       "2    168                   LLM Debate and Key AI Techniques   \n",
       "3     43              GSM-Hard Dataset and Key Contributors   \n",
       "4     81  Graph-Based RAG Applications and Key Technologies   \n",
       "..   ...                                                ...   \n",
       "180   75           MIRAGE Benchmark and Medical QA Datasets   \n",
       "181  141                 Zhuang and Search Algorithms in AI   \n",
       "182   51      LM Agent and Sequential Decision-Making in AI   \n",
       "183  137  Suggester Agent and Genetic Predisposition in ...   \n",
       "184  211                             Safe-ADAS and Caldwell   \n",
       "\n",
       "     occurrence weight                                            content  \\\n",
       "0             0.464286  # Quality-Diversity and Lu's Contributions in ...   \n",
       "1             0.214286  # Tree-of-Thought Prompting and Search Algorit...   \n",
       "2             0.214286  # LLM Debate and Key AI Techniques\\n\\nThe comm...   \n",
       "3             0.214286  # GSM-Hard Dataset and Key Contributors\\n\\nThe...   \n",
       "4             0.142857  # Graph-Based RAG Applications and Key Technol...   \n",
       "..                 ...                                                ...   \n",
       "180           0.107143  # MIRAGE Benchmark and Medical QA Datasets\\n\\n...   \n",
       "181           0.107143  # Zhuang and Search Algorithms in AI\\n\\nThe co...   \n",
       "182           0.071429  # LM Agent and Sequential Decision-Making in A...   \n",
       "183           0.035714  # Suggester Agent and Genetic Predisposition i...   \n",
       "184           0.035714  # Safe-ADAS and Caldwell\\n\\nThe community revo...   \n",
       "\n",
       "     rank  \n",
       "0     9.0  \n",
       "1     9.0  \n",
       "2     9.0  \n",
       "3     8.5  \n",
       "4     9.0  \n",
       "..    ...  \n",
       "180   8.5  \n",
       "181   8.5  \n",
       "182   9.0  \n",
       "183   8.5  \n",
       "184   7.5  \n",
       "\n",
       "[185 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the data used to build the context for the LLM responses\n",
    "result.context_data[\"reports\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM calls: 13. LLM tokens: 148682\n"
     ]
    }
   ],
   "source": [
    "# inspect number of LLM calls and tokens\n",
    "print(f\"LLM calls: {result.llm_calls}. LLM tokens: {result.prompt_tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
