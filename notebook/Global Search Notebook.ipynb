{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.indexer_adapters import read_indexer_entities, read_indexer_reports\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.structured_search.global_search.community_context import (\n",
    "    GlobalCommunityContext,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.search import GlobalSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Search example\n",
    "\n",
    "Global search method generates answers by searching over all AI-generated community reports in a map-reduce fashion. This is a resource-intensive method, but often gives good responses for questions that require an understanding of the dataset as a whole (e.g. What are the most significant values of the herbs mentioned in this notebook?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"GRAPHRAG_API_KEY\"]\n",
    "llm_model = os.environ[\"GRAPHRAG_LLM_MODEL\"]\n",
    "embedding_model = os.environ[\"GRAPHRAG_EMBEDDING_MODEL\"]\n",
    "api_base = os.environ[\"GRAPHRAG_API_BASE\"]\n",
    "api_version = os.environ[\"GRAPHRAG_API_VERSION\"]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_base=api_base,\n",
    "    api_version=api_version,\n",
    "    model=llm_model,\n",
    "    api_type=OpenaiApiType.AzureOpenAI,  # OpenaiApiType.OpenAI or OpenaiApiType.AzureOpenAI\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load community reports as context for global search\n",
    "\n",
    "- Load all community reports in the `create_final_community_reports` table from the ire-indexing engine, to be used as context data for global search.\n",
    "- Load entities from the `create_final_nodes` and `create_final_entities` tables from the ire-indexing engine, to be used for calculating community weights for context ranking. Note that this is optional (if no entities are provided, we will not calculate community weights and only use the `rank` attribute in the community reports table for context ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet files generated from indexing pipeline\n",
    "INPUT_DIR = \"../graphfleet/output/20240829-184001/artifacts\"\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "\n",
    "# community level in the Leiden community hierarchy from which we will load the community reports\n",
    "# higher value means we use reports from more fine-grained communities (at the cost of higher computation cost)\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/GraphFleet/.venv/lib/python3.11/site-packages/graphrag/query/indexer_adapters.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].fillna(-1)\n",
      "/workspaces/GraphFleet/.venv/lib/python3.11/site-packages/graphrag/query/indexer_adapters.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total report count: 280\n",
      "Report count after filtering by community level 2: 221\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "      <th>full_content</th>\n",
       "      <th>level</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>full_content_json</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td># LATS: Enhancing Language Model Performance t...</td>\n",
       "      <td>3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>LATS: Enhancing Language Model Performance thr...</td>\n",
       "      <td>The rating is high due to the comprehensive an...</td>\n",
       "      <td>The community revolves around the LATS (Langua...</td>\n",
       "      <td>[{'explanation': 'LATS (Language Agent Tree Se...</td>\n",
       "      <td>{\\n    \"title\": \"LATS: Enhancing Language Mode...</td>\n",
       "      <td>d208e1b8-576f-4968-8c1b-92cb0fcb59d4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279</td>\n",
       "      <td># RL-Based Training and Human Performance in W...</td>\n",
       "      <td>3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>RL-Based Training and Human Performance in Web...</td>\n",
       "      <td>The rating is high due to the significant insi...</td>\n",
       "      <td>The community centers around RL-based training...</td>\n",
       "      <td>[{'explanation': 'RL-based training is a centr...</td>\n",
       "      <td>{\\n    \"title\": \"RL-Based Training and Human P...</td>\n",
       "      <td>9c6a08a4-98c1-4cb6-bec6-52875abd78bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145</td>\n",
       "      <td># Monte Carlo Tree Search (MCTS) and its Algor...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Monte Carlo Tree Search (MCTS) and its Algorit...</td>\n",
       "      <td>The rating is high due to the significant impa...</td>\n",
       "      <td>The community revolves around the Monte Carlo ...</td>\n",
       "      <td>[{'explanation': 'Monte Carlo Tree Search (MCT...</td>\n",
       "      <td>{\\n    \"title\": \"Monte Carlo Tree Search (MCTS...</td>\n",
       "      <td>c1d17e27-378b-4d79-bcea-d27df46432d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146</td>\n",
       "      <td># Search Algorithms in LATS and ADAS\\n\\nThe co...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Search Algorithms in LATS and ADAS</td>\n",
       "      <td>The rating is high due to the critical role th...</td>\n",
       "      <td>The community revolves around various search a...</td>\n",
       "      <td>[{'explanation': 'Search algorithms such as DF...</td>\n",
       "      <td>{\\n    \"title\": \"Search Algorithms in LATS and...</td>\n",
       "      <td>471b2b23-dd3e-4851-a064-e3ac36c653b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td># Tree-Based Search and Key Contributors\\n\\nTh...</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Tree-Based Search and Key Contributors</td>\n",
       "      <td>The impact rating is high due to the significa...</td>\n",
       "      <td>The community revolves around the Tree-Based S...</td>\n",
       "      <td>[{'explanation': 'Tree-Based Search is the cen...</td>\n",
       "      <td>{\\n    \"title\": \"Tree-Based Search and Key Con...</td>\n",
       "      <td>200708bc-44e2-4cfd-9a57-ce82e132ee55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  community                                       full_content  level  rank  \\\n",
       "0       278  # LATS: Enhancing Language Model Performance t...      3   9.5   \n",
       "1       279  # RL-Based Training and Human Performance in W...      3   8.5   \n",
       "2       145  # Monte Carlo Tree Search (MCTS) and its Algor...      2   9.0   \n",
       "3       146  # Search Algorithms in LATS and ADAS\\n\\nThe co...      2   9.0   \n",
       "4       147  # Tree-Based Search and Key Contributors\\n\\nTh...      2   9.0   \n",
       "\n",
       "                                               title  \\\n",
       "0  LATS: Enhancing Language Model Performance thr...   \n",
       "1  RL-Based Training and Human Performance in Web...   \n",
       "2  Monte Carlo Tree Search (MCTS) and its Algorit...   \n",
       "3                 Search Algorithms in LATS and ADAS   \n",
       "4             Tree-Based Search and Key Contributors   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The rating is high due to the comprehensive an...   \n",
       "1  The rating is high due to the significant insi...   \n",
       "2  The rating is high due to the significant impa...   \n",
       "3  The rating is high due to the critical role th...   \n",
       "4  The impact rating is high due to the significa...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The community revolves around the LATS (Langua...   \n",
       "1  The community centers around RL-based training...   \n",
       "2  The community revolves around the Monte Carlo ...   \n",
       "3  The community revolves around various search a...   \n",
       "4  The community revolves around the Tree-Based S...   \n",
       "\n",
       "                                            findings  \\\n",
       "0  [{'explanation': 'LATS (Language Agent Tree Se...   \n",
       "1  [{'explanation': 'RL-based training is a centr...   \n",
       "2  [{'explanation': 'Monte Carlo Tree Search (MCT...   \n",
       "3  [{'explanation': 'Search algorithms such as DF...   \n",
       "4  [{'explanation': 'Tree-Based Search is the cen...   \n",
       "\n",
       "                                   full_content_json  \\\n",
       "0  {\\n    \"title\": \"LATS: Enhancing Language Mode...   \n",
       "1  {\\n    \"title\": \"RL-Based Training and Human P...   \n",
       "2  {\\n    \"title\": \"Monte Carlo Tree Search (MCTS...   \n",
       "3  {\\n    \"title\": \"Search Algorithms in LATS and...   \n",
       "4  {\\n    \"title\": \"Tree-Based Search and Key Con...   \n",
       "\n",
       "                                     id  \n",
       "0  d208e1b8-576f-4968-8c1b-92cb0fcb59d4  \n",
       "1  9c6a08a4-98c1-4cb6-bec6-52875abd78bf  \n",
       "2  c1d17e27-378b-4d79-bcea-d27df46432d5  \n",
       "3  471b2b23-dd3e-4851-a064-e3ac36c653b8  \n",
       "4  200708bc-44e2-4cfd-9a57-ce82e132ee55  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "print(f\"Total report count: {len(report_df)}\")\n",
    "print(\n",
    "    f\"Report count after filtering by community level {COMMUNITY_LEVEL}: {len(reports)}\"\n",
    ")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build global context based on community reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = GlobalCommunityContext(\n",
    "    community_reports=reports,\n",
    "    entities=entities,  # default to None if you don't want to use community weights for ranking\n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform global search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder_params = {\n",
    "    \"use_community_summary\": False,  # False means using full community reports. True means using community short summaries.\n",
    "    \"shuffle_data\": True,\n",
    "    \"include_community_rank\": True,\n",
    "    \"min_community_rank\": 0,\n",
    "    \"community_rank_name\": \"rank\",\n",
    "    \"include_community_weight\": True,\n",
    "    \"community_weight_name\": \"occurrence weight\",\n",
    "    \"normalize_community_weight\": True,\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    \"context_name\": \"Reports\",\n",
    "}\n",
    "\n",
    "map_llm_params = {\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.0,\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "}\n",
    "\n",
    "reduce_llm_params = {\n",
    "    \"max_tokens\": 2000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000-1500)\n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = GlobalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    max_data_tokens=12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "    map_llm_params=map_llm_params,\n",
    "    reduce_llm_params=reduce_llm_params,\n",
    "    allow_general_knowledge=True,  # set this to True will add instruction to encourage the LLM to incorporate general knowledge in the response, which may increase hallucinations, but could be useful in some use cases.\n",
    "    json_mode=True,  # set this to False if your LLM model does not support JSON mode.\n",
    "    context_builder_params=context_builder_params,\n",
    "    concurrent_coroutines=32,\n",
    "    response_type=\"multiple paragraphs\",\n",
    "    # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Multi-Agent System Incorporating Tree Search Algorithm and GraphRAG\n",
      "\n",
      "A multi-agent system that incorporates both the tree search algorithm and GraphRAG can be designed to enhance decision-making, planning, and knowledge graph construction. Below is an example of such a system:\n",
      "\n",
      "#### System Overview\n",
      "\n",
      "The system consists of multiple agents, each specialized in different tasks such as data retrieval, decision-making, and knowledge graph construction. The integration of tree search algorithms and GraphRAG ensures that the system can efficiently explore decision paths and generate comprehensive knowledge graphs.\n",
      "\n",
      "#### Key Components\n",
      "\n",
      "1. **Tree Search Agents**:\n",
      "    - **Language Agent Tree Search (LATS)**: This agent uses Monte Carlo Tree Search (MCTS) to explore decision trees and optimize outcomes. LATS integrates language models and self-reflections to enhance decision-making and problem-solving capabilities. It is particularly effective in domains like programming, interactive question-answering (QA), and web navigation [Data: Reports (165, 145, 166, 148, 159)].\n",
      "    - **Reasoning via Planning (RAP)**: This agent employs MCTS with roll-outs simulated by language models for reasoning tasks. RAP relies on internal knowledge without external feedback, making it suitable for complex decision-making processes [Data: Reports (154, 674, 631, 533, 784)].\n",
      "\n",
      "2. **GraphRAG Agents**:\n",
      "    - **GraphRAG for Summarization**: This agent uses GraphRAG to generate summaries and insights from graph data. It leverages the strengths of both retrieval-based and generative models to provide accurate and contextually relevant responses [Data: Reports (123, 54, 174, 57, 195)].\n",
      "    - **Knowledge Graph Construction**: This agent uses GraphRAG to retrieve relevant information from various datasets and generate structured data entries. It organizes this information into a coherent knowledge graph, ensuring that the data is accurate and comprehensive [Data: Reports (84, 200, 192, 239, 17, +more)].\n",
      "\n",
      "### Example Agent for Knowledge Graph Creation\n",
      "\n",
      "An agent designed to help create a knowledge graph can leverage the capabilities of both tree search algorithms and GraphRAG. Here is a detailed example:\n",
      "\n",
      "#### Agent: Knowledge Graph Builder\n",
      "\n",
      "**Functionality**:\n",
      "- **Data Retrieval**: The agent uses GraphRAG to retrieve relevant information from various sources such as databases, APIs, and text documents. It employs advanced entity extraction techniques to identify key entities and relationships within the data [Data: Reports (84, 200, 192, 239, 17, +more)].\n",
      "- **Tree Search for Decision-Making**: The agent uses LATS to explore different possible connections and relationships between entities. By simulating various actions and their potential results, the agent ensures that the most relevant and accurate links are established in the knowledge graph [Data: Reports (165, 145, 166, 148, 159)].\n",
      "- **Graph Construction**: The agent organizes the retrieved information into a structured knowledge graph. It uses GraphRAG's hierarchical community structure to ensure efficient data management and insightful reasoning capabilities [Data: Reports (200, 197, 155)].\n",
      "- **Summarization and Insights**: The agent generates summaries and insights from the graph data using GraphRAG. This provides a comprehensive view of the knowledge graph's structure and content, making it easier to understand and query [Data: Reports (123, 54, 174, 57, 195)].\n",
      "\n",
      "**Example Use Case**:\n",
      "- **Medical Knowledge Graph**: In a medical domain, the agent could use GraphRAG to retrieve and generate answers from medical question-answering datasets like BIOASQ, PubMedQA, and MedMCQA. The agent would integrate this information into a comprehensive knowledge graph, providing valuable insights for medical research and decision-making [Data: Reports (84)].\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "By integrating tree search algorithms and GraphRAG, the multi-agent system can effectively handle complex reasoning, planning, and knowledge graph construction tasks. The Knowledge Graph Builder agent exemplifies how these technologies can be combined to create a robust and informative knowledge graph, ensuring accurate and comprehensive data representation.\n"
     ]
    }
   ],
   "source": [
    "result = await search_engine.asearch(\n",
    "    \"Write an example of multi-agent system that incorporates the tree search algorithm? and GraphRAG?Show me an agent that can help me create a knowledge graph\"\n",
    ")\n",
    "\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>occurrence weight</th>\n",
       "      <th>content</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>GPT-4 and its Benchmarking Ecosystem</td>\n",
       "      <td>1.00</td>\n",
       "      <td># GPT-4 and its Benchmarking Ecosystem\\n\\nThe ...</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218</td>\n",
       "      <td>Meta Agent Search and ADAS Framework</td>\n",
       "      <td>1.00</td>\n",
       "      <td># Meta Agent Search and ADAS Framework\\n\\nThe ...</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>ARC Challenge and Transformation Rules</td>\n",
       "      <td>0.20</td>\n",
       "      <td># ARC Challenge and Transformation Rules\\n\\nTh...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174</td>\n",
       "      <td>Mistral-7B-Instruct and Orca-3 Performance Com...</td>\n",
       "      <td>0.20</td>\n",
       "      <td># Mistral-7B-Instruct and Orca-3 Performance C...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>Neo4J and NaLLM in Knowledge Graph Creation</td>\n",
       "      <td>0.15</td>\n",
       "      <td># Neo4J and NaLLM in Knowledge Graph Creation\\...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>171</td>\n",
       "      <td>Mostly Basic Programming Problems (MBPP) and A...</td>\n",
       "      <td>0.05</td>\n",
       "      <td># Mostly Basic Programming Problems (MBPP) and...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>65</td>\n",
       "      <td>Library Reconstruction and Nutritional APIs</td>\n",
       "      <td>0.05</td>\n",
       "      <td># Library Reconstruction and Nutritional APIs\\...</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>80</td>\n",
       "      <td>ACI-BENCH and its Contributors</td>\n",
       "      <td>0.10</td>\n",
       "      <td># ACI-BENCH and its Contributors\\n\\nThe commun...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>84</td>\n",
       "      <td>Medical Question-Answering Datasets and GPT Va...</td>\n",
       "      <td>0.10</td>\n",
       "      <td># Medical Question-Answering Datasets and GPT ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>152</td>\n",
       "      <td>Monte Carlo Tree Search (MCTS) and Upper Confi...</td>\n",
       "      <td>0.05</td>\n",
       "      <td># Monte Carlo Tree Search (MCTS) and Upper Con...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0     81               GPT-4 and its Benchmarking Ecosystem   \n",
       "1    218               Meta Agent Search and ADAS Framework   \n",
       "2    118             ARC Challenge and Transformation Rules   \n",
       "3    174  Mistral-7B-Instruct and Orca-3 Performance Com...   \n",
       "4     61        Neo4J and NaLLM in Knowledge Graph Creation   \n",
       "..   ...                                                ...   \n",
       "216  171  Mostly Basic Programming Problems (MBPP) and A...   \n",
       "217   65        Library Reconstruction and Nutritional APIs   \n",
       "218   80                     ACI-BENCH and its Contributors   \n",
       "219   84  Medical Question-Answering Datasets and GPT Va...   \n",
       "220  152  Monte Carlo Tree Search (MCTS) and Upper Confi...   \n",
       "\n",
       "     occurrence weight                                            content  \\\n",
       "0                 1.00  # GPT-4 and its Benchmarking Ecosystem\\n\\nThe ...   \n",
       "1                 1.00  # Meta Agent Search and ADAS Framework\\n\\nThe ...   \n",
       "2                 0.20  # ARC Challenge and Transformation Rules\\n\\nTh...   \n",
       "3                 0.20  # Mistral-7B-Instruct and Orca-3 Performance C...   \n",
       "4                 0.15  # Neo4J and NaLLM in Knowledge Graph Creation\\...   \n",
       "..                 ...                                                ...   \n",
       "216               0.05  # Mostly Basic Programming Problems (MBPP) and...   \n",
       "217               0.05  # Library Reconstruction and Nutritional APIs\\...   \n",
       "218               0.10  # ACI-BENCH and its Contributors\\n\\nThe commun...   \n",
       "219               0.10  # Medical Question-Answering Datasets and GPT ...   \n",
       "220               0.05  # Monte Carlo Tree Search (MCTS) and Upper Con...   \n",
       "\n",
       "     rank  \n",
       "0     9.5  \n",
       "1     9.5  \n",
       "2     9.0  \n",
       "3     8.5  \n",
       "4     9.0  \n",
       "..    ...  \n",
       "216   8.5  \n",
       "217   8.5  \n",
       "218   9.0  \n",
       "219   9.0  \n",
       "220   9.0  \n",
       "\n",
       "[221 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the data used to build the context for the LLM responses\n",
    "result.context_data[\"reports\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM calls: 15. LLM tokens: 171906\n"
     ]
    }
   ],
   "source": [
    "# inspect number of LLM calls and tokens\n",
    "print(f\"LLM calls: {result.llm_calls}. LLM tokens: {result.prompt_tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
