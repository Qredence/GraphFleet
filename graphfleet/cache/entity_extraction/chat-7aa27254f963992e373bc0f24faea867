{"result": "## Entities and Relationships Identified:\n\n(\"entity\"<|>\"Graph RAG\"<|>\"organization\"<|>\"Graph RAG is an advanced retrieval-augmented generation system that uses a graph-based approach to improve comprehensiveness and diversity in answers.\")##\n(\"entity\"<|>\"Na\u00efve RAG\"<|>\"organization\"<|>\"Na\u00efve RAG is a basic retrieval-augmented generation system that converts documents to text, splits text into chunks, and embeds these chunks into a vector space for retrieval.\")##\n(\"entity\"<|>\"Podcast Dataset\"<|>\"geo\"<|>\"The Podcast Dataset is a collection of podcast transcripts used for evaluating the performance of different RAG systems.\")##\n(\"entity\"<|>\"News Dataset\"<|>\"geo\"<|>\"The News Dataset is a collection of news articles used for evaluating the performance of different RAG systems.\")##\n(\"entity\"<|>\"Comprehensiveness\"<|>\"event\"<|>\"Comprehensiveness refers to the ability of a system to provide detailed and complete answers.\")##\n(\"entity\"<|>\"Diversity\"<|>\"event\"<|>\"Diversity refers to the ability of a system to provide varied and rich responses covering a wide range of perspectives.\")##\n(\"entity\"<|>\"Empowerment\"<|>\"event\"<|>\"Empowerment refers to the ability of a system to help users reach an informed understanding by providing specific examples, quotes, and citations.\")##\n(\"entity\"<|>\"Directness\"<|>\"event\"<|>\"Directness refers to the ability of a system to provide concise and specific answers to questions.\")##\n\n(\"relationship\"<|>\"Graph RAG\"<|>\"Na\u00efve RAG\"<|>\"Graph RAG outperforms Na\u00efve RAG in terms of comprehensiveness and diversity across datasets.\"<|>9)##\n(\"relationship\"<|>\"Graph RAG\"<|>\"Podcast Dataset\"<|>\"Graph RAG uses the Podcast Dataset to evaluate its performance in providing comprehensive and diverse answers.\"<|>8)##\n(\"relationship\"<|>\"Graph RAG\"<|>\"News Dataset\"<|>\"Graph RAG uses the News Dataset to evaluate its performance in providing comprehensive and diverse answers.\"<|>8)##\n(\"relationship\"<|>\"Na\u00efve RAG\"<|>\"Podcast Dataset\"<|>\"Na\u00efve RAG uses the Podcast Dataset to evaluate its performance in providing direct answers.\"<|>7)##\n(\"relationship\"<|>\"Na\u00efve RAG\"<|>\"News Dataset\"<|>\"Na\u00efve RAG uses the News Dataset to evaluate its performance in providing direct answers.\"<|>7)##\n(\"relationship\"<|>\"Comprehensiveness\"<|>\"Graph RAG\"<|>\"Graph RAG achieves high comprehensiveness win rates in evaluations.\"<|>9)##\n(\"relationship\"<|>\"Diversity\"<|>\"Graph RAG\"<|>\"Graph RAG achieves high diversity win rates in evaluations.\"<|>9)##\n(\"relationship\"<|>\"Empowerment\"<|>\"Graph RAG\"<|>\"Graph RAG shows mixed results in empowerment, indicating room for improvement in providing specific examples and citations.\"<|>6)##\n(\"relationship\"<|>\"Directness\"<|>\"Na\u00efve RAG\"<|>\"Na\u00efve RAG produces the most direct responses across all comparisons.\"<|>8)##\n\n<|COMPLETE|>", "input": "\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n\n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity's attributes and activities\nFormat each entity as (\"entity\"<|><entity_name><|><entity_type><|><entity_description>\n\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as (\"relationship\"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n\n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n\n4. When finished, output <|COMPLETE|>\n\n######################\n-Examples-\n######################\nExample 1:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\nwhile Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor's authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan's shared commitment to discovery was an unspoken rebellion against Cruz's narrowing vision of control and order.\n\nThen Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. \u201cIf this tech can be understood...\" Taylor said, their voice quieter, \"It could change the game for us. For all of us.\u201d\n\nThe underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor's, a wordless clash of wills softening into an uneasy truce.\n\nIt was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\n################\nOutput:\n(\"entity\"<|>\"Alex\"<|>\"person\"<|>\"Alex is a character who experiences frustration and is observant of the dynamics among other characters.\")##\n(\"entity\"<|>\"Taylor\"<|>\"person\"<|>\"Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.\")##\n(\"entity\"<|>\"Jordan\"<|>\"person\"<|>\"Jordan shares a commitment to discovery and has a significant interaction with Taylor regarding a device.\")##\n(\"entity\"<|>\"Cruz\"<|>\"person\"<|>\"Cruz is associated with a vision of control and order, influencing the dynamics among other characters.\")##\n(\"entity\"<|>\"The Device\"<|>\"technology\"<|>\"The Device is central to the story, with potential game-changing implications, and is revered by Taylor.\")##\n(\"relationship\"<|>\"Alex\"<|>\"Taylor\"<|>\"Alex is affected by Taylor's authoritarian certainty and observes changes in Taylor's attitude towards the device.\"<|>7)##\n(\"relationship\"<|>\"Alex\"<|>\"Jordan\"<|>\"Alex and Jordan share a commitment to discovery, which contrasts with Cruz's vision.\"<|>6)##\n(\"relationship\"<|>\"Taylor\"<|>\"Jordan\"<|>\"Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce.\"<|>8)##\n(\"relationship\"<|>\"Jordan\"<|>\"Cruz\"<|>\"Jordan's commitment to discovery is in rebellion against Cruz's vision of control and order.\"<|>5)##\n(\"relationship\"<|>\"Taylor\"<|>\"The Device\"<|>\"Taylor shows reverence towards the device, indicating its importance and potential impact.\"<|>9)<|COMPLETE|>\n#############################\nExample 2:\n\nEntity_types: [person, technology, mission, organization, location]\nText:\nThey were no longer mere operatives; they had become guardians of a threshold, keepers of a message from a realm beyond stars and stripes. This elevation in their mission could not be shackled by regulations and established protocols\u2014it demanded a new perspective, a new resolve.\n\nTension threaded through the dialogue of beeps and static as communications with Washington buzzed in the background. The team stood, a portentous air enveloping them. It was clear that the decisions they made in the ensuing hours could redefine humanity's place in the cosmos or condemn them to ignorance and potential peril.\n\nTheir connection to the stars solidified, the group moved to address the crystallizing warning, shifting from passive recipients to active participants. Mercer's latter instincts gained precedence\u2014 the team's mandate had evolved, no longer solely to observe and report but to interact and prepare. A metamorphosis had begun, and Operation: Dulce hummed with the newfound frequency of their daring, a tone set not by the earthly\n#############\nOutput:\n(\"entity\"<|>\"Washington\"<|>\"location\"<|>\"Washington is a location where communications are being received, indicating its importance in the decision-making process.\")##\n(\"entity\"<|>\"Operation: Dulce\"<|>\"mission\"<|>\"Operation: Dulce is described as a mission that has evolved to interact and prepare, indicating a significant shift in objectives and activities.\")##\n(\"entity\"<|>\"The team\"<|>\"organization\"<|>\"The team is portrayed as a group of individuals who have transitioned from passive observers to active participants in a mission, showing a dynamic change in their role.\")##\n(\"relationship\"<|>\"The team\"<|>\"Washington\"<|>\"The team receives communications from Washington, which influences their decision-making process.\"<|>7)##\n(\"relationship\"<|>\"The team\"<|>\"Operation: Dulce\"<|>\"The team is directly involved in Operation: Dulce, executing its evolved objectives and activities.\"<|>9)<|COMPLETE|>\n#############################\nExample 3:\n\nEntity_types: [person, role, technology, organization, event, location, concept]\nText:\ntheir voice slicing through the buzz of activity. \"Control may be an illusion when facing an intelligence that literally writes its own rules,\" they stated stoically, casting a watchful eye over the flurry of data.\n\n\"It's like it's learning to communicate,\" offered Sam Rivera from a nearby interface, their youthful energy boding a mix of awe and anxiety. \"This gives talking to strangers' a whole new meaning.\"\n\nAlex surveyed his team\u2014each face a study in concentration, determination, and not a small measure of trepidation. \"This might well be our first contact,\" he acknowledged, \"And we need to be ready for whatever answers back.\"\n\nTogether, they stood on the edge of the unknown, forging humanity's response to a message from the heavens. The ensuing silence was palpable\u2014a collective introspection about their role in this grand cosmic play, one that could rewrite human history.\n\nThe encrypted dialogue continued to unfold, its intricate patterns showing an almost uncanny anticipation\n#############\nOutput:\n(\"entity\"<|>\"Sam Rivera\"<|>\"person\"<|>\"Sam Rivera is a member of a team working on communicating with an unknown intelligence, showing a mix of awe and anxiety.\")##\n(\"entity\"<|>\"Alex\"<|>\"person\"<|>\"Alex is the leader of a team attempting first contact with an unknown intelligence, acknowledging the significance of their task.\")##\n(\"entity\"<|>\"Control\"<|>\"concept\"<|>\"Control refers to the ability to manage or govern, which is challenged by an intelligence that writes its own rules.\")##\n(\"entity\"<|>\"Intelligence\"<|>\"concept\"<|>\"Intelligence here refers to an unknown entity capable of writing its own rules and learning to communicate.\")##\n(\"entity\"<|>\"First Contact\"<|>\"event\"<|>\"First Contact is the potential initial communication between humanity and an unknown intelligence.\")##\n(\"entity\"<|>\"Humanity's Response\"<|>\"event\"<|>\"Humanity's Response is the collective action taken by Alex's team in response to a message from an unknown intelligence.\")##\n(\"relationship\"<|>\"Sam Rivera\"<|>\"Intelligence\"<|>\"Sam Rivera is directly involved in the process of learning to communicate with the unknown intelligence.\"<|>9)##\n(\"relationship\"<|>\"Alex\"<|>\"First Contact\"<|>\"Alex leads the team that might be making the First Contact with the unknown intelligence.\"<|>10)##\n(\"relationship\"<|>\"Alex\"<|>\"Humanity's Response\"<|>\"Alex and his team are the key figures in Humanity's Response to the unknown intelligence.\"<|>8)##\n(\"relationship\"<|>\"Control\"<|>\"Intelligence\"<|>\"The concept of Control is challenged by the Intelligence that writes its own rules.\"<|>7)<|COMPLETE|>\n#############################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: media. It also includes specific examples of their contributions and the impact they have on their\nrespective fields, as well as mentions of controversies and their implications. Answer 2, while\ndetailed in its coverage of a few individuals, is limited to a smaller number of public figures and\nfocuses primarily on their personal lives and relationships rather than a broad spectrum of their\nprofessional influence across the entertainment industry.\nDiversity: Winner=1 (Graph RAG)\nAnswer 1 is better because it provides a more varied and rich response by covering a wide range of\npublic figures from different sectors of the entertainment industry, including film, television, music,\nsports, gaming, and digital media. It offers insights into the contributions and influence of these\nfigures, as well as controversies and their impact on public discourse. The answer also cites specific\ndata sources for each mentioned figure, indicating a diverse range of evidence to support the claims.\nIn contrast, Answer 2 focuses on a smaller group of public figures, primarily from the music industry\nand sports, and relies heavily on a single source for data, which makes it less diverse in perspectives\nand insights.\nEmpowerment: Winner=1 (Graph RAG)\nAnswer 1 is better because it provides a comprehensive and structured overview of public figures\nacross various sectors of the entertainment industry, including film, television, music, sports, and\ndigital media. It lists multiple individuals, providing specific examples of their contributions and the\ncontext in which they are mentioned in entertainment articles, along with references to data reports\nfor each claim. This approach helps the reader understand the breadth of the topic and make informed\njudgments without being misled. In contrast, Answer 2 focuses on a smaller group of public figures\nand primarily discusses their personal lives and relationships, which may not provide as broad an\nunderstanding of the topic. While Answer 2 also cites sources, it does not match the depth and variety\nof Answer 1.\nDirectness: Winner=2 (Na \u00a8\u0131ve RAG)\nAnswer 2 is better because it directly lists specific public figures who are repeatedly mentioned\nacross various entertainment articles, such as Taylor Swift, Travis Kelce, Britney Spears, and Justin\nTimberlake, and provides concise explanations for their frequent mentions. Answer 1, while\ncomprehensive, includes a lot of detailed information about various figures in different sectors of\nentertainment, which, while informative, does not directly answer the question with the same level of\nconciseness and specificity as Answer 2.\nTable 2: Example question for the News article dataset, with generated answers from Graph RAG\n(C2) and Na \u00a8\u0131ve RAG, as well as LLM-generated assessments.\n8Podcast transcripts\n501728252221\n835050484344\n725050535049\n755247505250\n785750485052\n795651504850SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nComprehensiveness501823251919\n825050504346\n775050504644\n755050504445\n815754565048\n815456555250SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDiversity504257524951\n585059555251\n434150494748\n484551504950\n514853515051\n494952504950SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nEmpowerment505665606060\n445055525152\n354550474848\n404853505050\n404952505050\n404852505050SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDirectness\nNews articles\n502028252121\n805044413836\n725650525452\n755948505855\n796246425059\n796448454150SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nComprehensiveness503338352931\n675053454440\n624750404141\n655560505050\n715659505051\n696059504950SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDiversity504757495050\n535058505048\n434250424544\n515058505251\n505055485050\n505256495050SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nEmpowerment505459555554\n465055535252\n414550484847\n454752504949\n454852515049\n464853515150SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDirectness\nFigure 4: Head-to-head win rate percentages of (row condition) over (column condition) across two\ndatasets, four metrics, and 125 questions per comparison (each repeated five times and averaged).\nThe overall winner per dataset and metric is shown in bold. Self-win rates were not computed but\nare shown as the expected 50% for reference. All Graph RAG conditions outperformed na \u00a8\u0131ve RAG\non comprehensiveness and diversity. Conditions C1-C3 also showed slight improvements in answer\ncomprehensiveness and diversity over TS (global text summarization without a graph index).\n3.5 Configuration\nThe effect of context window size on any particular task is unclear, especially for models like\ngpt-4-turbo with a large context size of 128k tokens. Given the potential for information to\nbe \u201clost in the middle\u201d of longer contexts (Kuratov et al., 2024; Liu et al., 2023), we wanted to ex-\nplore the effects of varying the context window size for our combinations of datasets, questions, and\nmetrics. In particular, our goal was to determine the optimum context size for our baseline condition\n(SS) and then use this uniformly for all query-time LLM use. To that end, we tested four context\nwindow sizes: 8k, 16k, 32k and 64k. Surprisingly, the smallest context window size tested (8k)\nwas universally better for all comparisons on comprehensiveness (average win rate of 58.1%), while\nperforming comparably with larger context sizes on diversity (average win rate = 52.4%), and em-\npowerment (average win rate = 51.3%). Given our preference for more comprehensive and diverse\nanswers, we therefore used a fixed context window size of 8k tokens for the final evaluation.\n3.6 Results\nThe indexing process resulted in a graph consisting of 8564 nodes and 20691 edges for the Podcast\ndataset, and a larger graph of 15754 nodes and 19520 edges for the News dataset. Table 3 shows the\nnumber of community summaries at different levels of each graph community hierarchy.\nGlobal approaches vs. na \u00a8\u0131ve RAG . As shown in Figure 4, global approaches consistently out-\nperformed the na \u00a8\u0131ve RAG ( SS) approach in both comprehensiveness and diversity metrics across\ndatasets. Specifically, global approaches achieved comprehensiveness win rates between 72-83%\nfor Podcast transcripts and 72-80% for News articles, while diversity win rates ranged from 75-82%\nand 62-71% respectively. Our use of directness as a validity test also achieved the expected results,\ni.e., that na \u00a8\u0131ve RAG produces the most direct responses across all comparisons.\n9Podcast Transcripts News Articles\nC0 C1 C2 C3 TS C0 C1 C2 C3 TS\nUnits 34 367 969 1310 1669 55 555 1797 2142 3197\nTokens 26657 225756 565720 746100 1014611 39770 352641 980898 1140266 1707694\n% Max 2.6 22.2 55.8 73.5 100 2.3 20.7 57.4 66.8 100\nTable 3: Number of context units (community summaries for C0-C3 and text chunks for TS), corre-\nsponding token counts, and percentage of the maximum token count. Map-reduce summarization of\nsource texts is the most resource-intensive approach requiring the highest number of context tokens.\nRoot-level community summaries ( C0) require dramatically fewer tokens per query (9x-43x).\nCommunity summaries vs. source texts. When comparing community summaries to source texts\nusing Graph RAG, community summaries generally provided a small but consistent improvement\nin answer comprehensiveness and diversity, except for root-level summaries. Intermediate-level\nsummaries in the Podcast dataset and low-level community summaries in the News dataset achieved\ncomprehensiveness win rates of 57% and 64%, respectively. Diversity win rates were 57% for\nPodcast intermediate-level summaries and 60% for News low-level community summaries. Table 3\nalso illustrates the scalability advantages of Graph RAG compared to source text summarization: for\nlow-level community summaries ( C3), Graph RAG required 26-33% fewer context tokens, while\nfor root-level community summaries ( C0), it required over 97% fewer tokens. For a modest drop in\nperformance compared with other global methods, root-level Graph RAG offers a highly efficient\nmethod for the iterative question answering that characterizes sensemaking activity, while retaining\nadvantages in comprehensiveness (72% win rate) and diversity (62% win rate) over na \u00a8\u0131ve RAG.\nEmpowerment . Empowerment comparisons showed mixed results for both global approaches versus\nna\u00a8\u0131ve RAG ( SS) and Graph RAG approaches versus source text summarization ( TS). Ad-hoc LLM\nuse to analyze LLM reasoning for this measure indicated that the ability to provide specific exam-\nples, quotes, and citations was judged to be key to helping users reach an informed understanding.\nTuning element extraction prompts may help to retain more of these details in the Graph RAG index.\n4 Related Work\n4.1 RAG Approaches and Systems\nWhen using LLMs, RAG involves first retrieving relevant information from external data sources,\nthen adding this information to the context window of the LLM along with the original query (Ram\net al., 2023). Na \u00a8\u0131ve RAG approaches (Gao et al., 2023) do this by converting documents to text,\nsplitting text into chunks, and embedding these chunks into a vector space in which similar positions\nrepresent similar semantics. Queries are then embedded into the same vector space, with the text\nchunks of the nearest kvectors used as context. More advanced variations exist, but all solve the\nproblem of what to do when an external dataset of interest exceeds the LLM\u2019s context window.\nAdvanced RAG systems include pre-retrieval, retrieval, post-retrieval strategies designed to over-\ncome the drawbacks of Na \u00a8\u0131ve RAG, while Modular RAG systems include patterns for iterative and\ndynamic cycles of interleaved retrieval and generation (Gao et al., 2023). Our implementation of\nGraph RAG incorporates multiple concepts related to other systems. For example, our community\nsummaries are a kind of self-memory (Selfmem, Cheng et al., 2024) for generation-augmented re-\ntrieval (GAR, Mao et al., 2020) that facilitates future generation cycles, while our parallel generation\nof community answers from these summaries is a kind of iterative (Iter-RetGen, Shao et al., 2023)\nor federated (FeB4RAG, Wang et al., 2024) retrieval-generation strategy. Other systems have also\ncombined these concepts for multi-document summarization (CAiRE-COVID, Su et al., 2020) and\nmulti-hop question answering (ITRG, Feng et al., 2023; IR-CoT, Trivedi et al., 2022; DSP, Khattab\net al., 2022). Our use of a hierarchical index and summarization also bears resemblance to further\napproaches, such as generating a hierarchical index of text chunks by clustering the vectors of text\nembeddings (RAPTOR, Sarthi et al., 2024) or generating a \u201ctree of clarifications\u201d to answer mul-\ntiple interpretations of ambiguous questions (Kim et al., 2023). However, none of these iterative or\nhierarchical approaches use the kind of self-generated graph index that enables Graph RAG.\n104.2 Graphs and LLMs\nUse of graphs in connection with LLMs and RAG is a developing research area, with multiple\ndirections already established. These include using LLMs for knowledge graph creation (Tra-\njanoska et al., 2023) and completion (Yao et al., 2023), as well as for the extraction of causal\ngraphs (Ban et al., 2023; Zhang et al., 2024) from source texts. They also include forms of ad-\nvanced RAG (Gao et al., 2023) where the index is a knowledge graph (KAPING, Baek et al., 2023),\nwhere subsets of the graph structure (G-Retriever, He et al., 2024) or derived graph metrics (Graph-\nToolFormer, Zhang, 2023) are the objects of enquiry, where narrative outputs are strongly grounded\nin the facts of retrieved subgraphs (SURGE, Kang et al., 2023), where retrieved event-plot sub-\ngraphs are serialized using narrative templates (FABULA, Ranade and Joshi, 2023), and where the\nsystem supports both creation and traversal of text-relationship graphs for multi-hop question an-\nswering (Wang et al., 2023b). In terms of open-source software, a variety a graph databases are\nsupported by both the LangChain (LangChain, 2024) and LlamaIndex (Llama\n######################\nOutput:", "parameters": {"model": "=\"gpt-4o\"", "temperature": 0.0, "frequency_penalty": 0.0, "presence_penalty": 0.0, "top_p": 1.0, "max_tokens": 4000, "n": null}}