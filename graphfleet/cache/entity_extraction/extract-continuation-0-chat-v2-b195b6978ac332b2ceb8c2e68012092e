{"result": "## \n(\"entity\"<|>FIGURE 1<|>DATA VISUALIZATION, FIGURE<|>A figure referenced in the text that illustrates the high-level data flow of the Graph RAG approach and pipeline)\n##\n(\"entity\"<|>FIGURE 2<|>DATA VISUALIZATION, FIGURE<|>A figure referenced in the text that shows the behavior of text chunk extraction in the Graph RAG approach)\n##\n(\"entity\"<|>SINGLE EXTRACTION ROUND<|>PROCESS, METHOD<|>A process involving one round of extraction without additional gleanings, used to observe the behavior of text chunk extraction)\n##\n(\"entity\"<|>ZERO GLEANINGS<|>CONCEPT, PHENOMENON<|>A condition in the extraction process where no additional gleanings are performed)\n##\n(\"entity\"<|>CHUNK SIZE<|>PARAMETER, ATTRIBUTE<|>The size of text chunks used in the extraction process, which affects the number of entity references extracted)\n##\n(\"entity\"<|>600 TOKEN<|>PARAMETER, ATTRIBUTE<|>A specific chunk size used in the extraction process that extracted almost twice as many entity references as a larger chunk size)\n##\n(\"entity\"<|>2400 TOKEN<|>PARAMETER, ATTRIBUTE<|>A specific chunk size used in the extraction process that extracted fewer entity references compared to a smaller chunk size)\n##\n(\"entity\"<|>TARGET ACTIVITY<|>ACTIVITY, TASK<|>The specific activity or task for which the extraction process needs to balance recall and precision)\n##\n(\"entity\"<|>DOMAIN OF THE DOCUMENT CORPUS<|>CONTEXT, DOMAIN<|>The specific field or area of knowledge to which the document corpus belongs, affecting the tailoring of LLM prompts)\n##\n(\"entity\"<|>SCIENCE<|>DOMAIN, FIELD<|>A specialized domain that can benefit from few-shot examples tailored to its specific knowledge)\n##\n(\"entity\"<|>MEDICINE<|>DOMAIN, FIELD<|>A specialized domain that can benefit from few-shot examples tailored to its specific knowledge)\n##\n(\"entity\"<|>LAW<|>DOMAIN, FIELD<|>A specialized domain that can benefit from few-shot examples tailored to its specific knowledge)\n##\n(\"relationship\"<|>GRAPH RAG APPROACH<|>FIGURE 1<|>Figure 1 illustrates the high-level data flow of the Graph RAG approach and pipeline<|>8)\n##\n(\"relationship\"<|>SINGLE EXTRACTION ROUND<|>FIGURE 2<|>Figure 2 shows the behavior of text chunk extraction in the case of a single extraction round<|>8)\n##\n(\"relationship\"<|>ZERO GLEANINGS<|>SINGLE EXTRACTION ROUND<|>A single extraction round involves zero gleanings<|>7)\n##\n(\"relationship\"<|>CHUNK SIZE<|>600 TOKEN<|>600 token is a specific chunk size used in the extraction process<|>8)\n##\n(\"relationship\"<|>CHUNK SIZE<|>2400 TOKEN<|>2400 token is a specific chunk size used in the extraction process<|>8)\n##\n(\"relationship\"<|>TEXT CHUNKS<|>CHUNK SIZE<|>Text chunks are processed using different chunk sizes to balance recall and precision<|>9)\n##\n(\"relationship\"<|>LLM PROMPTS<|>DOMAIN OF THE DOCUMENT CORPUS<|>LLM prompts can be tailored to the domain of the document corpus using few-shot examples<|>8)\n##\n(\"relationship\"<|>FEW-SHOT EXAMPLES<|>SCIENCE<|>Few-shot examples can be specialized for the science domain<|>7)\n##\n(\"relationship\"<|>FEW-SHOT EXAMPLES<|>MEDICINE<|>Few-shot examples can be specialized for the medicine domain<|>7)\n##\n(\"relationship\"<|>FEW-SHOT EXAMPLES<|>LAW<|>Few-shot examples can be specialized for the law domain<|>7)\n<|COMPLETE|>", "input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n", "parameters": {"model": "gpt-4o", "temperature": 0.0, "frequency_penalty": 0.0, "presence_penalty": 0.0, "top_p": 1.0, "max_tokens": 4000, "n": 1}, "history": [{"role": "user", "content": "\n-Goal-\nGiven a text document that is potentially relevant to this activity, first identify all entities needed from the text in order to capture the information and ideas in the text.\nNext, report all relationships among the identified entities.\n\n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: Suggest several labels or categories for the entity. The categories should not be specific, but should be as general as possible.\n- entity_description: Comprehensive description of the entity's attributes and activities\nFormat each entity as (\"entity\"<|><entity_name><|><entity_type><|><entity_description>)\n\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\nFormat each relationship as (\"relationship\"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n\n3. Return output in The primary language of the provided text is \"English.\" as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n\n4. If you have to translate into The primary language of the provided text is \"English.\", just translate the descriptions, nothing else!\n\n5. When finished, output <|COMPLETE|>.\n\n-Examples-\n######################\n\nExample 1:\n\ntext:\n he tasks studied in the lab thus far have tended to \nbe those for which researchers hypothesized generative AI would \nperform well . This was, in fact, the focus of most of the studies \npresented in the first AI and Productivity report we published  \n(Cambon et al. 2023) . Actual information work , however, often \nincludes a huge variety of tasks  and much of the unstructured and \ninformal work in people’s jobs is not yet directly supported by the \nfirst-generation of generative AI tools.  Software developer \nworkflows , for example,  involve far more than the hands-on coding supported by GitHub Copilot (Meyer et al. 2017). The ability to \nshed light on generative AI's productivity dynamics in the natural \ncomplexity of entire workflows is a key advantage of field studies \nof generative AI’s productivity impacts , and a major reason we \nhope to see many more field studies emerging in the literature\n------------------------\noutput:\n(\"entity\"<|>LAB<|>LOCATION, RESEARCH ENVIRONMENT<|>The lab is where tasks are studied to hypothesize the performance of generative AI)\n##\n(\"entity\"<|>GENERATIVE AI<|>TECHNOLOGY, TOOL<|>Generative AI refers to artificial intelligence systems that can generate content, such as text, based on input data)\n##\n(\"entity\"<|>AI AND PRODUCTIVITY REPORT<|>DOCUMENT, PUBLICATION<|>A report published by Cambon et al. in 2023 focusing on the performance of generative AI in various tasks)\n##\n(\"entity\"<|>INFORMATION WORK<|>ACTIVITY, TASK<|>Information work includes a variety of tasks, often unstructured and informal, that are part of people's jobs)\n##\n(\"entity\"<|>FIRST-GENERATION GENERATIVE AI TOOLS<|>TECHNOLOGY, TOOL<|>The initial versions of generative AI tools that support specific tasks but not the full range of unstructured work)\n##\n(\"entity\"<|>SOFTWARE DEVELOPER WORKFLOWS<|>ACTIVITY, TASK<|>The comprehensive set of activities involved in software development, beyond just coding)\n##\n(\"entity\"<|>GITHUB COPILOT<|>TECHNOLOGY, TOOL<|>A generative AI tool that assists with hands-on coding tasks for software developers)\n##\n(\"entity\"<|>FIELD STUDIES<|>RESEARCH METHOD, STUDY TYPE<|>Studies conducted in natural settings to observe the real-world impacts of generative AI on productivity)\n##\n(\"entity\"<|>PRODUCTIVITY DYNAMICS<|>CONCEPT, PHENOMENON<|>The various factors and interactions that affect productivity when using generative AI in real-world workflows)\n##\n(\"entity\"<|>LITERATURE<|>BODY OF WORK, RESEARCH<|>The collection of academic and professional studies and publications on a given topic)\n##\n(\"relationship\"<|>LAB<|>GENERATIVE AI<|>The lab is where tasks are studied to hypothesize the performance of generative AI<|>7)\n##\n(\"relationship\"<|>AI AND PRODUCTIVITY REPORT<|>GENERATIVE AI<|>The report focuses on the performance of generative AI in various tasks<|>8)\n##\n(\"relationship\"<|>INFORMATION WORK<|>FIRST-GENERATION GENERATIVE AI TOOLS<|>First-generation generative AI tools do not yet directly support much of the unstructured and informal information work<|>6)\n##\n(\"relationship\"<|>SOFTWARE DEVELOPER WORKFLOWS<|>GITHUB COPILOT<|>GitHub Copilot supports hands-on coding, which is a part of software developer workflows<|>9)\n##\n(\"relationship\"<|>FIELD STUDIES<|>PRODUCTIVITY DYNAMICS<|>Field studies help shed light on the productivity dynamics of generative AI in real-world settings<|>8)\n##\n(\"relationship\"<|>FIELD STUDIES<|>LITERATURE<|>The hope is to see more field studies emerging in the literature to understand generative AI's productivity impacts<|>7)\n<|COMPLETE|>\n#############################\n\n\nExample 2:\n\ntext:\nLiu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., and Liang, P. (2023). Lost\nin the middle: How language models use long contexts. arXiv:2307.03172.\nLiu, Y . and Lapata, M. (2019). Hierarchical transformers for multi-document summarization. arXiv\npreprint arXiv:1905.13164 .\nLlamaIndex (2024). LlamaIndex Knowledge Graph Index. https://docs .llamaindex .ai/en/stable/\nexamples/index structs/knowledge graph/KnowledgeGraphDemo .html.\nManakul, P., Liusie, A., and Gales, M. J. (2023). Selfcheckgpt: Zero-resource black-box hallucina-\ntion detection for generative large language models. arXiv preprint ar\n------------------------\noutput:\n(\"entity\"<|>LIU, N. F.<|>PERSON<|>Liu, N. F. is an author of the paper \"Lost in the middle: How language models use long contexts\" published in 2023)\n##\n(\"entity\"<|>LIN, K.<|>PERSON<|>Lin, K. is an author of the paper \"Lost in the middle: How language models use long contexts\" published in 2023)\n##\n(\"entity\"<|>HEWITT, J.<|>PERSON<|>Hewitt, J. is an author of the paper \"Lost in the middle: How language models use long contexts\" published in 2023)\n##\n(\"entity\"<|>PARANJAPE, A.<|>PERSON<|>Paranjape, A. is an author of the paper \"Lost in the middle: How language models use long contexts\" published in 2023)\n##\n(\"entity\"<|>BEVILACQUA, M.<|>PERSON<|>Bevilacqua, M. is an author of the paper \"Lost in the middle: How language models use long contexts\" published in 2023)\n##\n(\"entity\"<|>PETRONI, F.<|>PERSON<|>Petroni, F. is an author of the paper \"Lost in the middle: How language models use long contexts\" published in 2023)\n##\n(\"entity\"<|>LIANG, P.<|>PERSON<|>Liang, P. is an author of the paper \"Lost in the middle: How language models use long contexts\" published in 2023)\n##\n(\"entity\"<|>LIU, Y.<|>PERSON<|>Liu, Y. is an author of the paper \"Hierarchical transformers for multi-document summarization\" published in 2019)\n##\n(\"entity\"<|>LAPATA, M.<|>PERSON<|>Lapata, M. is an author of the paper \"Hierarchical transformers for multi-document summarization\" published in 2019)\n##\n(\"entity\"<|>LLAMAINDEX<|>ORGANIZATION<|>LlamaIndex is an organization that developed the LlamaIndex Knowledge Graph Index, with documentation available online)\n##\n(\"entity\"<|>MANAKUL, P.<|>PERSON<|>Manakul, P. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\" published in 2023)\n##\n(\"entity\"<|>LIUSIE, A.<|>PERSON<|>Liusie, A. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\" published in 2023)\n##\n(\"entity\"<|>GALES, M. J.<|>PERSON<|>Gales, M. J. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\" published in 2023)\n##\n(\"entity\"<|>LOST IN THE MIDDLE: HOW LANGUAGE MODELS USE LONG CONTEXTS<|>DOCUMENT<|>A paper published in 2023 by Liu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., and Liang, P.)\n##\n(\"entity\"<|>HIERARCHICAL TRANSFORMERS FOR MULTI-DOCUMENT SUMMARIZATION<|>DOCUMENT<|>A paper published in 2019 by Liu, Y. and Lapata, M.)\n##\n(\"entity\"<|>SELFCHECKGPT: ZERO-RESOURCE BLACK-BOX HALLUCINATION DETECTION FOR GENERATIVE LARGE LANGUAGE MODELS<|>DOCUMENT<|>A paper published in 2023 by Manakul, P., Liusie, A., and Gales, M. J.)\n##\n(\"relationship\"<|>LIU, N. F.<|>LOST IN THE MIDDLE: HOW LANGUAGE MODELS USE LONG CONTEXTS<|>Liu, N. F. is an author of the paper \"Lost in the middle: How language models use long contexts\"<|>9)\n##\n(\"relationship\"<|>LIN, K.<|>LOST IN THE MIDDLE: HOW LANGUAGE MODELS USE LONG CONTEXTS<|>Lin, K. is an author of the paper \"Lost in the middle: How language models use long contexts\"<|>9)\n##\n(\"relationship\"<|>HEWITT, J.<|>LOST IN THE MIDDLE: HOW LANGUAGE MODELS USE LONG CONTEXTS<|>Hewitt, J. is an author of the paper \"Lost in the middle: How language models use long contexts\"<|>9)\n##\n(\"relationship\"<|>PARANJAPE, A.<|>LOST IN THE MIDDLE: HOW LANGUAGE MODELS USE LONG CONTEXTS<|>Paranjape, A. is an author of the paper \"Lost in the middle: How language models use long contexts\"<|>9)\n##\n(\"relationship\"<|>BEVILACQUA, M.<|>LOST IN THE MIDDLE: HOW LANGUAGE MODELS USE LONG CONTEXTS<|>Bevilacqua, M. is an author of the paper \"Lost in the middle: How language models use long contexts\"<|>9)\n##\n(\"relationship\"<|>PETRONI, F.<|>LOST IN THE MIDDLE: HOW LANGUAGE MODELS USE LONG CONTEXTS<|>Petroni, F. is an author of the paper \"Lost in the middle: How language models use long contexts\"<|>9)\n##\n(\"relationship\"<|>LIANG, P.<|>LOST IN THE MIDDLE: HOW LANGUAGE MODELS USE LONG CONTEXTS<|>Liang, P. is an author of the paper \"Lost in the middle: How language models use long contexts\"<|>9)\n##\n(\"relationship\"<|>LIU, Y.<|>HIERARCHICAL TRANSFORMERS FOR MULTI-DOCUMENT SUMMARIZATION<|>Liu, Y. is an author of the paper \"Hierarchical transformers for multi-document summarization\"<|>9)\n##\n(\"relationship\"<|>LAPATA, M.<|>HIERARCHICAL TRANSFORMERS FOR MULTI-DOCUMENT SUMMARIZATION<|>Lapata, M. is an author of the paper \"Hierarchical transformers for multi-document summarization\"<|>9)\n##\n(\"relationship\"<|>MANAKUL, P.<|>SELFCHECKGPT: ZERO-RESOURCE BLACK-BOX HALLUCINATION DETECTION FOR GENERATIVE LARGE LANGUAGE MODELS<|>Manakul, P. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"<|>9)\n##\n(\"relationship\"<|>LIUSIE, A.<|>SELFCHECKGPT: ZERO-RESOURCE BLACK-BOX HALLUCINATION DETECTION FOR GENERATIVE LARGE LANGUAGE MODELS<|>Liusie, A. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"<|>9)\n##\n(\"relationship\"<|>GALES, M. J.<|>SELFCHECKGPT: ZERO-RESOURCE BLACK-BOX HALLUCINATION DETECTION FOR GENERATIVE LARGE LANGUAGE MODELS<|>Gales, M. J. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"<|>9)\n<|COMPLETE|>\n#############################\n\n\n\n-Real Data-\n######################\ntext: intermediate- and low-level community summaries shows\nfavorable performance over source text summarization on these same metrics, at lower token costs.\n2 Graph RAG Approach & Pipeline\nWe now unpack the high-level data flow of the Graph RAG approach (Figure 1) and pipeline, de-\nscribing key design parameters, techniques, and implementation details for each step.\n2.1 Source Documents →Text Chunks\nA fundamental design decision is the granularity with which input texts extracted from source doc-\numents should be split into text chunks for processing. In the following step, each of these chunks\nwill be passed to a set of LLM prompts designed to extract the various elements of a graph index.\nLonger text chunks require fewer LLM calls for such extraction, but suffer from the recall degrada-\ntion of longer LLM context windows (Kuratov et al., 2024; Liu et al., 2023). This behavior can be\nobserved in Figure 2 in the case of a single extraction round (i.e., with zero gleanings): on a sample\ndataset (HotPotQA, Yang et al., 2018), using a chunk size of 600 token extracted almost twice as\nmany entity references as when using a chunk size of 2400. While more references are generally\nbetter, any extraction process needs to balance recall and precision for the target activity.\n2.2 Text Chunks →Element Instances\nThe baseline requirement for this step is to identify and extract instances of graph nodes and edges\nfrom each chunk of source text. We do this using a multipart LLM prompt that first identifies all\nentities in the text, including their name, type, and description, before identifying all relationships\nbetween clearly-related entities, including the source and target entities and a description of their\nrelationship. Both kinds of element instance are output in a single list of delimited tuples.\nThe primary opportunity to tailor this prompt to the domain of the document corpus lies in the\nchoice of few-shot examples provided to the LLM for in-context learning (Brown et al., 2020).\n3For example, while our default prompt extracting the broad class of “named entities” like people,\nplaces, and organizations is generally applicable, domains with specialized knowledge (e.g., science,\nmedicine, law) will benefit from few-shot examples specialized to those domains. We also support\na secondary extraction prompt for any additional covariates we would like to associate with the\nextracted node instances. Our default covariate prompt\n######################\noutput:\n"}, {"role": "assistant", "content": "## \n(\"entity\"<|>COMMUNITY SUMMARIES<|>DOCUMENT, SUMMARY<|>Intermediate- and low-level summaries of community data that show favorable performance over source text summarization on certain metrics at lower token costs)\n##\n(\"entity\"<|>GRAPH RAG APPROACH<|>METHOD, TECHNIQUE<|>A high-level data flow approach involving the use of graph-based retrieval-augmented generation (RAG) for processing and summarizing text)\n##\n(\"entity\"<|>PIPELINE<|>PROCESS, SYSTEM<|>The sequence of steps and techniques used in the Graph RAG approach to process and summarize text)\n##\n(\"entity\"<|>SOURCE DOCUMENTS<|>DOCUMENT, TEXT<|>Original texts from which input data is extracted and split into text chunks for further processing)\n##\n(\"entity\"<|>TEXT CHUNKS<|>DATA UNIT, TEXT<|>Smaller segments of text extracted from source documents for processing in the Graph RAG approach)\n##\n(\"entity\"<|>LLM PROMPTS<|>TECHNIQUE, TOOL<|>Prompts designed for large language models (LLMs) to extract various elements of a graph index from text chunks)\n##\n(\"entity\"<|>GRAPH INDEX<|>DATA STRUCTURE, INDEX<|>A structured representation of data elements and their relationships, extracted from text chunks using LLM prompts)\n##\n(\"entity\"<|>RECALL DEGRADATION<|>CONCEPT, PHENOMENON<|>The decline in the ability of LLMs to recall information accurately as the context window lengthens)\n##\n(\"entity\"<|>HOTPOTQA<|>DATASET<|>A sample dataset used to observe the behavior of text chunk extraction in the Graph RAG approach)\n##\n(\"entity\"<|>ENTITY REFERENCES<|>DATA ELEMENT, REFERENCE<|>Mentions of entities within text chunks that are extracted during the processing phase)\n##\n(\"entity\"<|>RECALL<|>METRIC, PERFORMANCE MEASURE<|>A measure of how well the extraction process identifies relevant entities and relationships from text chunks)\n##\n(\"entity\"<|>PRECISION<|>METRIC, PERFORMANCE MEASURE<|>A measure of the accuracy of the extraction process in identifying relevant entities and relationships from text chunks)\n##\n(\"entity\"<|>GRAPH NODES<|>DATA ELEMENT, NODE<|>Instances of entities identified in the text chunks that form the nodes in a graph index)\n##\n(\"entity\"<|>GRAPH EDGES<|>DATA ELEMENT, EDGE<|>Instances of relationships between entities identified in the text chunks that form the edges in a graph index)\n##\n(\"entity\"<|>FEW-SHOT EXAMPLES<|>TECHNIQUE, EXAMPLE<|>Examples provided to the LLM for in-context learning to tailor the extraction prompt to the domain of the document corpus)\n##\n(\"entity\"<|>NAMED ENTITIES<|>DATA ELEMENT, ENTITY<|>Broad class of entities such as people, places, and organizations that are generally applicable across domains)\n##\n(\"entity\"<|>COVARIATES<|>DATA ELEMENT, ATTRIBUTE<|>Additional attributes associated with the extracted node instances in the graph index)\n##\n(\"entity\"<|>BROWN ET AL., 2020<|>REFERENCE, CITATION<|>A reference to the work by Brown et al. in 2020 on in-context learning for LLMs)\n##\n(\"entity\"<|>KURATOV ET AL., 2024<|>REFERENCE, CITATION<|>A reference to the work by Kuratov et al. in 2024 on the recall degradation of longer LLM context windows)\n##\n(\"entity\"<|>LIU ET AL., 2023<|>REFERENCE, CITATION<|>A reference to the work by Liu et al. in 2023 on the recall degradation of longer LLM context windows)\n##\n(\"entity\"<|>YANG ET AL., 2018<|>REFERENCE, CITATION<|>A reference to the work by Yang et al. in 2018 on the HotPotQA dataset)\n##\n(\"relationship\"<|>GRAPH RAG APPROACH<|>PIPELINE<|>The pipeline describes the sequence of steps and techniques used in the Graph RAG approach<|>9)\n##\n(\"relationship\"<|>SOURCE DOCUMENTS<|>TEXT CHUNKS<|>Text chunks are extracted from source documents for further processing<|>9)\n##\n(\"relationship\"<|>TEXT CHUNKS<|>LLM PROMPTS<|>LLM prompts are used to process text chunks and extract elements of a graph index<|>9)\n##\n(\"relationship\"<|>LLM PROMPTS<|>GRAPH INDEX<|>LLM prompts are designed to extract various elements of a graph index from text chunks<|>9)\n##\n(\"relationship\"<|>TEXT CHUNKS<|>ENTITY REFERENCES<|>Entity references are extracted from text chunks during the processing phase<|>8)\n##\n(\"relationship\"<|>GRAPH NODES<|>GRAPH EDGES<|>Graph nodes and edges are instances of entities and relationships identified in the text chunks<|>9)\n##\n(\"relationship\"<|>FEW-SHOT EXAMPLES<|>LLM PROMPTS<|>Few-shot examples are used to tailor LLM prompts to the domain of the document corpus<|>8)\n##\n(\"relationship\"<|>NAMED ENTITIES<|>FEW-SHOT EXAMPLES<|>Few-shot examples can be specialized to extract named entities in specific domains<|>7)\n##\n(\"relationship\"<|>COVARIATES<|>GRAPH NODES<|>Covariates are additional attributes associated with the extracted node instances<|>7)\n##\n(\"relationship\"<|>KURATOV ET AL., 2024<|>RECALL DEGRADATION<|>Kuratov et al. (2024) studied the recall degradation of longer LLM context windows<|>8)\n##\n(\"relationship\"<|>LIU ET AL., 2023<|>RECALL DEGRADATION<|>Liu et al. (2023) studied the recall degradation of longer LLM context windows<|>8)\n##\n(\"relationship\"<|>YANG ET AL., 2018<|>HOTPOTQA<|>Yang et al. (2018) created the HotPotQA dataset<|>9)\n<|COMPLETE|>"}]}