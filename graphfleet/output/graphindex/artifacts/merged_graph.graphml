<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d6" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d5" for="edge" attr.name="description" attr.type="string" />
  <key id="d4" for="edge" attr.name="weight" attr.type="double" />
  <key id="d3" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d2" for="node" attr.name="source_id" attr.type="string" />
  <key id="d1" for="node" attr.name="description" attr.type="string" />
  <key id="d0" for="node" attr.name="type" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="DARREN EDGE">
      <data key="d0">PERSON</data>
      <data key="d1">Darren Edge is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="HA TRINH">
      <data key="d0">PERSON</data>
      <data key="d1">Ha Trinh is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="NEWMAN CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Newman Cheng is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="JOSHUA BRADLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Bradley is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="ALEX CHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Chao is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="APURVA MODY">
      <data key="d0">PERSON</data>
      <data key="d1">Apurva Mody is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="STEVEN TRUITT">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Truitt is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="JONATHAN LARSON">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Larson is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="MICROSOFT RESEARCH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Research is an organization where some of the authors of the paper are affiliated</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Strategic Missions and Technologies is an organization where some of the authors of the paper are affiliated</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="MICROSOFT OFFICE OF THE CTO">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Office of the CTO is an organization where some of the authors of the paper are affiliated</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="RAG">
      <data key="d0">METHOD</data>
      <data key="d1">RAG (Retrieval-Augmented Generation) is a method used to retrieve relevant information from an external knowledge source to enable large language models to answer questions
RAG (Retrieval-Augmented Generation) is a method used for generating responses in text generation tasks
RAG (Retrieval-Augmented Generation) is a method that produces direct responses in text generation tasks

Retrieval-Augmented Generation, a method that incorporates retrieval of relevant data to augment text generation
RAG (Retrieval-Augmented Generation) is a developing research area with multiple established directions, including knowledge graph creation, completion, and extraction of causal graphs</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,6f33a085ff3304e5994f7fbb86c881a4,92e93fc6449756c0a60200636b297f65,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="LLM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM (Large Language Model) is a type of model used to automate human-like sensemaking and reasoning over large collections of documents
LLM (Large Language Model) is a type of AI model used for generating text and answering queries
LLM (Large Language Model) is used to process text chunks and extract elements of a graph index
LLM (Large Language Model) is a type of artificial intelligence used for tasks such as entity extraction, summarization, and understanding relationships in text
LLM (Large Language Model) is used to generate intermediate answers and scores for each chunk
Large Language Model used to automate the generation of questions for dataset evaluation
LLM (Large Language Model) is a type of artificial intelligence used for generating and assessing text
Large Language Models (LLMs) are used to analyze and generate text based on retrieved information and queries
Large Language Model, a type of AI model with a context window that can be exceeded by external datasets</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,21e52bc06a82796b1f4bcd73edda1f2a,2c6ed90897310eea2f28e33fff1c32b0,6f33a085ff3304e5994f7fbb86c881a4,922778ce1cb2fdd6dbab1746c8795620,bc9e2c9e369c4108cf4f6dd5f60960f4,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="GRAPH RAG">
      <data key="d0">METHOD</data>
      <data key="d1">Graph RAG is an approach that combines retrieval-augmented generation with graph-based text indexing to answer questions over private text corpora
A new approach based on global summarization of an LLM-derived knowledge graph, targeting global summarization tasks
Graph RAG is a specific approach to RAG that focuses on global summarization using a knowledge graph
Graph RAG (Retrieval-Augmented Generation) is an approach that involves a high-level data flow and pipeline for processing and summarizing text
A specific implementation of RAG using four levels of graph communities
Graph RAG is a method using graph communities at different levels to answer user queries
A multi-stage mechanism for Retrieval-Augmented Generation (RAG) that involves comparing multiple conditions
Graph RAG is a method that provides a comprehensive overview of public figures in the entertainment industry
Graph RAG is a method used to generate responses that provide a comprehensive and structured overview of public figures across various sectors of the entertainment industry.
Graph RAG is a method used to generate answers for questions in the News article dataset
Graph RAG is a method that outperformed naive RAG on comprehensiveness and diversity in text generation tasks
A method used to compare community summaries to source texts, generally providing a small but consistent improvement in answer comprehensiveness and diversity
Graph RAG is a method that uses community summaries to improve answer comprehensiveness and diversity while requiring fewer tokens compared to source text summarization
An implementation of RAG that incorporates multiple concepts from other systems, including self-memory and parallel generation of community answers
A method that uses the natural modularity of graphs to partition data for global summarization
Graph RAG is a method that combines knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) to support human sensemaking over text corpora
Graph RAG (Retrieval-Augmented Generation) is a method that combines global and local approaches for efficient token usage in text generation tasks
Graph RAG is a retrieval-augmented generation technology based on knowledge graphs launched by NebulaGraph</data>
      <data key="d2">086021a89900a39bcb62036981737bfa,21e52bc06a82796b1f4bcd73edda1f2a,322e02986c8724eedbcf3ebfa20b989c,36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,718017a4871c909420f84b85b8ba969d,833e7d67dcd30790b26b71c9b5306f6b,922778ce1cb2fdd6dbab1746c8795620,92e93fc6449756c0a60200636b297f65,973164fa90bf2b4ee267f4fd795916bf,bc9e2c9e369c4108cf4f6dd5f60960f4,e4d9b12cf2b4c691c74019eefff4fb39,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,ebf5249c888e07fedce6572a4c03f88c,f35de4d9fb65f1d5a392064b20545c19,fb3c48579608fa28be585ceb6cd2f0fe</data>
    </node>
    <node id="QFS">
      <data key="d0">METHOD</data>
      <data key="d1">QFS (Query-Focused Summarization) is a method used to generate summaries based on specific user queries</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="COMMUNITY SUMMARIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Community summaries are pre-generated summaries for groups of closely-related entities used in the Graph RAG approach
Community summaries are summaries of graph communities, tailored to the domain
Summaries generated from modular communities in the knowledge graph
Report-like summaries of each community in a hierarchical structure, useful for understanding the dataset
Community summaries are generated summaries of data clusters or communities, used to answer queries
Community summaries are randomly shuffled and divided into chunks of pre-specified token size to ensure relevant information is distributed across chunks
Summaries of different levels of each graph community hierarchy
Community summaries are summaries derived from community-generated content, used in the analysis to compare with source texts
Summaries that act as a kind of self-memory for generation-augmented retrieval
Summaries of root-level communities in an entity-based graph index</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,21e52bc06a82796b1f4bcd73edda1f2a,36db32c37e1987e2c5863898ad882190,6f33a085ff3304e5994f7fbb86c881a4,7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd,e4d9b12cf2b4c691c74019eefff4fb39,e8d83e6e7a7c0f57b218cef24976b745,f0306814bf64f5c9e79603fc6a52f4ea,f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="GLOBAL SENSEMAKING QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Global sensemaking questions are questions that require understanding and summarizing large datasets, often beyond the explicit content of the source texts</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="1 MILLION TOKEN RANGE">
      <data key="d0">METRIC</data>
      <data key="d1">1 million token range refers to the scale of datasets used in the evaluation of the Graph RAG approach</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="PYTHON">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Python is a programming language used to implement the open-source version of the Graph RAG approach
Python is a programming language used for implementing both global and local Graph RAG approaches</data>
      <data key="d2">086021a89900a39bcb62036981737bfa,e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="HTTPS://AKA.MS/GRAPHRAG">
      <data key="d0">URL</data>
      <data key="d1">The URL where the open-source implementation of the Graph RAG approach will be available
A URL where the open-source, Python-based implementation of Graph RAG approaches will be available</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39,e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">Query-Focused Summarization (QFS) is a method used to generate summaries based on specific user queries
Query-focused summarization is a method used to generate summaries that are relevant to a specific query
A summarization method that focuses on answering specific queries using the entire corpus
A method for summarizing information based on specific queries</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,7fb7d9ce2da9c940a32afdd87d1d9e56,e8d83e6e7a7c0f57b218cef24976b745,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="EXTERNAL KNOWLEDGE SOURCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">An external knowledge source is a repository of information that can be accessed to retrieve relevant data for answering questions</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="TEXT CORPUS">
      <data key="d0">CONCEPT</data>
      <data key="d1">A text corpus is a large collection of written texts used for analysis and research</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="ENTITY KNOWLEDGE GRAPH">
      <data key="d0">CONCEPT</data>
      <data key="d1">An entity knowledge graph is a graph-based representation of entities and their relationships derived from source documents</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="SOURCE DOCUMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Source documents are the original texts from which information is retrieved or summarized
Source documents are the original texts from which information is extracted and analyzed
Source documents are the original texts from which input texts are extracted for processing in the Graph RAG approach</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4,e8d83e6e7a7c0f57b218cef24976b745,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="PARTIAL RESPONSE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A partial response is an intermediate answer generated from community summaries before being combined into a final response</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="FINAL RESPONSE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A final response is the comprehensive answer generated after combining all partial responses</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
    </node>
    <node id="COMPREHENSIVENESS">
      <data key="d0">METRIC</data>
      <data key="d1">Comprehensiveness is a metric used to evaluate the extent to which generated answers cover the relevant information
A target quality used to evaluate the summarization approach, focusing on the completeness of the summary
A metric that measures how much detail an answer provides to cover all aspects and details of a question
A metric used to evaluate the comprehensiveness of the generated responses
A metric used to evaluate the thoroughness of the generated answers
A metric used to evaluate the quality of answers in terms of their completeness
A metric used to evaluate the thoroughness of responses, with win rates between 72-83% for Podcast transcripts and 72-80% for News articles</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,322e02986c8724eedbcf3ebfa20b989c,36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="DIVERSITY">
      <data key="d0">METRIC</data>
      <data key="d1">Diversity is a metric used to evaluate the variety of information included in the generated answers
A target quality used to evaluate the summarization approach, focusing on the variety of information in the summary
A metric that measures how varied and rich an answer is in providing different perspectives and insights on a question
A metric used to evaluate the variety in the generated answers
A metric used to evaluate the variety of answers generated
A metric used to evaluate the variety of responses, with win rates ranging from 75-82% for Podcast transcripts and 62-71% for News articles
Diversity is a measure used to evaluate the variety of answers provided by different methods</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,322e02986c8724eedbcf3ebfa20b989c,36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,e8d83e6e7a7c0f57b218cef24976b745,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="HUMAN ENDEAVORS">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Human endeavors refer to activities and efforts across various domains that rely on reading and reasoning about large collections of documents</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Large language models are advanced AI models designed to understand and generate human-like text, used in automating sensemaking in complex domains
Modern language models, including GPT, Llama, and Gemini, that can use in-context learning to summarize content</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea,fb3c48579608fa28be585ceb6cd2f0fe</data>
    </node>
    <node id="SCIENTIFIC DISCOVERY">
      <data key="d0">DOMAIN</data>
      <data key="d1">Scientific discovery is a complex domain where sensemaking is applied to understand and generate new knowledge from scientific texts</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="INTELLIGENCE ANALYSIS">
      <data key="d0">DOMAIN</data>
      <data key="d1">Intelligence analysis is a complex domain where sensemaking is applied to understand and generate insights from intelligence data</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="SENSEMAKING">
      <data key="d0">PROCESS</data>
      <data key="d1">Sensemaking is the process of understanding connections among people, places, and events to anticipate their trajectories and act effectively
Sensemaking is the process of understanding and making sense of complex information</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="TEXT CHUNKS">
      <data key="d0">DATA</data>
      <data key="d1">Text chunks are segments of source documents that are extracted for further analysis
Text chunks are segments of input texts extracted from source documents, used for processing in the Graph RAG approach
Segments of text that are embedded into a vector space for analysis</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea,f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="ELEMENT INSTANCES">
      <data key="d0">DATA</data>
      <data key="d1">Element instances are specific pieces of information extracted from text chunks, tailored to the domain
Element instances are identified and extracted instances of graph nodes and edges from text chunks
Element instances are individual occurrences of entities, relationships, and claims extracted from source texts</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0,bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="ELEMENT SUMMARIES">
      <data key="d0">DATA</data>
      <data key="d1">Element summaries are concise representations of element instances, tailored to the domain
Element summaries are descriptive texts created by the LLM to summarize entities, relationships, and claims extracted from source texts
Summaries of elements within a graph, used to understand the structure and semantics of the dataset
Element summaries are detailed descriptions of nodes, edges, and covariates within a community</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0,7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="GRAPH COMMUNITIES">
      <data key="d0">DATA</data>
      <data key="d1">Graph communities are groups of elements (nodes, edges, covariates) detected in a graph index, used for summarization
Groups of nodes within a graph that have stronger connections to each other than to other nodes</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="COMMUNITY ANSWERS">
      <data key="d0">DATA</data>
      <data key="d1">Community answers are query-focused summaries of community summaries
Community answers are responses generated from community summaries to answer user queries
Answers generated in parallel from community summaries</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd,f0306814bf64f5c9e79603fc6a52f4ea,f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="GLOBAL ANSWER">
      <data key="d0">DATA</data>
      <data key="d1">Global answer is the final query-focused summary produced from all relevant community summaries
A global answer is a comprehensive response generated from multiple community summaries to answer a user query
The final answer generated by combining intermediate community answers based on their helpfulness scores</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,843fc5421e086120ffa1c75856ecf6cd,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="INDEXING TIME">
      <data key="d0">TIME</data>
      <data key="d1">Indexing time refers to the time when the graph index is created and elements are summarized</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="QUERY TIME">
      <data key="d0">TIME</data>
      <data key="d1">Query time refers to the time when a query is made and the relevant summaries are generated</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="GRAPH RAG PIPELINE">
      <data key="d0">PROCESS</data>
      <data key="d1">Graph RAG pipeline is a process using an LLM-derived graph index to detect, extract, and summarize nodes, edges, and covariates in source documents</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="NODES">
      <data key="d0">DATA</data>
      <data key="d1">Nodes are entities detected in the graph index of source documents
The individual elements or points in a graph, with 8564 nodes for the Podcast dataset and 15754 nodes for the News dataset</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="EDGES">
      <data key="d0">DATA</data>
      <data key="d1">Edges are relationships detected in the graph index of source documents
The connections or links between nodes in a graph, with 20691 edges for the Podcast dataset and 19520 edges for the News dataset</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="COVARIATES">
      <data key="d0">DATA</data>
      <data key="d1">Covariates are claims or additional information detected in the graph index of source documents
Covariates are additional attributes associated with extracted node instances in the graph index</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="LEIDEN">
      <data key="d0">METHOD</data>
      <data key="d1">Leiden is a community detection method used to partition the graph index into groups of elements
Leiden is a community detection algorithm used to partition graphs into modular communities
A community detection algorithm known for its ability to recover hierarchical community structure efficiently</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">METHOD</data>
      <data key="d1">Retrieval-augmented generation is an approach to answering user questions over entire datasets by retrieving and generating relevant information
RAG is an established approach to answering user questions over entire datasets by retrieving relevant text regions to provide grounding for the generation task</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea,fb3c48579608fa28be585ceb6cd2f0fe</data>
    </node>
    <node id="MICROSOFT">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft is an organization involved in automating sensemaking in scientific discovery using LLMs
Microsoft is a technology company whose CTO, Kevin Scott, participates in the podcast conversations
Microsoft is an organization that conducted a study on the impact of large language models on scientific discovery using GPT-4</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,833e7d67dcd30790b26b71c9b5306f6b,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="RANADE">
      <data key="d0">PERSON</data>
      <data key="d1">Ranade is an author involved in research on automating sensemaking in intelligence analysis using LLMs</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Joshi is an author involved in research on automating sensemaking in intelligence analysis using LLMs</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="KLEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Klein is an author who defined sensemaking and discussed its importance in understanding connections among people, places, and events</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="LEWIS">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis is an author who contributed to the development of the retrieval-augmented generation (RAG) approach</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="TRAAG">
      <data key="d0">PERSON</data>
      <data key="d1">Traag is an author who contributed to the development of the Leiden community detection method</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="ARXIV">
      <data key="d0">PUBLICATION</data>
      <data key="d1">arXiv is a repository where the preprint of the discussed research paper is available
arXiv is a repository where the mentioned papers are published as preprints
The platform where the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models" was published
arXiv is the platform where the paper "Retrieval-augmented generation for large language models: A survey" was publishedarXiv is the platform where the paper "Knowledge graph-augmented language models for knowledge-grounded dialogue generation" was published
arXiv is a repository of electronic preprints (known as e-prints) approved for publication after moderation, but not full peer review
The preprint server where the paper "Lost in the middle: How language models use long contexts" was published
arXiv is a preprint repository where several papers mentioned in the text were published
arXiv is a repository where the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management" was publishedarXiv is a repository where the paper "Llama 2: Open foundation and fine-tuned chat models" was publishedarXiv is a repository where the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy" was publishedarXiv is a repository where the paper "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries" was publishedarXiv is a repository where the paper "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions" was publishedarXiv is a repository where the paper "Enhancing knowledge graph construction using large language models" was publishedarXiv is a repository where the paper "Is chatgpt a good nlg evaluator? a preliminary study" was published
arXiv is the platform where the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" was publishedarXiv is the platform where the paper "Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt" was publishedarXiv is the platform where the paper "Is chatgpt a good nlg evaluator? a preliminary study" was publishedarXiv is the platform where the paper "Causal graph discovery with retrieval-augmented generation based large language models" was publishedarXiv is the platform where the paper "Knowledge graph prompting for multi-document question answering" was publishedarXiv is the platform where the paper "Text summarization with latent queries" was published</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,086021a89900a39bcb62036981737bfa,58ae80c41cfe46db39da26b6a83584e5,6cd82819982879bd164547d2773ba5c7,71f6daf11e64e5273a3847d46bf228e1,833e7d67dcd30790b26b71c9b5306f6b,8d87efac8c50cf20cdf26bf61e5e2035,f0306814bf64f5c9e79603fc6a52f4ea,fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="PREPRINT">
      <data key="d0">PUBLICATION</data>
      <data key="d1">Preprint refers to the version of the research paper that is under review and available on arXiv</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="CS.CL">
      <data key="d0">CATEGORY</data>
      <data key="d1">cs.CL is the category under which the research paper is classified on arXiv</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="24 APR 2024">
      <data key="d0">DATE</data>
      <data key="d1">24 Apr 2024 is the date when the research paper was submitted to arXiv</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="2404.16130V1">
      <data key="d0">IDENTIFIER</data>
      <data key="d1">2404.16130v1 is the identifier for the research paper on arXiv</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="DOCUMENT COLLECTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Document collections refer to large sets of documents that are analyzed for sensemaking</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="LLM PROMPTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM prompts are specific instructions given to large language models to tailor their responses to the domain of the dataset
LLM prompts are specific instructions given to the LLM to extract elements from text chunks</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="COMMUNITY DETECTION">
      <data key="d0">METHOD</data>
      <data key="d1">Community detection is a method used to identify groups of related elements within a graph
The process of identifying communities within a graph</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="DOMAIN-TAILORED SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">Domain-tailored summarization is a method used to create summaries that are specific to the domain of the dataset</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="KLEIN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Klein et al. are authors who defined sensemaking and discussed its importance in understanding connections among people, places, and events</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="RANADE AND JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ranade and Joshi are authors who discussed the use of LLMs in intelligence analysis</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="LEWIS ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis et al. are authors who developed the retrieval-augmented generation (RAG) approach</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="TRAAG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Traag et al. are authors who developed the Leiden community detection method
Authors of the Leiden algorithm, known for its efficiency in recovering hierarchical community structures</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d0">METHOD</data>
      <data key="d1">QFS is a task framing that focuses on generating summaries based on specific queries, rather than just concatenating excerpts</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </node>
    <node id="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A type of summarization that generates natural language summaries based on specific queries, rather than just extracting text</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </node>
    <node id="TRANSFORMER ARCHITECTURE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A neural network architecture that has shown substantial improvements in various summarization tasks</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </node>
    <node id="GPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A series of large language models known for their ability to perform in-context learning and summarization</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </node>
    <node id="LLAMA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A series of large language models known for their ability to perform in-context learning and summarization</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </node>
    <node id="GEMINI">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A series of large language models known for their ability to perform in-context learning and summarization
Gemini is a family of highly capable multimodal models described in an arXiv preprint</data>
      <data key="d2">086021a89900a39bcb62036981737bfa,fb3c48579608fa28be585ceb6cd2f0fe</data>
    </node>
    <node id="KNOWLEDGE GRAPH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A structured representation of knowledge used in the Graph RAG approach for global summarization
A knowledge graph is a structured representation of information, used in the Graph RAG approach for summarization</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,fb3c48579608fa28be585ceb6cd2f0fe</data>
    </node>
    <node id="LEWIS ET AL., 2020">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on Retrieval-augmented generation (RAG)</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="DANG, 2006">
      <data key="d0">REFERENCE</data>
      <data key="d1">Author of a paper on query-focused summarization (QFS)</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="BAUMEL ET AL., 2018">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on query-focused abstractive summarization</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="LASKAR ET AL., 2020">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on query-focused abstractive summarization</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="YAO ET AL., 2017">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on query-focused abstractive summarization</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="GOODWIN ET AL., 2020">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the early applications of the transformer architecture</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="LASKAR ET AL., 2022">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the early applications of the transformer architecture</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="LIU AND LAPATA, 2019">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the early applications of the transformer architecture</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="ACHIAM ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the GPT series of large language models</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="BROWN ET AL., 2020">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the GPT series of large language models
A reference to a publication by Brown et al. in 2020, discussing in-context learning with few-shot examples</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="TOUVRON ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the Llama series of large language models</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="ANIL ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the Gemini series of large language models</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="KURATOV ET AL., 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the limitations of LLM context windows
A reference to a publication by Kuratov et al. in 2024, discussing the recall degradation of longer LLM context windows
A reference to a study by Kuratov et al. in 2024, discussing the potential for information to be lost in longer contexts</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f,bc9e2c9e369c4108cf4f6dd5f60960f4,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="LIU ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the limitations of LLM context windows
A reference to a publication by Liu et al. in 2023, discussing the recall degradation of longer LLM context windows
A reference to a study by Liu et al. in 2023, discussing the potential for information to be lost in longer contexts</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f,bc9e2c9e369c4108cf4f6dd5f60960f4,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="COMMUNITY DETECTION ALGORITHMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Algorithms used to partition graphs into modular communities of closely-related nodes
Algorithms used to partition a graph into communities of nodes with stronger connections to one another</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="LOUVAIN">
      <data key="d0">ALGORITHM</data>
      <data key="d1">Louvain is a community detection algorithm used to partition graphs into modular communities</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="HOTPOTQA">
      <data key="d0">DATASET</data>
      <data key="d1">HotPotQA is a dataset used to evaluate the entity extraction prompt with gpt-4-turbo
HotPotQA is a dataset used to observe the behavior of text chunk extraction in the Graph RAG approach
A benchmark dataset for open-domain question answering, targeting explicit fact retrieval</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,922778ce1cb2fdd6dbab1746c8795620,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="GPT-4-TURBO">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4-Turbo is a version of the GPT-4 model used for entity extraction in the evaluation
GPT-4-Turbo is a model with a large context size of 128k tokens used in the analysis</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,4c855404ee3d3c94aa2136f1513c666f</data>
    </node>
    <node id="PODCAST TRANSCRIPTS">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset consisting of transcripts from podcasts used for analysis
A dataset consisting of compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders
Compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders. Size: 1669 &#215; 600-token text chunks, with 100-token overlaps between chunks, approximately 1 million tokens
A dataset consisting of transcripts from podcasts used for analysis
A dataset consisting of transcripts from podcasts used for analysis</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,21e52bc06a82796b1f4bcd73edda1f2a,36db32c37e1987e2c5863898ad882190,922778ce1cb2fdd6dbab1746c8795620,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="NEWS ARTICLES">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset consisting of news articles used for analysis
A dataset consisting of news articles used for analysis
Benchmark dataset comprising news articles published from September 2013 to December 2023 in a range of categories, including entertainment, business, sports, technology, health, and science. Size: 3197 &#215; 600-token text chunks, with 100-token overlaps between chunks, approximately 1.7 million tokens
A dataset consisting of news articles used for analysis</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,21e52bc06a82796b1f4bcd73edda1f2a,36db32c37e1987e2c5863898ad882190,922778ce1cb2fdd6dbab1746c8795620</data>
    </node>
    <node id="MAP-REDUCE">
      <data key="d0">METHOD</data>
      <data key="d1">Map-reduce is a method used for query-focused summarization of an entire corpus
A method used for text summarization by applying a map-reduce approach directly to source texts</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="EMPOWERMENT">
      <data key="d0">METRIC</data>
      <data key="d1">A target quality used to evaluate the summarization approach, focusing on the ability to develop understanding of broad issues and themes
A metric that measures how well an answer helps the reader understand and make informed judgements about a topic
A metric used to evaluate how empowering the generated answers are
A metric used to evaluate the effectiveness of answers in empowering users
A concept or metric used in the evaluation, with an average win rate of 51.3%
Empowerment is a measure used to evaluate the ability of different methods to help users reach an informed understanding</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,322e02986c8724eedbcf3ebfa20b989c,36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="NAIVE RAG">
      <data key="d0">METHOD</data>
      <data key="d1">Naive RAG is a basic approach to RAG used as a baseline for comparison
Naive RAG is a method that lists public figures mentioned in entertainment articles, focusing on their professional achievements and personal lives
Naive RAG is a baseline method used for comparison in text generation tasks
A method that produces the most direct responses but is outperformed by global approaches in comprehensiveness and diversity
Naive RAG is a basic retrieval-augmented generation method that converts documents to text, splits them into chunks, and embeds these chunks into a vector space for query matching</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="GLOBAL MAP-REDUCE SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A method for summarizing source texts using a map-reduce approach</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="ACTIVITY-CENTERED SENSEMAKING QUESTIONS">
      <data key="d0">OUTPUT</data>
      <data key="d1">Questions generated to evaluate the summarization approach, focusing on understanding activities</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="HIERARCHICAL LEVEL">
      <data key="d0">PARAMETER</data>
      <data key="d1">The level of detail in community summaries used to answer queries</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="TOKEN COSTS">
      <data key="d0">METRIC</data>
      <data key="d1">The computational cost measured in tokens used in the summarization process
Token costs refer to the number of tokens required for processing text in the Graph RAG approach</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="DATA FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">The high-level process of the Graph RAG approach and pipeline</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="DESIGN PARAMETERS">
      <data key="d0">PARAMETER</data>
      <data key="d1">Key parameters that influence the design of the Graph RAG approach and pipeline
Design parameters are key settings and configurations in the Graph RAG approach</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="GLOBAL SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">Global summarization is a method that aims to summarize information from a large dataset or corpus
A method for summarizing the overall structure and semantics of a dataset
A method for summarizing information on a global scale</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,7fb7d9ce2da9c940a32afdd87d1d9e56,e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="MODULARITY">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Modularity is an inherent quality of graphs that allows them to be partitioned into communities of closely-related nodes</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="COMMUNITY DESCRIPTIONS">
      <data key="d0">OUTPUT</data>
      <data key="d1">Descriptions generated from modular communities in the knowledge graph</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="QUERY">
      <data key="d0">INPUT</data>
      <data key="d1">A specific question or request for information that the summarization methods aim to answer</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="CORPUS">
      <data key="d0">DATASET</data>
      <data key="d1">A large collection of texts or documents used for analysis and summarization</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="PARTIAL ANSWERS">
      <data key="d0">OUTPUT</data>
      <data key="d1">Intermediate answers generated from community summaries before being combined into a final global answer</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="FINAL GLOBAL ANSWER">
      <data key="d0">OUTPUT</data>
      <data key="d1">The comprehensive answer generated by combining all relevant partial answers</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="ACTIVITY-CENTERED SENSEMAKING">
      <data key="d0">METHOD</data>
      <data key="d1">A method that focuses on generating questions to understand activities from datasets</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="SHORT DESCRIPTIONS">
      <data key="d0">INPUT</data>
      <data key="d1">Brief descriptions of datasets used to generate sensemaking questions</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="REAL-WORLD DATASETS">
      <data key="d0">DATASET</data>
      <data key="d1">Datasets that represent real-world information, such as podcast transcripts and news articles</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES">
      <data key="d0">PARAMETER</data>
      <data key="d1">The level of detail in community summaries used to answer queries</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="SOURCE TEXT SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A method that summarizes the original source texts directly</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">OUTPUT</data>
      <data key="d1">Summaries generated from lower hierarchical levels of the community in the knowledge graph
Low-level community summaries are summaries that provide a detailed overview of the source text
Low-level community summaries are a type of community summary used in the News dataset for analysis</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,6f33a085ff3304e5994f7fbb86c881a4,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="INTERMEDIATE-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">OUTPUT</data>
      <data key="d1">Summaries generated from intermediate hierarchical levels of the community in the knowledge graph
Intermediate-level community summaries are summaries that provide a mid-level overview of the source text</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="HIGH-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">OUTPUT</data>
      <data key="d1">Summaries generated from higher hierarchical levels of the community in the knowledge graph</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </node>
    <node id="PIPELINE">
      <data key="d0">PROCESS, SYSTEM</data>
      <data key="d1">The pipeline refers to the sequence of steps and processes involved in the Graph RAG approach
A series of processes or steps used to analyze and summarize a dataset</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="GRAPH INDEX">
      <data key="d0">DATA STRUCTURE, OUTPUT</data>
      <data key="d1">Graph index is a data structure that includes various elements extracted from text chunks using LLM prompts
An index created from a graph structure, used for query-focused summarization and other tasks
The graph index supporting conditions C0-C3, created using generic prompts for entity and relationship extraction
A self-generated index that enables Graph RAG
A data structure used in RAG systems to organize and retrieve information
An index built using a graph structure to organize and retrieve information</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,92e93fc6449756c0a60200636b297f65,973164fa90bf2b4ee267f4fd795916bf,bc9e2c9e369c4108cf4f6dd5f60960f4,e4d9b12cf2b4c691c74019eefff4fb39,f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="ENTITY REFERENCES">
      <data key="d0">DATA, UNIT</data>
      <data key="d1">Entity references are mentions of entities within text chunks, extracted during the processing</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="RECALL">
      <data key="d0">METRIC</data>
      <data key="d1">Recall is a metric used to measure the completeness of entity extraction from text chunks</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="PRECISION">
      <data key="d0">METRIC</data>
      <data key="d1">Precision is a metric used to measure the accuracy of entity extraction from text chunks</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="FEW-SHOT EXAMPLES">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Few-shot examples are sample inputs provided to the LLM for in-context learning to tailor the extraction prompt to the document corpus domain
Few-shot examples are specialized instances provided to the LLM to improve its performance in domains with specialized knowledge such as science, medicine, and law
Examples tailored to the domain of the data used in the graph indexing process</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0,973164fa90bf2b4ee267f4fd795916bf,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="NAMED ENTITIES">
      <data key="d0">DATA, UNIT</data>
      <data key="d1">Named entities are specific types of entities such as people, places, and organizations, extracted from text chunks</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="YANG ET AL., 2018">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Yang et al. in 2018, introducing the HotPotQA dataset</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="TECHNIQUES">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Techniques refer to the specific methods used in the Graph RAG approach</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="IMPLEMENTATION DETAILS">
      <data key="d0">ATTRIBUTE, CONFIGURATION</data>
      <data key="d1">Implementation details are specific configurations and settings used in the Graph RAG approach</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="SINGLE EXTRACTION ROUND">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">A single extraction round refers to one complete cycle of extracting elements from text chunks using LLM prompts</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="CHUNK SIZE">
      <data key="d0">ATTRIBUTE, CONFIGURATION</data>
      <data key="d1">Chunk size refers to the length of text chunks used in the extraction process</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="RECALL DEGRADATION">
      <data key="d0">METRIC, ISSUE</data>
      <data key="d1">Recall degradation refers to the decrease in recall performance when using longer LLM context windows</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="EXTRACTION PROCESS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The extraction process involves identifying and extracting elements from text chunks using LLM prompts</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="DOMAIN">
      <data key="d0">ATTRIBUTE, CONFIGURATION</data>
      <data key="d1">Domain refers to the specific area of knowledge or field to which the document corpus belongs</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="DOCUMENT CORPUS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Document corpus refers to the collection of documents being processed in the Graph RAG approach</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="DEFAULT PROMPT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Default prompt is the standard set of instructions given to the LLM for extracting named entities</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="SECONDARY EXTRACTION PROMPT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Secondary extraction prompt is an additional set of instructions given to the LLM for extracting covariates</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </node>
    <node id="COVARIATE PROMPT">
      <data key="d0">METHOD</data>
      <data key="d1">A covariate prompt is used to extract additional attributes associated with detected entities, including claims linked to the entities</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="CLAIMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Claims are statements or assertions linked to detected entities, including details such as subject, object, type, description, source text span, and start and end dates</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="GLEANINGS">
      <data key="d0">METHOD</data>
      <data key="d1">Gleanings refer to multiple rounds of entity extraction to ensure that no entities are missed in the process</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="LOGIT BIAS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Logit bias is a technique used to force a yes/no decision from the LLM during the entity extraction process</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="ENTITY NODE">
      <data key="d0">CONCEPT</data>
      <data key="d1">An entity node is a representation of an entity in a graph structure</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="RELATIONSHIP EDGE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A relationship edge is a representation of a relationship between entities in a graph structure</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="CLAIM COVARIATE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A claim covariate is an additional attribute or variable associated with a claim in a graph structure</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="COMMUNITIES OF ENTITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Communities of entities are groups of closely-related entities detected and summarized by the LLM</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="NOISY GRAPH STRUCTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A noisy graph structure is a graph that may contain duplicate or inconsistent entity elements due to variations in text format
A graph structure that may contain inconsistencies or errors, making it challenging to analyze</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0,7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="SCIENCE">
      <data key="d0">DOMAIN</data>
      <data key="d1">Science is a specialized domain that benefits from few-shot examples to improve LLM performance</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="MEDICINE">
      <data key="d0">DOMAIN</data>
      <data key="d1">Medicine is a specialized domain that benefits from few-shot examples to improve LLM performance</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="LAW">
      <data key="d0">DOMAIN</data>
      <data key="d1">Law is a specialized domain that benefits from few-shot examples to improve LLM performance</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="SOURCE TEXT SPAN">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Source text span is an attribute of a claim that indicates the specific portion of text from which the claim was extracted</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="START DATE">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Start date is an attribute of a claim that indicates when the event or fact described in the claim began</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="END DATE">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">End date is an attribute of a claim that indicates when the event or fact described in the claim ended</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="DESCRIPTION">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Description is an attribute of a claim that provides a detailed explanation of the claim</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="SUBJECT">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Subject is an attribute of a claim that indicates the main entity involved in the claim</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="OBJECT">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Object is an attribute of a claim that indicates the entity that is affected by the subject in the claim</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
    </node>
    <node id="COMMON ENTITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A concept referring to an entity that has multiple name variations but is resilient to such variations due to sufficient connectivity to closely-related entities</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="LLMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Large Language Models (LLMs) are advanced AI models capable of understanding and generating human-like text
Large Language Models used as evaluators of natural language generation
Large Language Models (LLMs) are used for various tasks such as knowledge graph creation and completion</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,92e93fc6449756c0a60200636b297f65,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="KNOWLEDGE GRAPHS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Structured representations of knowledge in the form of triples (subject, predicate, object) used for reasoning tasks</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="HOMOGENEOUS NODES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Nodes in a graph that are of the same type and are described using rich descriptive text</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="RELATIONSHIP EDGES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Edges in a graph that represent relationships between entity nodes</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="EDGE WEIGHTS">
      <data key="d0">METRIC</data>
      <data key="d1">Weights assigned to edges in a graph, representing the normalized counts of detected relationship instances</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A structure in which communities are organized in a hierarchy, with each level providing a partition of the graph nodes
Hierarchical community structure is a multi-level clustering of communities used to generate community summaries
A structure that organizes data into a hierarchy of communities</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd,e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="COMMUNITY PARTITION">
      <data key="d0">CONCEPT</data>
      <data key="d1">A division of graph nodes into mutually-exclusive, collectively-exhaustive communities</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="MULTIHOP-RAG">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A specific implementation or variant of Retrieval-Augmented Generation (RAG) used in the context of graph communities
MultiHop-RAG is a dataset used for community detection and analysis
A benchmark dataset comprising news articles published from September 2013 to December 2023 in a range of categories, including entertainment, business, sports, technology, health, and scienceA benchmark dataset for open-domain question answering, targeting explicit fact retrieval</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd,922778ce1cb2fdd6dbab1746c8795620</data>
    </node>
    <node id="FORTUNATO">
      <data key="d0">PERSON</data>
      <data key="d1">An author who has conducted surveys on community detection algorithms</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="JIN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Authors who have conducted surveys on community detection algorithms</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="DATASET">
      <data key="d0">CONCEPT</data>
      <data key="d1">A collection of data used for analysis and summarization
A collection of data used for analysis, such as podcast transcripts or news articles
A collection of data used for evaluation, including the Podcast and News datasets</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,7fb7d9ce2da9c940a32afdd87d1d9e56,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="GLOBAL QUERIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Queries that aim to retrieve information from a global perspective, covering the entire dataset
Global queries refer to questions or inquiries that require comprehensive answers derived from multiple sources or datasets</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="ROOT COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">The top-level communities in a hierarchical community structure
Root communities are the top-level clusters in a hierarchical community structure</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="SUB-COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Lower-level communities in a hierarchical community structure, providing more detailed information
Sub-communities are lower-level clusters within root communities in a hierarchical community structure</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="REPORTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Detailed documents that provide information about specific subtopics within a community</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="PARTITION">
      <data key="d0">CONCEPT</data>
      <data key="d1">The division of a graph into distinct communities</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="HIERARCHY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A system in which elements are ranked or organized in levels</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="LEVEL 0">
      <data key="d0">CONCEPT</data>
      <data key="d1">The root level in a hierarchical community structure
Level 0 represents the root-level communities in the hierarchical clustering with maximum modularity</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="LEVEL 1">
      <data key="d0">CONCEPT</data>
      <data key="d1">A sub-level in a hierarchical community structure, providing more detailed information
Level 1 represents sub-communities within the root-level communities, revealing internal structure</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="FIGURE 3">
      <data key="d0">CONCEPT</data>
      <data key="d1">A visual representation of graph communities detected using the Leiden algorithm</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </node>
    <node id="LEIDEN ALGORITHM">
      <data key="d0">METHOD</data>
      <data key="d1">The Leiden algorithm is a method used for detecting communities in large networks</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="OPENORD">
      <data key="d0">TOOL</data>
      <data key="d1">OpenORD is a tool used for node layout in graph visualizations</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="FORCE ATLAS 2">
      <data key="d0">TOOL</data>
      <data key="d1">Force Atlas 2 is a tool used for node layout in graph visualizations</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="NODE">
      <data key="d0">ELEMENT</data>
      <data key="d1">Nodes represent entities in a graph, with size proportional to their degree</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="EDGE">
      <data key="d0">ELEMENT</data>
      <data key="d1">Edges represent connections between nodes in a graph</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="COVARIATE">
      <data key="d0">ELEMENT</data>
      <data key="d1">Covariates are variables that are linked to nodes and edges in a graph</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="LLM CONTEXT WINDOW">
      <data key="d0">CONCEPT</data>
      <data key="d1">The LLM context window is the token limit within which summaries are added for processing by a language model</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="HIERARCHICAL CLUSTERING">
      <data key="d0">METHOD</data>
      <data key="d1">Hierarchical clustering is a method of clustering data into a tree-like structure with multiple levels</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="TOKEN LIMIT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The token limit is the maximum number of tokens that can be processed in a single context window by a language model</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="SUMMARY DETAIL">
      <data key="d0">CONCEPT</data>
      <data key="d1">Summary detail refers to the level of detail provided in a summary</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="SCOPE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Scope refers to the range or extent of information covered in a summary</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="USER QUERY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A user query is a question or inquiry posed by a user seeking information
A query from the user that the system aims to answer</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CHUNK">
      <data key="d0">ELEMENT</data>
      <data key="d1">Chunks are segments of community summaries divided into pre-specified token sizes</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d3">ELEMENT</data>
    </node>
    <node id="PROMINENCE">
      <data key="d0">METRIC</data>
      <data key="d1">Prominence is a metric used to prioritize community edges based on the combined degree of source and target nodes</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="COMBINED SOURCE AND TARGET NODE DEGREE">
      <data key="d0">METRIC</data>
      <data key="d1">Combined source and target node degree is a metric used to measure the overall prominence of community edges</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="COMMUNITY EDGE">
      <data key="d0">ELEMENT</data>
      <data key="d1">Community edges are connections between nodes within a community, prioritized based on prominence</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="SUB-COMMUNITY SUMMARIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Sub-community summaries are shorter summaries of sub-communities used when element summaries exceed the token limit</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="SUMMARY DETAIL AND SCOPE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Summary detail and scope refer to the balance of detail and range of information in community summaries for sensemaking</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="COMMUNITY LEVEL">
      <data key="d0">CATEGORY</data>
      <data key="d1">Community level refers to the different levels in the hierarchical community structure used to generate summaries</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
    </node>
    <node id="CHUNKS">
      <data key="d0">DATA</data>
      <data key="d1">Chunks are segments of community summaries divided based on a pre-specified token size</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="HELPFULNESS SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">A score between 0-100 generated by the LLM to indicate how helpful an answer is in addressing the target question</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="TECH JOURNALIST">
      <data key="d0">USER</data>
      <data key="d1">A user looking for insights and trends in the tech industry</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="EDUCATOR">
      <data key="d0">USER</data>
      <data key="d1">A user incorporating current affairs into curricula</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="TECH POLICY">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic dealing with tech policy and government regulation</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="PRIVACY LAWS">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic discussing the impact of privacy laws on technology development</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="INNOVATION AND ETHICS">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic discussing the balance between innovation and ethical considerations</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="POLICY CHANGES">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic discussing suggested changes to current policies</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="COLLABORATIONS">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic discussing collaborations between tech companies and governments</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="HEALTH TOPICS">
      <data key="d0">TOPIC</data>
      <data key="d1">Current topics in health that can be integrated into health education curricula</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="PREVENTIVE MEDICINE">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic addressing the concepts of preventive medicine and wellness</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="CONTRADICTORY ARTICLES">
      <data key="d0">TOPIC</data>
      <data key="d1">Examples of health articles that contradict each other</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="PUBLIC HEALTH PRIORITIES">
      <data key="d0">TOPIC</data>
      <data key="d1">Insights about public health priorities based on news coverage</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="HEALTH LITERACY">
      <data key="d0">TOPIC</data>
      <data key="d1">The importance of health literacy highlighted through the dataset</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="INTERMEDIATE ANSWERS">
      <data key="d0">OUTPUT</data>
      <data key="d1">Answers generated for each chunk of community summaries</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="TOKEN SIZE">
      <data key="d0">METRIC</data>
      <data key="d1">The pre-specified size of tokens used to divide community summaries into chunks</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="CONTEXT WINDOW">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A window of text used to generate answers, limited by token size
The size of the context window used for answer generation, which is the same across all conditions</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="KEVIN SCOTT">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin Scott is the CTO of Microsoft and a participant in the podcast conversations
Microsoft CTO who participates in podcast conversations compiled in the dataset</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,922778ce1cb2fdd6dbab1746c8795620</data>
    </node>
    <node id="TECHNOLOGY LEADERS">
      <data key="d0">PERSON</data>
      <data key="d1">Individuals who are leaders in the technology industry and participate in the podcast conversations</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="TASK">
      <data key="d0">INPUT</data>
      <data key="d1">A specific activity or goal that the user aims to achieve using the datasets</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="QUESTIONS">
      <data key="d0">INPUT</data>
      <data key="d1">Specific questions generated by the LLM based on the user's task and the target datasets
The questions used in the analysis to evaluate the performance of different methods</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,4c855404ee3d3c94aa2136f1513c666f</data>
    </node>
    <node id="USER">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
    </node>
    <node id="MT-BENCH">
      <data key="d0">DATASET</data>
      <data key="d1">A benchmark dataset for open-domain question answering, targeting explicit fact retrieval
MT-Bench is a benchmarking tool used in the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620,b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="DATA SENSEMAKING">
      <data key="d0">PROCESS</data>
      <data key="d1">The process through which people inspect, engage with, and contextualize data within the broader scope of real-world activities</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="RAG SYSTEMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Retrieval-Augmented Generation systems used for global sensemaking tasks</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="KOESTEN ET AL.">
      <data key="d0">AUTHORS</data>
      <data key="d1">Authors of a paper on data sensemaking behaviors</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">AUTHORS</data>
    </node>
    <node id="XU AND LAPATA">
      <data key="d0">AUTHORS</data>
      <data key="d1">Authors of a paper on methods for extracting latent summarization queries from source texts</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">AUTHORS</data>
    </node>
    <node id="TANG AND YANG">
      <data key="d0">AUTHORS</data>
      <data key="d1">Authors associated with the MultiHop-RAG dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
    </node>
    <node id="YANG ET AL.">
      <data key="d0">AUTHORS</data>
      <data key="d1">Authors associated with the HotPotQA dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">AUTHORS</data>
    </node>
    <node id="ZHENG ET AL.">
      <data key="d0">AUTHORS</data>
      <data key="d1">Authors associated with the MT-Bench dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">AUTHORS</data>
    </node>
    <node id="LATENT SUMMARIZATION QUERIES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
    </node>
    <node id="BEHIND THE TECH">
      <data key="d0">PODCAST</data>
      <data key="d1">A podcast series featuring conversations between Kevin Scott and other technology leaders
Behind the Tech is a media platform associated with Scott, K.</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,922778ce1cb2fdd6dbab1746c8795620</data>
    </node>
    <node id="SCOTT">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin Scott, Microsoft CTO, who participates in the podcast conversations compiled in the dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
    </node>
    <node id="TANG">
      <data key="d0">PERSON</data>
      <data key="d1">An author associated with the MultiHop-RAG dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
    </node>
    <node id="YANG">
      <data key="d0">PERSON</data>
      <data key="d1">An author associated with the MultiHop-RAG dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
    </node>
    <node id="HOTSPOTQA">
      <data key="d0">DATASET</data>
      <data key="d1">A benchmark dataset for open-domain question answering, targeting explicit fact retrieval</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
    </node>
    <node id="N">
      <data key="d0">METRIC</data>
      <data key="d1">N represents the number of test questions per dataset used in the evaluation</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="TEXT SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A method applying a map-reduce approach directly to source texts for summarization</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="SEMANTIC SEARCH RAG">
      <data key="d0">METHOD</data>
      <data key="d1">A na&#168;&#305;ve RAG approach where text chunks are retrieved and added to the context window until the token limit is reached</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="C0">
      <data key="d0">CATEGORY</data>
      <data key="d1">Root-level community summaries used to answer user queries, representing the fewest number of summaries
A category or cluster used in the analysis, representing a specific subset of the data
A category or condition used in the analysis, representing a specific subset of the data
A category or cluster used in the analysis, representing a specific subset of the data
A category representing root-level community summaries in the analysis</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="C1">
      <data key="d0">CATEGORY</data>
      <data key="d1">High-level community summaries used to answer user queries, representing sub-communities of C0
A category or cluster used in the analysis, representing a specific subset of the data
A category or condition used in the analysis, representing a specific subset of the data
A category or cluster used in the analysis, representing a specific subset of the data</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="C2">
      <data key="d0">CATEGORY</data>
      <data key="d1">Intermediate-level community summaries used to answer user queries, representing sub-communities of C1
A category or cluster used in the analysis, representing a specific subset of the data
A category or condition used in the analysis, representing a specific subset of the data
A category or cluster used in the analysis, representing a specific subset of the data</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="C3">
      <data key="d0">CATEGORY</data>
      <data key="d1">Low-level community summaries used to answer user queries, representing sub-communities of C2
A category or cluster used in the analysis, representing a specific subset of the data
A category or condition used in the analysis, representing a specific subset of the data
A category or cluster used in the analysis, representing a specific subset of the data
A category representing low-level community summaries in the analysis</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="TS">
      <data key="d0">METHOD</data>
      <data key="d1">A text summarization method applying a map-reduce approach directly to source texts
A category or cluster used in the analysis, representing a specific subset of the data
A category or condition used in the analysis, representing a specific subset of the data
A category or cluster used in the analysis, representing a specific subset of the data
A category representing source text summarization in the analysis</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="SS">
      <data key="d0">METHOD</data>
      <data key="d1">A na&#168;&#305;ve RAG approach where text chunks are retrieved and added to the context window until the token limit is reached
A category or cluster used in the analysis, representing a specific subset of the data
A baseline condition used in the analysis, representing a specific subset of the data
A category representing na&#168;&#305;ve RAG in the analysis</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="PROMPTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The prompts used for answer generation, which are the same across all conditions with minor modifications</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="PODCAST DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset consisting of podcast transcripts used in the evaluation
A dataset consisting of podcast transcripts, used in the analysis
A dataset consisting of podcast transcripts used for analysis</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="NEWS DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset consisting of news articles used in the evaluation
A dataset consisting of news articles, used in the analysis
A dataset consisting of news articles used for analysis</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="METRICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Metrics used to evaluate natural language generation, including reference-based metrics and qualities of generated texts
The metrics used in the analysis to evaluate the performance of different methods</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="WANG ET AL., 2023A">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a study by Wang et al. in 2023, indicating the effectiveness of LLMs in evaluation
A reference to a study or paper authored by Wang and others in 2023</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="ZHENG ET AL., 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a study by Zheng et al. in 2024, indicating the effectiveness of LLMs in evaluation
A reference to a study or paper authored by Zheng and others in 2024</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="TABLE 1">
      <data key="d0">REFERENCE</data>
      <data key="d1">Table 1 shows example questions for each of the two evaluation datasets</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="CONDITIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Different conditions compared in the analysis, including Graph RAG, text summarization, and semantic search RAG
Different scenarios or variables that are compared in an experiment</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="USER QUERIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Queries made by users that are answered using different methods and conditions
Queries made by users to retrieve information</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf,e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="ENTITY TYPES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Types of entities extracted during the graph indexing process</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="CONTEXT WINDOW SIZE">
      <data key="d0">METRIC</data>
      <data key="d1">The size of the context window used in the graph indexing process, set to 600 tokens
The size of the context window used in the analysis, tested at 8k, 16k, 32k, and 64k tokens
The fixed size of the context window used for the final evaluation, set to 8k tokens</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="GLEANING">
      <data key="d0">CONCEPT</data>
      <data key="d1">The process of extracting information, with 1 gleaning for the Podcast dataset and 0 gleanings for the News dataset</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
    </node>
    <node id="NATURAL LANGUAGE GENERATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Natural Language Generation (NLG) is a subfield of artificial intelligence that focuses on generating human-like text from data</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="LLM-AS-A-JUDGE">
      <data key="d0">METHOD</data>
      <data key="d1">A method where a Large Language Model (LLM) is used to compare and evaluate competing outputs</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="RAGAS">
      <data key="d0">METHOD</data>
      <data key="d1">A method for evaluating the performance of Retrieval-Augmented Generation (RAG) systems, focusing on context relevance, faithfulness, and answer relevance</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="ES ET AL., 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A reference to a study or paper authored by Es and others in 2023</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="LLM EVALUATOR">
      <data key="d0">TOOL</data>
      <data key="d1">A Large Language Model (LLM) used to evaluate and compare generated texts based on specific metrics</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="DIRECTNESS">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures how specifically and clearly an answer addresses a question
A metric used to evaluate the straightforwardness of the generated answers
A validity test metric used to measure the directness of responses, with naive RAG producing the most direct responses</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="TABLE 2">
      <data key="d0">DATA</data>
      <data key="d1">An example of LLM-generated assessment shown in a table format</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="QUESTION">
      <data key="d0">DATA</data>
      <data key="d1">A specific query used in the evaluation process
A metric used to evaluate the generated responses by asking specific questions</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="PUBLIC FIGURES">
      <data key="d0">ENTITY</data>
      <data key="d1">Individuals who are well-known in the entertainment industry and are mentioned across various articles
Public figures are individuals who have gained fame or notoriety in various sectors such as entertainment, sports, and digital media.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,718017a4871c909420f84b85b8ba969d</data>
    </node>
    <node id="ENTERTAINMENT ARTICLES">
      <data key="d0">DATASET</data>
      <data key="d1">A collection of articles focused on the entertainment industry
A dataset consisting of articles related to the entertainment industry</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="ENTERTAINMENT INDUSTRY">
      <data key="d0">DOMAIN</data>
      <data key="d1">A sector that encompasses various forms of entertainment, including movies, music, and television
The entertainment industry encompasses film, television, music, sports, and digital media</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="STATE-OF-THE-ART">
      <data key="d0">METRIC</data>
      <data key="d1">A metric indicating the highest level of development or achievement in a particular field</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="COMPETITIVE RESULTS">
      <data key="d0">METRIC</data>
      <data key="d1">A metric indicating results that are comparable to or better than those of others in the same field</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="HUMAN JUDGEMENTS">
      <data key="d0">METRIC</data>
      <data key="d1">A metric based on evaluations made by humans</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="REFERENCE-BASED METRICS">
      <data key="d0">METRIC</data>
      <data key="d1">Metrics that require a gold standard or reference answers for evaluation</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="REFERENCE-FREE STYLE">
      <data key="d0">METHOD</data>
      <data key="d1">An evaluation method that does not require reference answers</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="CONTEXT RELEVANCE">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures how relevant the generated text is to the given context</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="FAITHFULNESS">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures how accurately the generated text reflects the source information</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="ANSWER RELEVANCE">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures how relevant the generated answer is to the question</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="MULTI-STAGE">
      <data key="d0">METHOD</data>
      <data key="d1">A method involving multiple stages or steps</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="GOLD STANDARD ANSWERS">
      <data key="d0">DATA</data>
      <data key="d1">The correct or ideal answers used as a benchmark in evaluations</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="SENSEMAKING QUESTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Questions designed to help understand and make sense of complex information
A class of questions used to evaluate the performance of RAG systems
Questions designed to validate the understanding and interpretation of data</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,92e93fc6449756c0a60200636b297f65,e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="HEAD-TO-HEAD COMPARISON">
      <data key="d0">METHOD</data>
      <data key="d1">A method where two items are directly compared against each other</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="TARGET METRICS">
      <data key="d0">DATA</data>
      <data key="d1">Specific metrics that are the focus of an evaluation
Specific measures used to evaluate the performance of RAG systems
Specific metrics aimed to be achieved or measured in the analysis</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,92e93fc6449756c0a60200636b297f65,e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="CONTROL METRIC">
      <data key="d0">DATA</data>
      <data key="d1">A metric used as a baseline or standard for comparison</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="VALIDITY">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures the accuracy and reliability of a method or result</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="STOCHASTICITY">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures the randomness or variability in a process</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="MEAN SCORES">
      <data key="d0">DATA</data>
      <data key="d1">The average scores obtained from multiple evaluations</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
    </node>
    <node id="TAYLOR SWIFT">
      <data key="d0">PERSON</data>
      <data key="d1">Taylor Swift is a public figure frequently mentioned in entertainment articles, known for her contributions to music and her high-profile personal life
Taylor Swift is a public figure frequently mentioned in entertainment articles, known for her contributions to the music industry.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="TRAVIS KELCE">
      <data key="d0">PERSON</data>
      <data key="d1">Travis Kelce is a public figure frequently mentioned in entertainment articles, known for his contributions to sports and his high-profile personal life
Travis Kelce is a public figure frequently mentioned in entertainment articles, known for his contributions to the sports industry.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="BRITNEY SPEARS">
      <data key="d0">PERSON</data>
      <data key="d1">Britney Spears is a public figure frequently mentioned in entertainment articles, known for her contributions to music and her high-profile personal life
Britney Spears is a public figure frequently mentioned in entertainment articles, known for her contributions to the music industry.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="JUSTIN TIMBERLAKE">
      <data key="d0">PERSON</data>
      <data key="d1">Justin Timberlake is a public figure frequently mentioned in entertainment articles, known for his contributions to music and his high-profile personal life
Justin Timberlake is a public figure frequently mentioned in entertainment articles, known for his contributions to the music industry.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="ACTORS AND DIRECTORS">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category of public figures in the entertainment industry, including those involved in film and television</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="MUSICIANS AND EXECUTIVES">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category of public figures in the entertainment industry, including those involved in music</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="ATHLETES AND COACHES">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category of public figures in the entertainment industry, including those involved in sports</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="INFLUENCERS AND ENTREPRENEURS">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category of public figures in the entertainment industry, including those involved in digital media and business</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="PUBLIC FIGURES IN CONTROVERSY">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category of public figures in the entertainment industry who are involved in controversies</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="DECISION">
      <data key="d0">METRIC</data>
      <data key="d1">A metric used to determine the winner in the comparison of generated responses</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="ASSESSMENT">
      <data key="d0">METRIC</data>
      <data key="d1">A metric used to evaluate the quality of LLM-generated responses</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="FILM">
      <data key="d0">SECTOR</data>
      <data key="d1">A sector within the entertainment industry that includes movies and cinema
The film sector includes public figures involved in the movie industry, including actors, directors, and producers.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="TELEVISION">
      <data key="d0">SECTOR</data>
      <data key="d1">A sector within the entertainment industry that includes TV shows and series
The television sector includes public figures involved in TV shows, including actors, hosts, and producers.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="MUSIC">
      <data key="d0">SECTOR</data>
      <data key="d1">A sector within the entertainment industry that includes musical performances and recordings
The music sector includes public figures involved in the music industry, including singers, musicians, and producers.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="SPORTS">
      <data key="d0">SECTOR</data>
      <data key="d1">A sector within the entertainment industry that includes athletic events and competitions
The sports sector includes public figures involved in sports, including athletes, coaches, and sports commentators.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="DIGITAL MEDIA">
      <data key="d0">SECTOR</data>
      <data key="d1">A sector within the entertainment industry that includes online content and social media
The digital media sector includes public figures involved in online platforms, including influencers, content creators, and digital marketers.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="CULTURAL NARRATIVES">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category within the entertainment industry that includes stories and themes that shape culture</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="TRENDS">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category within the entertainment industry that includes popular movements and styles</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="SOCIAL DISCUSSIONS">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category within the entertainment industry that includes public conversations and debates</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="PUBLIC DISCOURSE">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category within the entertainment industry that includes formal discussions and communications</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
    </node>
    <node id="ANSWER 1">
      <data key="d0">RESPONSE</data>
      <data key="d1">Answer 1 provides a varied and rich response by covering a wide range of public figures from different sectors of the entertainment industry, including film, television, music, sports, gaming, and digital media. It offers insights into the contributions and influence of these figures, as well as controversies and their impact on public discourse. The answer also cites specific data sources for each mentioned figure, indicating a diverse range of evidence to support the claims.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d</data>
    </node>
    <node id="ANSWER 2">
      <data key="d0">RESPONSE</data>
      <data key="d1">Answer 2 focuses on a smaller group of public figures, primarily from the music industry and sports, and relies heavily on a single source for data. It provides concise explanations for the frequent mentions of specific public figures such as Taylor Swift, Travis Kelce, Britney Spears, and Justin Timberlake.
Answer 2 is a generated answer for the example question in the News article dataset</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="NA&#207;VE RAG">
      <data key="d0">METHOD</data>
      <data key="d1">Na&#239;ve RAG is a method used to generate responses that directly list specific public figures who are repeatedly mentioned across various entertainment articles.
Na&#239;ve RAG is a method used to generate answers for questions in the News article dataset
A basic form of RAG that has certain drawbacks which advanced RAG systems aim to overcome
A baseline method for retrieval-augmented generation (RAG) that does not use advanced techniques</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e4d9b12cf2b4c691c74019eefff4fb39,ebf5249c888e07fedce6572a4c03f88c,f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="NEWS ARTICLE DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset consisting of news articles used for generating responses to questions about public figures in the entertainment industry.
A dataset consisting of news articles used for analysis</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="CONTROVERSIES">
      <data key="d0">TOPIC</data>
      <data key="d1">Controversies are events or issues involving public figures that generate public debate and impact public discourse.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d</data>
    </node>
    <node id="GAMING">
      <data key="d0">SECTOR</data>
      <data key="d1">The gaming sector includes public figures involved in the gaming industry, including gamers, developers, and streamers.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d</data>
    </node>
    <node id="DATA SOURCES">
      <data key="d0">RESOURCE</data>
      <data key="d1">Data sources are references or reports used to support claims about public figures and their influence.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d</data>
    </node>
    <node id="LLM-GENERATED ASSESSMENTS">
      <data key="d0">METHOD</data>
      <data key="d1">Assessments generated by large language models (LLMs) to evaluate the answers produced by different methods</data>
      <data key="d2">ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="EXAMPLE QUESTION">
      <data key="d0">DATASET</data>
      <data key="d1">An example question used in the News article dataset for analysis</data>
      <data key="d2">ebf5249c888e07fedce6572a4c03f88c</data>
    </node>
    <node id="DATASETS">
      <data key="d0">DATA</data>
      <data key="d1">The datasets used in the analysis, consisting of various text sources</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
    </node>
    <node id="HEAD-TO-HEAD WIN RATE">
      <data key="d0">METRIC</data>
      <data key="d1">A metric used to compare the performance of different conditions in the analysis</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
    </node>
    <node id="CONDITION">
      <data key="d0">CATEGORY</data>
      <data key="d1">A specific setup or scenario used in the analysis, such as C0, C1, C2, C3, TS, and SS</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
    </node>
    <node id="WIN RATE">
      <data key="d0">METRIC</data>
      <data key="d1">The percentage of times a condition outperformed another in the analysis
The percentage of times a particular approach or method achieves a win in a given context
Win rate is a measure used to evaluate the success rate of different methods in providing comprehensive and diverse answers</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4</data>
    </node>
    <node id="OVERALL WINNER">
      <data key="d0">METRIC</data>
      <data key="d1">The condition that performed the best across all comparisons in the analysis</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
    </node>
    <node id="SELF-WIN RATE">
      <data key="d0">METRIC</data>
      <data key="d1">The expected win rate of a condition when compared to itself, shown as 50% for reference</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
    </node>
    <node id="QUERY-TIME LLM USE">
      <data key="d0">METHOD</data>
      <data key="d1">The use of large language models (LLMs) at the time of querying, evaluated in the analysis</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
    </node>
    <node id="FINAL EVALUATION">
      <data key="d0">METHOD</data>
      <data key="d1">The last stage of the analysis where the best performing context window size was used
</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f</data>
    </node>
    <node id="INDEXING PROCESS">
      <data key="d0">PROCESS</data>
      <data key="d1">The process that resulted in the creation of graphs for the Podcast and News datasets</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
    </node>
    <node id="GRAPH">
      <data key="d0">STRUCTURE</data>
      <data key="d1">A data structure consisting of nodes and edges, used to represent the Podcast and News datasets</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
    </node>
    <node id="GLOBAL APPROACHES">
      <data key="d0">METHOD</data>
      <data key="d1">Approaches that consistently outperformed the naive RAG in comprehensiveness and diversity metrics</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
    </node>
    <node id="UNITS">
      <data key="d0">METRIC</data>
      <data key="d1">The number of context units, such as community summaries or text chunks, used in the analysis</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="TOKENS">
      <data key="d0">METRIC</data>
      <data key="d1">The number of tokens, or individual words, used in the analysis
The number of individual words used in the analysis, with the evaluation focusing on corpora in the region of 1 million tokens</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="% MAX">
      <data key="d0">METRIC</data>
      <data key="d1">The percentage of the maximum token count used in the analysis</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="MAP-REDUCE SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A summarization approach that is the most resource-intensive, requiring the highest number of context tokens
A method for summarizing source texts using a map-reduce approach</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="ROOT-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA</data>
      <data key="d1">Summaries at the root level of the community hierarchy, requiring dramatically fewer tokens per query</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
    </node>
    <node id="SOURCE TEXTS">
      <data key="d0">DATASET</data>
      <data key="d1">Source texts are the original texts used for comparison with community summaries in the analysis
Original texts from which summaries or analyses are derived</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4,e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="RAM ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a paper by Ram et al. in 2023 discussing RAG approaches</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
    </node>
    <node id="GAO ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a paper by Gao et al. in 2023 discussing naive RAG approaches
A reference to a publication by Gao et al. in 2023
A paper by Gao et al. published in 2023, focusing on advanced RAG where the index is a knowledge graph</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4,92e93fc6449756c0a60200636b297f65,f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d0">CATEGORY</data>
      <data key="d1">Intermediate-level summaries are a type of community summary used in the Podcast dataset for analysis</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
    </node>
    <node id="ROOT-LEVEL SUMMARIES">
      <data key="d0">CATEGORY</data>
      <data key="d1">Root-level summaries are a type of community summary used in the analysis</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
    </node>
    <node id="ANSWER COMPREHENSIVENESS">
      <data key="d0">METRIC</data>
      <data key="d1">Answer comprehensiveness is a measure used to evaluate the completeness of answers provided by different methods</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
    </node>
    <node id="AD-HOC LLM USE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Ad-hoc LLM use refers to the spontaneous use of large language models to analyze reasoning and provide specific examples, quotes, and citations</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
    </node>
    <node id="ELEMENT EXTRACTION PROMPTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Element extraction prompts are used to extract specific details in the Graph RAG index</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
    </node>
    <node id="VECTOR SPACE">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">A mathematical space in which text chunks and queries are embedded to represent similar semantics</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="QUERIES">
      <data key="d0">CONCEPT, DATA</data>
      <data key="d1">Search inputs that are embedded into the same vector space as text chunks to find relevant context</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="MODULAR RAG">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A type of RAG system that includes patterns for iterative and dynamic cycles of interleaved retrieval and generation</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="SELF-MEMORY (SELFMEM)">
      <data key="d0">TECHNOLOGY, CONCEPT</data>
      <data key="d1">A concept related to generation-augmented retrieval that facilitates future generation cycles</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="GENERATION-AUGMENTED RETRIEVAL (GAR)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A method that facilitates future generation cycles by using self-memory</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A strategy for iterative retrieval and generation</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="FEDERATED RETRIEVAL-GENERATION (FEB4RAG)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A federated strategy for retrieval and generation</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="MULTI-DOCUMENT SUMMARIZATION">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A method that combines multiple concepts for summarizing multiple documents</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A method for answering questions that require multiple steps or "hops" to gather information</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="HIERARCHICAL INDEX">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">An approach that involves generating a hierarchical index of text chunks by clustering the vectors of text embeddings</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="RAPTOR">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A method for generating a hierarchical index of text chunks by clustering the vectors of text embeddings</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="TREE OF CLARIFICATIONS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A method for answering multiple interpretations of ambiguous questions by generating a hierarchical structure</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="KNOWLEDGE GRAPH CREATION">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A process that involves using LLMs to create knowledge graphs</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="KNOWLEDGE GRAPH COMPLETION">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A process that involves using LLMs to complete existing knowledge graphs</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="CAUSAL GRAPHS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Graphs that represent causal relationships, which can be extracted using LLMs</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="CHENG ET AL., 2024">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Cheng et al. in 2024</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="MAO ET AL., 2020">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Mao et al. in 2020</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="SHAO ET AL., 2023">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Shao et al. in 2023</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="WANG ET AL., 2024">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Wang et al. in 2024</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="SU ET AL., 2020">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Su et al. in 2020</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="FENG ET AL., 2023">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Feng et al. in 2023</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="TRIVEDI ET AL., 2022">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Trivedi et al. in 2022</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="KHATTAB ET AL., 2022">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Khattab et al. in 2022</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="SARTHI ET AL., 2024">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Sarthi et al. in 2024</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="KIM ET AL., 2023">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Kim et al. in 2023</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="TRAJANOSKA ET AL., 2023">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Trajanoska et al. in 2023
A paper by Trajanoska et al. published in 2023, focusing on using LLMs for knowledge graph creation</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="YAO ET AL., 2023">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Yao et al. in 2023
A paper by Yao et al. published in 2023, focusing on using LLMs for knowledge graph completion</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="BAN ET AL.">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Ban et al.</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">REFERENCE, PUBLICATION</data>
    </node>
    <node id="MULTI-DOCUMENT SUMMARIZATION (CAIRE-COVID)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A system that combines multiple concepts for multi-document summarization</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING (ITRG)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A system for multi-hop question answering</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING (IR-COT)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A system for multi-hop question answering</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING (DSP)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A system for multi-hop question answering</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="PRE-RETRIEVAL STRATEGIES">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Strategies used before the retrieval process in advanced RAG systems</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="RETRIEVAL STRATEGIES">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Strategies used during the retrieval process in advanced RAG systems</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="POST-RETRIEVAL STRATEGIES">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Strategies used after the retrieval process in advanced RAG systems</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="INTERLEAVED RETRIEVAL AND GENERATION">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A pattern in Modular RAG systems for iterative and dynamic cycles of retrieval and generation</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="GENERATION CYCLES">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Cycles of generation that are facilitated by self-memory in Graph RAG</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
    </node>
    <node id="BAN ET AL., 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Ban et al. published in 2023, focusing on the extraction of causal graphs from source texts</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="ZHANG ET AL., 2024">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Zhang et al. published in 2024, focusing on the extraction of causal graphs from source texts</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="KAPING">
      <data key="d0">METHOD</data>
      <data key="d1">A method where the index is a knowledge graph, developed by Baek et al. in 2023</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METHOD</data>
    </node>
    <node id="BAEK ET AL., 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Baek et al. published in 2023, focusing on the KAPING method</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="G-RETRIEVER">
      <data key="d0">METHOD</data>
      <data key="d1">A method where subsets of the graph structure are the objects of enquiry, developed by He et al. in 2024</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METHOD</data>
    </node>
    <node id="HE ET AL., 2024">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by He et al. published in 2024, focusing on the G-Retriever method</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="GRAPH-TOOLFORMER">
      <data key="d0">METHOD</data>
      <data key="d1">A method where derived graph metrics are the objects of enquiry, developed by Zhang in 2023</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METHOD</data>
    </node>
    <node id="ZHANG, 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Zhang published in 2023, focusing on the Graph-ToolFormer method</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="SURGE">
      <data key="d0">METHOD</data>
      <data key="d1">A method where narrative outputs are strongly grounded in the facts of retrieved subgraphs, developed by Kang et al. in 2023</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METHOD</data>
    </node>
    <node id="KANG ET AL., 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Kang et al. published in 2023, focusing on the SURGE method</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="FABULA">
      <data key="d0">METHOD</data>
      <data key="d1">A method where retrieved event-plot subgraphs are serialized using narrative templates, developed by Ranade and Joshi in 2023</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METHOD</data>
    </node>
    <node id="RANADE AND JOSHI, 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Ranade and Joshi published in 2023, focusing on the FABULA method</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="WANG ET AL., 2023B">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Wang et al. published in 2023, focusing on a system that supports both creation and traversal of text-relationship graphs for multi-hop question answering</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="LANGCHAIN">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">LangChain is an organization that supports a variety of graph databases
LangChain is an organization that developed Langchain graphs</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1,92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="LLAMAINDEX">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">LlamaIndex is an organization that supports a variety of graph databases
LlamaIndex is an organization that developed the LlamaIndex Knowledge Graph Index</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NEO4J">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Neo4J is a graph database format supported by various RAG applications
Neo4J is an organization that developed Project NaLLM</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="NALLM">
      <data key="d0">METHOD</data>
      <data key="d1">A method that can create and reason over knowledge graphs in Neo4J format, developed by Neo4J in 2024</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METHOD</data>
    </node>
    <node id="NEBULAGRAPH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">NebulaGraph is a graph database format supported by various RAG applications
NebulaGraph is an organization that launched the industry-first graph RAG: Retrieval-augmented generation with LLM based on knowledge graphs</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="GRAPHRAG">
      <data key="d0">METHOD</data>
      <data key="d1">A method that can create and reason over knowledge graphs in NebulaGraph format, developed by NebulaGraph in 2024</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METHOD</data>
    </node>
    <node id="SELFCHECKGPT">
      <data key="d0">METHOD</data>
      <data key="d1">A method for comparing fabrication rates, developed by Manakul et al. in 2023</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METHOD</data>
    </node>
    <node id="MANAKUL ET AL., 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Manakul et al. published in 2023, focusing on the SelfCheckGPT method
A reference to the work by Manakul and colleagues published in 2023, related to SelfCheckGPT</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="END USERS">
      <data key="d0">STAKEHOLDER</data>
      <data key="d1">Individuals who validate sensemaking questions and target metrics
Individuals who are the final users of the system or analysis</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">STAKEHOLDER</data>
    </node>
    <node id="TRADE-OFFS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Considerations and compromises involved in building a graph index</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PERFORMANCE">
      <data key="d0">METRIC</data>
      <data key="d1">The effectiveness of RAG systems, which varies across different ranges of question types, data types, and dataset sizes</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="DATA TYPES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Various forms of data used in RAG systems</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DATASET SIZES">
      <data key="d0">METRIC</data>
      <data key="d1">The scale of datasets used in RAG systems, which affects performance</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="EVALUATION">
      <data key="d0">PROCESS</data>
      <data key="d1">The process of assessing the performance of RAG systems</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="CORPORA">
      <data key="d0">DATASET</data>
      <data key="d1">Collections of texts used in the evaluation of RAG systems</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="QUESTION TYPES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Different categories of questions used to evaluate RAG systems</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SELFHECKGPT">
      <data key="d0">METHOD</data>
      <data key="d1">SelfCheckGPT is an approach used to compare fabrication rates in text generation tasks</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="GRAPH-FREE APPROACH">
      <data key="d0">METHOD</data>
      <data key="d1">A method for global summarization of source texts that does not use a graph index</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="COMPUTE BUDGET">
      <data key="d0">RESOURCE</data>
      <data key="d1">The amount of computational resources allocated for a task</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="LIFETIME QUERIES">
      <data key="d0">METRIC</data>
      <data key="d1">The expected number of queries over the lifetime of a dataset</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="RICH TEXT ANNOTATIONS">
      <data key="d0">DATA</data>
      <data key="d1">Annotations that provide detailed information about the text</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="EMBEDDING-BASED MATCHING">
      <data key="d0">METHOD</data>
      <data key="d1">A method that uses embeddings to match user queries with graph annotations</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="HYBRID RAG SCHEMES">
      <data key="d0">METHOD</data>
      <data key="d1">RAG schemes that combine embedding-based matching with other approaches</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="MAP-REDUCE SUMMARIZATION MECHANISMS">
      <data key="d0">METHOD</data>
      <data key="d1">Mechanisms used in map-reduce summarization</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="COMMUNITY HIERARCHY">
      <data key="d0">DATA</data>
      <data key="d1">A hierarchical organization of communities</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="GLOBAL APPROACH TO GRAPH RAG">
      <data key="d0">METHOD</data>
      <data key="d1">A method that combines knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) for global text summarization</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="TOKEN COST">
      <data key="d0">METRIC</data>
      <data key="d1">The cost associated with the number of tokens used in a text generation task</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="PYTHON-BASED IMPLEMENTATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">An implementation of Graph RAG approaches using the Python programming language</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="ALONSO">
      <data key="d0">PERSON</data>
      <data key="d1">A person who contributed to the work mentioned in the acknowledgements</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="FABRICATION RATES">
      <data key="d0">METRIC</data>
      <data key="d1">The rates at which fabrications occur in text generation tasks</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="LIFETIME QUERIES PER DATASET">
      <data key="d0">METRIC</data>
      <data key="d1">The expected number of queries over the lifetime of a specific dataset</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="VALUE FROM GRAPH INDEX">
      <data key="d0">METRIC</data>
      <data key="d1">The benefits or value obtained from using a graph index</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="OTHER GRAPH-RELATED RAG APPROACHES">
      <data key="d0">METHOD</data>
      <data key="d1">Different methods related to retrieval-augmented generation that utilize graph structures</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="LOCAL GRAPH RAG APPROACHES">
      <data key="d0">METHOD</data>
      <data key="d1">Graph RAG approaches that operate in a more localized manner</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="GRAPH ANNOTATIONS">
      <data key="d0">DATA</data>
      <data key="d1">Annotations made on the graph to provide additional information</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="COMMUNITY REPORTS">
      <data key="d0">DATA</data>
      <data key="d1">Reports generated from community summaries</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="ROLL-UP OPERATION">
      <data key="d0">METHOD</data>
      <data key="d1">An operation that aggregates information across multiple levels of a hierarchy</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="DRILL DOWN MECHANISM">
      <data key="d0">METHOD</data>
      <data key="d1">A mechanism that allows for exploring detailed information by following higher-level summaries</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="INFORMATION SCENT">
      <data key="d0">DATA</data>
      <data key="d1">The trail of information that guides users to more detailed data</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="ROOT-LEVEL COMMUNITIES">
      <data key="d0">DATA</data>
      <data key="d1">The top-level communities in a hierarchical structure</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="ENTITY-BASED GRAPH INDEX">
      <data key="d0">DATA</data>
      <data key="d1">A graph index organized around entities</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="OPEN-SOURCE IMPLEMENTATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A publicly available implementation of a technology</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </node>
    <node id="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Alonso Guevara Fern&#225;ndez is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="AMBER HOAK">
      <data key="d0">PERSON</data>
      <data key="d1">Amber Hoak is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d0">PERSON</data>
      <data key="d1">Andr&#233;s Morales Esquivel is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="BEN CUTLER">
      <data key="d0">PERSON</data>
      <data key="d1">Ben Cutler is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="BILLIE RINALDI">
      <data key="d0">PERSON</data>
      <data key="d1">Billie Rinaldi is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="CHRIS SANCHEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Sanchez is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="CHRIS TREVINO">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Trevino is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="CHRISTINE CAGGIANO">
      <data key="d0">PERSON</data>
      <data key="d1">Christine Caggiano is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="DAVID TITTSWORTH">
      <data key="d0">PERSON</data>
      <data key="d1">David Tittsworth is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="DAYENNE DE SOUZA">
      <data key="d0">PERSON</data>
      <data key="d1">Dayenne de Souza is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="DOUGLAS ORBAKER">
      <data key="d0">PERSON</data>
      <data key="d1">Douglas Orbaker is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="ED CLARK">
      <data key="d0">PERSON</data>
      <data key="d1">Ed Clark is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="GABRIEL NIEVES-PONCE">
      <data key="d0">PERSON</data>
      <data key="d1">Gabriel Nieves-Ponce is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="GAUDY BLANCO MENESES">
      <data key="d0">PERSON</data>
      <data key="d1">Gaudy Blanco Meneses is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="KATE LYTVYNETS">
      <data key="d0">PERSON</data>
      <data key="d1">Kate Lytvynets is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="KATY SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Katy Smith is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="M&#211;NICA CARVAJAL">
      <data key="d0">PERSON</data>
      <data key="d1">M&#243;nica Carvajal is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="NATHAN EVANS">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Evans is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="RICHARD ORTEGA">
      <data key="d0">PERSON</data>
      <data key="d1">Richard Ortega is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="RODRIGO RACANICCI">
      <data key="d0">PERSON</data>
      <data key="d1">Rodrigo Racanicci is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="SARAH SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Smith is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="SHANE SOLOMON">
      <data key="d0">PERSON</data>
      <data key="d1">Shane Solomon is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="GPT-4 TECHNICAL REPORT">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A technical report on GPT-4 published as an arXiv preprint</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d0">METHOD</data>
      <data key="d1">A method for zero-shot knowledge graph question answering described in an arXiv preprint</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="QUERY TOOLS TO CAUSAL ARCHITECTS">
      <data key="d0">METHOD</data>
      <data key="d1">A method for harnessing large language models for advanced causal discovery from data</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="QUERY FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A method incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="J. ACHIAM">
      <data key="d0">PERSON</data>
      <data key="d1">J. Achiam is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="S. ADLER">
      <data key="d0">PERSON</data>
      <data key="d1">S. Adler is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="S. AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">S. Agarwal is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="L. AHMAD">
      <data key="d0">PERSON</data>
      <data key="d1">L. Ahmad is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="I. AKKAYA">
      <data key="d0">PERSON</data>
      <data key="d1">I. Akkaya is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="F. L. ALEMAN">
      <data key="d0">PERSON</data>
      <data key="d1">F. L. Aleman is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="D. ALMEIDA">
      <data key="d0">PERSON</data>
      <data key="d1">D. Almeida is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="J. ALTENSCHMIDT">
      <data key="d0">PERSON</data>
      <data key="d1">J. Altenschmidt is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="S. ALTMAN">
      <data key="d0">PERSON</data>
      <data key="d1">S. Altman is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="S. ANADKAT">
      <data key="d0">PERSON</data>
      <data key="d1">S. Anadkat is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="R. ANIL">
      <data key="d0">PERSON</data>
      <data key="d1">R. Anil is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="S. BORGEAUD">
      <data key="d0">PERSON</data>
      <data key="d1">S. Borgeaud is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="Y. WU">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Wu is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="J.-B. ALAYRAC">
      <data key="d0">PERSON</data>
      <data key="d1">J.-B. Alayrac is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="J. YU">
      <data key="d0">PERSON</data>
      <data key="d1">J. Yu is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="R. SORICUT">
      <data key="d0">PERSON</data>
      <data key="d1">R. Soricut is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="J. SCHALKWYK">
      <data key="d0">PERSON</data>
      <data key="d1">J. Schalkwyk is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="A. M. DAI">
      <data key="d0">PERSON</data>
      <data key="d1">A. M. Dai is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="A. HAUTH">
      <data key="d0">PERSON</data>
      <data key="d1">A. Hauth is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="J. BAEK">
      <data key="d0">PERSON</data>
      <data key="d1">J. Baek is an author of the paper on knowledge-augmented language model prompting</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="A. F. AJI">
      <data key="d0">PERSON</data>
      <data key="d1">A. F. Aji is an author of the paper on knowledge-augmented language model prompting</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="A. SAFFARI">
      <data key="d0">PERSON</data>
      <data key="d1">A. Saffari is an author of the paper on knowledge-augmented language model prompting</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="T. BAN">
      <data key="d0">PERSON</data>
      <data key="d1">T. Ban is an author of the paper on query tools to causal architects</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="L. CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">L. Chen is an author of the paper on query tools to causal architects</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="X. WANG">
      <data key="d0">PERSON</data>
      <data key="d1">X. Wang is an author of the paper on query tools to causal architects</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="H. CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">H. Chen is an author of the paper on query tools to causal architects</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="T. BAUMEL">
      <data key="d0">PERSON</data>
      <data key="d1">T. Baumel is an author of the paper on query focused abstractive summarization</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="M. EYAL">
      <data key="d0">PERSON</data>
      <data key="d1">M. Eyal is an author of the paper on query focused abstractive summarization</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="M. ELHADAD">
      <data key="d0">PERSON</data>
      <data key="d1">M. Elhadad is an author of the paper on query focused abstractive summarization</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="ARXIV:2303.08774">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv preprint identifier for the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="ARXIV:2312.11805">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv preprint identifier for the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="ARXIV:2306.04136">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv preprint identifier for the paper on knowledge-augmented language model prompting</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="ARXIV:180">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv preprint identifier for the paper on query focused abstractive summarization</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
    </node>
    <node id="BAUMEL, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Baumel, T. is an author of the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="EYAL, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Eyal, M. is an author of the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="ELHADAD, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Elhadad, M. is an author of the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="BLONDEL, V. D.">
      <data key="d0">PERSON</data>
      <data key="d1">Blondel, V. D. is an author of the paper "Fast unfolding of communities in large networks"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="GUILLAUME, J.-L.">
      <data key="d0">PERSON</data>
      <data key="d1">Guillaume, J.-L. is an author of the paper "Fast unfolding of communities in large networks"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="LAMBIOTTE, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Lambiotte, R. is an author of the paper "Fast unfolding of communities in large networks"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="LEFEBVRE, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Lefebvre, E. is an author of the paper "Fast unfolding of communities in large networks"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Fast unfolding of communities in large networks" was published</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="BROWN, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Brown, T. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="MANN, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Mann, B. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="RYDER, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Ryder, N. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="SUBBIAH, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Subbiah, M. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="KAPLAN, J. D.">
      <data key="d0">PERSON</data>
      <data key="d1">Kaplan, J. D. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="DHARIWAL, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Dhariwal, P. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="NEELAKANTAN, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Neelakantan, A. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="SHYAM, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Shyam, P. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="SASTRY, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Sastry, G. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="ASKELL, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Askell, A. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The conference where the paper "Language models are few-shot learners" was presented
The conference where the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks" was presented
The journal where the paper "Judging llm-as-a-judge with mt-bench and chatbot arena" was published</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5,6cd82819982879bd164547d2773ba5c7,b1bbda43309e8e0e2175ea034aa88e13</data>
    </node>
    <node id="CHENG, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Cheng, X. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="LUO, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Luo, D. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="CHEN, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Chen, X. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="LIU, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Liu, L. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="ZHAO, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhao, D. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"Zhao, D. is an author of the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YAN, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Yan, R. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="DANG, H. T.">
      <data key="d0">PERSON</data>
      <data key="d1">Dang, H. T. is an author of the paper "Duc 2005: Evaluation of question-focused summarization systems"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="PROCEEDINGS OF THE WORKSHOP ON TASK-FOCUSED SUMMARIZATION AND QUESTION ANSWERING">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The conference where the paper "Duc 2005: Evaluation of question-focused summarization systems" was presented</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="ES, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Es, S. is an author of the paper "Ragas: Automated evaluation of retrieval augmented generation"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="JAMES, J.">
      <data key="d0">PERSON</data>
      <data key="d1">James, J. is an author of the paper "Ragas: Automated evaluation of retrieval augmented generation"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="ESPINOSA-ANKE, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Espinosa-Anke, L. is an author of the paper "Ragas: Automated evaluation of retrieval augmented generation"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="SCHOCKAERT, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Schockaert, S. is an author of the paper "Ragas: Automated evaluation of retrieval augmented generation"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="FENG, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Feng, Z. is an author of the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="FENG, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Feng, X. is an author of the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="YANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Yang, M. is an author of the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="QIN, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Qin, B. is an author of the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="FORTUNATO, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Fortunato, S. is an author of the paper "Community detection in graphs"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="PHYSICS REPORTS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Community detection in graphs" was published</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="GAO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Gao, Y. is an author of the paper "Retrieval-augmented generation"
Gao, Y. is an author of the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="XIONG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Xiong, Y. is an author of the paper "Retrieval-augmented generation"
Xiong, Y. is an author of the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="GAO, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Gao, X. is an author of the paper "Retrieval-augmented generation"
Gao, X. is an author of the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="JIA, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Jia, K. is an author of the paper "Retrieval-augmented generation"
Jia, K. is an author of the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="PAN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Pan, J. is an author of the paper "Retrieval-augmented generation"
Pan, J. is an author of the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="BI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Bi, Y. is an author of the paper "Retrieval-augmented generation"
Bi, Y. is an author of the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="DAI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Dai, Y. is an author of the paper "Retrieval-augmented generation"
Dai, Y. is an author of the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="SUN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Sun, J. is an author of the paper "Retrieval-augmented generation"
Sun, J. is an author of the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="WANG, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, H. is an author of the paper "Retrieval-augmented generation"
Wang, H. is an author of the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="ARXIV:1801.07704">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv identifier for the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="ARXIV:2309.15217">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv identifier for the paper "Ragas: Automated evaluation of retrieval augmented generation"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="ARXIV:2310.05149">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv identifier for the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
    </node>
    <node id="GOODWIN, T. R.">
      <data key="d0">PERSON</data>
      <data key="d1">Goodwin, T. R. is an author of the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="SAVERY, M. E.">
      <data key="d0">PERSON</data>
      <data key="d1">Savery, M. E. is an author of the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="DEMNER-FUSHMAN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Demner-Fushman, D. is an author of the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="COLING">
      <data key="d0">CONFERENCE</data>
      <data key="d1">COLING (International Conference on Computational Linguistics) is the conference where the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization" was presented</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="HE, X.">
      <data key="d0">PERSON</data>
      <data key="d1">He, X. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="TIAN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Tian, Y. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="SUN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Sun, Y. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="CHAWLA, N. V.">
      <data key="d0">PERSON</data>
      <data key="d1">Chawla, N. V. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="LAURENT, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Laurent, T. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="LECUN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">LeCun, Y. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="BRESSON, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Bresson, X. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="HOOI, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Hooi, B. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="JACOMY, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Jacomy, M. is an author of the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="VENTURINI, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Venturini, T. is an author of the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="HEYMANN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Heymann, S. is an author of the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="BASTIAN, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Bastian, M. is an author of the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="PLOS ONE">
      <data key="d0">PUBLICATION</data>
      <data key="d1">PLOS ONE is the journal where the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software" was published</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="JIN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Jin, D. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="YU, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Yu, Z. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="JIAO, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Jiao, P. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="PAN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Pan, S. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="HE, D.">
      <data key="d0">PERSON</data>
      <data key="d1">He, D. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="WU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Wu, J. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="PHILIP, S. Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Philip, S. Y. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="ZHANG, W.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, W. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING">
      <data key="d0">PUBLICATION</data>
      <data key="d1">IEEE Transactions on Knowledge and Data Engineering is the journal where the paper "A survey of community detection approaches: From statistical modeling to deep learning" was published</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="KANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Kang, M. is an author of the paper "Knowledge graph-augmented language models for knowledge-grounded dialogue generation"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="KWAK, J. M.">
      <data key="d0">PERSON</data>
      <data key="d1">Kwak, J. M. is an author of the paper "Knowledge graph-augmented language models for knowledge-grounded dialogue generation"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="BAEK, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Baek, J. is an author of the paper "Knowledge graph-augmented language models for knowledge-grounded dialogue generation"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="HWANG, S. J.">
      <data key="d0">PERSON</data>
      <data key="d1">Hwang, S. J. is an author of the paper "Knowledge graph-augmented language models for knowledge-grounded dialogue generation"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
    </node>
    <node id="KHATTAB, O.">
      <data key="d0">PERSON</data>
      <data key="d1">Khattab, O. is an author of the paper mentioned in the text
Khattab, O. is an author of the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="SANTHANAM, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Santhanam, K. is an author of the paper mentioned in the text
Santhanam, K. is an author of the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="LI, X. L.">
      <data key="d0">PERSON</data>
      <data key="d1">Li, X. L. is an author of the paper mentioned in the text
Li, X. L. is an author of the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="HALL, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Hall, D. is an author of the paper mentioned in the text
Hall, D. is an author of the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="LIANG, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Liang, P. is an author of the paper mentioned in the text
Liang, P. is an author of the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"
Liang, P. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,6cd82819982879bd164547d2773ba5c7,71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="POTTS, C.">
      <data key="d0">PERSON</data>
      <data key="d1">Potts, C. is an author of the paper mentioned in the text
Potts, C. is an author of the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="ZAHARIA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Zaharia, M. is an author of the paper mentioned in the text
Zaharia, M. is an author of the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="KIM, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Kim, G. is an author of the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="KIM, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Kim, S. is an author of the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="JEON, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Jeon, B. is an author of the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="PARK, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Park, J. is an author of the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="KANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Kang, J. is an author of the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="KLEIN, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Klein, G. is an author of the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="MOON, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Moon, B. is an author of the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="HOFFMAN, R. R.">
      <data key="d0">PERSON</data>
      <data key="d1">Hoffman, R. R. is an author of the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="IEEE INTELLIGENT SYSTEMS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model" were published</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="KOESTEN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Koesten, L. is an author of the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="GREGORY, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Gregory, K. is an author of the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="GROTH, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Groth, P. is an author of the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="SIMPERL, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Simperl, E. is an author of the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Talking datasets&#8211;understanding data sensemaking behaviours" was published</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="KURATOV, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Kuratov, Y. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="BULATOV, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Bulatov, A. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="ANOKHIN, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Anokhin, P. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="SOROKIN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Sorokin, D. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="SOROKIN, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Sorokin, A. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="BURTSEV, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Burtsev, M. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="LANGCHAIN GRAPHS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Langchain graphs is a technology developed by LangChain</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="LASKAR, M. T. R.">
      <data key="d0">PERSON</data>
      <data key="d1">Laskar, M. T. R. is an author of the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models"
Laskar, M. T. R. is an author of the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="HOQUE, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Hoque, E. is an author of the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models"
Hoque, E. is an author of the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="HUANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Huang, J. is an author of the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="ADVANCES IN ARTIFICIAL INTELLIGENCE">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The conference where the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models" was presented</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="ARXIV PREPRINT">
      <data key="d0">PUBLICATION</data>
      <data key="d1">arXiv preprint refers to a preprint of a paper that is available on the arXiv repository</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
    </node>
    <node id="33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE">
      <data key="d0">EVENT</data>
      <data key="d1">The 33rd Canadian Conference on Artificial Intelligence, held in Ottawa, ON, Canada, from May 13&#8211;15, 2020</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="CANADIAN AI 2020">
      <data key="d0">EVENT</data>
      <data key="d1">The 2020 edition of the Canadian Conference on Artificial Intelligence</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="SPRINGER">
      <data key="d0">PUBLISHER</data>
      <data key="d1">Springer is the publisher of the proceedings of the 33rd Canadian Conference on Artificial Intelligence</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="HUANG, J. X.">
      <data key="d0">PERSON</data>
      <data key="d1">Huang, J. X. is an author of the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="COMPUTATIONAL LINGUISTICS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" was published</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="LEWIS, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis, P. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="PEREZ, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Perez, E. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="PIKTUS, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Piktus, A. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="PETRONI, F.">
      <data key="d0">PERSON</data>
      <data key="d1">Petroni, F. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"Petroni, F. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KARPUKHIN, V.">
      <data key="d0">PERSON</data>
      <data key="d1">Karpukhin, V. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="GOYAL, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Goyal, N. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="K&#220;TTLER, H.">
      <data key="d0">PERSON</data>
      <data key="d1">K&#252;ttler, H. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="LEWIS, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis, M. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="YIH, W.-T.">
      <data key="d0">PERSON</data>
      <data key="d1">Yih, W.-T. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="ROCKT&#196;SCHEL, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Rockt&#228;schel, T. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="LIU, N. F.">
      <data key="d0">PERSON</data>
      <data key="d1">Liu, N. F. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="LIN, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Lin, K. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="HEWITT, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Hewitt, J. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="PARANJAPE, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Paranjape, A. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="BEVILACQUA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Bevilacqua, M. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="LIU, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Liu, Y. is an author of the paper "Hierarchical transformers for multi-document summarization"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="LAPATA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Lapata, M. is an author of the paper "Hierarchical transformers for multi-document summarization"
Lapata, M. is an author of the paper "Text summarization with latent queries"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="LLAMAINDEX KNOWLEDGE GRAPH INDEX">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LlamaIndex Knowledge Graph Index is a technology developed by LlamaIndex</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="MANAKUL, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Manakul, P. is an author of the paper "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="LIUSIE, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Liusie, A. is an author of the paper "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="GALES, M. J.">
      <data key="d0">PERSON</data>
      <data key="d1">Gales, M. J. is an author of the paper "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="MAO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Mao, Y. is an author of the paper "Generation-augmented retrieval for open-domain question answering"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="HE, P.">
      <data key="d0">PERSON</data>
      <data key="d1">He, P. is an author of the paper "Generation-augmented retrieval for open-domain question answering"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="LIU, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Liu, X. is an author of the paper "Generation-augmented retrieval for open-domain question answering"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="SHEN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Shen, Y. is an author of the paper "Generation-augmented retrieval for open-domain question answering"
Shen, Y. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </node>
    <node id="GAO, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Gao, J. is an author of the paper "Generation-augmented retrieval for open-domain question answering"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="HAN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Han, J. is an author of the paper "Generation-augmented retrieval for open-domain question answering"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
    </node>
    <node id="CHEN, W.">
      <data key="d0">PERSON</data>
      <data key="d1">Chen, W. is an author of the paper "Generation-augmented retrieval for open-domain question answering"
Chen, W. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"
Chen, W. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b,8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="MARTIN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Martin, S. is an author of the paper "Openord: An open-source toolbox for large graph"
Martin, S. is an author of the paper "Openord: An open-source toolbox for large graph layout"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </node>
    <node id="BROWN, W. M.">
      <data key="d0">PERSON</data>
      <data key="d1">Brown, W. M. is an author of the paper "Openord: An open-source toolbox for large graph"
Brown, W. M. is an author of the paper "Openord: An open-source toolbox for large graph layout"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </node>
    <node id="KLAVANS, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Klavans, R. is an author of the paper "Openord: An open-source toolbox for large graph"
Klavans, R. is an author of the paper "Openord: An open-source toolbox for large graph layout"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </node>
    <node id="BOYACK, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Boyack, K. is an author of the paper "Openord: An open-source toolbox for large graph"
Boyack, K. is an author of the paper "Openord: An open-source toolbox for large graph layout"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </node>
    <node id="SPIE CONFERENCE ON VISUALIZATION AND DATA ANALYSIS (VDA)">
      <data key="d0">EVENT</data>
      <data key="d1">The conference where the paper "Openord: An open-source toolbox for large graph layout" was presented</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="GPT-4">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4 is a large language model used in Microsoft's study on scientific discovery</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="PROJECT NALLM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Project NaLLM is a project developed by Neo4J</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="NEWMAN, M. E.">
      <data key="d0">PERSON</data>
      <data key="d1">Newman, M. E. is the author of the paper "Modularity and community structure in networks"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Modularity and community structure in networks" was published</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="RAM, O.">
      <data key="d0">PERSON</data>
      <data key="d1">Ram, O. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEVINE, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Levine, Y. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DALMEDIGOS, I.">
      <data key="d0">PERSON</data>
      <data key="d1">Dalmedigos, I. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MUHLGAY, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Muhlgay, D. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHASHUA, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Shashua, A. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEYTON-BROWN, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Leyton-Brown, K. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHOHAM, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Shoham, Y. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "In-context retrieval-augmented language models" was published</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="RANADE, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Ranade, P. is an author of the paper "Fabula: Intelligence report generation using retrieval-augmented narrative construction"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOSHI, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Joshi, A. is an author of the paper "Fabula: Intelligence report generation using retrieval-augmented narrative construction"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SARTHI, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Sarthi, P. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ABDULLAH, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Abdullah, S. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TULI, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Tuli, A. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KHANNA, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Khanna, S. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GOLDIE, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Goldie, A. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MANNING, C. D.">
      <data key="d0">PERSON</data>
      <data key="d1">Manning, C. D. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"
Manning, C. D. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SCOTT, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Scott, K. is associated with "Behind the Tech"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHAO, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Shao, Z. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GONG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Gong, Y. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HUANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Huang, M. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"
Huang, M. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DUAN, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Duan, N. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"
Duan, N. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SU, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Su, D. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="XU, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Xu, Y. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"
Xu, Y. is an author of the paper "Text summarization with latent queries"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="YU, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Yu, T. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="SIDDIQUE, F. B.">
      <data key="d0">PERSON</data>
      <data key="d1">Siddique, F. B. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="BAREZI, E. J.">
      <data key="d0">PERSON</data>
      <data key="d1">Barezi, E. J. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="FUNG, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Fung, P. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="TANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Tang, Y. is an author of the paper "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="YANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Yang, Y. is an author of the paper "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="TOUVRON, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Touvron, H. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="MARTIN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Martin, L. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="STONE, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Stone, K. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="ALBERT, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Albert, P. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="ALMAHAIRI, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Almahairi, A. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="BABAEI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Babaei, Y. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="BASHLYKOV, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Bashlykov, N. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="BATRA, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Batra, S. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="BHARGAVA, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Bhargava, P. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="BHOSALE, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Bhosale, S. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="TRAAG, V. A.">
      <data key="d0">PERSON</data>
      <data key="d1">Traag, V. A. is an author of the paper "From Louvain to Leiden: guaranteeing well-connected communities"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="WALTMAN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Waltman, L. is an author of the paper "From Louvain to Leiden: guaranteeing well-connected communities"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="VAN ECK, N. J.">
      <data key="d0">PERSON</data>
      <data key="d1">Van Eck, N. J. is an author of the paper "From Louvain to Leiden: guaranteeing well-connected communities"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="SCIENTIFIC REPORTS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">Scientific Reports is the journal where the paper "From Louvain to Leiden: guaranteeing well-connected communities" was published</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="TRAJANOSKA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Trajanoska, M. is an author of the paper "Enhancing knowledge graph construction using large language models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="STOJANOV, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Stojanov, R. is an author of the paper "Enhancing knowledge graph construction using large language models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="TRAJANOV, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Trajanov, D. is an author of the paper "Enhancing knowledge graph construction using large language models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="TRIVEDI, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Trivedi, H. is an author of the paper "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="BALASUBRAMANIAN, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Balasubramanian, N. is an author of the paper "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="KHOT, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Khot, T. is an author of the paper "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="SABHARWAL, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Sabharwal, A. is an author of the paper "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="WANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="LIANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Liang, Y. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="MENG, F.">
      <data key="d0">PERSON</data>
      <data key="d1">Meng, F. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="SUN, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Sun, Z. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="SHI, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Shi, H. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="LI, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Li, Z. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Li, Z. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Li, Z. is an author of the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="XU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Xu, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Xu, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="QU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Qu, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Qu, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="ZHOU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhou, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Zhou, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="WANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, S. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Wang, S. is an author of the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="KHRAMTSOVA">
      <data key="d0">PERSON</data>
      <data key="d1">Khramtsova is an author mentioned in the text</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </node>
    <node id="H.">
      <data key="d0">PERSON</data>
      <data key="d1">H. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="KHRAMTSOVA, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Khramtsova, E. is an author of the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="ZHUANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuang, S. is an author of the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"
Zhuang, S. is an author of the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="ZUCCON, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Zuccon, G. is an author of the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="WANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, Y. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="LIPKA, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Lipka, N. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="ROSSI, R. A.">
      <data key="d0">PERSON</data>
      <data key="d1">Rossi, R. A. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="SIU, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Siu, A. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="ZHANG, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, R. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="DERR, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Derr, T. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="YANG, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Yang, Z. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="QI, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Qi, P. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="ZHANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, S. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="BENGIO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Bengio, Y. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="COHEN, W. W.">
      <data key="d0">PERSON</data>
      <data key="d1">Cohen, W. W. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="SALAKHUTDINOV, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Salakhutdinov, R. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="EMNLP">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The conference where the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering" was presented</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="YAO, J.-G.">
      <data key="d0">PERSON</data>
      <data key="d1">Yao, J.-g. is an author of the paper "Recent advances in document summarization"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="WAN, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Wan, X. is an author of the paper "Recent advances in document summarization"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="XIAO, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Xiao, J. is an author of the paper "Recent advances in document summarization"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="KNOWLEDGE AND INFORMATION SYSTEMS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Recent advances in document summarization" was published</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
    </node>
    <node id="YAO, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Yao, L. is an author of the paper "Causal graph discovery with retrieval-augmented generation based large language models"Yao, L. is an author of the paper "Exploring large language models for knowledge graph completion"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PENG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Peng, J. is an author of the paper "Exploring large language models for knowledge graph completion"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAO, C.">
      <data key="d0">PERSON</data>
      <data key="d1">Mao, C. is an author of the paper "Exploring large language models for knowledge graph completion"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LUO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Luo, Y. is an author of the paper "Exploring large language models for knowledge graph completion"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, J. is an author of the paper "Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, Y. is an author of the paper "Causal graph discovery with retrieval-augmented generation based large language models"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GAN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Gan, Y. is an author of the paper "Causal graph discovery with retrieval-augmented generation based large language models"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WANG, C.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, C. is an author of the paper "Causal graph discovery with retrieval-augmented generation based large language models"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHENG, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Zheng, L. is an author of the paper "Exploring large language models for knowledge graph completion"
Zheng, L. is an author of the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHIANG, W.-L.">
      <data key="d0">PERSON</data>
      <data key="d1">Chiang, W.-L. is an author of the paper "Exploring large language models for knowledge graph completion"
Chiang, W.-L. is an author of the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHENG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Sheng, Y. is an author of the paper "Exploring large language models for knowledge graph completion"
Sheng, Y. is an author of the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WU, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Wu, Z. is an author of the paper "Exploring large language models for knowledge graph completion"
Wu, Z. is an author of the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHUANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuang, Y. is an author of the paper "Exploring large language models for knowledge graph completion"
Zhuang, Y. is an author of the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LIN, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Lin, Z. is an author of the paper "Exploring large language models for knowledge graph completion"
Lin, Z. is an author of the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LI, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Li, D. is an author of the paper "Exploring large language models for knowledge graph completion"
Li, D. is an author of the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XING, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Xing, E. is an author of the paper "Exploring large language models for knowledge graph completion"
Xing, E. is an author of the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHATBOT ARENA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Chatbot Arena is a platform or tool used in the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13</data>
    </node>
    <edge source="DARREN EDGE" target="HA TRINH">
      <data key="d4">1.0</data>
      <data key="d5">Darren Edge and Ha Trinh co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="DARREN EDGE" target="NEWMAN CHENG">
      <data key="d4">1.0</data>
      <data key="d5">Darren Edge and Newman Cheng co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="DARREN EDGE" target="JOSHUA BRADLEY">
      <data key="d4">1.0</data>
      <data key="d5">Darren Edge and Joshua Bradley co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="DARREN EDGE" target="ALEX CHAO">
      <data key="d4">1.0</data>
      <data key="d5">Darren Edge and Alex Chao co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="DARREN EDGE" target="APURVA MODY">
      <data key="d4">1.0</data>
      <data key="d5">Darren Edge and Apurva Mody co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="DARREN EDGE" target="STEVEN TRUITT">
      <data key="d4">1.0</data>
      <data key="d5">Darren Edge and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="DARREN EDGE" target="JONATHAN LARSON">
      <data key="d4">1.0</data>
      <data key="d5">Darren Edge and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="DARREN EDGE" target="MICROSOFT RESEARCH">
      <data key="d4">1.0</data>
      <data key="d5">Darren Edge is affiliated with Microsoft Research</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="HA TRINH" target="NEWMAN CHENG">
      <data key="d4">1.0</data>
      <data key="d5">Ha Trinh and Newman Cheng co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="HA TRINH" target="JOSHUA BRADLEY">
      <data key="d4">1.0</data>
      <data key="d5">Ha Trinh and Joshua Bradley co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="HA TRINH" target="ALEX CHAO">
      <data key="d4">1.0</data>
      <data key="d5">Ha Trinh and Alex Chao co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="HA TRINH" target="APURVA MODY">
      <data key="d4">1.0</data>
      <data key="d5">Ha Trinh and Apurva Mody co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="HA TRINH" target="STEVEN TRUITT">
      <data key="d4">1.0</data>
      <data key="d5">Ha Trinh and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="HA TRINH" target="JONATHAN LARSON">
      <data key="d4">1.0</data>
      <data key="d5">Ha Trinh and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="HA TRINH" target="MICROSOFT RESEARCH">
      <data key="d4">1.0</data>
      <data key="d5">Ha Trinh is affiliated with Microsoft Research</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="NEWMAN CHENG" target="JOSHUA BRADLEY">
      <data key="d4">1.0</data>
      <data key="d5">Newman Cheng and Joshua Bradley co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="NEWMAN CHENG" target="ALEX CHAO">
      <data key="d4">1.0</data>
      <data key="d5">Newman Cheng and Alex Chao co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="NEWMAN CHENG" target="APURVA MODY">
      <data key="d4">1.0</data>
      <data key="d5">Newman Cheng and Apurva Mody co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="NEWMAN CHENG" target="STEVEN TRUITT">
      <data key="d4">1.0</data>
      <data key="d5">Newman Cheng and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="NEWMAN CHENG" target="JONATHAN LARSON">
      <data key="d4">1.0</data>
      <data key="d5">Newman Cheng and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="NEWMAN CHENG" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d4">1.0</data>
      <data key="d5">Newman Cheng is affiliated with Microsoft Strategic Missions and Technologies</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="ALEX CHAO">
      <data key="d4">1.0</data>
      <data key="d5">Joshua Bradley and Alex Chao co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="APURVA MODY">
      <data key="d4">1.0</data>
      <data key="d5">Joshua Bradley and Apurva Mody co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="STEVEN TRUITT">
      <data key="d4">1.0</data>
      <data key="d5">Joshua Bradley and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="JONATHAN LARSON">
      <data key="d4">1.0</data>
      <data key="d5">Joshua Bradley and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d4">1.0</data>
      <data key="d5">Joshua Bradley is affiliated with Microsoft Strategic Missions and Technologies</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="ALEX CHAO" target="APURVA MODY">
      <data key="d4">1.0</data>
      <data key="d5">Alex Chao and Apurva Mody co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="ALEX CHAO" target="STEVEN TRUITT">
      <data key="d4">1.0</data>
      <data key="d5">Alex Chao and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="ALEX CHAO" target="JONATHAN LARSON">
      <data key="d4">1.0</data>
      <data key="d5">Alex Chao and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="ALEX CHAO" target="MICROSOFT OFFICE OF THE CTO">
      <data key="d4">1.0</data>
      <data key="d5">Alex Chao is affiliated with Microsoft Office of the CTO</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="APURVA MODY" target="STEVEN TRUITT">
      <data key="d4">1.0</data>
      <data key="d5">Apurva Mody and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="APURVA MODY" target="JONATHAN LARSON">
      <data key="d4">1.0</data>
      <data key="d5">Apurva Mody and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="APURVA MODY" target="MICROSOFT OFFICE OF THE CTO">
      <data key="d4">1.0</data>
      <data key="d5">Apurva Mody is affiliated with Microsoft Office of the CTO</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="STEVEN TRUITT" target="JONATHAN LARSON">
      <data key="d4">1.0</data>
      <data key="d5">Steven Truitt and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="STEVEN TRUITT" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d4">1.0</data>
      <data key="d5">Steven Truitt is affiliated with Microsoft Strategic Missions and Technologies</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="JONATHAN LARSON" target="MICROSOFT RESEARCH">
      <data key="d4">1.0</data>
      <data key="d5">Jonathan Larson is affiliated with Microsoft Research</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="RAG" target="LLM">
      <data key="d4">4.0</data>
      <data key="d5">RAG uses LLMs to retrieve relevant information from external knowledge sources
LLM uses RAG to generate and assess text
RAG is used to augment the capabilities of LLMs</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="RAG" target="GRAPH RAG">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG combines the strengths of RAG with graph-based text indexing
Graph RAG is a specific approach to RAG
Graph RAG is a specific implementation of RAG
Graph RAG is an implementation of RAG
Graph RAG is a method that uses the natural modularity of graphs to partition data for global summarization</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,92e93fc6449756c0a60200636b297f65,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="RAG" target="QUERY-FOCUSED SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Query-Focused Summarization is a task that RAG fails to address effectively</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="RAG" target="EXTERNAL KNOWLEDGE SOURCE">
      <data key="d4">1.0</data>
      <data key="d5">RAG retrieves relevant information from an external knowledge source</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="RAG" target="NAIVE RAG">
      <data key="d4">1.0</data>
      <data key="d5">Naive RAG is a specific implementation of RAG</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="RAG" target="RAM ET AL., 2023">
      <data key="d4">1.0</data>
      <data key="d5">Ram et al., 2023 discusses RAG approaches</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="RAG" target="NA&#207;VE RAG">
      <data key="d4">2.0</data>
      <data key="d5">Na&#239;ve RAG is a basic form of RAG</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="RAG" target="MODULAR RAG">
      <data key="d4">2.0</data>
      <data key="d5">Modular RAG is an advanced form of RAG</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="RAG" target="LLMS">
      <data key="d4">2.0</data>
      <data key="d5">LLMs are used in various RAG tasks such as knowledge graph creation and completion</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="TRAJANOSKA ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Trajanoska et al. discusses using LLMs for knowledge graph creation, which is a direction in RAG</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="YAO ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Yao et al. discusses using LLMs for knowledge graph completion, which is a direction in RAG</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="BAN ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Ban et al. discusses the extraction of causal graphs, which is a direction in RAG</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="ZHANG ET AL., 2024">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Zhang et al. discusses the extraction of causal graphs, which is a direction in RAG</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="GAO ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Gao et al. discusses advanced RAG where the index is a knowledge graph</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="KAPING">
      <data key="d4">2.0</data>
      <data key="d5">KAPING is a method where the index is a knowledge graph, which is a direction in RAG</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="G-RETRIEVER">
      <data key="d4">2.0</data>
      <data key="d5">G-Retriever is a method where subsets of the graph structure are the objects of enquiry, which is a direction in RAG</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="GRAPH-TOOLFORMER">
      <data key="d4">2.0</data>
      <data key="d5">Graph-ToolFormer is a method where derived graph metrics are the objects of enquiry, which is a direction in RAG</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="SURGE">
      <data key="d4">2.0</data>
      <data key="d5">SURGE is a method where narrative outputs are strongly grounded in the facts of retrieved subgraphs, which is a direction in RAG</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="FABULA">
      <data key="d4">2.0</data>
      <data key="d5">FABULA is a method where retrieved event-plot subgraphs are serialized using narrative templates, which is a direction in RAG</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="WANG ET AL., 2023B">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Wang et al. discusses a system that supports both creation and traversal of text-relationship graphs for multi-hop question answering, which is a direction in RAG</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="SENSEMAKING QUESTIONS">
      <data key="d4">2.0</data>
      <data key="d5">Sensemaking questions are used to evaluate the performance of RAG systems</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="TOKENS">
      <data key="d4">2.0</data>
      <data key="d5">The evaluation of RAG systems focuses on corpora in the region of 1 million tokens</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="TRADE-OFFS">
      <data key="d4">2.0</data>
      <data key="d5">Trade-offs are considerations involved in building a graph index for RAG systems</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="GRAPH INDEX">
      <data key="d4">2.0</data>
      <data key="d5">A graph index is a data structure used in RAG systems to organize and retrieve information</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="PERFORMANCE">
      <data key="d4">2.0</data>
      <data key="d5">Performance of RAG systems varies across different ranges of question types, data types, and dataset sizes</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="DATA TYPES">
      <data key="d4">2.0</data>
      <data key="d5">Different data types are used in RAG systems</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="DATASET SIZES">
      <data key="d4">2.0</data>
      <data key="d5">Dataset sizes affect the performance of RAG systems</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="EVALUATION">
      <data key="d4">2.0</data>
      <data key="d5">Evaluation is the process of assessing the performance of RAG systems</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="CORPORA">
      <data key="d4">2.0</data>
      <data key="d5">Corpora are collections of texts used in the evaluation of RAG systems</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="QUESTION TYPES">
      <data key="d4">2.0</data>
      <data key="d5">Different question types are used to evaluate RAG systems</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="RAG" target="TARGET METRICS">
      <data key="d4">2.0</data>
      <data key="d5">Target metrics are specific measures used to evaluate the performance of RAG systems</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="LLM" target="GRAPH RAG">
      <data key="d4">4.0</data>
      <data key="d5">Graph RAG uses LLMs to build a graph-based text index
LLM is used in the Graph RAG approach to generate summaries and answer queries
LLM uses Graph RAG to provide a comprehensive overview of public figures in the entertainment industry
LLMs are used in Graph RAG to analyze and generate text based on retrieved information and queries</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,6f33a085ff3304e5994f7fbb86c881a4,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="LLM" target="TEXT CHUNKS">
      <data key="d4">1.0</data>
      <data key="d5">Text chunks are processed using LLM to extract elements of a graph index</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="GRAPH INDEX">
      <data key="d4">1.0</data>
      <data key="d5">LLM is used to extract elements of a graph index from text chunks</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="FEW-SHOT EXAMPLES">
      <data key="d4">2.0</data>
      <data key="d5">Few-shot examples are provided to the LLM for in-context learning to tailor the extraction prompt
Few-shot examples are used to improve the performance of the LLM in specialized domains</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="NAMED ENTITIES">
      <data key="d4">1.0</data>
      <data key="d5">LLM extracts named entities from text chunks</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="KURATOV ET AL., 2024">
      <data key="d4">1.0</data>
      <data key="d5">Kuratov et al. (2024) discuss the recall degradation of longer LLM context windows</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="LIU ET AL., 2023">
      <data key="d4">1.0</data>
      <data key="d5">Liu et al. (2023) discuss the recall degradation of longer LLM context windows</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="LLM PROMPTS">
      <data key="d4">1.0</data>
      <data key="d5">LLM prompts are instructions given to the LLM for extracting elements from text chunks</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="RECALL DEGRADATION">
      <data key="d4">1.0</data>
      <data key="d5">Recall degradation occurs with longer LLM context windows</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="EXTRACTION PROCESS">
      <data key="d4">1.0</data>
      <data key="d5">The extraction process involves using LLM to identify and extract elements from text chunks</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="DEFAULT PROMPT">
      <data key="d4">1.0</data>
      <data key="d5">Default prompt is the standard set of instructions given to the LLM</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="SECONDARY EXTRACTION PROMPT">
      <data key="d4">1.0</data>
      <data key="d5">Secondary extraction prompt is an additional set of instructions given to the LLM</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="LLM" target="COVARIATE PROMPT">
      <data key="d4">1.0</data>
      <data key="d5">The LLM uses covariate prompts to extract additional attributes associated with detected entities</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="LLM" target="GLEANINGS">
      <data key="d4">1.0</data>
      <data key="d5">The LLM uses multiple rounds of gleanings to ensure no entities are missed</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="LLM" target="LOGIT BIAS">
      <data key="d4">1.0</data>
      <data key="d5">Logit bias is used to force a yes/no decision from the LLM during entity extraction</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="LLM" target="ELEMENT INSTANCES">
      <data key="d4">1.0</data>
      <data key="d5">The LLM extracts element instances from source texts</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="LLM" target="COMMUNITIES OF ENTITIES">
      <data key="d4">1.0</data>
      <data key="d5">The LLM detects and summarizes communities of entities</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="LLM" target="CHUNKS">
      <data key="d4">1.0</data>
      <data key="d5">LLM generates intermediate answers and scores for each chunk</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="LLM" target="HELPFULNESS SCORE">
      <data key="d4">1.0</data>
      <data key="d5">LLM generates a helpfulness score for each answer</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="LLM" target="PODCAST TRANSCRIPTS">
      <data key="d4">2.0</data>
      <data key="d5">LLM is used to generate questions for evaluating the Podcast Transcripts dataset</data>
      <data key="d6">922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="LLM" target="NEWS ARTICLES">
      <data key="d4">2.0</data>
      <data key="d5">LLM is used to generate questions for evaluating the News Articles dataset</data>
      <data key="d6">922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="LLM" target="NAIVE RAG">
      <data key="d4">1.0</data>
      <data key="d5">LLM uses Naive RAG to list public figures mentioned in entertainment articles</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="LLM" target="ASSESSMENT">
      <data key="d4">1.0</data>
      <data key="d5">LLM-generated responses are evaluated using assessment metrics</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="LLM" target="QUESTION">
      <data key="d4">1.0</data>
      <data key="d5">LLM-generated responses are evaluated using specific questions</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="LLM" target="AD-HOC LLM USE">
      <data key="d4">1.0</data>
      <data key="d5">Ad-hoc LLM use involves the use of large language models to analyze reasoning and provide specific examples, quotes, and citations</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="LLM" target="KNOWLEDGE GRAPH CREATION">
      <data key="d4">2.0</data>
      <data key="d5">LLMs are used for knowledge graph creation</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="LLM" target="KNOWLEDGE GRAPH COMPLETION">
      <data key="d4">2.0</data>
      <data key="d5">LLMs are used for knowledge graph completion</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="LLM" target="CAUSAL GRAPHS">
      <data key="d4">2.0</data>
      <data key="d5">LLMs are used for the extraction of causal graphs</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="LLM" target="TRAJANOSKA ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">LLMs are used for knowledge graph creation as per Trajanoska et al., 2023</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="LLM" target="YAO ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">LLMs are used for knowledge graph completion as per Yao et al., 2023</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="LLM" target="BAN ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">LLMs are used for the extraction of causal graphs as per Ban et al.</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="QFS">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG is proposed as a method to combine the strengths of RAG and QFS</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Community summaries are used in the Graph RAG approach to generate partial responses
Community summaries are generated in the Graph RAG approach
Graph RAG is used to compare community summaries to source texts
Graph RAG uses community summaries to improve answer comprehensiveness and diversity
Graph RAG uses community summaries as a kind of self-memory
Graph RAG uses summaries of root-level communities in an entity-based graph index</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,36db32c37e1987e2c5863898ad882190,6f33a085ff3304e5994f7fbb86c881a4,e4d9b12cf2b4c691c74019eefff4fb39,e8d83e6e7a7c0f57b218cef24976b745,f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL SENSEMAKING QUESTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG is designed to handle global sensemaking questions over large datasets</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="GRAPH RAG" target="PYTHON">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG is implemented in Python
Graph RAG is implemented using Python</data>
      <data key="d6">086021a89900a39bcb62036981737bfa,e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="GRAPH RAG" target="HTTPS://AKA.MS/GRAPHRAG">
      <data key="d4">1.0</data>
      <data key="d5">The open-source implementation of Graph RAG will be available at this URL</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="GRAPH RAG" target="ENTITY KNOWLEDGE GRAPH">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG uses an entity knowledge graph to index text</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="GRAPH RAG" target="COMPREHENSIVENESS">
      <data key="d4">3.0</data>
      <data key="d5">Graph RAG improves the comprehensiveness of generated answers
Comprehensiveness is a target quality used to evaluate the Graph RAG approach
Graph RAG is evaluated for comprehensiveness</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="GRAPH RAG" target="DIVERSITY">
      <data key="d4">3.0</data>
      <data key="d5">Graph RAG improves the diversity of generated answers
Diversity is a target quality used to evaluate the Graph RAG approach
Diversity is used to evaluate the performance of Graph RAG</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,6f33a085ff3304e5994f7fbb86c881a4,e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="GRAPH RAG" target="KNOWLEDGE GRAPH">
      <data key="d4">3.0</data>
      <data key="d5">Graph RAG uses a knowledge graph for global summarization
Graph RAG uses a knowledge graph for global summarization</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">1.0</data>
      <data key="d5">Community detection algorithms are used in the Graph RAG approach to partition graphs</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="PODCAST TRANSCRIPTS">
      <data key="d4">1.0</data>
      <data key="d5">Podcast transcripts are used as a dataset to evaluate the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWS ARTICLES">
      <data key="d4">1.0</data>
      <data key="d5">News articles are used as a dataset to evaluate the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="EMPOWERMENT">
      <data key="d4">2.0</data>
      <data key="d5">Empowerment is a target quality used to evaluate the Graph RAG approach
Empowerment is used to evaluate Graph RAG's ability to help users reach an informed understanding</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="GRAPH RAG" target="NAIVE RAG">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG is compared to naive RAG in the evaluation
Graph RAG outperformed naive RAG on comprehensiveness and diversity</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL MAP-REDUCE SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG is compared to global map-reduce summarization in the evaluation</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="QUERY-FOCUSED SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Query-focused summarization is a method used in the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="ACTIVITY-CENTERED SENSEMAKING QUESTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Activity-centered sensemaking questions are used to evaluate the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL LEVEL">
      <data key="d4">1.0</data>
      <data key="d5">Hierarchical level of community summaries is varied to evaluate the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="TOKEN COSTS">
      <data key="d4">2.0</data>
      <data key="d5">Token costs are measured to evaluate the efficiency of the Graph RAG approach
Token costs are a consideration in the performance of the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="GRAPH RAG" target="DATA FLOW">
      <data key="d4">1.0</data>
      <data key="d5">Data flow describes the high-level process of the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="DESIGN PARAMETERS">
      <data key="d4">3.0</data>
      <data key="d5">Design parameters influence the Graph RAG approach and pipeline
Design parameters are key settings in the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG uses global summarization to summarize information from a large dataset</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="QUERY">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG aims to answer specific queries</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="CORPUS">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG uses a corpus for analysis and summarization</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="ACTIVITY-CENTERED SENSEMAKING">
      <data key="d4">1.0</data>
      <data key="d5">Activity-centered sensemaking is used to evaluate the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="REAL-WORLD DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">Real-world datasets are used to evaluate the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">Hierarchical level of community summaries is varied to evaluate the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="SOURCE TEXT SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG is compared to source text summarization in the evaluation</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">Low-level community summaries are generated in the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="INTERMEDIATE-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">Intermediate-level community summaries are generated in the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="HIGH-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">High-level community summaries are generated in the Graph RAG approach</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="GRAPH RAG" target="PIPELINE">
      <data key="d4">1.0</data>
      <data key="d5">The Graph RAG approach involves a specific pipeline for processing and summarizing text</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="GRAPH RAG" target="TECHNIQUES">
      <data key="d4">1.0</data>
      <data key="d5">Techniques are specific methods used in the Graph RAG approach</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="GRAPH RAG" target="IMPLEMENTATION DETAILS">
      <data key="d4">1.0</data>
      <data key="d5">Implementation details are specific configurations used in the Graph RAG approach</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="GRAPH RAG" target="RAG SYSTEMS">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG is a specific implementation of RAG systems</data>
      <data key="d6">922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="GRAPH RAG" target="C0">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG uses root-level community summaries (C0) to answer user queries
C0 represents root-level community summaries in the Graph RAG analysis</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH RAG" target="C1">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG uses high-level community summaries (C1) to answer user queries</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH RAG" target="C2">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG uses intermediate-level community summaries (C2) to answer user queries</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH RAG" target="C3">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG uses low-level community summaries (C3) to answer user queries
C3 represents low-level community summaries in the Graph RAG analysis</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH RAG" target="CONDITIONS">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG is one of the conditions compared in the analysis
Graph RAG compares multiple conditions</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c,973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH RAG" target="USER QUERIES">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG uses different levels of graph communities to answer user queries</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH RAG" target="LLM EVALUATOR">
      <data key="d4">1.0</data>
      <data key="d5">The Graph RAG mechanism uses an LLM evaluator for head-to-head comparison</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="GRAPH RAG" target="MULTI-STAGE">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG is a multi-stage mechanism</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="GRAPH RAG" target="TAYLOR SWIFT">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG mentions Taylor Swift as a prominent public figure</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="GRAPH RAG" target="TRAVIS KELCE">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG mentions Travis Kelce as a prominent public figure</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="GRAPH RAG" target="BRITNEY SPEARS">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG mentions Britney Spears as a prominent public figure</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="GRAPH RAG" target="JUSTIN TIMBERLAKE">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG mentions Justin Timberlake as a prominent public figure</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="GRAPH RAG" target="DECISION">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG is determined to be the winner based on the decision metric</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="GRAPH RAG" target="ANSWER 1">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 was generated using the Graph RAG method, which provides a comprehensive and structured overview of public figures across various sectors of the entertainment industry.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG is used to generate answers for questions in the News article dataset</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="GRAPH RAG" target="SOURCE TEXTS">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG is compared with source texts for answer comprehensiveness and diversity</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="GRAPH RAG" target="TS">
      <data key="d4">1.0</data>
      <data key="d5">TS represents source text summarization in the Graph RAG analysis</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="GRAPH RAG" target="ROOT-LEVEL SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">Root-level summaries are used in the Graph RAG analysis</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="GRAPH RAG" target="ANSWER COMPREHENSIVENESS">
      <data key="d4">1.0</data>
      <data key="d5">Answer comprehensiveness is used to evaluate the performance of Graph RAG</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="GRAPH RAG" target="WIN RATE">
      <data key="d4">1.0</data>
      <data key="d5">Win rate is used to measure the success rate of Graph RAG in providing comprehensive and diverse answers</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="GRAPH RAG" target="ELEMENT EXTRACTION PROMPTS">
      <data key="d4">1.0</data>
      <data key="d5">Element extraction prompts are used in Graph RAG to retain specific details in the index</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="GRAPH RAG" target="SELF-MEMORY (SELFMEM)">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates the concept of self-memory</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates the concept of iterative retrieval-generation</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="FEDERATED RETRIEVAL-GENERATION (FEB4RAG)">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates the concept of federated retrieval-generation</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="MULTI-DOCUMENT SUMMARIZATION">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts used in multi-document summarization</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="MULTI-HOP QUESTION ANSWERING">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts used in multi-hop question answering</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL INDEX">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG uses a hierarchical index</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="TREE OF CLARIFICATIONS">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates the concept of a tree of clarifications</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="GRAPH INDEX">
      <data key="d4">3.0</data>
      <data key="d5">Graph RAG uses a self-generated graph index
Graph RAG uses a graph index</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39,f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="GAO ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Gao et al., 2023</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="CHENG ET AL., 2024">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Cheng et al., 2024</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="MAO ET AL., 2020">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Mao et al., 2020</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="SHAO ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Shao et al., 2023</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="WANG ET AL., 2024">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Wang et al., 2024</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="SU ET AL., 2020">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Su et al., 2020</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="FENG ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Feng et al., 2023</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="TRIVEDI ET AL., 2022">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Trivedi et al., 2022</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="KHATTAB ET AL., 2022">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Khattab et al., 2022</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="SARTHI ET AL., 2024">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Sarthi et al., 2024</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="KIM ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts from Kim et al., 2023</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY ANSWERS">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG generates community answers in parallel</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="GRAPH RAG" target="GRAPH-FREE APPROACH">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG is compared to a graph-free approach for global summarization</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="MAP-REDUCE SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG is compared to map-reduce summarization</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="RICH TEXT ANNOTATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG uses rich text annotations</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG uses a hierarchical community structure</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="EMBEDDING-BASED MATCHING">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG can operate using embedding-based matching</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="HYBRID RAG SCHEMES">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG can be part of hybrid RAG schemes</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="MAP-REDUCE SUMMARIZATION MECHANISMS">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG can employ map-reduce summarization mechanisms</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY HIERARCHY">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG can extend operations across the community hierarchy</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="ALONSO">
      <data key="d4">1.0</data>
      <data key="d5">Alonso contributed to the work on Graph RAG</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="LOCAL GRAPH RAG APPROACHES">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG includes local graph RAG approaches</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="ENTITY-BASED GRAPH INDEX">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG uses an entity-based graph index</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH RAG" target="NEBULAGRAPH">
      <data key="d4">2.0</data>
      <data key="d5">NebulaGraph launched the industry-first graph RAG: Retrieval-augmented generation with LLM based on knowledge graphs</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="PARTIAL RESPONSE">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are used to generate partial responses</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GRAPH COMMUNITIES">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are created from graph communities</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="COMMUNITY ANSWERS">
      <data key="d4">2.0</data>
      <data key="d5">Community answers are created from community summaries
Community answers are generated from community summaries</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="DOMAIN-TAILORED SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Domain-tailored summarization is used to create community summaries</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="COMMUNITY DESCRIPTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Community descriptions are generated from community summaries</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="PARTIAL ANSWERS">
      <data key="d4">1.0</data>
      <data key="d5">Partial answers are generated from community summaries</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are created for each level in the hierarchical community structure</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are useful for understanding the global structure and semantics of the dataset</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL QUERIES">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are used to answer global queries</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="ROOT COMMUNITIES">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are generated from root communities</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SUB-COMMUNITIES">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are generated from sub-communities</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="LLM CONTEXT WINDOW">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are added to the LLM context window until the token limit is reached</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL ANSWER">
      <data key="d4">1.0</data>
      <data key="d5">Global answers are generated from community summaries</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SUMMARY DETAIL">
      <data key="d4">1.0</data>
      <data key="d5">The level of summary detail affects the content of community summaries</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SCOPE">
      <data key="d4">1.0</data>
      <data key="d5">The scope of information affects the content of community summaries</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SENSEMAKING">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are used for sensemaking</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="CHUNK">
      <data key="d4">2.0</data>
      <data key="d5">Community summaries are divided into chunks of pre-specified token size</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SUMMARY DETAIL AND SCOPE">
      <data key="d4">1.0</data>
      <data key="d5">Summary detail and scope affect the content of community summaries</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="CHUNKS">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are divided into chunks</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="USER QUERY">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are prepared to answer user queries</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="INTERMEDIATE ANSWERS">
      <data key="d4">1.0</data>
      <data key="d5">Intermediate answers are generated from community summaries</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GRAPH">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are part of the graph community hierarchy</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="PODCAST DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are derived from the Podcast dataset for analysis</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are derived from the News dataset for analysis</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="ROOT-LEVEL COMMUNITIES">
      <data key="d4">1.0</data>
      <data key="d5">Summaries of root-level communities are used in Graph RAG</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GLOBAL SENSEMAKING QUESTIONS" target="1 MILLION TOKEN RANGE">
      <data key="d4">1.0</data>
      <data key="d5">Global sensemaking questions are evaluated over datasets in the 1 million token range</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="GLOBAL SENSEMAKING QUESTIONS" target="TEXT CORPUS">
      <data key="d4">1.0</data>
      <data key="d5">Global sensemaking questions are directed at an entire text corpus</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="HTTPS://AKA.MS/GRAPHRAG" target="PYTHON-BASED IMPLEMENTATION">
      <data key="d4">1.0</data>
      <data key="d5">The Python-based implementation of Graph RAG approaches will be available at this URL</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION" target="GLOBAL ANSWER">
      <data key="d4">1.0</data>
      <data key="d5">Query-focused summarization is used to produce the global answer</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION" target="MAP-REDUCE">
      <data key="d4">1.0</data>
      <data key="d5">Map-reduce is used for query-focused summarization of an entire corpus</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION" target="GLOBAL QUERIES">
      <data key="d4">1.0</data>
      <data key="d5">Query-focused summarization is used for answering global queries</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="ENTITY KNOWLEDGE GRAPH" target="SOURCE DOCUMENTS">
      <data key="d4">1.0</data>
      <data key="d5">An entity knowledge graph is derived from source documents</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="TEXT CHUNKS">
      <data key="d4">2.0</data>
      <data key="d5">Text chunks are extracted from source documents
Text chunks are extracted from source documents for processing in the Graph RAG approach</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="INTERMEDIATE-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">Intermediate-level community summaries are derived from source documents</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">Low-level community summaries are derived from source documents</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="DOCUMENT CORPUS">
      <data key="d4">1.0</data>
      <data key="d5">Document corpus consists of source documents being processed</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="PARTIAL RESPONSE" target="FINAL RESPONSE">
      <data key="d4">1.0</data>
      <data key="d5">Partial responses are summarized to generate a final response</data>
      <data key="d6">e8d83e6e7a7c0f57b218cef24976b745</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="LLM EVALUATOR">
      <data key="d4">1.0</data>
      <data key="d5">The LLM evaluator assesses answers based on the comprehensiveness metric</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="NAIVE RAG">
      <data key="d4">1.0</data>
      <data key="d5">Naive RAG is evaluated for comprehensiveness</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="DECISION">
      <data key="d4">1.0</data>
      <data key="d5">Comprehensiveness is a metric used to determine the decision</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Comprehensiveness is used to evaluate the thoroughness of the generated answers for news articles</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="PODCAST TRANSCRIPTS">
      <data key="d4">1.0</data>
      <data key="d5">Comprehensiveness is used to evaluate the thoroughness of the generated answers for podcast transcripts</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="CONTEXT WINDOW SIZE">
      <data key="d4">1.0</data>
      <data key="d5">The smallest context window size (8k) was universally better for comprehensiveness</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="FINAL EVALUATION">
      <data key="d4">1.0</data>
      <data key="d5">The final evaluation prioritized comprehensiveness in answers</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="GLOBAL APPROACHES">
      <data key="d4">1.0</data>
      <data key="d5">Global approaches achieved higher comprehensiveness win rates</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="DIVERSITY" target="LLM EVALUATOR">
      <data key="d4">1.0</data>
      <data key="d5">The LLM evaluator assesses answers based on the diversity metric</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="DIVERSITY" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Diversity is used to evaluate the variety in the generated answers for news articles</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="DIVERSITY" target="PODCAST TRANSCRIPTS">
      <data key="d4">1.0</data>
      <data key="d5">Diversity is used to evaluate the variety in the generated answers for podcast transcripts</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="DIVERSITY" target="CONTEXT WINDOW SIZE">
      <data key="d4">1.0</data>
      <data key="d5">The smallest context window size (8k) performed comparably with larger context sizes on diversity</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="DIVERSITY" target="FINAL EVALUATION">
      <data key="d4">1.0</data>
      <data key="d5">The final evaluation prioritized diversity in answers</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="DIVERSITY" target="GLOBAL APPROACHES">
      <data key="d4">1.0</data>
      <data key="d5">Global approaches achieved higher diversity win rates</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="HUMAN ENDEAVORS" target="SENSEMAKING">
      <data key="d4">1.0</data>
      <data key="d5">Human endeavors rely on sensemaking to understand and reason about large collections of documents</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="HUMAN ENDEAVORS" target="DOCUMENT COLLECTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Human endeavors rely on analyzing document collections for sensemaking</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="SENSEMAKING">
      <data key="d4">1.0</data>
      <data key="d5">LLMs are used to automate sensemaking in complex domains</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="MICROSOFT">
      <data key="d4">1.0</data>
      <data key="d5">Microsoft uses LLMs for automating sensemaking in scientific discovery</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="RANADE">
      <data key="d4">1.0</data>
      <data key="d5">Ranade uses LLMs for automating sensemaking in intelligence analysis</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="JOSHI">
      <data key="d4">1.0</data>
      <data key="d5">Joshi uses LLMs for automating sensemaking in intelligence analysis</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="LLM PROMPTS">
      <data key="d4">1.0</data>
      <data key="d5">LLM prompts are used to tailor the responses of large language models</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="RANADE AND JOSHI">
      <data key="d4">1.0</data>
      <data key="d5">Ranade and Joshi discussed the use of LLMs in intelligence analysis</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="GPT">
      <data key="d4">2.0</data>
      <data key="d5">GPT is a type of large language model</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="LLAMA">
      <data key="d4">2.0</data>
      <data key="d5">Llama is a type of large language model</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="GEMINI">
      <data key="d4">2.0</data>
      <data key="d5">Gemini is a type of large language model</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="KURATOV ET AL., 2024">
      <data key="d4">2.0</data>
      <data key="d5">Kuratov et al., 2024, discussed the limitations of LLM context windows</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="LIU ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Liu et al., 2023, discussed the limitations of LLM context windows</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="SCIENTIFIC DISCOVERY" target="SENSEMAKING">
      <data key="d4">1.0</data>
      <data key="d5">Sensemaking is applied in the domain of scientific discovery</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="INTELLIGENCE ANALYSIS" target="SENSEMAKING">
      <data key="d4">1.0</data>
      <data key="d5">Sensemaking is applied in the domain of intelligence analysis</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="SENSEMAKING" target="KLEIN">
      <data key="d4">1.0</data>
      <data key="d5">Klein defined and discussed the importance of sensemaking</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="SENSEMAKING" target="KLEIN ET AL.">
      <data key="d4">1.0</data>
      <data key="d5">Klein et al. defined and discussed the importance of sensemaking</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="TEXT CHUNKS" target="ELEMENT INSTANCES">
      <data key="d4">2.0</data>
      <data key="d5">Element instances are extracted from text chunks
Element instances are extracted from text chunks</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="TEXT CHUNKS" target="ENTITY REFERENCES">
      <data key="d4">1.0</data>
      <data key="d5">Entity references are extracted from text chunks during processing</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="TEXT CHUNKS" target="CHUNK SIZE">
      <data key="d4">1.0</data>
      <data key="d5">Chunk size refers to the length of text chunks used in the extraction process</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="ELEMENT SUMMARIES">
      <data key="d4">2.0</data>
      <data key="d5">Element summaries are created from element instances
Element instances are converted into element summaries by the LLM</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="COVARIATES">
      <data key="d4">1.0</data>
      <data key="d5">Covariates are additional attributes associated with extracted element instances</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="DOMAIN-TAILORED SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Domain-tailored summarization is used to create element summaries</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="ENTITY NODE">
      <data key="d4">1.0</data>
      <data key="d5">Element summaries include descriptions of entity nodes</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="RELATIONSHIP EDGE">
      <data key="d4">1.0</data>
      <data key="d5">Element summaries include descriptions of relationship edges</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="CLAIM COVARIATE">
      <data key="d4">1.0</data>
      <data key="d5">Element summaries include descriptions of claim covariates</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="GRAPH COMMUNITIES">
      <data key="d4">1.0</data>
      <data key="d5">Element summaries are used to understand the structure and semantics of graph communities</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="NODE">
      <data key="d4">1.0</data>
      <data key="d5">Element summaries include descriptions of nodes</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="EDGE">
      <data key="d4">1.0</data>
      <data key="d5">Element summaries include descriptions of edges</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="COVARIATE">
      <data key="d4">1.0</data>
      <data key="d5">Element summaries include descriptions of covariates</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="SUB-COMMUNITY SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">Sub-community summaries are used when element summaries exceed the token limit</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="COMMUNITY DETECTION">
      <data key="d4">2.0</data>
      <data key="d5">Community detection is used to identify graph communities
Graph communities are identified through community detection</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="COMMUNITY ANSWERS" target="GLOBAL ANSWER">
      <data key="d4">1.0</data>
      <data key="d5">Global answer is created from community answers</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="USER QUERY">
      <data key="d4">2.0</data>
      <data key="d5">Global answers are generated in response to user queries</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="HELPFULNESS SCORE">
      <data key="d4">1.0</data>
      <data key="d5">Global answer is generated by sorting intermediate answers based on helpfulness scores</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="INTERMEDIATE ANSWERS">
      <data key="d4">1.0</data>
      <data key="d5">Intermediate answers are combined to form the global answer</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="CONTEXT WINDOW">
      <data key="d4">1.0</data>
      <data key="d5">The final context window is used to generate the global answer</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="INDEXING TIME" target="GRAPH RAG PIPELINE">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG pipeline operates at indexing time</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="QUERY TIME" target="GRAPH RAG PIPELINE">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG pipeline operates at query time</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="GRAPH RAG PIPELINE" target="NODES">
      <data key="d4">1.0</data>
      <data key="d5">Nodes are detected in the graph RAG pipeline</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="GRAPH RAG PIPELINE" target="EDGES">
      <data key="d4">1.0</data>
      <data key="d5">Edges are detected in the graph RAG pipeline</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="GRAPH RAG PIPELINE" target="COVARIATES">
      <data key="d4">1.0</data>
      <data key="d5">Covariates are detected in the graph RAG pipeline</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="GRAPH RAG PIPELINE" target="LEIDEN">
      <data key="d4">1.0</data>
      <data key="d5">Leiden method is used in the graph RAG pipeline for community detection</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="GRAPH RAG PIPELINE" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG pipeline uses the RAG approach</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="NODES" target="PODCAST DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The Podcast dataset graph consists of 8564 nodes</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NODES" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The News dataset graph consists of 15754 nodes</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="EDGES" target="PODCAST DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The Podcast dataset graph consists of 20691 edges</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="EDGES" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The News dataset graph consists of 19520 edges</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="LEIDEN" target="TRAAG">
      <data key="d4">1.0</data>
      <data key="d5">Traag contributed to the development of the Leiden method</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="LEIDEN" target="TRAAG ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Traag et al. developed the Leiden method
Traag et al. are the authors of the Leiden algorithm</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="LEIDEN" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">2.0</data>
      <data key="d5">Leiden is a type of community detection algorithm
Leiden is a specific community detection algorithm used in the pipeline</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a,7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="LEIDEN" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d4">1.0</data>
      <data key="d5">Leiden is known for its ability to recover hierarchical community structures efficiently</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="LEIDEN" target="MULTIHOP-RAG">
      <data key="d4">1.0</data>
      <data key="d5">The Leiden algorithm is used to detect graph communities in the MultiHop-RAG</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="LEIDEN" target="FIGURE 3">
      <data key="d4">1.0</data>
      <data key="d5">Figure 3 shows graph communities detected using the Leiden algorithm</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="LEWIS">
      <data key="d4">1.0</data>
      <data key="d5">Lewis contributed to the development of the RAG approach</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="LEWIS ET AL.">
      <data key="d4">1.0</data>
      <data key="d5">Lewis et al. developed the RAG approach</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="LEWIS ET AL., 2020">
      <data key="d4">2.0</data>
      <data key="d5">Lewis et al., 2020, are the authors who established the RAG approach</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="MICROSOFT" target="KEVIN SCOTT">
      <data key="d4">1.0</data>
      <data key="d5">Kevin Scott is the CTO of Microsoft</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="MICROSOFT" target="GPT-4">
      <data key="d4">2.0</data>
      <data key="d5">Microsoft conducted a study on the impact of large language models on scientific discovery using GPT-4</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="ARXIV" target="PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Preprint is available on arXiv</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="ARXIV" target="BAUMEL, T.">
      <data key="d4">1.0</data>
      <data key="d5">Baumel, T. published the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="EYAL, M.">
      <data key="d4">1.0</data>
      <data key="d5">Eyal, M. published the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="ELHADAD, M.">
      <data key="d4">1.0</data>
      <data key="d5">Elhadad, M. published the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="ES, S.">
      <data key="d4">1.0</data>
      <data key="d5">Es, S. published the paper "Ragas: Automated evaluation of retrieval augmented generation" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="JAMES, J.">
      <data key="d4">1.0</data>
      <data key="d5">James, J. published the paper "Ragas: Automated evaluation of retrieval augmented generation" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="ESPINOSA-ANKE, L.">
      <data key="d4">1.0</data>
      <data key="d5">Espinosa-Anke, L. published the paper "Ragas: Automated evaluation of retrieval augmented generation" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="SCHOCKAERT, S.">
      <data key="d4">1.0</data>
      <data key="d5">Schockaert, S. published the paper "Ragas: Automated evaluation of retrieval augmented generation" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="FENG, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Feng, Z. published the paper "Retrieval-generation synergy augmented large language models" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="FENG, X.">
      <data key="d4">1.0</data>
      <data key="d5">Feng, X. published the paper "Retrieval-generation synergy augmented large language models" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="ZHAO, D.">
      <data key="d4">1.0</data>
      <data key="d5">Zhao, D. published the paper "Retrieval-generation synergy augmented large language models" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="YANG, M.">
      <data key="d4">1.0</data>
      <data key="d5">Yang, M. published the paper "Retrieval-generation synergy augmented large language models" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="QIN, B.">
      <data key="d4">1.0</data>
      <data key="d5">Qin, B. published the paper "Retrieval-generation synergy augmented large language models" on arXiv</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ARXIV" target="LANGCHAIN">
      <data key="d4">1.0</data>
      <data key="d5">LangChain is an organization that has published on arXiv</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="ARXIV" target="WANG, S.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, S. published the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="KHRAMTSOVA, E.">
      <data key="d4">1.0</data>
      <data key="d5">Khramtsova, E. published the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="ZHUANG, S.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, S. published the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="ZUCCON, G.">
      <data key="d4">1.0</data>
      <data key="d5">Zuccon, G. published the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="WANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, Y. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="LIPKA, N.">
      <data key="d4">1.0</data>
      <data key="d5">Lipka, N. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="ROSSI, R. A.">
      <data key="d4">1.0</data>
      <data key="d5">Rossi, R. A. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="SIU, A.">
      <data key="d4">1.0</data>
      <data key="d5">Siu, A. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="ZHANG, R.">
      <data key="d4">1.0</data>
      <data key="d5">Zhang, R. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="DERR, T.">
      <data key="d4">1.0</data>
      <data key="d5">Derr, T. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="XU, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Xu, Y. published the paper "Text summarization with latent queries" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="LAPATA, M.">
      <data key="d4">1.0</data>
      <data key="d5">Lapata, M. published the paper "Text summarization with latent queries" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="ZHANG, J.">
      <data key="d4">1.0</data>
      <data key="d5">Zhang, J. published the paper "Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="ZHANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Zhang, Y. published the paper "Causal graph discovery with retrieval-augmented generation based large language models" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="GAN, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Gan, Y. published the paper "Causal graph discovery with retrieval-augmented generation based large language models" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="YAO, L.">
      <data key="d4">1.0</data>
      <data key="d5">Yao, L. published the paper "Causal graph discovery with retrieval-augmented generation based large language models" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="WANG, C.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, C. published the paper "Causal graph discovery with retrieval-augmented generation based large language models" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="ZHENG, L.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="CHIANG, W.-L.">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="SHENG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Sheng, Y. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="WU, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Wu, Z. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="ZHUANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, Y. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="LIN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Lin, Z. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="LI, D.">
      <data key="d4">1.0</data>
      <data key="d5">Li, D. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ARXIV" target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Xing, E. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="PREPRINT" target="CS.CL">
      <data key="d4">1.0</data>
      <data key="d5">Preprint is classified under cs.CL on arXiv</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="PREPRINT" target="24 APR 2024">
      <data key="d4">1.0</data>
      <data key="d5">Preprint was submitted on 24 Apr 2024</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="PREPRINT" target="2404.16130V1">
      <data key="d4">1.0</data>
      <data key="d5">Preprint has the identifier 2404.16130v1 on arXiv</data>
      <data key="d6">f0306814bf64f5c9e79603fc6a52f4ea</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="PARTITION">
      <data key="d4">1.0</data>
      <data key="d5">Community detection results in the partition of a graph into distinct communities</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="PIPELINE">
      <data key="d4">1.0</data>
      <data key="d5">The pipeline includes a step for community detection</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="DANG, 2006">
      <data key="d4">2.0</data>
      <data key="d5">Dang, 2006, is the author who established the QFS approach</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="BAUMEL ET AL., 2018">
      <data key="d4">2.0</data>
      <data key="d5">Baumel et al., 2018, are the authors who worked on query-focused abstractive summarization</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="LASKAR ET AL., 2020">
      <data key="d4">2.0</data>
      <data key="d5">Laskar et al., 2020, are the authors who worked on query-focused abstractive summarization</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="YAO ET AL., 2017">
      <data key="d4">2.0</data>
      <data key="d5">Yao et al., 2017, are the authors who worked on query-focused abstractive summarization</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="TRANSFORMER ARCHITECTURE" target="GOODWIN ET AL., 2020">
      <data key="d4">2.0</data>
      <data key="d5">Goodwin et al., 2020, are the authors who worked on the early applications of the transformer architecture</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="TRANSFORMER ARCHITECTURE" target="LASKAR ET AL., 2022">
      <data key="d4">2.0</data>
      <data key="d5">Laskar et al., 2022, are the authors who worked on the early applications of the transformer architecture</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="TRANSFORMER ARCHITECTURE" target="LIU AND LAPATA, 2019">
      <data key="d4">2.0</data>
      <data key="d5">Liu and Lapata, 2019, are the authors who worked on the early applications of the transformer architecture</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="GPT" target="ACHIAM ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Achiam et al., 2023, are the authors who worked on the GPT series of large language models</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="GPT" target="BROWN ET AL., 2020">
      <data key="d4">2.0</data>
      <data key="d5">Brown et al., 2020, are the authors who worked on the GPT series of large language models</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="LLAMA" target="TOUVRON ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Touvron et al., 2023, are the authors who worked on the Llama series of large language models</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="GEMINI" target="ANIL ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Anil et al., 2023, are the authors who worked on the Gemini series of large language models</data>
      <data key="d6">fb3c48579608fa28be585ceb6cd2f0fe</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="MODULARITY">
      <data key="d4">1.0</data>
      <data key="d5">Modularity is an inherent quality of knowledge graphs</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="BROWN ET AL., 2020" target="FEW-SHOT EXAMPLES">
      <data key="d4">1.0</data>
      <data key="d5">Brown et al. (2020) discuss in-context learning with few-shot examples</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="KURATOV ET AL., 2024" target="CONTEXT WINDOW SIZE">
      <data key="d4">1.0</data>
      <data key="d5">Kuratov et al. discussed the potential for information to be lost in longer contexts</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="LIU ET AL., 2023" target="CONTEXT WINDOW SIZE">
      <data key="d4">1.0</data>
      <data key="d5">Liu et al. discussed the potential for information to be lost in longer contexts</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="LOUVAIN">
      <data key="d4">1.0</data>
      <data key="d5">Louvain is a type of community detection algorithm</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="GRAPH INDEX">
      <data key="d4">1.0</data>
      <data key="d5">Community detection algorithms are used to partition the graph index into communities</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="FORTUNATO">
      <data key="d4">1.0</data>
      <data key="d5">Fortunato has conducted surveys on community detection algorithms</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="JIN ET AL.">
      <data key="d4">1.0</data>
      <data key="d5">Jin et al. have conducted surveys on community detection algorithms</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="HOTPOTQA" target="GPT-4-TURBO">
      <data key="d4">1.0</data>
      <data key="d5">HotPotQA dataset is used to evaluate the entity extraction prompt with gpt-4-turbo</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="HOTPOTQA" target="YANG ET AL., 2018">
      <data key="d4">1.0</data>
      <data key="d5">Yang et al. (2018) introduced the HotPotQA dataset</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="HOTPOTQA" target="YANG ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Yang et al. are the authors associated with the HotPotQA dataset</data>
      <data key="d6">922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="GPT-4-TURBO" target="CONTEXT WINDOW SIZE">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4-Turbo was tested with varying context window sizes</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TECH JOURNALIST">
      <data key="d4">1.0</data>
      <data key="d5">Tech journalist uses podcast transcripts to look for insights and trends in the tech industry</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="KEVIN SCOTT">
      <data key="d4">3.0</data>
      <data key="d5">Kevin Scott's conversations are part of the podcast transcripts
Kevin Scott is a participant in the podcast conversations compiled in the Podcast Transcripts dataset</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9,922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TECHNOLOGY LEADERS">
      <data key="d4">1.0</data>
      <data key="d5">Technology leaders participate in the podcast conversations</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="RAG SYSTEMS">
      <data key="d4">2.0</data>
      <data key="d5">RAG systems are used to evaluate the Podcast Transcripts dataset for global sensemaking tasks</data>
      <data key="d6">922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="C0">
      <data key="d4">2.0</data>
      <data key="d5">C0 is a category used in the analysis of podcast transcripts
C0 is a category used in the analysis of podcast transcripts</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="C1">
      <data key="d4">2.0</data>
      <data key="d5">C1 is a category used in the analysis of podcast transcripts
C1 is a category used in the analysis of podcast transcripts</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="C2">
      <data key="d4">2.0</data>
      <data key="d5">C2 is a category used in the analysis of podcast transcripts
C2 is a category used in the analysis of podcast transcripts</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="C3">
      <data key="d4">2.0</data>
      <data key="d5">C3 is a category used in the analysis of podcast transcripts
C3 is a category used in the analysis of podcast transcripts</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TS">
      <data key="d4">2.0</data>
      <data key="d5">TS is a category used in the analysis of podcast transcripts
TS is a category used in the analysis of podcast transcripts</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="EMPOWERMENT">
      <data key="d4">1.0</data>
      <data key="d5">Empowerment is used to evaluate how empowering the generated answers are for podcast transcripts</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="SS">
      <data key="d4">1.0</data>
      <data key="d5">SS is a category used in the analysis of podcast transcripts</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="UNITS">
      <data key="d4">1.0</data>
      <data key="d5">Units are used to measure the context in podcast transcripts</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TOKENS">
      <data key="d4">1.0</data>
      <data key="d5">Tokens are used to measure the word count in podcast transcripts</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="% MAX">
      <data key="d4">1.0</data>
      <data key="d5">% Max is used to measure the percentage of maximum token count in podcast transcripts</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="NEWS ARTICLES">
      <data key="d4">1.0</data>
      <data key="d5">Both are datasets used in the analysis</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS ARTICLES" target="EDUCATOR">
      <data key="d4">1.0</data>
      <data key="d5">Educator uses news articles to incorporate current affairs into curricula</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="NEWS ARTICLES" target="RAG SYSTEMS">
      <data key="d4">2.0</data>
      <data key="d5">RAG systems are used to evaluate the News Articles dataset for global sensemaking tasks</data>
      <data key="d6">922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="NEWS ARTICLES" target="C0">
      <data key="d4">1.0</data>
      <data key="d5">C0 is a category used in the analysis of news articles</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS ARTICLES" target="C1">
      <data key="d4">1.0</data>
      <data key="d5">C1 is a category used in the analysis of news articles</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS ARTICLES" target="C2">
      <data key="d4">1.0</data>
      <data key="d5">C2 is a category used in the analysis of news articles</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS ARTICLES" target="C3">
      <data key="d4">1.0</data>
      <data key="d5">C3 is a category used in the analysis of news articles</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS ARTICLES" target="TS">
      <data key="d4">1.0</data>
      <data key="d5">TS is a category used in the analysis of news articles</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS ARTICLES" target="UNITS">
      <data key="d4">1.0</data>
      <data key="d5">Units are used to measure the context in news articles</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS ARTICLES" target="TOKENS">
      <data key="d4">1.0</data>
      <data key="d5">Tokens are used to measure the word count in news articles</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS ARTICLES" target="% MAX">
      <data key="d4">1.0</data>
      <data key="d5">% Max is used to measure the percentage of maximum token count in news articles</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="MAP-REDUCE" target="TEXT SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Map-reduce is the method used in the text summarization condition</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="EMPOWERMENT" target="LLM EVALUATOR">
      <data key="d4">1.0</data>
      <data key="d5">The LLM evaluator assesses answers based on the empowerment metric</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="EMPOWERMENT" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Empowerment is used to evaluate how empowering the generated answers are for news articles</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="EMPOWERMENT" target="CONTEXT WINDOW SIZE">
      <data key="d4">1.0</data>
      <data key="d5">The smallest context window size (8k) performed comparably with larger context sizes on empowerment</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="EMPOWERMENT" target="WIN RATE">
      <data key="d4">1.0</data>
      <data key="d5">Empowerment has an average win rate of 51.3%</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NAIVE RAG" target="TAYLOR SWIFT">
      <data key="d4">1.0</data>
      <data key="d5">Naive RAG mentions Taylor Swift as a public figure</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="NAIVE RAG" target="TRAVIS KELCE">
      <data key="d4">1.0</data>
      <data key="d5">Naive RAG mentions Travis Kelce as a public figure</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="NAIVE RAG" target="BRITNEY SPEARS">
      <data key="d4">1.0</data>
      <data key="d5">Naive RAG mentions Britney Spears as a public figure</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="NAIVE RAG" target="JUSTIN TIMBERLAKE">
      <data key="d4">1.0</data>
      <data key="d5">Naive RAG mentions Justin Timberlake as a public figure</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="NAIVE RAG" target="DECISION">
      <data key="d4">1.0</data>
      <data key="d5">Naive RAG is determined to be the loser based on the decision metric</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="NAIVE RAG" target="GLOBAL APPROACHES">
      <data key="d4">1.0</data>
      <data key="d5">Global approaches consistently outperformed the naive RAG</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NAIVE RAG" target="DIRECTNESS">
      <data key="d4">1.0</data>
      <data key="d5">Naive RAG produces the most direct responses</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NAIVE RAG" target="SS">
      <data key="d4">1.0</data>
      <data key="d5">SS represents naive RAG in the analysis</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="NAIVE RAG" target="GAO ET AL., 2023">
      <data key="d4">1.0</data>
      <data key="d5">Gao et al., 2023 discusses naive RAG approaches</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="GLOBAL SUMMARIZATION" target="COMMUNITY PARTITION">
      <data key="d4">1.0</data>
      <data key="d5">Community partitions enable divide-and-conquer global summarization</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="GLOBAL SUMMARIZATION" target="GRAPH-FREE APPROACH">
      <data key="d4">1.0</data>
      <data key="d5">Global summarization can be performed using a graph-free approach</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GLOBAL SUMMARIZATION" target="SOURCE TEXTS">
      <data key="d4">1.0</data>
      <data key="d5">Source texts are used in global summarization</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="PARTIAL ANSWERS" target="FINAL GLOBAL ANSWER">
      <data key="d4">1.0</data>
      <data key="d5">Final global answer is generated by combining all relevant partial answers</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSEMAKING" target="SHORT DESCRIPTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Short descriptions are used to generate sensemaking questions</data>
      <data key="d6">21e52bc06a82796b1f4bcd73edda1f2a</data>
    </edge>
    <edge source="LOW-LEVEL COMMUNITY SUMMARIES" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Low-level community summaries are derived from the News dataset for analysis</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="GRAPH INDEX" target="LLMS">
      <data key="d4">1.0</data>
      <data key="d5">The use of rich descriptive text for homogeneous nodes in a graph index aligns with the capabilities of LLMs</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="GRAPH INDEX" target="KNOWLEDGE GRAPHS">
      <data key="d4">1.0</data>
      <data key="d5">Graph indexes differ from typical knowledge graphs in their use of rich descriptive text instead of concise knowledge triples</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="GRAPH INDEX" target="C0">
      <data key="d4">1.0</data>
      <data key="d5">The graph index supports condition C0</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH INDEX" target="C1">
      <data key="d4">1.0</data>
      <data key="d5">The graph index supports condition C1</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH INDEX" target="C2">
      <data key="d4">1.0</data>
      <data key="d5">The graph index supports condition C2</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH INDEX" target="C3">
      <data key="d4">1.0</data>
      <data key="d5">The graph index supports condition C3</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH INDEX" target="PODCAST DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The graph indexing process used a context window size of 600 tokens with 1 gleaning for the Podcast dataset</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH INDEX" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The graph indexing process used a context window size of 600 tokens with 0 gleanings for the News dataset</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH INDEX" target="ENTITY TYPES">
      <data key="d4">1.0</data>
      <data key="d5">The graph index was created using generic prompts for entity and relationship extraction</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH INDEX" target="FEW-SHOT EXAMPLES">
      <data key="d4">1.0</data>
      <data key="d5">Few-shot examples tailored to the domain of the data were used in the graph indexing process</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH INDEX" target="CONTEXT WINDOW SIZE">
      <data key="d4">1.0</data>
      <data key="d5">The graph indexing process used a context window size of 600 tokens</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="GRAPH INDEX" target="LIFETIME QUERIES PER DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The decision to build a graph index depends on the expected number of lifetime queries per dataset</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH INDEX" target="VALUE FROM GRAPH INDEX">
      <data key="d4">1.0</data>
      <data key="d5">The decision to build a graph index depends on the value obtained from it</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GRAPH INDEX" target="OTHER GRAPH-RELATED RAG APPROACHES">
      <data key="d4">1.0</data>
      <data key="d5">The decision to build a graph index depends on the value obtained from other graph-related RAG approaches</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="ENTITY REFERENCES" target="RECALL">
      <data key="d4">1.0</data>
      <data key="d5">Recall measures the completeness of entity references extracted from text chunks</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="ENTITY REFERENCES" target="PRECISION">
      <data key="d4">1.0</data>
      <data key="d5">Precision measures the accuracy of entity references extracted from text chunks</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="DEFAULT PROMPT">
      <data key="d4">1.0</data>
      <data key="d5">Few-shot examples are used to tailor the default prompt to the domain</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="SECONDARY EXTRACTION PROMPT">
      <data key="d4">1.0</data>
      <data key="d5">Few-shot examples are used to tailor the secondary extraction prompt to the domain</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="SCIENCE">
      <data key="d4">1.0</data>
      <data key="d5">Few-shot examples are used to improve LLM performance in the domain of science</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="MEDICINE">
      <data key="d4">1.0</data>
      <data key="d5">Few-shot examples are used to improve LLM performance in the domain of medicine</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="LAW">
      <data key="d4">1.0</data>
      <data key="d5">Few-shot examples are used to improve LLM performance in the domain of law</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="SINGLE EXTRACTION ROUND" target="EXTRACTION PROCESS">
      <data key="d4">1.0</data>
      <data key="d5">A single extraction round is part of the extraction process</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="DOMAIN" target="DOCUMENT CORPUS">
      <data key="d4">1.0</data>
      <data key="d5">Domain refers to the specific area of knowledge of the document corpus</data>
      <data key="d6">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
    </edge>
    <edge source="COVARIATE PROMPT" target="CLAIMS">
      <data key="d4">1.0</data>
      <data key="d5">Covariate prompts are used to extract claims linked to detected entities</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="CLAIMS" target="SOURCE TEXT SPAN">
      <data key="d4">1.0</data>
      <data key="d5">Source text span is an attribute of claims</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="CLAIMS" target="START DATE">
      <data key="d4">1.0</data>
      <data key="d5">Start date is an attribute of claims</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="CLAIMS" target="END DATE">
      <data key="d4">1.0</data>
      <data key="d5">End date is an attribute of claims</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="CLAIMS" target="DESCRIPTION">
      <data key="d4">1.0</data>
      <data key="d5">Description is an attribute of claims</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="CLAIMS" target="SUBJECT">
      <data key="d4">1.0</data>
      <data key="d5">Subject is an attribute of claims</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="CLAIMS" target="OBJECT">
      <data key="d4">1.0</data>
      <data key="d5">Object is an attribute of claims</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="COMMUNITIES OF ENTITIES" target="NOISY GRAPH STRUCTURE">
      <data key="d4">1.0</data>
      <data key="d5">Communities of entities help manage variations in a noisy graph structure</data>
      <data key="d6">2c6ed90897310eea2f28e33fff1c32b0</data>
    </edge>
    <edge source="COMMON ENTITY" target="HOMOGENEOUS NODES">
      <data key="d4">1.0</data>
      <data key="d5">Common entities are described using rich descriptive text for homogeneous nodes</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="LLMS" target="METRICS">
      <data key="d4">1.0</data>
      <data key="d5">LLMs are used to generate metrics for evaluating natural language generation</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="LLMS" target="WANG ET AL., 2023A">
      <data key="d4">1.0</data>
      <data key="d5">Wang et al. (2023) indicated the effectiveness of LLMs in evaluation</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="LLMS" target="ZHENG ET AL., 2024">
      <data key="d4">1.0</data>
      <data key="d5">Zheng et al. (2024) indicated the effectiveness of LLMs in evaluation</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="HOMOGENEOUS NODES" target="RELATIONSHIP EDGES">
      <data key="d4">1.0</data>
      <data key="d5">Relationship edges connect homogeneous nodes in a graph</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="RELATIONSHIP EDGES" target="EDGE WEIGHTS">
      <data key="d4">1.0</data>
      <data key="d5">Edge weights represent the normalized counts of detected relationship instances on relationship edges</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="COMMUNITY PARTITION">
      <data key="d4">1.0</data>
      <data key="d5">Each level of the hierarchical community structure provides a community partition</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="ROOT COMMUNITIES">
      <data key="d4">2.0</data>
      <data key="d5">Root communities are the top-level communities in a hierarchical community structure
Root communities are part of the hierarchical community structure</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="SUB-COMMUNITIES">
      <data key="d4">2.0</data>
      <data key="d5">Sub-communities are lower-level communities in a hierarchical community structure
Sub-communities are part of the hierarchical community structure</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="COMMUNITY LEVEL">
      <data key="d4">1.0</data>
      <data key="d5">Community levels are part of the hierarchical community structure</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="LEIDEN ALGORITHM">
      <data key="d4">1.0</data>
      <data key="d5">The Leiden algorithm is used to detect communities in the MultiHop-RAG dataset</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="OPENORD">
      <data key="d4">1.0</data>
      <data key="d5">OpenORD is used for node layout in the MultiHop-RAG dataset</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="FORCE ATLAS 2">
      <data key="d4">1.0</data>
      <data key="d5">Force Atlas 2 is used for node layout in the MultiHop-RAG dataset</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="NODE">
      <data key="d4">1.0</data>
      <data key="d5">Nodes represent entities in the MultiHop-RAG dataset</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="EDGE">
      <data key="d4">1.0</data>
      <data key="d5">Edges represent connections between nodes in the MultiHop-RAG dataset</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="COVARIATE">
      <data key="d4">1.0</data>
      <data key="d5">Covariates are variables linked to nodes and edges in the MultiHop-RAG dataset</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="TANG AND YANG">
      <data key="d4">2.0</data>
      <data key="d5">Tang and Yang are the authors associated with the MultiHop-RAG dataset</data>
      <data key="d6">922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="DATASET" target="QUESTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Questions are generated based on the target datasets</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="DATASET" target="N">
      <data key="d4">1.0</data>
      <data key="d5">N represents the number of test questions per dataset</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="DATASET" target="TABLE 1">
      <data key="d4">1.0</data>
      <data key="d5">Table 1 shows example questions for each of the two evaluation datasets</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="ROOT COMMUNITIES" target="HIERARCHICAL CLUSTERING">
      <data key="d4">1.0</data>
      <data key="d5">Root communities are identified through hierarchical clustering</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="ROOT COMMUNITIES" target="LEVEL 0">
      <data key="d4">1.0</data>
      <data key="d5">Level 0 represents the root-level communities in the hierarchical clustering</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="SUB-COMMUNITIES" target="REPORTS">
      <data key="d4">1.0</data>
      <data key="d5">Reports provide detailed information about specific subtopics within sub-communities</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="SUB-COMMUNITIES" target="HIERARCHICAL CLUSTERING">
      <data key="d4">1.0</data>
      <data key="d5">Sub-communities are identified through hierarchical clustering</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="SUB-COMMUNITIES" target="LEVEL 1">
      <data key="d4">1.0</data>
      <data key="d5">Level 1 represents sub-communities within the root-level communities</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="PARTITION" target="HIERARCHY">
      <data key="d4">1.0</data>
      <data key="d5">Partitions can be organized into a hierarchy</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="HIERARCHY" target="LEVEL 0">
      <data key="d4">1.0</data>
      <data key="d5">Level 0 is the root level in a hierarchy</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="HIERARCHY" target="LEVEL 1">
      <data key="d4">1.0</data>
      <data key="d5">Level 1 is a sub-level in a hierarchy</data>
      <data key="d6">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
    </edge>
    <edge source="LLM CONTEXT WINDOW" target="TOKEN LIMIT">
      <data key="d4">1.0</data>
      <data key="d5">The token limit defines the maximum number of tokens in the LLM context window</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="PROMINENCE" target="COMMUNITY EDGE">
      <data key="d4">1.0</data>
      <data key="d5">Prominence is used to prioritize community edges</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="PROMINENCE" target="COMBINED SOURCE AND TARGET NODE DEGREE">
      <data key="d4">1.0</data>
      <data key="d5">Combined source and target node degree is used to measure prominence</data>
      <data key="d6">843fc5421e086120ffa1c75856ecf6cd</data>
    </edge>
    <edge source="CHUNKS" target="TOKEN SIZE">
      <data key="d4">1.0</data>
      <data key="d5">Chunks are divided based on a pre-specified token size</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="HELPFULNESS SCORE" target="INTERMEDIATE ANSWERS">
      <data key="d4">1.0</data>
      <data key="d5">Helpfulness scores are assigned to intermediate answers</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="TECH JOURNALIST" target="TECH POLICY">
      <data key="d4">1.0</data>
      <data key="d5">Tech journalist is interested in episodes dealing with tech policy and government regulation</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="TECH JOURNALIST" target="PRIVACY LAWS">
      <data key="d4">1.0</data>
      <data key="d5">Tech journalist is interested in how guests perceive the impact of privacy laws on technology development</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="TECH JOURNALIST" target="INNOVATION AND ETHICS">
      <data key="d4">1.0</data>
      <data key="d5">Tech journalist is interested in discussions about the balance between innovation and ethical considerations</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="TECH JOURNALIST" target="POLICY CHANGES">
      <data key="d4">1.0</data>
      <data key="d5">Tech journalist is interested in suggested changes to current policies</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="TECH JOURNALIST" target="COLLABORATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Tech journalist is interested in discussions about collaborations between tech companies and governments</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="EDUCATOR" target="HEALTH TOPICS">
      <data key="d4">1.0</data>
      <data key="d5">Educator is interested in current topics in health that can be integrated into health education curricula</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="EDUCATOR" target="PREVENTIVE MEDICINE">
      <data key="d4">1.0</data>
      <data key="d5">Educator is interested in how news articles address the concepts of preventive medicine and wellness</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="EDUCATOR" target="CONTRADICTORY ARTICLES">
      <data key="d4">1.0</data>
      <data key="d5">Educator is interested in examples of health articles that contradict each other</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="EDUCATOR" target="PUBLIC HEALTH PRIORITIES">
      <data key="d4">1.0</data>
      <data key="d5">Educator is interested in insights about public health priorities based on news coverage</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="EDUCATOR" target="HEALTH LITERACY">
      <data key="d4">1.0</data>
      <data key="d5">Educator is interested in highlighting the importance of health literacy through the dataset</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="PROMPTS">
      <data key="d4">1.0</data>
      <data key="d5">The size of the context window and the prompts used for answer generation are the same across all conditions</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="TASK" target="USER">
      <data key="d4">1.0</data>
      <data key="d5">The task is an activity or goal that the user aims to achieve</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="TASK" target="QUESTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Questions are generated based on the user's task</data>
      <data key="d6">1d07b4248c2655081c7af0e373bd70c9</data>
    </edge>
    <edge source="QUESTIONS" target="DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">Datasets were used in combination with questions for the analysis</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="QUESTIONS" target="METRICS">
      <data key="d4">1.0</data>
      <data key="d5">Questions were evaluated using various metrics</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="MT-BENCH" target="ZHENG ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Zheng et al. are the authors associated with the MT-Bench dataset</data>
      <data key="d6">922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="MT-BENCH" target="ZHENG, L.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. is an author of the paper that discusses MT-Bench</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="MT-BENCH" target="CHIANG, W.-L.">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. is an author of the paper that discusses MT-Bench</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="MT-BENCH" target="SHENG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Sheng, Y. is an author of the paper that discusses MT-Bench</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="MT-BENCH" target="ZHUANG, S.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, S. is an author of the paper that discusses MT-Bench</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="MT-BENCH" target="WU, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Wu, Z. is an author of the paper that discusses MT-Bench</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="MT-BENCH" target="ZHUANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, Y. is an author of the paper that discusses MT-Bench</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="MT-BENCH" target="LIN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Lin, Z. is an author of the paper that discusses MT-Bench</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="MT-BENCH" target="LI, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Li, Z. is an author of the paper that discusses MT-Bench</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="MT-BENCH" target="LI, D.">
      <data key="d4">1.0</data>
      <data key="d5">Li, D. is an author of the paper that discusses MT-Bench</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="MT-BENCH" target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Xing, E. is an author of the paper that discusses MT-Bench</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="MT-BENCH" target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">MT-Bench and Chatbot Arena are both tools used in the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="DATA SENSEMAKING" target="KOESTEN ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Koesten et al. authored a paper on data sensemaking behaviors</data>
      <data key="d6">922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="XU AND LAPATA" target="LATENT SUMMARIZATION QUERIES">
      <data key="d4">2.0</data>
      <data key="d5">Xu and Lapata authored a paper on methods for extracting latent summarization queries from source texts</data>
      <data key="d6">922778ce1cb2fdd6dbab1746c8795620</data>
    </edge>
    <edge source="TEXT SUMMARIZATION" target="TS">
      <data key="d4">1.0</data>
      <data key="d5">Text summarization method applies a map-reduce approach directly to source texts (TS)</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="TEXT SUMMARIZATION" target="CONDITIONS">
      <data key="d4">1.0</data>
      <data key="d5">Text summarization is one of the conditions compared in the analysis</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="SEMANTIC SEARCH RAG" target="SS">
      <data key="d4">1.0</data>
      <data key="d5">Semantic search RAG is a na&#168;&#305;ve RAG approach where text chunks are retrieved and added to the context window until the token limit is reached (SS)</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="SEMANTIC SEARCH RAG" target="CONDITIONS">
      <data key="d4">1.0</data>
      <data key="d5">Semantic search RAG is one of the conditions compared in the analysis</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="C0" target="USER QUERIES">
      <data key="d4">1.0</data>
      <data key="d5">C0 uses root-level community summaries to answer user queries</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="C0" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C0 is a category used in the analysis of news articles</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="C0" target="PODCAST DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C0 is a category used in the analysis of the Podcast dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="C0" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C0 is a category used in the analysis of the News dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="C1" target="USER QUERIES">
      <data key="d4">1.0</data>
      <data key="d5">C1 uses high-level community summaries to answer user queries</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="C1" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C1 is a category used in the analysis of news articles</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="C1" target="TS">
      <data key="d4">1.0</data>
      <data key="d5">C1 showed slight improvements in answer comprehensiveness and diversity over TS</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="C1" target="PODCAST DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C1 is a category used in the analysis of the Podcast dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="C1" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C1 is a category used in the analysis of the News dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="C2" target="USER QUERIES">
      <data key="d4">1.0</data>
      <data key="d5">C2 uses intermediate-level community summaries to answer user queries</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="C2" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C2 is a category used in the analysis of news articles</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="C2" target="TS">
      <data key="d4">1.0</data>
      <data key="d5">C2 showed slight improvements in answer comprehensiveness and diversity over TS</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="C2" target="PODCAST DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C2 is a category used in the analysis of the Podcast dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="C2" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C2 is a category used in the analysis of the News dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="C3" target="USER QUERIES">
      <data key="d4">1.0</data>
      <data key="d5">C3 uses low-level community summaries to answer user queries</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="C3" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C3 is a category used in the analysis of news articles</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="C3" target="TS">
      <data key="d4">1.0</data>
      <data key="d5">C3 showed slight improvements in answer comprehensiveness and diversity over TS</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="C3" target="PODCAST DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C3 is a category used in the analysis of the Podcast dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="C3" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">C3 is a category used in the analysis of the News dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="TS" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">TS is a category used in the analysis of news articles</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="TS" target="PODCAST DATASET">
      <data key="d4">1.0</data>
      <data key="d5">TS is a category used in the analysis of the Podcast dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="TS" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">TS is a category used in the analysis of the News dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="SS" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">SS is a category used in the analysis of news articles</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="PODCAST DATASET" target="GLEANING">
      <data key="d4">1.0</data>
      <data key="d5">The graph indexing process used 1 gleaning for the Podcast dataset</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="PODCAST DATASET" target="GRAPH">
      <data key="d4">1.0</data>
      <data key="d5">A graph was created for the Podcast dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="PODCAST DATASET" target="UNITS">
      <data key="d4">1.0</data>
      <data key="d5">Units are used to measure the context in the Podcast dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="PODCAST DATASET" target="TOKENS">
      <data key="d4">1.0</data>
      <data key="d5">Tokens are used to measure the word count in the Podcast dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="PODCAST DATASET" target="% MAX">
      <data key="d4">1.0</data>
      <data key="d5">% Max is used to measure the percentage of maximum token count in the Podcast dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="PODCAST DATASET" target="INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">Intermediate-level summaries are derived from the Podcast dataset for analysis</data>
      <data key="d6">6f33a085ff3304e5994f7fbb86c881a4</data>
    </edge>
    <edge source="NEWS DATASET" target="GLEANING">
      <data key="d4">1.0</data>
      <data key="d5">The graph indexing process used 0 gleanings for the News dataset</data>
      <data key="d6">973164fa90bf2b4ee267f4fd795916bf</data>
    </edge>
    <edge source="NEWS DATASET" target="GRAPH">
      <data key="d4">1.0</data>
      <data key="d5">A graph was created for the News dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS DATASET" target="UNITS">
      <data key="d4">1.0</data>
      <data key="d5">Units are used to measure the context in the News dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS DATASET" target="TOKENS">
      <data key="d4">1.0</data>
      <data key="d5">Tokens are used to measure the word count in the News dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="NEWS DATASET" target="% MAX">
      <data key="d4">1.0</data>
      <data key="d5">% Max is used to measure the percentage of maximum token count in the News dataset</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="METRICS" target="DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">Datasets were evaluated using various metrics</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="WANG ET AL., 2023A" target="NATURAL LANGUAGE GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">Wang et al., 2023a discusses the state-of-the-art results achieved by Natural Language Generation</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="ZHENG ET AL., 2024" target="NATURAL LANGUAGE GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">Zheng et al., 2024 discusses the competitive results achieved by Natural Language Generation</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="ZHENG ET AL., 2024" target="LLM-AS-A-JUDGE">
      <data key="d4">1.0</data>
      <data key="d5">Zheng et al., 2024 discusses the LLM-as-a-judge method</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="USER QUERIES" target="EMBEDDING-BASED MATCHING">
      <data key="d4">1.0</data>
      <data key="d5">Embedding-based matching is used to match user queries</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="CONTEXT WINDOW SIZE" target="QUERY-TIME LLM USE">
      <data key="d4">1.0</data>
      <data key="d5">Query-time LLM use was evaluated with different context window sizes</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="CONTEXT WINDOW SIZE" target="FINAL EVALUATION">
      <data key="d4">2.0</data>
      <data key="d5">The final evaluation used a fixed context window size of 8k tokens
A fixed context window size of 8k tokens was used for the final evaluation</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="STATE-OF-THE-ART">
      <data key="d4">1.0</data>
      <data key="d5">Natural Language Generation achieves state-of-the-art results</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="COMPETITIVE RESULTS">
      <data key="d4">1.0</data>
      <data key="d5">Natural Language Generation achieves competitive results</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="HUMAN JUDGEMENTS">
      <data key="d4">1.0</data>
      <data key="d5">Natural Language Generation is compared against human judgements</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="REFERENCE-BASED METRICS">
      <data key="d4">1.0</data>
      <data key="d5">Natural Language Generation can generate reference-based metrics</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="REFERENCE-FREE STYLE">
      <data key="d4">1.0</data>
      <data key="d5">Natural Language Generation can measure qualities in a reference-free style</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="RAGAS" target="ES ET AL., 2023">
      <data key="d4">1.0</data>
      <data key="d5">Es et al., 2023 discusses the RAGAS method</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="RAGAS" target="CONTEXT RELEVANCE">
      <data key="d4">1.0</data>
      <data key="d5">RAGAS evaluates context relevance</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="RAGAS" target="FAITHFULNESS">
      <data key="d4">1.0</data>
      <data key="d5">RAGAS evaluates faithfulness</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="RAGAS" target="ANSWER RELEVANCE">
      <data key="d4">1.0</data>
      <data key="d5">RAGAS evaluates answer relevance</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="LLM EVALUATOR" target="DIRECTNESS">
      <data key="d4">1.0</data>
      <data key="d5">The LLM evaluator assesses answers based on the directness metric</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="LLM EVALUATOR" target="TABLE 2">
      <data key="d4">1.0</data>
      <data key="d5">Table 2 shows an example of LLM-generated assessment</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="LLM EVALUATOR" target="HEAD-TO-HEAD COMPARISON">
      <data key="d4">1.0</data>
      <data key="d5">The LLM evaluator uses a head-to-head comparison approach</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="LLM EVALUATOR" target="TARGET METRICS">
      <data key="d4">1.0</data>
      <data key="d5">The LLM evaluator assesses answers based on target metrics</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="LLM EVALUATOR" target="CONTROL METRIC">
      <data key="d4">1.0</data>
      <data key="d5">The LLM evaluator uses a control metric for validity</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="LLM EVALUATOR" target="STOCHASTICITY">
      <data key="d4">1.0</data>
      <data key="d5">The LLM evaluator accounts for stochasticity</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="LLM EVALUATOR" target="MEAN SCORES">
      <data key="d4">1.0</data>
      <data key="d5">The LLM evaluator uses mean scores from multiple comparisons</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="DIRECTNESS" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Directness is used to evaluate the straightforwardness of the generated answers for news articles</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="QUESTION" target="PUBLIC FIGURES">
      <data key="d4">1.0</data>
      <data key="d5">The question asks about public figures mentioned in entertainment articles</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ENTERTAINMENT ARTICLES">
      <data key="d4">1.0</data>
      <data key="d5">Public figures are repeatedly mentioned across various entertainment articles</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ANSWER 1">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 covers a wide range of public figures from different sectors of the entertainment industry.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ANSWER 2">
      <data key="d4">1.0</data>
      <data key="d5">Answer 2 focuses on a smaller group of public figures, primarily from the music industry and sports.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="CONTROVERSIES">
      <data key="d4">1.0</data>
      <data key="d5">Controversies involve public figures and impact public discourse.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="ENTERTAINMENT INDUSTRY">
      <data key="d4">1.0</data>
      <data key="d5">Entertainment articles cover topics related to the entertainment industry</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="TAYLOR SWIFT">
      <data key="d4">1.0</data>
      <data key="d5">Taylor Swift is frequently mentioned in entertainment articles</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="TRAVIS KELCE">
      <data key="d4">1.0</data>
      <data key="d5">Travis Kelce is frequently mentioned in entertainment articles</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="BRITNEY SPEARS">
      <data key="d4">1.0</data>
      <data key="d5">Britney Spears is frequently mentioned in entertainment articles</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="JUSTIN TIMBERLAKE">
      <data key="d4">1.0</data>
      <data key="d5">Justin Timberlake is frequently mentioned in entertainment articles</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="TAYLOR SWIFT">
      <data key="d4">1.0</data>
      <data key="d5">Taylor Swift is a significant figure in the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="TRAVIS KELCE">
      <data key="d4">1.0</data>
      <data key="d5">Travis Kelce is a significant figure in the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="BRITNEY SPEARS">
      <data key="d4">1.0</data>
      <data key="d5">Britney Spears is a significant figure in the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="JUSTIN TIMBERLAKE">
      <data key="d4">1.0</data>
      <data key="d5">Justin Timberlake is a significant figure in the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="ACTORS AND DIRECTORS">
      <data key="d4">1.0</data>
      <data key="d5">Actors and Directors are a category within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="MUSICIANS AND EXECUTIVES">
      <data key="d4">1.0</data>
      <data key="d5">Musicians and Executives are a category within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="ATHLETES AND COACHES">
      <data key="d4">1.0</data>
      <data key="d5">Athletes and Coaches are a category within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="INFLUENCERS AND ENTREPRENEURS">
      <data key="d4">1.0</data>
      <data key="d5">Influencers and Entrepreneurs are a category within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="PUBLIC FIGURES IN CONTROVERSY">
      <data key="d4">1.0</data>
      <data key="d5">Public Figures in Controversy are a category within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="FILM">
      <data key="d4">1.0</data>
      <data key="d5">Film is a sector within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="TELEVISION">
      <data key="d4">1.0</data>
      <data key="d5">Television is a sector within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="MUSIC">
      <data key="d4">1.0</data>
      <data key="d5">Music is a sector within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="SPORTS">
      <data key="d4">1.0</data>
      <data key="d5">Sports is a sector within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="DIGITAL MEDIA">
      <data key="d4">1.0</data>
      <data key="d5">Digital Media is a sector within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="CULTURAL NARRATIVES">
      <data key="d4">1.0</data>
      <data key="d5">Cultural Narratives are a category within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="TRENDS">
      <data key="d4">1.0</data>
      <data key="d5">Trends are a category within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="SOCIAL DISCUSSIONS">
      <data key="d4">1.0</data>
      <data key="d5">Social Discussions are a category within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="PUBLIC DISCOURSE">
      <data key="d4">1.0</data>
      <data key="d5">Public Discourse is a category within the entertainment industry</data>
      <data key="d6">e8c8f911135faf3ff35f24107eb3f99c</data>
    </edge>
    <edge source="REFERENCE-BASED METRICS" target="GOLD STANDARD ANSWERS">
      <data key="d4">1.0</data>
      <data key="d5">Reference-based metrics require gold standard answers</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="GOLD STANDARD ANSWERS" target="SENSEMAKING QUESTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Gold standard answers are lacking for sensemaking questions</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="SENSEMAKING QUESTIONS" target="END USERS">
      <data key="d4">3.0</data>
      <data key="d5">End users validate sensemaking questions and target metrics
Sensemaking questions are validated with end users</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65,e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="TARGET METRICS" target="END USERS">
      <data key="d4">1.0</data>
      <data key="d5">Target metrics are validated with end users</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="CONTROL METRIC" target="VALIDITY">
      <data key="d4">1.0</data>
      <data key="d5">The control metric is used as an indicator of validity</data>
      <data key="d6">322e02986c8724eedbcf3ebfa20b989c</data>
    </edge>
    <edge source="TAYLOR SWIFT" target="ANSWER 2">
      <data key="d4">1.0</data>
      <data key="d5">Taylor Swift is one of the specific public figures mentioned in Answer 2.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="TAYLOR SWIFT" target="MUSIC">
      <data key="d4">1.0</data>
      <data key="d5">Taylor Swift is a public figure in the music sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="TRAVIS KELCE" target="ANSWER 2">
      <data key="d4">1.0</data>
      <data key="d5">Travis Kelce is one of the specific public figures mentioned in Answer 2.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="TRAVIS KELCE" target="SPORTS">
      <data key="d4">1.0</data>
      <data key="d5">Travis Kelce is a public figure in the sports sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="ANSWER 2">
      <data key="d4">1.0</data>
      <data key="d5">Britney Spears is one of the specific public figures mentioned in Answer 2.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="MUSIC">
      <data key="d4">1.0</data>
      <data key="d5">Britney Spears is a public figure in the music sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="ANSWER 2">
      <data key="d4">1.0</data>
      <data key="d5">Justin Timberlake is one of the specific public figures mentioned in Answer 2.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="MUSIC">
      <data key="d4">1.0</data>
      <data key="d5">Justin Timberlake is a public figure in the music sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="FILM" target="ANSWER 1">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 includes public figures from the film sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="TELEVISION" target="ANSWER 1">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 includes public figures from the television sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="MUSIC" target="ANSWER 1">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 includes public figures from the music sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="MUSIC" target="ANSWER 2">
      <data key="d4">1.0</data>
      <data key="d5">Answer 2 focuses on public figures primarily from the music sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="SPORTS" target="ANSWER 1">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 includes public figures from the sports sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="SPORTS" target="ANSWER 2">
      <data key="d4">1.0</data>
      <data key="d5">Answer 2 focuses on public figures primarily from the sports sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="DIGITAL MEDIA" target="ANSWER 1">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 includes public figures from the digital media sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="ANSWER 1" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 cites specific data sources from the News article dataset for each mentioned figure.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="ANSWER 1" target="CONTROVERSIES">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 provides insights into controversies involving public figures and their impact on public discourse.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="ANSWER 1" target="GAMING">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 includes public figures from the gaming sector.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="ANSWER 1" target="DATA SOURCES">
      <data key="d4">1.0</data>
      <data key="d5">Answer 1 cites specific data sources for each mentioned figure.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="ANSWER 2" target="NA&#207;VE RAG">
      <data key="d4">1.0</data>
      <data key="d5">Answer 2 was generated using the Na&#239;ve RAG method, which directly lists specific public figures who are repeatedly mentioned across various entertainment articles.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="ANSWER 2" target="NEWS ARTICLE DATASET">
      <data key="d4">2.0</data>
      <data key="d5">Answer 2 relies heavily on a single source from the News article dataset for data.
Answer 2 is a generated answer for a question in the News article dataset</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d,ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="ANSWER 2" target="DATA SOURCES">
      <data key="d4">1.0</data>
      <data key="d5">Answer 2 relies heavily on a single data source.</data>
      <data key="d6">718017a4871c909420f84b85b8ba969d</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="NEWS ARTICLE DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Na&#239;ve RAG is used to generate answers for questions in the News article dataset</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="GLOBAL APPROACH TO GRAPH RAG">
      <data key="d4">1.0</data>
      <data key="d5">The global approach to Graph RAG shows improvements over na&#239;ve RAG</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="NEWS ARTICLE DATASET" target="LLM-GENERATED ASSESSMENTS">
      <data key="d4">1.0</data>
      <data key="d5">LLM-generated assessments are used to evaluate the answers produced for questions in the News article dataset</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="NEWS ARTICLE DATASET" target="EXAMPLE QUESTION">
      <data key="d4">1.0</data>
      <data key="d5">Example question is part of the News article dataset used for analysis</data>
      <data key="d6">ebf5249c888e07fedce6572a4c03f88c</data>
    </edge>
    <edge source="HEAD-TO-HEAD WIN RATE" target="CONDITION">
      <data key="d4">1.0</data>
      <data key="d5">Head-to-head win rate percentages were used to compare different conditions</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="CONDITION" target="WIN RATE">
      <data key="d4">1.0</data>
      <data key="d5">Win rate percentages were used to measure the performance of different conditions</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="CONDITION" target="OVERALL WINNER">
      <data key="d4">1.0</data>
      <data key="d5">The overall winner per dataset and metric was determined for each condition</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="CONDITION" target="SELF-WIN RATE">
      <data key="d4">1.0</data>
      <data key="d5">Self-win rates were shown as the expected 50% for each condition</data>
      <data key="d6">4c855404ee3d3c94aa2136f1513c666f</data>
    </edge>
    <edge source="INDEXING PROCESS" target="GRAPH">
      <data key="d4">1.0</data>
      <data key="d5">The indexing process resulted in the creation of graphs</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="TOKENS" target="MAP-REDUCE SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Map-reduce summarization requires the highest number of context tokens</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="TOKENS" target="ROOT-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">Root-level community summaries require dramatically fewer tokens per query</data>
      <data key="d6">36db32c37e1987e2c5863898ad882190</data>
    </edge>
    <edge source="VECTOR SPACE" target="QUERIES">
      <data key="d4">2.0</data>
      <data key="d5">Queries are embedded into the same vector space as text chunks to find relevant context</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="SELF-MEMORY (SELFMEM)" target="GENERATION-AUGMENTED RETRIEVAL (GAR)">
      <data key="d4">2.0</data>
      <data key="d5">Self-memory is related to generation-augmented retrieval</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="MULTI-DOCUMENT SUMMARIZATION" target="MULTI-DOCUMENT SUMMARIZATION (CAIRE-COVID)">
      <data key="d4">2.0</data>
      <data key="d5">CAiRE-COVID is a system for multi-document summarization</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="MULTI-HOP QUESTION ANSWERING" target="MULTI-HOP QUESTION ANSWERING (ITRG)">
      <data key="d4">2.0</data>
      <data key="d5">ITRG is a system for multi-hop question answering</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="MULTI-HOP QUESTION ANSWERING" target="MULTI-HOP QUESTION ANSWERING (IR-COT)">
      <data key="d4">2.0</data>
      <data key="d5">IR-CoT is a system for multi-hop question answering</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="MULTI-HOP QUESTION ANSWERING" target="MULTI-HOP QUESTION ANSWERING (DSP)">
      <data key="d4">2.0</data>
      <data key="d5">DSP is a system for multi-hop question answering</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="HIERARCHICAL INDEX" target="RAPTOR">
      <data key="d4">2.0</data>
      <data key="d5">RAPTOR is a method for generating a hierarchical index</data>
      <data key="d6">f35de4d9fb65f1d5a392064b20545c19</data>
    </edge>
    <edge source="KAPING" target="BAEK ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Baek et al. discusses the KAPING method</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="G-RETRIEVER" target="HE ET AL., 2024">
      <data key="d4">2.0</data>
      <data key="d5">The paper by He et al. discusses the G-Retriever method</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="GRAPH-TOOLFORMER" target="ZHANG, 2023">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Zhang discusses the Graph-ToolFormer method</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="SURGE" target="KANG ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Kang et al. discusses the SURGE method</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="FABULA" target="RANADE AND JOSHI, 2023">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Ranade and Joshi discusses the FABULA method</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="LANGCHAIN" target="LLAMAINDEX">
      <data key="d4">2.0</data>
      <data key="d5">Both LangChain and LlamaIndex support a variety of graph databases</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="LANGCHAIN" target="NEO4J">
      <data key="d4">2.0</data>
      <data key="d5">LangChain supports graph databases in Neo4J format</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="LANGCHAIN" target="NEBULAGRAPH">
      <data key="d4">2.0</data>
      <data key="d5">LangChain supports graph databases in NebulaGraph format</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="LANGCHAIN" target="LANGCHAIN GRAPHS">
      <data key="d4">1.0</data>
      <data key="d5">LangChain developed Langchain graphs</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LLAMAINDEX" target="NEO4J">
      <data key="d4">2.0</data>
      <data key="d5">LlamaIndex supports graph databases in Neo4J format</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="LLAMAINDEX" target="NEBULAGRAPH">
      <data key="d4">2.0</data>
      <data key="d5">LlamaIndex supports graph databases in NebulaGraph format</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="NEO4J" target="NALLM">
      <data key="d4">2.0</data>
      <data key="d5">NaLLM is a method that can create and reason over knowledge graphs in Neo4J format</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="NEO4J" target="PROJECT NALLM">
      <data key="d4">2.0</data>
      <data key="d5">Neo4J developed Project NaLLM</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="NEBULAGRAPH" target="GRAPHRAG">
      <data key="d4">2.0</data>
      <data key="d5">GraphRAG is a method that can create and reason over knowledge graphs in NebulaGraph format</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="SELFCHECKGPT" target="MANAKUL ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">The paper by Manakul et al. discusses the SelfCheckGPT method</data>
      <data key="d6">92e93fc6449756c0a60200636b297f65</data>
    </edge>
    <edge source="MANAKUL ET AL., 2023" target="SELFHECKGPT">
      <data key="d4">1.0</data>
      <data key="d5">SelfCheckGPT is an approach mentioned in the work by Manakul et al., 2023</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="SELFHECKGPT" target="FABRICATION RATES">
      <data key="d4">1.0</data>
      <data key="d5">SelfCheckGPT is used to compare fabrication rates</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="EMBEDDING-BASED MATCHING" target="GRAPH ANNOTATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Embedding-based matching is used to match user queries with graph annotations</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="HYBRID RAG SCHEMES" target="COMMUNITY REPORTS">
      <data key="d4">1.0</data>
      <data key="d5">Hybrid RAG schemes combine embedding-based matching against community reports</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="MAP-REDUCE SUMMARIZATION MECHANISMS" target="ROLL-UP OPERATION">
      <data key="d4">1.0</data>
      <data key="d5">The roll-up operation can be extended using map-reduce summarization mechanisms</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="COMMUNITY HIERARCHY" target="DRILL DOWN MECHANISM">
      <data key="d4">1.0</data>
      <data key="d5">The drill down mechanism follows the information scent in the community hierarchy</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="GLOBAL APPROACH TO GRAPH RAG" target="TOKEN COST">
      <data key="d4">1.0</data>
      <data key="d5">The global approach to Graph RAG achieves competitive performance at a fraction of the token cost</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="PYTHON-BASED IMPLEMENTATION" target="OPEN-SOURCE IMPLEMENTATION">
      <data key="d4">1.0</data>
      <data key="d5">The open-source implementation of Graph RAG approaches is Python-based</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="DRILL DOWN MECHANISM" target="INFORMATION SCENT">
      <data key="d4">1.0</data>
      <data key="d5">The drill down mechanism follows the information scent</data>
      <data key="d6">e4d9b12cf2b4c691c74019eefff4fb39</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="AMBER HOAK">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Amber Hoak both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Andr&#233;s Morales Esquivel both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="BEN CUTLER">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Ben Cutler both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="BILLIE RINALDI">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Billie Rinaldi both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="CHRIS SANCHEZ">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Chris Sanchez both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="CHRIS TREVINO">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Chris Trevino both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="CHRISTINE CAGGIANO">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Christine Caggiano both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="DAVID TITTSWORTH">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and David Tittsworth both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="DAYENNE DE SOUZA">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Dayenne de Souza both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="DOUGLAS ORBAKER">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Douglas Orbaker both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="ED CLARK">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Ed Clark both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="GABRIEL NIEVES-PONCE">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Gabriel Nieves-Ponce both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="GAUDY BLANCO MENESES">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Gaudy Blanco Meneses both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="KATE LYTVYNETS">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Kate Lytvynets both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="KATY SMITH">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Katy Smith both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="M&#211;NICA CARVAJAL">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and M&#243;nica Carvajal both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="NATHAN EVANS">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Nathan Evans both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="RICHARD ORTEGA">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Richard Ortega both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="RODRIGO RACANICCI">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Rodrigo Racanicci both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="SARAH SMITH">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Sarah Smith both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="SHANE SOLOMON">
      <data key="d4">1.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Shane Solomon both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Andr&#233;s Morales Esquivel both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="BEN CUTLER">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Ben Cutler both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="BILLIE RINALDI">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Billie Rinaldi both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="CHRIS SANCHEZ">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Chris Sanchez both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="CHRIS TREVINO">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Chris Trevino both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="CHRISTINE CAGGIANO">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Christine Caggiano both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="DAVID TITTSWORTH">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and David Tittsworth both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="DAYENNE DE SOUZA">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Dayenne de Souza both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="DOUGLAS ORBAKER">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Douglas Orbaker both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="ED CLARK">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Ed Clark both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="GABRIEL NIEVES-PONCE">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Gabriel Nieves-Ponce both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="GAUDY BLANCO MENESES">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Gaudy Blanco Meneses both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="KATE LYTVYNETS">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Kate Lytvynets both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="KATY SMITH">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Katy Smith both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="M&#211;NICA CARVAJAL">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and M&#243;nica Carvajal both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="NATHAN EVANS">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Nathan Evans both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="RICHARD ORTEGA">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Richard Ortega both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="AMBER HOAK" target="RODRIGO RACANICCI">
      <data key="d4">1.0</data>
      <data key="d5">Amber Hoak and Rodrigo Racanicci both contributed to the work acknowledged in the document</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ACHIAM" target="S. ADLER">
      <data key="d4">1.0</data>
      <data key="d5">J. Achiam and S. Adler co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ACHIAM" target="S. AGARWAL">
      <data key="d4">1.0</data>
      <data key="d5">J. Achiam and S. Agarwal co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ACHIAM" target="L. AHMAD">
      <data key="d4">1.0</data>
      <data key="d5">J. Achiam and L. Ahmad co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ACHIAM" target="I. AKKAYA">
      <data key="d4">1.0</data>
      <data key="d5">J. Achiam and I. Akkaya co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ACHIAM" target="F. L. ALEMAN">
      <data key="d4">1.0</data>
      <data key="d5">J. Achiam and F. L. Aleman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ACHIAM" target="D. ALMEIDA">
      <data key="d4">1.0</data>
      <data key="d5">J. Achiam and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ACHIAM" target="J. ALTENSCHMIDT">
      <data key="d4">1.0</data>
      <data key="d5">J. Achiam and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ACHIAM" target="S. ALTMAN">
      <data key="d4">1.0</data>
      <data key="d5">J. Achiam and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ACHIAM" target="S. ANADKAT">
      <data key="d4">1.0</data>
      <data key="d5">J. Achiam and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. ADLER" target="S. AGARWAL">
      <data key="d4">1.0</data>
      <data key="d5">S. Adler and S. Agarwal co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. ADLER" target="L. AHMAD">
      <data key="d4">1.0</data>
      <data key="d5">S. Adler and L. Ahmad co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. ADLER" target="I. AKKAYA">
      <data key="d4">1.0</data>
      <data key="d5">S. Adler and I. Akkaya co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. ADLER" target="F. L. ALEMAN">
      <data key="d4">1.0</data>
      <data key="d5">S. Adler and F. L. Aleman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. ADLER" target="D. ALMEIDA">
      <data key="d4">1.0</data>
      <data key="d5">S. Adler and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. ADLER" target="J. ALTENSCHMIDT">
      <data key="d4">1.0</data>
      <data key="d5">S. Adler and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. ADLER" target="S. ALTMAN">
      <data key="d4">1.0</data>
      <data key="d5">S. Adler and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. ADLER" target="S. ANADKAT">
      <data key="d4">1.0</data>
      <data key="d5">S. Adler and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. AGARWAL" target="L. AHMAD">
      <data key="d4">1.0</data>
      <data key="d5">S. Agarwal and L. Ahmad co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. AGARWAL" target="I. AKKAYA">
      <data key="d4">1.0</data>
      <data key="d5">S. Agarwal and I. Akkaya co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. AGARWAL" target="F. L. ALEMAN">
      <data key="d4">1.0</data>
      <data key="d5">S. Agarwal and F. L. Aleman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. AGARWAL" target="D. ALMEIDA">
      <data key="d4">1.0</data>
      <data key="d5">S. Agarwal and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. AGARWAL" target="J. ALTENSCHMIDT">
      <data key="d4">1.0</data>
      <data key="d5">S. Agarwal and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. AGARWAL" target="S. ALTMAN">
      <data key="d4">1.0</data>
      <data key="d5">S. Agarwal and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. AGARWAL" target="S. ANADKAT">
      <data key="d4">1.0</data>
      <data key="d5">S. Agarwal and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="L. AHMAD" target="I. AKKAYA">
      <data key="d4">1.0</data>
      <data key="d5">L. Ahmad and I. Akkaya co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="L. AHMAD" target="F. L. ALEMAN">
      <data key="d4">1.0</data>
      <data key="d5">L. Ahmad and F. L. Aleman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="L. AHMAD" target="D. ALMEIDA">
      <data key="d4">1.0</data>
      <data key="d5">L. Ahmad and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="L. AHMAD" target="J. ALTENSCHMIDT">
      <data key="d4">1.0</data>
      <data key="d5">L. Ahmad and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="L. AHMAD" target="S. ALTMAN">
      <data key="d4">1.0</data>
      <data key="d5">L. Ahmad and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="L. AHMAD" target="S. ANADKAT">
      <data key="d4">1.0</data>
      <data key="d5">L. Ahmad and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="I. AKKAYA" target="F. L. ALEMAN">
      <data key="d4">1.0</data>
      <data key="d5">I. Akkaya and F. L. Aleman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="I. AKKAYA" target="D. ALMEIDA">
      <data key="d4">1.0</data>
      <data key="d5">I. Akkaya and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="I. AKKAYA" target="J. ALTENSCHMIDT">
      <data key="d4">1.0</data>
      <data key="d5">I. Akkaya and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="I. AKKAYA" target="S. ALTMAN">
      <data key="d4">1.0</data>
      <data key="d5">I. Akkaya and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="I. AKKAYA" target="S. ANADKAT">
      <data key="d4">1.0</data>
      <data key="d5">I. Akkaya and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="F. L. ALEMAN" target="D. ALMEIDA">
      <data key="d4">1.0</data>
      <data key="d5">F. L. Aleman and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="F. L. ALEMAN" target="J. ALTENSCHMIDT">
      <data key="d4">1.0</data>
      <data key="d5">F. L. Aleman and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="F. L. ALEMAN" target="S. ALTMAN">
      <data key="d4">1.0</data>
      <data key="d5">F. L. Aleman and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="F. L. ALEMAN" target="S. ANADKAT">
      <data key="d4">1.0</data>
      <data key="d5">F. L. Aleman and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="D. ALMEIDA" target="J. ALTENSCHMIDT">
      <data key="d4">1.0</data>
      <data key="d5">D. Almeida and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="D. ALMEIDA" target="S. ALTMAN">
      <data key="d4">1.0</data>
      <data key="d5">D. Almeida and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="D. ALMEIDA" target="S. ANADKAT">
      <data key="d4">1.0</data>
      <data key="d5">D. Almeida and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ALTENSCHMIDT" target="S. ALTMAN">
      <data key="d4">1.0</data>
      <data key="d5">J. Altenschmidt and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. ALTENSCHMIDT" target="S. ANADKAT">
      <data key="d4">1.0</data>
      <data key="d5">J. Altenschmidt and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. ALTMAN" target="S. ANADKAT">
      <data key="d4">1.0</data>
      <data key="d5">S. Altman and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. ANIL" target="S. BORGEAUD">
      <data key="d4">1.0</data>
      <data key="d5">R. Anil and S. Borgeaud co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. ANIL" target="Y. WU">
      <data key="d4">1.0</data>
      <data key="d5">R. Anil and Y. Wu co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. ANIL" target="J.-B. ALAYRAC">
      <data key="d4">1.0</data>
      <data key="d5">R. Anil and J.-B. Alayrac co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. ANIL" target="J. YU">
      <data key="d4">1.0</data>
      <data key="d5">R. Anil and J. Yu co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. ANIL" target="R. SORICUT">
      <data key="d4">1.0</data>
      <data key="d5">R. Anil and R. Soricut co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. ANIL" target="J. SCHALKWYK">
      <data key="d4">1.0</data>
      <data key="d5">R. Anil and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. ANIL" target="A. M. DAI">
      <data key="d4">1.0</data>
      <data key="d5">R. Anil and A. M. Dai co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. ANIL" target="A. HAUTH">
      <data key="d4">1.0</data>
      <data key="d5">R. Anil and A. Hauth co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. BORGEAUD" target="Y. WU">
      <data key="d4">1.0</data>
      <data key="d5">S. Borgeaud and Y. Wu co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. BORGEAUD" target="J.-B. ALAYRAC">
      <data key="d4">1.0</data>
      <data key="d5">S. Borgeaud and J.-B. Alayrac co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. BORGEAUD" target="J. YU">
      <data key="d4">1.0</data>
      <data key="d5">S. Borgeaud and J. Yu co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. BORGEAUD" target="R. SORICUT">
      <data key="d4">1.0</data>
      <data key="d5">S. Borgeaud and R. Soricut co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. BORGEAUD" target="J. SCHALKWYK">
      <data key="d4">1.0</data>
      <data key="d5">S. Borgeaud and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. BORGEAUD" target="A. M. DAI">
      <data key="d4">1.0</data>
      <data key="d5">S. Borgeaud and A. M. Dai co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="S. BORGEAUD" target="A. HAUTH">
      <data key="d4">1.0</data>
      <data key="d5">S. Borgeaud and A. Hauth co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="Y. WU" target="J.-B. ALAYRAC">
      <data key="d4">1.0</data>
      <data key="d5">Y. Wu and J.-B. Alayrac co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="Y. WU" target="J. YU">
      <data key="d4">1.0</data>
      <data key="d5">Y. Wu and J. Yu co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="Y. WU" target="R. SORICUT">
      <data key="d4">1.0</data>
      <data key="d5">Y. Wu and R. Soricut co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="Y. WU" target="J. SCHALKWYK">
      <data key="d4">1.0</data>
      <data key="d5">Y. Wu and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="Y. WU" target="A. M. DAI">
      <data key="d4">1.0</data>
      <data key="d5">Y. Wu and A. M. Dai co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="Y. WU" target="A. HAUTH">
      <data key="d4">1.0</data>
      <data key="d5">Y. Wu and A. Hauth co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J.-B. ALAYRAC" target="J. YU">
      <data key="d4">1.0</data>
      <data key="d5">J.-B. Alayrac and J. Yu co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J.-B. ALAYRAC" target="R. SORICUT">
      <data key="d4">1.0</data>
      <data key="d5">J.-B. Alayrac and R. Soricut co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J.-B. ALAYRAC" target="J. SCHALKWYK">
      <data key="d4">1.0</data>
      <data key="d5">J.-B. Alayrac and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J.-B. ALAYRAC" target="A. M. DAI">
      <data key="d4">1.0</data>
      <data key="d5">J.-B. Alayrac and A. M. Dai co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J.-B. ALAYRAC" target="A. HAUTH">
      <data key="d4">1.0</data>
      <data key="d5">J.-B. Alayrac and A. Hauth co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. YU" target="R. SORICUT">
      <data key="d4">1.0</data>
      <data key="d5">J. Yu and R. Soricut co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. YU" target="J. SCHALKWYK">
      <data key="d4">1.0</data>
      <data key="d5">J. Yu and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. YU" target="A. M. DAI">
      <data key="d4">1.0</data>
      <data key="d5">J. Yu and A. M. Dai co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. YU" target="A. HAUTH">
      <data key="d4">1.0</data>
      <data key="d5">J. Yu and A. Hauth co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. SORICUT" target="J. SCHALKWYK">
      <data key="d4">1.0</data>
      <data key="d5">R. Soricut and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. SORICUT" target="A. M. DAI">
      <data key="d4">1.0</data>
      <data key="d5">R. Soricut and A. M. Dai co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="R. SORICUT" target="A. HAUTH">
      <data key="d4">1.0</data>
      <data key="d5">R. Soricut and A. Hauth co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. SCHALKWYK" target="A. M. DAI">
      <data key="d4">1.0</data>
      <data key="d5">J. Schalkwyk and A. M. Dai co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. SCHALKWYK" target="A. HAUTH">
      <data key="d4">1.0</data>
      <data key="d5">J. Schalkwyk and A. Hauth co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="A. M. DAI" target="A. HAUTH">
      <data key="d4">1.0</data>
      <data key="d5">A. M. Dai and A. Hauth co-authored the Gemini paper</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. BAEK" target="A. F. AJI">
      <data key="d4">1.0</data>
      <data key="d5">J. Baek and A. F. Aji co-authored the paper on knowledge-augmented language model prompting</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="J. BAEK" target="A. SAFFARI">
      <data key="d4">1.0</data>
      <data key="d5">J. Baek and A. Saffari co-authored the paper on knowledge-augmented language model prompting</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="A. F. AJI" target="A. SAFFARI">
      <data key="d4">1.0</data>
      <data key="d5">A. F. Aji and A. Saffari co-authored the paper on knowledge-augmented language model prompting</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="T. BAN" target="L. CHEN">
      <data key="d4">1.0</data>
      <data key="d5">T. Ban and L. Chen co-authored the paper on query tools to causal architects</data>
      <data key="d6">086021a89900a39bcb62036981737bfa</data>
    </edge>
    <edge source="BAUMEL, T." target="EYAL, M.">
      <data key="d4">1.0</data>
      <data key="d5">Baumel, T. and Eyal, M. co-authored the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BAUMEL, T." target="ELHADAD, M.">
      <data key="d4">1.0</data>
      <data key="d5">Baumel, T. and Elhadad, M. co-authored the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BAUMEL, T." target="ARXIV:1801.07704">
      <data key="d4">1.0</data>
      <data key="d5">Baumel, T. is an author of the paper with arXiv identifier 1801.07704</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="EYAL, M." target="ELHADAD, M.">
      <data key="d4">1.0</data>
      <data key="d5">Eyal, M. and Elhadad, M. co-authored the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="EYAL, M." target="ARXIV:1801.07704">
      <data key="d4">1.0</data>
      <data key="d5">Eyal, M. is an author of the paper with arXiv identifier 1801.07704</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ELHADAD, M." target="ARXIV:1801.07704">
      <data key="d4">1.0</data>
      <data key="d5">Elhadad, M. is an author of the paper with arXiv identifier 1801.07704</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BLONDEL, V. D." target="GUILLAUME, J.-L.">
      <data key="d4">1.0</data>
      <data key="d5">Blondel, V. D. and Guillaume, J.-L. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BLONDEL, V. D." target="LAMBIOTTE, R.">
      <data key="d4">1.0</data>
      <data key="d5">Blondel, V. D. and Lambiotte, R. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BLONDEL, V. D." target="LEFEBVRE, E.">
      <data key="d4">1.0</data>
      <data key="d5">Blondel, V. D. and Lefebvre, E. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="GUILLAUME, J.-L." target="LAMBIOTTE, R.">
      <data key="d4">1.0</data>
      <data key="d5">Guillaume, J.-L. and Lambiotte, R. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="GUILLAUME, J.-L." target="LEFEBVRE, E.">
      <data key="d4">1.0</data>
      <data key="d5">Guillaume, J.-L. and Lefebvre, E. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="LAMBIOTTE, R." target="LEFEBVRE, E.">
      <data key="d4">1.0</data>
      <data key="d5">Lambiotte, R. and Lefebvre, E. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BROWN, T." target="MANN, B.">
      <data key="d4">1.0</data>
      <data key="d5">Brown, T. and Mann, B. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BROWN, T." target="RYDER, N.">
      <data key="d4">1.0</data>
      <data key="d5">Brown, T. and Ryder, N. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BROWN, T." target="SUBBIAH, M.">
      <data key="d4">1.0</data>
      <data key="d5">Brown, T. and Subbiah, M. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BROWN, T." target="KAPLAN, J. D.">
      <data key="d4">1.0</data>
      <data key="d5">Brown, T. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BROWN, T." target="DHARIWAL, P.">
      <data key="d4">1.0</data>
      <data key="d5">Brown, T. and Dhariwal, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BROWN, T." target="NEELAKANTAN, A.">
      <data key="d4">1.0</data>
      <data key="d5">Brown, T. and Neelakantan, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BROWN, T." target="SHYAM, P.">
      <data key="d4">1.0</data>
      <data key="d5">Brown, T. and Shyam, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BROWN, T." target="SASTRY, G.">
      <data key="d4">1.0</data>
      <data key="d5">Brown, T. and Sastry, G. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="BROWN, T." target="ASKELL, A.">
      <data key="d4">1.0</data>
      <data key="d5">Brown, T. and Askell, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="MANN, B." target="RYDER, N.">
      <data key="d4">1.0</data>
      <data key="d5">Mann, B. and Ryder, N. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="MANN, B." target="SUBBIAH, M.">
      <data key="d4">1.0</data>
      <data key="d5">Mann, B. and Subbiah, M. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="MANN, B." target="KAPLAN, J. D.">
      <data key="d4">1.0</data>
      <data key="d5">Mann, B. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="MANN, B." target="DHARIWAL, P.">
      <data key="d4">1.0</data>
      <data key="d5">Mann, B. and Dhariwal, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="MANN, B." target="NEELAKANTAN, A.">
      <data key="d4">1.0</data>
      <data key="d5">Mann, B. and Neelakantan, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="MANN, B." target="SHYAM, P.">
      <data key="d4">1.0</data>
      <data key="d5">Mann, B. and Shyam, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="MANN, B." target="SASTRY, G.">
      <data key="d4">1.0</data>
      <data key="d5">Mann, B. and Sastry, G. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="MANN, B." target="ASKELL, A.">
      <data key="d4">1.0</data>
      <data key="d5">Mann, B. and Askell, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="RYDER, N." target="SUBBIAH, M.">
      <data key="d4">1.0</data>
      <data key="d5">Ryder, N. and Subbiah, M. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="RYDER, N." target="KAPLAN, J. D.">
      <data key="d4">1.0</data>
      <data key="d5">Ryder, N. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="RYDER, N." target="DHARIWAL, P.">
      <data key="d4">1.0</data>
      <data key="d5">Ryder, N. and Dhariwal, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="RYDER, N." target="NEELAKANTAN, A.">
      <data key="d4">1.0</data>
      <data key="d5">Ryder, N. and Neelakantan, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="RYDER, N." target="SHYAM, P.">
      <data key="d4">1.0</data>
      <data key="d5">Ryder, N. and Shyam, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="RYDER, N." target="SASTRY, G.">
      <data key="d4">1.0</data>
      <data key="d5">Ryder, N. and Sastry, G. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="RYDER, N." target="ASKELL, A.">
      <data key="d4">1.0</data>
      <data key="d5">Ryder, N. and Askell, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="SUBBIAH, M." target="KAPLAN, J. D.">
      <data key="d4">1.0</data>
      <data key="d5">Subbiah, M. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="SUBBIAH, M." target="DHARIWAL, P.">
      <data key="d4">1.0</data>
      <data key="d5">Subbiah, M. and Dhariwal, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="SUBBIAH, M." target="NEELAKANTAN, A.">
      <data key="d4">1.0</data>
      <data key="d5">Subbiah, M. and Neelakantan, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="SUBBIAH, M." target="SHYAM, P.">
      <data key="d4">1.0</data>
      <data key="d5">Subbiah, M. and Shyam, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="SUBBIAH, M." target="SASTRY, G.">
      <data key="d4">1.0</data>
      <data key="d5">Subbiah, M. and Sastry, G. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ZHAO, D." target="ARXIV:2310.05149">
      <data key="d4">1.0</data>
      <data key="d5">Zhao, D. is an author of the paper with arXiv identifier 2310.05149</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ES, S." target="ARXIV:2309.15217">
      <data key="d4">1.0</data>
      <data key="d5">Es, S. is an author of the paper with arXiv identifier 2309.15217</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="JAMES, J." target="ARXIV:2309.15217">
      <data key="d4">1.0</data>
      <data key="d5">James, J. is an author of the paper with arXiv identifier 2309.15217</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="ESPINOSA-ANKE, L." target="ARXIV:2309.15217">
      <data key="d4">1.0</data>
      <data key="d5">Espinosa-Anke, L. is an author of the paper with arXiv identifier 2309.15217</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="SCHOCKAERT, S." target="ARXIV:2309.15217">
      <data key="d4">1.0</data>
      <data key="d5">Schockaert, S. is an author of the paper with arXiv identifier 2309.15217</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="FENG, Z." target="ARXIV:2310.05149">
      <data key="d4">1.0</data>
      <data key="d5">Feng, Z. is an author of the paper with arXiv identifier 2310.05149</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="FENG, X." target="ARXIV:2310.05149">
      <data key="d4">1.0</data>
      <data key="d5">Feng, X. is an author of the paper with arXiv identifier 2310.05149</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="YANG, M." target="ARXIV:2310.05149">
      <data key="d4">1.0</data>
      <data key="d5">Yang, M. is an author of the paper with arXiv identifier 2310.05149</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="QIN, B." target="ARXIV:2310.05149">
      <data key="d4">1.0</data>
      <data key="d5">Qin, B. is an author of the paper with arXiv identifier 2310.05149</data>
      <data key="d6">58ae80c41cfe46db39da26b6a83584e5</data>
    </edge>
    <edge source="GAO, Y." target="XIONG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, Y. and Xiong, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, Y." target="GAO, X.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, Y. and Gao, X. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, Y." target="JIA, K.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, Y. and Jia, K. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, Y." target="PAN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, Y. and Pan, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, Y." target="BI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, Y. and Bi, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, Y." target="DAI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, Y. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, Y." target="SUN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, Y. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, Y." target="WANG, H.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, Y. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="XIONG, Y." target="GAO, X.">
      <data key="d4">1.0</data>
      <data key="d5">Xiong, Y. and Gao, X. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="XIONG, Y." target="JIA, K.">
      <data key="d4">1.0</data>
      <data key="d5">Xiong, Y. and Jia, K. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="XIONG, Y." target="PAN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Xiong, Y. and Pan, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="XIONG, Y." target="BI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Xiong, Y. and Bi, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="XIONG, Y." target="DAI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Xiong, Y. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="XIONG, Y." target="SUN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Xiong, Y. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="XIONG, Y." target="WANG, H.">
      <data key="d4">1.0</data>
      <data key="d5">Xiong, Y. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, X." target="JIA, K.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, X. and Jia, K. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, X." target="PAN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, X. and Pan, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, X." target="BI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, X. and Bi, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, X." target="DAI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, X. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, X." target="SUN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, X. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GAO, X." target="WANG, H.">
      <data key="d4">1.0</data>
      <data key="d5">Gao, X. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="JIA, K." target="PAN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Jia, K. and Pan, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="JIA, K." target="BI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Jia, K. and Bi, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="JIA, K." target="DAI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Jia, K. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="JIA, K." target="SUN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Jia, K. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="JIA, K." target="WANG, H.">
      <data key="d4">1.0</data>
      <data key="d5">Jia, K. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="PAN, J." target="BI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Pan, J. and Bi, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="PAN, J." target="DAI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Pan, J. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="PAN, J." target="SUN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Pan, J. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="PAN, J." target="WANG, H.">
      <data key="d4">1.0</data>
      <data key="d5">Pan, J. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="BI, Y." target="DAI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Bi, Y. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="BI, Y." target="SUN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Bi, Y. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="BI, Y." target="WANG, H.">
      <data key="d4">1.0</data>
      <data key="d5">Bi, Y. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="DAI, Y." target="SUN, J.">
      <data key="d4">1.0</data>
      <data key="d5">Dai, Y. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="DAI, Y." target="WANG, H.">
      <data key="d4">1.0</data>
      <data key="d5">Dai, Y. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="SUN, J." target="WANG, H.">
      <data key="d4">1.0</data>
      <data key="d5">Sun, J. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GOODWIN, T. R." target="SAVERY, M. E.">
      <data key="d4">1.0</data>
      <data key="d5">Goodwin, T. R. and Savery, M. E. co-authored the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="GOODWIN, T. R." target="DEMNER-FUSHMAN, D.">
      <data key="d4">1.0</data>
      <data key="d5">Goodwin, T. R. and Demner-Fushman, D. co-authored the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b</data>
    </edge>
    <edge source="KHATTAB, O." target="SANTHANAM, K.">
      <data key="d4">2.0</data>
      <data key="d5">Khattab, O. and Santhanam, K. co-authored a paper mentioned in the text
Khattab, O. and Santhanam, K. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KHATTAB, O." target="LI, X. L.">
      <data key="d4">2.0</data>
      <data key="d5">Khattab, O. and Li, X. L. co-authored a paper mentioned in the text
Khattab, O. and Li, X. L. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KHATTAB, O." target="HALL, D.">
      <data key="d4">2.0</data>
      <data key="d5">Khattab, O. and Hall, D. co-authored a paper mentioned in the text
Khattab, O. and Hall, D. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KHATTAB, O." target="LIANG, P.">
      <data key="d4">2.0</data>
      <data key="d5">Khattab, O. and Liang, P. co-authored a paper mentioned in the text
Khattab, O. and Liang, P. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KHATTAB, O." target="POTTS, C.">
      <data key="d4">2.0</data>
      <data key="d5">Khattab, O. and Potts, C. co-authored a paper mentioned in the text
Khattab, O. and Potts, C. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KHATTAB, O." target="ZAHARIA, M.">
      <data key="d4">2.0</data>
      <data key="d5">Khattab, O. and Zaharia, M. co-authored a paper mentioned in the text
Khattab, O. and Zaharia, M. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KHATTAB, O." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Khattab, O. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="SANTHANAM, K." target="LI, X. L.">
      <data key="d4">2.0</data>
      <data key="d5">Santhanam, K. and Li, X. L. co-authored a paper mentioned in the text
Santhanam, K. and Li, X. L. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="SANTHANAM, K." target="HALL, D.">
      <data key="d4">2.0</data>
      <data key="d5">Santhanam, K. and Hall, D. co-authored a paper mentioned in the text
Santhanam, K. and Hall, D. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="SANTHANAM, K." target="LIANG, P.">
      <data key="d4">2.0</data>
      <data key="d5">Santhanam, K. and Liang, P. co-authored a paper mentioned in the text
Santhanam, K. and Liang, P. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="SANTHANAM, K." target="POTTS, C.">
      <data key="d4">2.0</data>
      <data key="d5">Santhanam, K. and Potts, C. co-authored a paper mentioned in the text
Santhanam, K. and Potts, C. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="SANTHANAM, K." target="ZAHARIA, M.">
      <data key="d4">2.0</data>
      <data key="d5">Santhanam, K. and Zaharia, M. co-authored a paper mentioned in the text
Santhanam, K. and Zaharia, M. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="SANTHANAM, K." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Santhanam, K. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LI, X. L." target="HALL, D.">
      <data key="d4">2.0</data>
      <data key="d5">Li, X. L. and Hall, D. co-authored a paper mentioned in the text
Li, X. L. and Hall, D. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LI, X. L." target="LIANG, P.">
      <data key="d4">2.0</data>
      <data key="d5">Li, X. L. and Liang, P. co-authored a paper mentioned in the text
Li, X. L. and Liang, P. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LI, X. L." target="POTTS, C.">
      <data key="d4">2.0</data>
      <data key="d5">Li, X. L. and Potts, C. co-authored a paper mentioned in the text
Li, X. L. and Potts, C. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LI, X. L." target="ZAHARIA, M.">
      <data key="d4">2.0</data>
      <data key="d5">Li, X. L. and Zaharia, M. co-authored a paper mentioned in the text
Li, X. L. and Zaharia, M. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LI, X. L." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Li, X. L. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="HALL, D." target="LIANG, P.">
      <data key="d4">2.0</data>
      <data key="d5">Hall, D. and Liang, P. co-authored a paper mentioned in the text
Hall, D. and Liang, P. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="HALL, D." target="POTTS, C.">
      <data key="d4">2.0</data>
      <data key="d5">Hall, D. and Potts, C. co-authored a paper mentioned in the text
Hall, D. and Potts, C. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="HALL, D." target="ZAHARIA, M.">
      <data key="d4">2.0</data>
      <data key="d5">Hall, D. and Zaharia, M. co-authored a paper mentioned in the text
Hall, D. and Zaharia, M. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="HALL, D." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Hall, D. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LIANG, P." target="POTTS, C.">
      <data key="d4">2.0</data>
      <data key="d5">Liang, P. and Potts, C. co-authored a paper mentioned in the text
Liang, P. and Potts, C. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LIANG, P." target="ZAHARIA, M.">
      <data key="d4">2.0</data>
      <data key="d5">Liang, P. and Zaharia, M. co-authored a paper mentioned in the text
Liang, P. and Zaharia, M. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LIANG, P." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Liang, P. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="POTTS, C." target="ZAHARIA, M.">
      <data key="d4">2.0</data>
      <data key="d5">Potts, C. and Zaharia, M. co-authored a paper mentioned in the text
Potts, C. and Zaharia, M. co-authored the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="POTTS, C." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Potts, C. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="ZAHARIA, M." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Zaharia, M. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KIM, G." target="KIM, S.">
      <data key="d4">1.0</data>
      <data key="d5">Kim, G. and Kim, S. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KIM, G." target="JEON, B.">
      <data key="d4">1.0</data>
      <data key="d5">Kim, G. and Jeon, B. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KIM, G." target="PARK, J.">
      <data key="d4">1.0</data>
      <data key="d5">Kim, G. and Park, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KIM, G." target="KANG, J.">
      <data key="d4">1.0</data>
      <data key="d5">Kim, G. and Kang, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KIM, G." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Kim, G. is an author of the arXiv preprint "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KIM, S." target="JEON, B.">
      <data key="d4">1.0</data>
      <data key="d5">Kim, S. and Jeon, B. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KIM, S." target="PARK, J.">
      <data key="d4">1.0</data>
      <data key="d5">Kim, S. and Park, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KIM, S." target="KANG, J.">
      <data key="d4">1.0</data>
      <data key="d5">Kim, S. and Kang, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KIM, S." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Kim, S. is an author of the arXiv preprint "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="JEON, B." target="PARK, J.">
      <data key="d4">1.0</data>
      <data key="d5">Jeon, B. and Park, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="JEON, B." target="KANG, J.">
      <data key="d4">1.0</data>
      <data key="d5">Jeon, B. and Kang, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="JEON, B." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Jeon, B. is an author of the arXiv preprint "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="PARK, J." target="KANG, J.">
      <data key="d4">1.0</data>
      <data key="d5">Park, J. and Kang, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="PARK, J." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Park, J. is an author of the arXiv preprint "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KANG, J." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Kang, J. is an author of the arXiv preprint "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KLEIN, G." target="MOON, B.">
      <data key="d4">1.0</data>
      <data key="d5">Klein, G. and Moon, B. co-authored the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KLEIN, G." target="HOFFMAN, R. R.">
      <data key="d4">1.0</data>
      <data key="d5">Klein, G. and Hoffman, R. R. co-authored the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KLEIN, G." target="IEEE INTELLIGENT SYSTEMS">
      <data key="d4">1.0</data>
      <data key="d5">Klein, G. is an author of papers published in IEEE Intelligent Systems</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="MOON, B." target="HOFFMAN, R. R.">
      <data key="d4">1.0</data>
      <data key="d5">Moon, B. and Hoffman, R. R. co-authored the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="MOON, B." target="IEEE INTELLIGENT SYSTEMS">
      <data key="d4">1.0</data>
      <data key="d5">Moon, B. is an author of papers published in IEEE Intelligent Systems</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="HOFFMAN, R. R." target="IEEE INTELLIGENT SYSTEMS">
      <data key="d4">1.0</data>
      <data key="d5">Hoffman, R. R. is an author of papers published in IEEE Intelligent Systems</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KOESTEN, L." target="GREGORY, K.">
      <data key="d4">1.0</data>
      <data key="d5">Koesten, L. and Gregory, K. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KOESTEN, L." target="GROTH, P.">
      <data key="d4">1.0</data>
      <data key="d5">Koesten, L. and Groth, P. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KOESTEN, L." target="SIMPERL, E.">
      <data key="d4">1.0</data>
      <data key="d5">Koesten, L. and Simperl, E. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KOESTEN, L." target="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d4">1.0</data>
      <data key="d5">Koesten, L. is an author of a paper published in International Journal of Human-Computer Studies</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="GREGORY, K." target="GROTH, P.">
      <data key="d4">1.0</data>
      <data key="d5">Gregory, K. and Groth, P. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="GREGORY, K." target="SIMPERL, E.">
      <data key="d4">1.0</data>
      <data key="d5">Gregory, K. and Simperl, E. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="GREGORY, K." target="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d4">1.0</data>
      <data key="d5">Gregory, K. is an author of a paper published in International Journal of Human-Computer Studies</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="GROTH, P." target="SIMPERL, E.">
      <data key="d4">1.0</data>
      <data key="d5">Groth, P. and Simperl, E. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="GROTH, P." target="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d4">1.0</data>
      <data key="d5">Groth, P. is an author of a paper published in International Journal of Human-Computer Studies</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="SIMPERL, E." target="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d4">1.0</data>
      <data key="d5">Simperl, E. is an author of a paper published in International Journal of Human-Computer Studies</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="KURATOV, Y." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Kuratov, Y. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="BULATOV, A." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Bulatov, A. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="ANOKHIN, P." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Anokhin, P. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="SOROKIN, D." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Sorokin, D. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="SOROKIN, A." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Sorokin, A. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="BURTSEV, M." target="ARXIV PREPRINT">
      <data key="d4">1.0</data>
      <data key="d5">Burtsev, M. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="ADVANCES IN ARTIFICIAL INTELLIGENCE">
      <data key="d4">1.0</data>
      <data key="d5">Laskar, M. T. R. is an author of a paper presented at Advances in Artificial Intelligence</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="HOQUE, E.">
      <data key="d4">2.0</data>
      <data key="d5">Laskar, M. T. R. and Hoque, E. co-authored the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models"
Laskar, M. T. R. and Hoque, E. co-authored the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7,71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="HUANG, J.">
      <data key="d4">1.0</data>
      <data key="d5">Laskar, M. T. R. and Huang, J. co-authored the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="HUANG, J. X.">
      <data key="d4">1.0</data>
      <data key="d5">Laskar, M. T. R. and Huang, J. X. co-authored the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="COMPUTATIONAL LINGUISTICS">
      <data key="d4">1.0</data>
      <data key="d5">Laskar, M. T. R. published the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" in Computational Linguistics</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="HOQUE, E." target="ADVANCES IN ARTIFICIAL INTELLIGENCE">
      <data key="d4">1.0</data>
      <data key="d5">Hoque, E. is an author of a paper presented at Advances in Artificial Intelligence</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="HOQUE, E." target="HUANG, J.">
      <data key="d4">1.0</data>
      <data key="d5">Hoque, E. and Huang, J. co-authored the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models"</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="HOQUE, E." target="HUANG, J. X.">
      <data key="d4">1.0</data>
      <data key="d5">Hoque, E. and Huang, J. X. co-authored the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="HOQUE, E." target="COMPUTATIONAL LINGUISTICS">
      <data key="d4">1.0</data>
      <data key="d5">Hoque, E. published the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" in Computational Linguistics</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="HUANG, J." target="ADVANCES IN ARTIFICIAL INTELLIGENCE">
      <data key="d4">1.0</data>
      <data key="d5">Huang, J. is an author of a paper presented at Advances in Artificial Intelligence</data>
      <data key="d6">71f6daf11e64e5273a3847d46bf228e1</data>
    </edge>
    <edge source="33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE" target="CANADIAN AI 2020">
      <data key="d4">1.0</data>
      <data key="d5">The 33rd Canadian Conference on Artificial Intelligence is also known as Canadian AI 2020</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE" target="SPRINGER">
      <data key="d4">1.0</data>
      <data key="d5">Springer published the proceedings of the 33rd Canadian Conference on Artificial Intelligence</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="HUANG, J. X." target="COMPUTATIONAL LINGUISTICS">
      <data key="d4">1.0</data>
      <data key="d5">Huang, J. X. published the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" in Computational Linguistics</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LEWIS, P." target="PEREZ, E.">
      <data key="d4">1.0</data>
      <data key="d5">Lewis, P. and Perez, E. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LEWIS, P." target="PIKTUS, A.">
      <data key="d4">1.0</data>
      <data key="d5">Lewis, P. and Piktus, A. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LEWIS, P." target="PETRONI, F.">
      <data key="d4">1.0</data>
      <data key="d5">Lewis, P. and Petroni, F. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LEWIS, P." target="KARPUKHIN, V.">
      <data key="d4">1.0</data>
      <data key="d5">Lewis, P. and Karpukhin, V. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LEWIS, P." target="GOYAL, N.">
      <data key="d4">1.0</data>
      <data key="d5">Lewis, P. and Goyal, N. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LEWIS, P." target="K&#220;TTLER, H.">
      <data key="d4">1.0</data>
      <data key="d5">Lewis, P. and K&#252;ttler, H. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LEWIS, P." target="LEWIS, M.">
      <data key="d4">1.0</data>
      <data key="d5">Lewis, P. and Lewis, M. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LEWIS, P." target="YIH, W.-T.">
      <data key="d4">1.0</data>
      <data key="d5">Lewis, P. and Yih, W.-T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LEWIS, P." target="ROCKT&#196;SCHEL, T.">
      <data key="d4">1.0</data>
      <data key="d5">Lewis, P. and Rockt&#228;schel, T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PEREZ, E." target="PIKTUS, A.">
      <data key="d4">1.0</data>
      <data key="d5">Perez, E. and Piktus, A. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PEREZ, E." target="PETRONI, F.">
      <data key="d4">1.0</data>
      <data key="d5">Perez, E. and Petroni, F. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PEREZ, E." target="KARPUKHIN, V.">
      <data key="d4">1.0</data>
      <data key="d5">Perez, E. and Karpukhin, V. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PEREZ, E." target="GOYAL, N.">
      <data key="d4">1.0</data>
      <data key="d5">Perez, E. and Goyal, N. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PEREZ, E." target="K&#220;TTLER, H.">
      <data key="d4">1.0</data>
      <data key="d5">Perez, E. and K&#252;ttler, H. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PEREZ, E." target="LEWIS, M.">
      <data key="d4">1.0</data>
      <data key="d5">Perez, E. and Lewis, M. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PEREZ, E." target="YIH, W.-T.">
      <data key="d4">1.0</data>
      <data key="d5">Perez, E. and Yih, W.-T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PEREZ, E." target="ROCKT&#196;SCHEL, T.">
      <data key="d4">1.0</data>
      <data key="d5">Perez, E. and Rockt&#228;schel, T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PIKTUS, A." target="PETRONI, F.">
      <data key="d4">1.0</data>
      <data key="d5">Piktus, A. and Petroni, F. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PIKTUS, A." target="KARPUKHIN, V.">
      <data key="d4">1.0</data>
      <data key="d5">Piktus, A. and Karpukhin, V. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PIKTUS, A." target="GOYAL, N.">
      <data key="d4">1.0</data>
      <data key="d5">Piktus, A. and Goyal, N. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PIKTUS, A." target="K&#220;TTLER, H.">
      <data key="d4">1.0</data>
      <data key="d5">Piktus, A. and K&#252;ttler, H. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PIKTUS, A." target="LEWIS, M.">
      <data key="d4">1.0</data>
      <data key="d5">Piktus, A. and Lewis, M. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PIKTUS, A." target="YIH, W.-T.">
      <data key="d4">1.0</data>
      <data key="d5">Piktus, A. and Yih, W.-T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PIKTUS, A." target="ROCKT&#196;SCHEL, T.">
      <data key="d4">1.0</data>
      <data key="d5">Piktus, A. and Rockt&#228;schel, T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PETRONI, F." target="KARPUKHIN, V.">
      <data key="d4">1.0</data>
      <data key="d5">Petroni, F. and Karpukhin, V. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PETRONI, F." target="GOYAL, N.">
      <data key="d4">1.0</data>
      <data key="d5">Petroni, F. and Goyal, N. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PETRONI, F." target="K&#220;TTLER, H.">
      <data key="d4">1.0</data>
      <data key="d5">Petroni, F. and K&#252;ttler, H. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PETRONI, F." target="LEWIS, M.">
      <data key="d4">1.0</data>
      <data key="d5">Petroni, F. and Lewis, M. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PETRONI, F." target="YIH, W.-T.">
      <data key="d4">1.0</data>
      <data key="d5">Petroni, F. and Yih, W.-T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="PETRONI, F." target="ROCKT&#196;SCHEL, T.">
      <data key="d4">1.0</data>
      <data key="d5">Petroni, F. and Rockt&#228;schel, T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="KARPUKHIN, V." target="GOYAL, N.">
      <data key="d4">1.0</data>
      <data key="d5">Karpukhin, V. and Goyal, N. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7</data>
    </edge>
    <edge source="LAPATA, M." target="XU, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Xu, Y. and Lapata, M. co-authored the paper "Text summarization with latent queries"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="CHEN, W." target="HUANG, M.">
      <data key="d4">1.0</data>
      <data key="d5">Huang, M. and Chen, W. co-authored the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="CHEN, W." target="DUAN, N.">
      <data key="d4">1.0</data>
      <data key="d5">Duan, N. and Chen, W. co-authored the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MARTIN, S." target="BROWN, W. M.">
      <data key="d4">3.0</data>
      <data key="d5">Martin, S. and Brown, W. M. co-authored the paper "Openord: An open-source toolbox for large graph"
Martin, S. and Brown, W. M. co-authored the paper "Openord: An open-source toolbox for large graph layout"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="MARTIN, S." target="KLAVANS, R.">
      <data key="d4">3.0</data>
      <data key="d5">Martin, S. and Klavans, R. co-authored the paper "Openord: An open-source toolbox for large graph"
Martin, S. and Klavans, R. co-authored the paper "Openord: An open-source toolbox for large graph layout"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="MARTIN, S." target="BOYACK, K.">
      <data key="d4">3.0</data>
      <data key="d5">Martin, S. and Boyack, K. co-authored the paper "Openord: An open-source toolbox for large graph"
Martin, S. and Boyack, K. co-authored the paper "Openord: An open-source toolbox for large graph layout"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="BROWN, W. M." target="KLAVANS, R.">
      <data key="d4">3.0</data>
      <data key="d5">Brown, W. M. and Klavans, R. co-authored the paper "Openord: An open-source toolbox for large graph"
Brown, W. M. and Klavans, R. co-authored the paper "Openord: An open-source toolbox for large graph layout"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="BROWN, W. M." target="BOYACK, K.">
      <data key="d4">3.0</data>
      <data key="d5">Brown, W. M. and Boyack, K. co-authored the paper "Openord: An open-source toolbox for large graph"
Brown, W. M. and Boyack, K. co-authored the paper "Openord: An open-source toolbox for large graph layout"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="KLAVANS, R." target="BOYACK, K.">
      <data key="d4">3.0</data>
      <data key="d5">Klavans, R. and Boyack, K. co-authored the paper "Openord: An open-source toolbox for large graph"
Klavans, R. and Boyack, K. co-authored the paper "Openord: An open-source toolbox for large graph layout"</data>
      <data key="d6">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="NEWMAN, M. E." target="PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES">
      <data key="d4">2.0</data>
      <data key="d5">Newman, M. E. published the paper "Modularity and community structure in networks" in the Proceedings of the National Academy of Sciences</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="RAM, O." target="LEVINE, Y.">
      <data key="d4">2.0</data>
      <data key="d5">Ram, O. and Levine, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="RAM, O." target="DALMEDIGOS, I.">
      <data key="d4">2.0</data>
      <data key="d5">Ram, O. and Dalmedigos, I. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="RAM, O." target="MUHLGAY, D.">
      <data key="d4">2.0</data>
      <data key="d5">Ram, O. and Muhlgay, D. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="RAM, O." target="SHASHUA, A.">
      <data key="d4">2.0</data>
      <data key="d5">Ram, O. and Shashua, A. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="RAM, O." target="LEYTON-BROWN, K.">
      <data key="d4">2.0</data>
      <data key="d5">Ram, O. and Leyton-Brown, K. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="RAM, O." target="SHOHAM, Y.">
      <data key="d4">2.0</data>
      <data key="d5">Ram, O. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="LEVINE, Y." target="DALMEDIGOS, I.">
      <data key="d4">2.0</data>
      <data key="d5">Levine, Y. and Dalmedigos, I. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="LEVINE, Y." target="MUHLGAY, D.">
      <data key="d4">2.0</data>
      <data key="d5">Levine, Y. and Muhlgay, D. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="LEVINE, Y." target="SHASHUA, A.">
      <data key="d4">2.0</data>
      <data key="d5">Levine, Y. and Shashua, A. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="LEVINE, Y." target="LEYTON-BROWN, K.">
      <data key="d4">2.0</data>
      <data key="d5">Levine, Y. and Leyton-Brown, K. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="LEVINE, Y." target="SHOHAM, Y.">
      <data key="d4">2.0</data>
      <data key="d5">Levine, Y. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="DALMEDIGOS, I." target="MUHLGAY, D.">
      <data key="d4">2.0</data>
      <data key="d5">Dalmedigos, I. and Muhlgay, D. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="DALMEDIGOS, I." target="SHASHUA, A.">
      <data key="d4">2.0</data>
      <data key="d5">Dalmedigos, I. and Shashua, A. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="DALMEDIGOS, I." target="LEYTON-BROWN, K.">
      <data key="d4">2.0</data>
      <data key="d5">Dalmedigos, I. and Leyton-Brown, K. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="DALMEDIGOS, I." target="SHOHAM, Y.">
      <data key="d4">2.0</data>
      <data key="d5">Dalmedigos, I. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="MUHLGAY, D." target="SHASHUA, A.">
      <data key="d4">2.0</data>
      <data key="d5">Muhlgay, D. and Shashua, A. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="MUHLGAY, D." target="LEYTON-BROWN, K.">
      <data key="d4">2.0</data>
      <data key="d5">Muhlgay, D. and Leyton-Brown, K. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="MUHLGAY, D." target="SHOHAM, Y.">
      <data key="d4">2.0</data>
      <data key="d5">Muhlgay, D. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="SHASHUA, A." target="LEYTON-BROWN, K.">
      <data key="d4">2.0</data>
      <data key="d5">Shashua, A. and Leyton-Brown, K. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="SHASHUA, A." target="SHOHAM, Y.">
      <data key="d4">2.0</data>
      <data key="d5">Shashua, A. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="LEYTON-BROWN, K." target="SHOHAM, Y.">
      <data key="d4">2.0</data>
      <data key="d5">Leyton-Brown, K. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="RANADE, P." target="JOSHI, A.">
      <data key="d4">2.0</data>
      <data key="d5">Ranade, P. and Joshi, A. co-authored the paper "Fabula: Intelligence report generation using retrieval-augmented narrative construction"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="SARTHI, P." target="ABDULLAH, S.">
      <data key="d4">2.0</data>
      <data key="d5">Sarthi, P. and Abdullah, S. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="SARTHI, P." target="TULI, A.">
      <data key="d4">2.0</data>
      <data key="d5">Sarthi, P. and Tuli, A. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="SARTHI, P." target="KHANNA, S.">
      <data key="d4">2.0</data>
      <data key="d5">Sarthi, P. and Khanna, S. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="SARTHI, P." target="GOLDIE, A.">
      <data key="d4">2.0</data>
      <data key="d5">Sarthi, P. and Goldie, A. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="SARTHI, P." target="MANNING, C. D.">
      <data key="d4">2.0</data>
      <data key="d5">Sarthi, P. and Manning, C. D. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="ABDULLAH, S." target="TULI, A.">
      <data key="d4">2.0</data>
      <data key="d5">Abdullah, S. and Tuli, A. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="ABDULLAH, S." target="KHANNA, S.">
      <data key="d4">2.0</data>
      <data key="d5">Abdullah, S. and Khanna, S. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="ABDULLAH, S." target="GOLDIE, A.">
      <data key="d4">2.0</data>
      <data key="d5">Abdullah, S. and Goldie, A. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="ABDULLAH, S." target="MANNING, C. D.">
      <data key="d4">2.0</data>
      <data key="d5">Abdullah, S. and Manning, C. D. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="TULI, A." target="KHANNA, S.">
      <data key="d4">2.0</data>
      <data key="d5">Tuli, A. and Khanna, S. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="TULI, A." target="GOLDIE, A.">
      <data key="d4">2.0</data>
      <data key="d5">Tuli, A. and Goldie, A. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="TULI, A." target="MANNING, C. D.">
      <data key="d4">2.0</data>
      <data key="d5">Tuli, A. and Manning, C. D. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d6">833e7d67dcd30790b26b71c9b5306f6b</data>
    </edge>
    <edge source="MANNING, C. D." target="YANG, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Yang, Z. and Manning, C. D. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="HUANG, M." target="DUAN, N.">
      <data key="d4">1.0</data>
      <data key="d5">Huang, M. and Duan, N. co-authored the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SU, D." target="XU, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Su, D. and Xu, Y. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SU, D." target="YU, T.">
      <data key="d4">1.0</data>
      <data key="d5">Su, D. and Yu, T. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SU, D." target="SIDDIQUE, F. B.">
      <data key="d4">1.0</data>
      <data key="d5">Su, D. and Siddique, F. B. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SU, D." target="BAREZI, E. J.">
      <data key="d4">1.0</data>
      <data key="d5">Su, D. and Barezi, E. J. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SU, D." target="FUNG, P.">
      <data key="d4">1.0</data>
      <data key="d5">Su, D. and Fung, P. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="XU, Y." target="YU, T.">
      <data key="d4">1.0</data>
      <data key="d5">Xu, Y. and Yu, T. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="XU, Y." target="SIDDIQUE, F. B.">
      <data key="d4">1.0</data>
      <data key="d5">Xu, Y. and Siddique, F. B. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="XU, Y." target="BAREZI, E. J.">
      <data key="d4">1.0</data>
      <data key="d5">Xu, Y. and Barezi, E. J. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="XU, Y." target="FUNG, P.">
      <data key="d4">1.0</data>
      <data key="d5">Xu, Y. and Fung, P. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="YU, T." target="SIDDIQUE, F. B.">
      <data key="d4">1.0</data>
      <data key="d5">Yu, T. and Siddique, F. B. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="YU, T." target="BAREZI, E. J.">
      <data key="d4">1.0</data>
      <data key="d5">Yu, T. and Barezi, E. J. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="YU, T." target="FUNG, P.">
      <data key="d4">1.0</data>
      <data key="d5">Yu, T. and Fung, P. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SIDDIQUE, F. B." target="BAREZI, E. J.">
      <data key="d4">1.0</data>
      <data key="d5">Siddique, F. B. and Barezi, E. J. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SIDDIQUE, F. B." target="FUNG, P.">
      <data key="d4">1.0</data>
      <data key="d5">Siddique, F. B. and Fung, P. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="BAREZI, E. J." target="FUNG, P.">
      <data key="d4">1.0</data>
      <data key="d5">Barezi, E. J. and Fung, P. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="TANG, Y." target="YANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Tang, Y. and Yang, Y. co-authored the paper "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="TOUVRON, H." target="MARTIN, L.">
      <data key="d4">1.0</data>
      <data key="d5">Touvron, H. and Martin, L. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="TOUVRON, H." target="STONE, K.">
      <data key="d4">1.0</data>
      <data key="d5">Touvron, H. and Stone, K. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="TOUVRON, H." target="ALBERT, P.">
      <data key="d4">1.0</data>
      <data key="d5">Touvron, H. and Albert, P. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="TOUVRON, H." target="ALMAHAIRI, A.">
      <data key="d4">1.0</data>
      <data key="d5">Touvron, H. and Almahairi, A. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="TOUVRON, H." target="BABAEI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Touvron, H. and Babaei, Y. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="TOUVRON, H." target="BASHLYKOV, N.">
      <data key="d4">1.0</data>
      <data key="d5">Touvron, H. and Bashlykov, N. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="TOUVRON, H." target="BATRA, S.">
      <data key="d4">1.0</data>
      <data key="d5">Touvron, H. and Batra, S. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="TOUVRON, H." target="BHARGAVA, P.">
      <data key="d4">1.0</data>
      <data key="d5">Touvron, H. and Bhargava, P. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="TOUVRON, H." target="BHOSALE, S.">
      <data key="d4">1.0</data>
      <data key="d5">Touvron, H. and Bhosale, S. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MARTIN, L." target="STONE, K.">
      <data key="d4">1.0</data>
      <data key="d5">Martin, L. and Stone, K. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MARTIN, L." target="ALBERT, P.">
      <data key="d4">1.0</data>
      <data key="d5">Martin, L. and Albert, P. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MARTIN, L." target="ALMAHAIRI, A.">
      <data key="d4">1.0</data>
      <data key="d5">Martin, L. and Almahairi, A. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MARTIN, L." target="BABAEI, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Martin, L. and Babaei, Y. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MARTIN, L." target="BASHLYKOV, N.">
      <data key="d4">1.0</data>
      <data key="d5">Martin, L. and Bashlykov, N. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MARTIN, L." target="BATRA, S.">
      <data key="d4">1.0</data>
      <data key="d5">Martin, L. and Batra, S. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="WANG, J." target="LIANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, J. and Liang, Y. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="WANG, J." target="MENG, F.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, J. and Meng, F. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="WANG, J." target="SUN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, J. and Sun, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="WANG, J." target="SHI, H.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, J. and Shi, H. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="WANG, J." target="LI, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, J. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="WANG, J." target="XU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, J. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="WANG, J." target="QU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, J. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="WANG, J." target="ZHOU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, J. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="LIANG, Y." target="MENG, F.">
      <data key="d4">1.0</data>
      <data key="d5">Liang, Y. and Meng, F. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="LIANG, Y." target="SUN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Liang, Y. and Sun, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="LIANG, Y." target="SHI, H.">
      <data key="d4">1.0</data>
      <data key="d5">Liang, Y. and Shi, H. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="LIANG, Y." target="LI, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Liang, Y. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="LIANG, Y." target="XU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Liang, Y. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="LIANG, Y." target="QU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Liang, Y. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="LIANG, Y." target="ZHOU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Liang, Y. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MENG, F." target="SUN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Meng, F. and Sun, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MENG, F." target="SHI, H.">
      <data key="d4">1.0</data>
      <data key="d5">Meng, F. and Shi, H. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MENG, F." target="LI, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Meng, F. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MENG, F." target="XU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Meng, F. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MENG, F." target="QU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Meng, F. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="MENG, F." target="ZHOU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Meng, F. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SUN, Z." target="SHI, H.">
      <data key="d4">1.0</data>
      <data key="d5">Sun, Z. and Shi, H. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SUN, Z." target="LI, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Sun, Z. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SUN, Z." target="XU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Sun, Z. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SUN, Z." target="QU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Sun, Z. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SUN, Z." target="ZHOU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Sun, Z. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SHI, H." target="LI, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Shi, H. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SHI, H." target="XU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Shi, H. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SHI, H." target="QU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Shi, H. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="SHI, H." target="ZHOU, J.">
      <data key="d4">1.0</data>
      <data key="d5">Shi, H. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035</data>
    </edge>
    <edge source="LI, Z." target="XU, J.">
      <data key="d4">2.0</data>
      <data key="d5">Li, Z. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Li, Z. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="LI, Z." target="QU, J.">
      <data key="d4">2.0</data>
      <data key="d5">Li, Z. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Li, Z. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="LI, Z." target="ZHOU, J.">
      <data key="d4">2.0</data>
      <data key="d5">Li, Z. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Li, Z. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="LI, Z." target="H.">
      <data key="d4">1.0</data>
      <data key="d5">H. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="LI, Z." target="ZHENG, L.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, Z." target="CHIANG, W.-L.">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, Z." target="SHENG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Sheng, Y. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, Z." target="ZHUANG, S.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, S. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, Z." target="WU, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Wu, Z. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, Z." target="ZHUANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, Y. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, Z." target="LIN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Lin, Z. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, Z." target="LI, D.">
      <data key="d4">1.0</data>
      <data key="d5">Li, Z. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, Z." target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Li, Z. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, Z." target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Li, Z. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="XU, J." target="QU, J.">
      <data key="d4">2.0</data>
      <data key="d5">Xu, J. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Xu, J. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="XU, J." target="ZHOU, J.">
      <data key="d4">2.0</data>
      <data key="d5">Xu, J. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Xu, J. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="XU, J." target="H.">
      <data key="d4">1.0</data>
      <data key="d5">H. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="QU, J." target="ZHOU, J.">
      <data key="d4">2.0</data>
      <data key="d5">Qu, J. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"
Qu, J. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="QU, J." target="H.">
      <data key="d4">1.0</data>
      <data key="d5">H. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ZHOU, J." target="H.">
      <data key="d4">1.0</data>
      <data key="d5">H. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="WANG, S." target="KHRAMTSOVA, E.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, S. and Khramtsova, E. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="WANG, S." target="ZHUANG, S.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, S. and Zhuang, S. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="WANG, S." target="ZUCCON, G.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, S. and Zuccon, G. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="KHRAMTSOVA, E." target="ZHUANG, S.">
      <data key="d4">1.0</data>
      <data key="d5">Khramtsova, E. and Zhuang, S. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="KHRAMTSOVA, E." target="ZUCCON, G.">
      <data key="d4">1.0</data>
      <data key="d5">Khramtsova, E. and Zuccon, G. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ZHUANG, S." target="ZUCCON, G.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, S. and Zuccon, G. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ZHUANG, S." target="ZHENG, L.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. and Zhuang, S. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, S." target="CHIANG, W.-L.">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. and Zhuang, S. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, S." target="SHENG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Sheng, Y. and Zhuang, S. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, S." target="WU, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, S. and Wu, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, S." target="ZHUANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, S. and Zhuang, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, S." target="LIN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, S. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, S." target="LI, D.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, S. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, S." target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, S. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, S." target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, S. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="WANG, Y." target="LIPKA, N.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, Y. and Lipka, N. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="WANG, Y." target="ROSSI, R. A.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, Y. and Rossi, R. A. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="WANG, Y." target="SIU, A.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, Y. and Siu, A. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="WANG, Y." target="ZHANG, R.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, Y. and Zhang, R. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="WANG, Y." target="DERR, T.">
      <data key="d4">1.0</data>
      <data key="d5">Wang, Y. and Derr, T. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="LIPKA, N." target="ROSSI, R. A.">
      <data key="d4">1.0</data>
      <data key="d5">Lipka, N. and Rossi, R. A. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="LIPKA, N." target="SIU, A.">
      <data key="d4">1.0</data>
      <data key="d5">Lipka, N. and Siu, A. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="LIPKA, N." target="ZHANG, R.">
      <data key="d4">1.0</data>
      <data key="d5">Lipka, N. and Zhang, R. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="LIPKA, N." target="DERR, T.">
      <data key="d4">1.0</data>
      <data key="d5">Lipka, N. and Derr, T. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ROSSI, R. A." target="SIU, A.">
      <data key="d4">1.0</data>
      <data key="d5">Rossi, R. A. and Siu, A. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ROSSI, R. A." target="ZHANG, R.">
      <data key="d4">1.0</data>
      <data key="d5">Rossi, R. A. and Zhang, R. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ROSSI, R. A." target="DERR, T.">
      <data key="d4">1.0</data>
      <data key="d5">Rossi, R. A. and Derr, T. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="SIU, A." target="ZHANG, R.">
      <data key="d4">1.0</data>
      <data key="d5">Siu, A. and Zhang, R. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="SIU, A." target="DERR, T.">
      <data key="d4">1.0</data>
      <data key="d5">Siu, A. and Derr, T. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ZHANG, R." target="DERR, T.">
      <data key="d4">1.0</data>
      <data key="d5">Zhang, R. and Derr, T. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="YANG, Z." target="QI, P.">
      <data key="d4">1.0</data>
      <data key="d5">Yang, Z. and Qi, P. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="YANG, Z." target="ZHANG, S.">
      <data key="d4">1.0</data>
      <data key="d5">Yang, Z. and Zhang, S. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="YANG, Z." target="BENGIO, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Yang, Z. and Bengio, Y. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="YANG, Z." target="COHEN, W. W.">
      <data key="d4">1.0</data>
      <data key="d5">Yang, Z. and Cohen, W. W. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="YANG, Z." target="SALAKHUTDINOV, R.">
      <data key="d4">1.0</data>
      <data key="d5">Yang, Z. and Salakhutdinov, R. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d6">fc4b27d64f055b7fc30176ba110dd02e</data>
    </edge>
    <edge source="ZHENG, L." target="CHIANG, W.-L.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. and Chiang, W.-L. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHENG, L." target="SHENG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. and Sheng, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHENG, L." target="WU, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. and Wu, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHENG, L." target="ZHUANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. and Zhuang, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHENG, L." target="LIN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHENG, L." target="LI, D.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHENG, L." target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHENG, L." target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="CHIANG, W.-L." target="SHENG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. and Sheng, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="CHIANG, W.-L." target="WU, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. and Wu, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="CHIANG, W.-L." target="ZHUANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. and Zhuang, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="CHIANG, W.-L." target="LIN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="CHIANG, W.-L." target="LI, D.">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="CHIANG, W.-L." target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="CHIANG, W.-L." target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Chiang, W.-L. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="SHENG, Y." target="WU, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Sheng, Y. and Wu, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="SHENG, Y." target="ZHUANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Sheng, Y. and Zhuang, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="SHENG, Y." target="LIN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Sheng, Y. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="SHENG, Y." target="LI, D.">
      <data key="d4">1.0</data>
      <data key="d5">Sheng, Y. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="SHENG, Y." target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Sheng, Y. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="SHENG, Y." target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Sheng, Y. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="WU, Z." target="ZHUANG, Y.">
      <data key="d4">1.0</data>
      <data key="d5">Wu, Z. and Zhuang, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="WU, Z." target="LIN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Wu, Z. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="WU, Z." target="LI, D.">
      <data key="d4">1.0</data>
      <data key="d5">Wu, Z. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="WU, Z." target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Wu, Z. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="WU, Z." target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Wu, Z. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, Y." target="LIN, Z.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, Y. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, Y." target="LI, D.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, Y. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, Y." target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, Y. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="ZHUANG, Y." target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang, Y. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LIN, Z." target="LI, D.">
      <data key="d4">1.0</data>
      <data key="d5">Lin, Z. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LIN, Z." target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Lin, Z. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LIN, Z." target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Lin, Z. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, D." target="XING, E.">
      <data key="d4">1.0</data>
      <data key="d5">Li, D. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="LI, D." target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Li, D. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
    <edge source="XING, E." target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Xing, E. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d6">b1bbda43309e8e0e2175ea034aa88e13</data>
    </edge>
  </graph>
</graphml>