<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d14" for="edge" attr.name="level" attr.type="long" />
  <key id="d13" for="edge" attr.name="human_readable_id" attr.type="long" />
  <key id="d12" for="edge" attr.name="id" attr.type="string" />
  <key id="d11" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d10" for="edge" attr.name="description" attr.type="string" />
  <key id="d9" for="edge" attr.name="weight" attr.type="double" />
  <key id="d8" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d7" for="node" attr.name="level" attr.type="long" />
  <key id="d6" for="node" attr.name="cluster" attr.type="string" />
  <key id="d5" for="node" attr.name="id" attr.type="string" />
  <key id="d4" for="node" attr.name="human_readable_id" attr.type="long" />
  <key id="d3" for="node" attr.name="degree" attr.type="long" />
  <key id="d2" for="node" attr.name="source_id" attr.type="string" />
  <key id="d1" for="node" attr.name="description" attr.type="string" />
  <key id="d0" for="node" attr.name="type" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="DARREN EDGE">
      <data key="d0">PERSON</data>
      <data key="d1">Darren Edge is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">8</data>
      <data key="d4">0</data>
      <data key="d5">b45241d70f0e43fca764df95b2b81f77</data>
    </node>
    <node id="HA TRINH">
      <data key="d0">PERSON</data>
      <data key="d1">Ha Trinh is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">8</data>
      <data key="d4">1</data>
      <data key="d5">4119fd06010c494caa07f439b333f4c5</data>
    </node>
    <node id="NEWMAN CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Newman Cheng is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">8</data>
      <data key="d4">2</data>
      <data key="d5">d3835bf3dda84ead99deadbeac5d0d7d</data>
    </node>
    <node id="JOSHUA BRADLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Bradley is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">8</data>
      <data key="d4">3</data>
      <data key="d5">077d2820ae1845bcbb1803379a3d1eae</data>
    </node>
    <node id="ALEX CHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Chao is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">8</data>
      <data key="d4">4</data>
      <data key="d5">3671ea0dd4e84c1a9b02c5ab2c8f4bac</data>
    </node>
    <node id="APURVA MODY">
      <data key="d0">PERSON</data>
      <data key="d1">Apurva Mody is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">8</data>
      <data key="d4">5</data>
      <data key="d5">19a7f254a5d64566ab5cc15472df02de</data>
    </node>
    <node id="STEVEN TRUITT">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Truitt is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">8</data>
      <data key="d4">6</data>
      <data key="d5">e7ffaee9d31d4d3c96e04f911d0a8f9e</data>
    </node>
    <node id="JONATHAN LARSON">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Larson is an author of the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">8</data>
      <data key="d4">7</data>
      <data key="d5">f7e11b0e297a44a896dc67928368f600</data>
    </node>
    <node id="MICROSOFT RESEARCH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Research is an organization where some of the authors of the paper are affiliated</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">3</data>
      <data key="d4">8</data>
      <data key="d5">1fd3fa8bb5a2408790042ab9573779ee</data>
    </node>
    <node id="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Strategic Missions and Technologies is an organization where some of the authors of the paper are affiliated</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">3</data>
      <data key="d4">9</data>
      <data key="d5">27f9fbe6ad8c4a8b9acee0d3596ed57c</data>
    </node>
    <node id="MICROSOFT OFFICE OF THE CTO">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Office of the CTO is an organization where some of the authors of the paper are affiliated</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">2</data>
      <data key="d4">10</data>
      <data key="d5">e1fd0e904a53409aada44442f23a51cb</data>
    </node>
    <node id="RAG">
      <data key="d0">METHOD</data>
      <data key="d1">RAG (Retrieval-Augmented Generation) is a developing research area with multiple established directions, including knowledge graph creation, completion, and extraction of causal graphs. It is a method used for generating responses in text generation tasks by retrieving relevant information from an external knowledge source to enable large language models to answer questions. This approach incorporates the retrieval of relevant data to augment text generation, producing direct responses in various text generation tasks.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,6f33a085ff3304e5994f7fbb86c881a4,92e93fc6449756c0a60200636b297f65,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">31</data>
      <data key="d4">11</data>
      <data key="d5">de988724cfdf45cebfba3b13c43ceede</data>
    </node>
    <node id="LLM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM (Large Language Model) is a type of artificial intelligence model used for a variety of tasks in the field of Natural Language Processing and Information Retrieval. These tasks include generating and assessing text, entity extraction, summarization, understanding relationships in text, and automating human-like sensemaking and reasoning over large collections of documents. LLMs are also employed to generate intermediate answers and scores for text chunks, process these chunks to extract elements of a graph index, and automate the generation of questions for dataset evaluation. Additionally, LLMs can analyze and generate text based on retrieved information and queries, and they possess a context window that can be exceeded by external datasets.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,21e52bc06a82796b1f4bcd73edda1f2a,2c6ed90897310eea2f28e33fff1c32b0,6f33a085ff3304e5994f7fbb86c881a4,922778ce1cb2fdd6dbab1746c8795620,bc9e2c9e369c4108cf4f6dd5f60960f4,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">32</data>
      <data key="d4">12</data>
      <data key="d5">96aad7cb4b7d40e9b7e13b94a67af206</data>
    </node>
    <node id="GRAPH RAG">
      <data key="d0">METHOD</data>
      <data key="d1">Graph RAG (Retrieval-Augmented Generation) is a sophisticated method that leverages the natural modularity of graphs to partition data for global summarization tasks. This approach integrates multiple stages and concepts, including knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS), to support human sensemaking over text corpora. It is particularly effective in providing comprehensive and structured overviews of public figures across various sectors of the entertainment industry, as well as generating answers for questions in the News article dataset.

Graph RAG employs a high-level data flow and pipeline for processing and summarizing text, combining both global and local approaches to optimize token usage in text generation tasks. It uses community summaries to improve answer comprehensiveness and diversity while requiring fewer tokens compared to traditional source text summarization methods. This method has been shown to outperform naive RAG in terms of comprehensiveness and diversity in text generation tasks.

A specific implementation of Graph RAG involves using four levels of graph communities, incorporating concepts from other systems such as self-memory and parallel generation of community answers. This multi-stage mechanism allows for the comparison of multiple conditions, enhancing the overall effectiveness of the summarization process.

Graph RAG, launched by NebulaGraph, is a retrieval-augmented generation technology based on knowledge graphs. It combines global summarization with graph-based text indexing to answer questions over private text corpora, making it a versatile tool for various text analysis and summarization applications.</data>
      <data key="d2">086021a89900a39bcb62036981737bfa,21e52bc06a82796b1f4bcd73edda1f2a,322e02986c8724eedbcf3ebfa20b989c,36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,718017a4871c909420f84b85b8ba969d,833e7d67dcd30790b26b71c9b5306f6b,922778ce1cb2fdd6dbab1746c8795620,92e93fc6449756c0a60200636b297f65,973164fa90bf2b4ee267f4fd795916bf,bc9e2c9e369c4108cf4f6dd5f60960f4,e4d9b12cf2b4c691c74019eefff4fb39,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,ebf5249c888e07fedce6572a4c03f88c,f35de4d9fb65f1d5a392064b20545c19,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">90</data>
      <data key="d4">13</data>
      <data key="d5">c9632a35146940c2a86167c7726d35e9</data>
    </node>
    <node id="QFS">
      <data key="d0">METHOD</data>
      <data key="d1">QFS (Query-Focused Summarization) is a method used to generate summaries based on specific user queries</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">14</data>
      <data key="d5">9646481f66ce4fd2b08c2eddda42fc82</data>
    </node>
    <node id="COMMUNITY SUMMARIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Community summaries are generated summaries of data clusters or communities, used to answer queries and tailored to the domain. These summaries are pre-generated for groups of closely-related entities, particularly in the Graph RAG approach, and are derived from community-generated content to compare with source texts. They are randomly shuffled and divided into chunks of pre-specified token size to ensure relevant information is distributed across chunks. Community summaries provide report-like insights into each community within a hierarchical structure, which is useful for understanding the dataset. They are generated from modular communities in the knowledge graph and cover different levels of each graph community hierarchy, including root-level communities in an entity-based graph index. Additionally, these summaries act as a kind of self-memory for generation-augmented retrieval.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,21e52bc06a82796b1f4bcd73edda1f2a,36db32c37e1987e2c5863898ad882190,6f33a085ff3304e5994f7fbb86c881a4,7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd,e4d9b12cf2b4c691c74019eefff4fb39,e8d83e6e7a7c0f57b218cef24976b745,f0306814bf64f5c9e79603fc6a52f4ea,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">26</data>
      <data key="d4">15</data>
      <data key="d5">d91a266f766b4737a06b0fda588ba40b</data>
    </node>
    <node id="GLOBAL SENSEMAKING QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Global sensemaking questions are questions that require understanding and summarizing large datasets, often beyond the explicit content of the source texts</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">3</data>
      <data key="d4">16</data>
      <data key="d5">bc0e3f075a4c4ebbb7c7b152b65a5625</data>
    </node>
    <node id="1 MILLION TOKEN RANGE">
      <data key="d0">METRIC</data>
      <data key="d1">1 million token range refers to the scale of datasets used in the evaluation of the Graph RAG approach</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">1</data>
      <data key="d4">17</data>
      <data key="d5">254770028d7a4fa9877da4ba0ad5ad21</data>
    </node>
    <node id="PYTHON">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Python is a programming language used for implementing both global and local Graph RAG approaches. Additionally, Python is utilized to implement the open-source version of the Graph RAG approach.</data>
      <data key="d2">086021a89900a39bcb62036981737bfa,e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">18</data>
      <data key="d5">4a67211867e5464ba45126315a122a8a</data>
    </node>
    <node id="HTTPS://AKA.MS/GRAPHRAG">
      <data key="d0">URL</data>
      <data key="d1">The URL "HTTPS://AKA.MS/GRAPHRAG" is the location where the open-source, Python-based implementation of Graph RAG approaches will be available. This URL serves as the repository for accessing the open-source implementation of the Graph RAG approach.</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39,e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">2</data>
      <data key="d4">19</data>
      <data key="d5">04dbbb2283b845baaeac0eaf0c34c9da</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">Query-Focused Summarization (QFS) is a method used to generate summaries that are relevant to specific user queries. This summarization technique focuses on answering specific queries by utilizing the entire corpus of information available. It is designed to provide concise and relevant information based on the specific needs of the user, ensuring that the generated summaries are directly aligned with the queries posed.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,7fb7d9ce2da9c940a32afdd87d1d9e56,e8d83e6e7a7c0f57b218cef24976b745,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">70</data>
      <data key="d7">1</data>
      <data key="d3">5</data>
      <data key="d4">20</data>
      <data key="d5">1943f245ee4243bdbfbd2fd619ae824a</data>
    </node>
    <node id="EXTERNAL KNOWLEDGE SOURCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">An external knowledge source is a repository of information that can be accessed to retrieve relevant data for answering questions</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">21</data>
      <data key="d5">273daeec8cad41e6b3e450447db58ee7</data>
    </node>
    <node id="TEXT CORPUS">
      <data key="d0">CONCEPT</data>
      <data key="d1">A text corpus is a large collection of written texts used for analysis and research</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d3">1</data>
      <data key="d4">22</data>
      <data key="d5">e69dc259edb944ea9ea41264b9fcfe59</data>
    </node>
    <node id="ENTITY KNOWLEDGE GRAPH">
      <data key="d0">CONCEPT</data>
      <data key="d1">An entity knowledge graph is a graph-based representation of entities and their relationships derived from source documents</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">23</data>
      <data key="d5">e2f5735c7d714423a2c4f61ca2644626</data>
    </node>
    <node id="SOURCE DOCUMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Source documents are the original texts from which information is extracted, retrieved, or summarized. These documents serve as the foundational input texts for various processing tasks, including the Graph RAG (Retrieval-Augmented Generation) approach. In this context, source documents are critical for extracting and analyzing information, ensuring that the data used in computational linguistics and information retrieval tasks is accurate and comprehensive.</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4,e8d83e6e7a7c0f57b218cef24976b745,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">5</data>
      <data key="d4">24</data>
      <data key="d5">deece7e64b2a4628850d4bb6e394a9c3</data>
    </node>
    <node id="PARTIAL RESPONSE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A partial response is an intermediate answer generated from community summaries before being combined into a final response</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">25</data>
      <data key="d5">e657b5121ff8456b9a610cfaead8e0cb</data>
    </node>
    <node id="FINAL RESPONSE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A final response is the comprehensive answer generated after combining all partial responses</data>
      <data key="d2">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">26</data>
      <data key="d5">bf4e255cdac94ccc83a56435a5e4b075</data>
    </node>
    <node id="COMPREHENSIVENESS">
      <data key="d0">METRIC</data>
      <data key="d1">COMPREHENSIVENESS is a metric used to evaluate the quality of generated responses by measuring how much detail an answer provides to cover all aspects and details of a question. It assesses the completeness and thoroughness of answers, ensuring that they encompass all relevant information. This metric is particularly important in evaluating the summarization approach, focusing on the completeness of the summary. In practical applications, such as evaluating Podcast transcripts and News articles, comprehensiveness has shown win rates between 72-83% and 72-80%, respectively.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,322e02986c8724eedbcf3ebfa20b989c,36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">9</data>
      <data key="d4">27</data>
      <data key="d5">3b040bcc19f14e04880ae52881a89c1c</data>
    </node>
    <node id="DIVERSITY">
      <data key="d0">METRIC</data>
      <data key="d1">DIVERSITY is a metric used to evaluate the variety and richness of answers generated in response to a question. It measures how varied and rich an answer is in providing different perspectives and insights. This metric is particularly important in assessing the quality of summarization approaches, focusing on the variety of information included in the summary. DIVERSITY is applied to various types of content, including Podcast transcripts, where win rates range from 75-82%, and News articles, with win rates ranging from 62-71%. It is a crucial target quality for evaluating the effectiveness of different methods in generating diverse and informative responses.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,322e02986c8724eedbcf3ebfa20b989c,36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,e8d83e6e7a7c0f57b218cef24976b745,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">7</data>
      <data key="d4">28</data>
      <data key="d5">3d6b216c14354332b1bf1927ba168986</data>
    </node>
    <node id="HUMAN ENDEAVORS">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Human endeavors refer to activities and efforts across various domains that rely on reading and reasoning about large collections of documents</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">37</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">29</data>
      <data key="d5">1c109cfdc370463eb6d537e5b7b382fb</data>
    </node>
    <node id="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Large Language Models (LLMs) are advanced AI models designed to understand and generate human-like text, playing a crucial role in automating sensemaking in complex domains. Modern language models, such as GPT, Llama, and Gemini, leverage in-context learning to effectively summarize content. These models are integral to the field of Natural Language Processing and Information Retrieval, enabling sophisticated text analysis and generation capabilities.</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d6">36</data>
      <data key="d7">1</data>
      <data key="d3">11</data>
      <data key="d4">30</data>
      <data key="d5">3d0dcbc8971b415ea18065edc4d8c8ef</data>
    </node>
    <node id="SCIENTIFIC DISCOVERY">
      <data key="d0">DOMAIN</data>
      <data key="d1">Scientific discovery is a complex domain where sensemaking is applied to understand and generate new knowledge from scientific texts</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">37</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">31</data>
      <data key="d5">68105770b523412388424d984e711917</data>
    </node>
    <node id="INTELLIGENCE ANALYSIS">
      <data key="d0">DOMAIN</data>
      <data key="d1">Intelligence analysis is a complex domain where sensemaking is applied to understand and generate insights from intelligence data</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">37</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">32</data>
      <data key="d5">85c79fd84f5e4f918471c386852204c5</data>
    </node>
    <node id="SENSEMAKING">
      <data key="d0">PROCESS</data>
      <data key="d1">SENSEMAKING is the process of understanding and making sense of complex information. It involves understanding connections among people, places, and events to anticipate their trajectories and act effectively. This process is crucial for navigating and interpreting intricate data landscapes, enabling individuals and organizations to make informed decisions based on the relationships and patterns identified within the information.</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">37</data>
      <data key="d7">1</data>
      <data key="d3">7</data>
      <data key="d4">33</data>
      <data key="d5">eae4259b19a741ab9f9f6af18c4a0470</data>
    </node>
    <node id="TEXT CHUNKS">
      <data key="d0">DATA</data>
      <data key="d1">TEXT CHUNKS are segments of text that are embedded into a vector space for analysis. These segments are extracted from source documents and are used for processing in the Graph RAG (Retrieval-Augmented Generation) approach. By embedding these text chunks into a vector space, they can be analyzed more effectively, facilitating various natural language processing and information retrieval tasks.</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">5</data>
      <data key="d4">34</data>
      <data key="d5">3138f39f2bcd43a69e0697cd3b05bc4d</data>
    </node>
    <node id="ELEMENT INSTANCES">
      <data key="d0">DATA</data>
      <data key="d1">Element instances are identified and extracted instances of graph nodes and edges from text chunks. They represent individual occurrences of entities, relationships, and claims extracted from source texts. These specific pieces of information are tailored to the domain, providing a structured representation of the underlying data.</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0,bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">59</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">35</data>
      <data key="d5">dde131ab575d44dbb55289a6972be18f</data>
    </node>
    <node id="ELEMENT SUMMARIES">
      <data key="d0">DATA</data>
      <data key="d1">Element summaries are concise representations of element instances, tailored to the domain. They are descriptive texts created by the LLM to summarize entities, relationships, and claims extracted from source texts. These summaries provide detailed descriptions of nodes, edges, and covariates within a community, and are used to understand the structure and semantics of the dataset. In essence, element summaries serve as a tool to encapsulate and convey the intricate details of elements within a graph, facilitating a deeper comprehension of the dataset's structural dynamics and semantic relationships.</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0,7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">59</data>
      <data key="d7">1</data>
      <data key="d3">10</data>
      <data key="d4">36</data>
      <data key="d5">de9e343f2e334d88a8ac7f8813a915e5</data>
    </node>
    <node id="GRAPH COMMUNITIES">
      <data key="d0">DATA</data>
      <data key="d1">Graph communities are groups of elements, including nodes, edges, and covariates, detected within a graph index, primarily used for summarization. These communities consist of groups of nodes that exhibit stronger connections to each other than to nodes outside the group. This structural characteristic allows for the identification and analysis of densely connected subgraphs, which can be crucial for understanding the underlying relationships and dynamics within complex networks.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">68</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">37</data>
      <data key="d5">e2bf260115514fb3b252fd879fb3e7be</data>
    </node>
    <node id="COMMUNITY ANSWERS">
      <data key="d0">DATA</data>
      <data key="d1">COMMUNITY ANSWERS are query-focused summaries derived from community summaries. These answers are generated in parallel from the community summaries and are designed to respond to user queries effectively. Essentially, COMMUNITY ANSWERS serve as responses that synthesize information from community summaries to provide concise and relevant answers to specific questions posed by users.</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd,f0306814bf64f5c9e79603fc6a52f4ea,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">38</data>
      <data key="d5">b462b94ce47a4b8c8fffa33f7242acec</data>
    </node>
    <node id="GLOBAL ANSWER">
      <data key="d0">DATA</data>
      <data key="d1">GLOBAL ANSWER is a comprehensive response generated from multiple community summaries to answer a user query. It is the final query-focused summary produced from all relevant community summaries. The final answer is generated by combining intermediate community answers based on their helpfulness scores.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,843fc5421e086120ffa1c75856ecf6cd,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">64</data>
      <data key="d7">1</data>
      <data key="d3">7</data>
      <data key="d4">39</data>
      <data key="d5">17ed1d92075643579a712cc6c29e8ddb</data>
    </node>
    <node id="INDEXING TIME">
      <data key="d0">TIME</data>
      <data key="d1">Indexing time refers to the time when the graph index is created and elements are summarized</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">63</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">40</data>
      <data key="d5">3ce7c210a21b4deebad7cc9308148d86</data>
    </node>
    <node id="QUERY TIME">
      <data key="d0">TIME</data>
      <data key="d1">Query time refers to the time when a query is made and the relevant summaries are generated</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">63</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">41</data>
      <data key="d5">d64ed762ea924caa95c8d06f072a9a96</data>
    </node>
    <node id="GRAPH RAG PIPELINE">
      <data key="d0">PROCESS</data>
      <data key="d1">Graph RAG pipeline is a process using an LLM-derived graph index to detect, extract, and summarize nodes, edges, and covariates in source documents</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">63</data>
      <data key="d7">1</data>
      <data key="d3">7</data>
      <data key="d4">42</data>
      <data key="d5">adf4ee3fbe9b4d0381044838c4f889c8</data>
    </node>
    <node id="NODES">
      <data key="d0">DATA</data>
      <data key="d1">NODES are entities detected in the graph index of source documents. They represent the individual elements or points in a graph. For instance, in the Podcast dataset, there are 8,564 nodes, while the News dataset contains 15,754 nodes.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">43</data>
      <data key="d5">32ee140946e5461f9275db664dc541a5</data>
    </node>
    <node id="EDGES">
      <data key="d0">DATA</data>
      <data key="d1">EDGES are relationships detected in the graph index of source documents. They represent the connections or links between nodes in a graph. For instance, in the Podcast dataset, there are 20,691 edges, while the News dataset contains 19,520 edges. These edges are crucial for understanding the structural dynamics and relationships within the datasets, providing insights into how different nodes (such as topics, entities, or documents) are interconnected.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">44</data>
      <data key="d5">c160b9cb27d6408ba6ab20214a2f3f81</data>
    </node>
    <node id="COVARIATES">
      <data key="d0">DATA</data>
      <data key="d1">Covariates are additional attributes associated with extracted node instances in the graph index. They represent claims or additional information detected in the graph index of source documents.</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">63</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">45</data>
      <data key="d5">23527cd679ff4d5a988d52e7cd056078</data>
    </node>
    <node id="LEIDEN">
      <data key="d0">METHOD</data>
      <data key="d1">LEIDEN is a community detection algorithm renowned for its efficiency in recovering hierarchical community structures. It is widely used to partition graphs into modular communities, effectively grouping elements within a graph index. The algorithm's ability to identify and organize these communities makes it a valuable tool in the analysis of complex networks, particularly within the domains of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">61</data>
      <data key="d7">1</data>
      <data key="d3">7</data>
      <data key="d4">46</data>
      <data key="d5">f1c6eed066f24cbdb376b910fce29ed4</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">METHOD</data>
      <data key="d1">Retrieval-Augmented Generation (RAG) is an established approach in the field of Natural Language Processing and Information Retrieval, designed to answer user questions over entire datasets. This method involves retrieving relevant text regions to provide grounding for the generation task, thereby enhancing the accuracy and relevance of the generated responses. By combining retrieval and generation processes, RAG effectively synthesizes and presents pertinent information, making it a powerful tool for handling complex queries and large datasets.</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d6">63</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">47</data>
      <data key="d5">83a6cb03df6b41d8ad6ee5f6fef5f024</data>
    </node>
    <node id="MICROSOFT">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft is a technology company whose Chief Technology Officer, Kevin Scott, actively participates in podcast conversations. The organization is deeply involved in automating sensemaking in scientific discovery through the use of large language models (LLMs). Notably, Microsoft conducted a study examining the impact of large language models, specifically GPT-4, on scientific discovery.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,833e7d67dcd30790b26b71c9b5306f6b,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">38</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">48</data>
      <data key="d5">147c038aef3e4422acbbc5f7938c4ab8</data>
    </node>
    <node id="RANADE">
      <data key="d0">PERSON</data>
      <data key="d1">Ranade is an author involved in research on automating sensemaking in intelligence analysis using LLMs</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">36</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">49</data>
      <data key="d5">b7702b90c7f24190b864e8c6e64612a5</data>
    </node>
    <node id="JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Joshi is an author involved in research on automating sensemaking in intelligence analysis using LLMs</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">36</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">50</data>
      <data key="d5">de6fa24480894518ab3cbcb66f739266</data>
    </node>
    <node id="KLEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Klein is an author who defined sensemaking and discussed its importance in understanding connections among people, places, and events</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">37</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">51</data>
      <data key="d5">6fae5ee1a831468aa585a1ea09095998</data>
    </node>
    <node id="LEWIS">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis is an author who contributed to the development of the retrieval-augmented generation (RAG) approach</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">63</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">52</data>
      <data key="d5">ef32c4b208d041cc856f6837915dc1b0</data>
    </node>
    <node id="TRAAG">
      <data key="d0">PERSON</data>
      <data key="d1">Traag is an author who contributed to the development of the Leiden community detection method</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">61</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">53</data>
      <data key="d5">07b2425216bd4f0aa4e079827cb48ef5</data>
    </node>
    <node id="ARXIV">
      <data key="d0">PUBLICATION</data>
      <data key="d1">arXiv is a preprint repository where several significant papers in the field of Natural Language Processing and Information Retrieval have been published. It serves as a platform for electronic preprints (known as e-prints) that are approved for publication after moderation, but not full peer review. Notable papers published on arXiv include "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models," "Lost in the middle: How language models use long contexts," "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management," "Llama 2: Open foundation and fine-tuned chat models," "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy," "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries," "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions," "Enhancing knowledge graph construction using large language models," "Is chatgpt a good nlg evaluator? a preliminary study," "Feb4rag: Evaluating federated search in the context of retrieval augmented generation," "Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt," "Causal graph discovery with retrieval-augmented generation based large language models," "Knowledge graph prompting for multi-document question answering," "Text summarization with latent queries," "Retrieval-augmented generation for large language models: A survey," and "Knowledge graph-augmented language models for knowledge-grounded dialogue generation." This repository is a crucial resource for researchers to disseminate their findings rapidly and access the latest advancements in their fields.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,086021a89900a39bcb62036981737bfa,58ae80c41cfe46db39da26b6a83584e5,6cd82819982879bd164547d2773ba5c7,71f6daf11e64e5273a3847d46bf228e1,833e7d67dcd30790b26b71c9b5306f6b,8d87efac8c50cf20cdf26bf61e5e2035,f0306814bf64f5c9e79603fc6a52f4ea,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">39</data>
      <data key="d4">54</data>
      <data key="d5">2670deebfa3f4d69bb82c28ab250a209</data>
    </node>
    <node id="PREPRINT">
      <data key="d0">PUBLICATION</data>
      <data key="d1">Preprint refers to the version of the research paper that is under review and available on arXiv</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">41</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">55</data>
      <data key="d5">404309e89a5241d6bff42c05a45df206</data>
    </node>
    <node id="CS.CL">
      <data key="d0">CATEGORY</data>
      <data key="d1">cs.CL is the category under which the research paper is classified on arXiv</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">41</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">56</data>
      <data key="d5">b785a9025069417f94950ad231bb1441</data>
    </node>
    <node id="24 APR 2024">
      <data key="d0">DATE</data>
      <data key="d1">24 Apr 2024 is the date when the research paper was submitted to arXiv</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">41</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">57</data>
      <data key="d5">3b6cd96a27304614850709aba1c9598b</data>
    </node>
    <node id="2404.16130V1">
      <data key="d0">IDENTIFIER</data>
      <data key="d1">2404.16130v1 is the identifier for the research paper on arXiv</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">41</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">58</data>
      <data key="d5">d54956b79dd147f894b67a8b97dcbef0</data>
    </node>
    <node id="DOCUMENT COLLECTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Document collections refer to large sets of documents that are analyzed for sensemaking</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">37</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">59</data>
      <data key="d5">958beecdb5bb4060948415ffd75d2b03</data>
    </node>
    <node id="LLM PROMPTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM PROMPTS are specific instructions given to large language models (LLMs) to tailor their responses to the domain of the dataset. These prompts are also used to extract elements from text chunks, ensuring that the LLMs provide relevant and precise information based on the given context.</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">36</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">60</data>
      <data key="d5">b999ed77e19e4f85b7f1ae79af5c002a</data>
    </node>
    <node id="COMMUNITY DETECTION">
      <data key="d0">METHOD</data>
      <data key="d1">Community detection is a method used to identify groups of related elements within a graph. It involves the process of identifying communities within a graph, which are clusters of nodes that are more densely connected internally than with the rest of the network. This technique is crucial in understanding the structural dynamics and relationships within complex networks, such as those found in social networks, biological systems, and information retrieval systems. By uncovering these communities, researchers can gain insights into the underlying structure and function of the network, facilitating more effective analysis and interpretation of the data.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">68</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">61</data>
      <data key="d5">48c0c4d72da74ff5bb926fa0c856d1a7</data>
    </node>
    <node id="DOMAIN-TAILORED SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">Domain-tailored summarization is a method used to create summaries that are specific to the domain of the dataset</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">59</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">62</data>
      <data key="d5">4f3c97517f794ebfb49c4c6315f9cf23</data>
    </node>
    <node id="KLEIN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Klein et al. are authors who defined sensemaking and discussed its importance in understanding connections among people, places, and events</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">37</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">63</data>
      <data key="d5">1745a2485a9443bab76587ad650e9be0</data>
    </node>
    <node id="RANADE AND JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ranade and Joshi are authors who discussed the use of LLMs in intelligence analysis</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">36</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">64</data>
      <data key="d5">32e6ccab20d94029811127dbbe424c64</data>
    </node>
    <node id="LEWIS ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis et al. are authors who developed the retrieval-augmented generation (RAG) approach</data>
      <data key="d2">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">63</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">65</data>
      <data key="d5">94a964c6992945ebb3833dfdfdc8d655</data>
    </node>
    <node id="TRAAG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Traag et al. are the authors who developed the Leiden algorithm, a method renowned for its efficiency in recovering hierarchical community structures. This algorithm is widely recognized in the field of Natural Language Processing and Information Retrieval for its ability to accurately detect and map out complex community dynamics.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d6">61</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">66</data>
      <data key="d5">1eb829d0ace042089f0746f78729696c</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d0">METHOD</data>
      <data key="d1">QFS is a task framing that focuses on generating summaries based on specific queries, rather than just concatenating excerpts</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">1</data>
      <data key="d4">67</data>
      <data key="d5">015e7b58d1a14b44beab3bbc9f912c18</data>
    </node>
    <node id="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A type of summarization that generates natural language summaries based on specific queries, rather than just extracting text</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">3</data>
      <data key="d4">68</data>
      <data key="d5">26f88ab3e2e04c33a459ad6270ade565</data>
    </node>
    <node id="TRANSFORMER ARCHITECTURE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A neural network architecture that has shown substantial improvements in various summarization tasks</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d3">3</data>
      <data key="d4">69</data>
      <data key="d5">babe97e1d9784cffa1c85abc1e588126</data>
    </node>
    <node id="GPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A series of large language models known for their ability to perform in-context learning and summarization</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d6">35</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">70</data>
      <data key="d5">1033a18c45aa4584b2aef6ab96890351</data>
    </node>
    <node id="LLAMA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A series of large language models known for their ability to perform in-context learning and summarization</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d6">40</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">71</data>
      <data key="d5">c9b8ce91fc2945b4907fe35519339cac</data>
    </node>
    <node id="GEMINI">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GEMINI is a family of highly capable multimodal models, as described in an arXiv preprint. These models are known for their ability to perform in-context learning and summarization, making them a significant advancement in the field of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">086021a89900a39bcb62036981737bfa,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d6">36</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">72</data>
      <data key="d5">fa3c4204421c48609e52c8de2da4c654</data>
    </node>
    <node id="KNOWLEDGE GRAPH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A knowledge graph is a structured representation of information, utilized in the Graph RAG approach for summarization. This structured representation of knowledge is specifically employed in the Graph RAG approach for global summarization, highlighting its role in organizing and integrating information to facilitate comprehensive and coherent summaries.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">73</data>
      <data key="d5">53af055f068244d0ac861b2e89376495</data>
    </node>
    <node id="LEWIS ET AL., 2020">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on Retrieval-augmented generation (RAG)</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d6">63</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">74</data>
      <data key="d5">c03ab3ce8cb74ad2a03b94723bfab3c7</data>
    </node>
    <node id="DANG, 2006">
      <data key="d0">REFERENCE</data>
      <data key="d1">Author of a paper on query-focused summarization (QFS)</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d3">1</data>
      <data key="d4">75</data>
      <data key="d5">ed6d2eee9d7b4f5db466b1f6404d31cc</data>
    </node>
    <node id="BAUMEL ET AL., 2018">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on query-focused abstractive summarization</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d3">1</data>
      <data key="d4">76</data>
      <data key="d5">fc01e9baa80e417c9206f941bb279407</data>
    </node>
    <node id="LASKAR ET AL., 2020">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on query-focused abstractive summarization</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d3">1</data>
      <data key="d4">77</data>
      <data key="d5">56d0e5ebe79e4814bd1463cf6ca21394</data>
    </node>
    <node id="YAO ET AL., 2017">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on query-focused abstractive summarization</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d3">1</data>
      <data key="d4">78</data>
      <data key="d5">7c49f2710e8b4d3b8dc9310834406ea5</data>
    </node>
    <node id="GOODWIN ET AL., 2020">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the early applications of the transformer architecture</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d3">1</data>
      <data key="d4">79</data>
      <data key="d5">c6d1e4f56c2843e89cf0b91c10bb6de2</data>
    </node>
    <node id="LASKAR ET AL., 2022">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the early applications of the transformer architecture</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d3">1</data>
      <data key="d4">80</data>
      <data key="d5">0adb2d9941f34ef7b2f7743cc6225844</data>
    </node>
    <node id="LIU AND LAPATA, 2019">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the early applications of the transformer architecture</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d3">1</data>
      <data key="d4">81</data>
      <data key="d5">6b02373137fd438ba96af28f735cdbdb</data>
    </node>
    <node id="ACHIAM ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the GPT series of large language models</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d6">35</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">82</data>
      <data key="d5">36a4fcd8efc144e6b8af9a1c7ab8b2ce</data>
    </node>
    <node id="BROWN ET AL., 2020">
      <data key="d0">REFERENCE</data>
      <data key="d1">"BROWN ET AL., 2020" refers to a publication by Brown et al. in 2020, which discusses in-context learning with few-shot examples. The authors of this paper are also known for their work on the GPT series of large language models.</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d6">35</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">83</data>
      <data key="d5">fbeef791d19b413a9c93c6608286ab63</data>
    </node>
    <node id="TOUVRON ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the Llama series of large language models</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d6">40</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">84</data>
      <data key="d5">d2b629c0396f4180a03e16ddf3818589</data>
    </node>
    <node id="ANIL ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">Authors of a paper on the Gemini series of large language models</data>
      <data key="d2">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d6">36</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">85</data>
      <data key="d5">6102fc6619ed422ebc42588bfa97355d</data>
    </node>
    <node id="KURATOV ET AL., 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">"KURATOV ET AL., 2024" refers to a publication by Kuratov and colleagues in 2024. The study discusses the recall degradation and potential for information loss in longer context windows of Large Language Models (LLMs). The authors explore the limitations of these extended context windows, providing insights into how the performance of LLMs can be affected when dealing with longer sequences of text.</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f,bc9e2c9e369c4108cf4f6dd5f60960f4,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d6">36</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">86</data>
      <data key="d5">8d141c0b80f74b79a05eed7fe161fe49</data>
    </node>
    <node id="LIU ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">"LIU ET AL., 2023" refers to a publication by Liu et al. in 2023, which discusses the recall degradation and potential for information loss in longer context windows of large language models (LLMs). The authors explore the limitations of LLM context windows, highlighting how extended contexts can lead to decreased recall accuracy and information retention.</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f,bc9e2c9e369c4108cf4f6dd5f60960f4,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d8">REFERENCE</data>
      <data key="d6">36</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">87</data>
      <data key="d5">e22d1d1cd8d14f12b81828d940f40d70</data>
    </node>
    <node id="COMMUNITY DETECTION ALGORITHMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">COMMUNITY DETECTION ALGORITHMS are algorithms used to partition a graph into communities of nodes with stronger connections to one another. These algorithms are designed to identify modular communities of closely-related nodes within a graph, thereby revealing the underlying structure and relationships within the network.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d6">61</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">88</data>
      <data key="d5">9ab48505fb1b487babd0d1f6d3a3f980</data>
    </node>
    <node id="LOUVAIN">
      <data key="d0">ALGORITHM</data>
      <data key="d1">Louvain is a community detection algorithm used to partition graphs into modular communities</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">61</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">89</data>
      <data key="d5">148fffeb994541b2b4b6dcefda7001a8</data>
    </node>
    <node id="HOTPOTQA">
      <data key="d0">DATASET</data>
      <data key="d1">HOTPOTQA is a benchmark dataset designed for open-domain question answering, specifically targeting explicit fact retrieval. It serves as a critical resource for evaluating entity extraction prompts, particularly with advanced models like GPT-4-turbo. Additionally, HotPotQA is utilized to observe the behavior of text chunk extraction within the Graph RAG (Retrieval-Augmented Generation) approach, making it a versatile tool in the Natural Language Processing and Information Retrieval domain.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,922778ce1cb2fdd6dbab1746c8795620,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">39</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">90</data>
      <data key="d5">89c08e793298442686292454a1abff31</data>
    </node>
    <node id="GPT-4-TURBO">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4-Turbo is a version of the GPT-4 model characterized by its large context size of 128k tokens, which is utilized in various analytical tasks. Specifically, GPT-4-Turbo is employed for entity extraction in evaluations, leveraging its extensive context capacity to enhance the accuracy and comprehensiveness of the analysis. This model is particularly suited for tasks within the Natural Language Processing and Information Retrieval domain, where handling large volumes of text and extracting relevant entities are critical.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d6">39</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">91</data>
      <data key="d5">0467928aa65e4a4fba62bdb1467e3a54</data>
    </node>
    <node id="PODCAST TRANSCRIPTS">
      <data key="d0">DATASET</data>
      <data key="d1">The "PODCAST TRANSCRIPTS" dataset is a comprehensive collection of compiled transcripts from podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders. This dataset is used for analysis and consists of 1669 text chunks, each containing 600 tokens with 100-token overlaps between chunks, amounting to approximately 1 million tokens in total.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,21e52bc06a82796b1f4bcd73edda1f2a,36db32c37e1987e2c5863898ad882190,922778ce1cb2fdd6dbab1746c8795620,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">19</data>
      <data key="d4">92</data>
      <data key="d5">43c3390303c6476cb65f584e37c3e81c</data>
    </node>
    <node id="NEWS ARTICLES">
      <data key="d0">DATASET</data>
      <data key="d1">The "NEWS ARTICLES" dataset is a comprehensive collection of news articles used for analysis. It serves as a benchmark dataset comprising news articles published from September 2013 to December 2023. The dataset spans a range of categories, including entertainment, business, sports, technology, health, and science. It consists of 3197 text chunks, each containing 600 tokens, with a 100-token overlap between chunks, amounting to approximately 1.7 million tokens in total.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,21e52bc06a82796b1f4bcd73edda1f2a,36db32c37e1987e2c5863898ad882190,922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">13</data>
      <data key="d4">93</data>
      <data key="d5">fa14b16c17e3417dba5a4b473ea5b18d</data>
    </node>
    <node id="MAP-REDUCE">
      <data key="d0">METHOD</data>
      <data key="d1">MAP-REDUCE is a method employed for text summarization by applying a map-reduce approach directly to source texts. It is particularly utilized for query-focused summarization of an entire corpus, enabling efficient processing and extraction of relevant information from large datasets. This technique leverages the map-reduce paradigm to distribute the computational workload, making it suitable for handling extensive text collections in the domain of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">70</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">94</data>
      <data key="d5">7cc3356d38de4328a51a5cbcb187dac3</data>
    </node>
    <node id="EMPOWERMENT">
      <data key="d0">METRIC</data>
      <data key="d1">"EMPOWERMENT" is a concept and metric used in the evaluation of various methods, with an average win rate of 51.3%. It measures how well an answer helps the reader understand and make informed judgments about a topic. Specifically, it evaluates the effectiveness of generated answers in empowering users by developing their understanding of broad issues and themes. Empowerment is a target quality in summarization approaches, focusing on the ability to help users reach an informed understanding.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,322e02986c8724eedbcf3ebfa20b989c,36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">23</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">95</data>
      <data key="d5">bef16fb5fd7344cca5e295b13ef3e0cd</data>
    </node>
    <node id="NAIVE RAG">
      <data key="d0">METHOD</data>
      <data key="d1">Naive RAG is a basic retrieval-augmented generation (RAG) method used as a baseline for comparison in text generation tasks. It converts documents to text, splits them into chunks, and embeds these chunks into a vector space for query matching. While it produces the most direct responses, it is outperformed by global approaches in terms of comprehensiveness and diversity. Naive RAG is also noted for listing public figures mentioned in entertainment articles, focusing on their professional achievements and personal lives.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">13</data>
      <data key="d4">96</data>
      <data key="d5">bb9e01bc171d4326a29afda59ece8d17</data>
    </node>
    <node id="GLOBAL MAP-REDUCE SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A method for summarizing source texts using a map-reduce approach</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">97</data>
      <data key="d5">3c063eea52e94164b70c99431ea30bae</data>
    </node>
    <node id="ACTIVITY-CENTERED SENSEMAKING QUESTIONS">
      <data key="d0">OUTPUT</data>
      <data key="d1">Questions generated to evaluate the summarization approach, focusing on understanding activities</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">98</data>
      <data key="d5">252cc8452bfc4c2aa58cab68d8b61879</data>
    </node>
    <node id="HIERARCHICAL LEVEL">
      <data key="d0">PARAMETER</data>
      <data key="d1">The level of detail in community summaries used to answer queries</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">99</data>
      <data key="d5">7e2c84548fb94ee395ba8588d8f2a006</data>
    </node>
    <node id="TOKEN COSTS">
      <data key="d0">METRIC</data>
      <data key="d1">TOKEN COSTS refer to the computational cost measured in tokens used in the summarization process. Specifically, in the context of the Graph RAG (Retrieval-Augmented Generation) approach, token costs denote the number of tokens required for processing text. This metric is crucial for evaluating the efficiency and scalability of text processing methods within the Natural Language Processing and Information Retrieval domain.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">100</data>
      <data key="d5">f034618dde7948beb6dab30176d0fc87</data>
    </node>
    <node id="DATA FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">The high-level process of the Graph RAG approach and pipeline</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">101</data>
      <data key="d5">5c41f96be13e49dba649454297834546</data>
    </node>
    <node id="DESIGN PARAMETERS">
      <data key="d0">PARAMETER</data>
      <data key="d1">Design parameters are key settings and configurations in the Graph RAG approach. These parameters are crucial as they influence the design of the Graph RAG approach and pipeline, determining the effectiveness and efficiency of the overall system.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d8">PARAMETER</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">102</data>
      <data key="d5">7ea4afbf8a264f29af29950ce98105ba</data>
    </node>
    <node id="GLOBAL SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">GLOBAL SUMMARIZATION is a method for summarizing information on a global scale. It aims to encapsulate the overall structure and semantics of a dataset, providing a comprehensive overview of information from large datasets or corpora. This technique is particularly useful in the field of Natural Language Processing and Information Retrieval, where it helps in distilling vast amounts of data into coherent and concise summaries, facilitating better understanding and analysis of the underlying information.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,7fb7d9ce2da9c940a32afdd87d1d9e56,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">55</data>
      <data key="d7">1</data>
      <data key="d3">5</data>
      <data key="d4">103</data>
      <data key="d5">91ff849d12b24574b0691dbddf44968b</data>
    </node>
    <node id="MODULARITY">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Modularity is an inherent quality of graphs that allows them to be partitioned into communities of closely-related nodes</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">104</data>
      <data key="d5">d73c1f2fb3094d8dace42ad2a76e9a52</data>
    </node>
    <node id="COMMUNITY DESCRIPTIONS">
      <data key="d0">OUTPUT</data>
      <data key="d1">Descriptions generated from modular communities in the knowledge graph</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">105</data>
      <data key="d5">cdc8901e668749889bd49bebdc4ff1f6</data>
    </node>
    <node id="QUERY">
      <data key="d0">INPUT</data>
      <data key="d1">A specific question or request for information that the summarization methods aim to answer</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">106</data>
      <data key="d5">36084a9fab53433493f079e97e68bf65</data>
    </node>
    <node id="CORPUS">
      <data key="d0">DATASET</data>
      <data key="d1">A large collection of texts or documents used for analysis and summarization</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">107</data>
      <data key="d5">eebcc7ec8e3e4df7aea83659bbdc2199</data>
    </node>
    <node id="PARTIAL ANSWERS">
      <data key="d0">OUTPUT</data>
      <data key="d1">Intermediate answers generated from community summaries before being combined into a final global answer</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">108</data>
      <data key="d5">ceadf262ef834e9ab146b20650912cae</data>
    </node>
    <node id="FINAL GLOBAL ANSWER">
      <data key="d0">OUTPUT</data>
      <data key="d1">The comprehensive answer generated by combining all relevant partial answers</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">109</data>
      <data key="d5">7f65feab75424b53b24470d305ba331a</data>
    </node>
    <node id="ACTIVITY-CENTERED SENSEMAKING">
      <data key="d0">METHOD</data>
      <data key="d1">A method that focuses on generating questions to understand activities from datasets</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">49</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">110</data>
      <data key="d5">fd9cb733b28d420cb5cef01e545a132c</data>
    </node>
    <node id="SHORT DESCRIPTIONS">
      <data key="d0">INPUT</data>
      <data key="d1">Brief descriptions of datasets used to generate sensemaking questions</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">49</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">111</data>
      <data key="d5">0fbcca3f17c649a08aea64b5a7d9ef36</data>
    </node>
    <node id="REAL-WORLD DATASETS">
      <data key="d0">DATASET</data>
      <data key="d1">Datasets that represent real-world information, such as podcast transcripts and news articles</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">112</data>
      <data key="d5">482027a59f32484c9c44fd700615c1b6</data>
    </node>
    <node id="HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES">
      <data key="d0">PARAMETER</data>
      <data key="d1">The level of detail in community summaries used to answer queries</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">113</data>
      <data key="d5">de837ff3d626451282ff6ac77a82216d</data>
    </node>
    <node id="SOURCE TEXT SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A method that summarizes the original source texts directly</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">114</data>
      <data key="d5">460295fed3ae4cd39f9f274cec9c2506</data>
    </node>
    <node id="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">OUTPUT</data>
      <data key="d1">LOW-LEVEL COMMUNITY SUMMARIES are a type of community summary used in the News dataset for analysis. These summaries provide a detailed overview of the source text and are generated from lower hierarchical levels of the community in the knowledge graph.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,6f33a085ff3304e5994f7fbb86c881a4,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">115</data>
      <data key="d5">553b285bba60460ab1ed8341ae61282b</data>
    </node>
    <node id="INTERMEDIATE-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">OUTPUT</data>
      <data key="d1">INTERMEDIATE-LEVEL COMMUNITY SUMMARIES are summaries that provide a mid-level overview of the source text. These summaries are generated from intermediate hierarchical levels of the community in the knowledge graph, offering a balanced perspective that captures essential details without overwhelming the reader with excessive information. This approach ensures that the summaries are both informative and concise, making them valuable for understanding the structural dynamics and relationships within specialized communities, particularly in the domain of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">116</data>
      <data key="d5">cec95bf17e7e4c939b56c9c6f402a29f</data>
    </node>
    <node id="HIGH-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">OUTPUT</data>
      <data key="d1">Summaries generated from higher hierarchical levels of the community in the knowledge graph</data>
      <data key="d2">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">117</data>
      <data key="d5">599164aead034bc19446efacc77554d2</data>
    </node>
    <node id="PIPELINE">
      <data key="d0">PROCESS, SYSTEM</data>
      <data key="d1">The entity "PIPELINE" refers to a series of processes or steps used to analyze and summarize a dataset. Specifically, in the context of the Graph RAG approach, the pipeline denotes the sequence of steps and processes involved. This structured sequence is essential for systematically handling data, ensuring that each stage of the analysis is methodically executed to achieve accurate and comprehensive results.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">68</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">118</data>
      <data key="d5">bbf148ae4d48422f8fdef754cfa2b9e4</data>
    </node>
    <node id="GRAPH INDEX">
      <data key="d0">DATA STRUCTURE, OUTPUT</data>
      <data key="d1">The "GRAPH INDEX" is a data structure used in Retrieval-Augmented Generation (RAG) systems to organize and retrieve information. It is a self-generated index that enables Graph RAG by utilizing a graph structure to organize and retrieve data. This index is created from a graph structure and is employed for tasks such as query-focused summarization. The graph index includes various elements extracted from text chunks using Large Language Model (LLM) prompts. Additionally, it supports conditions C0-C3 and is created using generic prompts for entity and relationship extraction.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,92e93fc6449756c0a60200636b297f65,973164fa90bf2b4ee267f4fd795916bf,bc9e2c9e369c4108cf4f6dd5f60960f4,e4d9b12cf2b4c691c74019eefff4fb39,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">22</data>
      <data key="d7">1</data>
      <data key="d3">18</data>
      <data key="d4">119</data>
      <data key="d5">de61b2670999433f807a6a1dc2b81e43</data>
    </node>
    <node id="ENTITY REFERENCES">
      <data key="d0">DATA, UNIT</data>
      <data key="d1">Entity references are mentions of entities within text chunks, extracted during the processing</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">120</data>
      <data key="d5">3e95dacfe57b4d57b5da4310ef2e157f</data>
    </node>
    <node id="RECALL">
      <data key="d0">METRIC</data>
      <data key="d1">Recall is a metric used to measure the completeness of entity extraction from text chunks</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">121</data>
      <data key="d5">1f1545308e9347af91fd03b94aadc21f</data>
    </node>
    <node id="PRECISION">
      <data key="d0">METRIC</data>
      <data key="d1">Precision is a metric used to measure the accuracy of entity extraction from text chunks</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">122</data>
      <data key="d5">6ea81acaf232485e94fff638e03336e1</data>
    </node>
    <node id="FEW-SHOT EXAMPLES">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">FEW-SHOT EXAMPLES are specialized instances provided to the Large Language Model (LLM) to improve its performance in domains with specialized knowledge such as science, medicine, and law. These examples are tailored to the domain of the data used in the graph indexing process and serve as sample inputs for in-context learning. By tailoring the extraction prompt to the document corpus domain, few-shot examples enhance the LLM's ability to understand and process domain-specific information effectively.</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0,973164fa90bf2b4ee267f4fd795916bf,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">8</data>
      <data key="d4">123</data>
      <data key="d5">d136b08d586d488f9e4188b524c85a29</data>
    </node>
    <node id="NAMED ENTITIES">
      <data key="d0">DATA, UNIT</data>
      <data key="d1">Named entities are specific types of entities such as people, places, and organizations, extracted from text chunks</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">124</data>
      <data key="d5">cccfa151fedc4b218a8d96adc7dceabe</data>
    </node>
    <node id="YANG ET AL., 2018">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Yang et al. in 2018, introducing the HotPotQA dataset</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">39</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">125</data>
      <data key="d5">ce54725672a74ebcabe6127577dacb2b</data>
    </node>
    <node id="TECHNIQUES">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Techniques refer to the specific methods used in the Graph RAG approach</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">126</data>
      <data key="d5">ea2b28ca1a974ffab4517811dc1d1e5c</data>
    </node>
    <node id="IMPLEMENTATION DETAILS">
      <data key="d0">ATTRIBUTE, CONFIGURATION</data>
      <data key="d1">Implementation details are specific configurations and settings used in the Graph RAG approach</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">127</data>
      <data key="d5">aff21f1da1654e7babdcf3fb0e4a75fc</data>
    </node>
    <node id="SINGLE EXTRACTION ROUND">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">A single extraction round refers to one complete cycle of extracting elements from text chunks using LLM prompts</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">128</data>
      <data key="d5">dc2cc9016e3f49dbac7232f05cce794d</data>
    </node>
    <node id="CHUNK SIZE">
      <data key="d0">ATTRIBUTE, CONFIGURATION</data>
      <data key="d1">Chunk size refers to the length of text chunks used in the extraction process</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">129</data>
      <data key="d5">6ea0cef05f694dcea455478f40674e45</data>
    </node>
    <node id="RECALL DEGRADATION">
      <data key="d0">METRIC, ISSUE</data>
      <data key="d1">Recall degradation refers to the decrease in recall performance when using longer LLM context windows</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">130</data>
      <data key="d5">7ab5d53a872f4dfc98f3d386879f3c75</data>
    </node>
    <node id="EXTRACTION PROCESS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The extraction process involves identifying and extracting elements from text chunks using LLM prompts</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">131</data>
      <data key="d5">af1d0fec22114a3398b8016f5225f9ed</data>
    </node>
    <node id="DOMAIN">
      <data key="d0">ATTRIBUTE, CONFIGURATION</data>
      <data key="d1">Domain refers to the specific area of knowledge or field to which the document corpus belongs</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">132</data>
      <data key="d5">b07a7f088364459098cd8511ff27a4c8</data>
    </node>
    <node id="DOCUMENT CORPUS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Document corpus refers to the collection of documents being processed in the Graph RAG approach</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">60</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">133</data>
      <data key="d5">8870cf2b5df64d2cab5820f67e29b9f1</data>
    </node>
    <node id="DEFAULT PROMPT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Default prompt is the standard set of instructions given to the LLM for extracting named entities</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">134</data>
      <data key="d5">cd130938a2844050be991af70baf5ee0</data>
    </node>
    <node id="SECONDARY EXTRACTION PROMPT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Secondary extraction prompt is an additional set of instructions given to the LLM for extracting covariates</data>
      <data key="d2">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">135</data>
      <data key="d5">43544b99c3b04b059546198a0ae6366d</data>
    </node>
    <node id="COVARIATE PROMPT">
      <data key="d0">METHOD</data>
      <data key="d1">A covariate prompt is used to extract additional attributes associated with detected entities, including claims linked to the entities</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d3">2</data>
      <data key="d4">136</data>
      <data key="d5">a671bf7fea2f4514b6e96ba99127fafd</data>
    </node>
    <node id="CLAIMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Claims are statements or assertions linked to detected entities, including details such as subject, object, type, description, source text span, and start and end dates</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d3">7</data>
      <data key="d4">137</data>
      <data key="d5">525f41ea20274a05af4e52b625b473f3</data>
    </node>
    <node id="GLEANINGS">
      <data key="d0">METHOD</data>
      <data key="d1">Gleanings refer to multiple rounds of entity extraction to ensure that no entities are missed in the process</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">138</data>
      <data key="d5">071a416efbec4f0886c19ac68f6d43cb</data>
    </node>
    <node id="LOGIT BIAS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Logit bias is a technique used to force a yes/no decision from the LLM during the entity extraction process</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">139</data>
      <data key="d5">6d8473ef3b1042bf87178a611e3dbcc6</data>
    </node>
    <node id="ENTITY NODE">
      <data key="d0">CONCEPT</data>
      <data key="d1">An entity node is a representation of an entity in a graph structure</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d6">59</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">140</data>
      <data key="d5">30c9641543c24773938bd8ec57ea98ab</data>
    </node>
    <node id="RELATIONSHIP EDGE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A relationship edge is a representation of a relationship between entities in a graph structure</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d6">59</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">141</data>
      <data key="d5">18b839da898e4026b81727d759d95c6a</data>
    </node>
    <node id="CLAIM COVARIATE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A claim covariate is an additional attribute or variable associated with a claim in a graph structure</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d6">59</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">142</data>
      <data key="d5">eeef6ae5c464400c8755900b4f1ac37a</data>
    </node>
    <node id="COMMUNITIES OF ENTITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Communities of entities are groups of closely-related entities detected and summarized by the LLM</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">143</data>
      <data key="d5">422433aa45804c7ebb973b2fafce5da6</data>
    </node>
    <node id="NOISY GRAPH STRUCTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The "NOISY GRAPH STRUCTURE" refers to a graph structure that may contain inconsistencies or errors, making it challenging to analyze. This type of graph often includes duplicate or inconsistent entity elements due to variations in text format. These inconsistencies can arise from various sources, such as data entry errors, differing data formats, or incomplete information, which complicate the process of extracting meaningful insights and relationships from the graph.</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0,7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">144</data>
      <data key="d5">86505bca739d4bccaaa1a8e0f3baffdc</data>
    </node>
    <node id="SCIENCE">
      <data key="d0">DOMAIN</data>
      <data key="d1">Science is a specialized domain that benefits from few-shot examples to improve LLM performance</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">145</data>
      <data key="d5">1af9faf341e14a5bbf4ddc9080e8dc0b</data>
    </node>
    <node id="MEDICINE">
      <data key="d0">DOMAIN</data>
      <data key="d1">Medicine is a specialized domain that benefits from few-shot examples to improve LLM performance</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">146</data>
      <data key="d5">353d91abc68648639d65a549e59b5cf3</data>
    </node>
    <node id="LAW">
      <data key="d0">DOMAIN</data>
      <data key="d1">Law is a specialized domain that benefits from few-shot examples to improve LLM performance</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">147</data>
      <data key="d5">7ce637e4f35b42e3a9f8272cab69cd22</data>
    </node>
    <node id="SOURCE TEXT SPAN">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Source text span is an attribute of a claim that indicates the specific portion of text from which the claim was extracted</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d3">1</data>
      <data key="d4">148</data>
      <data key="d5">4d999d7744b04a998475f8f8531589f0</data>
    </node>
    <node id="START DATE">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Start date is an attribute of a claim that indicates when the event or fact described in the claim began</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d3">1</data>
      <data key="d4">149</data>
      <data key="d5">9a6f414210e14841a5b0e661aedc898d</data>
    </node>
    <node id="END DATE">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">End date is an attribute of a claim that indicates when the event or fact described in the claim ended</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d3">1</data>
      <data key="d4">150</data>
      <data key="d5">db541b7260974db8bac94e953009f60e</data>
    </node>
    <node id="DESCRIPTION">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Description is an attribute of a claim that provides a detailed explanation of the claim</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d3">1</data>
      <data key="d4">151</data>
      <data key="d5">f2ff8044718648e18acef16dd9a65436</data>
    </node>
    <node id="SUBJECT">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Subject is an attribute of a claim that indicates the main entity involved in the claim</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d3">1</data>
      <data key="d4">152</data>
      <data key="d5">00d785e7d76b47ec81b508e768d40584</data>
    </node>
    <node id="OBJECT">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Object is an attribute of a claim that indicates the entity that is affected by the subject in the claim</data>
      <data key="d2">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d3">1</data>
      <data key="d4">153</data>
      <data key="d5">87915637da3e474c9349bd0ae604bd95</data>
    </node>
    <node id="COMMON ENTITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A concept referring to an entity that has multiple name variations but is resilient to such variations due to sufficient connectivity to closely-related entities</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d3">1</data>
      <data key="d4">154</data>
      <data key="d5">8f1eba29f39e411188200bf0d14628ec</data>
    </node>
    <node id="LLMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Large Language Models (LLMs) are advanced AI models capable of understanding and generating human-like text. They are utilized for a variety of tasks, including the creation and completion of knowledge graphs, which are essential for structuring and interlinking information in a meaningful way. Additionally, LLMs serve as evaluators of natural language generation, assessing the quality and coherence of text produced by other AI systems. These models play a crucial role in the field of Natural Language Processing and Information Retrieval, contributing significantly to advancements in how machines comprehend and interact with human language.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,92e93fc6449756c0a60200636b297f65,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">31</data>
      <data key="d7">1</data>
      <data key="d3">5</data>
      <data key="d4">155</data>
      <data key="d5">7282c73622b8408e97289d959faff483</data>
    </node>
    <node id="KNOWLEDGE GRAPHS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Structured representations of knowledge in the form of triples (subject, predicate, object) used for reasoning tasks</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d6">22</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">156</data>
      <data key="d5">3deb220d31f74103aa44870a36a63220</data>
    </node>
    <node id="HOMOGENEOUS NODES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Nodes in a graph that are of the same type and are described using rich descriptive text</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d3">2</data>
      <data key="d4">157</data>
      <data key="d5">af7a1584dd15492cb9a4940e285f57fc</data>
    </node>
    <node id="RELATIONSHIP EDGES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Edges in a graph that represent relationships between entity nodes</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d3">2</data>
      <data key="d4">158</data>
      <data key="d5">6e8d9029ce4e4ea182367173ab2c7bbf</data>
    </node>
    <node id="EDGE WEIGHTS">
      <data key="d0">METRIC</data>
      <data key="d1">Weights assigned to edges in a graph, representing the normalized counts of detected relationship instances</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d3">1</data>
      <data key="d4">159</data>
      <data key="d5">cbf232211e7d4eb6abdbe182f71c2cf0</data>
    </node>
    <node id="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The "HIERARCHICAL COMMUNITY STRUCTURE" is a framework in which communities are organized in a hierarchy, with each level providing a partition of the graph nodes. This structure organizes data into a hierarchy of communities, facilitating a multi-level clustering approach. Hierarchical community structure is utilized to generate community summaries, offering a comprehensive method for understanding the relationships and structural dynamics within specialized communities.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">65</data>
      <data key="d7">1</data>
      <data key="d3">7</data>
      <data key="d4">160</data>
      <data key="d5">bb0cff774a4440b289cc6f3b929fe13c</data>
    </node>
    <node id="COMMUNITY PARTITION">
      <data key="d0">CONCEPT</data>
      <data key="d1">A division of graph nodes into mutually-exclusive, collectively-exhaustive communities</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d6">55</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">161</data>
      <data key="d5">ce55841ebfdd47008bab8c258f10372e</data>
    </node>
    <node id="MULTIHOP-RAG">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">MULTIHOP-RAG is a benchmark dataset comprising news articles published from September 2013 to December 2023, covering a range of categories including entertainment, business, sports, technology, health, and science. It is specifically designed for open-domain question answering, targeting explicit fact retrieval. Additionally, MULTIHOP-RAG represents a specific implementation or variant of Retrieval-Augmented Generation (RAG) used in the context of graph communities. This dataset is also utilized for community detection and analysis, making it a versatile tool in the field of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd,922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d6">62</data>
      <data key="d7">1</data>
      <data key="d3">8</data>
      <data key="d4">162</data>
      <data key="d5">6090e736374d45fd84f0e4610a314f8f</data>
    </node>
    <node id="FORTUNATO">
      <data key="d0">PERSON</data>
      <data key="d1">An author who has conducted surveys on community detection algorithms</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d6">61</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">163</data>
      <data key="d5">0e8d921ccd8d4a8594b65b7fd19f7120</data>
    </node>
    <node id="JIN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Authors who have conducted surveys on community detection algorithms</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d6">61</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">164</data>
      <data key="d5">59c726a8792d443e84ab052cb7942b4a</data>
    </node>
    <node id="DATASET">
      <data key="d0">CONCEPT</data>
      <data key="d1">The entity "DATASET" refers to a collection of data used for various purposes such as analysis, summarization, and evaluation. This can include diverse types of data like podcast transcripts and news articles. Specifically, the term encompasses datasets used for evaluation purposes, including notable examples like the Podcast and News datasets.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,7fb7d9ce2da9c940a32afdd87d1d9e56,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d3">3</data>
      <data key="d4">165</data>
      <data key="d5">4f2c665decf242b0bfcaf7350b0e02ed</data>
    </node>
    <node id="GLOBAL QUERIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">GLOBAL QUERIES refer to questions or inquiries that require comprehensive answers derived from multiple sources or datasets. These queries aim to retrieve information from a global perspective, covering the entire dataset.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">70</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">166</data>
      <data key="d5">66cdf168f36d4a57a505028c97dc06e0</data>
    </node>
    <node id="ROOT COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">ROOT COMMUNITIES are the top-level clusters in a hierarchical community structure. These communities represent the highest level of organization within the hierarchy, serving as the primary divisions from which more specific sub-communities branch out.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">65</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">167</data>
      <data key="d5">38f51478f41f48db9bee570859b6f43e</data>
    </node>
    <node id="SUB-COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">SUB-COMMUNITIES are lower-level clusters within root communities in a hierarchical community structure, providing more detailed information. These sub-communities play a crucial role in breaking down the larger, more general root communities into more specific and focused groups, thereby facilitating a deeper and more granular understanding of the overall community dynamics.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">65</data>
      <data key="d7">1</data>
      <data key="d3">5</data>
      <data key="d4">168</data>
      <data key="d5">896d2a51e8de47de85ba8ced108c3d53</data>
    </node>
    <node id="REPORTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Detailed documents that provide information about specific subtopics within a community</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d6">65</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">169</data>
      <data key="d5">14555b518e954637b83aa762dc03164e</data>
    </node>
    <node id="PARTITION">
      <data key="d0">CONCEPT</data>
      <data key="d1">The division of a graph into distinct communities</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d6">68</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">170</data>
      <data key="d5">b1f6164116d44fe8b8f135d7f65b9e58</data>
    </node>
    <node id="HIERARCHY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A system in which elements are ranked or organized in levels</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d6">68</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">171</data>
      <data key="d5">c8b2408617804483b620e1a6691ac90d</data>
    </node>
    <node id="LEVEL 0">
      <data key="d0">CONCEPT</data>
      <data key="d1">LEVEL 0 represents the root-level communities in the hierarchical clustering with maximum modularity. It serves as the foundational layer in a hierarchical community structure, indicating the initial and most significant division of the dataset into distinct groups.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">68</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">172</data>
      <data key="d5">a5e0d1644eb547ba9a5c3211aac4631a</data>
    </node>
    <node id="LEVEL 1">
      <data key="d0">CONCEPT</data>
      <data key="d1">LEVEL 1 is a sub-level in a hierarchical community structure, providing more detailed information about the internal organization. Specifically, Level 1 represents sub-communities within the root-level communities, thereby revealing the internal structure and dynamics of these larger groups. This level of granularity helps in understanding the intricate relationships and specialized interactions that occur within the broader community framework.</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">68</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">173</data>
      <data key="d5">5a28b94bc63b44edb30c54748fd14f15</data>
    </node>
    <node id="FIGURE 3">
      <data key="d0">CONCEPT</data>
      <data key="d1">A visual representation of graph communities detected using the Leiden algorithm</data>
      <data key="d2">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d6">61</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">174</data>
      <data key="d5">f97011b2a99d44648e18d517e1eae15c</data>
    </node>
    <node id="LEIDEN ALGORITHM">
      <data key="d0">METHOD</data>
      <data key="d1">The Leiden algorithm is a method used for detecting communities in large networks</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">62</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">175</data>
      <data key="d5">35489ca6a63b47d6a8913cf333818bc1</data>
    </node>
    <node id="OPENORD">
      <data key="d0">TOOL</data>
      <data key="d1">OpenORD is a tool used for node layout in graph visualizations</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">62</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">176</data>
      <data key="d5">5d3344f45e654d2c808481672f2f08dd</data>
    </node>
    <node id="FORCE ATLAS 2">
      <data key="d0">TOOL</data>
      <data key="d1">Force Atlas 2 is a tool used for node layout in graph visualizations</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">62</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">177</data>
      <data key="d5">6fb57f83baec45c9b30490ee991f433f</data>
    </node>
    <node id="NODE">
      <data key="d0">ELEMENT</data>
      <data key="d1">Nodes represent entities in a graph, with size proportional to their degree</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">62</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">178</data>
      <data key="d5">68762e6f0d1c41cd857c6b964a8e76c3</data>
    </node>
    <node id="EDGE">
      <data key="d0">ELEMENT</data>
      <data key="d1">Edges represent connections between nodes in a graph</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">59</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">179</data>
      <data key="d5">70634e10a5e845aa8c6a32fe7e8eb2b2</data>
    </node>
    <node id="COVARIATE">
      <data key="d0">ELEMENT</data>
      <data key="d1">Covariates are variables that are linked to nodes and edges in a graph</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">62</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">180</data>
      <data key="d5">04085f7cf46544b79597fc49286ff84d</data>
    </node>
    <node id="LLM CONTEXT WINDOW">
      <data key="d0">CONCEPT</data>
      <data key="d1">The LLM context window is the token limit within which summaries are added for processing by a language model</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">69</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">181</data>
      <data key="d5">d203efdbfb2f4b2a899abfb31cf72e82</data>
    </node>
    <node id="HIERARCHICAL CLUSTERING">
      <data key="d0">METHOD</data>
      <data key="d1">Hierarchical clustering is a method of clustering data into a tree-like structure with multiple levels</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">65</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">182</data>
      <data key="d5">6731a665561840c2898ce8c9788e4c88</data>
    </node>
    <node id="TOKEN LIMIT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The token limit is the maximum number of tokens that can be processed in a single context window by a language model</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">69</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">183</data>
      <data key="d5">4026806fa92f4e849a59a7f5c9a45c79</data>
    </node>
    <node id="SUMMARY DETAIL">
      <data key="d0">CONCEPT</data>
      <data key="d1">Summary detail refers to the level of detail provided in a summary</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">184</data>
      <data key="d5">68e0c60d2e8845d89d9d0ad397833648</data>
    </node>
    <node id="SCOPE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Scope refers to the range or extent of information covered in a summary</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">185</data>
      <data key="d5">101572f552b54e529fe7765c05168981</data>
    </node>
    <node id="USER QUERY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A "USER QUERY" is a question or inquiry posed by a user seeking information, which the system aims to answer.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d8">CONCEPT</data>
      <data key="d6">64</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">186</data>
      <data key="d5">60c58026b2764b40adffca6eaa31d6d9</data>
    </node>
    <node id="CHUNK">
      <data key="d0">ELEMENT</data>
      <data key="d1">Chunks are segments of community summaries divided into pre-specified token sizes</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d8">ELEMENT</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">187</data>
      <data key="d5">ad1595a78935472999444c9330e7730e</data>
    </node>
    <node id="PROMINENCE">
      <data key="d0">METRIC</data>
      <data key="d1">Prominence is a metric used to prioritize community edges based on the combined degree of source and target nodes</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d3">2</data>
      <data key="d4">188</data>
      <data key="d5">735d19aea0744b2295556841c5c4c3fd</data>
    </node>
    <node id="COMBINED SOURCE AND TARGET NODE DEGREE">
      <data key="d0">METRIC</data>
      <data key="d1">Combined source and target node degree is a metric used to measure the overall prominence of community edges</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d3">1</data>
      <data key="d4">189</data>
      <data key="d5">c725babdb14a485582f8fbdf95429030</data>
    </node>
    <node id="COMMUNITY EDGE">
      <data key="d0">ELEMENT</data>
      <data key="d1">Community edges are connections between nodes within a community, prioritized based on prominence</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d3">1</data>
      <data key="d4">190</data>
      <data key="d5">a0047221896d418d849847d422fa4bb8</data>
    </node>
    <node id="SUB-COMMUNITY SUMMARIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Sub-community summaries are shorter summaries of sub-communities used when element summaries exceed the token limit</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">59</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">191</data>
      <data key="d5">98fc2ee593184c5a839454db4eec7013</data>
    </node>
    <node id="SUMMARY DETAIL AND SCOPE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Summary detail and scope refer to the balance of detail and range of information in community summaries for sensemaking</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">192</data>
      <data key="d5">80020a1da63042459e00266b2a605452</data>
    </node>
    <node id="COMMUNITY LEVEL">
      <data key="d0">CATEGORY</data>
      <data key="d1">Community level refers to the different levels in the hierarchical community structure used to generate summaries</data>
      <data key="d2">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d6">65</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">193</data>
      <data key="d5">31a7e680c4d54101afe4c8d52d246913</data>
    </node>
    <node id="CHUNKS">
      <data key="d0">DATA</data>
      <data key="d1">Chunks are segments of community summaries divided based on a pre-specified token size</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d6">67</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">194</data>
      <data key="d5">351abba16e5c448994c6daf48121b14d</data>
    </node>
    <node id="HELPFULNESS SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">A score between 0-100 generated by the LLM to indicate how helpful an answer is in addressing the target question</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d6">64</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">195</data>
      <data key="d5">50ea7d3b69614bcdbfbff7ddbfbf3d34</data>
    </node>
    <node id="TECH JOURNALIST">
      <data key="d0">USER</data>
      <data key="d1">A user looking for insights and trends in the tech industry</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">6</data>
      <data key="d4">196</data>
      <data key="d5">004f40a5aeca48a1879db728eb12bcba</data>
    </node>
    <node id="EDUCATOR">
      <data key="d0">USER</data>
      <data key="d1">A user incorporating current affairs into curricula</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">6</data>
      <data key="d4">197</data>
      <data key="d5">4465efb7f6ed4dedad72a658184addd2</data>
    </node>
    <node id="TECH POLICY">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic dealing with tech policy and government regulation</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">198</data>
      <data key="d5">b0dd60e11dad4ff782623acf039b3948</data>
    </node>
    <node id="PRIVACY LAWS">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic discussing the impact of privacy laws on technology development</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">199</data>
      <data key="d5">db8c43fa4df947b09e5754d3b1393ead</data>
    </node>
    <node id="INNOVATION AND ETHICS">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic discussing the balance between innovation and ethical considerations</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">200</data>
      <data key="d5">5dabc4cd05da425cb194a04482bf0c29</data>
    </node>
    <node id="POLICY CHANGES">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic discussing suggested changes to current policies</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">201</data>
      <data key="d5">9d08f285a7be4c79b8f359c51d51db37</data>
    </node>
    <node id="COLLABORATIONS">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic discussing collaborations between tech companies and governments</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">202</data>
      <data key="d5">adffed660d154b519c1817e514e83096</data>
    </node>
    <node id="HEALTH TOPICS">
      <data key="d0">TOPIC</data>
      <data key="d1">Current topics in health that can be integrated into health education curricula</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">203</data>
      <data key="d5">b7e9c9ef572c445a9574ca571e41fb96</data>
    </node>
    <node id="PREVENTIVE MEDICINE">
      <data key="d0">TOPIC</data>
      <data key="d1">A topic addressing the concepts of preventive medicine and wellness</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">204</data>
      <data key="d5">dcb9f281cd6248c699e0ebb285a42a5e</data>
    </node>
    <node id="CONTRADICTORY ARTICLES">
      <data key="d0">TOPIC</data>
      <data key="d1">Examples of health articles that contradict each other</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">205</data>
      <data key="d5">072cdee531b74513984f49d99a8d64a0</data>
    </node>
    <node id="PUBLIC HEALTH PRIORITIES">
      <data key="d0">TOPIC</data>
      <data key="d1">Insights about public health priorities based on news coverage</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">206</data>
      <data key="d5">5ae335d9210a45fda3f92a9a028d6d9b</data>
    </node>
    <node id="HEALTH LITERACY">
      <data key="d0">TOPIC</data>
      <data key="d1">The importance of health literacy highlighted through the dataset</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">207</data>
      <data key="d5">5ac60a941a5b4934bdc43d2f87de601c</data>
    </node>
    <node id="INTERMEDIATE ANSWERS">
      <data key="d0">OUTPUT</data>
      <data key="d1">Answers generated for each chunk of community summaries</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d6">64</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">208</data>
      <data key="d5">d405c3154d0e48ce96fad4c28fe20590</data>
    </node>
    <node id="TOKEN SIZE">
      <data key="d0">METRIC</data>
      <data key="d1">The pre-specified size of tokens used to divide community summaries into chunks</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d6">67</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">209</data>
      <data key="d5">7923d8521c744bd9aab131c1aea91ffd</data>
    </node>
    <node id="CONTEXT WINDOW">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The "CONTEXT WINDOW" refers to a window of text used to generate answers, constrained by token size. The size of the context window is consistent across all conditions, ensuring uniformity in answer generation processes.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">64</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">210</data>
      <data key="d5">5bd156c87ec44e19ae6f8f62e6e50b9d</data>
    </node>
    <node id="KEVIN SCOTT">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin Scott is the Chief Technology Officer (CTO) of Microsoft and actively participates in podcast conversations. His involvement in these discussions is documented and compiled in the dataset, highlighting his contributions to the field of technology and his role in shaping Microsoft's strategic direction.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">211</data>
      <data key="d5">c1a146d7fb16429ea6d0aa2a55ee597f</data>
    </node>
    <node id="TECHNOLOGY LEADERS">
      <data key="d0">PERSON</data>
      <data key="d1">Individuals who are leaders in the technology industry and participate in the podcast conversations</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">212</data>
      <data key="d5">ede9350632084da5b0b577ff799ab14b</data>
    </node>
    <node id="TASK">
      <data key="d0">INPUT</data>
      <data key="d1">A specific activity or goal that the user aims to achieve using the datasets</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">2</data>
      <data key="d4">213</data>
      <data key="d5">ed559fb4ebde45518849ec803b350fa3</data>
    </node>
    <node id="QUESTIONS">
      <data key="d0">INPUT</data>
      <data key="d1">QUESTIONS refer to specific inquiries generated by the Large Language Model (LLM) based on the user's task and the target datasets. These questions are utilized in the analysis to evaluate the performance of different methods within the domain of Natural Language Processing and Information Retrieval. The generation and subsequent use of these questions are crucial for assessing the effectiveness and accuracy of various computational techniques and models.</data>
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9,4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d3">4</data>
      <data key="d4">214</data>
      <data key="d5">f422035f8b78417f98e4d116971cf9f3</data>
    </node>
    <node id="USER">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d3">1</data>
      <data key="d4">215</data>
      <data key="d5">c79d686eba044c5586c706cdc096817d</data>
    </node>
    <node id="MT-BENCH">
      <data key="d0">DATASET</data>
      <data key="d1">MT-BENCH is a benchmark dataset designed for open-domain question answering, specifically targeting explicit fact retrieval. It serves as a critical tool in evaluating the performance of models in retrieving accurate and relevant information from a broad range of topics. MT-Bench is prominently featured in the academic paper titled "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena," where it is utilized to assess the capabilities of large language models in a structured and rigorous manner. This dataset plays a significant role in advancing the field of Natural Language Processing and Information Retrieval by providing a standardized metric for model comparison and evaluation.</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620,b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d8">DATASET</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">12</data>
      <data key="d4">216</data>
      <data key="d5">0f70db1e598d463fbbcdd1e288bd9490</data>
    </node>
    <node id="DATA SENSEMAKING">
      <data key="d0">PROCESS</data>
      <data key="d1">The process through which people inspect, engage with, and contextualize data within the broader scope of real-world activities</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d8">PROCESS</data>
      <data key="d3">1</data>
      <data key="d4">217</data>
      <data key="d5">b35c3d1a7daa4924b6bdb58bc69c354d</data>
    </node>
    <node id="RAG SYSTEMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Retrieval-Augmented Generation systems used for global sensemaking tasks</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d8">TECHNOLOGY</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">218</data>
      <data key="d5">a97e2ecd870944cfbe71c79bc0fcc752</data>
    </node>
    <node id="KOESTEN ET AL.">
      <data key="d0">AUTHORS</data>
      <data key="d1">Authors of a paper on data sensemaking behaviors</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d8">AUTHORS</data>
      <data key="d3">1</data>
      <data key="d4">219</data>
      <data key="d5">3e1b063bbfa9423d84e50311296d2f3c</data>
    </node>
    <node id="XU AND LAPATA">
      <data key="d0">AUTHORS</data>
      <data key="d1">Authors of a paper on methods for extracting latent summarization queries from source texts</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d8">AUTHORS</data>
      <data key="d3">1</data>
      <data key="d4">220</data>
      <data key="d5">9a8ce816ee954bdabd01ea2081538009</data>
    </node>
    <node id="TANG AND YANG">
      <data key="d0">AUTHORS</data>
      <data key="d1">Authors associated with the MultiHop-RAG dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d6">62</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">221</data>
      <data key="d5">09f18f81442d4d6d93a90f0fac683f9b</data>
    </node>
    <node id="YANG ET AL.">
      <data key="d0">AUTHORS</data>
      <data key="d1">Authors associated with the HotPotQA dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d8">AUTHORS</data>
      <data key="d6">39</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">222</data>
      <data key="d5">e02be3e37ca0454883a4c1fd859c24bb</data>
    </node>
    <node id="ZHENG ET AL.">
      <data key="d0">AUTHORS</data>
      <data key="d1">Authors associated with the MT-Bench dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d8">AUTHORS</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">223</data>
      <data key="d5">6e0c81bef5364c988b21bf9b709d9861</data>
    </node>
    <node id="LATENT SUMMARIZATION QUERIES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">1</data>
      <data key="d4">224</data>
      <data key="d5">1dbc51475cb04dafa4a8833a8378635e</data>
    </node>
    <node id="BEHIND THE TECH">
      <data key="d0">PODCAST</data>
      <data key="d1">"BEHIND THE TECH" is a podcast series featuring conversations between Kevin Scott and other technology leaders. It serves as a media platform associated with Kevin Scott, providing insights and discussions on various technological advancements and industry trends.</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">0</data>
      <data key="d4">225</data>
      <data key="d5">c12b9ebd8b4e42b7896822a32e3fa6eb</data>
    </node>
    <node id="SCOTT">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin Scott, Microsoft CTO, who participates in the podcast conversations compiled in the dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">0</data>
      <data key="d4">226</data>
      <data key="d5">27505f6ade4b4e5f9316ffe9c34821f7</data>
    </node>
    <node id="TANG">
      <data key="d0">PERSON</data>
      <data key="d1">An author associated with the MultiHop-RAG dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">0</data>
      <data key="d4">227</data>
      <data key="d5">0ee7db2c6bea4630ba9f0c25e8a967ad</data>
    </node>
    <node id="YANG">
      <data key="d0">PERSON</data>
      <data key="d1">An author associated with the MultiHop-RAG dataset</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">0</data>
      <data key="d4">228</data>
      <data key="d5">5a6c1d15424149f69052cd8d91fbff75</data>
    </node>
    <node id="HOTSPOTQA">
      <data key="d0">DATASET</data>
      <data key="d1">A benchmark dataset for open-domain question answering, targeting explicit fact retrieval</data>
      <data key="d2">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d3">0</data>
      <data key="d4">229</data>
      <data key="d5">d005bf75c31d4848ad7041f39651e59c</data>
    </node>
    <node id="N">
      <data key="d0">METRIC</data>
      <data key="d1">N represents the number of test questions per dataset used in the evaluation</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d3">1</data>
      <data key="d4">230</data>
      <data key="d5">9b3eef8f3a3a45e6873838db95295b8a</data>
    </node>
    <node id="TEXT SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A method applying a map-reduce approach directly to source texts for summarization</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">70</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">231</data>
      <data key="d5">fdc954b454744820804d7798f3e0b5de</data>
    </node>
    <node id="SEMANTIC SEARCH RAG">
      <data key="d0">METHOD</data>
      <data key="d1">A na&#168;&#305;ve RAG approach where text chunks are retrieved and added to the context window until the token limit is reached</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">23</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">232</data>
      <data key="d5">49c1383836934ec495c3b35769100a73</data>
    </node>
    <node id="C0">
      <data key="d0">CATEGORY</data>
      <data key="d1">C0 is a category or cluster used in the analysis, representing a specific subset of the data. It serves as a root-level community summary, which is utilized to answer user queries by providing the fewest number of summaries. This category is essential for understanding the structural dynamics within the community, particularly in the domain of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">8</data>
      <data key="d4">233</data>
      <data key="d5">859dedcc3736439a8a563419f16cb3d8</data>
    </node>
    <node id="C1">
      <data key="d0">CATEGORY</data>
      <data key="d1">C1 is a category or cluster used in the analysis, representing a specific subset of the data. It serves as a high-level community summary used to answer user queries, effectively representing sub-communities of C0.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">9</data>
      <data key="d4">234</data>
      <data key="d5">6078b9980a6c4dcd9198d151b833ead7</data>
    </node>
    <node id="C2">
      <data key="d0">CATEGORY</data>
      <data key="d1">C2 is a category or condition used in the analysis, representing a specific subset of the data. It functions as an intermediate-level community summary used to answer user queries, representing sub-communities of C1.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">9</data>
      <data key="d4">235</data>
      <data key="d5">f93cd6b8213e46dda67af7e5382e1bd2</data>
    </node>
    <node id="C3">
      <data key="d0">CATEGORY</data>
      <data key="d1">C3 is a category or cluster used in the analysis, representing a specific subset of the data. It serves as a category or condition that encapsulates low-level community summaries, which are instrumental in answering user queries. These summaries represent sub-communities of C2, providing detailed insights into the structural dynamics and relationships within the broader community.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">9</data>
      <data key="d4">236</data>
      <data key="d5">496f17c2f74244c681db1b23c7a39c0c</data>
    </node>
    <node id="TS">
      <data key="d0">METHOD</data>
      <data key="d1">TS, or "Text Summarization," is a category or condition used in the analysis, representing a specific subset of the data. It is particularly focused on source text summarization within the analysis. TS employs a text summarization method that applies a map-reduce approach directly to source texts, facilitating efficient and scalable summarization processes. This category is integral to understanding and processing large volumes of text data, making it a crucial component in the field of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">10</data>
      <data key="d4">237</data>
      <data key="d5">da1684437ab04f23adac28ff70bd8429</data>
    </node>
    <node id="SS">
      <data key="d0">METHOD</data>
      <data key="d1">"SS" is a category or cluster used in the analysis, representing a specific subset of the data. It serves as a baseline condition and is associated with a na&#168;&#305;ve RAG (Retrieval-Augmented Generation) approach. In this context, text chunks are retrieved and added to the context window until the token limit is reached.</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">23</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">238</data>
      <data key="d5">4517768fc4e24bd2a790be0e08a7856e</data>
    </node>
    <node id="PROMPTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The prompts used for answer generation, which are the same across all conditions with minor modifications</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">64</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">239</data>
      <data key="d5">545edff337344e518f68d1301d745455</data>
    </node>
    <node id="PODCAST DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The "PODCAST DATASET" is a collection of podcast transcripts utilized for both analysis and evaluation purposes. This dataset is specifically designed to support various analytical tasks, providing a rich source of textual data for researchers and practitioners in the field of Natural Language Processing and Information Retrieval. The transcripts within the dataset offer valuable insights and serve as a critical resource for evaluating different computational models and techniques.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">15</data>
      <data key="d4">240</data>
      <data key="d5">9376ce8940e647a99e5e087514b88fa4</data>
    </node>
    <node id="NEWS DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The "NEWS DATASET" is a collection of news articles utilized for both analysis and evaluation purposes. This dataset serves as a valuable resource for examining and assessing various aspects of news content, making it an essential tool in the field of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">15</data>
      <data key="d4">241</data>
      <data key="d5">b38a636e86984600bb4b57c2e2df9747</data>
    </node>
    <node id="METRICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">METRICS in the context of Natural Language Processing and Information Retrieval are essential tools used to evaluate the performance of natural language generation. These metrics include both reference-based metrics, which compare generated texts to a set of reference texts, and qualities of the generated texts themselves. They are crucial in the analysis to assess the effectiveness of different methods in generating natural language, ensuring that the outputs are both accurate and of high quality.</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d3">3</data>
      <data key="d4">242</data>
      <data key="d5">4bc7440b8f4b4e4cae65a5c49defa923</data>
    </node>
    <node id="WANG ET AL., 2023A">
      <data key="d0">REFERENCE</data>
      <data key="d1">"WANG ET AL., 2023A" refers to a study conducted by Wang and colleagues in 2023, which highlights the effectiveness of Large Language Models (LLMs) in evaluation. This study is a significant contribution to the field, providing insights into the capabilities and performance of LLMs in various evaluative tasks.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">31</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">243</data>
      <data key="d5">5d1b038ce8be4533b54dd79d6496de9b</data>
    </node>
    <node id="ZHENG ET AL., 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">"ZHENG ET AL., 2024" refers to a study conducted by Zheng and colleagues in 2024. This study highlights the effectiveness of Large Language Models (LLMs) in evaluation processes. The research, authored by Zheng et al., provides significant insights into the capabilities and applications of LLMs within the domain of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">31</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">244</data>
      <data key="d5">ac6e5a44e0c04a4fa93589376fde4c34</data>
    </node>
    <node id="TABLE 1">
      <data key="d0">REFERENCE</data>
      <data key="d1">Table 1 shows example questions for each of the two evaluation datasets</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d3">1</data>
      <data key="d4">245</data>
      <data key="d5">40e4ef7dbc98473ba311bd837859a62a</data>
    </node>
    <node id="CONDITIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The entity "CONDITIONS" refers to the different scenarios or variables that are compared in an experiment. Specifically, in the context of the analysis, these conditions include Graph RAG, text summarization, and semantic search RAG. These conditions are used to evaluate and compare various aspects of performance and effectiveness within the domain of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">246</data>
      <data key="d5">222f0ea8a5684123a7045986640ec844</data>
    </node>
    <node id="USER QUERIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">USER QUERIES refer to the inquiries made by users to retrieve information. These queries are answered using different methods and conditions, depending on the context and the specific requirements of the information retrieval process.</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">247</data>
      <data key="d5">668cf1fdfd644d39acc6350b86117ea2</data>
    </node>
    <node id="ENTITY TYPES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Types of entities extracted during the graph indexing process</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">22</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">248</data>
      <data key="d5">478e4c72d8fb46dd8cc9f0691c9878fd</data>
    </node>
    <node id="CONTEXT WINDOW SIZE">
      <data key="d0">METRIC</data>
      <data key="d1">The "CONTEXT WINDOW SIZE" refers to the fixed size of the context window used in various stages of natural language processing and information retrieval tasks. For the final evaluation, the context window size is set to 8k tokens. During the analysis phase, different context window sizes are tested, including 8k, 16k, 32k, and 64k tokens. Additionally, in the graph indexing process, the context window size is set to 600 tokens. This variability in context window sizes highlights the importance of adapting the window size to the specific requirements of different tasks within the domain.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">39</data>
      <data key="d7">1</data>
      <data key="d3">9</data>
      <data key="d4">249</data>
      <data key="d5">82b0446e7c9d4fc793f7b97f890e9049</data>
    </node>
    <node id="GLEANING">
      <data key="d0">CONCEPT</data>
      <data key="d1">The process of extracting information, with 1 gleaning for the Podcast dataset and 0 gleanings for the News dataset</data>
      <data key="d2">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">250</data>
      <data key="d5">8169efeea3ce473d9fd2f1c688126a1c</data>
    </node>
    <node id="NATURAL LANGUAGE GENERATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Natural Language Generation (NLG) is a subfield of artificial intelligence that focuses on generating human-like text from data</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d6">31</data>
      <data key="d7">1</data>
      <data key="d3">7</data>
      <data key="d4">251</data>
      <data key="d5">c2d48b75af6a4d7989ccf9eceabd934e</data>
    </node>
    <node id="LLM-AS-A-JUDGE">
      <data key="d0">METHOD</data>
      <data key="d1">A method where a Large Language Model (LLM) is used to compare and evaluate competing outputs</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d6">31</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">252</data>
      <data key="d5">5f1fc373a8f34050a5f7dbd8ac852c1b</data>
    </node>
    <node id="RAGAS">
      <data key="d0">METHOD</data>
      <data key="d1">A method for evaluating the performance of Retrieval-Augmented Generation (RAG) systems, focusing on context relevance, faithfulness, and answer relevance</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">4</data>
      <data key="d4">253</data>
      <data key="d5">0c010fa3aeac4b28b2fbb8c2339c2521</data>
    </node>
    <node id="ES ET AL., 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A reference to a study or paper authored by Es and others in 2023</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">1</data>
      <data key="d4">254</data>
      <data key="d5">c2999bdca08a478b84b10219875b285e</data>
    </node>
    <node id="LLM EVALUATOR">
      <data key="d0">TOOL</data>
      <data key="d1">A Large Language Model (LLM) used to evaluate and compare generated texts based on specific metrics</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">11</data>
      <data key="d4">255</data>
      <data key="d5">263d07354a1b4336b462024288f9bcd3</data>
    </node>
    <node id="DIRECTNESS">
      <data key="d0">METRIC</data>
      <data key="d1">DIRECTNESS is a metric that measures how specifically and clearly an answer addresses a question. It is used to evaluate the straightforwardness of the generated answers. Additionally, it serves as a validity test metric to measure the directness of responses, with naive RAG (Retrieval-Augmented Generation) producing the most direct responses.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d3">3</data>
      <data key="d4">256</data>
      <data key="d5">f9005e5c01b44bb489f7112322fd1162</data>
    </node>
    <node id="TABLE 2">
      <data key="d0">DATA</data>
      <data key="d1">An example of LLM-generated assessment shown in a table format</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">1</data>
      <data key="d4">257</data>
      <data key="d5">d9ef017549724f4fbc4ff4ba6701dac0</data>
    </node>
    <node id="QUESTION">
      <data key="d0">DATA</data>
      <data key="d1">The entity "QUESTION" refers to a specific query used in the evaluation process, particularly as a metric to evaluate the generated responses by asking specific questions. This approach is commonly employed in the domain of Natural Language Processing and Information Retrieval to assess the quality and relevance of responses generated by various models or systems.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">258</data>
      <data key="d5">33b9e826af3f43838c07c847b6349497</data>
    </node>
    <node id="PUBLIC FIGURES">
      <data key="d0">ENTITY</data>
      <data key="d1">Public figures are individuals who have gained fame or notoriety in various sectors such as entertainment, sports, and digital media. These individuals are well-known in the entertainment industry and are frequently mentioned across various articles. Their prominence in public discourse spans multiple domains, reflecting their influence and recognition in society.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,718017a4871c909420f84b85b8ba969d</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">5</data>
      <data key="d4">259</data>
      <data key="d5">dbe9063124d047dc8d6fcaeadcda038f</data>
    </node>
    <node id="ENTERTAINMENT ARTICLES">
      <data key="d0">DATASET</data>
      <data key="d1">ENTERTAINMENT ARTICLES is a collection of articles focused on the entertainment industry. This dataset consists of articles related to various aspects of the entertainment sector, providing a comprehensive resource for understanding trends, developments, and key topics within this field.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">260</data>
      <data key="d5">c885166d0c454a748376b56279f96408</data>
    </node>
    <node id="ENTERTAINMENT INDUSTRY">
      <data key="d0">DOMAIN</data>
      <data key="d1">The **ENTERTAINMENT INDUSTRY** is a multifaceted sector that encompasses various forms of entertainment, including movies, music, television, sports, and digital media. This industry is characterized by its diverse range of content and mediums, which collectively contribute to its broad appeal and significant cultural impact. The entertainment industry plays a crucial role in shaping public opinion, trends, and cultural norms through its extensive reach and influence across different platforms and genres.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">19</data>
      <data key="d4">261</data>
      <data key="d5">586bccefb1e344289c1ee984e165de9c</data>
    </node>
    <node id="STATE-OF-THE-ART">
      <data key="d0">METRIC</data>
      <data key="d1">A metric indicating the highest level of development or achievement in a particular field</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d6">31</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">262</data>
      <data key="d5">a2201b8753ba4847ab0b22054e27d2c0</data>
    </node>
    <node id="COMPETITIVE RESULTS">
      <data key="d0">METRIC</data>
      <data key="d1">A metric indicating results that are comparable to or better than those of others in the same field</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d6">31</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">263</data>
      <data key="d5">b5ecd0553dd742f5813c9b855d548a41</data>
    </node>
    <node id="HUMAN JUDGEMENTS">
      <data key="d0">METRIC</data>
      <data key="d1">A metric based on evaluations made by humans</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d6">31</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">264</data>
      <data key="d5">89b2003e97804961805ea1886d078ebd</data>
    </node>
    <node id="REFERENCE-BASED METRICS">
      <data key="d0">METRIC</data>
      <data key="d1">Metrics that require a gold standard or reference answers for evaluation</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d6">32</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">265</data>
      <data key="d5">6dd7f5f6b4544271a97f6a136f82fc3d</data>
    </node>
    <node id="REFERENCE-FREE STYLE">
      <data key="d0">METHOD</data>
      <data key="d1">An evaluation method that does not require reference answers</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d6">31</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">266</data>
      <data key="d5">eb01db8435554f2cbafe39a50f62f20a</data>
    </node>
    <node id="CONTEXT RELEVANCE">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures how relevant the generated text is to the given context</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">1</data>
      <data key="d4">267</data>
      <data key="d5">3d175ad1f0014cd4871eff4e86db9f88</data>
    </node>
    <node id="FAITHFULNESS">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures how accurately the generated text reflects the source information</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">1</data>
      <data key="d4">268</data>
      <data key="d5">c8e706fbdc90420d952deed03c4f04b4</data>
    </node>
    <node id="ANSWER RELEVANCE">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures how relevant the generated answer is to the question</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">1</data>
      <data key="d4">269</data>
      <data key="d5">cf6115e69d6649cc99ef2bd11854ccfb</data>
    </node>
    <node id="MULTI-STAGE">
      <data key="d0">METHOD</data>
      <data key="d1">A method involving multiple stages or steps</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">270</data>
      <data key="d5">9ed7e3d187b94ab0a90830b17d66615e</data>
    </node>
    <node id="GOLD STANDARD ANSWERS">
      <data key="d0">DATA</data>
      <data key="d1">The correct or ideal answers used as a benchmark in evaluations</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d6">32</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">271</data>
      <data key="d5">b4c7432f712849d7aba9dccbb77471ef</data>
    </node>
    <node id="SENSEMAKING QUESTIONS">
      <data key="d0">DATA</data>
      <data key="d1">"SENSEMAKING QUESTIONS" are a class of questions used to evaluate the performance of Retrieval-Augmented Generation (RAG) systems. These questions are specifically designed to help users understand and make sense of complex information, as well as to validate the understanding and interpretation of data. By employing sensemaking questions, researchers and practitioners can assess how effectively a RAG system can retrieve and generate relevant information, thereby ensuring that the system aids in the comprehension and accurate interpretation of intricate datasets.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,92e93fc6449756c0a60200636b297f65,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">32</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">272</data>
      <data key="d5">434e752b992c4e6a812557529315c5b9</data>
    </node>
    <node id="HEAD-TO-HEAD COMPARISON">
      <data key="d0">METHOD</data>
      <data key="d1">A method where two items are directly compared against each other</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">1</data>
      <data key="d4">273</data>
      <data key="d5">df79a27b9a4f42fd839c90bb8a79ad91</data>
    </node>
    <node id="TARGET METRICS">
      <data key="d0">DATA</data>
      <data key="d1">TARGET METRICS are specific measures used to evaluate the performance of RAG systems. These metrics are aimed to be achieved or measured in the analysis and are the focus of an evaluation.</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c,92e93fc6449756c0a60200636b297f65,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">274</data>
      <data key="d5">8f140fd7126f47b6b00307b0181509f9</data>
    </node>
    <node id="CONTROL METRIC">
      <data key="d0">DATA</data>
      <data key="d1">A metric used as a baseline or standard for comparison</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">2</data>
      <data key="d4">275</data>
      <data key="d5">40450f2c91944a81944621b94f190b49</data>
    </node>
    <node id="VALIDITY">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures the accuracy and reliability of a method or result</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">1</data>
      <data key="d4">276</data>
      <data key="d5">5b9fa6a959294dc29c8420b2d7d3096f</data>
    </node>
    <node id="STOCHASTICITY">
      <data key="d0">METRIC</data>
      <data key="d1">A metric that measures the randomness or variability in a process</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">1</data>
      <data key="d4">277</data>
      <data key="d5">b84d71ed9c3b45819eb3205fd28e13a0</data>
    </node>
    <node id="MEAN SCORES">
      <data key="d0">DATA</data>
      <data key="d1">The average scores obtained from multiple evaluations</data>
      <data key="d2">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d3">1</data>
      <data key="d4">278</data>
      <data key="d5">b0b464bc92a541e48547fe9738378dab</data>
    </node>
    <node id="TAYLOR SWIFT">
      <data key="d0">PERSON</data>
      <data key="d1">Taylor Swift is a public figure frequently mentioned in entertainment articles, known for her contributions to the music industry and her high-profile personal life.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">279</data>
      <data key="d5">44c65dda6fb7472dae36f6eea720ab47</data>
    </node>
    <node id="TRAVIS KELCE">
      <data key="d0">PERSON</data>
      <data key="d1">Travis Kelce is a public figure frequently mentioned in entertainment articles, known for his contributions to the sports industry and his high-profile personal life.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">280</data>
      <data key="d5">5d97ff82691c4482973d73d1860e4757</data>
    </node>
    <node id="BRITNEY SPEARS">
      <data key="d0">PERSON</data>
      <data key="d1">Britney Spears is a public figure frequently mentioned in entertainment articles, known for her significant contributions to the music industry and her high-profile personal life.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">281</data>
      <data key="d5">2567445079794d1e84f17abc48776002</data>
    </node>
    <node id="JUSTIN TIMBERLAKE">
      <data key="d0">PERSON</data>
      <data key="d1">Justin Timberlake is a public figure frequently mentioned in entertainment articles, known for his significant contributions to the music industry and his high-profile personal life.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">282</data>
      <data key="d5">392be891f8b649fabdc20e7bf549f669</data>
    </node>
    <node id="ACTORS AND DIRECTORS">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category of public figures in the entertainment industry, including those involved in film and television</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">283</data>
      <data key="d5">0111777c4e9e4260ab2e5ddea7cbcf58</data>
    </node>
    <node id="MUSICIANS AND EXECUTIVES">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category of public figures in the entertainment industry, including those involved in music</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">284</data>
      <data key="d5">785f7f32471c439e89601ab81c828d1d</data>
    </node>
    <node id="ATHLETES AND COACHES">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category of public figures in the entertainment industry, including those involved in sports</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">285</data>
      <data key="d5">6768339b54084020aec27adcef8994ff</data>
    </node>
    <node id="INFLUENCERS AND ENTREPRENEURS">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category of public figures in the entertainment industry, including those involved in digital media and business</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">286</data>
      <data key="d5">f09f381c319f4251847d1a4bb8cdcac1</data>
    </node>
    <node id="PUBLIC FIGURES IN CONTROVERSY">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category of public figures in the entertainment industry who are involved in controversies</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">287</data>
      <data key="d5">eec11f567e7f4943b157c3a657eb9a46</data>
    </node>
    <node id="DECISION">
      <data key="d0">METRIC</data>
      <data key="d1">A metric used to determine the winner in the comparison of generated responses</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">288</data>
      <data key="d5">efef117839b64ce9adf614a461d41ba6</data>
    </node>
    <node id="ASSESSMENT">
      <data key="d0">METRIC</data>
      <data key="d1">A metric used to evaluate the quality of LLM-generated responses</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">289</data>
      <data key="d5">2171091ada0942d8ae7944df11659f6e</data>
    </node>
    <node id="FILM">
      <data key="d0">SECTOR</data>
      <data key="d1">The entity "FILM" refers to a sector within the entertainment industry that encompasses movies and cinema. This sector includes public figures involved in the movie industry, such as actors, directors, and producers.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">290</data>
      <data key="d5">bcfdc48e5f044e1d84c5d217c1992d4b</data>
    </node>
    <node id="TELEVISION">
      <data key="d0">SECTOR</data>
      <data key="d1">The entity "TELEVISION" refers to a sector within the entertainment industry that encompasses TV shows and series. This sector includes public figures involved in TV shows, such as actors, hosts, and producers.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">291</data>
      <data key="d5">b232fb0f2ac14790b931d1e7fcddd8ad</data>
    </node>
    <node id="MUSIC">
      <data key="d0">SECTOR</data>
      <data key="d1">MUSIC is a sector within the entertainment industry that encompasses musical performances and recordings. This sector includes public figures involved in the music industry, such as singers, musicians, and producers.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">292</data>
      <data key="d5">1c16b22e18d3483b8d41b284754274e2</data>
    </node>
    <node id="SPORTS">
      <data key="d0">SECTOR</data>
      <data key="d1">The entity "SPORTS" refers to a sector within the entertainment industry that encompasses athletic events and competitions. This sector includes public figures involved in sports, such as athletes, coaches, and sports commentators.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">293</data>
      <data key="d5">0080f96708cd4054a5f0986ca86889f4</data>
    </node>
    <node id="DIGITAL MEDIA">
      <data key="d0">SECTOR</data>
      <data key="d1">DIGITAL MEDIA is a sector within the entertainment industry that encompasses online content and social media. This sector includes public figures involved in online platforms, such as influencers, content creators, and digital marketers. These individuals play a significant role in shaping digital landscapes through their engagement with audiences and their ability to leverage various online tools and platforms for content dissemination and marketing purposes.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">294</data>
      <data key="d5">e683130322ac47708a852a5e51abb7c5</data>
    </node>
    <node id="CULTURAL NARRATIVES">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category within the entertainment industry that includes stories and themes that shape culture</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">295</data>
      <data key="d5">71a0a8c1beb64da08124205e9a803d98</data>
    </node>
    <node id="TRENDS">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category within the entertainment industry that includes popular movements and styles</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">296</data>
      <data key="d5">f84314943bee4c859c9a62f268c9c216</data>
    </node>
    <node id="SOCIAL DISCUSSIONS">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category within the entertainment industry that includes public conversations and debates</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">297</data>
      <data key="d5">ba481175ee1d4329bf07757a30abd3a1</data>
    </node>
    <node id="PUBLIC DISCOURSE">
      <data key="d0">CATEGORY</data>
      <data key="d1">A category within the entertainment industry that includes formal discussions and communications</data>
      <data key="d2">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">298</data>
      <data key="d5">8d8da35190bf43c5878fa38f3eb4f3d2</data>
    </node>
    <node id="ANSWER 1">
      <data key="d0">RESPONSE</data>
      <data key="d1">Answer 1 provides a varied and rich response by covering a wide range of public figures from different sectors of the entertainment industry, including film, television, music, sports, gaming, and digital media. It offers insights into the contributions and influence of these figures, as well as controversies and their impact on public discourse. The answer also cites specific data sources for each mentioned figure, indicating a diverse range of evidence to support the claims.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">11</data>
      <data key="d4">299</data>
      <data key="d5">2fb7e14a3f124526bd7b24867fc18e81</data>
    </node>
    <node id="ANSWER 2">
      <data key="d0">RESPONSE</data>
      <data key="d1">"ANSWER 2" is a generated answer for the example question in the News article dataset. It focuses on a smaller group of public figures, primarily from the music industry and sports, and relies heavily on a single source for data. "ANSWER 2" provides concise explanations for the frequent mentions of specific public figures such as Taylor Swift, Travis Kelce, Britney Spears, and Justin Timberlake.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">10</data>
      <data key="d4">300</data>
      <data key="d5">5c13c7d61e6c4bfe839f21e7ad3530a7</data>
    </node>
    <node id="NA&#207;VE RAG">
      <data key="d0">METHOD</data>
      <data key="d1">Na&#239;ve RAG is a baseline method for retrieval-augmented generation (RAG) that does not use advanced techniques. It is a basic form of RAG with certain drawbacks that advanced RAG systems aim to overcome. Na&#239;ve RAG is used to generate answers for questions in the News article dataset and to generate responses that directly list specific public figures who are repeatedly mentioned across various entertainment articles.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,e4d9b12cf2b4c691c74019eefff4fb39,ebf5249c888e07fedce6572a4c03f88c,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">301</data>
      <data key="d5">a621663edba64d99b7e50f1e53f32ee7</data>
    </node>
    <node id="NEWS ARTICLE DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The "NEWS ARTICLE DATASET" is a collection of news articles utilized for various analytical purposes. This dataset is specifically employed for generating responses to questions about public figures in the entertainment industry, making it a valuable resource for both analysis and information retrieval tasks within this domain.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">23</data>
      <data key="d7">1</data>
      <data key="d3">16</data>
      <data key="d4">302</data>
      <data key="d5">42be4e140061482ea509dd3e26189480</data>
    </node>
    <node id="CONTROVERSIES">
      <data key="d0">TOPIC</data>
      <data key="d1">Controversies are events or issues involving public figures that generate public debate and impact public discourse.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">303</data>
      <data key="d5">4da4ef951ff340f1a3dd679de4be3341</data>
    </node>
    <node id="GAMING">
      <data key="d0">SECTOR</data>
      <data key="d1">The gaming sector includes public figures involved in the gaming industry, including gamers, developers, and streamers.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">304</data>
      <data key="d5">2f05fcce857e4a499ca4e89a3cefbcb3</data>
    </node>
    <node id="DATA SOURCES">
      <data key="d0">RESOURCE</data>
      <data key="d1">Data sources are references or reports used to support claims about public figures and their influence.</data>
      <data key="d2">718017a4871c909420f84b85b8ba969d</data>
      <data key="d6">54</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">305</data>
      <data key="d5">b3aeb7ae009a4f52ae3ae4586e32fe11</data>
    </node>
    <node id="LLM-GENERATED ASSESSMENTS">
      <data key="d0">METHOD</data>
      <data key="d1">Assessments generated by large language models (LLMs) to evaluate the answers produced by different methods</data>
      <data key="d2">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">23</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">306</data>
      <data key="d5">089b9b9841714b8da043777e2cda3767</data>
    </node>
    <node id="EXAMPLE QUESTION">
      <data key="d0">DATASET</data>
      <data key="d1">An example question used in the News article dataset for analysis</data>
      <data key="d2">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d6">23</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">307</data>
      <data key="d5">38f1e44579d0437dac1203c34678d3c3</data>
    </node>
    <node id="DATASETS">
      <data key="d0">DATA</data>
      <data key="d1">The datasets used in the analysis, consisting of various text sources</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d3">2</data>
      <data key="d4">308</data>
      <data key="d5">1ca24718a96b47f3a8855550506c4b41</data>
    </node>
    <node id="HEAD-TO-HEAD WIN RATE">
      <data key="d0">METRIC</data>
      <data key="d1">A metric used to compare the performance of different conditions in the analysis</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d3">1</data>
      <data key="d4">309</data>
      <data key="d5">9c980dfe3cab44b7a83408405edab0b6</data>
    </node>
    <node id="CONDITION">
      <data key="d0">CATEGORY</data>
      <data key="d1">A specific setup or scenario used in the analysis, such as C0, C1, C2, C3, TS, and SS</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d3">4</data>
      <data key="d4">310</data>
      <data key="d5">f23484b1b45d44c3b7847e1906dddd37</data>
    </node>
    <node id="WIN RATE">
      <data key="d0">METRIC</data>
      <data key="d1">WIN RATE is a measure used to evaluate the success rate of different methods in providing comprehensive and diverse answers. It represents the percentage of times a particular approach or method achieves a win in a given context. Specifically, it quantifies the percentage of times a condition outperformed another in the analysis. This metric is crucial in assessing the effectiveness of various strategies within the domain of Natural Language Processing and Information Retrieval, offering insights into the comparative performance of different techniques.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f,6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d3">3</data>
      <data key="d4">311</data>
      <data key="d5">929f30875e1744b49e7b416eaf5a790c</data>
    </node>
    <node id="OVERALL WINNER">
      <data key="d0">METRIC</data>
      <data key="d1">The condition that performed the best across all comparisons in the analysis</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d3">1</data>
      <data key="d4">312</data>
      <data key="d5">4920fda031804ce8a1073ace8e061ed6</data>
    </node>
    <node id="SELF-WIN RATE">
      <data key="d0">METRIC</data>
      <data key="d1">The expected win rate of a condition when compared to itself, shown as 50% for reference</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d3">1</data>
      <data key="d4">313</data>
      <data key="d5">4b8aa4587c7344adac2cbfa69d5e40fa</data>
    </node>
    <node id="QUERY-TIME LLM USE">
      <data key="d0">METHOD</data>
      <data key="d1">The use of large language models (LLMs) at the time of querying, evaluated in the analysis</data>
      <data key="d2">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d6">39</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">314</data>
      <data key="d5">52701d941dfb45359693baae8f267056</data>
    </node>
    <node id="FINAL EVALUATION">
      <data key="d0">METHOD</data>
      <data key="d1">The "FINAL EVALUATION" is the last stage of the analysis where the best performing context window size was used.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d6">39</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">315</data>
      <data key="d5">31499ee6277a4d71b19cb5b6be554c69</data>
    </node>
    <node id="INDEXING PROCESS">
      <data key="d0">PROCESS</data>
      <data key="d1">The process that resulted in the creation of graphs for the Podcast and News datasets</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">316</data>
      <data key="d5">d99eabad5dfd47278692569d2a9395b1</data>
    </node>
    <node id="GRAPH">
      <data key="d0">STRUCTURE</data>
      <data key="d1">A data structure consisting of nodes and edges, used to represent the Podcast and News datasets</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">317</data>
      <data key="d5">d53f15cb7f7845de91cc44ad44ff9f6e</data>
    </node>
    <node id="GLOBAL APPROACHES">
      <data key="d0">METHOD</data>
      <data key="d1">Approaches that consistently outperformed the naive RAG in comprehensiveness and diversity metrics</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">318</data>
      <data key="d5">23becf8c6fca4f47a53ec4883d4bf63f</data>
    </node>
    <node id="UNITS">
      <data key="d0">METRIC</data>
      <data key="d1">The number of context units, such as community summaries or text chunks, used in the analysis</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
      <data key="d8">METRIC</data>
      <data key="d6">20</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">319</data>
      <data key="d5">d0ffa3bcd1234258953ff4956d19f561</data>
    </node>
    <node id="TOKENS">
      <data key="d0">METRIC</data>
      <data key="d1">The term "TOKENS" refers to the number of individual words used in the analysis. The evaluation typically focuses on corpora in the region of 1 million tokens. This metric is crucial for understanding the scope and scale of the text data being analyzed, particularly in the fields of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METRIC</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">7</data>
      <data key="d4">320</data>
      <data key="d5">ac41b77ba33c4c84877eb425aba03aa1</data>
    </node>
    <node id="% MAX">
      <data key="d0">METRIC</data>
      <data key="d1">The percentage of the maximum token count used in the analysis</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
      <data key="d8">METRIC</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">321</data>
      <data key="d5">5d3184dabfd647a5a7e565f72c60ff24</data>
    </node>
    <node id="MAP-REDUCE SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">MAP-REDUCE SUMMARIZATION is a method for summarizing source texts using a map-reduce approach. This summarization technique is notably resource-intensive, necessitating the highest number of context tokens compared to other methods. The map-reduce framework, originally popularized for its efficiency in processing large-scale data, is adapted here to handle the complexities of text summarization, ensuring comprehensive and accurate extraction of key information from extensive source texts.</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">322</data>
      <data key="d5">0ec262c2cfef4dd581f3655e5e496e31</data>
    </node>
    <node id="ROOT-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA</data>
      <data key="d1">Summaries at the root level of the community hierarchy, requiring dramatically fewer tokens per query</data>
      <data key="d2">36db32c37e1987e2c5863898ad882190</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">323</data>
      <data key="d5">100c2fccd7f74d9281707082f062ba72</data>
    </node>
    <node id="SOURCE TEXTS">
      <data key="d0">DATASET</data>
      <data key="d1">SOURCE TEXTS are the original texts from which summaries or analyses are derived. These texts serve as the foundational material used for comparison with community summaries in the analysis.</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">55</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">324</data>
      <data key="d5">378fc7636eeb4aabbfd40995a6960c64</data>
    </node>
    <node id="RAM ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a paper by Ram et al. in 2023 discussing RAG approaches</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">325</data>
      <data key="d5">80a04aa18cd649d584292f23b10c0727</data>
    </node>
    <node id="GAO ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">"GAO ET AL., 2023" is a paper published in 2023 by Gao et al. that delves into advanced Retrieval-Augmented Generation (RAG) techniques, specifically where the index is a knowledge graph. The publication also touches upon naive RAG approaches, providing a comprehensive examination of both advanced and basic methodologies within the domain of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4,92e93fc6449756c0a60200636b297f65,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">53</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">326</data>
      <data key="d5">4e9ca18ccc1d4527a3bc035d07f5e162</data>
    </node>
    <node id="INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d0">CATEGORY</data>
      <data key="d1">Intermediate-level summaries are a type of community summary used in the Podcast dataset for analysis</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d6">21</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">327</data>
      <data key="d5">5564257e89f1428486a64fcf52f49490</data>
    </node>
    <node id="ROOT-LEVEL SUMMARIES">
      <data key="d0">CATEGORY</data>
      <data key="d1">Root-level summaries are a type of community summary used in the analysis</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">328</data>
      <data key="d5">83c76fbd2a004d90a5b0a6736ffed61d</data>
    </node>
    <node id="ANSWER COMPREHENSIVENESS">
      <data key="d0">METRIC</data>
      <data key="d1">Answer comprehensiveness is a measure used to evaluate the completeness of answers provided by different methods</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">329</data>
      <data key="d5">d9779c41e3c74fe0b26e23822a4b995b</data>
    </node>
    <node id="AD-HOC LLM USE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Ad-hoc LLM use refers to the spontaneous use of large language models to analyze reasoning and provide specific examples, quotes, and citations</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">330</data>
      <data key="d5">9d7a563b3b2d405092c31f1fe08cff77</data>
    </node>
    <node id="ELEMENT EXTRACTION PROMPTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Element extraction prompts are used to extract specific details in the Graph RAG index</data>
      <data key="d2">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">331</data>
      <data key="d5">bd43f3d439a54781bd4b721a9a269b92</data>
    </node>
    <node id="VECTOR SPACE">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">A mathematical space in which text chunks and queries are embedded to represent similar semantics</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">1</data>
      <data key="d4">332</data>
      <data key="d5">adc0f95733e74351a891c4dadf650a52</data>
    </node>
    <node id="QUERIES">
      <data key="d0">CONCEPT, DATA</data>
      <data key="d1">Search inputs that are embedded into the same vector space as text chunks to find relevant context</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">1</data>
      <data key="d4">333</data>
      <data key="d5">225105a7be14447cb03186bd40756059</data>
    </node>
    <node id="MODULAR RAG">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A type of RAG system that includes patterns for iterative and dynamic cycles of interleaved retrieval and generation</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">334</data>
      <data key="d5">efce8a9d61254447a26aee99e53f0398</data>
    </node>
    <node id="SELF-MEMORY (SELFMEM)">
      <data key="d0">TECHNOLOGY, CONCEPT</data>
      <data key="d1">A concept related to generation-augmented retrieval that facilitates future generation cycles</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">56</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">335</data>
      <data key="d5">4a75a9f0b18a48bea9c0601c0fc395c4</data>
    </node>
    <node id="GENERATION-AUGMENTED RETRIEVAL (GAR)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A method that facilitates future generation cycles by using self-memory</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">56</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">336</data>
      <data key="d5">e19287afe00a431f9a593a4827d1b448</data>
    </node>
    <node id="ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A strategy for iterative retrieval and generation</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">337</data>
      <data key="d5">f2c06f3a0c704296bf3353b91ee8af47</data>
    </node>
    <node id="FEDERATED RETRIEVAL-GENERATION (FEB4RAG)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A federated strategy for retrieval and generation</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">338</data>
      <data key="d5">f512103ed4624accac6cbbf90d7d250a</data>
    </node>
    <node id="MULTI-DOCUMENT SUMMARIZATION">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A method that combines multiple concepts for summarizing multiple documents</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d6">58</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">339</data>
      <data key="d5">2325dafe50d1435cbee8ebcaa69688df</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A method for answering questions that require multiple steps or "hops" to gather information</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">4</data>
      <data key="d4">340</data>
      <data key="d5">469aeef98cd1421fa123277b93d7b83a</data>
    </node>
    <node id="HIERARCHICAL INDEX">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">An approach that involves generating a hierarchical index of text chunks by clustering the vectors of text embeddings</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">TECHNOLOGY, METHOD</data>
      <data key="d6">52</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">341</data>
      <data key="d5">2fb66f9a0de6406d83b61742a3b52cd6</data>
    </node>
    <node id="RAPTOR">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A method for generating a hierarchical index of text chunks by clustering the vectors of text embeddings</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">TECHNOLOGY, METHOD</data>
      <data key="d6">52</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">342</data>
      <data key="d5">b0e6cfd979ea48b997019b059999d3c2</data>
    </node>
    <node id="TREE OF CLARIFICATIONS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A method for answering multiple interpretations of ambiguous questions by generating a hierarchical structure</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">TECHNOLOGY, METHOD</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">343</data>
      <data key="d5">ef00ec3a324f4f5986141401002af3f6</data>
    </node>
    <node id="KNOWLEDGE GRAPH CREATION">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A process that involves using LLMs to create knowledge graphs</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">TECHNOLOGY, METHOD</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">344</data>
      <data key="d5">a542fd7aed7341468028928937ea2983</data>
    </node>
    <node id="KNOWLEDGE GRAPH COMPLETION">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A process that involves using LLMs to complete existing knowledge graphs</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">TECHNOLOGY, METHOD</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">345</data>
      <data key="d5">1c5e296a5ac541c1b5cac4357537c22d</data>
    </node>
    <node id="CAUSAL GRAPHS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Graphs that represent causal relationships, which can be extracted using LLMs</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">TECHNOLOGY, METHOD</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">346</data>
      <data key="d5">5ecf534a9ffe46e0b1c2144110c691c0</data>
    </node>
    <node id="CHENG ET AL., 2024">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Cheng et al. in 2024</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">347</data>
      <data key="d5">4d183e7007624fcd98af96b9d752c16d</data>
    </node>
    <node id="MAO ET AL., 2020">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Mao et al. in 2020</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">348</data>
      <data key="d5">718c507cb8ac49e6a35c251ac951b5ca</data>
    </node>
    <node id="SHAO ET AL., 2023">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Shao et al. in 2023</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">349</data>
      <data key="d5">b45ef27279c043269b23b894461d7d8c</data>
    </node>
    <node id="WANG ET AL., 2024">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Wang et al. in 2024</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">350</data>
      <data key="d5">10983a248cc448c59c94df4d1d0898f0</data>
    </node>
    <node id="SU ET AL., 2020">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Su et al. in 2020</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">351</data>
      <data key="d5">e2ec7d3cdbeb4dd086ae6eb399332363</data>
    </node>
    <node id="FENG ET AL., 2023">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Feng et al. in 2023</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">352</data>
      <data key="d5">67f10971666240ea930f3b875aabdc1a</data>
    </node>
    <node id="TRIVEDI ET AL., 2022">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Trivedi et al. in 2022</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">353</data>
      <data key="d5">8b95083939ad4771b57a97c2d5805f36</data>
    </node>
    <node id="KHATTAB ET AL., 2022">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Khattab et al. in 2022</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">354</data>
      <data key="d5">3c4062de44d64870a3cc5913d5769244</data>
    </node>
    <node id="SARTHI ET AL., 2024">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Sarthi et al. in 2024</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">355</data>
      <data key="d5">24652fab20d84381b112b8491de2887e</data>
    </node>
    <node id="KIM ET AL., 2023">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Kim et al. in 2023</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">356</data>
      <data key="d5">d4602d4a27b34358baa86814a3836d68</data>
    </node>
    <node id="TRAJANOSKA ET AL., 2023">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">"TRAJANOSKA ET AL., 2023" refers to a paper by Trajanoska et al. published in 2023, which focuses on using Large Language Models (LLMs) for knowledge graph creation. This publication is a significant contribution to the field of Natural Language Processing and Information Retrieval, highlighting innovative methodologies for leveraging advanced language models to construct and enhance knowledge graphs.</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">357</data>
      <data key="d5">36be44627ece444284f9e759b8cd25c6</data>
    </node>
    <node id="YAO ET AL., 2023">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">"Yao et al., 2023" refers to a paper published by Yao and colleagues in 2023. The study focuses on the application of large language models (LLMs) for the task of knowledge graph completion. This publication is a significant contribution to the field of Natural Language Processing and Information Retrieval, highlighting the potential of advanced LLMs to enhance the accuracy and efficiency of knowledge graph completion processes.</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">358</data>
      <data key="d5">a64b4b17b07a44e4b1ac33580d811936</data>
    </node>
    <node id="BAN ET AL.">
      <data key="d0">REFERENCE, PUBLICATION</data>
      <data key="d1">A reference to a publication by Ban et al.</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">REFERENCE, PUBLICATION</data>
      <data key="d6">25</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">359</data>
      <data key="d5">423b72bbd56f4caa98f3328202c1c3c9</data>
    </node>
    <node id="MULTI-DOCUMENT SUMMARIZATION (CAIRE-COVID)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A system that combines multiple concepts for multi-document summarization</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">TECHNOLOGY, METHOD</data>
      <data key="d6">58</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">360</data>
      <data key="d5">5c7ef01f46a94641bf1ae5cd25f8a538</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING (ITRG)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A system for multi-hop question answering</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">TECHNOLOGY, METHOD</data>
      <data key="d3">1</data>
      <data key="d4">361</data>
      <data key="d5">aefde1f7617f4c0e9aed31db77f6d862</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING (IR-COT)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A system for multi-hop question answering</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">TECHNOLOGY, METHOD</data>
      <data key="d3">1</data>
      <data key="d4">362</data>
      <data key="d5">ad52ba79a84748a49067e53b1d5095f9</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING (DSP)">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A system for multi-hop question answering</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d8">TECHNOLOGY, METHOD</data>
      <data key="d3">1</data>
      <data key="d4">363</data>
      <data key="d5">289616058bf4495887292003b27ba216</data>
    </node>
    <node id="PRE-RETRIEVAL STRATEGIES">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Strategies used before the retrieval process in advanced RAG systems</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">0</data>
      <data key="d4">364</data>
      <data key="d5">7ffa3a064bce468082739c5a164df5a3</data>
    </node>
    <node id="RETRIEVAL STRATEGIES">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Strategies used during the retrieval process in advanced RAG systems</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">0</data>
      <data key="d4">365</data>
      <data key="d5">ce36d1d637cf4a4e93f5e37ffbc6bd76</data>
    </node>
    <node id="POST-RETRIEVAL STRATEGIES">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Strategies used after the retrieval process in advanced RAG systems</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">0</data>
      <data key="d4">366</data>
      <data key="d5">eeb9c02c0efa4131b9e95d33c31019fc</data>
    </node>
    <node id="INTERLEAVED RETRIEVAL AND GENERATION">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">A pattern in Modular RAG systems for iterative and dynamic cycles of retrieval and generation</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">0</data>
      <data key="d4">367</data>
      <data key="d5">7b2472c5dd9949c58828413387b94659</data>
    </node>
    <node id="GENERATION CYCLES">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Cycles of generation that are facilitated by self-memory in Graph RAG</data>
      <data key="d2">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d3">0</data>
      <data key="d4">368</data>
      <data key="d5">bdddcb17ba6c408599dd395ce64f960a</data>
    </node>
    <node id="BAN ET AL., 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Ban et al. published in 2023, focusing on the extraction of causal graphs from source texts</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">PUBLICATION</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">369</data>
      <data key="d5">bc70fee2061541148833d19e86f225b3</data>
    </node>
    <node id="ZHANG ET AL., 2024">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Zhang et al. published in 2024, focusing on the extraction of causal graphs from source texts</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">PUBLICATION</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">370</data>
      <data key="d5">0fc15cc3b44c4142a770feb4c037a6f7</data>
    </node>
    <node id="KAPING">
      <data key="d0">METHOD</data>
      <data key="d1">A method where the index is a knowledge graph, developed by Baek et al. in 2023</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METHOD</data>
      <data key="d6">27</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">371</data>
      <data key="d5">a24e9df02e1b4b43bf6324b039e28285</data>
    </node>
    <node id="BAEK ET AL., 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Baek et al. published in 2023, focusing on the KAPING method</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">PUBLICATION</data>
      <data key="d6">27</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">372</data>
      <data key="d5">ab3a5a6713244fd595a1ace978c3d960</data>
    </node>
    <node id="G-RETRIEVER">
      <data key="d0">METHOD</data>
      <data key="d1">A method where subsets of the graph structure are the objects of enquiry, developed by He et al. in 2024</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METHOD</data>
      <data key="d6">29</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">373</data>
      <data key="d5">02a88c0d128e4586b2f1f64329786d3c</data>
    </node>
    <node id="HE ET AL., 2024">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by He et al. published in 2024, focusing on the G-Retriever method</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">PUBLICATION</data>
      <data key="d6">29</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">374</data>
      <data key="d5">1ca41537c47c4752a17a44d1d7086d96</data>
    </node>
    <node id="GRAPH-TOOLFORMER">
      <data key="d0">METHOD</data>
      <data key="d1">A method where derived graph metrics are the objects of enquiry, developed by Zhang in 2023</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METHOD</data>
      <data key="d6">34</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">375</data>
      <data key="d5">7e0d14ca308b4796bdc675a64bd3a36e</data>
    </node>
    <node id="ZHANG, 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Zhang published in 2023, focusing on the Graph-ToolFormer method</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">PUBLICATION</data>
      <data key="d6">34</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">376</data>
      <data key="d5">8323efc8e539419e9ca3c98e758f6609</data>
    </node>
    <node id="SURGE">
      <data key="d0">METHOD</data>
      <data key="d1">A method where narrative outputs are strongly grounded in the facts of retrieved subgraphs, developed by Kang et al. in 2023</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METHOD</data>
      <data key="d6">30</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">377</data>
      <data key="d5">a80c7c98c0b647f8b9f6f8cc09168e44</data>
    </node>
    <node id="KANG ET AL., 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Kang et al. published in 2023, focusing on the SURGE method</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">PUBLICATION</data>
      <data key="d6">30</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">378</data>
      <data key="d5">2d66a15939294d21b83b3e277f0a4e46</data>
    </node>
    <node id="FABULA">
      <data key="d0">METHOD</data>
      <data key="d1">A method where retrieved event-plot subgraphs are serialized using narrative templates, developed by Ranade and Joshi in 2023</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METHOD</data>
      <data key="d6">28</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">379</data>
      <data key="d5">47f6d6573cf34e1096c95e36251dd60c</data>
    </node>
    <node id="RANADE AND JOSHI, 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Ranade and Joshi published in 2023, focusing on the FABULA method</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">PUBLICATION</data>
      <data key="d6">28</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">380</data>
      <data key="d5">2fbd74d5ccca4be99c5257b3ac95cfba</data>
    </node>
    <node id="WANG ET AL., 2023B">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A paper by Wang et al. published in 2023, focusing on a system that supports both creation and traversal of text-relationship graphs for multi-hop question answering</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">PUBLICATION</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">381</data>
      <data key="d5">a2b1621a3e424ae29a6a73f00edbeca3</data>
    </node>
    <node id="LANGCHAIN">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">LangChain is an organization that developed Langchain graphs and supports a variety of graph databases.</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1,92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">ORGANIZATION</data>
      <data key="d3">5</data>
      <data key="d4">382</data>
      <data key="d5">ec45e1c400654c4f875046926486ded7</data>
    </node>
    <node id="LLAMAINDEX">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">LlamaIndex is an organization that developed the LlamaIndex Knowledge Graph Index and supports a variety of graph databases.</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">ORGANIZATION</data>
      <data key="d3">3</data>
      <data key="d4">383</data>
      <data key="d5">047cd93e9d704c7d8dadb6e79f9458df</data>
    </node>
    <node id="NEO4J">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Neo4J is both a graph database format supported by various Retrieval-Augmented Generation (RAG) applications and an organization that developed Project NaLLM. The graph database format of Neo4J is widely recognized for its efficiency in handling complex relationships and structures, making it a valuable tool in the field of Natural Language Processing and Information Retrieval. As an organization, Neo4J has contributed significantly to the advancement of these domains through innovative projects like NaLLM, which further underscores its pivotal role in the community.</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">TECHNOLOGY</data>
      <data key="d3">4</data>
      <data key="d4">384</data>
      <data key="d5">5b71ee73a5b6484495b2a0a75219426c</data>
    </node>
    <node id="NALLM">
      <data key="d0">METHOD</data>
      <data key="d1">A method that can create and reason over knowledge graphs in Neo4J format, developed by Neo4J in 2024</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METHOD</data>
      <data key="d3">1</data>
      <data key="d4">385</data>
      <data key="d5">e1f524d4b9754ce2b64a0a4c8f73b854</data>
    </node>
    <node id="NEBULAGRAPH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">NebulaGraph is both a graph database format and an organization that has made significant contributions to the field of graph databases and retrieval-augmented generation (RAG) applications. As a graph database format, NebulaGraph is supported by various RAG applications, facilitating the efficient handling and querying of complex graph data structures. Additionally, NebulaGraph, as an organization, has pioneered the industry-first graph RAG, which integrates retrieval-augmented generation with large language models (LLMs) based on knowledge graphs. This innovation underscores NebulaGraph's role in advancing the capabilities of knowledge graph-based applications and enhancing the performance of LLMs in generating contextually relevant information.</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">TECHNOLOGY</data>
      <data key="d3">4</data>
      <data key="d4">386</data>
      <data key="d5">ae1fe1c014c54ec4bcdf10dbdaed5068</data>
    </node>
    <node id="GRAPHRAG">
      <data key="d0">METHOD</data>
      <data key="d1">A method that can create and reason over knowledge graphs in NebulaGraph format, developed by NebulaGraph in 2024</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METHOD</data>
      <data key="d3">1</data>
      <data key="d4">387</data>
      <data key="d5">92646910ee624bd7909fac2b5c0232e3</data>
    </node>
    <node id="SELFCHECKGPT">
      <data key="d0">METHOD</data>
      <data key="d1">A method for comparing fabrication rates, developed by Manakul et al. in 2023</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METHOD</data>
      <data key="d3">1</data>
      <data key="d4">388</data>
      <data key="d5">05913bee89a94bca88449249e35ba74d</data>
    </node>
    <node id="MANAKUL ET AL., 2023">
      <data key="d0">PUBLICATION</data>
      <data key="d1">"MANAKUL ET AL., 2023" refers to a paper by Manakul et al. published in 2023, which focuses on the SelfCheckGPT method. This work by Manakul and colleagues is centered around the development and application of SelfCheckGPT, a technique likely aimed at enhancing the performance and reliability of GPT models. The paper contributes to the field of Natural Language Processing and Information Retrieval by addressing specific challenges and proposing innovative solutions through the SelfCheckGPT method.</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d8">PUBLICATION</data>
      <data key="d3">2</data>
      <data key="d4">389</data>
      <data key="d5">57b8930790c34dcba4a32c6be703ed78</data>
    </node>
    <node id="END USERS">
      <data key="d0">STAKEHOLDER</data>
      <data key="d1">END USERS are individuals who are the final users of the system or analysis. They play a crucial role in validating sensemaking questions and target metrics, ensuring that the system or analysis meets the intended objectives and provides meaningful insights.</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d8">STAKEHOLDER</data>
      <data key="d6">32</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">390</data>
      <data key="d5">838c4498bc3c437f8d65428b580766a2</data>
    </node>
    <node id="TRADE-OFFS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Considerations and compromises involved in building a graph index</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">CONCEPT</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">391</data>
      <data key="d5">1b893f24eb98477aad6ce49c0f26737e</data>
    </node>
    <node id="PERFORMANCE">
      <data key="d0">METRIC</data>
      <data key="d1">The effectiveness of RAG systems, which varies across different ranges of question types, data types, and dataset sizes</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METRIC</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">392</data>
      <data key="d5">6573bc2af4f94596a3f4452a602d6fc4</data>
    </node>
    <node id="DATA TYPES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Various forms of data used in RAG systems</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">CONCEPT</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">393</data>
      <data key="d5">0dddcca0e5df4b16bc03a51a2d2d8e16</data>
    </node>
    <node id="DATASET SIZES">
      <data key="d0">METRIC</data>
      <data key="d1">The scale of datasets used in RAG systems, which affects performance</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">METRIC</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">394</data>
      <data key="d5">df40ad480a3c47299a6c8fad05349304</data>
    </node>
    <node id="EVALUATION">
      <data key="d0">PROCESS</data>
      <data key="d1">The process of assessing the performance of RAG systems</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">PROCESS</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">395</data>
      <data key="d5">fe98fb197d294b0b837aee8d5a98dfb1</data>
    </node>
    <node id="CORPORA">
      <data key="d0">DATASET</data>
      <data key="d1">Collections of texts used in the evaluation of RAG systems</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">DATASET</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">396</data>
      <data key="d5">feb9ddd0ac2949178f26a36949aa5422</data>
    </node>
    <node id="QUESTION TYPES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Different categories of questions used to evaluate RAG systems</data>
      <data key="d2">92e93fc6449756c0a60200636b297f65</data>
      <data key="d8">CONCEPT</data>
      <data key="d6">26</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">397</data>
      <data key="d5">b4e4fa2e3dfc46e68d532d659b18d17d</data>
    </node>
    <node id="SELFHECKGPT">
      <data key="d0">METHOD</data>
      <data key="d1">SelfCheckGPT is an approach used to compare fabrication rates in text generation tasks</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">2</data>
      <data key="d4">398</data>
      <data key="d5">f58813d090b947a48c1b4614b92c3ec3</data>
    </node>
    <node id="GRAPH-FREE APPROACH">
      <data key="d0">METHOD</data>
      <data key="d1">A method for global summarization of source texts that does not use a graph index</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">55</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">399</data>
      <data key="d5">30a251bc3d04430d82b5a1a98c7b8c75</data>
    </node>
    <node id="COMPUTE BUDGET">
      <data key="d0">RESOURCE</data>
      <data key="d1">The amount of computational resources allocated for a task</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">0</data>
      <data key="d4">400</data>
      <data key="d5">93e1d19f9bfa4c6b8962d56d10ea9483</data>
    </node>
    <node id="LIFETIME QUERIES">
      <data key="d0">METRIC</data>
      <data key="d1">The expected number of queries over the lifetime of a dataset</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">0</data>
      <data key="d4">401</data>
      <data key="d5">8046335ba70b434aa3188392a746fd78</data>
    </node>
    <node id="RICH TEXT ANNOTATIONS">
      <data key="d0">DATA</data>
      <data key="d1">Annotations that provide detailed information about the text</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">402</data>
      <data key="d5">5c02b1ab32064c64a0f8b27b219e358a</data>
    </node>
    <node id="EMBEDDING-BASED MATCHING">
      <data key="d0">METHOD</data>
      <data key="d1">A method that uses embeddings to match user queries with graph annotations</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">24</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">403</data>
      <data key="d5">c5f77ba0c261408780db3d50346f16b7</data>
    </node>
    <node id="HYBRID RAG SCHEMES">
      <data key="d0">METHOD</data>
      <data key="d1">RAG schemes that combine embedding-based matching with other approaches</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">51</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">404</data>
      <data key="d5">453ecf5476f64f4a8d5020b95baf1314</data>
    </node>
    <node id="MAP-REDUCE SUMMARIZATION MECHANISMS">
      <data key="d0">METHOD</data>
      <data key="d1">Mechanisms used in map-reduce summarization</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">57</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">405</data>
      <data key="d5">6a1d83c9ce2b483dbd7de5ab3ae2487d</data>
    </node>
    <node id="COMMUNITY HIERARCHY">
      <data key="d0">DATA</data>
      <data key="d1">A hierarchical organization of communities</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">2</data>
      <data key="d4">406</data>
      <data key="d5">66c3dffb7d7a4fa8bb6b48a22ca917a6</data>
    </node>
    <node id="GLOBAL APPROACH TO GRAPH RAG">
      <data key="d0">METHOD</data>
      <data key="d1">A method that combines knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) for global text summarization</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">33</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">407</data>
      <data key="d5">6f3dd1fd6d7f4df4af0656ed0525c92e</data>
    </node>
    <node id="TOKEN COST">
      <data key="d0">METRIC</data>
      <data key="d1">The cost associated with the number of tokens used in a text generation task</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">33</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">408</data>
      <data key="d5">711eb39432794b0a91110358dd536517</data>
    </node>
    <node id="PYTHON-BASED IMPLEMENTATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">An implementation of Graph RAG approaches using the Python programming language</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">2</data>
      <data key="d4">409</data>
      <data key="d5">0e00585b08044954a254116665400463</data>
    </node>
    <node id="ALONSO">
      <data key="d0">PERSON</data>
      <data key="d1">A person who contributed to the work mentioned in the acknowledgements</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">410</data>
      <data key="d5">db0147eff2204a20b5e5e6bec7a8bae5</data>
    </node>
    <node id="FABRICATION RATES">
      <data key="d0">METRIC</data>
      <data key="d1">The rates at which fabrications occur in text generation tasks</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">1</data>
      <data key="d4">411</data>
      <data key="d5">67bb4f4678284819add02ba04f3b1103</data>
    </node>
    <node id="LIFETIME QUERIES PER DATASET">
      <data key="d0">METRIC</data>
      <data key="d1">The expected number of queries over the lifetime of a specific dataset</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">22</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">412</data>
      <data key="d5">2033ec0487f04240abb3bdbe77b39087</data>
    </node>
    <node id="VALUE FROM GRAPH INDEX">
      <data key="d0">METRIC</data>
      <data key="d1">The benefits or value obtained from using a graph index</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">22</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">413</data>
      <data key="d5">f026fab8fec948ae9e7baa2ad715e6ef</data>
    </node>
    <node id="OTHER GRAPH-RELATED RAG APPROACHES">
      <data key="d0">METHOD</data>
      <data key="d1">Different methods related to retrieval-augmented generation that utilize graph structures</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">22</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">414</data>
      <data key="d5">d0d7ed36d6f54b5d986dfd854096b728</data>
    </node>
    <node id="LOCAL GRAPH RAG APPROACHES">
      <data key="d0">METHOD</data>
      <data key="d1">Graph RAG approaches that operate in a more localized manner</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">415</data>
      <data key="d5">bf6a4c18f44042799eb7456a6b85b54a</data>
    </node>
    <node id="GRAPH ANNOTATIONS">
      <data key="d0">DATA</data>
      <data key="d1">Annotations made on the graph to provide additional information</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">24</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">416</data>
      <data key="d5">fac4a59c2278498d83f9f1b4231ad62e</data>
    </node>
    <node id="COMMUNITY REPORTS">
      <data key="d0">DATA</data>
      <data key="d1">Reports generated from community summaries</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">51</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">417</data>
      <data key="d5">d6d2b5862ddc4c4d87deee3423506817</data>
    </node>
    <node id="ROLL-UP OPERATION">
      <data key="d0">METHOD</data>
      <data key="d1">An operation that aggregates information across multiple levels of a hierarchy</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">57</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">418</data>
      <data key="d5">47d588d26e2b4cccb68fe2af4c147c8f</data>
    </node>
    <node id="DRILL DOWN MECHANISM">
      <data key="d0">METHOD</data>
      <data key="d1">A mechanism that allows for exploring detailed information by following higher-level summaries</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">2</data>
      <data key="d4">419</data>
      <data key="d5">c0f2dc03d8df400db4997c1a0babd6ad</data>
    </node>
    <node id="INFORMATION SCENT">
      <data key="d0">DATA</data>
      <data key="d1">The trail of information that guides users to more detailed data</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">1</data>
      <data key="d4">420</data>
      <data key="d5">0211d61aae834229a3a1e004ff5cc658</data>
    </node>
    <node id="ROOT-LEVEL COMMUNITIES">
      <data key="d0">DATA</data>
      <data key="d1">The top-level communities in a hierarchical structure</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">66</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">421</data>
      <data key="d5">ccbbbcc055c34709abcf103208c2c299</data>
    </node>
    <node id="ENTITY-BASED GRAPH INDEX">
      <data key="d0">DATA</data>
      <data key="d1">A graph index organized around entities</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d6">50</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">422</data>
      <data key="d5">989add81cf874018a569239b68d17ff2</data>
    </node>
    <node id="OPEN-SOURCE IMPLEMENTATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A publicly available implementation of a technology</data>
      <data key="d2">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d3">1</data>
      <data key="d4">423</data>
      <data key="d5">fd7d94fbab084bc380480abeef6bfade</data>
    </node>
    <node id="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Alonso Guevara Fern&#225;ndez is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">21</data>
      <data key="d4">424</data>
      <data key="d5">cfb915c95caf41c6a25e99a9f37f03a2</data>
    </node>
    <node id="AMBER HOAK">
      <data key="d0">PERSON</data>
      <data key="d1">Amber Hoak is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">19</data>
      <data key="d4">425</data>
      <data key="d5">8815ed80f9b741dbb458d902024f34a4</data>
    </node>
    <node id="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d0">PERSON</data>
      <data key="d1">Andr&#233;s Morales Esquivel is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">426</data>
      <data key="d5">dddb831546354e088d29aebd154e3a31</data>
    </node>
    <node id="BEN CUTLER">
      <data key="d0">PERSON</data>
      <data key="d1">Ben Cutler is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">427</data>
      <data key="d5">005d2154da754b21adcd90ac921bd5f7</data>
    </node>
    <node id="BILLIE RINALDI">
      <data key="d0">PERSON</data>
      <data key="d1">Billie Rinaldi is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">428</data>
      <data key="d5">711ba818354546cea69f1532b92a2f26</data>
    </node>
    <node id="CHRIS SANCHEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Sanchez is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">429</data>
      <data key="d5">5c4d8a8f9c104176b87d2bfdf04ae0bd</data>
    </node>
    <node id="CHRIS TREVINO">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Trevino is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">430</data>
      <data key="d5">5a781604f1fb4719b730f43f534627f6</data>
    </node>
    <node id="CHRISTINE CAGGIANO">
      <data key="d0">PERSON</data>
      <data key="d1">Christine Caggiano is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">431</data>
      <data key="d5">ecdc1020b10e49ca869d399825e16fa3</data>
    </node>
    <node id="DAVID TITTSWORTH">
      <data key="d0">PERSON</data>
      <data key="d1">David Tittsworth is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">432</data>
      <data key="d5">0d8fde01d7234726a00d7e73e2e01d66</data>
    </node>
    <node id="DAYENNE DE SOUZA">
      <data key="d0">PERSON</data>
      <data key="d1">Dayenne de Souza is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">433</data>
      <data key="d5">9c4bd60958fd4e09a6d5b9e2ab163b5a</data>
    </node>
    <node id="DOUGLAS ORBAKER">
      <data key="d0">PERSON</data>
      <data key="d1">Douglas Orbaker is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">434</data>
      <data key="d5">39d31f770cf740e78d526a2e1101a1db</data>
    </node>
    <node id="ED CLARK">
      <data key="d0">PERSON</data>
      <data key="d1">Ed Clark is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">435</data>
      <data key="d5">9d282b2250f7408888504f1f93c202a8</data>
    </node>
    <node id="GABRIEL NIEVES-PONCE">
      <data key="d0">PERSON</data>
      <data key="d1">Gabriel Nieves-Ponce is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">436</data>
      <data key="d5">c063484895794a0eaae1b0ff070ad4c9</data>
    </node>
    <node id="GAUDY BLANCO MENESES">
      <data key="d0">PERSON</data>
      <data key="d1">Gaudy Blanco Meneses is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">437</data>
      <data key="d5">e8868920e21b4431aad16e86db977ecb</data>
    </node>
    <node id="KATE LYTVYNETS">
      <data key="d0">PERSON</data>
      <data key="d1">Kate Lytvynets is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">438</data>
      <data key="d5">aea3378bfff842e5b3f4b7a4b55b3879</data>
    </node>
    <node id="KATY SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Katy Smith is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">439</data>
      <data key="d5">d562223c17d948bf98e34b4d97dde932</data>
    </node>
    <node id="M&#211;NICA CARVAJAL">
      <data key="d0">PERSON</data>
      <data key="d1">M&#243;nica Carvajal is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">440</data>
      <data key="d5">cde2d75c51d245879265b79d14b8699b</data>
    </node>
    <node id="NATHAN EVANS">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Evans is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">441</data>
      <data key="d5">44594467054849d4a1fadb46ddd51641</data>
    </node>
    <node id="RICHARD ORTEGA">
      <data key="d0">PERSON</data>
      <data key="d1">Richard Ortega is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">442</data>
      <data key="d5">2918130221f94f4387da049b647bfe6a</data>
    </node>
    <node id="RODRIGO RACANICCI">
      <data key="d0">PERSON</data>
      <data key="d1">Rodrigo Racanicci is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">443</data>
      <data key="d5">fd139ac75b0e4777ab67b7423eaaa37f</data>
    </node>
    <node id="SARAH SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Smith is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">1</data>
      <data key="d4">444</data>
      <data key="d5">a701c349eb7142d48ba7efad89caf9d2</data>
    </node>
    <node id="SHANE SOLOMON">
      <data key="d0">PERSON</data>
      <data key="d1">Shane Solomon is a contributor to the work acknowledged in the document</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">1</data>
      <data key="d4">445</data>
      <data key="d5">e5d40a1b17f74b1db5d18279caedb04a</data>
    </node>
    <node id="GPT-4 TECHNICAL REPORT">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A technical report on GPT-4 published as an arXiv preprint</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">446</data>
      <data key="d5">de25d06733d04385825ee082792f5e52</data>
    </node>
    <node id="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d0">METHOD</data>
      <data key="d1">A method for zero-shot knowledge graph question answering described in an arXiv preprint</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">447</data>
      <data key="d5">32f6f11a7845416b8c6eb9fb0b382140</data>
    </node>
    <node id="QUERY TOOLS TO CAUSAL ARCHITECTS">
      <data key="d0">METHOD</data>
      <data key="d1">A method for harnessing large language models for advanced causal discovery from data</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">448</data>
      <data key="d5">91407be8c3e54e23918d3a7183d962db</data>
    </node>
    <node id="QUERY FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A method incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">449</data>
      <data key="d5">3831134696584d83bbf676a6b3bfa8f9</data>
    </node>
    <node id="J. ACHIAM">
      <data key="d0">PERSON</data>
      <data key="d1">J. Achiam is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">9</data>
      <data key="d4">450</data>
      <data key="d5">50e512a5dbe941f5af68bfdf74b1c3c0</data>
    </node>
    <node id="S. ADLER">
      <data key="d0">PERSON</data>
      <data key="d1">S. Adler is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">9</data>
      <data key="d4">451</data>
      <data key="d5">edc717747e904728b57185f5013461f9</data>
    </node>
    <node id="S. AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">S. Agarwal is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">9</data>
      <data key="d4">452</data>
      <data key="d5">8fba1fea719d49d380ac2d9c310d68b3</data>
    </node>
    <node id="L. AHMAD">
      <data key="d0">PERSON</data>
      <data key="d1">L. Ahmad is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">9</data>
      <data key="d4">453</data>
      <data key="d5">532da08f04f645708e747c57e9c4ee05</data>
    </node>
    <node id="I. AKKAYA">
      <data key="d0">PERSON</data>
      <data key="d1">I. Akkaya is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">9</data>
      <data key="d4">454</data>
      <data key="d5">3cf0ab4cf14e47ddabd49d500a3dc488</data>
    </node>
    <node id="F. L. ALEMAN">
      <data key="d0">PERSON</data>
      <data key="d1">F. L. Aleman is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">9</data>
      <data key="d4">455</data>
      <data key="d5">a39b72f8921f43ef8ef295c7cc8f7294</data>
    </node>
    <node id="D. ALMEIDA">
      <data key="d0">PERSON</data>
      <data key="d1">D. Almeida is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">9</data>
      <data key="d4">456</data>
      <data key="d5">9f5adbeb6cf04f089abe78d86cfa6aba</data>
    </node>
    <node id="J. ALTENSCHMIDT">
      <data key="d0">PERSON</data>
      <data key="d1">J. Altenschmidt is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">9</data>
      <data key="d4">457</data>
      <data key="d5">efb6350e65964659bc20396c0166b296</data>
    </node>
    <node id="S. ALTMAN">
      <data key="d0">PERSON</data>
      <data key="d1">S. Altman is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">9</data>
      <data key="d4">458</data>
      <data key="d5">e095cc36da784300b27c6f8c60a96440</data>
    </node>
    <node id="S. ANADKAT">
      <data key="d0">PERSON</data>
      <data key="d1">S. Anadkat is an author of the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">9</data>
      <data key="d4">459</data>
      <data key="d5">c68893ca39d74ba08c6eb138f24441e1</data>
    </node>
    <node id="R. ANIL">
      <data key="d0">PERSON</data>
      <data key="d1">R. Anil is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">8</data>
      <data key="d4">460</data>
      <data key="d5">472b23bb92834173b4118d101040c726</data>
    </node>
    <node id="S. BORGEAUD">
      <data key="d0">PERSON</data>
      <data key="d1">S. Borgeaud is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">8</data>
      <data key="d4">461</data>
      <data key="d5">81869985b45a4fefbbbb23ea118a3de4</data>
    </node>
    <node id="Y. WU">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Wu is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">8</data>
      <data key="d4">462</data>
      <data key="d5">42b8584c5a874eb08fbd61f0c18f3ca0</data>
    </node>
    <node id="J.-B. ALAYRAC">
      <data key="d0">PERSON</data>
      <data key="d1">J.-B. Alayrac is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">8</data>
      <data key="d4">463</data>
      <data key="d5">824d93d9840a4b7c8b1f31bc6816b497</data>
    </node>
    <node id="J. YU">
      <data key="d0">PERSON</data>
      <data key="d1">J. Yu is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">8</data>
      <data key="d4">464</data>
      <data key="d5">f209a808f1f04a5699601e672f4abd06</data>
    </node>
    <node id="R. SORICUT">
      <data key="d0">PERSON</data>
      <data key="d1">R. Soricut is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">8</data>
      <data key="d4">465</data>
      <data key="d5">ccb335166f6c4564ac1c61549d8ded50</data>
    </node>
    <node id="J. SCHALKWYK">
      <data key="d0">PERSON</data>
      <data key="d1">J. Schalkwyk is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">8</data>
      <data key="d4">466</data>
      <data key="d5">cbe1a41a82aa4f268e8264568b25938f</data>
    </node>
    <node id="A. M. DAI">
      <data key="d0">PERSON</data>
      <data key="d1">A. M. Dai is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">8</data>
      <data key="d4">467</data>
      <data key="d5">28e7639f55ce464c8a080cbb2c745fa2</data>
    </node>
    <node id="A. HAUTH">
      <data key="d0">PERSON</data>
      <data key="d1">A. Hauth is an author of the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">8</data>
      <data key="d4">468</data>
      <data key="d5">3f3a2d7aa1294116814f0b4d89baa23d</data>
    </node>
    <node id="J. BAEK">
      <data key="d0">PERSON</data>
      <data key="d1">J. Baek is an author of the paper on knowledge-augmented language model prompting</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">469</data>
      <data key="d5">3073b33926bd4f33807ffa3befacefaf</data>
    </node>
    <node id="A. F. AJI">
      <data key="d0">PERSON</data>
      <data key="d1">A. F. Aji is an author of the paper on knowledge-augmented language model prompting</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">470</data>
      <data key="d5">2b916117691c4872a9c4e4888d4fe4ab</data>
    </node>
    <node id="A. SAFFARI">
      <data key="d0">PERSON</data>
      <data key="d1">A. Saffari is an author of the paper on knowledge-augmented language model prompting</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">2</data>
      <data key="d4">471</data>
      <data key="d5">1f7b02bf486e4f42b23e9cb1a63207f3</data>
    </node>
    <node id="T. BAN">
      <data key="d0">PERSON</data>
      <data key="d1">T. Ban is an author of the paper on query tools to causal architects</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">1</data>
      <data key="d4">472</data>
      <data key="d5">e744c118ae7f4638a01d060bbaedd6e9</data>
    </node>
    <node id="L. CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">L. Chen is an author of the paper on query tools to causal architects</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">1</data>
      <data key="d4">473</data>
      <data key="d5">e1c1080c717d437996def1a41772d179</data>
    </node>
    <node id="X. WANG">
      <data key="d0">PERSON</data>
      <data key="d1">X. Wang is an author of the paper on query tools to causal architects</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">474</data>
      <data key="d5">63fba9a7c47a4f14ac0bee6bc90d0fea</data>
    </node>
    <node id="H. CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">H. Chen is an author of the paper on query tools to causal architects</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">475</data>
      <data key="d5">6bfc2395b4f54a528a1ebac94a43acb8</data>
    </node>
    <node id="T. BAUMEL">
      <data key="d0">PERSON</data>
      <data key="d1">T. Baumel is an author of the paper on query focused abstractive summarization</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">476</data>
      <data key="d5">1cce5cebf437428eb1a60dffbdfa603f</data>
    </node>
    <node id="M. EYAL">
      <data key="d0">PERSON</data>
      <data key="d1">M. Eyal is an author of the paper on query focused abstractive summarization</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">477</data>
      <data key="d5">dc94039d6643460ca3c66150b9087129</data>
    </node>
    <node id="M. ELHADAD">
      <data key="d0">PERSON</data>
      <data key="d1">M. Elhadad is an author of the paper on query focused abstractive summarization</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">478</data>
      <data key="d5">f197d75f159943f8a3ff441199790bc7</data>
    </node>
    <node id="ARXIV:2303.08774">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv preprint identifier for the GPT-4 technical report</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">479</data>
      <data key="d5">4d8890c699684c9381105b03b0b41b03</data>
    </node>
    <node id="ARXIV:2312.11805">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv preprint identifier for the Gemini paper</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">480</data>
      <data key="d5">b1658adfa43847eabad1437db235e858</data>
    </node>
    <node id="ARXIV:2306.04136">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv preprint identifier for the paper on knowledge-augmented language model prompting</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">481</data>
      <data key="d5">a1773cac7d4c4939aec965660e5015fe</data>
    </node>
    <node id="ARXIV:180">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv preprint identifier for the paper on query focused abstractive summarization</data>
      <data key="d2">086021a89900a39bcb62036981737bfa</data>
      <data key="d3">0</data>
      <data key="d4">482</data>
      <data key="d5">6a054cb59fb44cf494b93988b5f88833</data>
    </node>
    <node id="BAUMEL, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Baumel, T. is an author of the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">44</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">483</data>
      <data key="d5">e7b103a52e384e3e8bf14105223e7e82</data>
    </node>
    <node id="EYAL, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Eyal, M. is an author of the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">44</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">484</data>
      <data key="d5">3f1042452c254cecaf7189e89162adc8</data>
    </node>
    <node id="ELHADAD, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Elhadad, M. is an author of the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">44</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">485</data>
      <data key="d5">fd31d549420744d1bd1a6b1112a9a6ba</data>
    </node>
    <node id="BLONDEL, V. D.">
      <data key="d0">PERSON</data>
      <data key="d1">Blondel, V. D. is an author of the paper "Fast unfolding of communities in large networks"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">3</data>
      <data key="d4">486</data>
      <data key="d5">f7ab348030714072a277682b51f7c588</data>
    </node>
    <node id="GUILLAUME, J.-L.">
      <data key="d0">PERSON</data>
      <data key="d1">Guillaume, J.-L. is an author of the paper "Fast unfolding of communities in large networks"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">3</data>
      <data key="d4">487</data>
      <data key="d5">2139b0906dc541e094138a978d070416</data>
    </node>
    <node id="LAMBIOTTE, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Lambiotte, R. is an author of the paper "Fast unfolding of communities in large networks"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">3</data>
      <data key="d4">488</data>
      <data key="d5">ff5466607e5d4453b1d833629292f664</data>
    </node>
    <node id="LEFEBVRE, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Lefebvre, E. is an author of the paper "Fast unfolding of communities in large networks"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">3</data>
      <data key="d4">489</data>
      <data key="d5">71f95003936e46a98d90757ffd845d40</data>
    </node>
    <node id="JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Fast unfolding of communities in large networks" was published</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">0</data>
      <data key="d4">490</data>
      <data key="d5">bada987ea7da4c939393ee1c3d08ccd4</data>
    </node>
    <node id="BROWN, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Brown, T. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">9</data>
      <data key="d4">491</data>
      <data key="d5">d0a274e7934d446fb91847bb53a961a6</data>
    </node>
    <node id="MANN, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Mann, B. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">9</data>
      <data key="d4">492</data>
      <data key="d5">0a799eab61bc4e6b884db6689f9c2c4a</data>
    </node>
    <node id="RYDER, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Ryder, N. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">9</data>
      <data key="d4">493</data>
      <data key="d5">8c34cd494a63438dac219c1dc0f73100</data>
    </node>
    <node id="SUBBIAH, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Subbiah, M. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">8</data>
      <data key="d4">494</data>
      <data key="d5">c6f428af0c5e4f629902fd5455bf19ac</data>
    </node>
    <node id="KAPLAN, J. D.">
      <data key="d0">PERSON</data>
      <data key="d1">Kaplan, J. D. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">4</data>
      <data key="d4">495</data>
      <data key="d5">d1fd271d16c348019c2fcced762b35a2</data>
    </node>
    <node id="DHARIWAL, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Dhariwal, P. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">4</data>
      <data key="d4">496</data>
      <data key="d5">ffa128c9c0c84d39bad1bba8cfa4adc5</data>
    </node>
    <node id="NEELAKANTAN, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Neelakantan, A. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">4</data>
      <data key="d4">497</data>
      <data key="d5">058f66cc356b43cc9433bd3c8d57fa46</data>
    </node>
    <node id="SHYAM, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Shyam, P. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">4</data>
      <data key="d4">498</data>
      <data key="d5">ff74091eaba246698fcae59c21eec828</data>
    </node>
    <node id="SASTRY, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Sastry, G. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">4</data>
      <data key="d4">499</data>
      <data key="d5">f6cbbf1b8f4b48a28a16e4dd8976b9bb</data>
    </node>
    <node id="ASKELL, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Askell, A. is an author of the paper "Language models are few-shot learners"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">3</data>
      <data key="d4">500</data>
      <data key="d5">757ca40654d5476aa949a26b733be8d4</data>
    </node>
    <node id="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS" is a prominent conference where significant papers in the field of Natural Language Processing and Information Retrieval are presented. Notable papers presented at this conference include "Language models are few-shot learners" and "Retrieval-augmented generation for knowledge-intensive NLP tasks." Additionally, it is also the journal where the paper "Judging llm-as-a-judge with mt-bench and chatbot arena" was published. This conference and journal serve as key platforms for disseminating cutting-edge research in neural information processing systems.</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5,6cd82819982879bd164547d2773ba5c7,b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d3">0</data>
      <data key="d4">501</data>
      <data key="d5">539d55e7c42e44b59d98f59fae3e0ee1</data>
    </node>
    <node id="CHENG, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Cheng, X. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">0</data>
      <data key="d4">502</data>
      <data key="d5">3785eeadea9042bfb2e50f16c0397a12</data>
    </node>
    <node id="LUO, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Luo, D. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">0</data>
      <data key="d4">503</data>
      <data key="d5">48cd97f2297143e09d61ff2a8542c0c5</data>
    </node>
    <node id="CHEN, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Chen, X. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">0</data>
      <data key="d4">504</data>
      <data key="d5">ff95eb0d5f7f49b782027d5c7ae3c3fe</data>
    </node>
    <node id="LIU, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Liu, L. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">0</data>
      <data key="d4">505</data>
      <data key="d5">086da554db5b4ad5806aedeb0024197c</data>
    </node>
    <node id="ZHAO, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhao, D. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"Zhao, D. is an author of the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d8">PERSON</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">506</data>
      <data key="d5">216ee8a907a0466a88b27f8ada19ffa0</data>
    </node>
    <node id="YAN, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Yan, R. is an author of the paper "Lift yourself up: Retrieval-augmented text generation with self-memory"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">0</data>
      <data key="d4">507</data>
      <data key="d5">6fefb317687d4ac98efe39a52f3e190f</data>
    </node>
    <node id="DANG, H. T.">
      <data key="d0">PERSON</data>
      <data key="d1">Dang, H. T. is an author of the paper "Duc 2005: Evaluation of question-focused summarization systems"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">0</data>
      <data key="d4">508</data>
      <data key="d5">320d9d91238948a8be67972ccceab878</data>
    </node>
    <node id="PROCEEDINGS OF THE WORKSHOP ON TASK-FOCUSED SUMMARIZATION AND QUESTION ANSWERING">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The conference where the paper "Duc 2005: Evaluation of question-focused summarization systems" was presented</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">0</data>
      <data key="d4">509</data>
      <data key="d5">bdcbcccadd474b3bbe9a8f56c811bab4</data>
    </node>
    <node id="ES, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Es, S. is an author of the paper "Ragas: Automated evaluation of retrieval augmented generation"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">42</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">510</data>
      <data key="d5">f127fc4d87f94794be89134406ba0694</data>
    </node>
    <node id="JAMES, J.">
      <data key="d0">PERSON</data>
      <data key="d1">James, J. is an author of the paper "Ragas: Automated evaluation of retrieval augmented generation"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">42</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">511</data>
      <data key="d5">c27966a4e3be434686454204ac7b3ab4</data>
    </node>
    <node id="ESPINOSA-ANKE, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Espinosa-Anke, L. is an author of the paper "Ragas: Automated evaluation of retrieval augmented generation"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">42</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">512</data>
      <data key="d5">dab39f92d0ed468c80699f28c05c45fa</data>
    </node>
    <node id="SCHOCKAERT, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Schockaert, S. is an author of the paper "Ragas: Automated evaluation of retrieval augmented generation"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">42</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">513</data>
      <data key="d5">3076f330d121489aa50964ce54a3b1ac</data>
    </node>
    <node id="FENG, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Feng, Z. is an author of the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">514</data>
      <data key="d5">c8e5d3afdcb54c8589e280f0c4a87417</data>
    </node>
    <node id="FENG, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Feng, X. is an author of the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">515</data>
      <data key="d5">f3d30627e19245649e497ab49bf0fa30</data>
    </node>
    <node id="YANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Yang, M. is an author of the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">516</data>
      <data key="d5">e3f1098c3d984bc7b5f30b9c0101f7a6</data>
    </node>
    <node id="QIN, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Qin, B. is an author of the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">2</data>
      <data key="d4">517</data>
      <data key="d5">24b4a5f4db67418cbfa08c5316f0ab51</data>
    </node>
    <node id="FORTUNATO, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Fortunato, S. is an author of the paper "Community detection in graphs"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">0</data>
      <data key="d4">518</data>
      <data key="d5">e4b707e3e6964197855b82fc66ef59e7</data>
    </node>
    <node id="PHYSICS REPORTS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Community detection in graphs" was published</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">0</data>
      <data key="d4">519</data>
      <data key="d5">109b8be5a8ee4180a1465cd23f019d7b</data>
    </node>
    <node id="GAO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Gao, Y. is an author of the paper "Retrieval-augmented generation for large language models: A survey." This work delves into the integration of retrieval mechanisms with generative models to enhance the performance of large language models, a significant topic within the fields of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">8</data>
      <data key="d4">520</data>
      <data key="d5">49f771e31a0c4b35bc39e389f3623509</data>
    </node>
    <node id="XIONG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Xiong, Y. is an author of the paper "Retrieval-augmented generation for large language models: A survey." This work delves into the integration of retrieval mechanisms with generative models to enhance the performance of large language models. The paper provides a comprehensive survey of the methodologies and applications of retrieval-augmented generation, highlighting its significance in the field of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">8</data>
      <data key="d4">521</data>
      <data key="d5">aa946d4379694a74ba0da37e69d2810a</data>
    </node>
    <node id="GAO, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Gao, X. is an author of the paper titled "Retrieval-augmented generation for large language models: A survey." This work delves into the integration of retrieval mechanisms with generative models to enhance the performance of large language models, a significant topic within the fields of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">8</data>
      <data key="d4">522</data>
      <data key="d5">268446fc52a54fd2837f73aeb3e0b74f</data>
    </node>
    <node id="JIA, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Jia, K. is an author of the paper "Retrieval-augmented generation for large language models: A survey" and also contributed to the paper titled "Retrieval-augmented generation." These works focus on the integration of retrieval mechanisms with generative models to enhance the performance of large language models, a significant area of research within the domains of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">8</data>
      <data key="d4">523</data>
      <data key="d5">f6ddfa8491ff40d2839bb5b2e105df22</data>
    </node>
    <node id="PAN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Pan, J. is an author of the paper "Retrieval-augmented generation for large language models: A survey" and also contributed to the paper titled "Retrieval-augmented generation."</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">8</data>
      <data key="d4">524</data>
      <data key="d5">db1295504da645b69d9786d54f233fed</data>
    </node>
    <node id="BI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Bi, Y. is an author of the paper "Retrieval-augmented generation for large language models: A survey" and also contributed to the paper titled "Retrieval-augmented generation."</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">8</data>
      <data key="d4">525</data>
      <data key="d5">6ff4ed0dda4f4158af37be99f505565f</data>
    </node>
    <node id="DAI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Dai, Y. is an author of the paper "Retrieval-augmented generation for large language models: A survey" and also contributed to the paper titled "Retrieval-augmented generation." These works focus on the integration of retrieval mechanisms with generative models to enhance the performance and capabilities of large language models, a significant area of research within the fields of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">8</data>
      <data key="d4">526</data>
      <data key="d5">5d398b88ee4242a59c32feb188683ec3</data>
    </node>
    <node id="SUN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Sun, J. is an author of the paper "Retrieval-augmented generation for large language models: A survey" and also contributed to the paper titled "Retrieval-augmented generation."</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">8</data>
      <data key="d4">527</data>
      <data key="d5">0a784e00c9464bd3aeb830b908f73170</data>
    </node>
    <node id="WANG, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, H. is an author of the paper titled "Retrieval-augmented generation for large language models: A survey." This work delves into the integration of retrieval mechanisms with generative models to enhance the performance of large language models, a significant topic within the fields of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d3">8</data>
      <data key="d4">528</data>
      <data key="d5">b0966a0f455e44229e6c9705d57bfca9</data>
    </node>
    <node id="ARXIV:1801.07704">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv identifier for the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">44</data>
      <data key="d7">1</data>
      <data key="d3">3</data>
      <data key="d4">529</data>
      <data key="d5">99761e9b89cc4060be3ed6b34532e7ff</data>
    </node>
    <node id="ARXIV:2309.15217">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv identifier for the paper "Ragas: Automated evaluation of retrieval augmented generation"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">42</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">530</data>
      <data key="d5">8130a1a82bde46048952cf147690e630</data>
    </node>
    <node id="ARXIV:2310.05149">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The arXiv identifier for the paper "Retrieval-generation synergy augmented large language models"</data>
      <data key="d2">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">5</data>
      <data key="d4">531</data>
      <data key="d5">79c99026b7ef4946b9b8e0be841fd4c5</data>
    </node>
    <node id="GOODWIN, T. R.">
      <data key="d0">PERSON</data>
      <data key="d1">Goodwin, T. R. is an author of the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">2</data>
      <data key="d4">532</data>
      <data key="d5">fdcb1673254842f1935f53d0c38c467e</data>
    </node>
    <node id="SAVERY, M. E.">
      <data key="d0">PERSON</data>
      <data key="d1">Savery, M. E. is an author of the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">1</data>
      <data key="d4">533</data>
      <data key="d5">dcb3f4cc8abc46faabc193d9885e91d0</data>
    </node>
    <node id="DEMNER-FUSHMAN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Demner-Fushman, D. is an author of the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">1</data>
      <data key="d4">534</data>
      <data key="d5">3295be59128d451bb720c6688adc1e0b</data>
    </node>
    <node id="COLING">
      <data key="d0">CONFERENCE</data>
      <data key="d1">COLING (International Conference on Computational Linguistics) is the conference where the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization" was presented</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">535</data>
      <data key="d5">aca3eb8924ac494486fe0bfe892f7f2e</data>
    </node>
    <node id="HE, X.">
      <data key="d0">PERSON</data>
      <data key="d1">He, X. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">536</data>
      <data key="d5">66689accdd974295b7eb779e43578748</data>
    </node>
    <node id="TIAN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Tian, Y. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">537</data>
      <data key="d5">6b49c78aa1524609ab7aa74aeaa3e01d</data>
    </node>
    <node id="SUN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Sun, Y. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">538</data>
      <data key="d5">7ff31ce54f424f0bbb297b0b3ba7c757</data>
    </node>
    <node id="CHAWLA, N. V.">
      <data key="d0">PERSON</data>
      <data key="d1">Chawla, N. V. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">539</data>
      <data key="d5">bac51e00d486420c8e91e824d8e17411</data>
    </node>
    <node id="LAURENT, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Laurent, T. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">540</data>
      <data key="d5">4adee3aad6524a4aa4c4711c1ee05e64</data>
    </node>
    <node id="LECUN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">LeCun, Y. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">541</data>
      <data key="d5">d034e4fd8ac849278e658daad1a1f033</data>
    </node>
    <node id="BRESSON, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Bresson, X. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">542</data>
      <data key="d5">091e998370dd42d1b05ab0fcf6595a7e</data>
    </node>
    <node id="HOOI, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Hooi, B. is an author of the paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">543</data>
      <data key="d5">1e6cabc18fab4c048281fd29d3044438</data>
    </node>
    <node id="JACOMY, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Jacomy, M. is an author of the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">544</data>
      <data key="d5">dc08f6d7398b4b798a3bdccf508a2ad4</data>
    </node>
    <node id="VENTURINI, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Venturini, T. is an author of the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">545</data>
      <data key="d5">1c7fd5af8d8041e186eae2431fc627cd</data>
    </node>
    <node id="HEYMANN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Heymann, S. is an author of the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">546</data>
      <data key="d5">b16eda56dcec40f2b3e109fb9246bee3</data>
    </node>
    <node id="BASTIAN, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Bastian, M. is an author of the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">547</data>
      <data key="d5">43c68f9a86654a32a2215e23957ed184</data>
    </node>
    <node id="PLOS ONE">
      <data key="d0">PUBLICATION</data>
      <data key="d1">PLOS ONE is the journal where the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software" was published</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">548</data>
      <data key="d5">1ba06fe2e86140a59bbc4f4e969d0f71</data>
    </node>
    <node id="JIN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Jin, D. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">549</data>
      <data key="d5">36caa0a230c8422c8acb4dc62e35bb32</data>
    </node>
    <node id="YU, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Yu, Z. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">550</data>
      <data key="d5">09940fed9d154504948bba2df1789a50</data>
    </node>
    <node id="JIAO, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Jiao, P. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">551</data>
      <data key="d5">4d6608557eed49368a6d09c7c5c664c5</data>
    </node>
    <node id="PAN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Pan, S. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">552</data>
      <data key="d5">eb7c93eeb9dc41aab57d29e97ebb4951</data>
    </node>
    <node id="HE, D.">
      <data key="d0">PERSON</data>
      <data key="d1">He, D. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">553</data>
      <data key="d5">3b6e2ac584b64847b53828c9d779fed3</data>
    </node>
    <node id="WU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Wu, J. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">554</data>
      <data key="d5">e9b68002e035447baae848208cea5503</data>
    </node>
    <node id="PHILIP, S. Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Philip, S. Y. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">555</data>
      <data key="d5">fe18353546824ca98294ce4be7b96e02</data>
    </node>
    <node id="ZHANG, W.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, W. is an author of the paper "A survey of community detection approaches: From statistical modeling to deep learning"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">556</data>
      <data key="d5">0e9740e25f5a460c81318336e00ac880</data>
    </node>
    <node id="IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING">
      <data key="d0">PUBLICATION</data>
      <data key="d1">IEEE Transactions on Knowledge and Data Engineering is the journal where the paper "A survey of community detection approaches: From statistical modeling to deep learning" was published</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">557</data>
      <data key="d5">b7cd9a62710849778fdadced0d754687</data>
    </node>
    <node id="KANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Kang, M. is an author of the paper "Knowledge graph-augmented language models for knowledge-grounded dialogue generation"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">558</data>
      <data key="d5">432a6b4962544200949421a96a405142</data>
    </node>
    <node id="KWAK, J. M.">
      <data key="d0">PERSON</data>
      <data key="d1">Kwak, J. M. is an author of the paper "Knowledge graph-augmented language models for knowledge-grounded dialogue generation"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">559</data>
      <data key="d5">d6700b360ac141d282cdb567414bf4ce</data>
    </node>
    <node id="BAEK, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Baek, J. is an author of the paper "Knowledge graph-augmented language models for knowledge-grounded dialogue generation"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">560</data>
      <data key="d5">c1b40a4039b44061a358e098867f7412</data>
    </node>
    <node id="HWANG, S. J.">
      <data key="d0">PERSON</data>
      <data key="d1">Hwang, S. J. is an author of the paper "Knowledge graph-augmented language models for knowledge-grounded dialogue generation"</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d3">0</data>
      <data key="d4">561</data>
      <data key="d5">4643a7a319674adfb732b6f6122c7c64</data>
    </node>
    <node id="KHATTAB, O.">
      <data key="d0">PERSON</data>
      <data key="d1">Khattab, O. is an author of the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This work focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">7</data>
      <data key="d4">562</data>
      <data key="d5">46e8056fb2ec4811ab33cb34a0dc9fb3</data>
    </node>
    <node id="SANTHANAM, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Santhanam, K. is an author of the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is referenced in the text and contributes to the field of Natural Language Processing and Information Retrieval by exploring the integration of retrieval and language models to enhance knowledge-intensive NLP tasks.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">7</data>
      <data key="d4">563</data>
      <data key="d5">8b57a9f43a1942a49b58cf881835f974</data>
    </node>
    <node id="LI, X. L.">
      <data key="d0">PERSON</data>
      <data key="d1">Li, X. L. is an author of the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is referenced in the provided text and contributes to the field of Natural Language Processing and Information Retrieval by exploring the integration of retrieval and language models to enhance knowledge-intensive tasks.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">7</data>
      <data key="d4">564</data>
      <data key="d5">f78b01b0d93948c283644ec58f7be74a</data>
    </node>
    <node id="HALL, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Hall, D. is an author of the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is referenced in the provided text, indicating its relevance within the domain of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">7</data>
      <data key="d4">565</data>
      <data key="d5">8dbe8f9867e4448f998416c18923eac4</data>
    </node>
    <node id="LIANG, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Liang, P. is an author of multiple influential papers in the field of Natural Language Processing and Information Retrieval. Notably, Liang, P. contributed to the paper "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP," which explores the integration of retrieval and language models to enhance knowledge-intensive tasks in NLP. Additionally, Liang, P. authored the paper "Lost in the middle: How language models use long contexts," which investigates the utilization of extended contexts by language models. These contributions highlight Liang, P.'s significant role in advancing the understanding and application of language models in complex NLP tasks.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,6cd82819982879bd164547d2773ba5c7,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">7</data>
      <data key="d4">566</data>
      <data key="d5">fe8ea8bf1395434393e04e8f7a33025f</data>
    </node>
    <node id="POTTS, C.">
      <data key="d0">PERSON</data>
      <data key="d1">Potts, C. is an author of the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is referenced in the provided text and contributes to the field of Natural Language Processing and Information Retrieval by exploring the integration of retrieval and language models to enhance knowledge-intensive NLP tasks.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">7</data>
      <data key="d4">567</data>
      <data key="d5">7d58b089bfc549e8951e91ad62541119</data>
    </node>
    <node id="ZAHARIA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Zaharia, M. is an author of the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is referenced in the text and contributes to the field of Natural Language Processing and Information Retrieval by exploring the integration of retrieval and language models to enhance knowledge-intensive NLP tasks.</data>
      <data key="d2">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">7</data>
      <data key="d4">568</data>
      <data key="d5">1fa6d3118bd846c8837b5fa9fb78f262</data>
    </node>
    <node id="KIM, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Kim, G. is an author of the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">5</data>
      <data key="d4">569</data>
      <data key="d5">62c65bbae33c4ee9a21b61f6f454c4b4</data>
    </node>
    <node id="KIM, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Kim, S. is an author of the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">5</data>
      <data key="d4">570</data>
      <data key="d5">30b7034c4468473f98ee18d00ee73b33</data>
    </node>
    <node id="JEON, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Jeon, B. is an author of the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">5</data>
      <data key="d4">571</data>
      <data key="d5">00f78b85e5b84999a810e311e540037b</data>
    </node>
    <node id="PARK, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Park, J. is an author of the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">5</data>
      <data key="d4">572</data>
      <data key="d5">3e460d9f011d4b0b9ccaae7b6a5202de</data>
    </node>
    <node id="KANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Kang, J. is an author of the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">5</data>
      <data key="d4">573</data>
      <data key="d5">9d98dece22eb401aa1a5ce9c88c603f0</data>
    </node>
    <node id="KLEIN, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Klein, G. is an author of the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">3</data>
      <data key="d4">574</data>
      <data key="d5">81446ea789b24eaf9eab02dc07c3d984</data>
    </node>
    <node id="MOON, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Moon, B. is an author of the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">3</data>
      <data key="d4">575</data>
      <data key="d5">79f4b1c1b2be4cf7aa828846e20a4eb6</data>
    </node>
    <node id="HOFFMAN, R. R.">
      <data key="d0">PERSON</data>
      <data key="d1">Hoffman, R. R. is an author of the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">3</data>
      <data key="d4">576</data>
      <data key="d5">de04830d6e414fd5b39a9e90769d9452</data>
    </node>
    <node id="IEEE INTELLIGENT SYSTEMS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model" were published</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">3</data>
      <data key="d4">577</data>
      <data key="d5">69db426b97714835bf4937180774787a</data>
    </node>
    <node id="KOESTEN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Koesten, L. is an author of the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">4</data>
      <data key="d4">578</data>
      <data key="d5">9c7bc862339d4a5bb21ee5154d9b33bb</data>
    </node>
    <node id="GREGORY, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Gregory, K. is an author of the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">4</data>
      <data key="d4">579</data>
      <data key="d5">17bad53a0ebe4569839e5e151ff78593</data>
    </node>
    <node id="GROTH, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Groth, P. is an author of the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">4</data>
      <data key="d4">580</data>
      <data key="d5">53d98f08e7c74158b7318357b6c660b3</data>
    </node>
    <node id="SIMPERL, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Simperl, E. is an author of the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">4</data>
      <data key="d4">581</data>
      <data key="d5">cd601f77419c403889aadeee591915b5</data>
    </node>
    <node id="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Talking datasets&#8211;understanding data sensemaking behaviours" was published</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">4</data>
      <data key="d4">582</data>
      <data key="d5">0f564ebd53e940fba9d16674ac7bc038</data>
    </node>
    <node id="KURATOV, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Kuratov, Y. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">1</data>
      <data key="d4">583</data>
      <data key="d5">7deb75816e4f473480e0c79ae99b5bf4</data>
    </node>
    <node id="BULATOV, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Bulatov, A. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">1</data>
      <data key="d4">584</data>
      <data key="d5">7f85b181f1184f77aeb3ea2155cf4027</data>
    </node>
    <node id="ANOKHIN, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Anokhin, P. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">1</data>
      <data key="d4">585</data>
      <data key="d5">d148b2b2033048618f1a090a492a40a5</data>
    </node>
    <node id="SOROKIN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Sorokin, D. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">1</data>
      <data key="d4">586</data>
      <data key="d5">4d839a10353e4144a26563b0966721d5</data>
    </node>
    <node id="SOROKIN, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Sorokin, A. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">1</data>
      <data key="d4">587</data>
      <data key="d5">521a862bb196488389f17c0b0f4b6f4d</data>
    </node>
    <node id="BURTSEV, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Burtsev, M. is an author of the paper "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">1</data>
      <data key="d4">588</data>
      <data key="d5">22ea3328fb6343f4ad2862495ea27640</data>
    </node>
    <node id="LANGCHAIN GRAPHS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Langchain graphs is a technology developed by LangChain</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">1</data>
      <data key="d4">589</data>
      <data key="d5">3f9a2a2c1c0a424e8b4980ea9d48bdbe</data>
    </node>
    <node id="LASKAR, M. T. R.">
      <data key="d0">PERSON</data>
      <data key="d1">Laskar, M. T. R. is an author of the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" and also contributed to the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models." Both works highlight Laskar's expertise in leveraging transformer models and transfer learning techniques to enhance the performance of query-focused abstractive text summarization, demonstrating a significant contribution to the field of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">5</data>
      <data key="d4">590</data>
      <data key="d5">aa2ec452728a4703ae1bdabe85b6c079</data>
    </node>
    <node id="HOQUE, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Hoque, E. is an author of two significant papers in the field of Natural Language Processing and Information Retrieval. The first paper, titled "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization," explores the use of pre-trained transformer models to enhance the performance of query-focused abstractive summarization through domain adaptation techniques. The second paper, "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models," delves into the integration of query relevance and transfer learning to improve the effectiveness of transformer models in query-focused abstractive summarization tasks. Both works contribute to advancing the understanding and application of transformer models in specialized summarization contexts.</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">5</data>
      <data key="d4">591</data>
      <data key="d5">c5ddb31e0a9c4b2683e4631283dd505b</data>
    </node>
    <node id="HUANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Huang, J. is an author of the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models"</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">3</data>
      <data key="d4">592</data>
      <data key="d5">07d8eeb549044ac88d2e788c146a0ef1</data>
    </node>
    <node id="ADVANCES IN ARTIFICIAL INTELLIGENCE">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The conference where the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models" was presented</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">3</data>
      <data key="d4">593</data>
      <data key="d5">47df2815030c4f1c99facd5cf2482526</data>
    </node>
    <node id="ARXIV PREPRINT">
      <data key="d0">PUBLICATION</data>
      <data key="d1">arXiv preprint refers to a preprint of a paper that is available on the arXiv repository</data>
      <data key="d2">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d3">18</data>
      <data key="d4">594</data>
      <data key="d5">ae521508bdc244f99c4fce4ab5214c79</data>
    </node>
    <node id="33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE">
      <data key="d0">EVENT</data>
      <data key="d1">The 33rd Canadian Conference on Artificial Intelligence, held in Ottawa, ON, Canada, from May 13&#8211;15, 2020</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">2</data>
      <data key="d4">595</data>
      <data key="d5">6315b4bf135c40358823ed7e4e4060e2</data>
    </node>
    <node id="CANADIAN AI 2020">
      <data key="d0">EVENT</data>
      <data key="d1">The 2020 edition of the Canadian Conference on Artificial Intelligence</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">1</data>
      <data key="d4">596</data>
      <data key="d5">33905debec1a45ecae1c65daac1d854c</data>
    </node>
    <node id="SPRINGER">
      <data key="d0">PUBLISHER</data>
      <data key="d1">Springer is the publisher of the proceedings of the 33rd Canadian Conference on Artificial Intelligence</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">1</data>
      <data key="d4">597</data>
      <data key="d5">bfbe904780fe47daad1a04126b12923c</data>
    </node>
    <node id="HUANG, J. X.">
      <data key="d0">PERSON</data>
      <data key="d1">Huang, J. X. is an author of the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">3</data>
      <data key="d4">598</data>
      <data key="d5">0614f00e932c4cd0b53928053811ebc1</data>
    </node>
    <node id="COMPUTATIONAL LINGUISTICS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" was published</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">3</data>
      <data key="d4">599</data>
      <data key="d5">9ef487dd0b574b108c60a56d6a2f146c</data>
    </node>
    <node id="LEWIS, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis, P. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">9</data>
      <data key="d4">600</data>
      <data key="d5">4067269e7f6943cdbc299ce02b7eadbd</data>
    </node>
    <node id="PEREZ, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Perez, E. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">9</data>
      <data key="d4">601</data>
      <data key="d5">094a736ba43c4da48c556437f47f88d1</data>
    </node>
    <node id="PIKTUS, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Piktus, A. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">9</data>
      <data key="d4">602</data>
      <data key="d5">563c2af32bb3476299e9b24a646097ab</data>
    </node>
    <node id="PETRONI, F.">
      <data key="d0">PERSON</data>
      <data key="d1">Petroni, F. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"Petroni, F. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d8">PERSON</data>
      <data key="d3">9</data>
      <data key="d4">603</data>
      <data key="d5">d59b49eb94ce442d89907e90c5d3a44e</data>
    </node>
    <node id="KARPUKHIN, V.">
      <data key="d0">PERSON</data>
      <data key="d1">Karpukhin, V. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">5</data>
      <data key="d4">604</data>
      <data key="d5">8ea7cef407df48098046551e303e1c64</data>
    </node>
    <node id="GOYAL, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Goyal, N. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">5</data>
      <data key="d4">605</data>
      <data key="d5">186e60d2176547bf84e5bf87bd16bb40</data>
    </node>
    <node id="K&#220;TTLER, H.">
      <data key="d0">PERSON</data>
      <data key="d1">K&#252;ttler, H. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">4</data>
      <data key="d4">606</data>
      <data key="d5">e65017091c8d4c7daa45b6c8414e0465</data>
    </node>
    <node id="LEWIS, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis, M. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">4</data>
      <data key="d4">607</data>
      <data key="d5">a0f326b9597b49dda6563e9208316117</data>
    </node>
    <node id="YIH, W.-T.">
      <data key="d0">PERSON</data>
      <data key="d1">Yih, W.-T. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">4</data>
      <data key="d4">608</data>
      <data key="d5">bff3db70f9af4f2c87a93df48ecbb6bc</data>
    </node>
    <node id="ROCKT&#196;SCHEL, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Rockt&#228;schel, T. is an author of the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">4</data>
      <data key="d4">609</data>
      <data key="d5">bf91f36307cb43e1ab1e967cb3ba8274</data>
    </node>
    <node id="LIU, N. F.">
      <data key="d0">PERSON</data>
      <data key="d1">Liu, N. F. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">610</data>
      <data key="d5">cd58a8740ba54d86a77db9bb9544ef0d</data>
    </node>
    <node id="LIN, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Lin, K. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">611</data>
      <data key="d5">e96d3475d43b42a781b297ae7e650afe</data>
    </node>
    <node id="HEWITT, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Hewitt, J. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">612</data>
      <data key="d5">1ce76a5547854d458878bd445f0ccbd6</data>
    </node>
    <node id="PARANJAPE, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Paranjape, A. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">613</data>
      <data key="d5">11e4325f59394ff1bc89892f79288702</data>
    </node>
    <node id="BEVILACQUA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Bevilacqua, M. is an author of the paper "Lost in the middle: How language models use long contexts"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">614</data>
      <data key="d5">71743537a07c440ea1710a269da8b538</data>
    </node>
    <node id="LIU, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Liu, Y. is an author of the paper "Hierarchical transformers for multi-document summarization"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">615</data>
      <data key="d5">1389192ce5464be6b3b5749bc9536709</data>
    </node>
    <node id="LAPATA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Lapata, M. is an author known for significant contributions to the field of Natural Language Processing and Information Retrieval. Notably, Lapata, M. has authored the paper "Hierarchical transformers for multi-document summarization," which explores advanced techniques in summarizing information from multiple documents using hierarchical transformer models. Additionally, Lapata, M. has contributed to the paper "Text summarization with latent queries," which delves into innovative methods for summarizing text by leveraging latent query representations. These works highlight Lapata, M.'s expertise and active research in the domain of text summarization, showcasing a focus on developing sophisticated models and methodologies to enhance the efficiency and accuracy of summarization tasks.</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">2</data>
      <data key="d4">616</data>
      <data key="d5">b349041c0be64c62b964ab1234e055e6</data>
    </node>
    <node id="LLAMAINDEX KNOWLEDGE GRAPH INDEX">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LlamaIndex Knowledge Graph Index is a technology developed by LlamaIndex</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">617</data>
      <data key="d5">969e1ea0b1e443a68e9a65dfef91d161</data>
    </node>
    <node id="MANAKUL, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Manakul, P. is an author of the paper "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">618</data>
      <data key="d5">8e09e7cfea7d405db8b22ae2f836ccb1</data>
    </node>
    <node id="LIUSIE, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Liusie, A. is an author of the paper "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">619</data>
      <data key="d5">490583524d394bf79289c5fe34f7dcf1</data>
    </node>
    <node id="GALES, M. J.">
      <data key="d0">PERSON</data>
      <data key="d1">Gales, M. J. is an author of the paper "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">620</data>
      <data key="d5">d7db38bb599c42cab7066f3fdd282282</data>
    </node>
    <node id="MAO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Mao, Y. is an author of the paper "Generation-augmented retrieval for open-domain question answering"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">621</data>
      <data key="d5">efd87a59d01e47c8adc02f63ef2c5c3e</data>
    </node>
    <node id="HE, P.">
      <data key="d0">PERSON</data>
      <data key="d1">He, P. is an author of the paper "Generation-augmented retrieval for open-domain question answering"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">622</data>
      <data key="d5">80e3ce3de41e4601823a333e22b7bb3f</data>
    </node>
    <node id="LIU, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Liu, X. is an author of the paper "Generation-augmented retrieval for open-domain question answering"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">623</data>
      <data key="d5">50eabc166e8944a49197e79c32f27597</data>
    </node>
    <node id="SHEN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Shen, Y. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy" and also contributed to the paper "Generation-augmented retrieval for open-domain question answering." These works indicate Shen, Y.'s involvement in advancing the field of Natural Language Processing and Information Retrieval, particularly focusing on the integration of retrieval and generation techniques to improve the performance of large language models and open-domain question answering systems.</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">0</data>
      <data key="d4">624</data>
      <data key="d5">5197a3fb02ef4677abd1900aa87e4efa</data>
    </node>
    <node id="GAO, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Gao, J. is an author of the paper "Generation-augmented retrieval for open-domain question answering"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">625</data>
      <data key="d5">887f444240bb474da23cdfb6abf7a998</data>
    </node>
    <node id="HAN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Han, J. is an author of the paper "Generation-augmented retrieval for open-domain question answering"</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d3">0</data>
      <data key="d4">626</data>
      <data key="d5">5d29053f2ce74442aa1855b327ef3bb7</data>
    </node>
    <node id="CHEN, W.">
      <data key="d0">PERSON</data>
      <data key="d1">Chen, W. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy" and also contributed to the paper "Generation-augmented retrieval for open-domain question answering." These works indicate Chen, W.'s involvement in advancing the field of Natural Language Processing and Information Retrieval, particularly focusing on the integration of retrieval and generation techniques to improve the performance of large language models and open-domain question answering systems.</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b,8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">2</data>
      <data key="d4">627</data>
      <data key="d5">7e40cd12839a4577a95e33d785147a31</data>
    </node>
    <node id="MARTIN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Martin, S. is an author of the paper "Openord: An open-source toolbox for large graph layout." This work focuses on providing a comprehensive, open-source solution for the layout of large graphs, which is a critical task in the visualization and analysis of complex networks. The toolbox aims to facilitate the understanding and interpretation of large-scale graph data, making it a valuable resource for researchers and practitioners in fields such as computational linguistics, information retrieval, and data science.</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">3</data>
      <data key="d4">628</data>
      <data key="d5">8fe58de8a04f4f8f807c77fb41829a3a</data>
    </node>
    <node id="BROWN, W. M.">
      <data key="d0">PERSON</data>
      <data key="d1">Brown, W. M. is an author of the paper "Openord: An open-source toolbox for large graph layout."</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">3</data>
      <data key="d4">629</data>
      <data key="d5">a9f50861273c4bb697d868a9d049d392</data>
    </node>
    <node id="KLAVANS, R.">
      <data key="d0">PERSON</data>
      <data key="d1">KLAVANS, R. is an author of the paper titled "Openord: An open-source toolbox for large graph layout." This work focuses on providing an open-source solution for the layout of large graphs, which is a significant contribution to the field of graph visualization and analysis.</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">3</data>
      <data key="d4">630</data>
      <data key="d5">be4820f29fd942b282049fa49697b4ed</data>
    </node>
    <node id="BOYACK, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Boyack, K. is an author of the paper titled "Openord: An open-source toolbox for large graph layout." This work focuses on the development and application of Openord, a comprehensive open-source toolbox designed for the layout of large graphs. The paper likely discusses the methodologies, algorithms, and practical implementations of the toolbox, contributing to the fields of graph theory and data visualization.</data>
      <data key="d2">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d3">3</data>
      <data key="d4">631</data>
      <data key="d5">6deaefe707f84b3dbda979dea0d095ac</data>
    </node>
    <node id="SPIE CONFERENCE ON VISUALIZATION AND DATA ANALYSIS (VDA)">
      <data key="d0">EVENT</data>
      <data key="d1">The conference where the paper "Openord: An open-source toolbox for large graph layout" was presented</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">EVENT</data>
      <data key="d3">0</data>
      <data key="d4">632</data>
      <data key="d5">d053ea9432a24fb192e8d6aa993b0caa</data>
    </node>
    <node id="GPT-4">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4 is a large language model used in Microsoft's study on scientific discovery</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">TECHNOLOGY</data>
      <data key="d6">38</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">633</data>
      <data key="d5">a3e683d294ed42a28d60d09a36cbeb54</data>
    </node>
    <node id="PROJECT NALLM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Project NaLLM is a project developed by Neo4J</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">TECHNOLOGY</data>
      <data key="d3">1</data>
      <data key="d4">634</data>
      <data key="d5">39887ca8567141d5b857b87a2bca4086</data>
    </node>
    <node id="NEWMAN, M. E.">
      <data key="d0">PERSON</data>
      <data key="d1">Newman, M. E. is the author of the paper "Modularity and community structure in networks"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">1</data>
      <data key="d4">635</data>
      <data key="d5">8df8563ab0394ee9a91b89dea7d59404</data>
    </node>
    <node id="PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Modularity and community structure in networks" was published</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PUBLICATION</data>
      <data key="d3">1</data>
      <data key="d4">636</data>
      <data key="d5">12398f70065143839d812fd42ac4b2e7</data>
    </node>
    <node id="RAM, O.">
      <data key="d0">PERSON</data>
      <data key="d1">Ram, O. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">6</data>
      <data key="d4">637</data>
      <data key="d5">74d43d20f251441baf8e3db64fedca43</data>
    </node>
    <node id="LEVINE, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Levine, Y. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">6</data>
      <data key="d4">638</data>
      <data key="d5">1b7a22f76f7741e8b140bdc3d8856d76</data>
    </node>
    <node id="DALMEDIGOS, I.">
      <data key="d0">PERSON</data>
      <data key="d1">Dalmedigos, I. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">6</data>
      <data key="d4">639</data>
      <data key="d5">b823ba1bfe944fa9887edd8faf8a5f17</data>
    </node>
    <node id="MUHLGAY, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Muhlgay, D. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">6</data>
      <data key="d4">640</data>
      <data key="d5">d0bfb473fdc64643954cdb4675e2f389</data>
    </node>
    <node id="SHASHUA, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Shashua, A. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">6</data>
      <data key="d4">641</data>
      <data key="d5">a4db1b2a9c3e4d2d838725f8166c36b4</data>
    </node>
    <node id="LEYTON-BROWN, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Leyton-Brown, K. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">6</data>
      <data key="d4">642</data>
      <data key="d5">8dae140578c841ae9373cbc607c4a6e6</data>
    </node>
    <node id="SHOHAM, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Shoham, Y. is an author of the paper "In-context retrieval-augmented language models"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">6</data>
      <data key="d4">643</data>
      <data key="d5">b215cc33cf40434f87f284ff8f3506a4</data>
    </node>
    <node id="TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "In-context retrieval-augmented language models" was published</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PUBLICATION</data>
      <data key="d3">0</data>
      <data key="d4">644</data>
      <data key="d5">c1ff9d8e1b8745d6860c34ce26122d79</data>
    </node>
    <node id="RANADE, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Ranade, P. is an author of the paper "Fabula: Intelligence report generation using retrieval-augmented narrative construction"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">1</data>
      <data key="d4">645</data>
      <data key="d5">9d1e6ca9ae8e4e068fb74631a633b20b</data>
    </node>
    <node id="JOSHI, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Joshi, A. is an author of the paper "Fabula: Intelligence report generation using retrieval-augmented narrative construction"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">1</data>
      <data key="d4">646</data>
      <data key="d5">1d7b0deca7674777bf76c163ac065845</data>
    </node>
    <node id="SARTHI, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Sarthi, P. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">5</data>
      <data key="d4">647</data>
      <data key="d5">03afe9988f864c9fa501bfbf043f74c0</data>
    </node>
    <node id="ABDULLAH, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Abdullah, S. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">5</data>
      <data key="d4">648</data>
      <data key="d5">4084f614af494fa8ab73095fb5b6b07b</data>
    </node>
    <node id="TULI, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Tuli, A. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">5</data>
      <data key="d4">649</data>
      <data key="d5">3ce25564af6e47f390a0b16b6f9433a1</data>
    </node>
    <node id="KHANNA, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Khanna, S. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">3</data>
      <data key="d4">650</data>
      <data key="d5">78213664d0eb45d1a9239ba4b85b10f7</data>
    </node>
    <node id="GOLDIE, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Goldie, A. is an author of the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">3</data>
      <data key="d4">651</data>
      <data key="d5">1226e4a4077b4b3a970db4d2509b590c</data>
    </node>
    <node id="MANNING, C. D.">
      <data key="d0">PERSON</data>
      <data key="d1">Manning, C. D. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering" and the paper "Raptor: Recursive abstractive processing for tree-organized retrieval". These contributions highlight Manning's involvement in advancing the fields of Natural Language Processing and Information Retrieval, particularly in the areas of multi-hop question answering and recursive abstractive processing.</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d3">4</data>
      <data key="d4">652</data>
      <data key="d5">b4c7de7a824a4a71b9f52193d2f1a10d</data>
    </node>
    <node id="SCOTT, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Scott, K. is associated with "Behind the Tech"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">0</data>
      <data key="d4">653</data>
      <data key="d5">b609f1939dae4c7383c7d199bb3c7dc3</data>
    </node>
    <node id="SHAO, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Shao, Z. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">0</data>
      <data key="d4">654</data>
      <data key="d5">aeee2f443dfb4e3ea80af6ae1d9197ce</data>
    </node>
    <node id="GONG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Gong, Y. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d8">PERSON</data>
      <data key="d3">0</data>
      <data key="d4">655</data>
      <data key="d5">8c46d37bc26e4d4dbd37d6ee26867bc6</data>
    </node>
    <node id="HUANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Huang, M. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d8">PERSON</data>
      <data key="d3">2</data>
      <data key="d4">656</data>
      <data key="d5">58a8fa7f29e347bdb9689b70b065a779</data>
    </node>
    <node id="DUAN, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Duan, N. is an author of the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d2">833e7d67dcd30790b26b71c9b5306f6b,8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d8">PERSON</data>
      <data key="d3">2</data>
      <data key="d4">657</data>
      <data key="d5">fae3fe31deb141ab93143ac411f1eaaa</data>
    </node>
    <node id="SU, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Su, D. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">5</data>
      <data key="d4">658</data>
      <data key="d5">a2cb46c226b94831853a5d28c5d94b0a</data>
    </node>
    <node id="XU, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Xu, Y. is an author of multiple academic papers in the field of Natural Language Processing and Information Retrieval. Notably, Xu, Y. contributed to the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management," which addresses the management of scholarly information related to COVID-19 through advanced question answering and summarization techniques. Additionally, Xu, Y. co-authored the paper "Text summarization with latent queries," which explores innovative methods for text summarization by leveraging latent queries. These contributions highlight Xu, Y.'s expertise and active involvement in developing sophisticated systems for information retrieval and summarization.</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">7</data>
      <data key="d4">659</data>
      <data key="d5">d3511ecd27cd4166bdb39e757e275300</data>
    </node>
    <node id="YU, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Yu, T. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">5</data>
      <data key="d4">660</data>
      <data key="d5">de3b561f5cce4c83bccb39180e362c97</data>
    </node>
    <node id="SIDDIQUE, F. B.">
      <data key="d0">PERSON</data>
      <data key="d1">Siddique, F. B. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">5</data>
      <data key="d4">661</data>
      <data key="d5">5bfefaa0fce04002851733337bed714c</data>
    </node>
    <node id="BAREZI, E. J.">
      <data key="d0">PERSON</data>
      <data key="d1">Barezi, E. J. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">5</data>
      <data key="d4">662</data>
      <data key="d5">b5fed5609f154df58c6a9f74e55fc0ba</data>
    </node>
    <node id="FUNG, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Fung, P. is an author of the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">5</data>
      <data key="d4">663</data>
      <data key="d5">91ae5251eaab4c08afe6cd4cbefcaa6b</data>
    </node>
    <node id="TANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Tang, Y. is an author of the paper "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">1</data>
      <data key="d4">664</data>
      <data key="d5">bbdd53a15e99452a9deff05d1de2d965</data>
    </node>
    <node id="YANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Yang, Y. is an author of the paper "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">1</data>
      <data key="d4">665</data>
      <data key="d5">532bf54d5a924ff48aee254970efb914</data>
    </node>
    <node id="TOUVRON, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Touvron, H. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">9</data>
      <data key="d4">666</data>
      <data key="d5">2489232bd2bb492babe00617e7290282</data>
    </node>
    <node id="MARTIN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Martin, L. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">7</data>
      <data key="d4">667</data>
      <data key="d5">d2ed972353af4d1db74702638bfdbb58</data>
    </node>
    <node id="STONE, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Stone, K. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">2</data>
      <data key="d4">668</data>
      <data key="d5">575befc8d64c47eb95af8b1096e02963</data>
    </node>
    <node id="ALBERT, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Albert, P. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">2</data>
      <data key="d4">669</data>
      <data key="d5">d6e6366617e04b0ba6732fd1d2d76429</data>
    </node>
    <node id="ALMAHAIRI, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Almahairi, A. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">2</data>
      <data key="d4">670</data>
      <data key="d5">b4c4354c8edb40db984942799fe0c8b1</data>
    </node>
    <node id="BABAEI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Babaei, Y. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">2</data>
      <data key="d4">671</data>
      <data key="d5">170507a64973429f818067b80506d428</data>
    </node>
    <node id="BASHLYKOV, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Bashlykov, N. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">2</data>
      <data key="d4">672</data>
      <data key="d5">fd9b298e6aea4685bbb2064b05fcda79</data>
    </node>
    <node id="BATRA, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Batra, S. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">2</data>
      <data key="d4">673</data>
      <data key="d5">eeecb159cc8a4c8989f8da0f3df09f2a</data>
    </node>
    <node id="BHARGAVA, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Bhargava, P. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">1</data>
      <data key="d4">674</data>
      <data key="d5">70f22b1d7336492dbade94b8edefe457</data>
    </node>
    <node id="BHOSALE, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Bhosale, S. is an author of the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">1</data>
      <data key="d4">675</data>
      <data key="d5">66e098dc431146e19fc4bc2ea37efbd9</data>
    </node>
    <node id="TRAAG, V. A.">
      <data key="d0">PERSON</data>
      <data key="d1">Traag, V. A. is an author of the paper "From Louvain to Leiden: guaranteeing well-connected communities"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">676</data>
      <data key="d5">932e213c57134098a07073febd51dcc2</data>
    </node>
    <node id="WALTMAN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Waltman, L. is an author of the paper "From Louvain to Leiden: guaranteeing well-connected communities"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">677</data>
      <data key="d5">9593428ad36746ae8af6d8ce639834ef</data>
    </node>
    <node id="VAN ECK, N. J.">
      <data key="d0">PERSON</data>
      <data key="d1">Van Eck, N. J. is an author of the paper "From Louvain to Leiden: guaranteeing well-connected communities"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">678</data>
      <data key="d5">1bcaeb58479d42a6963a073c09f3f397</data>
    </node>
    <node id="SCIENTIFIC REPORTS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">Scientific Reports is the journal where the paper "From Louvain to Leiden: guaranteeing well-connected communities" was published</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">679</data>
      <data key="d5">1ef0c1c59ce946668ccf1a6a4f5ab7cc</data>
    </node>
    <node id="TRAJANOSKA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Trajanoska, M. is an author of the paper "Enhancing knowledge graph construction using large language models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">680</data>
      <data key="d5">d734746e3d6146f780af91827e578dfd</data>
    </node>
    <node id="STOJANOV, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Stojanov, R. is an author of the paper "Enhancing knowledge graph construction using large language models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">681</data>
      <data key="d5">21ed913271614cbeb1b754cdbbef13af</data>
    </node>
    <node id="TRAJANOV, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Trajanov, D. is an author of the paper "Enhancing knowledge graph construction using large language models"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">682</data>
      <data key="d5">1505dfebbfb04652b0ba57de1a251d67</data>
    </node>
    <node id="TRIVEDI, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Trivedi, H. is an author of the paper "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">683</data>
      <data key="d5">907ec65076e5494a8631efffb81b3178</data>
    </node>
    <node id="BALASUBRAMANIAN, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Balasubramanian, N. is an author of the paper "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">684</data>
      <data key="d5">2dc7f6b230db452190a09643ca3d5ec0</data>
    </node>
    <node id="KHOT, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Khot, T. is an author of the paper "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">685</data>
      <data key="d5">c20ecfc93b3a4875ade5c92cfe4b94a1</data>
    </node>
    <node id="SABHARWAL, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Sabharwal, A. is an author of the paper "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">686</data>
      <data key="d5">4bc7dc91ede345dfb63d7d4f7ac3554f</data>
    </node>
    <node id="WANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d6">48</data>
      <data key="d7">1</data>
      <data key="d3">8</data>
      <data key="d4">687</data>
      <data key="d5">0b2b815c9f834aaaac0c341097def9ba</data>
    </node>
    <node id="LIANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Liang, Y. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d6">48</data>
      <data key="d7">1</data>
      <data key="d3">8</data>
      <data key="d4">688</data>
      <data key="d5">424ae71c56024094a02e6fd9bfcfbb04</data>
    </node>
    <node id="MENG, F.">
      <data key="d0">PERSON</data>
      <data key="d1">Meng, F. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d6">48</data>
      <data key="d7">1</data>
      <data key="d3">8</data>
      <data key="d4">689</data>
      <data key="d5">400d10f2ee1d49be9a66efa34dada0e6</data>
    </node>
    <node id="SUN, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Sun, Z. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d6">48</data>
      <data key="d7">1</data>
      <data key="d3">8</data>
      <data key="d4">690</data>
      <data key="d5">91deb9f152264e958d106d481ff2e1ee</data>
    </node>
    <node id="SHI, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Shi, H. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d6">48</data>
      <data key="d7">1</data>
      <data key="d3">8</data>
      <data key="d4">691</data>
      <data key="d5">586cf02da9494088aed9b3419725638f</data>
    </node>
    <node id="LI, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Li, Z. is an author who has contributed to the field of Natural Language Processing and Information Retrieval through their work on evaluating language models. Specifically, Li, Z. has co-authored the paper titled "Is ChatGPT a Good NLG Evaluator? A Preliminary Study," which explores the effectiveness of ChatGPT as a natural language generation evaluator. Additionally, Li, Z. has co-authored another paper, "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena," which examines the performance of large language models in evaluative roles using specific benchmarking tools. These contributions highlight Li, Z.'s active involvement in advancing the understanding and assessment of language models within the academic community.</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">48</data>
      <data key="d7">1</data>
      <data key="d3">20</data>
      <data key="d4">692</data>
      <data key="d5">229d85a2783e4a2991f17d2ab5750af7</data>
    </node>
    <node id="XU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Xu, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">48</data>
      <data key="d7">1</data>
      <data key="d3">9</data>
      <data key="d4">693</data>
      <data key="d5">b7f97d1909a3433abef8ca8e9334fafa</data>
    </node>
    <node id="QU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Qu, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">48</data>
      <data key="d7">1</data>
      <data key="d3">9</data>
      <data key="d4">694</data>
      <data key="d5">b7fdfffc38b94bf7872eabe9b022c8fd</data>
    </node>
    <node id="ZHOU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhou, J. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">48</data>
      <data key="d7">1</data>
      <data key="d3">9</data>
      <data key="d4">695</data>
      <data key="d5">6242e0c237a348908d0256ea790a0211</data>
    </node>
    <node id="WANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, S. is an author of the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" and also contributed to the paper "Is chatgpt a good nlg evaluator? a preliminary study." These works indicate Wang, S.'s involvement in cutting-edge research within the fields of federated search, retrieval augmented generation, and natural language generation evaluation, showcasing a focus on both the technical and evaluative aspects of Natural Language Processing and Information Retrieval.</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">47</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">696</data>
      <data key="d5">7cc9f26737e1442595e53253e98015ef</data>
    </node>
    <node id="KHRAMTSOVA">
      <data key="d0">PERSON</data>
      <data key="d1">Khramtsova is an author mentioned in the text</data>
      <data key="d2">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d3">0</data>
      <data key="d4">697</data>
      <data key="d5">1868fec1493643208dbdcad7bc97dfa0</data>
    </node>
    <node id="H.">
      <data key="d0">PERSON</data>
      <data key="d1">H. is an author of the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">48</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">698</data>
      <data key="d5">a87aa935dccf49cd98b40fb5afe7ad5c</data>
    </node>
    <node id="KHRAMTSOVA, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Khramtsova, E. is an author of the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">47</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">699</data>
      <data key="d5">36870a3393f6413e9bf647168eb6977a</data>
    </node>
    <node id="ZHUANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuang, S. is an author who has contributed to the field of Natural Language Processing and Information Retrieval through multiple academic papers. Notably, Zhuang, S. co-authored the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation," which explores the evaluation of federated search systems within the framework of retrieval-augmented generation. Additionally, Zhuang, S. co-authored another significant paper, "Judging llm-as-a-judge with mt-bench and chatbot arena," which delves into the assessment of large language models (LLMs) using the MT-Bench and Chatbot Arena frameworks. These contributions highlight Zhuang, S.'s active involvement in advancing research in federated search and the evaluation of LLMs.</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">15</data>
      <data key="d4">700</data>
      <data key="d5">4fe3ff52700c491f8cc650aadb4d7cb0</data>
    </node>
    <node id="ZUCCON, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Zuccon, G. is an author of the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">47</data>
      <data key="d7">1</data>
      <data key="d3">4</data>
      <data key="d4">701</data>
      <data key="d5">f1f6f6435a444e388d67e16e847afca6</data>
    </node>
    <node id="WANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, Y. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">43</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">702</data>
      <data key="d5">0af2ca1c090843ea92679fd14c1fbc9a</data>
    </node>
    <node id="LIPKA, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Lipka, N. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">43</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">703</data>
      <data key="d5">1b06d3e53ffd4771952fbef04d1e666c</data>
    </node>
    <node id="ROSSI, R. A.">
      <data key="d0">PERSON</data>
      <data key="d1">Rossi, R. A. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">43</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">704</data>
      <data key="d5">b8e966b34cba4b11b9995106767212ba</data>
    </node>
    <node id="SIU, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Siu, A. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">43</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">705</data>
      <data key="d5">f6de923de6474d2cab6a9c2f0d81fa59</data>
    </node>
    <node id="ZHANG, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, R. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">43</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">706</data>
      <data key="d5">6915637e8d124fdc8473111d501e3703</data>
    </node>
    <node id="DERR, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Derr, T. is an author of the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d6">43</data>
      <data key="d7">1</data>
      <data key="d3">6</data>
      <data key="d4">707</data>
      <data key="d5">2233f31929194eac89333ce8731a5584</data>
    </node>
    <node id="YANG, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Yang, Z. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">6</data>
      <data key="d4">708</data>
      <data key="d5">61f1dc4267314470ac820b6a46c61f7b</data>
    </node>
    <node id="QI, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Qi, P. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">1</data>
      <data key="d4">709</data>
      <data key="d5">f0c578614b224345974c3e4c110878af</data>
    </node>
    <node id="ZHANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, S. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">1</data>
      <data key="d4">710</data>
      <data key="d5">7ffb88ebc729492c897ccfb569d7f6d0</data>
    </node>
    <node id="BENGIO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Bengio, Y. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">1</data>
      <data key="d4">711</data>
      <data key="d5">60dce7d8bc1b4729a038178a400b9a59</data>
    </node>
    <node id="COHEN, W. W.">
      <data key="d0">PERSON</data>
      <data key="d1">Cohen, W. W. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">1</data>
      <data key="d4">712</data>
      <data key="d5">4cbb4e238c5b4656803fb9b4b6c3512e</data>
    </node>
    <node id="SALAKHUTDINOV, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Salakhutdinov, R. is an author of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">1</data>
      <data key="d4">713</data>
      <data key="d5">652873bcd6d5432187e5deafc4fc5211</data>
    </node>
    <node id="EMNLP">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The conference where the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering" was presented</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">0</data>
      <data key="d4">714</data>
      <data key="d5">78f9b30c08134ac5abb4f4e0bff0f7f2</data>
    </node>
    <node id="YAO, J.-G.">
      <data key="d0">PERSON</data>
      <data key="d1">Yao, J.-g. is an author of the paper "Recent advances in document summarization"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">0</data>
      <data key="d4">715</data>
      <data key="d5">f33e4e897b1e422bb516e8a2c941d9dc</data>
    </node>
    <node id="WAN, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Wan, X. is an author of the paper "Recent advances in document summarization"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">0</data>
      <data key="d4">716</data>
      <data key="d5">fac4e1553a9840e990bbfff46e64ff27</data>
    </node>
    <node id="XIAO, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Xiao, J. is an author of the paper "Recent advances in document summarization"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">0</data>
      <data key="d4">717</data>
      <data key="d5">029a55d327ee4fb3a8314b36d52bdf34</data>
    </node>
    <node id="KNOWLEDGE AND INFORMATION SYSTEMS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The journal where the paper "Recent advances in document summarization" was published</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d3">0</data>
      <data key="d4">718</data>
      <data key="d5">5a636c894c384532bff66212cf9d5824</data>
    </node>
    <node id="YAO, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Yao, L. is an author of the paper "Causal graph discovery with retrieval-augmented generation based large language models"Yao, L. is an author of the paper "Exploring large language models for knowledge graph completion"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">719</data>
      <data key="d5">a9c468ef78704e9aabfc0317a5b1b42d</data>
    </node>
    <node id="PENG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Peng, J. is an author of the paper "Exploring large language models for knowledge graph completion"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d3">0</data>
      <data key="d4">720</data>
      <data key="d5">5df80c25d33a4d148a14aa614343cc6b</data>
    </node>
    <node id="MAO, C.">
      <data key="d0">PERSON</data>
      <data key="d1">Mao, C. is an author of the paper "Exploring large language models for knowledge graph completion"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d3">0</data>
      <data key="d4">721</data>
      <data key="d5">6a87f06ed55a46f29b24f77e548a3f1d</data>
    </node>
    <node id="LUO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Luo, Y. is an author of the paper "Exploring large language models for knowledge graph completion"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d3">0</data>
      <data key="d4">722</data>
      <data key="d5">0daf88ac4ec94cbb868e27e956c6d7f1</data>
    </node>
    <node id="ZHANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, J. is an author of the paper "Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">723</data>
      <data key="d5">9ed120043e6247be9965e4904920991b</data>
    </node>
    <node id="ZHANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, Y. is an author of the paper "Causal graph discovery with retrieval-augmented generation based large language models"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">724</data>
      <data key="d5">94d81d7de9254ae4b3b16fcc69aa22ea</data>
    </node>
    <node id="GAN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Gan, Y. is an author of the paper "Causal graph discovery with retrieval-augmented generation based large language models"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">725</data>
      <data key="d5">60c9212246f84ae5b6ab254127a39262</data>
    </node>
    <node id="WANG, C.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, C. is an author of the paper "Causal graph discovery with retrieval-augmented generation based large language models"</data>
      <data key="d2">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">45</data>
      <data key="d7">1</data>
      <data key="d3">1</data>
      <data key="d4">726</data>
      <data key="d5">0f8d0c36a4274526a9eddedae5e63881</data>
    </node>
    <node id="ZHENG, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Zheng, L. is an author who has contributed to the field of Natural Language Processing and Information Retrieval through significant academic work. Notably, Zheng, L. has authored the paper "Exploring large language models for knowledge graph completion," which delves into the application of large language models to enhance the completeness and accuracy of knowledge graphs. Additionally, Zheng, L. has also authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena," which evaluates the performance of large language models in judgment tasks using specific benchmarking tools like MT-Bench and Chatbot Arena. These contributions highlight Zheng, L.'s active involvement in advancing the capabilities and evaluation methodologies of large language models within the NLP and IR domains.</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">12</data>
      <data key="d4">727</data>
      <data key="d5">6aedd377efbe4f07ae42e546996e7bfa</data>
    </node>
    <node id="CHIANG, W.-L.">
      <data key="d0">PERSON</data>
      <data key="d1">Chiang, W.-L. is an author who has contributed to the field of Natural Language Processing and Information Retrieval through significant academic work. Notably, Chiang, W.-L. has authored the paper "Exploring large language models for knowledge graph completion," which delves into the application of large language models in enhancing the completeness of knowledge graphs. Additionally, Chiang, W.-L. has also authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena," which evaluates the performance of large language models in judgment tasks using the MT-Bench and Chatbot Arena frameworks. These contributions highlight Chiang, W.-L.'s active involvement in advancing the understanding and capabilities of large language models within the NLP and IR communities.</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">12</data>
      <data key="d4">728</data>
      <data key="d5">1aa8484562784f378851c33843c89687</data>
    </node>
    <node id="SHENG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Sheng, Y. is an author known for contributing to the field of Natural Language Processing and Information Retrieval. Notably, Sheng, Y. has co-authored the paper "Exploring large language models for knowledge graph completion," which delves into the application of large language models to enhance the completeness and accuracy of knowledge graphs. Additionally, Sheng, Y. has contributed to the paper "Judging llm-as-a-judge with mt-bench and chatbot arena," which evaluates the performance of large language models in judgment tasks using specific benchmarking tools. These contributions highlight Sheng, Y.'s active involvement in advancing the capabilities and evaluation methodologies of large language models within the academic and technical community.</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">12</data>
      <data key="d4">729</data>
      <data key="d5">f1a65d05dd5d456b889217020475ef80</data>
    </node>
    <node id="WU, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Wu, Z. is an author who has contributed to the field of Natural Language Processing and Information Retrieval through significant academic work. Wu, Z. co-authored the paper titled "Exploring large language models for knowledge graph completion," which delves into the application of large language models to enhance the completeness and accuracy of knowledge graphs. Additionally, Wu, Z. is also credited with co-authoring the paper "Judging llm-as-a-judge with mt-bench and chatbot arena," which evaluates the performance of large language models in judgment tasks using the MT-Bench and Chatbot Arena frameworks. These contributions highlight Wu, Z.'s active involvement in advancing the capabilities and evaluation methodologies of large language models within the NLP and IR communities.</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">12</data>
      <data key="d4">730</data>
      <data key="d5">c077d92b48b6477db91e1a0460600f52</data>
    </node>
    <node id="ZHUANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuang, Y. is an author who has contributed to the field of Natural Language Processing and Information Retrieval through significant academic work. Notably, Zhuang, Y. has authored the paper "Exploring large language models for knowledge graph completion," which delves into the application of large language models to enhance the completeness of knowledge graphs. Additionally, Zhuang, Y. has also authored the paper "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena," which evaluates the performance of large language models in judgment tasks using specific benchmarking tools. These contributions highlight Zhuang, Y.'s active involvement in advancing the capabilities and evaluation methodologies of large language models within the domain.</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">12</data>
      <data key="d4">731</data>
      <data key="d5">5ca888df9b884e54accdd2ff29d125c1</data>
    </node>
    <node id="LIN, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Lin, Z. is an author of the paper "Exploring large language models for knowledge graph completion" and also contributed to the paper "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena." These works indicate Lin, Z.'s involvement in advancing the field of Natural Language Processing and Information Retrieval, particularly focusing on the application of large language models for tasks such as knowledge graph completion and the evaluation of language models in judgment tasks.</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">12</data>
      <data key="d4">732</data>
      <data key="d5">8290a6212d6c4430ae0056c7e8eccd5f</data>
    </node>
    <node id="LI, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Li, D. is an author who has contributed to the field of Natural Language Processing and Information Retrieval through significant research. Notably, Li, D. has co-authored the paper "Exploring large language models for knowledge graph completion," which delves into the application of large language models in enhancing the completeness of knowledge graphs. Additionally, Li, D. has also co-authored the paper "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena," which evaluates the performance of large language models in judgment tasks using specific benchmarking tools. These contributions highlight Li, D.'s active involvement in advancing the capabilities and evaluation methodologies of large language models within the academic community.</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">12</data>
      <data key="d4">733</data>
      <data key="d5">14f8ac195fdb4e06a0b9ebc6ef391180</data>
    </node>
    <node id="XING, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Xing, E. is an author of multiple influential papers in the field of Natural Language Processing and Information Retrieval. Notably, Xing, E. contributed to the paper "Exploring large language models for knowledge graph completion," which delves into the application of large language models to enhance the completeness and accuracy of knowledge graphs. Additionally, Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena," which evaluates the performance of large language models in judgment tasks using the MT-Bench and Chatbot Arena frameworks. These contributions highlight Xing, E.'s active involvement in advancing the capabilities and evaluation methodologies of large language models within the NLP community.</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d8">PERSON</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">12</data>
      <data key="d4">734</data>
      <data key="d5">667ee58a79194316ae2b82eadd3fc575</data>
    </node>
    <node id="CHATBOT ARENA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Chatbot Arena is a platform or tool used in the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d2">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d6">46</data>
      <data key="d7">1</data>
      <data key="d3">11</data>
      <data key="d4">735</data>
      <data key="d5">b0e3ee2324054c88adacdf80db13278f</data>
    </node>
    <edge source="DARREN EDGE" target="HA TRINH">
      <data key="d9">1.0</data>
      <data key="d10">Darren Edge and Ha Trinh co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">28b7457ca5dc4a38a488946a3f8e207e</data>
      <data key="d13">0</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DARREN EDGE" target="NEWMAN CHENG">
      <data key="d9">1.0</data>
      <data key="d10">Darren Edge and Newman Cheng co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">8029a14d15404e6db95ddf5e2bf9fc15</data>
      <data key="d13">1</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DARREN EDGE" target="JOSHUA BRADLEY">
      <data key="d9">1.0</data>
      <data key="d10">Darren Edge and Joshua Bradley co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">389314ca89d445888c8d4985864dd733</data>
      <data key="d13">2</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DARREN EDGE" target="ALEX CHAO">
      <data key="d9">1.0</data>
      <data key="d10">Darren Edge and Alex Chao co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">87fe1462b9064d5692641ab48e826301</data>
      <data key="d13">3</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DARREN EDGE" target="APURVA MODY">
      <data key="d9">1.0</data>
      <data key="d10">Darren Edge and Apurva Mody co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">a55175ac57014df696ca09d0def9604b</data>
      <data key="d13">4</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DARREN EDGE" target="STEVEN TRUITT">
      <data key="d9">1.0</data>
      <data key="d10">Darren Edge and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">1766e8858d7b45ed97f71cb5a39e96ea</data>
      <data key="d13">5</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DARREN EDGE" target="JONATHAN LARSON">
      <data key="d9">1.0</data>
      <data key="d10">Darren Edge and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">6191e014f3f64e46a0777063ed4ac19a</data>
      <data key="d13">6</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DARREN EDGE" target="MICROSOFT RESEARCH">
      <data key="d9">1.0</data>
      <data key="d10">Darren Edge is affiliated with Microsoft Research</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">21b0499cf14342269c46170c291d0535</data>
      <data key="d13">7</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HA TRINH" target="NEWMAN CHENG">
      <data key="d9">1.0</data>
      <data key="d10">Ha Trinh and Newman Cheng co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">c1ef05b38b3f4d59888150fc0dd26826</data>
      <data key="d13">8</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HA TRINH" target="JOSHUA BRADLEY">
      <data key="d9">1.0</data>
      <data key="d10">Ha Trinh and Joshua Bradley co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">74cb9b3510e84498b9aee0d904316e8b</data>
      <data key="d13">9</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HA TRINH" target="ALEX CHAO">
      <data key="d9">1.0</data>
      <data key="d10">Ha Trinh and Alex Chao co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">043d764b2e1b4d1294651ff938df5391</data>
      <data key="d13">10</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HA TRINH" target="APURVA MODY">
      <data key="d9">1.0</data>
      <data key="d10">Ha Trinh and Apurva Mody co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">31f2170fef004f3281c533a4a60dc3f3</data>
      <data key="d13">11</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HA TRINH" target="STEVEN TRUITT">
      <data key="d9">1.0</data>
      <data key="d10">Ha Trinh and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">57f186c5c2754483ba66750e98222f95</data>
      <data key="d13">12</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HA TRINH" target="JONATHAN LARSON">
      <data key="d9">1.0</data>
      <data key="d10">Ha Trinh and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">4b3fc569d91f4a7aa6501ad4fcf67b7a</data>
      <data key="d13">13</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HA TRINH" target="MICROSOFT RESEARCH">
      <data key="d9">1.0</data>
      <data key="d10">Ha Trinh is affiliated with Microsoft Research</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">cbc1667556f84a5eadf867a823e6986c</data>
      <data key="d13">14</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWMAN CHENG" target="JOSHUA BRADLEY">
      <data key="d9">1.0</data>
      <data key="d10">Newman Cheng and Joshua Bradley co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">a876d1ab79864396bc47a039225fd5c7</data>
      <data key="d13">15</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWMAN CHENG" target="ALEX CHAO">
      <data key="d9">1.0</data>
      <data key="d10">Newman Cheng and Alex Chao co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">c09f67d4f25448c99f7c0552c30b7706</data>
      <data key="d13">16</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWMAN CHENG" target="APURVA MODY">
      <data key="d9">1.0</data>
      <data key="d10">Newman Cheng and Apurva Mody co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">c0866306dc8c4da2a8a81c0c3a78b657</data>
      <data key="d13">17</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWMAN CHENG" target="STEVEN TRUITT">
      <data key="d9">1.0</data>
      <data key="d10">Newman Cheng and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">3884c37eb13a4c9097ee2c5be4eeefaf</data>
      <data key="d13">18</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWMAN CHENG" target="JONATHAN LARSON">
      <data key="d9">1.0</data>
      <data key="d10">Newman Cheng and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">90764eb2cab74cffb1c7d72d28b965cc</data>
      <data key="d13">19</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWMAN CHENG" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d9">1.0</data>
      <data key="d10">Newman Cheng is affiliated with Microsoft Strategic Missions and Technologies</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">01abe16e67c241a887aa62abe22d155c</data>
      <data key="d13">20</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="ALEX CHAO">
      <data key="d9">1.0</data>
      <data key="d10">Joshua Bradley and Alex Chao co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">37049be0a2c240c6a06acf9339237b8b</data>
      <data key="d13">21</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="APURVA MODY">
      <data key="d9">1.0</data>
      <data key="d10">Joshua Bradley and Apurva Mody co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">e785c52881704d95bf4ec03d2720f8ae</data>
      <data key="d13">22</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="STEVEN TRUITT">
      <data key="d9">1.0</data>
      <data key="d10">Joshua Bradley and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">654689c65613476b9905d7afb3809cd2</data>
      <data key="d13">23</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="JONATHAN LARSON">
      <data key="d9">1.0</data>
      <data key="d10">Joshua Bradley and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">15dfb45a6ffa4d34ad72cfe4b3c5cc0d</data>
      <data key="d13">24</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d9">1.0</data>
      <data key="d10">Joshua Bradley is affiliated with Microsoft Strategic Missions and Technologies</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">427c3b7458f148d8bace1b768e2b5b7c</data>
      <data key="d13">25</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALEX CHAO" target="APURVA MODY">
      <data key="d9">1.0</data>
      <data key="d10">Alex Chao and Apurva Mody co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">95d506750fd94e72bbd9cf2d3fe18e28</data>
      <data key="d13">26</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALEX CHAO" target="STEVEN TRUITT">
      <data key="d9">1.0</data>
      <data key="d10">Alex Chao and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">bf0138ccbcc740089a55fd0c24897360</data>
      <data key="d13">27</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALEX CHAO" target="JONATHAN LARSON">
      <data key="d9">1.0</data>
      <data key="d10">Alex Chao and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">83cd5df42643494396b00d6cb6376def</data>
      <data key="d13">28</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALEX CHAO" target="MICROSOFT OFFICE OF THE CTO">
      <data key="d9">1.0</data>
      <data key="d10">Alex Chao is affiliated with Microsoft Office of the CTO</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">909d28e443fd4e0bac189373125c8309</data>
      <data key="d13">29</data>
      <data key="d14">1</data>
    </edge>
    <edge source="APURVA MODY" target="STEVEN TRUITT">
      <data key="d9">1.0</data>
      <data key="d10">Apurva Mody and Steven Truitt co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">efbc2439e5034801af83ac1a0b440535</data>
      <data key="d13">30</data>
      <data key="d14">1</data>
    </edge>
    <edge source="APURVA MODY" target="JONATHAN LARSON">
      <data key="d9">1.0</data>
      <data key="d10">Apurva Mody and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">b9a2ef791a064f038cac2059ebea1138</data>
      <data key="d13">31</data>
      <data key="d14">1</data>
    </edge>
    <edge source="APURVA MODY" target="MICROSOFT OFFICE OF THE CTO">
      <data key="d9">1.0</data>
      <data key="d10">Apurva Mody is affiliated with Microsoft Office of the CTO</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">1ce2b24bc93442148dc2240d3c6223b1</data>
      <data key="d13">32</data>
      <data key="d14">1</data>
    </edge>
    <edge source="STEVEN TRUITT" target="JONATHAN LARSON">
      <data key="d9">1.0</data>
      <data key="d10">Steven Truitt and Jonathan Larson co-authored the paper "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">804c1e94e7974332a817931363ddb643</data>
      <data key="d13">33</data>
      <data key="d14">1</data>
    </edge>
    <edge source="STEVEN TRUITT" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d9">1.0</data>
      <data key="d10">Steven Truitt is affiliated with Microsoft Strategic Missions and Technologies</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">32dc0b572ad84c75a64a2007788eb981</data>
      <data key="d13">34</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JONATHAN LARSON" target="MICROSOFT RESEARCH">
      <data key="d9">1.0</data>
      <data key="d10">Jonathan Larson is affiliated with Microsoft Research</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">f5c11a5ac94e40068bca8be178a6bcd6</data>
      <data key="d13">35</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="LLM">
      <data key="d9">4.0</data>
      <data key="d10">RAG (Retrieval-Augmented Generation) and LLM (Large Language Models) are closely intertwined in the domain of Natural Language Processing and Information Retrieval. RAG is employed to enhance the capabilities of LLMs by enabling them to retrieve pertinent information from external knowledge sources. This symbiotic relationship allows LLMs to generate and assess text more effectively. Specifically, RAG leverages the power of LLMs to access and utilize relevant data, thereby augmenting the overall performance and accuracy of text generation tasks.</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">ea28ff7f127e4677a913952595dce2f5</data>
      <data key="d13">36</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="GRAPH RAG">
      <data key="d9">7.0</data>
      <data key="d10">Graph RAG is a specific implementation of RAG that combines the strengths of RAG with graph-based text indexing. This method leverages the natural modularity of graphs to partition data, facilitating global summarization. As a specialized approach within the RAG framework, Graph RAG enhances the capabilities of RAG by integrating graph structures to improve the efficiency and effectiveness of text data processing and summarization.</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,92e93fc6449756c0a60200636b297f65,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">192a6d23595045f38b0d46a3d8e52fd6</data>
      <data key="d13">37</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="QUERY-FOCUSED SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Query-Focused Summarization is a task that RAG fails to address effectively</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">ef67c9fc60284b50aa15ac655b06a155</data>
      <data key="d13">38</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="EXTERNAL KNOWLEDGE SOURCE">
      <data key="d9">1.0</data>
      <data key="d10">RAG retrieves relevant information from an external knowledge source</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">cc8201cce1024b5192056fe8e98fda22</data>
      <data key="d13">39</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="NAIVE RAG">
      <data key="d9">1.0</data>
      <data key="d10">Naive RAG is a specific implementation of RAG</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">97e097f9022540b88ab7c13d2805c25f</data>
      <data key="d13">40</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="RAM ET AL., 2023">
      <data key="d9">1.0</data>
      <data key="d10">Ram et al., 2023 discusses RAG approaches</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">829a6299a5fa4e7b8ff4020020a0be05</data>
      <data key="d13">41</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="NA&#207;VE RAG">
      <data key="d9">2.0</data>
      <data key="d10">Na&#239;ve RAG is a basic form of RAG</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">dde2742459c24fb4a91172aa5c1a7620</data>
      <data key="d13">42</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="MODULAR RAG">
      <data key="d9">2.0</data>
      <data key="d10">Modular RAG is an advanced form of RAG</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">323979a67d79498fa271acdf8cd1a0c2</data>
      <data key="d13">43</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="LLMS">
      <data key="d9">2.0</data>
      <data key="d10">LLMs are used in various RAG tasks such as knowledge graph creation and completion</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">c7e8b188b45841a0a1bcb22f3445ea6e</data>
      <data key="d13">44</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="TRAJANOSKA ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Trajanoska et al. discusses using LLMs for knowledge graph creation, which is a direction in RAG</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">5a4ad077106a4a3f951f43d2e01499b0</data>
      <data key="d13">45</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="YAO ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Yao et al. discusses using LLMs for knowledge graph completion, which is a direction in RAG</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">a7ec8df038d7461689d28f1bdea84d9b</data>
      <data key="d13">46</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="BAN ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Ban et al. discusses the extraction of causal graphs, which is a direction in RAG</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">8ddefa32e2ed4eaf8f76d17a676f74f3</data>
      <data key="d13">47</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="ZHANG ET AL., 2024">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Zhang et al. discusses the extraction of causal graphs, which is a direction in RAG</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">95ec30ce8dbe4ca28714e3e3735da8f3</data>
      <data key="d13">48</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="GAO ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Gao et al. discusses advanced RAG where the index is a knowledge graph</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">259e7f5e2ec04418937513413b6d51d1</data>
      <data key="d13">49</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="KAPING">
      <data key="d9">2.0</data>
      <data key="d10">KAPING is a method where the index is a knowledge graph, which is a direction in RAG</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">2289f06dd3804a3c84371dda0bab091e</data>
      <data key="d13">50</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="G-RETRIEVER">
      <data key="d9">2.0</data>
      <data key="d10">G-Retriever is a method where subsets of the graph structure are the objects of enquiry, which is a direction in RAG</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">34ff8ef897804691842071f9ff78708e</data>
      <data key="d13">51</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="GRAPH-TOOLFORMER">
      <data key="d9">2.0</data>
      <data key="d10">Graph-ToolFormer is a method where derived graph metrics are the objects of enquiry, which is a direction in RAG</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">a7401447d994439993da7cc57f127649</data>
      <data key="d13">52</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="SURGE">
      <data key="d9">2.0</data>
      <data key="d10">SURGE is a method where narrative outputs are strongly grounded in the facts of retrieved subgraphs, which is a direction in RAG</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">754b0f2616064b18abb90f409ef0539a</data>
      <data key="d13">53</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="FABULA">
      <data key="d9">2.0</data>
      <data key="d10">FABULA is a method where retrieved event-plot subgraphs are serialized using narrative templates, which is a direction in RAG</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">acd35bb6b3cb4979a3f3fb68a86b3b05</data>
      <data key="d13">54</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="WANG ET AL., 2023B">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Wang et al. discusses a system that supports both creation and traversal of text-relationship graphs for multi-hop question answering, which is a direction in RAG</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">9e1e7f67ba044c7fbf64723af1ade58e</data>
      <data key="d13">55</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="SENSEMAKING QUESTIONS">
      <data key="d9">2.0</data>
      <data key="d10">Sensemaking questions are used to evaluate the performance of RAG systems</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">57e16ff087a84b8ebd70de1e7e534225</data>
      <data key="d13">56</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="TOKENS">
      <data key="d9">2.0</data>
      <data key="d10">The evaluation of RAG systems focuses on corpora in the region of 1 million tokens</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">bbf4007dc9c0486b8ea76d616045467a</data>
      <data key="d13">57</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="TRADE-OFFS">
      <data key="d9">2.0</data>
      <data key="d10">Trade-offs are considerations involved in building a graph index for RAG systems</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">9535f4d754044e128cd3951a9d2e3702</data>
      <data key="d13">58</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="GRAPH INDEX">
      <data key="d9">2.0</data>
      <data key="d10">A graph index is a data structure used in RAG systems to organize and retrieve information</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">e1ed13e29ee946d4aaafac50aaa3b68f</data>
      <data key="d13">59</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="PERFORMANCE">
      <data key="d9">2.0</data>
      <data key="d10">Performance of RAG systems varies across different ranges of question types, data types, and dataset sizes</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">eb961d47a30c4870a1134b4a4672a8b2</data>
      <data key="d13">60</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="DATA TYPES">
      <data key="d9">2.0</data>
      <data key="d10">Different data types are used in RAG systems</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">5b019e8652264136b95306bac70a2e25</data>
      <data key="d13">61</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="DATASET SIZES">
      <data key="d9">2.0</data>
      <data key="d10">Dataset sizes affect the performance of RAG systems</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">325fc9e2b37043b7af9f6ad338b09469</data>
      <data key="d13">62</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="EVALUATION">
      <data key="d9">2.0</data>
      <data key="d10">Evaluation is the process of assessing the performance of RAG systems</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">6bb11aa08b414232b5b45f10f5766f62</data>
      <data key="d13">63</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="CORPORA">
      <data key="d9">2.0</data>
      <data key="d10">Corpora are collections of texts used in the evaluation of RAG systems</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">179737fd23c943babdfae01ac5c6bfc3</data>
      <data key="d13">64</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="QUESTION TYPES">
      <data key="d9">2.0</data>
      <data key="d10">Different question types are used to evaluate RAG systems</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">65a31e4da283411fb7c971f63d606723</data>
      <data key="d13">65</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAG" target="TARGET METRICS">
      <data key="d9">2.0</data>
      <data key="d10">Target metrics are specific measures used to evaluate the performance of RAG systems</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">de31810d43174a52aa2f31b72f4542f5</data>
      <data key="d13">66</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="GRAPH RAG">
      <data key="d9">4.0</data>
      <data key="d10">Graph RAG utilizes Large Language Models (LLMs) to construct a graph-based text index, enabling the generation of summaries and the answering of queries. In this approach, LLMs play a crucial role in analyzing and generating text based on the information retrieved through the graph structure. Additionally, LLMs leverage the Graph RAG framework to provide comprehensive overviews of public figures in the entertainment industry. This integration of LLMs within Graph RAG enhances the system's ability to process and synthesize complex text data, making it a powerful tool for information retrieval and natural language processing tasks.</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,6f33a085ff3304e5994f7fbb86c881a4,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">a6ae1d99330443fcacb06ace15a0d937</data>
      <data key="d13">67</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="TEXT CHUNKS">
      <data key="d9">1.0</data>
      <data key="d10">Text chunks are processed using LLM to extract elements of a graph index</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">5174cdabb6024de0975762d3a80b059f</data>
      <data key="d13">68</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="GRAPH INDEX">
      <data key="d9">1.0</data>
      <data key="d10">LLM is used to extract elements of a graph index from text chunks</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">e379fba901174b529250169e62d98c09</data>
      <data key="d13">69</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="FEW-SHOT EXAMPLES">
      <data key="d9">2.0</data>
      <data key="d10">LLM (Large Language Model) and Few-Shot Examples are closely related in the context of Natural Language Processing and Information Retrieval. Few-shot examples are provided to the LLM for in-context learning, which helps tailor the extraction prompt. This technique is particularly useful for improving the performance of the LLM in specialized domains. By leveraging a small number of examples, the LLM can better understand and adapt to specific tasks, thereby enhancing its overall effectiveness in extracting and processing information within those specialized areas.</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">81ee8bb20bbb4d37bc0db642f1c75b8e</data>
      <data key="d13">70</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="NAMED ENTITIES">
      <data key="d9">1.0</data>
      <data key="d10">LLM extracts named entities from text chunks</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">93b4aa6ce6e44123a861d4c3b3d509a2</data>
      <data key="d13">71</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="KURATOV ET AL., 2024">
      <data key="d9">1.0</data>
      <data key="d10">Kuratov et al. (2024) discuss the recall degradation of longer LLM context windows</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">ee8414e314f547eeb369849cdb51bac2</data>
      <data key="d13">72</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="LIU ET AL., 2023">
      <data key="d9">1.0</data>
      <data key="d10">Liu et al. (2023) discuss the recall degradation of longer LLM context windows</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">9f77aa8888bd4f94abba8a77c4b0565c</data>
      <data key="d13">73</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="LLM PROMPTS">
      <data key="d9">1.0</data>
      <data key="d10">LLM prompts are instructions given to the LLM for extracting elements from text chunks</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">dcf33412678340319e7ec8f7be267ef9</data>
      <data key="d13">74</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="RECALL DEGRADATION">
      <data key="d9">1.0</data>
      <data key="d10">Recall degradation occurs with longer LLM context windows</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">4aa1e0fa00c048939a5d006bfd305fb4</data>
      <data key="d13">75</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="EXTRACTION PROCESS">
      <data key="d9">1.0</data>
      <data key="d10">The extraction process involves using LLM to identify and extract elements from text chunks</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">03053ab4a9054384a5f5e88d28841621</data>
      <data key="d13">76</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="DEFAULT PROMPT">
      <data key="d9">1.0</data>
      <data key="d10">Default prompt is the standard set of instructions given to the LLM</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">9fd0f20997d541bca46c4ec9843a5d0f</data>
      <data key="d13">77</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="SECONDARY EXTRACTION PROMPT">
      <data key="d9">1.0</data>
      <data key="d10">Secondary extraction prompt is an additional set of instructions given to the LLM</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">27168beee1ff456696c330c9c3b3259f</data>
      <data key="d13">78</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="COVARIATE PROMPT">
      <data key="d9">1.0</data>
      <data key="d10">The LLM uses covariate prompts to extract additional attributes associated with detected entities</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">e1c20e06aeac436788a9c6e918bcb844</data>
      <data key="d13">79</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="GLEANINGS">
      <data key="d9">1.0</data>
      <data key="d10">The LLM uses multiple rounds of gleanings to ensure no entities are missed</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">344417f626ef4da4be4539ef4037bf3f</data>
      <data key="d13">80</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="LOGIT BIAS">
      <data key="d9">1.0</data>
      <data key="d10">Logit bias is used to force a yes/no decision from the LLM during entity extraction</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">8b1fff87c350475fb1d411a26c3c5b0c</data>
      <data key="d13">81</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="ELEMENT INSTANCES">
      <data key="d9">1.0</data>
      <data key="d10">The LLM extracts element instances from source texts</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">898a9458adfb4c13a1eafacf6a1068f6</data>
      <data key="d13">82</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="COMMUNITIES OF ENTITIES">
      <data key="d9">1.0</data>
      <data key="d10">The LLM detects and summarizes communities of entities</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">5448f05781de44ea96e3dea40b285842</data>
      <data key="d13">83</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="CHUNKS">
      <data key="d9">1.0</data>
      <data key="d10">LLM generates intermediate answers and scores for each chunk</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">76b1e69904b84d09ba05c4b7efc48f32</data>
      <data key="d13">84</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="HELPFULNESS SCORE">
      <data key="d9">1.0</data>
      <data key="d10">LLM generates a helpfulness score for each answer</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">3f5590a604894d268603b4b27c3348b5</data>
      <data key="d13">85</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="PODCAST TRANSCRIPTS">
      <data key="d9">2.0</data>
      <data key="d10">LLM is used to generate questions for evaluating the Podcast Transcripts dataset</data>
      <data key="d11">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">68f998c9c8c34bb7a994de5a998bb9a0</data>
      <data key="d13">86</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="NEWS ARTICLES">
      <data key="d9">2.0</data>
      <data key="d10">LLM is used to generate questions for evaluating the News Articles dataset</data>
      <data key="d11">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">aafc13d02ade40adae13d3bee241817a</data>
      <data key="d13">87</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="NAIVE RAG">
      <data key="d9">1.0</data>
      <data key="d10">LLM uses Naive RAG to list public figures mentioned in entertainment articles</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">81a4818e5cf84ea085abf09de385c86e</data>
      <data key="d13">88</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="ASSESSMENT">
      <data key="d9">1.0</data>
      <data key="d10">LLM-generated responses are evaluated using assessment metrics</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">b69851bf63e34ced83827b0021628543</data>
      <data key="d13">89</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="QUESTION">
      <data key="d9">1.0</data>
      <data key="d10">LLM-generated responses are evaluated using specific questions</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">b83a4e11bfa64559954327714b73293f</data>
      <data key="d13">90</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="AD-HOC LLM USE">
      <data key="d9">1.0</data>
      <data key="d10">Ad-hoc LLM use involves the use of large language models to analyze reasoning and provide specific examples, quotes, and citations</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">de23b974cc90497eb4363e26d931a57c</data>
      <data key="d13">91</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="KNOWLEDGE GRAPH CREATION">
      <data key="d9">2.0</data>
      <data key="d10">LLMs are used for knowledge graph creation</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">a9de65176e234a9f9073b8df9d675e90</data>
      <data key="d13">92</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="KNOWLEDGE GRAPH COMPLETION">
      <data key="d9">2.0</data>
      <data key="d10">LLMs are used for knowledge graph completion</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">09a1bd11eb9347a9b466edad1a562cc5</data>
      <data key="d13">93</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="CAUSAL GRAPHS">
      <data key="d9">2.0</data>
      <data key="d10">LLMs are used for the extraction of causal graphs</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">11d74eab1dcb4fcba7c45def5f0ee22d</data>
      <data key="d13">94</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="TRAJANOSKA ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">LLMs are used for knowledge graph creation as per Trajanoska et al., 2023</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">4f6a6fd018a948f4bd0e630266b8bf61</data>
      <data key="d13">95</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="YAO ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">LLMs are used for knowledge graph completion as per Yao et al., 2023</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">17dbfbecfaf0436bb11ed8f867c0caa1</data>
      <data key="d13">96</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM" target="BAN ET AL.">
      <data key="d9">2.0</data>
      <data key="d10">LLMs are used for the extraction of causal graphs as per Ban et al.</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">2b1ec99684574c2ab26bb050d5b57a4d</data>
      <data key="d13">97</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="QFS">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG is proposed as a method to combine the strengths of RAG and QFS</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">1ccce5d1892a4b6995bbaec22882d34d</data>
      <data key="d13">98</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY SUMMARIES">
      <data key="d9">7.0</data>
      <data key="d10">Graph RAG is an approach that utilizes community summaries in various capacities to enhance its functionality. Specifically, community summaries are generated within the Graph RAG framework and are employed to generate partial responses. These summaries are also used to compare against source texts, serving as a form of self-memory for the system. By leveraging community summaries, Graph RAG aims to improve the comprehensiveness and diversity of answers. Additionally, Graph RAG incorporates summaries of root-level communities within an entity-based graph index, further enriching its analytical capabilities.</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,36db32c37e1987e2c5863898ad882190,6f33a085ff3304e5994f7fbb86c881a4,e4d9b12cf2b4c691c74019eefff4fb39,e8d83e6e7a7c0f57b218cef24976b745,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">51cd93f89fbe4bcf883cdb2ca6774cd6</data>
      <data key="d13">99</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL SENSEMAKING QUESTIONS">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG is designed to handle global sensemaking questions over large datasets</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">5f353b18fadb438f95ba0ea8feae137c</data>
      <data key="d13">100</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="PYTHON">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG is implemented in Python.</data>
      <data key="d11">086021a89900a39bcb62036981737bfa,e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">947d70dd14b34cf398a1ab6dbdc51161</data>
      <data key="d13">101</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="HTTPS://AKA.MS/GRAPHRAG">
      <data key="d9">1.0</data>
      <data key="d10">The open-source implementation of Graph RAG will be available at this URL</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">90f5597a558a4652bded9001a4ec2e56</data>
      <data key="d13">102</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="ENTITY KNOWLEDGE GRAPH">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG uses an entity knowledge graph to index text</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">9532cf83e9324ea0a46e5ac89bac407d</data>
      <data key="d13">103</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="COMPREHENSIVENESS">
      <data key="d9">3.0</data>
      <data key="d10">Graph RAG is an approach that is evaluated for its comprehensiveness, a target quality used to assess its effectiveness. The method aims to improve the comprehensiveness of generated answers, ensuring that the information provided is thorough and complete. This evaluation metric is crucial in determining the success of Graph RAG in producing detailed and accurate responses.</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,e8c8f911135faf3ff35f24107eb3f99c,e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">8919fa72a9e74d1daff801e8f4c15b2b</data>
      <data key="d13">104</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="DIVERSITY">
      <data key="d9">3.0</data>
      <data key="d10">Graph RAG is an approach in the domain of Natural Language Processing and Information Retrieval that focuses on improving the diversity of generated answers. Diversity, in this context, is a target quality used to evaluate the performance of the Graph RAG approach. By enhancing the diversity of responses, Graph RAG aims to provide a broader range of answers, thereby improving the overall effectiveness and robustness of the system.</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,6f33a085ff3304e5994f7fbb86c881a4,e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">bef38889bb86413895d7dd25b4c3137c</data>
      <data key="d13">105</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="KNOWLEDGE GRAPH">
      <data key="d9">3.0</data>
      <data key="d10">Graph RAG uses a knowledge graph for global summarization</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">f770bc07cecf4aba8fe2d2c33fdc5542</data>
      <data key="d13">106</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d9">1.0</data>
      <data key="d10">Community detection algorithms are used in the Graph RAG approach to partition graphs</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">13cd49512d5642989c2c72bb5e674807</data>
      <data key="d13">107</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="PODCAST TRANSCRIPTS">
      <data key="d9">1.0</data>
      <data key="d10">Podcast transcripts are used as a dataset to evaluate the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">e5c5c87a281b43868c344ff60f44c100</data>
      <data key="d13">108</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWS ARTICLES">
      <data key="d9">1.0</data>
      <data key="d10">News articles are used as a dataset to evaluate the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">a562ffbe986247b7943990e7151f4d69</data>
      <data key="d13">109</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="EMPOWERMENT">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG is evaluated using the target quality of Empowerment. Empowerment is specifically utilized to assess Graph RAG's capability in aiding users to achieve an informed understanding. This evaluation metric underscores the importance of user comprehension and the effectiveness of the Graph RAG approach in facilitating informed decision-making processes.</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">7ea0bc1467e84184842de2d5e5bdd78e</data>
      <data key="d13">110</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="NAIVE RAG">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG is compared to naive RAG in the evaluation. In this comparison, Graph RAG outperformed naive RAG on comprehensiveness and diversity.</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">056f23eb710f471393ae5dc417d83fd9</data>
      <data key="d13">111</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL MAP-REDUCE SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG is compared to global map-reduce summarization in the evaluation</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">e1ae27016d63447a8dfa021370cba0fa</data>
      <data key="d13">112</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="QUERY-FOCUSED SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Query-focused summarization is a method used in the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">f8c10f61a8f344cea7bdafa2d8af14b8</data>
      <data key="d13">113</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="ACTIVITY-CENTERED SENSEMAKING QUESTIONS">
      <data key="d9">1.0</data>
      <data key="d10">Activity-centered sensemaking questions are used to evaluate the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">aa7d003f25624e19bc88d3951d4dc943</data>
      <data key="d13">114</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL LEVEL">
      <data key="d9">1.0</data>
      <data key="d10">Hierarchical level of community summaries is varied to evaluate the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">1c97184ce5ea4049be417a3fd125357b</data>
      <data key="d13">115</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="TOKEN COSTS">
      <data key="d9">2.0</data>
      <data key="d10">The "Graph RAG" approach is evaluated in terms of its performance by considering "Token Costs." Token costs are measured to assess the efficiency of the Graph RAG method, indicating that the computational expense associated with processing tokens is a critical factor in determining the overall effectiveness of this approach.</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">13a044c404394c34af1e9b07c48aa985</data>
      <data key="d13">116</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="DATA FLOW">
      <data key="d9">1.0</data>
      <data key="d10">Data flow describes the high-level process of the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">69ef1ac7b1f44372979149e82ecbc860</data>
      <data key="d13">117</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="DESIGN PARAMETERS">
      <data key="d9">3.0</data>
      <data key="d10">Design parameters are key settings in the Graph RAG approach and significantly influence the Graph RAG approach and pipeline.</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">6e26ce67bacc4fa089296843463f69ad</data>
      <data key="d13">118</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG uses global summarization to summarize information from a large dataset</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">ae0d3104647f4e6ab3ec2cf8e60be5ca</data>
      <data key="d13">119</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="QUERY">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG aims to answer specific queries</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">49e24b5f2c1d40d7857afe327db4f554</data>
      <data key="d13">120</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="CORPUS">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG uses a corpus for analysis and summarization</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">587f39a32e93412395d9c22ad0ac2f94</data>
      <data key="d13">121</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="ACTIVITY-CENTERED SENSEMAKING">
      <data key="d9">1.0</data>
      <data key="d10">Activity-centered sensemaking is used to evaluate the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">8d9ded5fc9cf4c4faba8c6c8cd50e2f4</data>
      <data key="d13">122</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="REAL-WORLD DATASETS">
      <data key="d9">1.0</data>
      <data key="d10">Real-world datasets are used to evaluate the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">595a841aa6034c93bd3dc55681e17710</data>
      <data key="d13">123</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES">
      <data key="d9">1.0</data>
      <data key="d10">Hierarchical level of community summaries is varied to evaluate the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">d0e58b78e8e84a0c8796e707b1f95f65</data>
      <data key="d13">124</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="SOURCE TEXT SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG is compared to source text summarization in the evaluation</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">215fcc6a3b5e452da123aa7f9ef0cbc9</data>
      <data key="d13">125</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d9">1.0</data>
      <data key="d10">Low-level community summaries are generated in the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">0d0fc5d4ecb548079b28979186f19bf6</data>
      <data key="d13">126</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="INTERMEDIATE-LEVEL COMMUNITY SUMMARIES">
      <data key="d9">1.0</data>
      <data key="d10">Intermediate-level community summaries are generated in the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">e7d3fe0f87ff47f5a4c8d9572d27245a</data>
      <data key="d13">127</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="HIGH-LEVEL COMMUNITY SUMMARIES">
      <data key="d9">1.0</data>
      <data key="d10">High-level community summaries are generated in the Graph RAG approach</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">6f7165b558ae427ca14b2b16d1e8e204</data>
      <data key="d13">128</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="PIPELINE">
      <data key="d9">1.0</data>
      <data key="d10">The Graph RAG approach involves a specific pipeline for processing and summarizing text</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">2ec093d2a76d45f88ec508e45ba8c6a3</data>
      <data key="d13">129</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="TECHNIQUES">
      <data key="d9">1.0</data>
      <data key="d10">Techniques are specific methods used in the Graph RAG approach</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">16d5a528d6374612b87a5656e8d95193</data>
      <data key="d13">130</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="IMPLEMENTATION DETAILS">
      <data key="d9">1.0</data>
      <data key="d10">Implementation details are specific configurations used in the Graph RAG approach</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">40293e74dbc643e8ab6546dff759ac7c</data>
      <data key="d13">131</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="RAG SYSTEMS">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG is a specific implementation of RAG systems</data>
      <data key="d11">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">1834b753dc7f4a8b98c2317a551b56ee</data>
      <data key="d13">132</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="C0">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG is a system that utilizes root-level community summaries, denoted as C0, to answer user queries. C0 represents these root-level community summaries within the Graph RAG analysis, serving as a foundational element in the system's ability to map out relationships and understand the structural dynamics within specialized communities.</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">d9b127eab2f64e338d7adcd186786a45</data>
      <data key="d13">133</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="C1">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG uses high-level community summaries (C1) to answer user queries</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">a18f7c9f58ca49d6acf18e1ca69d3033</data>
      <data key="d13">134</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="C2">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG uses intermediate-level community summaries (C2) to answer user queries</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">f3c3dd44cf50495c81e362174991242e</data>
      <data key="d13">135</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="C3">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG utilizes low-level community summaries, represented by C3, to answer user queries. C3 plays a crucial role in the Graph RAG analysis by providing detailed summaries of community structures, which are essential for effectively addressing user inquiries.</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">86c2b3749a3c4342bbb3a8c70c3a76a0</data>
      <data key="d13">136</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="CONDITIONS">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG is a key entity in the analysis, serving both as a condition being compared and as a tool for comparing multiple conditions. This dual role highlights its significance in the study, where it functions not only as a subject of comparison but also as a methodological framework for evaluating other conditions. The analysis likely involves a detailed examination of various conditions, with Graph RAG playing a central role in facilitating these comparisons.</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c,973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">571f65acb3134490932feeb91b01cca3</data>
      <data key="d13">137</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="USER QUERIES">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG uses different levels of graph communities to answer user queries</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">d3faf86c153f440eaa410305b3dc6617</data>
      <data key="d13">138</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="LLM EVALUATOR">
      <data key="d9">1.0</data>
      <data key="d10">The Graph RAG mechanism uses an LLM evaluator for head-to-head comparison</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">f85786004b0540349192d2ca05b15264</data>
      <data key="d13">139</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="MULTI-STAGE">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG is a multi-stage mechanism</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">cf56bfc9fa7d47fe9cb553dd09f2b412</data>
      <data key="d13">140</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="TAYLOR SWIFT">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG mentions Taylor Swift as a prominent public figure</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">a077dbcd38b644f6929cf05272c2fb9d</data>
      <data key="d13">141</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="TRAVIS KELCE">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG mentions Travis Kelce as a prominent public figure</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">d2659a32b9de406eb750a35d078c9774</data>
      <data key="d13">142</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="BRITNEY SPEARS">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG mentions Britney Spears as a prominent public figure</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">0b26876307ad4cc48839b61a21a1d03a</data>
      <data key="d13">143</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="JUSTIN TIMBERLAKE">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG mentions Justin Timberlake as a prominent public figure</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">c68e6c694a554256846d12178ddb12dc</data>
      <data key="d13">144</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="DECISION">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG is determined to be the winner based on the decision metric</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">ff25ce2e8ace4bdcb765c863b483852b</data>
      <data key="d13">145</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="ANSWER 1">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 was generated using the Graph RAG method, which provides a comprehensive and structured overview of public figures across various sectors of the entertainment industry.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">757e402cb7ee4601ac1bc8c4fafb5207</data>
      <data key="d13">146</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG is used to generate answers for questions in the News article dataset</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">62e8f5f04cd04384b246291cef3a9e4d</data>
      <data key="d13">147</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="SOURCE TEXTS">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG is compared with source texts for answer comprehensiveness and diversity</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">c04abbd5e59b4c64b023908f6db05498</data>
      <data key="d13">148</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="TS">
      <data key="d9">1.0</data>
      <data key="d10">TS represents source text summarization in the Graph RAG analysis</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">6bb9bed2e39c4e31a81f12479af3d16c</data>
      <data key="d13">149</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="ROOT-LEVEL SUMMARIES">
      <data key="d9">1.0</data>
      <data key="d10">Root-level summaries are used in the Graph RAG analysis</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">26c926c6016d4639b05427f01ba629f5</data>
      <data key="d13">150</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="ANSWER COMPREHENSIVENESS">
      <data key="d9">1.0</data>
      <data key="d10">Answer comprehensiveness is used to evaluate the performance of Graph RAG</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">8f6872eeb81b432b91405d327636113c</data>
      <data key="d13">151</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="WIN RATE">
      <data key="d9">1.0</data>
      <data key="d10">Win rate is used to measure the success rate of Graph RAG in providing comprehensive and diverse answers</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">ac80a99fda2b488285d29596dd4d1471</data>
      <data key="d13">152</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="ELEMENT EXTRACTION PROMPTS">
      <data key="d9">1.0</data>
      <data key="d10">Element extraction prompts are used in Graph RAG to retain specific details in the index</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">67d6a3481e4b419292247cef5cd5b737</data>
      <data key="d13">153</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="SELF-MEMORY (SELFMEM)">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates the concept of self-memory</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">904cd052ec194654bb72f4027e43daa3</data>
      <data key="d13">154</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates the concept of iterative retrieval-generation</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">7e88fd2e835147fbb71866612735e8d4</data>
      <data key="d13">155</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="FEDERATED RETRIEVAL-GENERATION (FEB4RAG)">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates the concept of federated retrieval-generation</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">029d1a8c3b184aa5bb21228f40cd12fd</data>
      <data key="d13">156</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="MULTI-DOCUMENT SUMMARIZATION">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts used in multi-document summarization</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">a1ebc53a0bc74a0eb6dbdd18cf3c88cd</data>
      <data key="d13">157</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="MULTI-HOP QUESTION ANSWERING">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts used in multi-hop question answering</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">a51d063ad4c744049edb359eb88407b7</data>
      <data key="d13">158</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL INDEX">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG uses a hierarchical index</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">b67268f90338474e8e53b9a6715b6833</data>
      <data key="d13">159</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="TREE OF CLARIFICATIONS">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates the concept of a tree of clarifications</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">acb53370e72b4430a752d9ea18c17352</data>
      <data key="d13">160</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="GRAPH INDEX">
      <data key="d9">3.0</data>
      <data key="d10">Graph RAG utilizes a self-generated graph index. This self-generated graph index is a crucial component of Graph RAG, enabling it to efficiently manage and retrieve information within its graph-based framework. The use of a self-generated graph index suggests that Graph RAG has an inherent capability to construct and maintain its indexing structure, which likely enhances its performance and adaptability in handling complex data relationships.</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39,f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">a8738c7de11543df930169741381c252</data>
      <data key="d13">161</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="GAO ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Gao et al., 2023</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">3f8b5b2727924ba0b62e6286063b6861</data>
      <data key="d13">162</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="CHENG ET AL., 2024">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Cheng et al., 2024</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">bb5010633113442eaf814852995cfa22</data>
      <data key="d13">163</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="MAO ET AL., 2020">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Mao et al., 2020</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">9eb8c635538243a690366f8bc1de34e0</data>
      <data key="d13">164</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="SHAO ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Shao et al., 2023</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">050c5b770d51409cb40f9c52f02d1329</data>
      <data key="d13">165</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="WANG ET AL., 2024">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Wang et al., 2024</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">9e12f514d26d48dfab65807568a6cff9</data>
      <data key="d13">166</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="SU ET AL., 2020">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Su et al., 2020</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">97f98b1623104f48aa93196a1f7dede2</data>
      <data key="d13">167</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="FENG ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Feng et al., 2023</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">87718ef799a34104b6ef9c2df6621cbc</data>
      <data key="d13">168</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="TRIVEDI ET AL., 2022">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Trivedi et al., 2022</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">f64e87431d674f298c533f6878458b95</data>
      <data key="d13">169</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="KHATTAB ET AL., 2022">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Khattab et al., 2022</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">e6d44d0db58f42799a02eacbd6b14543</data>
      <data key="d13">170</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="SARTHI ET AL., 2024">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Sarthi et al., 2024</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">64961fbc3a1641378be10bcb3b0955e1</data>
      <data key="d13">171</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="KIM ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG incorporates concepts from Kim et al., 2023</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">59bcc2ec512c4c1ba44272446b419230</data>
      <data key="d13">172</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY ANSWERS">
      <data key="d9">2.0</data>
      <data key="d10">Graph RAG generates community answers in parallel</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">8f39ae56f8b54b1b94faf04dbd0b9d11</data>
      <data key="d13">173</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="GRAPH-FREE APPROACH">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG is compared to a graph-free approach for global summarization</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">f3018b934ac241639a33c925c24bc507</data>
      <data key="d13">174</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="MAP-REDUCE SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG is compared to map-reduce summarization</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">ddedfd5179e64700adced4803c75cdba</data>
      <data key="d13">175</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="RICH TEXT ANNOTATIONS">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG uses rich text annotations</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">07d501edd4614e1d9d08d01b702688a3</data>
      <data key="d13">176</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG uses a hierarchical community structure</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">f745075dedcf444daa9370cf32403d31</data>
      <data key="d13">177</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="EMBEDDING-BASED MATCHING">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG can operate using embedding-based matching</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">1ef48284d238405f94190125092a3e28</data>
      <data key="d13">178</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="HYBRID RAG SCHEMES">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG can be part of hybrid RAG schemes</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">8806b817446447e3b50f5bc85ff497e1</data>
      <data key="d13">179</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="MAP-REDUCE SUMMARIZATION MECHANISMS">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG can employ map-reduce summarization mechanisms</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">7303ee20690449db8c168df3fe008bc5</data>
      <data key="d13">180</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY HIERARCHY">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG can extend operations across the community hierarchy</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">2f1c535a14b14758bf1cacca81c74878</data>
      <data key="d13">181</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="ALONSO">
      <data key="d9">1.0</data>
      <data key="d10">Alonso contributed to the work on Graph RAG</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">3b78cc7ce8224afcab3e4bbe550cde10</data>
      <data key="d13">182</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="LOCAL GRAPH RAG APPROACHES">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG includes local graph RAG approaches</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">29ec9dd9f5864170a7e75c46c11c0090</data>
      <data key="d13">183</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="ENTITY-BASED GRAPH INDEX">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG uses an entity-based graph index</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">7893ee15f0e941cbacad8cc1feaacbaf</data>
      <data key="d13">184</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG" target="NEBULAGRAPH">
      <data key="d9">2.0</data>
      <data key="d10">NebulaGraph launched the industry-first graph RAG: Retrieval-augmented generation with LLM based on knowledge graphs</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">f53397f743ca4d7397c0a694fe787da0</data>
      <data key="d13">185</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="PARTIAL RESPONSE">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are used to generate partial responses</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">0041db9da3694ad397f37c76f8477770</data>
      <data key="d13">186</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GRAPH COMMUNITIES">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are created from graph communities</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">a7c2a64e06374091adce74adb36801ab</data>
      <data key="d13">187</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="COMMUNITY ANSWERS">
      <data key="d9">2.0</data>
      <data key="d10">Community answers are created from community summaries. These answers are generated by synthesizing information from the summaries provided by the community, ensuring that the responses are comprehensive and reflective of the collective knowledge and insights within the community.</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">107568a67cac472c89dfce4bbe11157c</data>
      <data key="d13">188</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="DOMAIN-TAILORED SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Domain-tailored summarization is used to create community summaries</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">3d78aa9d14714ac189e4020f78b15d24</data>
      <data key="d13">189</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="COMMUNITY DESCRIPTIONS">
      <data key="d9">1.0</data>
      <data key="d10">Community descriptions are generated from community summaries</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">ce0366abadef410d9b65e2bfbbf0b0f9</data>
      <data key="d13">190</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="PARTIAL ANSWERS">
      <data key="d9">1.0</data>
      <data key="d10">Partial answers are generated from community summaries</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">f4370806deb84d0eb7e85e742e7d4bbf</data>
      <data key="d13">191</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are created for each level in the hierarchical community structure</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">c92392d168c2443e8ed7b04992d0c92b</data>
      <data key="d13">192</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are useful for understanding the global structure and semantics of the dataset</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">b5800c807edd4087a2420007272d15d0</data>
      <data key="d13">193</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL QUERIES">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are used to answer global queries</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">aa247540e90d4a7abc5bca6fafaaffa1</data>
      <data key="d13">194</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="ROOT COMMUNITIES">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are generated from root communities</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">34537afa1e954e08bdb52ead3a49e2f3</data>
      <data key="d13">195</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SUB-COMMUNITIES">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are generated from sub-communities</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">ae043af0299f4b32a98cf187efd2a5db</data>
      <data key="d13">196</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="LLM CONTEXT WINDOW">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are added to the LLM context window until the token limit is reached</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">6016863be3414d5a92397f2d45fdfd78</data>
      <data key="d13">197</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL ANSWER">
      <data key="d9">1.0</data>
      <data key="d10">Global answers are generated from community summaries</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">a9b900821b8444d69f432da08a77539f</data>
      <data key="d13">198</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SUMMARY DETAIL">
      <data key="d9">1.0</data>
      <data key="d10">The level of summary detail affects the content of community summaries</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">1fee51d6f4614127a3e1cc80d018506e</data>
      <data key="d13">199</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SCOPE">
      <data key="d9">1.0</data>
      <data key="d10">The scope of information affects the content of community summaries</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">00dc2c0748214e52bc799ca3e25204e9</data>
      <data key="d13">200</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SENSEMAKING">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are used for sensemaking</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">42d1a9e749ad40daa34c7b0b695f8751</data>
      <data key="d13">201</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="CHUNK">
      <data key="d9">2.0</data>
      <data key="d10">Community summaries are divided into chunks of pre-specified token size</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">20de9a1af6ab4e88acf003cb7be0217c</data>
      <data key="d13">202</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SUMMARY DETAIL AND SCOPE">
      <data key="d9">1.0</data>
      <data key="d10">Summary detail and scope affect the content of community summaries</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">f3229f10a5a54cb1b91a26ffa6ee77a3</data>
      <data key="d13">203</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="CHUNKS">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are divided into chunks</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">5154b4a4f3ac43729703c69fccb54633</data>
      <data key="d13">204</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="USER QUERY">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are prepared to answer user queries</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">2091070e709e45f5ae56d40a9da45520</data>
      <data key="d13">205</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="INTERMEDIATE ANSWERS">
      <data key="d9">1.0</data>
      <data key="d10">Intermediate answers are generated from community summaries</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">09045ef5c4314dde9a631a206274563f</data>
      <data key="d13">206</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GRAPH">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are part of the graph community hierarchy</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">1b9baa98ede84164883e8cdcbc7000c1</data>
      <data key="d13">207</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="PODCAST DATASET">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are derived from the Podcast dataset for analysis</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">e4f3fcc475a74756925b730caffcb70d</data>
      <data key="d13">208</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="NEWS DATASET">
      <data key="d9">1.0</data>
      <data key="d10">Community summaries are derived from the News dataset for analysis</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">7f3d5282303f4fc3a009e04f7de0ad84</data>
      <data key="d13">209</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="ROOT-LEVEL COMMUNITIES">
      <data key="d9">1.0</data>
      <data key="d10">Summaries of root-level communities are used in Graph RAG</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">1219a14eaf5f49ab84c9287ebf58db7a</data>
      <data key="d13">210</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GLOBAL SENSEMAKING QUESTIONS" target="1 MILLION TOKEN RANGE">
      <data key="d9">1.0</data>
      <data key="d10">Global sensemaking questions are evaluated over datasets in the 1 million token range</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">efaa386bd5e9454b87e1851cd8b28ac3</data>
      <data key="d13">211</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GLOBAL SENSEMAKING QUESTIONS" target="TEXT CORPUS">
      <data key="d9">1.0</data>
      <data key="d10">Global sensemaking questions are directed at an entire text corpus</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">073241be9b6a4952ad01dd14b94fb89c</data>
      <data key="d13">212</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HTTPS://AKA.MS/GRAPHRAG" target="PYTHON-BASED IMPLEMENTATION">
      <data key="d9">1.0</data>
      <data key="d10">The Python-based implementation of Graph RAG approaches will be available at this URL</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">f7ac6bc4a9ca4250ad29a3adb5d08657</data>
      <data key="d13">213</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION" target="GLOBAL ANSWER">
      <data key="d9">1.0</data>
      <data key="d10">Query-focused summarization is used to produce the global answer</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">ac2ee54e75a2492c8db372dadfccd083</data>
      <data key="d13">214</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION" target="MAP-REDUCE">
      <data key="d9">1.0</data>
      <data key="d10">Map-reduce is used for query-focused summarization of an entire corpus</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">ee895ad0b8cd40c29465e8527748d847</data>
      <data key="d13">215</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION" target="GLOBAL QUERIES">
      <data key="d9">1.0</data>
      <data key="d10">Query-focused summarization is used for answering global queries</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">fe38c996c2d64bc899eabd6389034075</data>
      <data key="d13">216</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTITY KNOWLEDGE GRAPH" target="SOURCE DOCUMENTS">
      <data key="d9">1.0</data>
      <data key="d10">An entity knowledge graph is derived from source documents</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">c0e28ae832c94405b8ddd4d2ad978be5</data>
      <data key="d13">217</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="TEXT CHUNKS">
      <data key="d9">2.0</data>
      <data key="d10">In the domain of Natural Language Processing and Information Retrieval, "SOURCE DOCUMENTS" and "TEXT CHUNKS" are closely related entities. Text chunks are extracted from source documents, specifically for processing in the Graph RAG (Retrieval-Augmented Generation) approach. This method involves breaking down the source documents into smaller, manageable pieces, or text chunks, which can then be effectively utilized in various computational processes, enhancing the efficiency and accuracy of information retrieval and generation tasks.</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">7a4573a19ef94e25b4480cb4d953ae7a</data>
      <data key="d13">218</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="INTERMEDIATE-LEVEL COMMUNITY SUMMARIES">
      <data key="d9">1.0</data>
      <data key="d10">Intermediate-level community summaries are derived from source documents</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">05f6639803524537b67a7f2b0c66ad23</data>
      <data key="d13">219</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d9">1.0</data>
      <data key="d10">Low-level community summaries are derived from source documents</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">21bfd14cbc1f4cbc8ac59f7fd8c75b31</data>
      <data key="d13">220</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="DOCUMENT CORPUS">
      <data key="d9">1.0</data>
      <data key="d10">Document corpus consists of source documents being processed</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">c19cf2d7b067421990ab9f3acec9e736</data>
      <data key="d13">221</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PARTIAL RESPONSE" target="FINAL RESPONSE">
      <data key="d9">1.0</data>
      <data key="d10">Partial responses are summarized to generate a final response</data>
      <data key="d11">e8d83e6e7a7c0f57b218cef24976b745</data>
      <data key="d12">3e1981b9301c4d339a9228ae7a089a04</data>
      <data key="d13">222</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="LLM EVALUATOR">
      <data key="d9">1.0</data>
      <data key="d10">The LLM evaluator assesses answers based on the comprehensiveness metric</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">0948efa844814529b4c023aacbc23d64</data>
      <data key="d13">223</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="NAIVE RAG">
      <data key="d9">1.0</data>
      <data key="d10">Naive RAG is evaluated for comprehensiveness</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">fcdc0cc5ff93453eb0b94b9254760999</data>
      <data key="d13">224</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="DECISION">
      <data key="d9">1.0</data>
      <data key="d10">Comprehensiveness is a metric used to determine the decision</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">0ec4ad4398a8457ab3d71bd2561858dc</data>
      <data key="d13">225</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">Comprehensiveness is used to evaluate the thoroughness of the generated answers for news articles</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">3c06988555334a389eab093f98679e85</data>
      <data key="d13">226</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="PODCAST TRANSCRIPTS">
      <data key="d9">1.0</data>
      <data key="d10">Comprehensiveness is used to evaluate the thoroughness of the generated answers for podcast transcripts</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">81ceb8db419b4697ad24e9d7f46422ff</data>
      <data key="d13">227</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="CONTEXT WINDOW SIZE">
      <data key="d9">1.0</data>
      <data key="d10">The smallest context window size (8k) was universally better for comprehensiveness</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">fd05d8198d0947b39b8fa1b16f3ecf5f</data>
      <data key="d13">228</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="FINAL EVALUATION">
      <data key="d9">1.0</data>
      <data key="d10">The final evaluation prioritized comprehensiveness in answers</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">d984f08ad62f47ab9aabb9aeec1b245e</data>
      <data key="d13">229</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="GLOBAL APPROACHES">
      <data key="d9">1.0</data>
      <data key="d10">Global approaches achieved higher comprehensiveness win rates</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">43603c7868164ac38c659bce7a77f45a</data>
      <data key="d13">230</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DIVERSITY" target="LLM EVALUATOR">
      <data key="d9">1.0</data>
      <data key="d10">The LLM evaluator assesses answers based on the diversity metric</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">54a20cc6062d4b7193d023b6ff20461f</data>
      <data key="d13">231</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DIVERSITY" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">Diversity is used to evaluate the variety in the generated answers for news articles</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">6bb190069a704ccca3d8e1648a384185</data>
      <data key="d13">232</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DIVERSITY" target="PODCAST TRANSCRIPTS">
      <data key="d9">1.0</data>
      <data key="d10">Diversity is used to evaluate the variety in the generated answers for podcast transcripts</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">47d2036509bf408095ab440bd052ac24</data>
      <data key="d13">233</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DIVERSITY" target="CONTEXT WINDOW SIZE">
      <data key="d9">1.0</data>
      <data key="d10">The smallest context window size (8k) performed comparably with larger context sizes on diversity</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">c20e6b1418a140389c31c7b71a6eba0c</data>
      <data key="d13">234</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DIVERSITY" target="FINAL EVALUATION">
      <data key="d9">1.0</data>
      <data key="d10">The final evaluation prioritized diversity in answers</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">ad96e5294247465a9c7d5ea8161dc305</data>
      <data key="d13">235</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DIVERSITY" target="GLOBAL APPROACHES">
      <data key="d9">1.0</data>
      <data key="d10">Global approaches achieved higher diversity win rates</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">25c968bf5a4f48369fded6c260f71540</data>
      <data key="d13">236</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HUMAN ENDEAVORS" target="SENSEMAKING">
      <data key="d9">1.0</data>
      <data key="d10">Human endeavors rely on sensemaking to understand and reason about large collections of documents</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">269b441634a144219f539202309bc9fb</data>
      <data key="d13">237</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HUMAN ENDEAVORS" target="DOCUMENT COLLECTIONS">
      <data key="d9">1.0</data>
      <data key="d10">Human endeavors rely on analyzing document collections for sensemaking</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">d0baf2392635468db7f5657f89eb2024</data>
      <data key="d13">238</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="SENSEMAKING">
      <data key="d9">1.0</data>
      <data key="d10">LLMs are used to automate sensemaking in complex domains</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">4f29bcf5377d4c9f94ff3f8ca2f8d941</data>
      <data key="d13">239</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="MICROSOFT">
      <data key="d9">1.0</data>
      <data key="d10">Microsoft uses LLMs for automating sensemaking in scientific discovery</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">e7072a582d9b4c1ea8b171ee940d4d6e</data>
      <data key="d13">240</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="RANADE">
      <data key="d9">1.0</data>
      <data key="d10">Ranade uses LLMs for automating sensemaking in intelligence analysis</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">cb6fcf84e3d04ef59b01f97ac94823a1</data>
      <data key="d13">241</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="JOSHI">
      <data key="d9">1.0</data>
      <data key="d10">Joshi uses LLMs for automating sensemaking in intelligence analysis</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">97a21db5f5954e2c8868b298a3f0090e</data>
      <data key="d13">242</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="LLM PROMPTS">
      <data key="d9">1.0</data>
      <data key="d10">LLM prompts are used to tailor the responses of large language models</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">c8f3e6cadcf34c8fafe8987e4a9b66f8</data>
      <data key="d13">243</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="RANADE AND JOSHI">
      <data key="d9">1.0</data>
      <data key="d10">Ranade and Joshi discussed the use of LLMs in intelligence analysis</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">26c9c44e5059429bb8abc3308bc6c814</data>
      <data key="d13">244</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="GPT">
      <data key="d9">2.0</data>
      <data key="d10">GPT is a type of large language model</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">7cea9903153f43b895c0b23d25bc90a3</data>
      <data key="d13">245</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="LLAMA">
      <data key="d9">2.0</data>
      <data key="d10">Llama is a type of large language model</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">b54436ccc23745c88d24edcc3fdd8ed1</data>
      <data key="d13">246</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="GEMINI">
      <data key="d9">2.0</data>
      <data key="d10">Gemini is a type of large language model</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">977c895bb98d4136a76e8749533154b6</data>
      <data key="d13">247</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="KURATOV ET AL., 2024">
      <data key="d9">2.0</data>
      <data key="d10">Kuratov et al., 2024, discussed the limitations of LLM context windows</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">8d75cfea884248aba1f372de5e1b82a9</data>
      <data key="d13">248</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="LIU ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">Liu et al., 2023, discussed the limitations of LLM context windows</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">90f4ee186bcd4996ad8002888569fffc</data>
      <data key="d13">249</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SCIENTIFIC DISCOVERY" target="SENSEMAKING">
      <data key="d9">1.0</data>
      <data key="d10">Sensemaking is applied in the domain of scientific discovery</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">4bb78401581b4240b0967309e96af00b</data>
      <data key="d13">250</data>
      <data key="d14">1</data>
    </edge>
    <edge source="INTELLIGENCE ANALYSIS" target="SENSEMAKING">
      <data key="d9">1.0</data>
      <data key="d10">Sensemaking is applied in the domain of intelligence analysis</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">a18dd9ea4143411cb32e261db056cf0c</data>
      <data key="d13">251</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SENSEMAKING" target="KLEIN">
      <data key="d9">1.0</data>
      <data key="d10">Klein defined and discussed the importance of sensemaking</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">cd8d9795f540413390927ea2a9e77c26</data>
      <data key="d13">252</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SENSEMAKING" target="KLEIN ET AL.">
      <data key="d9">1.0</data>
      <data key="d10">Klein et al. defined and discussed the importance of sensemaking</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">2917f3b478b04ffcacd4b47602f4d0f5</data>
      <data key="d13">253</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TEXT CHUNKS" target="ELEMENT INSTANCES">
      <data key="d9">2.0</data>
      <data key="d10">Element instances are extracted from text chunks</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">3984bd063b384901862e68506c77cc68</data>
      <data key="d13">254</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TEXT CHUNKS" target="ENTITY REFERENCES">
      <data key="d9">1.0</data>
      <data key="d10">Entity references are extracted from text chunks during processing</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">4137a2c7dd884bc2a8469b7fa937346c</data>
      <data key="d13">255</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TEXT CHUNKS" target="CHUNK SIZE">
      <data key="d9">1.0</data>
      <data key="d10">Chunk size refers to the length of text chunks used in the extraction process</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">60b6bf585ccc477d830d4b69b8c7b62a</data>
      <data key="d13">256</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="ELEMENT SUMMARIES">
      <data key="d9">2.0</data>
      <data key="d10">Element instances are converted into element summaries by the LLM (Large Language Model). Element summaries are created from element instances, indicating a transformation process facilitated by the LLM. This process involves the LLM taking detailed element instances and generating concise element summaries, which encapsulate the essential information from the instances.</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">4330f73cb78a4bb39a384eb29112201b</data>
      <data key="d13">257</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="COVARIATES">
      <data key="d9">1.0</data>
      <data key="d10">Covariates are additional attributes associated with extracted element instances</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">45c4ed77967746e485ec9e52c0dcc0d2</data>
      <data key="d13">258</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="DOMAIN-TAILORED SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Domain-tailored summarization is used to create element summaries</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">17c2cc25d00347c3bf2422d4f7a4ad7e</data>
      <data key="d13">259</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="ENTITY NODE">
      <data key="d9">1.0</data>
      <data key="d10">Element summaries include descriptions of entity nodes</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">0057fb2ddc0e4088ae5099b7ffa137da</data>
      <data key="d13">260</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="RELATIONSHIP EDGE">
      <data key="d9">1.0</data>
      <data key="d10">Element summaries include descriptions of relationship edges</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">d67d67cc3698438db76eb4a7f75e1ea0</data>
      <data key="d13">261</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="CLAIM COVARIATE">
      <data key="d9">1.0</data>
      <data key="d10">Element summaries include descriptions of claim covariates</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">c23761290af24cf29adc1ee8644bdad0</data>
      <data key="d13">262</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="GRAPH COMMUNITIES">
      <data key="d9">1.0</data>
      <data key="d10">Element summaries are used to understand the structure and semantics of graph communities</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">de51b828ce1f442bbb19a7b20bce9dda</data>
      <data key="d13">263</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="NODE">
      <data key="d9">1.0</data>
      <data key="d10">Element summaries include descriptions of nodes</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">4a3ff6a3471945fd8c7fd5c171c56d56</data>
      <data key="d13">264</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="EDGE">
      <data key="d9">1.0</data>
      <data key="d10">Element summaries include descriptions of edges</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">31bb84eb2a834dabacc0ed51af4fcefd</data>
      <data key="d13">265</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="COVARIATE">
      <data key="d9">1.0</data>
      <data key="d10">Element summaries include descriptions of covariates</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">5070012e83e7442381bcba1cdacdb7d8</data>
      <data key="d13">266</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="SUB-COMMUNITY SUMMARIES">
      <data key="d9">1.0</data>
      <data key="d10">Sub-community summaries are used when element summaries exceed the token limit</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">5eda9074df124f5497f17b61badd52ac</data>
      <data key="d13">267</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="COMMUNITY DETECTION">
      <data key="d9">2.0</data>
      <data key="d10">Community detection is a technique used to identify graph communities. Graph communities are groups of nodes within a graph that are more densely connected to each other than to the rest of the graph. This process of identifying such communities is crucial for understanding the structural dynamics and relationships within complex networks, particularly in the domain of Natural Language Processing and Information Retrieval. By leveraging community detection algorithms, researchers can uncover hidden patterns and insights within large datasets, facilitating more effective data analysis and interpretation.</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">4cf4107b0e2842778aaa658a1a85f3b3</data>
      <data key="d13">268</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY ANSWERS" target="GLOBAL ANSWER">
      <data key="d9">1.0</data>
      <data key="d10">Global answer is created from community answers</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">7f4857f94b4e4e49be7236a42071e167</data>
      <data key="d13">269</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="USER QUERY">
      <data key="d9">2.0</data>
      <data key="d10">Global answers are generated in response to user queries</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">d21a1fef903f4a399bd3cd366aad3c9e</data>
      <data key="d13">270</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="HELPFULNESS SCORE">
      <data key="d9">1.0</data>
      <data key="d10">Global answer is generated by sorting intermediate answers based on helpfulness scores</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">fc596a598ff74a4c843e405b597551b5</data>
      <data key="d13">271</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="INTERMEDIATE ANSWERS">
      <data key="d9">1.0</data>
      <data key="d10">Intermediate answers are combined to form the global answer</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">e2aacff6b4404574b818e7a3ece57b5b</data>
      <data key="d13">272</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="CONTEXT WINDOW">
      <data key="d9">1.0</data>
      <data key="d10">The final context window is used to generate the global answer</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">2ec5cae98c7a485881f0680fbca6d67f</data>
      <data key="d13">273</data>
      <data key="d14">1</data>
    </edge>
    <edge source="INDEXING TIME" target="GRAPH RAG PIPELINE">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG pipeline operates at indexing time</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">c87b815d61af448596d3194a804b57b3</data>
      <data key="d13">274</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUERY TIME" target="GRAPH RAG PIPELINE">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG pipeline operates at query time</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">2f92fc82c3b74417896bad3bd8e61f5e</data>
      <data key="d13">275</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG PIPELINE" target="NODES">
      <data key="d9">1.0</data>
      <data key="d10">Nodes are detected in the graph RAG pipeline</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">fb61c68efe5b4d69a9623e531e7c639c</data>
      <data key="d13">276</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG PIPELINE" target="EDGES">
      <data key="d9">1.0</data>
      <data key="d10">Edges are detected in the graph RAG pipeline</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">dc61e34c1ca8419e923aeeff7d83d949</data>
      <data key="d13">277</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG PIPELINE" target="COVARIATES">
      <data key="d9">1.0</data>
      <data key="d10">Covariates are detected in the graph RAG pipeline</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">697fb824eef34759852f1d5588921aec</data>
      <data key="d13">278</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG PIPELINE" target="LEIDEN">
      <data key="d9">1.0</data>
      <data key="d10">Leiden method is used in the graph RAG pipeline for community detection</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">b872fcc5b18a4f32b976f4693f22e88e</data>
      <data key="d13">279</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH RAG PIPELINE" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d9">1.0</data>
      <data key="d10">Graph RAG pipeline uses the RAG approach</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">64be9b98299f4d349e0f4358685ca235</data>
      <data key="d13">280</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NODES" target="PODCAST DATASET">
      <data key="d9">1.0</data>
      <data key="d10">The Podcast dataset graph consists of 8564 nodes</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">8302a03f6ede471bb955c0bbf44a4b3c</data>
      <data key="d13">281</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NODES" target="NEWS DATASET">
      <data key="d9">1.0</data>
      <data key="d10">The News dataset graph consists of 15754 nodes</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">a02263dd89964a1c8ab2d0e9aba0f4eb</data>
      <data key="d13">282</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EDGES" target="PODCAST DATASET">
      <data key="d9">1.0</data>
      <data key="d10">The Podcast dataset graph consists of 20691 edges</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">6b7aa6ce4cac4edbaaab831286e67e5e</data>
      <data key="d13">283</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EDGES" target="NEWS DATASET">
      <data key="d9">1.0</data>
      <data key="d10">The News dataset graph consists of 19520 edges</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">655d40ea08e348ad94ae49785797da90</data>
      <data key="d13">284</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEIDEN" target="TRAAG">
      <data key="d9">1.0</data>
      <data key="d10">Traag contributed to the development of the Leiden method</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">254cea99330f4f2aa062c771146da7ea</data>
      <data key="d13">285</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEIDEN" target="TRAAG ET AL.">
      <data key="d9">2.0</data>
      <data key="d10">Traag et al. are the authors of the Leiden algorithm and developed the Leiden method.</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56,f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">a2836232227c4e3383d166db860cb2a3</data>
      <data key="d13">286</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEIDEN" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d9">2.0</data>
      <data key="d10">Leiden is a specific type of community detection algorithm used in various analytical pipelines. It is designed to identify and map out the structural dynamics within specialized communities, particularly in the domain of Natural Language Processing and Information Retrieval. The algorithm is known for its efficiency and accuracy in detecting community structures, making it a valuable tool for researchers and practitioners in the field.</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a,7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">8a9247ee9bac45bdbf69c9d0bb8419b5</data>
      <data key="d13">287</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEIDEN" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d9">1.0</data>
      <data key="d10">Leiden is known for its ability to recover hierarchical community structures efficiently</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">757a0f78fcdd4bf6b8326a75fcee9e15</data>
      <data key="d13">288</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEIDEN" target="MULTIHOP-RAG">
      <data key="d9">1.0</data>
      <data key="d10">The Leiden algorithm is used to detect graph communities in the MultiHop-RAG</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">b5235cb24b8f440389f250ebd5b6e2f8</data>
      <data key="d13">289</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEIDEN" target="FIGURE 3">
      <data key="d9">1.0</data>
      <data key="d10">Figure 3 shows graph communities detected using the Leiden algorithm</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">bdee1849252749efa2e671ed87641f61</data>
      <data key="d13">290</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="LEWIS">
      <data key="d9">1.0</data>
      <data key="d10">Lewis contributed to the development of the RAG approach</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">057641c1476247958d8c357e17095d8e</data>
      <data key="d13">291</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="LEWIS ET AL.">
      <data key="d9">1.0</data>
      <data key="d10">Lewis et al. developed the RAG approach</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">b61dfd0b24664f37af4046bdf0cb7b19</data>
      <data key="d13">292</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="LEWIS ET AL., 2020">
      <data key="d9">2.0</data>
      <data key="d10">Lewis et al., 2020, are the authors who established the RAG approach</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">0bc00f14e6194df7b0fe9ef9ba28d34f</data>
      <data key="d13">293</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MICROSOFT" target="KEVIN SCOTT">
      <data key="d9">1.0</data>
      <data key="d10">Kevin Scott is the CTO of Microsoft</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">b823c5d22037423da919eee6c35c4c8b</data>
      <data key="d13">294</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MICROSOFT" target="GPT-4">
      <data key="d9">2.0</data>
      <data key="d10">Microsoft conducted a study on the impact of large language models on scientific discovery using GPT-4</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">cd7f555e4ab948ba94bade14e262ff84</data>
      <data key="d13">295</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Preprint is available on arXiv</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">86cd53087b2542f898d6cecca31e6145</data>
      <data key="d13">296</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="BAUMEL, T.">
      <data key="d9">1.0</data>
      <data key="d10">Baumel, T. published the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">5dc3480806b04fdd8089a3be46e22540</data>
      <data key="d13">297</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="EYAL, M.">
      <data key="d9">1.0</data>
      <data key="d10">Eyal, M. published the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">50c91820a91f488d8606198540aba894</data>
      <data key="d13">298</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ELHADAD, M.">
      <data key="d9">1.0</data>
      <data key="d10">Elhadad, M. published the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">a38eace89e7e40de8f007fde24597e9e</data>
      <data key="d13">299</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ES, S.">
      <data key="d9">1.0</data>
      <data key="d10">Es, S. published the paper "Ragas: Automated evaluation of retrieval augmented generation" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">5d75097d065e4b049a1678deab40949b</data>
      <data key="d13">300</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="JAMES, J.">
      <data key="d9">1.0</data>
      <data key="d10">James, J. published the paper "Ragas: Automated evaluation of retrieval augmented generation" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">c277134d380a42cd886a14a953554792</data>
      <data key="d13">301</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ESPINOSA-ANKE, L.">
      <data key="d9">1.0</data>
      <data key="d10">Espinosa-Anke, L. published the paper "Ragas: Automated evaluation of retrieval augmented generation" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">b680be879404440885b1d3af5b9af583</data>
      <data key="d13">302</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="SCHOCKAERT, S.">
      <data key="d9">1.0</data>
      <data key="d10">Schockaert, S. published the paper "Ragas: Automated evaluation of retrieval augmented generation" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">4cc609b1a64a442aac6b72078a315ac6</data>
      <data key="d13">303</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="FENG, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Feng, Z. published the paper "Retrieval-generation synergy augmented large language models" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">a3ee323c9c9a4f81b5907030122b80d2</data>
      <data key="d13">304</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="FENG, X.">
      <data key="d9">1.0</data>
      <data key="d10">Feng, X. published the paper "Retrieval-generation synergy augmented large language models" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">19aa5f0b738c4f4a96668c80c3e93331</data>
      <data key="d13">305</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ZHAO, D.">
      <data key="d9">1.0</data>
      <data key="d10">Zhao, D. published the paper "Retrieval-generation synergy augmented large language models" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">f8402b10349f4db888ac4fb6fd81723a</data>
      <data key="d13">306</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="YANG, M.">
      <data key="d9">1.0</data>
      <data key="d10">Yang, M. published the paper "Retrieval-generation synergy augmented large language models" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">5927f9089289429da4adf2bbd5641e44</data>
      <data key="d13">307</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="QIN, B.">
      <data key="d9">1.0</data>
      <data key="d10">Qin, B. published the paper "Retrieval-generation synergy augmented large language models" on arXiv</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">60724b8b268044b69a4b3d939f1757e2</data>
      <data key="d13">308</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="LANGCHAIN">
      <data key="d9">1.0</data>
      <data key="d10">LangChain is an organization that has published on arXiv</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">d931685d35e149909472f736114ca62f</data>
      <data key="d13">309</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="WANG, S.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, S. published the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">3f5e9927a4114a958d75f5ed313526a8</data>
      <data key="d13">310</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="KHRAMTSOVA, E.">
      <data key="d9">1.0</data>
      <data key="d10">Khramtsova, E. published the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">4728bf0cb7564bbd85c90ceaa846f290</data>
      <data key="d13">311</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ZHUANG, S.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, S. published the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">cdac6338c3234797a0d3a32cd68d1b2e</data>
      <data key="d13">312</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ZUCCON, G.">
      <data key="d9">1.0</data>
      <data key="d10">Zuccon, G. published the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">372f78df13f9452b84d898c703a1ba95</data>
      <data key="d13">313</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="WANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, Y. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">7af06d2b32a941a4b044579a7c423371</data>
      <data key="d13">314</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="LIPKA, N.">
      <data key="d9">1.0</data>
      <data key="d10">Lipka, N. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">a10b8fad74744ae981747dadf7234b78</data>
      <data key="d13">315</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ROSSI, R. A.">
      <data key="d9">1.0</data>
      <data key="d10">Rossi, R. A. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">0cb2118ecc87439a91409deef7ef9830</data>
      <data key="d13">316</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="SIU, A.">
      <data key="d9">1.0</data>
      <data key="d10">Siu, A. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">ea27218042d640fd81c23eb64aff6b46</data>
      <data key="d13">317</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ZHANG, R.">
      <data key="d9">1.0</data>
      <data key="d10">Zhang, R. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">9e5d626681094933abf87cf797f2fa46</data>
      <data key="d13">318</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="DERR, T.">
      <data key="d9">1.0</data>
      <data key="d10">Derr, T. published the paper "Knowledge graph prompting for multi-document question answering" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">545358ff14f84601a22e9f39f5ef1534</data>
      <data key="d13">319</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="XU, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Xu, Y. published the paper "Text summarization with latent queries" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">1b0e7dbc7c5944a7833f6540bde1fa4f</data>
      <data key="d13">320</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="LAPATA, M.">
      <data key="d9">1.0</data>
      <data key="d10">Lapata, M. published the paper "Text summarization with latent queries" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">0c0f2d8c623949f1ae89c67d0753aeab</data>
      <data key="d13">321</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ZHANG, J.">
      <data key="d9">1.0</data>
      <data key="d10">Zhang, J. published the paper "Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">20c3844c80a140ac97b62dc444feee41</data>
      <data key="d13">322</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ZHANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Zhang, Y. published the paper "Causal graph discovery with retrieval-augmented generation based large language models" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">c5fac1bea509464d9dc934275d938039</data>
      <data key="d13">323</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="GAN, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Gan, Y. published the paper "Causal graph discovery with retrieval-augmented generation based large language models" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">45b64fbddd8f4abdb86a9c3c6f53f802</data>
      <data key="d13">324</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="YAO, L.">
      <data key="d9">1.0</data>
      <data key="d10">Yao, L. published the paper "Causal graph discovery with retrieval-augmented generation based large language models" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">0e504b58cbda4d9188050bc43004c01f</data>
      <data key="d13">325</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="WANG, C.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, C. published the paper "Causal graph discovery with retrieval-augmented generation based large language models" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">c06bd37e120e4af49ec8bd6ce399473b</data>
      <data key="d13">326</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ZHENG, L.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">5d507985f2f540d8a1fa2d1191eae2a8</data>
      <data key="d13">327</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="CHIANG, W.-L.">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">8e0b5b4011d74bbb8dc09fa05d88369c</data>
      <data key="d13">328</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="SHENG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Sheng, Y. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">5d8184f5d52040d8bb67d1a6b889e9fe</data>
      <data key="d13">329</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="WU, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Wu, Z. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">b3bf669489ae4913bb60ddfe50e41697</data>
      <data key="d13">330</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="ZHUANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, Y. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">0eba9d55a3ff46298665a0c292e2237f</data>
      <data key="d13">331</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="LIN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Lin, Z. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">55e3f4a200eb4619ae2b6efb645464d1</data>
      <data key="d13">332</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="LI, D.">
      <data key="d9">1.0</data>
      <data key="d10">Li, D. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">c44324c171674d00a743413042e9b944</data>
      <data key="d13">333</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ARXIV" target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Xing, E. published the paper "Exploring large language models for knowledge graph completion" on arXiv</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">4bdaba79a3274241ab98e27aeaf98f57</data>
      <data key="d13">334</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PREPRINT" target="CS.CL">
      <data key="d9">1.0</data>
      <data key="d10">Preprint is classified under cs.CL on arXiv</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">7c8c464ed7044a7896adfeb35f58a04d</data>
      <data key="d13">335</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PREPRINT" target="24 APR 2024">
      <data key="d9">1.0</data>
      <data key="d10">Preprint was submitted on 24 Apr 2024</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">5fa2eec73bec481b85eba22ea7a2a927</data>
      <data key="d13">336</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PREPRINT" target="2404.16130V1">
      <data key="d9">1.0</data>
      <data key="d10">Preprint has the identifier 2404.16130v1 on arXiv</data>
      <data key="d11">f0306814bf64f5c9e79603fc6a52f4ea</data>
      <data key="d12">e6aa5eedca984c56b5fa5e179127951d</data>
      <data key="d13">337</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="PARTITION">
      <data key="d9">1.0</data>
      <data key="d10">Community detection results in the partition of a graph into distinct communities</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">1c4bd4ba4ef64a93acd55faa8fd97ca9</data>
      <data key="d13">338</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="PIPELINE">
      <data key="d9">1.0</data>
      <data key="d10">The pipeline includes a step for community detection</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">5b85c70d578c4d67b5cb4743552bd559</data>
      <data key="d13">339</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="DANG, 2006">
      <data key="d9">2.0</data>
      <data key="d10">Dang, 2006, is the author who established the QFS approach</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">956113fb770840c38bce65bb5832f988</data>
      <data key="d13">340</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="BAUMEL ET AL., 2018">
      <data key="d9">2.0</data>
      <data key="d10">Baumel et al., 2018, are the authors who worked on query-focused abstractive summarization</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">785bb55e79954b0c84a4a53cd7f0b454</data>
      <data key="d13">341</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="LASKAR ET AL., 2020">
      <data key="d9">2.0</data>
      <data key="d10">Laskar et al., 2020, are the authors who worked on query-focused abstractive summarization</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">1239281fd3774b91a99358c9c1e6ee1c</data>
      <data key="d13">342</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="YAO ET AL., 2017">
      <data key="d9">2.0</data>
      <data key="d10">Yao et al., 2017, are the authors who worked on query-focused abstractive summarization</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">32b29a842b224f4c99fa1d5c764efc9a</data>
      <data key="d13">343</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TRANSFORMER ARCHITECTURE" target="GOODWIN ET AL., 2020">
      <data key="d9">2.0</data>
      <data key="d10">Goodwin et al., 2020, are the authors who worked on the early applications of the transformer architecture</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">f5ae7dc11fd64822a3a15e7d3839031a</data>
      <data key="d13">344</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TRANSFORMER ARCHITECTURE" target="LASKAR ET AL., 2022">
      <data key="d9">2.0</data>
      <data key="d10">Laskar et al., 2022, are the authors who worked on the early applications of the transformer architecture</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">e1e254e67719488894eaa3553112a8cf</data>
      <data key="d13">345</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TRANSFORMER ARCHITECTURE" target="LIU AND LAPATA, 2019">
      <data key="d9">2.0</data>
      <data key="d10">Liu and Lapata, 2019, are the authors who worked on the early applications of the transformer architecture</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">ebdd79169d7d41b99faf09b039a66204</data>
      <data key="d13">346</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GPT" target="ACHIAM ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">Achiam et al., 2023, are the authors who worked on the GPT series of large language models</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">e036534e17b24dd2895167a20873230f</data>
      <data key="d13">347</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GPT" target="BROWN ET AL., 2020">
      <data key="d9">2.0</data>
      <data key="d10">Brown et al., 2020, are the authors who worked on the GPT series of large language models</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">a00bc5e4be634b08b1f084b6a07abafd</data>
      <data key="d13">348</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLAMA" target="TOUVRON ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">Touvron et al., 2023, are the authors who worked on the Llama series of large language models</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">ce8241c964724429bb361b7b53867007</data>
      <data key="d13">349</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GEMINI" target="ANIL ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">Anil et al., 2023, are the authors who worked on the Gemini series of large language models</data>
      <data key="d11">fb3c48579608fa28be585ceb6cd2f0fe</data>
      <data key="d12">61cd7f168f7f44d6a23415e9497f1e65</data>
      <data key="d13">350</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="MODULARITY">
      <data key="d9">1.0</data>
      <data key="d10">Modularity is an inherent quality of knowledge graphs</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">3be77a7b57e34c55acc1f1dfbc64ee10</data>
      <data key="d13">351</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN ET AL., 2020" target="FEW-SHOT EXAMPLES">
      <data key="d9">1.0</data>
      <data key="d10">Brown et al. (2020) discuss in-context learning with few-shot examples</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">751c564f8ff6444d9d4c8de4a677e655</data>
      <data key="d13">352</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KURATOV ET AL., 2024" target="CONTEXT WINDOW SIZE">
      <data key="d9">1.0</data>
      <data key="d10">Kuratov et al. discussed the potential for information to be lost in longer contexts</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">96963c158fb64680bded290f442ff9aa</data>
      <data key="d13">353</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIU ET AL., 2023" target="CONTEXT WINDOW SIZE">
      <data key="d9">1.0</data>
      <data key="d10">Liu et al. discussed the potential for information to be lost in longer contexts</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">bdbfbde5dd244447a2a0674b30ae3e8f</data>
      <data key="d13">354</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="LOUVAIN">
      <data key="d9">1.0</data>
      <data key="d10">Louvain is a type of community detection algorithm</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">f970bfe31db74929abff6ea38e5d18e6</data>
      <data key="d13">355</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="GRAPH INDEX">
      <data key="d9">1.0</data>
      <data key="d10">Community detection algorithms are used to partition the graph index into communities</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">6f0c2a8b79e6406a8ab7a20864ae2ce2</data>
      <data key="d13">356</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="FORTUNATO">
      <data key="d9">1.0</data>
      <data key="d10">Fortunato has conducted surveys on community detection algorithms</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">7b09e60e33f44ffdab9c656c5b9c1d50</data>
      <data key="d13">357</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="JIN ET AL.">
      <data key="d9">1.0</data>
      <data key="d10">Jin et al. have conducted surveys on community detection algorithms</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">8b7beab7c0a143aea7bffc31df7528d5</data>
      <data key="d13">358</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HOTPOTQA" target="GPT-4-TURBO">
      <data key="d9">1.0</data>
      <data key="d10">HotPotQA dataset is used to evaluate the entity extraction prompt with gpt-4-turbo</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">d03eb34a0612420680555ab9f10d03d5</data>
      <data key="d13">359</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HOTPOTQA" target="YANG ET AL., 2018">
      <data key="d9">1.0</data>
      <data key="d10">Yang et al. (2018) introduced the HotPotQA dataset</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">b066746cdff7440c8a3591f0c098201d</data>
      <data key="d13">360</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HOTPOTQA" target="YANG ET AL.">
      <data key="d9">2.0</data>
      <data key="d10">Yang et al. are the authors associated with the HotPotQA dataset</data>
      <data key="d11">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">1e2eded8ef7b4b458c33fbc2d36c4380</data>
      <data key="d13">361</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GPT-4-TURBO" target="CONTEXT WINDOW SIZE">
      <data key="d9">1.0</data>
      <data key="d10">GPT-4-Turbo was tested with varying context window sizes</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">c59e3e931b0f4cf888c2eb70857ee753</data>
      <data key="d13">362</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TECH JOURNALIST">
      <data key="d9">1.0</data>
      <data key="d10">Tech journalist uses podcast transcripts to look for insights and trends in the tech industry</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">305b80bb4df5488b8a34129daeeae0c7</data>
      <data key="d13">363</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="KEVIN SCOTT">
      <data key="d9">3.0</data>
      <data key="d10">Kevin Scott is a participant in the podcast conversations compiled in the Podcast Transcripts dataset. His conversations are included as part of the podcast transcripts, contributing to the overall content and discussions captured within this dataset.</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9,922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">66fa0de756da440bad8da583306410c4</data>
      <data key="d13">364</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TECHNOLOGY LEADERS">
      <data key="d9">1.0</data>
      <data key="d10">Technology leaders participate in the podcast conversations</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">d1e9c550a0e74c48ae81c319f26ccafc</data>
      <data key="d13">365</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="RAG SYSTEMS">
      <data key="d9">2.0</data>
      <data key="d10">RAG systems are used to evaluate the Podcast Transcripts dataset for global sensemaking tasks</data>
      <data key="d11">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">3730b5d759ba4fd28a54af0a02151f09</data>
      <data key="d13">366</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="C0">
      <data key="d9">2.0</data>
      <data key="d10">C0 is a category used in the analysis of podcast transcripts</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">82b7f7c27e2348f880c94ffb80942de7</data>
      <data key="d13">367</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="C1">
      <data key="d9">2.0</data>
      <data key="d10">C1 is a category used in the analysis of podcast transcripts</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">0980c4f558654466b4d691d0cb7ce16d</data>
      <data key="d13">368</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="C2">
      <data key="d9">2.0</data>
      <data key="d10">C2 is a category used in the analysis of podcast transcripts</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">f1e47cf5daa441649c3474c3339bb704</data>
      <data key="d13">369</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="C3">
      <data key="d9">2.0</data>
      <data key="d10">C3 is a category used in the analysis of podcast transcripts</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">0964dcfbff934c92af8961155673ac7f</data>
      <data key="d13">370</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TS">
      <data key="d9">2.0</data>
      <data key="d10">TS is a category used in the analysis of podcast transcripts</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">51b82bcdffe04056bad1c082c3830047</data>
      <data key="d13">371</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="EMPOWERMENT">
      <data key="d9">1.0</data>
      <data key="d10">Empowerment is used to evaluate how empowering the generated answers are for podcast transcripts</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">c62bb148852b49a98e2779ca23a0919d</data>
      <data key="d13">372</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="SS">
      <data key="d9">1.0</data>
      <data key="d10">SS is a category used in the analysis of podcast transcripts</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">72b5a0c357c24b739084d501b9354bc1</data>
      <data key="d13">373</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="UNITS">
      <data key="d9">1.0</data>
      <data key="d10">Units are used to measure the context in podcast transcripts</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">c827b62ebf134e55a3ccf0b63f976870</data>
      <data key="d13">374</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TOKENS">
      <data key="d9">1.0</data>
      <data key="d10">Tokens are used to measure the word count in podcast transcripts</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">b51ef388758845e880e736309ae791e3</data>
      <data key="d13">375</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="% MAX">
      <data key="d9">1.0</data>
      <data key="d10">% Max is used to measure the percentage of maximum token count in podcast transcripts</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">0a841cd4b6664423b033f22e3a80f33c</data>
      <data key="d13">376</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="NEWS ARTICLES">
      <data key="d9">1.0</data>
      <data key="d10">Both are datasets used in the analysis</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">16911c51c65b42f8a2d04c05f45b2c58</data>
      <data key="d13">377</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLES" target="EDUCATOR">
      <data key="d9">1.0</data>
      <data key="d10">Educator uses news articles to incorporate current affairs into curricula</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">fc3f77f29574410d991a2aa333950bf6</data>
      <data key="d13">378</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLES" target="RAG SYSTEMS">
      <data key="d9">2.0</data>
      <data key="d10">RAG systems are used to evaluate the News Articles dataset for global sensemaking tasks</data>
      <data key="d11">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">4f847eb72cbe48678d5634dcf93fc0e2</data>
      <data key="d13">379</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLES" target="C0">
      <data key="d9">1.0</data>
      <data key="d10">C0 is a category used in the analysis of news articles</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">829e64159ae04301982e88e93a2f0e49</data>
      <data key="d13">380</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLES" target="C1">
      <data key="d9">1.0</data>
      <data key="d10">C1 is a category used in the analysis of news articles</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">cf37d3d4bc154f65b3d79c831c587763</data>
      <data key="d13">381</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLES" target="C2">
      <data key="d9">1.0</data>
      <data key="d10">C2 is a category used in the analysis of news articles</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">4b4fce341d554012bc73d7886860749e</data>
      <data key="d13">382</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLES" target="C3">
      <data key="d9">1.0</data>
      <data key="d10">C3 is a category used in the analysis of news articles</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">9f6e7a08bd814d19b45fac58928027f8</data>
      <data key="d13">383</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLES" target="TS">
      <data key="d9">1.0</data>
      <data key="d10">TS is a category used in the analysis of news articles</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">ff9410fed5e64c04a875e040e3d182b2</data>
      <data key="d13">384</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLES" target="UNITS">
      <data key="d9">1.0</data>
      <data key="d10">Units are used to measure the context in news articles</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">1161272728914953b568f384d7a9f2f1</data>
      <data key="d13">385</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLES" target="TOKENS">
      <data key="d9">1.0</data>
      <data key="d10">Tokens are used to measure the word count in news articles</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">f09c82eb89944ae9846df82135123b90</data>
      <data key="d13">386</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLES" target="% MAX">
      <data key="d9">1.0</data>
      <data key="d10">% Max is used to measure the percentage of maximum token count in news articles</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">d221b743a51d464b87de3b72b85f6b59</data>
      <data key="d13">387</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MAP-REDUCE" target="TEXT SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Map-reduce is the method used in the text summarization condition</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">9fd31a28e1384b40a9d1658a765871cd</data>
      <data key="d13">388</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EMPOWERMENT" target="LLM EVALUATOR">
      <data key="d9">1.0</data>
      <data key="d10">The LLM evaluator assesses answers based on the empowerment metric</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">0119f233c8394b9584e55fadcce173f0</data>
      <data key="d13">389</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EMPOWERMENT" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">Empowerment is used to evaluate how empowering the generated answers are for news articles</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">5c20b469b92446dabb1b68976807be7c</data>
      <data key="d13">390</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EMPOWERMENT" target="CONTEXT WINDOW SIZE">
      <data key="d9">1.0</data>
      <data key="d10">The smallest context window size (8k) performed comparably with larger context sizes on empowerment</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">2c2392247a35456da663adfcffd12e73</data>
      <data key="d13">391</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EMPOWERMENT" target="WIN RATE">
      <data key="d9">1.0</data>
      <data key="d10">Empowerment has an average win rate of 51.3%</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">167a32ff67ce4471baa8cf019ee7c17b</data>
      <data key="d13">392</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NAIVE RAG" target="TAYLOR SWIFT">
      <data key="d9">1.0</data>
      <data key="d10">Naive RAG mentions Taylor Swift as a public figure</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">3280fc12ef414827838e6ac7089f0618</data>
      <data key="d13">393</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NAIVE RAG" target="TRAVIS KELCE">
      <data key="d9">1.0</data>
      <data key="d10">Naive RAG mentions Travis Kelce as a public figure</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">556fba72a0854ce4831f6cfea6fd035e</data>
      <data key="d13">394</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NAIVE RAG" target="BRITNEY SPEARS">
      <data key="d9">1.0</data>
      <data key="d10">Naive RAG mentions Britney Spears as a public figure</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">8e2e6eeed5a04c9f80efbcfc624ced95</data>
      <data key="d13">395</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NAIVE RAG" target="JUSTIN TIMBERLAKE">
      <data key="d9">1.0</data>
      <data key="d10">Naive RAG mentions Justin Timberlake as a public figure</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">ea6d546f1caa4b4aaacdad8b8af195ec</data>
      <data key="d13">396</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NAIVE RAG" target="DECISION">
      <data key="d9">1.0</data>
      <data key="d10">Naive RAG is determined to be the loser based on the decision metric</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">267ce44e6dae43ee94d0d375ec08ef17</data>
      <data key="d13">397</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NAIVE RAG" target="GLOBAL APPROACHES">
      <data key="d9">1.0</data>
      <data key="d10">Global approaches consistently outperformed the naive RAG</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">b37e5d15f3154ee39df016b8eac8de66</data>
      <data key="d13">398</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NAIVE RAG" target="DIRECTNESS">
      <data key="d9">1.0</data>
      <data key="d10">Naive RAG produces the most direct responses</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">e13eb574e885414b80f0b66992767ef2</data>
      <data key="d13">399</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NAIVE RAG" target="SS">
      <data key="d9">1.0</data>
      <data key="d10">SS represents naive RAG in the analysis</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">93f4140f654e41ccba908c6f6dc65f17</data>
      <data key="d13">400</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NAIVE RAG" target="GAO ET AL., 2023">
      <data key="d9">1.0</data>
      <data key="d10">Gao et al., 2023 discusses naive RAG approaches</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">a102d091986749ef90b45d411e707bef</data>
      <data key="d13">401</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GLOBAL SUMMARIZATION" target="COMMUNITY PARTITION">
      <data key="d9">1.0</data>
      <data key="d10">Community partitions enable divide-and-conquer global summarization</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">cd6ae38a5a6742899d14f4a064f42c19</data>
      <data key="d13">402</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GLOBAL SUMMARIZATION" target="GRAPH-FREE APPROACH">
      <data key="d9">1.0</data>
      <data key="d10">Global summarization can be performed using a graph-free approach</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">fe18688bd4ef44d1a184ec6d1451a5cf</data>
      <data key="d13">403</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GLOBAL SUMMARIZATION" target="SOURCE TEXTS">
      <data key="d9">1.0</data>
      <data key="d10">Source texts are used in global summarization</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">0f1282bdfedb4f6e8765007a90dd2959</data>
      <data key="d13">404</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PARTIAL ANSWERS" target="FINAL GLOBAL ANSWER">
      <data key="d9">1.0</data>
      <data key="d10">Final global answer is generated by combining all relevant partial answers</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">540af5c5d4cd41ceb29c40c5fb02e2fe</data>
      <data key="d13">405</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSEMAKING" target="SHORT DESCRIPTIONS">
      <data key="d9">1.0</data>
      <data key="d10">Short descriptions are used to generate sensemaking questions</data>
      <data key="d11">21e52bc06a82796b1f4bcd73edda1f2a</data>
      <data key="d12">bbf83708095f47019eaee93d6879bc77</data>
      <data key="d13">406</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LOW-LEVEL COMMUNITY SUMMARIES" target="NEWS DATASET">
      <data key="d9">1.0</data>
      <data key="d10">Low-level community summaries are derived from the News dataset for analysis</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">245a56f01d1b48a7b4d88ed0e354155a</data>
      <data key="d13">407</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="LLMS">
      <data key="d9">1.0</data>
      <data key="d10">The use of rich descriptive text for homogeneous nodes in a graph index aligns with the capabilities of LLMs</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">d3aa564fb4eb430a8ca6813ca76bfff6</data>
      <data key="d13">408</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="KNOWLEDGE GRAPHS">
      <data key="d9">1.0</data>
      <data key="d10">Graph indexes differ from typical knowledge graphs in their use of rich descriptive text instead of concise knowledge triples</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">d9b948357d96419ca135065ce1c360ef</data>
      <data key="d13">409</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="C0">
      <data key="d9">1.0</data>
      <data key="d10">The graph index supports condition C0</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">20a79ddd91ba48e4bb7bc194c79baaf6</data>
      <data key="d13">410</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="C1">
      <data key="d9">1.0</data>
      <data key="d10">The graph index supports condition C1</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">b95728a0b96b405cbccafa6c12fd8722</data>
      <data key="d13">411</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="C2">
      <data key="d9">1.0</data>
      <data key="d10">The graph index supports condition C2</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">5d6dc034d2014e8c930fde69c31b99cf</data>
      <data key="d13">412</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="C3">
      <data key="d9">1.0</data>
      <data key="d10">The graph index supports condition C3</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">127cbb53940f4efa8e1807b4452375ba</data>
      <data key="d13">413</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="PODCAST DATASET">
      <data key="d9">1.0</data>
      <data key="d10">The graph indexing process used a context window size of 600 tokens with 1 gleaning for the Podcast dataset</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">f1ea6ef9539043ab887bcce22ccf9625</data>
      <data key="d13">414</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="NEWS DATASET">
      <data key="d9">1.0</data>
      <data key="d10">The graph indexing process used a context window size of 600 tokens with 0 gleanings for the News dataset</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">b50c4f053f0546029c4095b7b93aa05e</data>
      <data key="d13">415</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="ENTITY TYPES">
      <data key="d9">1.0</data>
      <data key="d10">The graph index was created using generic prompts for entity and relationship extraction</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">0cea7f7a7fab49339cdd6fb02d0d183e</data>
      <data key="d13">416</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="FEW-SHOT EXAMPLES">
      <data key="d9">1.0</data>
      <data key="d10">Few-shot examples tailored to the domain of the data were used in the graph indexing process</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">5b89f0d8101c419b86e1959cca2db848</data>
      <data key="d13">417</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="CONTEXT WINDOW SIZE">
      <data key="d9">1.0</data>
      <data key="d10">The graph indexing process used a context window size of 600 tokens</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">cdb407fc600b45caa6f94f82e89d2e4f</data>
      <data key="d13">418</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="LIFETIME QUERIES PER DATASET">
      <data key="d9">1.0</data>
      <data key="d10">The decision to build a graph index depends on the expected number of lifetime queries per dataset</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">7f4905fcb43e4d6ca23e6d2b40f6958e</data>
      <data key="d13">419</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="VALUE FROM GRAPH INDEX">
      <data key="d9">1.0</data>
      <data key="d10">The decision to build a graph index depends on the value obtained from it</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">f5ad4fe84df544c69db25f0e30c6eace</data>
      <data key="d13">420</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH INDEX" target="OTHER GRAPH-RELATED RAG APPROACHES">
      <data key="d9">1.0</data>
      <data key="d10">The decision to build a graph index depends on the value obtained from other graph-related RAG approaches</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">237a46cc973b41dc9af4190c71c5c9e1</data>
      <data key="d13">421</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTITY REFERENCES" target="RECALL">
      <data key="d9">1.0</data>
      <data key="d10">Recall measures the completeness of entity references extracted from text chunks</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">aaa27aa0b1024e3aa3c87a6ec821a348</data>
      <data key="d13">422</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTITY REFERENCES" target="PRECISION">
      <data key="d9">1.0</data>
      <data key="d10">Precision measures the accuracy of entity references extracted from text chunks</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">f0a28fe3f68546dba7850815f7933275</data>
      <data key="d13">423</data>
      <data key="d14">1</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="DEFAULT PROMPT">
      <data key="d9">1.0</data>
      <data key="d10">Few-shot examples are used to tailor the default prompt to the domain</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">45b59feba7134bc18632cb42530c189a</data>
      <data key="d13">424</data>
      <data key="d14">1</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="SECONDARY EXTRACTION PROMPT">
      <data key="d9">1.0</data>
      <data key="d10">Few-shot examples are used to tailor the secondary extraction prompt to the domain</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">7747cd2048f94d378e83265b9561d921</data>
      <data key="d13">425</data>
      <data key="d14">1</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="SCIENCE">
      <data key="d9">1.0</data>
      <data key="d10">Few-shot examples are used to improve LLM performance in the domain of science</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">c4e9532dbc734264a0e3e827bc8014c6</data>
      <data key="d13">426</data>
      <data key="d14">1</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="MEDICINE">
      <data key="d9">1.0</data>
      <data key="d10">Few-shot examples are used to improve LLM performance in the domain of medicine</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">003e5d505a01434596c6d65ff20b0bdf</data>
      <data key="d13">427</data>
      <data key="d14">1</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="LAW">
      <data key="d9">1.0</data>
      <data key="d10">Few-shot examples are used to improve LLM performance in the domain of law</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">f79358f3535045d9aad3b828df59293b</data>
      <data key="d13">428</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SINGLE EXTRACTION ROUND" target="EXTRACTION PROCESS">
      <data key="d9">1.0</data>
      <data key="d10">A single extraction round is part of the extraction process</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">7d375c18c1e2415faecd9f7397068a32</data>
      <data key="d13">429</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DOMAIN" target="DOCUMENT CORPUS">
      <data key="d9">1.0</data>
      <data key="d10">Domain refers to the specific area of knowledge of the document corpus</data>
      <data key="d11">bc9e2c9e369c4108cf4f6dd5f60960f4</data>
      <data key="d12">dfa0e847a6704c93a0fe014b01858ff7</data>
      <data key="d13">430</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COVARIATE PROMPT" target="CLAIMS">
      <data key="d9">1.0</data>
      <data key="d10">Covariate prompts are used to extract claims linked to detected entities</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">9e91823feb174cd1b6a3bf8d0a5cb86b</data>
      <data key="d13">431</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CLAIMS" target="SOURCE TEXT SPAN">
      <data key="d9">1.0</data>
      <data key="d10">Source text span is an attribute of claims</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">ad76c8dc8dd94412a5e79005cf8e0f2f</data>
      <data key="d13">432</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CLAIMS" target="START DATE">
      <data key="d9">1.0</data>
      <data key="d10">Start date is an attribute of claims</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">26a03482961e41918ea049018080af7a</data>
      <data key="d13">433</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CLAIMS" target="END DATE">
      <data key="d9">1.0</data>
      <data key="d10">End date is an attribute of claims</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">1cfd220ff4d2493ca4b92d725d171d32</data>
      <data key="d13">434</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CLAIMS" target="DESCRIPTION">
      <data key="d9">1.0</data>
      <data key="d10">Description is an attribute of claims</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">97738fe0830d405ba53598b5cb1e5e38</data>
      <data key="d13">435</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CLAIMS" target="SUBJECT">
      <data key="d9">1.0</data>
      <data key="d10">Subject is an attribute of claims</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">354cea4f6e164a48ad12122c28a5b30d</data>
      <data key="d13">436</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CLAIMS" target="OBJECT">
      <data key="d9">1.0</data>
      <data key="d10">Object is an attribute of claims</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">1ee2380c1eda4ebb8c9304820750ac88</data>
      <data key="d13">437</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITIES OF ENTITIES" target="NOISY GRAPH STRUCTURE">
      <data key="d9">1.0</data>
      <data key="d10">Communities of entities help manage variations in a noisy graph structure</data>
      <data key="d11">2c6ed90897310eea2f28e33fff1c32b0</data>
      <data key="d12">57e00d4d4e0e4679a150f048deb80af3</data>
      <data key="d13">438</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMON ENTITY" target="HOMOGENEOUS NODES">
      <data key="d9">1.0</data>
      <data key="d10">Common entities are described using rich descriptive text for homogeneous nodes</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">c1e4a9dbe55c4fb89f0d927c9fb067a4</data>
      <data key="d13">439</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLMS" target="METRICS">
      <data key="d9">1.0</data>
      <data key="d10">LLMs are used to generate metrics for evaluating natural language generation</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">1474a72a5cff4b72ae6f99e804ceaa95</data>
      <data key="d13">440</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLMS" target="WANG ET AL., 2023A">
      <data key="d9">1.0</data>
      <data key="d10">Wang et al. (2023) indicated the effectiveness of LLMs in evaluation</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">738fda68df7a49a0bae96673a8711afc</data>
      <data key="d13">441</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLMS" target="ZHENG ET AL., 2024">
      <data key="d9">1.0</data>
      <data key="d10">Zheng et al. (2024) indicated the effectiveness of LLMs in evaluation</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">89dd5a0943c64247adae624abbc95afb</data>
      <data key="d13">442</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HOMOGENEOUS NODES" target="RELATIONSHIP EDGES">
      <data key="d9">1.0</data>
      <data key="d10">Relationship edges connect homogeneous nodes in a graph</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">405e9907440d4deab71f3960ae36f47b</data>
      <data key="d13">443</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RELATIONSHIP EDGES" target="EDGE WEIGHTS">
      <data key="d9">1.0</data>
      <data key="d10">Edge weights represent the normalized counts of detected relationship instances on relationship edges</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">f91e7c9600ca4623a8cc4a56d2dccd07</data>
      <data key="d13">444</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="COMMUNITY PARTITION">
      <data key="d9">1.0</data>
      <data key="d10">Each level of the hierarchical community structure provides a community partition</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">3af2a8619c394be6adf06e4bc742b7ec</data>
      <data key="d13">445</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="ROOT COMMUNITIES">
      <data key="d9">2.0</data>
      <data key="d10">The hierarchical community structure is a framework used to organize and understand the relationships and dynamics within specialized communities. Root communities are an integral part of this structure, serving as the top-level communities. These root communities form the foundational layer in the hierarchical community structure, providing a basis for further subdivision and organization of more specific sub-communities. This hierarchical approach allows for a systematic analysis of complex networks, facilitating a deeper understanding of the interconnections and dependencies within the domain of Natural Language Processing and Information Retrieval.</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">c10ffc51dcb54708a1dc757693010bfe</data>
      <data key="d13">446</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="SUB-COMMUNITIES">
      <data key="d9">2.0</data>
      <data key="d10">The hierarchical community structure is a framework that organizes communities into different levels, with sub-communities representing the lower-level communities within this structure. Sub-communities are integral components of the hierarchical community structure, indicating that they are nested within larger communities and contribute to the overall organization and dynamics of the community. This hierarchical arrangement allows for a more detailed and nuanced understanding of the relationships and interactions within the community, facilitating more effective analysis and mapping of complex text data, particularly in specialized domains such as Natural Language Processing and Information Retrieval.</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56,843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">e67ce34d48364422973ccf3a6b57af83</data>
      <data key="d13">447</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="COMMUNITY LEVEL">
      <data key="d9">1.0</data>
      <data key="d10">Community levels are part of the hierarchical community structure</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">98773a34c9bb474d8a789ea08f57250e</data>
      <data key="d13">448</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="LEIDEN ALGORITHM">
      <data key="d9">1.0</data>
      <data key="d10">The Leiden algorithm is used to detect communities in the MultiHop-RAG dataset</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">ae260498423e4d55aa413423cd0eb20b</data>
      <data key="d13">449</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="OPENORD">
      <data key="d9">1.0</data>
      <data key="d10">OpenORD is used for node layout in the MultiHop-RAG dataset</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">4aeecb9d885743ca9373337a43957dd8</data>
      <data key="d13">450</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="FORCE ATLAS 2">
      <data key="d9">1.0</data>
      <data key="d10">Force Atlas 2 is used for node layout in the MultiHop-RAG dataset</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">1121b50f7858427fa679d81861238825</data>
      <data key="d13">451</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="NODE">
      <data key="d9">1.0</data>
      <data key="d10">Nodes represent entities in the MultiHop-RAG dataset</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">6e3c8aa3abab475bb0148faa9112f0bf</data>
      <data key="d13">452</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="EDGE">
      <data key="d9">1.0</data>
      <data key="d10">Edges represent connections between nodes in the MultiHop-RAG dataset</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">948a00e8ee1246cc90c47b292d03ddff</data>
      <data key="d13">453</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="COVARIATE">
      <data key="d9">1.0</data>
      <data key="d10">Covariates are variables linked to nodes and edges in the MultiHop-RAG dataset</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">45c42e619f5e488f914608780dcf0579</data>
      <data key="d13">454</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="TANG AND YANG">
      <data key="d9">2.0</data>
      <data key="d10">Tang and Yang are the authors associated with the MultiHop-RAG dataset</data>
      <data key="d11">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">2b3bea0d9ede41f193828526bcb8e02c</data>
      <data key="d13">455</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DATASET" target="QUESTIONS">
      <data key="d9">1.0</data>
      <data key="d10">Questions are generated based on the target datasets</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">6b2586cc1f8e4dc8af64913af63d9837</data>
      <data key="d13">456</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DATASET" target="N">
      <data key="d9">1.0</data>
      <data key="d10">N represents the number of test questions per dataset</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">7983bfa8d173414685272b3844d6612e</data>
      <data key="d13">457</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DATASET" target="TABLE 1">
      <data key="d9">1.0</data>
      <data key="d10">Table 1 shows example questions for each of the two evaluation datasets</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">09294e8220a445e288ea8841f234a440</data>
      <data key="d13">458</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ROOT COMMUNITIES" target="HIERARCHICAL CLUSTERING">
      <data key="d9">1.0</data>
      <data key="d10">Root communities are identified through hierarchical clustering</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">d4e043cf972c4d129b6b855f1731caae</data>
      <data key="d13">459</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ROOT COMMUNITIES" target="LEVEL 0">
      <data key="d9">1.0</data>
      <data key="d10">Level 0 represents the root-level communities in the hierarchical clustering</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">e0d63137270c426dbbfe7fcf78c474de</data>
      <data key="d13">460</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUB-COMMUNITIES" target="REPORTS">
      <data key="d9">1.0</data>
      <data key="d10">Reports provide detailed information about specific subtopics within sub-communities</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">c50bca18bc454a98b935df012b7fd6f9</data>
      <data key="d13">461</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUB-COMMUNITIES" target="HIERARCHICAL CLUSTERING">
      <data key="d9">1.0</data>
      <data key="d10">Sub-communities are identified through hierarchical clustering</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">434b133c64bd46219e67c6eb296ad0ff</data>
      <data key="d13">462</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUB-COMMUNITIES" target="LEVEL 1">
      <data key="d9">1.0</data>
      <data key="d10">Level 1 represents sub-communities within the root-level communities</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">cb895bf7e7c147e6b5d923b6c8f67d63</data>
      <data key="d13">463</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PARTITION" target="HIERARCHY">
      <data key="d9">1.0</data>
      <data key="d10">Partitions can be organized into a hierarchy</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">87776e869a01402499a317cb9cf09453</data>
      <data key="d13">464</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HIERARCHY" target="LEVEL 0">
      <data key="d9">1.0</data>
      <data key="d10">Level 0 is the root level in a hierarchy</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">d1e5359d2e344260bf1b83823df839b7</data>
      <data key="d13">465</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HIERARCHY" target="LEVEL 1">
      <data key="d9">1.0</data>
      <data key="d10">Level 1 is a sub-level in a hierarchy</data>
      <data key="d11">7fb7d9ce2da9c940a32afdd87d1d9e56</data>
      <data key="d12">0522f6580b824bc39792b695fc8be66b</data>
      <data key="d13">466</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM CONTEXT WINDOW" target="TOKEN LIMIT">
      <data key="d9">1.0</data>
      <data key="d10">The token limit defines the maximum number of tokens in the LLM context window</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">580fd6d19460460fa40613f66b3ee200</data>
      <data key="d13">467</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PROMINENCE" target="COMMUNITY EDGE">
      <data key="d9">1.0</data>
      <data key="d10">Prominence is used to prioritize community edges</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">84f4684a7a5241c18bb087ccb00550d3</data>
      <data key="d13">468</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PROMINENCE" target="COMBINED SOURCE AND TARGET NODE DEGREE">
      <data key="d9">1.0</data>
      <data key="d10">Combined source and target node degree is used to measure prominence</data>
      <data key="d11">843fc5421e086120ffa1c75856ecf6cd</data>
      <data key="d12">9607ba4a796f46be8d4f79bc7065d60b</data>
      <data key="d13">469</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CHUNKS" target="TOKEN SIZE">
      <data key="d9">1.0</data>
      <data key="d10">Chunks are divided based on a pre-specified token size</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">236dd7dce9ee4cf5918fddd44b4863e5</data>
      <data key="d13">470</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HELPFULNESS SCORE" target="INTERMEDIATE ANSWERS">
      <data key="d9">1.0</data>
      <data key="d10">Helpfulness scores are assigned to intermediate answers</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">9e92fed814a64d9d88bfab9a227859d3</data>
      <data key="d13">471</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TECH JOURNALIST" target="TECH POLICY">
      <data key="d9">1.0</data>
      <data key="d10">Tech journalist is interested in episodes dealing with tech policy and government regulation</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">7dccecb29d3a419093b279b22e207539</data>
      <data key="d13">472</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TECH JOURNALIST" target="PRIVACY LAWS">
      <data key="d9">1.0</data>
      <data key="d10">Tech journalist is interested in how guests perceive the impact of privacy laws on technology development</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">89857eb61e63461cbad7c5014f5098f9</data>
      <data key="d13">473</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TECH JOURNALIST" target="INNOVATION AND ETHICS">
      <data key="d9">1.0</data>
      <data key="d10">Tech journalist is interested in discussions about the balance between innovation and ethical considerations</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">7b2e7a0d910c4988a7b64489f4159a65</data>
      <data key="d13">474</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TECH JOURNALIST" target="POLICY CHANGES">
      <data key="d9">1.0</data>
      <data key="d10">Tech journalist is interested in suggested changes to current policies</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">38630cf0996f4cff8d32b2dbdaa5ba85</data>
      <data key="d13">475</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TECH JOURNALIST" target="COLLABORATIONS">
      <data key="d9">1.0</data>
      <data key="d10">Tech journalist is interested in discussions about collaborations between tech companies and governments</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">bd0fb68ac7014b91a314c93ec55897f5</data>
      <data key="d13">476</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EDUCATOR" target="HEALTH TOPICS">
      <data key="d9">1.0</data>
      <data key="d10">Educator is interested in current topics in health that can be integrated into health education curricula</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">f24dcb3cd6d644f8af2b6c47983e280b</data>
      <data key="d13">477</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EDUCATOR" target="PREVENTIVE MEDICINE">
      <data key="d9">1.0</data>
      <data key="d10">Educator is interested in how news articles address the concepts of preventive medicine and wellness</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">b1cad695afbc4ec3bbcd46ea34bd26ca</data>
      <data key="d13">478</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EDUCATOR" target="CONTRADICTORY ARTICLES">
      <data key="d9">1.0</data>
      <data key="d10">Educator is interested in examples of health articles that contradict each other</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">72f7974758d74e5d89ddb64ad739abb8</data>
      <data key="d13">479</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EDUCATOR" target="PUBLIC HEALTH PRIORITIES">
      <data key="d9">1.0</data>
      <data key="d10">Educator is interested in insights about public health priorities based on news coverage</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">e6ee83249adf4e14b98d1676b1c6b05f</data>
      <data key="d13">480</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EDUCATOR" target="HEALTH LITERACY">
      <data key="d9">1.0</data>
      <data key="d10">Educator is interested in highlighting the importance of health literacy through the dataset</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">f805fd9fe42947a38b92a3db6e8cc986</data>
      <data key="d13">481</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="PROMPTS">
      <data key="d9">1.0</data>
      <data key="d10">The size of the context window and the prompts used for answer generation are the same across all conditions</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">e8b956218d5c4e5d9d390abcf527a514</data>
      <data key="d13">482</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TASK" target="USER">
      <data key="d9">1.0</data>
      <data key="d10">The task is an activity or goal that the user aims to achieve</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">9525aa223d774e62ad856c2201cfab1b</data>
      <data key="d13">483</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TASK" target="QUESTIONS">
      <data key="d9">1.0</data>
      <data key="d10">Questions are generated based on the user's task</data>
      <data key="d11">1d07b4248c2655081c7af0e373bd70c9</data>
      <data key="d12">1087596b06d1400a8f863d0ac1af64a4</data>
      <data key="d13">484</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUESTIONS" target="DATASETS">
      <data key="d9">1.0</data>
      <data key="d10">Datasets were used in combination with questions for the analysis</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">39058965295643c8a7738350cc18ceac</data>
      <data key="d13">485</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUESTIONS" target="METRICS">
      <data key="d9">1.0</data>
      <data key="d10">Questions were evaluated using various metrics</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">9a8a2e5e3f2645619a0403532d935afe</data>
      <data key="d13">486</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="ZHENG ET AL.">
      <data key="d9">2.0</data>
      <data key="d10">Zheng et al. are the authors associated with the MT-Bench dataset</data>
      <data key="d11">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">f0c21c67baac47f097f74f5055b89877</data>
      <data key="d13">487</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="ZHENG, L.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. is an author of the paper that discusses MT-Bench</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">323a4c7407ac401db79a6023c3a5a17d</data>
      <data key="d13">488</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="CHIANG, W.-L.">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. is an author of the paper that discusses MT-Bench</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">686bc2bd59644e398dde88ffd37bf49b</data>
      <data key="d13">489</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="SHENG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Sheng, Y. is an author of the paper that discusses MT-Bench</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">e368f8e9c9864acc880fdb5113631f3f</data>
      <data key="d13">490</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="ZHUANG, S.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, S. is an author of the paper that discusses MT-Bench</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">05063c19ddb847a89ae1746588464288</data>
      <data key="d13">491</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="WU, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Wu, Z. is an author of the paper that discusses MT-Bench</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">019b34e800414f7b87f38a14adf2eb67</data>
      <data key="d13">492</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="ZHUANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, Y. is an author of the paper that discusses MT-Bench</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">1064a663ca4742a78e743128546f6d87</data>
      <data key="d13">493</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="LIN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Lin, Z. is an author of the paper that discusses MT-Bench</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">9a5e0a4ae34f46b39a5a028cbc135264</data>
      <data key="d13">494</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="LI, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Li, Z. is an author of the paper that discusses MT-Bench</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">5a224002ecbc4725abeb5a424aaca6a6</data>
      <data key="d13">495</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="LI, D.">
      <data key="d9">1.0</data>
      <data key="d10">Li, D. is an author of the paper that discusses MT-Bench</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">8826a17bbda34012b3ea84d58ae531eb</data>
      <data key="d13">496</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Xing, E. is an author of the paper that discusses MT-Bench</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">bab69d76defb402da2a2a358739f1497</data>
      <data key="d13">497</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MT-BENCH" target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">MT-Bench and Chatbot Arena are both tools used in the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">ea465e5cd92247829f52ff0c8591d1bb</data>
      <data key="d13">498</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DATA SENSEMAKING" target="KOESTEN ET AL.">
      <data key="d9">2.0</data>
      <data key="d10">Koesten et al. authored a paper on data sensemaking behaviors</data>
      <data key="d11">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">2dbac25b512c4f21965169a95a910a94</data>
      <data key="d13">499</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XU AND LAPATA" target="LATENT SUMMARIZATION QUERIES">
      <data key="d9">2.0</data>
      <data key="d10">Xu and Lapata authored a paper on methods for extracting latent summarization queries from source texts</data>
      <data key="d11">922778ce1cb2fdd6dbab1746c8795620</data>
      <data key="d12">97958ed004f645b1b331fa0e66faa313</data>
      <data key="d13">500</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TEXT SUMMARIZATION" target="TS">
      <data key="d9">1.0</data>
      <data key="d10">Text summarization method applies a map-reduce approach directly to source texts (TS)</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">48129b4ee99f4e30843fd4395d4815c0</data>
      <data key="d13">501</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TEXT SUMMARIZATION" target="CONDITIONS">
      <data key="d9">1.0</data>
      <data key="d10">Text summarization is one of the conditions compared in the analysis</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">6de4c00e48b3480883e696e24df9fda4</data>
      <data key="d13">502</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SEMANTIC SEARCH RAG" target="SS">
      <data key="d9">1.0</data>
      <data key="d10">Semantic search RAG is a na&#168;&#305;ve RAG approach where text chunks are retrieved and added to the context window until the token limit is reached (SS)</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">4b3d236101de4904ab348e3e3b11b4be</data>
      <data key="d13">503</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SEMANTIC SEARCH RAG" target="CONDITIONS">
      <data key="d9">1.0</data>
      <data key="d10">Semantic search RAG is one of the conditions compared in the analysis</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">5be2ce9957ba404f939b6c8175015619</data>
      <data key="d13">504</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C0" target="USER QUERIES">
      <data key="d9">1.0</data>
      <data key="d10">C0 uses root-level community summaries to answer user queries</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">fe77344850214c1cac923094de81098c</data>
      <data key="d13">505</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C0" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C0 is a category used in the analysis of news articles</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">798f739abfc14a13bf3911d0a9cfb63b</data>
      <data key="d13">506</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C0" target="PODCAST DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C0 is a category used in the analysis of the Podcast dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">3105de8188fd41d88d0dbf0a5d48e443</data>
      <data key="d13">507</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C0" target="NEWS DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C0 is a category used in the analysis of the News dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">8108dde0e62a48008a270138a690a0b9</data>
      <data key="d13">508</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C1" target="USER QUERIES">
      <data key="d9">1.0</data>
      <data key="d10">C1 uses high-level community summaries to answer user queries</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">d07207b853c14504a44eea1d4778f902</data>
      <data key="d13">509</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C1" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C1 is a category used in the analysis of news articles</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">406822a1a01a4140baf9bbf1d479f07e</data>
      <data key="d13">510</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C1" target="TS">
      <data key="d9">1.0</data>
      <data key="d10">C1 showed slight improvements in answer comprehensiveness and diversity over TS</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">fe47ba3762ae4feda39904d59cbb4160</data>
      <data key="d13">511</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C1" target="PODCAST DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C1 is a category used in the analysis of the Podcast dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">53032c2afcb5474a88446ad7c5506980</data>
      <data key="d13">512</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C1" target="NEWS DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C1 is a category used in the analysis of the News dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">5c66a88612a245cb91fbba9c094f12fc</data>
      <data key="d13">513</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C2" target="USER QUERIES">
      <data key="d9">1.0</data>
      <data key="d10">C2 uses intermediate-level community summaries to answer user queries</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">b4c54fb7ce0b4b77afd5fbe5a8a2527f</data>
      <data key="d13">514</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C2" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C2 is a category used in the analysis of news articles</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">c8b60cdb74104667b5d2b4b70d74d039</data>
      <data key="d13">515</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C2" target="TS">
      <data key="d9">1.0</data>
      <data key="d10">C2 showed slight improvements in answer comprehensiveness and diversity over TS</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">333e294d7cc34df4abc47ad9ced3d186</data>
      <data key="d13">516</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C2" target="PODCAST DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C2 is a category used in the analysis of the Podcast dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">15e66e10d12f4520abca20985d2cb39c</data>
      <data key="d13">517</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C2" target="NEWS DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C2 is a category used in the analysis of the News dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">2a271d9b5d7b46fea4046d5590eed1d7</data>
      <data key="d13">518</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C3" target="USER QUERIES">
      <data key="d9">1.0</data>
      <data key="d10">C3 uses low-level community summaries to answer user queries</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">99e372089bed4a0394af57175679f8e4</data>
      <data key="d13">519</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C3" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C3 is a category used in the analysis of news articles</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">62afe93767684ea38f861d20fb05ff71</data>
      <data key="d13">520</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C3" target="TS">
      <data key="d9">1.0</data>
      <data key="d10">C3 showed slight improvements in answer comprehensiveness and diversity over TS</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">8fc1fbff7e6c459c93ce2c2f5a62226e</data>
      <data key="d13">521</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C3" target="PODCAST DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C3 is a category used in the analysis of the Podcast dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">04b3ae04020349a9bc568f26d17eab14</data>
      <data key="d13">522</data>
      <data key="d14">1</data>
    </edge>
    <edge source="C3" target="NEWS DATASET">
      <data key="d9">1.0</data>
      <data key="d10">C3 is a category used in the analysis of the News dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">bbc4d367c60f41ad8a279c12e5cc7da6</data>
      <data key="d13">523</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TS" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">TS is a category used in the analysis of news articles</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">9a1aff251eda416ea6270e6158e663fc</data>
      <data key="d13">524</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TS" target="PODCAST DATASET">
      <data key="d9">1.0</data>
      <data key="d10">TS is a category used in the analysis of the Podcast dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">7a9e50846c274338ab09e7313b540edb</data>
      <data key="d13">525</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TS" target="NEWS DATASET">
      <data key="d9">1.0</data>
      <data key="d10">TS is a category used in the analysis of the News dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">b268cc3ef860434ba663dd46af633cc5</data>
      <data key="d13">526</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SS" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">SS is a category used in the analysis of news articles</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">1c9f67904a4c4fcc8cdac6a605900248</data>
      <data key="d13">527</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST DATASET" target="GLEANING">
      <data key="d9">1.0</data>
      <data key="d10">The graph indexing process used 1 gleaning for the Podcast dataset</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">e00c403d1dc84ba6a37ee193596e320f</data>
      <data key="d13">528</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST DATASET" target="GRAPH">
      <data key="d9">1.0</data>
      <data key="d10">A graph was created for the Podcast dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">3f2e726c3b624fe7bf11de9be2c0457e</data>
      <data key="d13">529</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST DATASET" target="UNITS">
      <data key="d9">1.0</data>
      <data key="d10">Units are used to measure the context in the Podcast dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">f71dc0c394f04771af7e2ed37f85647e</data>
      <data key="d13">530</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST DATASET" target="TOKENS">
      <data key="d9">1.0</data>
      <data key="d10">Tokens are used to measure the word count in the Podcast dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">2fea9c1856e54a91b79a9ce85755fbf5</data>
      <data key="d13">531</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST DATASET" target="% MAX">
      <data key="d9">1.0</data>
      <data key="d10">% Max is used to measure the percentage of maximum token count in the Podcast dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">7823b4c5b3364c5f890d05f33a46bdde</data>
      <data key="d13">532</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PODCAST DATASET" target="INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d9">1.0</data>
      <data key="d10">Intermediate-level summaries are derived from the Podcast dataset for analysis</data>
      <data key="d11">6f33a085ff3304e5994f7fbb86c881a4</data>
      <data key="d12">183f3a0b73ff41c5bb4a19fd7adf0c1d</data>
      <data key="d13">533</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS DATASET" target="GLEANING">
      <data key="d9">1.0</data>
      <data key="d10">The graph indexing process used 0 gleanings for the News dataset</data>
      <data key="d11">973164fa90bf2b4ee267f4fd795916bf</data>
      <data key="d12">392e06f17d724484a9cfb85fe69aac50</data>
      <data key="d13">534</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS DATASET" target="GRAPH">
      <data key="d9">1.0</data>
      <data key="d10">A graph was created for the News dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">6f49e00cdac04a358173ecd40351ee00</data>
      <data key="d13">535</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS DATASET" target="UNITS">
      <data key="d9">1.0</data>
      <data key="d10">Units are used to measure the context in the News dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">3fef96af4ec343da8c34f8b09518de8a</data>
      <data key="d13">536</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS DATASET" target="TOKENS">
      <data key="d9">1.0</data>
      <data key="d10">Tokens are used to measure the word count in the News dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">bd403eff654e42c997e5656a2b1c1a20</data>
      <data key="d13">537</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS DATASET" target="% MAX">
      <data key="d9">1.0</data>
      <data key="d10">% Max is used to measure the percentage of maximum token count in the News dataset</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">5763d829837144f199fac2b490b38110</data>
      <data key="d13">538</data>
      <data key="d14">1</data>
    </edge>
    <edge source="METRICS" target="DATASETS">
      <data key="d9">1.0</data>
      <data key="d10">Datasets were evaluated using various metrics</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">234c6f1859f0405ab607f0be53e7b06c</data>
      <data key="d13">539</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG ET AL., 2023A" target="NATURAL LANGUAGE GENERATION">
      <data key="d9">1.0</data>
      <data key="d10">Wang et al., 2023a discusses the state-of-the-art results achieved by Natural Language Generation</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">21800eab85b94d4880bcada7a60763e5</data>
      <data key="d13">540</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHENG ET AL., 2024" target="NATURAL LANGUAGE GENERATION">
      <data key="d9">1.0</data>
      <data key="d10">Zheng et al., 2024 discusses the competitive results achieved by Natural Language Generation</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">b8bb28a7a9624b6d805be89adfe29eb5</data>
      <data key="d13">541</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHENG ET AL., 2024" target="LLM-AS-A-JUDGE">
      <data key="d9">1.0</data>
      <data key="d10">Zheng et al., 2024 discusses the LLM-as-a-judge method</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">61f26f8850504d56a6b7cd764c33299d</data>
      <data key="d13">542</data>
      <data key="d14">1</data>
    </edge>
    <edge source="USER QUERIES" target="EMBEDDING-BASED MATCHING">
      <data key="d9">1.0</data>
      <data key="d10">Embedding-based matching is used to match user queries</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">d4456fac0ada4b6fbe3cfee873403d00</data>
      <data key="d13">543</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CONTEXT WINDOW SIZE" target="QUERY-TIME LLM USE">
      <data key="d9">1.0</data>
      <data key="d10">Query-time LLM use was evaluated with different context window sizes</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">f8fd3fcf650b47b2b1692506ebe77762</data>
      <data key="d13">544</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CONTEXT WINDOW SIZE" target="FINAL EVALUATION">
      <data key="d9">2.0</data>
      <data key="d10">The **CONTEXT WINDOW SIZE** and **FINAL EVALUATION** are closely related in the given data. A fixed context window size of 8k tokens was used for the final evaluation. This indicates that during the final evaluation phase, the system or model was configured to process and analyze text data within a predefined window of 8,000 tokens, ensuring consistency and standardization in the evaluation process.</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190,4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">d95acc24180c47caa34114627d501592</data>
      <data key="d13">545</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="STATE-OF-THE-ART">
      <data key="d9">1.0</data>
      <data key="d10">Natural Language Generation achieves state-of-the-art results</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">f4753ab09adc42a9a52754e95440d4b9</data>
      <data key="d13">546</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="COMPETITIVE RESULTS">
      <data key="d9">1.0</data>
      <data key="d10">Natural Language Generation achieves competitive results</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">12f5a7c56b454a3d8aae97f65908f96b</data>
      <data key="d13">547</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="HUMAN JUDGEMENTS">
      <data key="d9">1.0</data>
      <data key="d10">Natural Language Generation is compared against human judgements</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">95f79ff0b8a34080ae2ac8448ce561f1</data>
      <data key="d13">548</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="REFERENCE-BASED METRICS">
      <data key="d9">1.0</data>
      <data key="d10">Natural Language Generation can generate reference-based metrics</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">8733d4602c084e1cab1384dde0306abf</data>
      <data key="d13">549</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="REFERENCE-FREE STYLE">
      <data key="d9">1.0</data>
      <data key="d10">Natural Language Generation can measure qualities in a reference-free style</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">ded3a49efdf6479a991cad53d0758cf4</data>
      <data key="d13">550</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAGAS" target="ES ET AL., 2023">
      <data key="d9">1.0</data>
      <data key="d10">Es et al., 2023 discusses the RAGAS method</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">816fceb7e1ca4b5d9277368f78e6ed80</data>
      <data key="d13">551</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAGAS" target="CONTEXT RELEVANCE">
      <data key="d9">1.0</data>
      <data key="d10">RAGAS evaluates context relevance</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">50539d4503a4495097f49a8ed83e2462</data>
      <data key="d13">552</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAGAS" target="FAITHFULNESS">
      <data key="d9">1.0</data>
      <data key="d10">RAGAS evaluates faithfulness</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">d6f67aa7ef0e4a19bf5830e777aafea5</data>
      <data key="d13">553</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAGAS" target="ANSWER RELEVANCE">
      <data key="d9">1.0</data>
      <data key="d10">RAGAS evaluates answer relevance</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">bbf61f9cd3e14f46a010d704e86be008</data>
      <data key="d13">554</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM EVALUATOR" target="DIRECTNESS">
      <data key="d9">1.0</data>
      <data key="d10">The LLM evaluator assesses answers based on the directness metric</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">5d34e587bd2f41dba285e9178f179577</data>
      <data key="d13">555</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM EVALUATOR" target="TABLE 2">
      <data key="d9">1.0</data>
      <data key="d10">Table 2 shows an example of LLM-generated assessment</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">901b491be7344401b4544ff05e591a0e</data>
      <data key="d13">556</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM EVALUATOR" target="HEAD-TO-HEAD COMPARISON">
      <data key="d9">1.0</data>
      <data key="d10">The LLM evaluator uses a head-to-head comparison approach</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">ecacbf62b81d485396a56e1730e75a04</data>
      <data key="d13">557</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM EVALUATOR" target="TARGET METRICS">
      <data key="d9">1.0</data>
      <data key="d10">The LLM evaluator assesses answers based on target metrics</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">ba0ad1bcf02b4928a1b7ff7b23acdd6f</data>
      <data key="d13">558</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM EVALUATOR" target="CONTROL METRIC">
      <data key="d9">1.0</data>
      <data key="d10">The LLM evaluator uses a control metric for validity</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">0e3c66c25d7e43a7960c37d28315e5d8</data>
      <data key="d13">559</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM EVALUATOR" target="STOCHASTICITY">
      <data key="d9">1.0</data>
      <data key="d10">The LLM evaluator accounts for stochasticity</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">a0e0d5b7db9f4efcb5277856db799775</data>
      <data key="d13">560</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLM EVALUATOR" target="MEAN SCORES">
      <data key="d9">1.0</data>
      <data key="d10">The LLM evaluator uses mean scores from multiple comparisons</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">3f85dab93736440f9776020b6410aa9b</data>
      <data key="d13">561</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DIRECTNESS" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">Directness is used to evaluate the straightforwardness of the generated answers for news articles</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">710ed70c346342ff81ccf205e30271bb</data>
      <data key="d13">562</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QUESTION" target="PUBLIC FIGURES">
      <data key="d9">1.0</data>
      <data key="d10">The question asks about public figures mentioned in entertainment articles</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">b3d3e8ba2ede4574a0498f082f0c15ae</data>
      <data key="d13">563</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ENTERTAINMENT ARTICLES">
      <data key="d9">1.0</data>
      <data key="d10">Public figures are repeatedly mentioned across various entertainment articles</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">8686013390614eca9116ccbab27431d7</data>
      <data key="d13">564</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ANSWER 1">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 covers a wide range of public figures from different sectors of the entertainment industry.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">fd8c8b7e3b9248abb1d8cb8958ab86d3</data>
      <data key="d13">565</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ANSWER 2">
      <data key="d9">1.0</data>
      <data key="d10">Answer 2 focuses on a smaller group of public figures, primarily from the music industry and sports.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">039594428123415f95deb246f5097169</data>
      <data key="d13">566</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="CONTROVERSIES">
      <data key="d9">1.0</data>
      <data key="d10">Controversies involve public figures and impact public discourse.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">d78ce7696ff14234a544de945ffe40d6</data>
      <data key="d13">567</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="ENTERTAINMENT INDUSTRY">
      <data key="d9">1.0</data>
      <data key="d10">Entertainment articles cover topics related to the entertainment industry</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">59b21508be904875af22b5c1cfdcd211</data>
      <data key="d13">568</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="TAYLOR SWIFT">
      <data key="d9">1.0</data>
      <data key="d10">Taylor Swift is frequently mentioned in entertainment articles</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">e9c7a1d505b14229afbbef7c0d04751e</data>
      <data key="d13">569</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="TRAVIS KELCE">
      <data key="d9">1.0</data>
      <data key="d10">Travis Kelce is frequently mentioned in entertainment articles</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">4b0efcd54efc40e8a884ac6c31deada2</data>
      <data key="d13">570</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="BRITNEY SPEARS">
      <data key="d9">1.0</data>
      <data key="d10">Britney Spears is frequently mentioned in entertainment articles</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">0970f08f3d1a4d638d44e2ccb9237382</data>
      <data key="d13">571</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="JUSTIN TIMBERLAKE">
      <data key="d9">1.0</data>
      <data key="d10">Justin Timberlake is frequently mentioned in entertainment articles</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">8f10c11ecb5142029869025521c73431</data>
      <data key="d13">572</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="TAYLOR SWIFT">
      <data key="d9">1.0</data>
      <data key="d10">Taylor Swift is a significant figure in the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">e36a0e3901864a7eaa5f5ad4280a6471</data>
      <data key="d13">573</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="TRAVIS KELCE">
      <data key="d9">1.0</data>
      <data key="d10">Travis Kelce is a significant figure in the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">6fce354faa104fe58ba8a565eb3c43f2</data>
      <data key="d13">574</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="BRITNEY SPEARS">
      <data key="d9">1.0</data>
      <data key="d10">Britney Spears is a significant figure in the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">20585e9a43c04375aa334e946e2dd144</data>
      <data key="d13">575</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="JUSTIN TIMBERLAKE">
      <data key="d9">1.0</data>
      <data key="d10">Justin Timberlake is a significant figure in the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">32e343c0ae454660bdfcd1d3133baf0a</data>
      <data key="d13">576</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="ACTORS AND DIRECTORS">
      <data key="d9">1.0</data>
      <data key="d10">Actors and Directors are a category within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">505ab840f6cc4fa6a839ebfe82d255ed</data>
      <data key="d13">577</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="MUSICIANS AND EXECUTIVES">
      <data key="d9">1.0</data>
      <data key="d10">Musicians and Executives are a category within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">e38eb1698900424bb7392a74ff0f3351</data>
      <data key="d13">578</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="ATHLETES AND COACHES">
      <data key="d9">1.0</data>
      <data key="d10">Athletes and Coaches are a category within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">855c57eecf2a45c7aab02ff1ac36938d</data>
      <data key="d13">579</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="INFLUENCERS AND ENTREPRENEURS">
      <data key="d9">1.0</data>
      <data key="d10">Influencers and Entrepreneurs are a category within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">6ee77949c94d4906bd98c24341fdfa03</data>
      <data key="d13">580</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="PUBLIC FIGURES IN CONTROVERSY">
      <data key="d9">1.0</data>
      <data key="d10">Public Figures in Controversy are a category within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">d06f506604b249feb423915db282ed75</data>
      <data key="d13">581</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="FILM">
      <data key="d9">1.0</data>
      <data key="d10">Film is a sector within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">0f642f63d4af4fc38298822bfc952719</data>
      <data key="d13">582</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="TELEVISION">
      <data key="d9">1.0</data>
      <data key="d10">Television is a sector within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">e017ad1f09b049a7ad41d5a11dc1e3d9</data>
      <data key="d13">583</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="MUSIC">
      <data key="d9">1.0</data>
      <data key="d10">Music is a sector within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">5cbced0ba7044b7490f520a436261c57</data>
      <data key="d13">584</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="SPORTS">
      <data key="d9">1.0</data>
      <data key="d10">Sports is a sector within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">d45dea925f8d4e7e93d0e17317001eec</data>
      <data key="d13">585</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="DIGITAL MEDIA">
      <data key="d9">1.0</data>
      <data key="d10">Digital Media is a sector within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">8123eee04a3a4c779f03bdb85de99f9f</data>
      <data key="d13">586</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="CULTURAL NARRATIVES">
      <data key="d9">1.0</data>
      <data key="d10">Cultural Narratives are a category within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">6129d90c83194bcfaede9ff00a011297</data>
      <data key="d13">587</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="TRENDS">
      <data key="d9">1.0</data>
      <data key="d10">Trends are a category within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">6ef76e963a564dbe9c9feff4f8ce1683</data>
      <data key="d13">588</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="SOCIAL DISCUSSIONS">
      <data key="d9">1.0</data>
      <data key="d10">Social Discussions are a category within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">1c8bad73fda646f8b3f413e432f0e351</data>
      <data key="d13">589</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="PUBLIC DISCOURSE">
      <data key="d9">1.0</data>
      <data key="d10">Public Discourse is a category within the entertainment industry</data>
      <data key="d11">e8c8f911135faf3ff35f24107eb3f99c</data>
      <data key="d12">7e75749d13d24321b8b10c5be0138805</data>
      <data key="d13">590</data>
      <data key="d14">1</data>
    </edge>
    <edge source="REFERENCE-BASED METRICS" target="GOLD STANDARD ANSWERS">
      <data key="d9">1.0</data>
      <data key="d10">Reference-based metrics require gold standard answers</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">05bfaf60aa304a288e6789443bd6fd6c</data>
      <data key="d13">591</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GOLD STANDARD ANSWERS" target="SENSEMAKING QUESTIONS">
      <data key="d9">1.0</data>
      <data key="d10">Gold standard answers are lacking for sensemaking questions</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">6097e047a74d41ca996a0b7949ef6f0e</data>
      <data key="d13">592</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SENSEMAKING QUESTIONS" target="END USERS">
      <data key="d9">3.0</data>
      <data key="d10">End users play a crucial role in the validation process of sensemaking questions and target metrics. Sensemaking questions are specifically validated with end users to ensure their relevance and accuracy. This collaborative approach ensures that the questions and metrics are aligned with the needs and expectations of the end users, thereby enhancing the overall effectiveness and applicability of the sensemaking process.</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65,e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">e257439ce5be47a88faaeb0fe01bc4a1</data>
      <data key="d13">593</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TARGET METRICS" target="END USERS">
      <data key="d9">1.0</data>
      <data key="d10">Target metrics are validated with end users</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">067b9486d59f45d2963235220f723a41</data>
      <data key="d13">594</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CONTROL METRIC" target="VALIDITY">
      <data key="d9">1.0</data>
      <data key="d10">The control metric is used as an indicator of validity</data>
      <data key="d11">322e02986c8724eedbcf3ebfa20b989c</data>
      <data key="d12">87c46c7ead5447bc8309ab116a316959</data>
      <data key="d13">595</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TAYLOR SWIFT" target="ANSWER 2">
      <data key="d9">1.0</data>
      <data key="d10">Taylor Swift is one of the specific public figures mentioned in Answer 2.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">f607d795f00347109cab3b2370c414f7</data>
      <data key="d13">596</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TAYLOR SWIFT" target="MUSIC">
      <data key="d9">1.0</data>
      <data key="d10">Taylor Swift is a public figure in the music sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">8f0610c89e9f42e9b8c3d8a947fa2852</data>
      <data key="d13">597</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TRAVIS KELCE" target="ANSWER 2">
      <data key="d9">1.0</data>
      <data key="d10">Travis Kelce is one of the specific public figures mentioned in Answer 2.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">75ef3591790a49748154ddbba20e9cdf</data>
      <data key="d13">598</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TRAVIS KELCE" target="SPORTS">
      <data key="d9">1.0</data>
      <data key="d10">Travis Kelce is a public figure in the sports sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">58b7f26cb17b4b2283d3cacbaed15cfc</data>
      <data key="d13">599</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="ANSWER 2">
      <data key="d9">1.0</data>
      <data key="d10">Britney Spears is one of the specific public figures mentioned in Answer 2.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">277cdf13617e47ca883b949f495bc243</data>
      <data key="d13">600</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="MUSIC">
      <data key="d9">1.0</data>
      <data key="d10">Britney Spears is a public figure in the music sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">26080c121c9645b2bb258e4d61d47672</data>
      <data key="d13">601</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="ANSWER 2">
      <data key="d9">1.0</data>
      <data key="d10">Justin Timberlake is one of the specific public figures mentioned in Answer 2.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">ee91a06f13b4495f95c800a0c7329ef7</data>
      <data key="d13">602</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="MUSIC">
      <data key="d9">1.0</data>
      <data key="d10">Justin Timberlake is a public figure in the music sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">6ed8b67be79242e98aa1b9283431d5df</data>
      <data key="d13">603</data>
      <data key="d14">1</data>
    </edge>
    <edge source="FILM" target="ANSWER 1">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 includes public figures from the film sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">40c2425cb1c34c1591f7cb89f9f5e0bf</data>
      <data key="d13">604</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TELEVISION" target="ANSWER 1">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 includes public figures from the television sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">7cf59650687a435ba26a7c5ffc6c4f4c</data>
      <data key="d13">605</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MUSIC" target="ANSWER 1">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 includes public figures from the music sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">53c2882604b74192a649a4eaa0536c5e</data>
      <data key="d13">606</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MUSIC" target="ANSWER 2">
      <data key="d9">1.0</data>
      <data key="d10">Answer 2 focuses on public figures primarily from the music sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">3fbb8aeacea54ca9a957118fba613ccf</data>
      <data key="d13">607</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SPORTS" target="ANSWER 1">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 includes public figures from the sports sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">496ae6a894584a6cb12e50b516341788</data>
      <data key="d13">608</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SPORTS" target="ANSWER 2">
      <data key="d9">1.0</data>
      <data key="d10">Answer 2 focuses on public figures primarily from the sports sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">dd1a82c597794ba3a490cb70d488d9dd</data>
      <data key="d13">609</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DIGITAL MEDIA" target="ANSWER 1">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 includes public figures from the digital media sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">bbd206ae4c1a4794813fd239fcfef313</data>
      <data key="d13">610</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ANSWER 1" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 cites specific data sources from the News article dataset for each mentioned figure.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">708ac105e8bb4beeade0472c899f214d</data>
      <data key="d13">611</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ANSWER 1" target="CONTROVERSIES">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 provides insights into controversies involving public figures and their impact on public discourse.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">b4fe3c6aea95472db73a5e8bf575895a</data>
      <data key="d13">612</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ANSWER 1" target="GAMING">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 includes public figures from the gaming sector.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">a861f44aa7dd414790ee82b3f651c609</data>
      <data key="d13">613</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ANSWER 1" target="DATA SOURCES">
      <data key="d9">1.0</data>
      <data key="d10">Answer 1 cites specific data sources for each mentioned figure.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">add9948a221a4aabafbaaed650b1db26</data>
      <data key="d13">614</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ANSWER 2" target="NA&#207;VE RAG">
      <data key="d9">1.0</data>
      <data key="d10">Answer 2 was generated using the Na&#239;ve RAG method, which directly lists specific public figures who are repeatedly mentioned across various entertainment articles.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">6c04f2ab7c9843ea900c3444b014bed8</data>
      <data key="d13">615</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ANSWER 2" target="NEWS ARTICLE DATASET">
      <data key="d9">2.0</data>
      <data key="d10">ANSWER 2 is a generated answer for a question in the NEWS ARTICLE DATASET. It relies heavily on a single source from the NEWS ARTICLE DATASET for data.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d,ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">88356435ca9d43ebaf93134b3af8a53e</data>
      <data key="d13">616</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ANSWER 2" target="DATA SOURCES">
      <data key="d9">1.0</data>
      <data key="d10">Answer 2 relies heavily on a single data source.</data>
      <data key="d11">718017a4871c909420f84b85b8ba969d</data>
      <data key="d12">233edf428a04436a8d32849af584f9d8</data>
      <data key="d13">617</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="NEWS ARTICLE DATASET">
      <data key="d9">1.0</data>
      <data key="d10">Na&#239;ve RAG is used to generate answers for questions in the News article dataset</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">28a6317db3d141db82a4a22525265fef</data>
      <data key="d13">618</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="GLOBAL APPROACH TO GRAPH RAG">
      <data key="d9">1.0</data>
      <data key="d10">The global approach to Graph RAG shows improvements over na&#239;ve RAG</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">90051a1b69cd40f696e440d54085887e</data>
      <data key="d13">619</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLE DATASET" target="LLM-GENERATED ASSESSMENTS">
      <data key="d9">1.0</data>
      <data key="d10">LLM-generated assessments are used to evaluate the answers produced for questions in the News article dataset</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">973fe6e8a1314a269748f40a98786115</data>
      <data key="d13">620</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWS ARTICLE DATASET" target="EXAMPLE QUESTION">
      <data key="d9">1.0</data>
      <data key="d10">Example question is part of the News article dataset used for analysis</data>
      <data key="d11">ebf5249c888e07fedce6572a4c03f88c</data>
      <data key="d12">9a442a8c054d48339aff04923bafe47f</data>
      <data key="d13">621</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HEAD-TO-HEAD WIN RATE" target="CONDITION">
      <data key="d9">1.0</data>
      <data key="d10">Head-to-head win rate percentages were used to compare different conditions</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">ffdacb33c3a94b7f9d890d7cc03a1f40</data>
      <data key="d13">622</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CONDITION" target="WIN RATE">
      <data key="d9">1.0</data>
      <data key="d10">Win rate percentages were used to measure the performance of different conditions</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">8792fc245cc94235a7764481ebad4828</data>
      <data key="d13">623</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CONDITION" target="OVERALL WINNER">
      <data key="d9">1.0</data>
      <data key="d10">The overall winner per dataset and metric was determined for each condition</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">b5982d09c32e4e7387e88f9160b4dd78</data>
      <data key="d13">624</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CONDITION" target="SELF-WIN RATE">
      <data key="d9">1.0</data>
      <data key="d10">Self-win rates were shown as the expected 50% for each condition</data>
      <data key="d11">4c855404ee3d3c94aa2136f1513c666f</data>
      <data key="d12">04ed223f57e44cf18284ba42ba760423</data>
      <data key="d13">625</data>
      <data key="d14">1</data>
    </edge>
    <edge source="INDEXING PROCESS" target="GRAPH">
      <data key="d9">1.0</data>
      <data key="d10">The indexing process resulted in the creation of graphs</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">0debfb49a28d480db1b7d5ef713cac8f</data>
      <data key="d13">626</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOKENS" target="MAP-REDUCE SUMMARIZATION">
      <data key="d9">1.0</data>
      <data key="d10">Map-reduce summarization requires the highest number of context tokens</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">1f9abc7d006f4afa86200385acc3d1ae</data>
      <data key="d13">627</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOKENS" target="ROOT-LEVEL COMMUNITY SUMMARIES">
      <data key="d9">1.0</data>
      <data key="d10">Root-level community summaries require dramatically fewer tokens per query</data>
      <data key="d11">36db32c37e1987e2c5863898ad882190</data>
      <data key="d12">cac3f76fbc11413e92cdfd3064d56ece</data>
      <data key="d13">628</data>
      <data key="d14">1</data>
    </edge>
    <edge source="VECTOR SPACE" target="QUERIES">
      <data key="d9">2.0</data>
      <data key="d10">Queries are embedded into the same vector space as text chunks to find relevant context</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">f120d98b793a4276a6f1a0a8e51a589a</data>
      <data key="d13">629</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SELF-MEMORY (SELFMEM)" target="GENERATION-AUGMENTED RETRIEVAL (GAR)">
      <data key="d9">2.0</data>
      <data key="d10">Self-memory is related to generation-augmented retrieval</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">bfda4c94278b49ab98cd3f407980d4d8</data>
      <data key="d13">630</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTI-DOCUMENT SUMMARIZATION" target="MULTI-DOCUMENT SUMMARIZATION (CAIRE-COVID)">
      <data key="d9">2.0</data>
      <data key="d10">CAiRE-COVID is a system for multi-document summarization</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">7e5e5b80b84749d98cb36f56dbfcb47b</data>
      <data key="d13">631</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTI-HOP QUESTION ANSWERING" target="MULTI-HOP QUESTION ANSWERING (ITRG)">
      <data key="d9">2.0</data>
      <data key="d10">ITRG is a system for multi-hop question answering</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">6330604339ca4113b94624bc9bed5ede</data>
      <data key="d13">632</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTI-HOP QUESTION ANSWERING" target="MULTI-HOP QUESTION ANSWERING (IR-COT)">
      <data key="d9">2.0</data>
      <data key="d10">IR-CoT is a system for multi-hop question answering</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">9638492c4f034be6b3bf88f8abd82edc</data>
      <data key="d13">633</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MULTI-HOP QUESTION ANSWERING" target="MULTI-HOP QUESTION ANSWERING (DSP)">
      <data key="d9">2.0</data>
      <data key="d10">DSP is a system for multi-hop question answering</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">a76322b81f644f3c8733d04fa046b4e4</data>
      <data key="d13">634</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HIERARCHICAL INDEX" target="RAPTOR">
      <data key="d9">2.0</data>
      <data key="d10">RAPTOR is a method for generating a hierarchical index</data>
      <data key="d11">f35de4d9fb65f1d5a392064b20545c19</data>
      <data key="d12">653ee6584dbc46d1b8e97a05a3eac81e</data>
      <data key="d13">635</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KAPING" target="BAEK ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Baek et al. discusses the KAPING method</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">9f0d58a479ec404d8e8f493f9269b08d</data>
      <data key="d13">636</data>
      <data key="d14">1</data>
    </edge>
    <edge source="G-RETRIEVER" target="HE ET AL., 2024">
      <data key="d9">2.0</data>
      <data key="d10">The paper by He et al. discusses the G-Retriever method</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">c5ae09d00a3f417981fc4177ef333eff</data>
      <data key="d13">637</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GRAPH-TOOLFORMER" target="ZHANG, 2023">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Zhang discusses the Graph-ToolFormer method</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">4dd086fcba704d26b976c08a81c1465c</data>
      <data key="d13">638</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SURGE" target="KANG ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Kang et al. discusses the SURGE method</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">f1ef6375ea84496eaed13c03318d80c6</data>
      <data key="d13">639</data>
      <data key="d14">1</data>
    </edge>
    <edge source="FABULA" target="RANADE AND JOSHI, 2023">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Ranade and Joshi discusses the FABULA method</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">ba6829116d114532b99530f101ff0c72</data>
      <data key="d13">640</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LANGCHAIN" target="LLAMAINDEX">
      <data key="d9">2.0</data>
      <data key="d10">Both LangChain and LlamaIndex support a variety of graph databases</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">1ab2048463174873883061373d480ac4</data>
      <data key="d13">641</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LANGCHAIN" target="NEO4J">
      <data key="d9">2.0</data>
      <data key="d10">LangChain supports graph databases in Neo4J format</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">97038fe907af4710859c3daeb13972e9</data>
      <data key="d13">642</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LANGCHAIN" target="NEBULAGRAPH">
      <data key="d9">2.0</data>
      <data key="d10">LangChain supports graph databases in NebulaGraph format</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">e0595082eb9f41a4ac2afd9e614b363c</data>
      <data key="d13">643</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LANGCHAIN" target="LANGCHAIN GRAPHS">
      <data key="d9">1.0</data>
      <data key="d10">LangChain developed Langchain graphs</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">5bd2ef268d4f4ba18925c17242370e21</data>
      <data key="d13">644</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLAMAINDEX" target="NEO4J">
      <data key="d9">2.0</data>
      <data key="d10">LlamaIndex supports graph databases in Neo4J format</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">96a21e764d1143fc90de0b2cc7751983</data>
      <data key="d13">645</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LLAMAINDEX" target="NEBULAGRAPH">
      <data key="d9">2.0</data>
      <data key="d10">LlamaIndex supports graph databases in NebulaGraph format</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">801b7142ab5b4c5eac41dade999a7c1f</data>
      <data key="d13">646</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEO4J" target="NALLM">
      <data key="d9">2.0</data>
      <data key="d10">NaLLM is a method that can create and reason over knowledge graphs in Neo4J format</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">aac39de4e7e74d1c83f0eb835e635c88</data>
      <data key="d13">647</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEO4J" target="PROJECT NALLM">
      <data key="d9">2.0</data>
      <data key="d10">Neo4J developed Project NaLLM</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">c2e801c8221c4806a4f59ba5b793c784</data>
      <data key="d13">648</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEBULAGRAPH" target="GRAPHRAG">
      <data key="d9">2.0</data>
      <data key="d10">GraphRAG is a method that can create and reason over knowledge graphs in NebulaGraph format</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">351fc21986564103b324540289e2e608</data>
      <data key="d13">649</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SELFCHECKGPT" target="MANAKUL ET AL., 2023">
      <data key="d9">2.0</data>
      <data key="d10">The paper by Manakul et al. discusses the SelfCheckGPT method</data>
      <data key="d11">92e93fc6449756c0a60200636b297f65</data>
      <data key="d12">1c8a90b0aed7439286bbf85903d423d4</data>
      <data key="d13">650</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MANAKUL ET AL., 2023" target="SELFHECKGPT">
      <data key="d9">1.0</data>
      <data key="d10">SelfCheckGPT is an approach mentioned in the work by Manakul et al., 2023</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">6c98609312154f118c04d8781663b16a</data>
      <data key="d13">651</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SELFHECKGPT" target="FABRICATION RATES">
      <data key="d9">1.0</data>
      <data key="d10">SelfCheckGPT is used to compare fabrication rates</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">b91a6bf16e334b3ab7ec57665e980ceb</data>
      <data key="d13">652</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EMBEDDING-BASED MATCHING" target="GRAPH ANNOTATIONS">
      <data key="d9">1.0</data>
      <data key="d10">Embedding-based matching is used to match user queries with graph annotations</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">c067e41adf9840df89052b111e6c0a6a</data>
      <data key="d13">653</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HYBRID RAG SCHEMES" target="COMMUNITY REPORTS">
      <data key="d9">1.0</data>
      <data key="d10">Hybrid RAG schemes combine embedding-based matching against community reports</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">76d7feb8140b4064b5492d3055736ee0</data>
      <data key="d13">654</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MAP-REDUCE SUMMARIZATION MECHANISMS" target="ROLL-UP OPERATION">
      <data key="d9">1.0</data>
      <data key="d10">The roll-up operation can be extended using map-reduce summarization mechanisms</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">53273797509d45178c49045830ec9fc2</data>
      <data key="d13">655</data>
      <data key="d14">1</data>
    </edge>
    <edge source="COMMUNITY HIERARCHY" target="DRILL DOWN MECHANISM">
      <data key="d9">1.0</data>
      <data key="d10">The drill down mechanism follows the information scent in the community hierarchy</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">2383fd3c3b4a4249a5a96550c494edb2</data>
      <data key="d13">656</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GLOBAL APPROACH TO GRAPH RAG" target="TOKEN COST">
      <data key="d9">1.0</data>
      <data key="d10">The global approach to Graph RAG achieves competitive performance at a fraction of the token cost</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">29f172df150042e0a6db5481d5d91cfc</data>
      <data key="d13">657</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PYTHON-BASED IMPLEMENTATION" target="OPEN-SOURCE IMPLEMENTATION">
      <data key="d9">1.0</data>
      <data key="d10">The open-source implementation of Graph RAG approaches is Python-based</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">a243935f440241a281fbabb20422c641</data>
      <data key="d13">658</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DRILL DOWN MECHANISM" target="INFORMATION SCENT">
      <data key="d9">1.0</data>
      <data key="d10">The drill down mechanism follows the information scent</data>
      <data key="d11">e4d9b12cf2b4c691c74019eefff4fb39</data>
      <data key="d12">34b704124fe94c2f933a344c11165f2e</data>
      <data key="d13">659</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="AMBER HOAK">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Amber Hoak both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">e429a497b01c40f3aef7e2205eaf01d8</data>
      <data key="d13">660</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Andr&#233;s Morales Esquivel both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">f521933b91564693b07bd838160083ac</data>
      <data key="d13">661</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="BEN CUTLER">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Ben Cutler both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">e0d361b6991b40debf5599e86f2638ca</data>
      <data key="d13">662</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="BILLIE RINALDI">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Billie Rinaldi both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">cf16005cfadf4e48832ffd0e43f57be1</data>
      <data key="d13">663</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="CHRIS SANCHEZ">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Chris Sanchez both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">db10b0e690754748b0d75639f3e8d2b8</data>
      <data key="d13">664</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="CHRIS TREVINO">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Chris Trevino both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">ec13b80209e246588bb5486d516f85eb</data>
      <data key="d13">665</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="CHRISTINE CAGGIANO">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Christine Caggiano both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">617a76d54ed546e29428a31dea955b96</data>
      <data key="d13">666</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="DAVID TITTSWORTH">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and David Tittsworth both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">c88ffd2aa7284ac38eb4351c5fad6f44</data>
      <data key="d13">667</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="DAYENNE DE SOUZA">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Dayenne de Souza both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">0dace3b24df14aae909a2815653e9db1</data>
      <data key="d13">668</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="DOUGLAS ORBAKER">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Douglas Orbaker both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">b3cfde857302479aa59b91d6648a40df</data>
      <data key="d13">669</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="ED CLARK">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Ed Clark both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">01a52a986b6a444badc83fb11aa7a160</data>
      <data key="d13">670</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="GABRIEL NIEVES-PONCE">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Gabriel Nieves-Ponce both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">2516b3485b754bdabf6820863c918e3d</data>
      <data key="d13">671</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="GAUDY BLANCO MENESES">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Gaudy Blanco Meneses both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">0523ed6330f4429f8468f5b49169c940</data>
      <data key="d13">672</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="KATE LYTVYNETS">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Kate Lytvynets both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">0b7ac591dfd34971b24d38e344b40c37</data>
      <data key="d13">673</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="KATY SMITH">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Katy Smith both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">2864f68297e94d7e84213833e22da077</data>
      <data key="d13">674</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="M&#211;NICA CARVAJAL">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and M&#243;nica Carvajal both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">629cd969d05c4c329bbe24f5d86e0089</data>
      <data key="d13">675</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="NATHAN EVANS">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Nathan Evans both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">f7bc5d1fb1404acdb77d50a6b9129141</data>
      <data key="d13">676</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="RICHARD ORTEGA">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Richard Ortega both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">d47535a52c2b40a3bacb3d520b8f0f1c</data>
      <data key="d13">677</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="RODRIGO RACANICCI">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Rodrigo Racanicci both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">557ed8720c2845cabcce0287f7284b3e</data>
      <data key="d13">678</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="SARAH SMITH">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Sarah Smith both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">cef8ff96a0e842fdae4751933bcb1a28</data>
      <data key="d13">679</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="SHANE SOLOMON">
      <data key="d9">1.0</data>
      <data key="d10">Alonso Guevara Fern&#225;ndez and Shane Solomon both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">93c8356953da486e9630d7e7304a6ff3</data>
      <data key="d13">680</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Andr&#233;s Morales Esquivel both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">dc52f3641c1548bba5b3cf8c65a5c072</data>
      <data key="d13">681</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="BEN CUTLER">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Ben Cutler both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">d0fdcc6945d84b20aa1de4afe2786592</data>
      <data key="d13">682</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="BILLIE RINALDI">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Billie Rinaldi both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">af6e03260c5946be96737b148b5edd9d</data>
      <data key="d13">683</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="CHRIS SANCHEZ">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Chris Sanchez both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">1949eb874c544c58a71bbd04d6241a22</data>
      <data key="d13">684</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="CHRIS TREVINO">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Chris Trevino both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">09384ed4453846cb8c4d0076ecbf928a</data>
      <data key="d13">685</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="CHRISTINE CAGGIANO">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Christine Caggiano both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">181833ae880a4d0ab24ba0ccb158138d</data>
      <data key="d13">686</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="DAVID TITTSWORTH">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and David Tittsworth both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">3426a7ea02f740aeabcb552feee11bcc</data>
      <data key="d13">687</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="DAYENNE DE SOUZA">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Dayenne de Souza both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">e47ae0eea85b4f6e86b77fe56396460e</data>
      <data key="d13">688</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="DOUGLAS ORBAKER">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Douglas Orbaker both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">1ad7e0ad19334488b5d3b008f93a4ef4</data>
      <data key="d13">689</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="ED CLARK">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Ed Clark both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">8c76a8cb5951422ba3b3cc6fcb66a391</data>
      <data key="d13">690</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="GABRIEL NIEVES-PONCE">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Gabriel Nieves-Ponce both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">096dee591c1f4141a73fd628a59ffbe9</data>
      <data key="d13">691</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="GAUDY BLANCO MENESES">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Gaudy Blanco Meneses both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">9886a385806e46a69d92a726017b99b6</data>
      <data key="d13">692</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="KATE LYTVYNETS">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Kate Lytvynets both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">4ecf891e9a5b4daf9e02d5b2ec963079</data>
      <data key="d13">693</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="KATY SMITH">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Katy Smith both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">59207227178147e39296a4059ac1055d</data>
      <data key="d13">694</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="M&#211;NICA CARVAJAL">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and M&#243;nica Carvajal both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">0682e47ed49146c0bc5e2b77fb924b6c</data>
      <data key="d13">695</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="NATHAN EVANS">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Nathan Evans both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">6022e4aa784f42b88dbcb27a5d9d2614</data>
      <data key="d13">696</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="RICHARD ORTEGA">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Richard Ortega both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">386047cff59549ea83158b69bbac1870</data>
      <data key="d13">697</data>
      <data key="d14">1</data>
    </edge>
    <edge source="AMBER HOAK" target="RODRIGO RACANICCI">
      <data key="d9">1.0</data>
      <data key="d10">Amber Hoak and Rodrigo Racanicci both contributed to the work acknowledged in the document</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">2ead31e49ce643ebae4d5f047bb7a37b</data>
      <data key="d13">698</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ACHIAM" target="S. ADLER">
      <data key="d9">1.0</data>
      <data key="d10">J. Achiam and S. Adler co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">a74ee5b02e1e41b0ac4cf5449f7cdf2c</data>
      <data key="d13">699</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ACHIAM" target="S. AGARWAL">
      <data key="d9">1.0</data>
      <data key="d10">J. Achiam and S. Agarwal co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">0f73fcdab31348a880a468124099071c</data>
      <data key="d13">700</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ACHIAM" target="L. AHMAD">
      <data key="d9">1.0</data>
      <data key="d10">J. Achiam and L. Ahmad co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">24d2dcb7f28144cbad714b0a8b6c9e70</data>
      <data key="d13">701</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ACHIAM" target="I. AKKAYA">
      <data key="d9">1.0</data>
      <data key="d10">J. Achiam and I. Akkaya co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">093447e0342e490aa6a55bd70ce7c2f2</data>
      <data key="d13">702</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ACHIAM" target="F. L. ALEMAN">
      <data key="d9">1.0</data>
      <data key="d10">J. Achiam and F. L. Aleman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">0439db7ac7d2484596e02246bd340424</data>
      <data key="d13">703</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ACHIAM" target="D. ALMEIDA">
      <data key="d9">1.0</data>
      <data key="d10">J. Achiam and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">81ffef86ebb341bebf145c742fb33dbd</data>
      <data key="d13">704</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ACHIAM" target="J. ALTENSCHMIDT">
      <data key="d9">1.0</data>
      <data key="d10">J. Achiam and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">a0da2872126f43769f75c8533fca5e26</data>
      <data key="d13">705</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ACHIAM" target="S. ALTMAN">
      <data key="d9">1.0</data>
      <data key="d10">J. Achiam and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">7facdc1f91014f42a67e34bac31a95ce</data>
      <data key="d13">706</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ACHIAM" target="S. ANADKAT">
      <data key="d9">1.0</data>
      <data key="d10">J. Achiam and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">ca7a635373294067b5f3050c82d38983</data>
      <data key="d13">707</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. ADLER" target="S. AGARWAL">
      <data key="d9">1.0</data>
      <data key="d10">S. Adler and S. Agarwal co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">2833c46f05984f729c7ec15e071f0c8e</data>
      <data key="d13">708</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. ADLER" target="L. AHMAD">
      <data key="d9">1.0</data>
      <data key="d10">S. Adler and L. Ahmad co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">ada7cf1171b74ad793f7856febc9c6fe</data>
      <data key="d13">709</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. ADLER" target="I. AKKAYA">
      <data key="d9">1.0</data>
      <data key="d10">S. Adler and I. Akkaya co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">33b355c0a8044ef2b2b8be81bea0d431</data>
      <data key="d13">710</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. ADLER" target="F. L. ALEMAN">
      <data key="d9">1.0</data>
      <data key="d10">S. Adler and F. L. Aleman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">85698526e09a47878e3255a251d95406</data>
      <data key="d13">711</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. ADLER" target="D. ALMEIDA">
      <data key="d9">1.0</data>
      <data key="d10">S. Adler and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">1a625c51e7ad497b86041757d1cde642</data>
      <data key="d13">712</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. ADLER" target="J. ALTENSCHMIDT">
      <data key="d9">1.0</data>
      <data key="d10">S. Adler and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">df91c0e5657a4bafa849c8a3079ca582</data>
      <data key="d13">713</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. ADLER" target="S. ALTMAN">
      <data key="d9">1.0</data>
      <data key="d10">S. Adler and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">091a9788b29443509feda24aa5f5c241</data>
      <data key="d13">714</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. ADLER" target="S. ANADKAT">
      <data key="d9">1.0</data>
      <data key="d10">S. Adler and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">6f750deaedcb4612b419c3d8dd7e5cb2</data>
      <data key="d13">715</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. AGARWAL" target="L. AHMAD">
      <data key="d9">1.0</data>
      <data key="d10">S. Agarwal and L. Ahmad co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">d5ea3f061e9c419fb1c07b680bfb287a</data>
      <data key="d13">716</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. AGARWAL" target="I. AKKAYA">
      <data key="d9">1.0</data>
      <data key="d10">S. Agarwal and I. Akkaya co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">1f4fd98283df43c69d5537c002b98f58</data>
      <data key="d13">717</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. AGARWAL" target="F. L. ALEMAN">
      <data key="d9">1.0</data>
      <data key="d10">S. Agarwal and F. L. Aleman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">f3bb299bf6454785a8a406dce9776789</data>
      <data key="d13">718</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. AGARWAL" target="D. ALMEIDA">
      <data key="d9">1.0</data>
      <data key="d10">S. Agarwal and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">218d3d5a4a544df99caed612e48add5b</data>
      <data key="d13">719</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. AGARWAL" target="J. ALTENSCHMIDT">
      <data key="d9">1.0</data>
      <data key="d10">S. Agarwal and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">02393af06d3649549b3e9290b4e46c0a</data>
      <data key="d13">720</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. AGARWAL" target="S. ALTMAN">
      <data key="d9">1.0</data>
      <data key="d10">S. Agarwal and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">ffa9208f15744978a4ea45c1cff18a86</data>
      <data key="d13">721</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. AGARWAL" target="S. ANADKAT">
      <data key="d9">1.0</data>
      <data key="d10">S. Agarwal and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">23ea2a1d78984eb38721adeadee662e1</data>
      <data key="d13">722</data>
      <data key="d14">1</data>
    </edge>
    <edge source="L. AHMAD" target="I. AKKAYA">
      <data key="d9">1.0</data>
      <data key="d10">L. Ahmad and I. Akkaya co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">0d0a729e30634e1fb198609ce10c69bf</data>
      <data key="d13">723</data>
      <data key="d14">1</data>
    </edge>
    <edge source="L. AHMAD" target="F. L. ALEMAN">
      <data key="d9">1.0</data>
      <data key="d10">L. Ahmad and F. L. Aleman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">896e7d03cad7450e8044fcb0fd9f6e92</data>
      <data key="d13">724</data>
      <data key="d14">1</data>
    </edge>
    <edge source="L. AHMAD" target="D. ALMEIDA">
      <data key="d9">1.0</data>
      <data key="d10">L. Ahmad and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">a777a0c3a34b4990899f2e1e1f1c2074</data>
      <data key="d13">725</data>
      <data key="d14">1</data>
    </edge>
    <edge source="L. AHMAD" target="J. ALTENSCHMIDT">
      <data key="d9">1.0</data>
      <data key="d10">L. Ahmad and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">6cd46299702049bcbd39407fa97f0dc0</data>
      <data key="d13">726</data>
      <data key="d14">1</data>
    </edge>
    <edge source="L. AHMAD" target="S. ALTMAN">
      <data key="d9">1.0</data>
      <data key="d10">L. Ahmad and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">7af01185ebd648e49bf9a57481e0dc7c</data>
      <data key="d13">727</data>
      <data key="d14">1</data>
    </edge>
    <edge source="L. AHMAD" target="S. ANADKAT">
      <data key="d9">1.0</data>
      <data key="d10">L. Ahmad and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">d6aad3495b4d4c7ab2a03c44600584ba</data>
      <data key="d13">728</data>
      <data key="d14">1</data>
    </edge>
    <edge source="I. AKKAYA" target="F. L. ALEMAN">
      <data key="d9">1.0</data>
      <data key="d10">I. Akkaya and F. L. Aleman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">482d5ecf4ce949e9a5d81f1b368769ee</data>
      <data key="d13">729</data>
      <data key="d14">1</data>
    </edge>
    <edge source="I. AKKAYA" target="D. ALMEIDA">
      <data key="d9">1.0</data>
      <data key="d10">I. Akkaya and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">64f7a02f89bd4a37844c482f00d00643</data>
      <data key="d13">730</data>
      <data key="d14">1</data>
    </edge>
    <edge source="I. AKKAYA" target="J. ALTENSCHMIDT">
      <data key="d9">1.0</data>
      <data key="d10">I. Akkaya and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">26609be86d614d85ae97deeae4a4be1e</data>
      <data key="d13">731</data>
      <data key="d14">1</data>
    </edge>
    <edge source="I. AKKAYA" target="S. ALTMAN">
      <data key="d9">1.0</data>
      <data key="d10">I. Akkaya and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">5dffe69693734eaeb360de4582d489b0</data>
      <data key="d13">732</data>
      <data key="d14">1</data>
    </edge>
    <edge source="I. AKKAYA" target="S. ANADKAT">
      <data key="d9">1.0</data>
      <data key="d10">I. Akkaya and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">e4fe96090a7641c68d0b1995d1f238b4</data>
      <data key="d13">733</data>
      <data key="d14">1</data>
    </edge>
    <edge source="F. L. ALEMAN" target="D. ALMEIDA">
      <data key="d9">1.0</data>
      <data key="d10">F. L. Aleman and D. Almeida co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">3fa1055cd26840678d546570e8b423d9</data>
      <data key="d13">734</data>
      <data key="d14">1</data>
    </edge>
    <edge source="F. L. ALEMAN" target="J. ALTENSCHMIDT">
      <data key="d9">1.0</data>
      <data key="d10">F. L. Aleman and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">9802dae4757b42269e93c66b5214a396</data>
      <data key="d13">735</data>
      <data key="d14">1</data>
    </edge>
    <edge source="F. L. ALEMAN" target="S. ALTMAN">
      <data key="d9">1.0</data>
      <data key="d10">F. L. Aleman and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">c39e66acec274a5980ce275709a847ba</data>
      <data key="d13">736</data>
      <data key="d14">1</data>
    </edge>
    <edge source="F. L. ALEMAN" target="S. ANADKAT">
      <data key="d9">1.0</data>
      <data key="d10">F. L. Aleman and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">667794d1397a40bb904d406205960864</data>
      <data key="d13">737</data>
      <data key="d14">1</data>
    </edge>
    <edge source="D. ALMEIDA" target="J. ALTENSCHMIDT">
      <data key="d9">1.0</data>
      <data key="d10">D. Almeida and J. Altenschmidt co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">891f50162c0140e4b9c0e4ba33f69a1b</data>
      <data key="d13">738</data>
      <data key="d14">1</data>
    </edge>
    <edge source="D. ALMEIDA" target="S. ALTMAN">
      <data key="d9">1.0</data>
      <data key="d10">D. Almeida and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">922773e5841a475d89d5904fe7a324f8</data>
      <data key="d13">739</data>
      <data key="d14">1</data>
    </edge>
    <edge source="D. ALMEIDA" target="S. ANADKAT">
      <data key="d9">1.0</data>
      <data key="d10">D. Almeida and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">0338bebae19c41c196ee6c09ccba36e3</data>
      <data key="d13">740</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ALTENSCHMIDT" target="S. ALTMAN">
      <data key="d9">1.0</data>
      <data key="d10">J. Altenschmidt and S. Altman co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">0b407647077c4288b2324f06ac355985</data>
      <data key="d13">741</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. ALTENSCHMIDT" target="S. ANADKAT">
      <data key="d9">1.0</data>
      <data key="d10">J. Altenschmidt and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">4e9254fd4b234106843cf8ff91fd3b6f</data>
      <data key="d13">742</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. ALTMAN" target="S. ANADKAT">
      <data key="d9">1.0</data>
      <data key="d10">S. Altman and S. Anadkat co-authored the GPT-4 technical report</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">e6a7f4ccd6f54136b784572db0d5cb88</data>
      <data key="d13">743</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. ANIL" target="S. BORGEAUD">
      <data key="d9">1.0</data>
      <data key="d10">R. Anil and S. Borgeaud co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">ccf54360ef954353b71c1c8175cd7f4e</data>
      <data key="d13">744</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. ANIL" target="Y. WU">
      <data key="d9">1.0</data>
      <data key="d10">R. Anil and Y. Wu co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">bd1c72f46b81427892b1f415fecce77e</data>
      <data key="d13">745</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. ANIL" target="J.-B. ALAYRAC">
      <data key="d9">1.0</data>
      <data key="d10">R. Anil and J.-B. Alayrac co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">148e7caecdf740e58ee09a9ff549d19c</data>
      <data key="d13">746</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. ANIL" target="J. YU">
      <data key="d9">1.0</data>
      <data key="d10">R. Anil and J. Yu co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">df78f3e3415a4d47b6dffdd3890f3eee</data>
      <data key="d13">747</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. ANIL" target="R. SORICUT">
      <data key="d9">1.0</data>
      <data key="d10">R. Anil and R. Soricut co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">003abb3c5743482aa63022cf20cf5ccc</data>
      <data key="d13">748</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. ANIL" target="J. SCHALKWYK">
      <data key="d9">1.0</data>
      <data key="d10">R. Anil and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">4788433078b843079ccd9a64e5430169</data>
      <data key="d13">749</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. ANIL" target="A. M. DAI">
      <data key="d9">1.0</data>
      <data key="d10">R. Anil and A. M. Dai co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">cbecfdbc04c9405aa139566d727d3a33</data>
      <data key="d13">750</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. ANIL" target="A. HAUTH">
      <data key="d9">1.0</data>
      <data key="d10">R. Anil and A. Hauth co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">f514a867efb948868009b435fecbe372</data>
      <data key="d13">751</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. BORGEAUD" target="Y. WU">
      <data key="d9">1.0</data>
      <data key="d10">S. Borgeaud and Y. Wu co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">6e4c8a7f1da147f5b38103c51c999502</data>
      <data key="d13">752</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. BORGEAUD" target="J.-B. ALAYRAC">
      <data key="d9">1.0</data>
      <data key="d10">S. Borgeaud and J.-B. Alayrac co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">ac0e52b6b3ae4cc485f9eef2f2dea7e7</data>
      <data key="d13">753</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. BORGEAUD" target="J. YU">
      <data key="d9">1.0</data>
      <data key="d10">S. Borgeaud and J. Yu co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">b150af2f3df24f17a7fd836ba663680a</data>
      <data key="d13">754</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. BORGEAUD" target="R. SORICUT">
      <data key="d9">1.0</data>
      <data key="d10">S. Borgeaud and R. Soricut co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">f9740be4adc946149b5941f355d45c74</data>
      <data key="d13">755</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. BORGEAUD" target="J. SCHALKWYK">
      <data key="d9">1.0</data>
      <data key="d10">S. Borgeaud and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">c6afe51b28f94c3ba21640387edd2ee8</data>
      <data key="d13">756</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. BORGEAUD" target="A. M. DAI">
      <data key="d9">1.0</data>
      <data key="d10">S. Borgeaud and A. M. Dai co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">040b86f496dc4930a895f2c21cb0731c</data>
      <data key="d13">757</data>
      <data key="d14">1</data>
    </edge>
    <edge source="S. BORGEAUD" target="A. HAUTH">
      <data key="d9">1.0</data>
      <data key="d10">S. Borgeaud and A. Hauth co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">e13ed464574f483c9f1db5f569e91445</data>
      <data key="d13">758</data>
      <data key="d14">1</data>
    </edge>
    <edge source="Y. WU" target="J.-B. ALAYRAC">
      <data key="d9">1.0</data>
      <data key="d10">Y. Wu and J.-B. Alayrac co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">e1131985dc53451fa7543912b2e7db07</data>
      <data key="d13">759</data>
      <data key="d14">1</data>
    </edge>
    <edge source="Y. WU" target="J. YU">
      <data key="d9">1.0</data>
      <data key="d10">Y. Wu and J. Yu co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">d6c00e0a975e4adc979afd25d4037d4d</data>
      <data key="d13">760</data>
      <data key="d14">1</data>
    </edge>
    <edge source="Y. WU" target="R. SORICUT">
      <data key="d9">1.0</data>
      <data key="d10">Y. Wu and R. Soricut co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">9cac1113be2148ce8abaa957620f9d59</data>
      <data key="d13">761</data>
      <data key="d14">1</data>
    </edge>
    <edge source="Y. WU" target="J. SCHALKWYK">
      <data key="d9">1.0</data>
      <data key="d10">Y. Wu and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">c277297e3e7b417892e986c8767f58ad</data>
      <data key="d13">762</data>
      <data key="d14">1</data>
    </edge>
    <edge source="Y. WU" target="A. M. DAI">
      <data key="d9">1.0</data>
      <data key="d10">Y. Wu and A. M. Dai co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">744f492f46d841c0b0fee5f4a9b40b6c</data>
      <data key="d13">763</data>
      <data key="d14">1</data>
    </edge>
    <edge source="Y. WU" target="A. HAUTH">
      <data key="d9">1.0</data>
      <data key="d10">Y. Wu and A. Hauth co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">d59386dbfa0349b49f7b904e288b21ad</data>
      <data key="d13">764</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J.-B. ALAYRAC" target="J. YU">
      <data key="d9">1.0</data>
      <data key="d10">J.-B. Alayrac and J. Yu co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">1005971b7e764bffa0a4610ad403976b</data>
      <data key="d13">765</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J.-B. ALAYRAC" target="R. SORICUT">
      <data key="d9">1.0</data>
      <data key="d10">J.-B. Alayrac and R. Soricut co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">1eaf3527e2804c75bbd9e3ccac9d760e</data>
      <data key="d13">766</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J.-B. ALAYRAC" target="J. SCHALKWYK">
      <data key="d9">1.0</data>
      <data key="d10">J.-B. Alayrac and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">301ab7b5f81d40788e46dacb09579b50</data>
      <data key="d13">767</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J.-B. ALAYRAC" target="A. M. DAI">
      <data key="d9">1.0</data>
      <data key="d10">J.-B. Alayrac and A. M. Dai co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">d6f25f03a08b41b4a2eaa9df3db9dceb</data>
      <data key="d13">768</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J.-B. ALAYRAC" target="A. HAUTH">
      <data key="d9">1.0</data>
      <data key="d10">J.-B. Alayrac and A. Hauth co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">6529cf63872440a98aeab73beee3762a</data>
      <data key="d13">769</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. YU" target="R. SORICUT">
      <data key="d9">1.0</data>
      <data key="d10">J. Yu and R. Soricut co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">65faae6c13f5444b8d71b4b2be38eba3</data>
      <data key="d13">770</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. YU" target="J. SCHALKWYK">
      <data key="d9">1.0</data>
      <data key="d10">J. Yu and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">9187af05545a4c8d92e38c2b46254092</data>
      <data key="d13">771</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. YU" target="A. M. DAI">
      <data key="d9">1.0</data>
      <data key="d10">J. Yu and A. M. Dai co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">f12578d1ff7b46f5ae84c7672fac8deb</data>
      <data key="d13">772</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. YU" target="A. HAUTH">
      <data key="d9">1.0</data>
      <data key="d10">J. Yu and A. Hauth co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">6b5c42bba0ec48c1a5de177a7f1b9bfc</data>
      <data key="d13">773</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. SORICUT" target="J. SCHALKWYK">
      <data key="d9">1.0</data>
      <data key="d10">R. Soricut and J. Schalkwyk co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">444ab529d10c47f19ef33e931489b8b8</data>
      <data key="d13">774</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. SORICUT" target="A. M. DAI">
      <data key="d9">1.0</data>
      <data key="d10">R. Soricut and A. M. Dai co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">0ffea4c3c86849ab828036b67b58acdc</data>
      <data key="d13">775</data>
      <data key="d14">1</data>
    </edge>
    <edge source="R. SORICUT" target="A. HAUTH">
      <data key="d9">1.0</data>
      <data key="d10">R. Soricut and A. Hauth co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">65b488142164407a81b496b4820ef556</data>
      <data key="d13">776</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. SCHALKWYK" target="A. M. DAI">
      <data key="d9">1.0</data>
      <data key="d10">J. Schalkwyk and A. M. Dai co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">b3b006f8629b44df81a266c1e4d81d3f</data>
      <data key="d13">777</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. SCHALKWYK" target="A. HAUTH">
      <data key="d9">1.0</data>
      <data key="d10">J. Schalkwyk and A. Hauth co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">2a48f66b6a424b9ebf38562836fe1c82</data>
      <data key="d13">778</data>
      <data key="d14">1</data>
    </edge>
    <edge source="A. M. DAI" target="A. HAUTH">
      <data key="d9">1.0</data>
      <data key="d10">A. M. Dai and A. Hauth co-authored the Gemini paper</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">54e486668fa94feda285f377fb05d14d</data>
      <data key="d13">779</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. BAEK" target="A. F. AJI">
      <data key="d9">1.0</data>
      <data key="d10">J. Baek and A. F. Aji co-authored the paper on knowledge-augmented language model prompting</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">d7c4899260084560905ac54dba81f0e6</data>
      <data key="d13">780</data>
      <data key="d14">1</data>
    </edge>
    <edge source="J. BAEK" target="A. SAFFARI">
      <data key="d9">1.0</data>
      <data key="d10">J. Baek and A. Saffari co-authored the paper on knowledge-augmented language model prompting</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">880db899ce864932843fe230e3d364ad</data>
      <data key="d13">781</data>
      <data key="d14">1</data>
    </edge>
    <edge source="A. F. AJI" target="A. SAFFARI">
      <data key="d9">1.0</data>
      <data key="d10">A. F. Aji and A. Saffari co-authored the paper on knowledge-augmented language model prompting</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">59463c48d2fb48308cd38ee8dd869f59</data>
      <data key="d13">782</data>
      <data key="d14">1</data>
    </edge>
    <edge source="T. BAN" target="L. CHEN">
      <data key="d9">1.0</data>
      <data key="d10">T. Ban and L. Chen co-authored the paper on query tools to causal architects</data>
      <data key="d11">086021a89900a39bcb62036981737bfa</data>
      <data key="d12">ff69f1aae7404c38b8bde6abc5a79b57</data>
      <data key="d13">783</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BAUMEL, T." target="EYAL, M.">
      <data key="d9">1.0</data>
      <data key="d10">Baumel, T. and Eyal, M. co-authored the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">8db22f709edb4ae98f0fef060ccd24b8</data>
      <data key="d13">784</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BAUMEL, T." target="ELHADAD, M.">
      <data key="d9">1.0</data>
      <data key="d10">Baumel, T. and Elhadad, M. co-authored the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">0e412e834e62475a9fe1920438f7b75b</data>
      <data key="d13">785</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BAUMEL, T." target="ARXIV:1801.07704">
      <data key="d9">1.0</data>
      <data key="d10">Baumel, T. is an author of the paper with arXiv identifier 1801.07704</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">2e3f6dbac98742ddb213037ae77f0a82</data>
      <data key="d13">786</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EYAL, M." target="ELHADAD, M.">
      <data key="d9">1.0</data>
      <data key="d10">Eyal, M. and Elhadad, M. co-authored the paper "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">59ced15f5a1d485ebf0eac7fa85c1cdf</data>
      <data key="d13">787</data>
      <data key="d14">1</data>
    </edge>
    <edge source="EYAL, M." target="ARXIV:1801.07704">
      <data key="d9">1.0</data>
      <data key="d10">Eyal, M. is an author of the paper with arXiv identifier 1801.07704</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">7cef69e2a71c4379b0816844799fc71e</data>
      <data key="d13">788</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ELHADAD, M." target="ARXIV:1801.07704">
      <data key="d9">1.0</data>
      <data key="d10">Elhadad, M. is an author of the paper with arXiv identifier 1801.07704</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">0f565c275f8148d885ae53c315ddc568</data>
      <data key="d13">789</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BLONDEL, V. D." target="GUILLAUME, J.-L.">
      <data key="d9">1.0</data>
      <data key="d10">Blondel, V. D. and Guillaume, J.-L. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">29c05af68cc541b79fdf499eac42b9c6</data>
      <data key="d13">790</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BLONDEL, V. D." target="LAMBIOTTE, R.">
      <data key="d9">1.0</data>
      <data key="d10">Blondel, V. D. and Lambiotte, R. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">8d5d7b8fb7d14d0ba46ce7f0be6de661</data>
      <data key="d13">791</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BLONDEL, V. D." target="LEFEBVRE, E.">
      <data key="d9">1.0</data>
      <data key="d10">Blondel, V. D. and Lefebvre, E. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">607a66de21cf42e497c23013327b751f</data>
      <data key="d13">792</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GUILLAUME, J.-L." target="LAMBIOTTE, R.">
      <data key="d9">1.0</data>
      <data key="d10">Guillaume, J.-L. and Lambiotte, R. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">f4f85b6086384211a25248f614bfb786</data>
      <data key="d13">793</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GUILLAUME, J.-L." target="LEFEBVRE, E.">
      <data key="d9">1.0</data>
      <data key="d10">Guillaume, J.-L. and Lefebvre, E. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">c1a4bcd4e7874e699f06bc795e291150</data>
      <data key="d13">794</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LAMBIOTTE, R." target="LEFEBVRE, E.">
      <data key="d9">1.0</data>
      <data key="d10">Lambiotte, R. and Lefebvre, E. co-authored the paper "Fast unfolding of communities in large networks"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">ca585d891433495aa70a3a01b252e50c</data>
      <data key="d13">795</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, T." target="MANN, B.">
      <data key="d9">1.0</data>
      <data key="d10">Brown, T. and Mann, B. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">f26b5e1c52e445998b6a63738d203b38</data>
      <data key="d13">796</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, T." target="RYDER, N.">
      <data key="d9">1.0</data>
      <data key="d10">Brown, T. and Ryder, N. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">0945030309e14518a16df16fbb25c76f</data>
      <data key="d13">797</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, T." target="SUBBIAH, M.">
      <data key="d9">1.0</data>
      <data key="d10">Brown, T. and Subbiah, M. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">35939cc34a734b5f867f8d75df419f37</data>
      <data key="d13">798</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, T." target="KAPLAN, J. D.">
      <data key="d9">1.0</data>
      <data key="d10">Brown, T. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">807561f61906451b880e04ac6a33687f</data>
      <data key="d13">799</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, T." target="DHARIWAL, P.">
      <data key="d9">1.0</data>
      <data key="d10">Brown, T. and Dhariwal, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">0538e2dc04174140a43bc0359fed2d23</data>
      <data key="d13">800</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, T." target="NEELAKANTAN, A.">
      <data key="d9">1.0</data>
      <data key="d10">Brown, T. and Neelakantan, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">6e87d210775b45e4a09e518492329bce</data>
      <data key="d13">801</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, T." target="SHYAM, P.">
      <data key="d9">1.0</data>
      <data key="d10">Brown, T. and Shyam, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">bde6223f81884473a1acc3b75dd056aa</data>
      <data key="d13">802</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, T." target="SASTRY, G.">
      <data key="d9">1.0</data>
      <data key="d10">Brown, T. and Sastry, G. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">7beb3a2ecfd5419b950a20a155e06169</data>
      <data key="d13">803</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, T." target="ASKELL, A.">
      <data key="d9">1.0</data>
      <data key="d10">Brown, T. and Askell, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">961dda09b0df497a974c38c28eb90686</data>
      <data key="d13">804</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MANN, B." target="RYDER, N.">
      <data key="d9">1.0</data>
      <data key="d10">Mann, B. and Ryder, N. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">1fb946075dd54b218b8dfad20647d33e</data>
      <data key="d13">805</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MANN, B." target="SUBBIAH, M.">
      <data key="d9">1.0</data>
      <data key="d10">Mann, B. and Subbiah, M. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">bf90efb1858e49b19987cbd280d0e911</data>
      <data key="d13">806</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MANN, B." target="KAPLAN, J. D.">
      <data key="d9">1.0</data>
      <data key="d10">Mann, B. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">f9949e43ea004014abec1b59f2155b5a</data>
      <data key="d13">807</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MANN, B." target="DHARIWAL, P.">
      <data key="d9">1.0</data>
      <data key="d10">Mann, B. and Dhariwal, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">3d89c7fe0b6448e0a0d27bceccc09f09</data>
      <data key="d13">808</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MANN, B." target="NEELAKANTAN, A.">
      <data key="d9">1.0</data>
      <data key="d10">Mann, B. and Neelakantan, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">185f98d04d9f484ab3d626fd459a23a2</data>
      <data key="d13">809</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MANN, B." target="SHYAM, P.">
      <data key="d9">1.0</data>
      <data key="d10">Mann, B. and Shyam, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">688e9b443bc44782855aea4afd8a9d16</data>
      <data key="d13">810</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MANN, B." target="SASTRY, G.">
      <data key="d9">1.0</data>
      <data key="d10">Mann, B. and Sastry, G. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">cd56c4963a0e49d7bab0e25f0e068779</data>
      <data key="d13">811</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MANN, B." target="ASKELL, A.">
      <data key="d9">1.0</data>
      <data key="d10">Mann, B. and Askell, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">c4d4216677af42f5a29a0f4dcb442220</data>
      <data key="d13">812</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RYDER, N." target="SUBBIAH, M.">
      <data key="d9">1.0</data>
      <data key="d10">Ryder, N. and Subbiah, M. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">d99684f88f2d43eaacd62ba9082b64a5</data>
      <data key="d13">813</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RYDER, N." target="KAPLAN, J. D.">
      <data key="d9">1.0</data>
      <data key="d10">Ryder, N. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">9ca07c62b7e146298882e33f3c6cb653</data>
      <data key="d13">814</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RYDER, N." target="DHARIWAL, P.">
      <data key="d9">1.0</data>
      <data key="d10">Ryder, N. and Dhariwal, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">eef3aeb29aba43da93b433a816e77203</data>
      <data key="d13">815</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RYDER, N." target="NEELAKANTAN, A.">
      <data key="d9">1.0</data>
      <data key="d10">Ryder, N. and Neelakantan, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">1c2a05515b9f49e1966a4ceb4bb0a3a5</data>
      <data key="d13">816</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RYDER, N." target="SHYAM, P.">
      <data key="d9">1.0</data>
      <data key="d10">Ryder, N. and Shyam, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">86db00646d264b0a922c6b639dc9d16b</data>
      <data key="d13">817</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RYDER, N." target="SASTRY, G.">
      <data key="d9">1.0</data>
      <data key="d10">Ryder, N. and Sastry, G. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">7892ab98e1b0475c97a798aa8b2d7f6c</data>
      <data key="d13">818</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RYDER, N." target="ASKELL, A.">
      <data key="d9">1.0</data>
      <data key="d10">Ryder, N. and Askell, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">9732636cdd50433bb146a241cd72dbc5</data>
      <data key="d13">819</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUBBIAH, M." target="KAPLAN, J. D.">
      <data key="d9">1.0</data>
      <data key="d10">Subbiah, M. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">a5a8a63d5baf4946b7d7d1696f0e4e0e</data>
      <data key="d13">820</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUBBIAH, M." target="DHARIWAL, P.">
      <data key="d9">1.0</data>
      <data key="d10">Subbiah, M. and Dhariwal, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">a69a82dd8773426096c58ddc56832770</data>
      <data key="d13">821</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUBBIAH, M." target="NEELAKANTAN, A.">
      <data key="d9">1.0</data>
      <data key="d10">Subbiah, M. and Neelakantan, A. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">72a7215e3e4a4b0db851351dfe5afd37</data>
      <data key="d13">822</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUBBIAH, M." target="SHYAM, P.">
      <data key="d9">1.0</data>
      <data key="d10">Subbiah, M. and Shyam, P. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">5f8224530d424618acb32b74a3afe2c9</data>
      <data key="d13">823</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUBBIAH, M." target="SASTRY, G.">
      <data key="d9">1.0</data>
      <data key="d10">Subbiah, M. and Sastry, G. co-authored the paper "Language models are few-shot learners"</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">99d4510732d843299514461aebd5f176</data>
      <data key="d13">824</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHAO, D." target="ARXIV:2310.05149">
      <data key="d9">1.0</data>
      <data key="d10">Zhao, D. is an author of the paper with arXiv identifier 2310.05149</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">1730cbfab07747508d5b5ea421b97953</data>
      <data key="d13">825</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ES, S." target="ARXIV:2309.15217">
      <data key="d9">1.0</data>
      <data key="d10">Es, S. is an author of the paper with arXiv identifier 2309.15217</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">7dd3aadc8f424988a72f8ba3ccf17155</data>
      <data key="d13">826</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JAMES, J." target="ARXIV:2309.15217">
      <data key="d9">1.0</data>
      <data key="d10">James, J. is an author of the paper with arXiv identifier 2309.15217</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">a2e7cbaf38c24564b2abe61680cacd72</data>
      <data key="d13">827</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ESPINOSA-ANKE, L." target="ARXIV:2309.15217">
      <data key="d9">1.0</data>
      <data key="d10">Espinosa-Anke, L. is an author of the paper with arXiv identifier 2309.15217</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">162f1ccf8dfc46cea4d54a36ed9ec823</data>
      <data key="d13">828</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SCHOCKAERT, S." target="ARXIV:2309.15217">
      <data key="d9">1.0</data>
      <data key="d10">Schockaert, S. is an author of the paper with arXiv identifier 2309.15217</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">17127080df794121830177e93631aa3b</data>
      <data key="d13">829</data>
      <data key="d14">1</data>
    </edge>
    <edge source="FENG, Z." target="ARXIV:2310.05149">
      <data key="d9">1.0</data>
      <data key="d10">Feng, Z. is an author of the paper with arXiv identifier 2310.05149</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">374a8f81e6304b6d90b44cdceb90ecb4</data>
      <data key="d13">830</data>
      <data key="d14">1</data>
    </edge>
    <edge source="FENG, X." target="ARXIV:2310.05149">
      <data key="d9">1.0</data>
      <data key="d10">Feng, X. is an author of the paper with arXiv identifier 2310.05149</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">8c6aafd2a5da496385bea2c69be03a5a</data>
      <data key="d13">831</data>
      <data key="d14">1</data>
    </edge>
    <edge source="YANG, M." target="ARXIV:2310.05149">
      <data key="d9">1.0</data>
      <data key="d10">Yang, M. is an author of the paper with arXiv identifier 2310.05149</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">06b9da0d4d9b4d6bb762bd2eeca7028a</data>
      <data key="d13">832</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QIN, B." target="ARXIV:2310.05149">
      <data key="d9">1.0</data>
      <data key="d10">Qin, B. is an author of the paper with arXiv identifier 2310.05149</data>
      <data key="d11">58ae80c41cfe46db39da26b6a83584e5</data>
      <data key="d12">a5f6de474fb24ec9af7403231c616831</data>
      <data key="d13">833</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, Y." target="XIONG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, Y. and Xiong, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">a0ef87eb823b400594300f5c47e5c9c3</data>
      <data key="d13">834</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, Y." target="GAO, X.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, Y. and Gao, X. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">ed076834490640acbb5d837aaac9fed5</data>
      <data key="d13">835</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, Y." target="JIA, K.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, Y. and Jia, K. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">f935684600f34a27906def1902627ff2</data>
      <data key="d13">836</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, Y." target="PAN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, Y. and Pan, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">72fc2f604fc644e39f7d70e25094e347</data>
      <data key="d13">837</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, Y." target="BI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, Y. and Bi, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">3ddb886b220c4bb2ab3d68f7f29ce5c5</data>
      <data key="d13">838</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, Y." target="DAI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, Y. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">2f482bb08d564072a5ff4f2509dfdda6</data>
      <data key="d13">839</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, Y." target="SUN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, Y. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">fc86507186da4c6c94fe3b788d77c471</data>
      <data key="d13">840</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, Y." target="WANG, H.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, Y. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">c235c2c649484c83967e2a42523028bb</data>
      <data key="d13">841</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XIONG, Y." target="GAO, X.">
      <data key="d9">1.0</data>
      <data key="d10">Xiong, Y. and Gao, X. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">7e9d748907ea4b74925a32999a2b40d9</data>
      <data key="d13">842</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XIONG, Y." target="JIA, K.">
      <data key="d9">1.0</data>
      <data key="d10">Xiong, Y. and Jia, K. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">eefaef8a5c7149d18d304f39bf41f280</data>
      <data key="d13">843</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XIONG, Y." target="PAN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Xiong, Y. and Pan, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">327114716cea49a79d33ba609158cd87</data>
      <data key="d13">844</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XIONG, Y." target="BI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Xiong, Y. and Bi, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">b45920e405af45f787ab167f54cfd2e9</data>
      <data key="d13">845</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XIONG, Y." target="DAI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Xiong, Y. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">00db8f6e99254c99be6c6f5c14a79500</data>
      <data key="d13">846</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XIONG, Y." target="SUN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Xiong, Y. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">aadd82f0e70c4fc49b1bdee3f60c1890</data>
      <data key="d13">847</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XIONG, Y." target="WANG, H.">
      <data key="d9">1.0</data>
      <data key="d10">Xiong, Y. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">9528d92ccc10454793c4df59e24586db</data>
      <data key="d13">848</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, X." target="JIA, K.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, X. and Jia, K. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">80618f4e809e4af1bcdb59342c375377</data>
      <data key="d13">849</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, X." target="PAN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, X. and Pan, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">32d785e275be458fb7178ad2021ecdfc</data>
      <data key="d13">850</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, X." target="BI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, X. and Bi, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">0757f97d1fbf49748169ba696a364e4c</data>
      <data key="d13">851</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, X." target="DAI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, X. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">ca9a355bf38b452cbde62dba747ec65f</data>
      <data key="d13">852</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, X." target="SUN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, X. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">ba297c67512447e4b86f0cbc39fbc301</data>
      <data key="d13">853</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GAO, X." target="WANG, H.">
      <data key="d9">1.0</data>
      <data key="d10">Gao, X. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">00a9c8745b404b659c76a694dba9851c</data>
      <data key="d13">854</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JIA, K." target="PAN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Jia, K. and Pan, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">eb338f2214414f0f9fa396f06ca12860</data>
      <data key="d13">855</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JIA, K." target="BI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Jia, K. and Bi, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">d119680bac3744e58d2ed3273b1208b6</data>
      <data key="d13">856</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JIA, K." target="DAI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Jia, K. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">d60eefaddf1e4b1db125d8f9ac49bacb</data>
      <data key="d13">857</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JIA, K." target="SUN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Jia, K. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">6058343c0824402e9843c92b2991f778</data>
      <data key="d13">858</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JIA, K." target="WANG, H.">
      <data key="d9">1.0</data>
      <data key="d10">Jia, K. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">383a003edc5a4f2387c7dd7865a984c9</data>
      <data key="d13">859</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PAN, J." target="BI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Pan, J. and Bi, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">6bf9623c44824e48b7451bdfa1b47816</data>
      <data key="d13">860</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PAN, J." target="DAI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Pan, J. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">cc62f333666e427eb1c66ec3f12a7a55</data>
      <data key="d13">861</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PAN, J." target="SUN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Pan, J. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">c6d99481f5f545278ca8a73650b66e87</data>
      <data key="d13">862</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PAN, J." target="WANG, H.">
      <data key="d9">1.0</data>
      <data key="d10">Pan, J. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">5a0887b99d8b4bd89286962cd6f07037</data>
      <data key="d13">863</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BI, Y." target="DAI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Bi, Y. and Dai, Y. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">75174e7af26f434c9154b182087b58dc</data>
      <data key="d13">864</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BI, Y." target="SUN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Bi, Y. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">0c43dd117fe6495991d4b4d8c2f5d70e</data>
      <data key="d13">865</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BI, Y." target="WANG, H.">
      <data key="d9">1.0</data>
      <data key="d10">Bi, Y. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">65e5d27c4f8a4dfa8ad92f227964b9cf</data>
      <data key="d13">866</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DAI, Y." target="SUN, J.">
      <data key="d9">1.0</data>
      <data key="d10">Dai, Y. and Sun, J. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">63c4595187884af29aa46d03319acded</data>
      <data key="d13">867</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DAI, Y." target="WANG, H.">
      <data key="d9">1.0</data>
      <data key="d10">Dai, Y. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">b32482039edd4d50bc43514570500345</data>
      <data key="d13">868</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUN, J." target="WANG, H.">
      <data key="d9">1.0</data>
      <data key="d10">Sun, J. and Wang, H. co-authored the paper "Retrieval-augmented generation for large language models: A survey"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">f3e6e2c82bab4430a33987a19e3d1835</data>
      <data key="d13">869</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GOODWIN, T. R." target="SAVERY, M. E.">
      <data key="d9">1.0</data>
      <data key="d10">Goodwin, T. R. and Savery, M. E. co-authored the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">6768cc24da5d4a2492ff936dd4b35661</data>
      <data key="d13">870</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GOODWIN, T. R." target="DEMNER-FUSHMAN, D.">
      <data key="d9">1.0</data>
      <data key="d10">Goodwin, T. R. and Demner-Fushman, D. co-authored the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization"</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b</data>
      <data key="d12">223e1e3e7c4f4282b086e940f8c935c2</data>
      <data key="d13">871</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KHATTAB, O." target="SANTHANAM, K.">
      <data key="d9">2.0</data>
      <data key="d10">Khattab, O. and Santhanam, K. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and contributes to the field of Natural Language Processing and Information Retrieval by exploring the integration of retrieval and language models to enhance knowledge-intensive NLP tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">f5bb365c9a814b909df0351498d79bb5</data>
      <data key="d13">872</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KHATTAB, O." target="LI, X. L.">
      <data key="d9">2.0</data>
      <data key="d10">Khattab, O. and Li, X. L. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and highlights their collaborative work in the field of Natural Language Processing and Information Retrieval.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">ab4ad26863b44497a1e48aa7c17a096c</data>
      <data key="d13">873</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KHATTAB, O." target="HALL, D.">
      <data key="d9">2.0</data>
      <data key="d10">Khattab, O. and Hall, D. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">145bc384290c49228a231ac124ce88a8</data>
      <data key="d13">874</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KHATTAB, O." target="LIANG, P.">
      <data key="d9">2.0</data>
      <data key="d10">Khattab, O. and Liang, P. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This work is mentioned in the text and contributes to the field of Natural Language Processing and Information Retrieval by exploring the integration of retrieval and language models to enhance knowledge-intensive NLP tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">f64c99537adf489ea58940e417cb5924</data>
      <data key="d13">875</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KHATTAB, O." target="POTTS, C.">
      <data key="d9">2.0</data>
      <data key="d10">Khattab, O. and Potts, C. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">fe98ea566cf6486b85f8ed14aabb2618</data>
      <data key="d13">876</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KHATTAB, O." target="ZAHARIA, M.">
      <data key="d9">2.0</data>
      <data key="d10">Khattab, O. and Zaharia, M. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">6bfb83cb716745fcb591c8d2fb54f8f4</data>
      <data key="d13">877</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KHATTAB, O." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Khattab, O. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">9866640f891944c7bb0a08748aa8b91f</data>
      <data key="d13">878</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SANTHANAM, K." target="LI, X. L.">
      <data key="d9">2.0</data>
      <data key="d10">Santhanam, K. and Li, X. L. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This collaboration is mentioned in the text, highlighting their joint contribution to the field of Natural Language Processing and Information Retrieval.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">b0d513adad104e14a89a767a66f30848</data>
      <data key="d13">879</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SANTHANAM, K." target="HALL, D.">
      <data key="d9">2.0</data>
      <data key="d10">Santhanam, K. and Hall, D. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">db37a25770a34437b472fa0038837868</data>
      <data key="d13">880</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SANTHANAM, K." target="LIANG, P.">
      <data key="d9">2.0</data>
      <data key="d10">Santhanam, K. and Liang, P. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">67746ba67d80491da102aab7704dfd30</data>
      <data key="d13">881</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SANTHANAM, K." target="POTTS, C.">
      <data key="d9">2.0</data>
      <data key="d10">Santhanam, K. and Potts, C. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and contributes to the field of Natural Language Processing and Information Retrieval by exploring the integration of retrieval and language models to enhance knowledge-intensive tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">873a1ca522e6461090d5cdebc2c9ae98</data>
      <data key="d13">882</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SANTHANAM, K." target="ZAHARIA, M.">
      <data key="d9">2.0</data>
      <data key="d10">Santhanam, K. and Zaharia, M. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">d919ccd28e2248b5ab1dcdd7af8b00cf</data>
      <data key="d13">883</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SANTHANAM, K." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Santhanam, K. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">1883a3ca4d6a4bfd984e7053e2553e16</data>
      <data key="d13">884</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, X. L." target="HALL, D.">
      <data key="d9">2.0</data>
      <data key="d10">Li, X. L. and Hall, D. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">2a0c93cf781a4020aceef7230b286bbf</data>
      <data key="d13">885</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, X. L." target="LIANG, P.">
      <data key="d9">2.0</data>
      <data key="d10">Li, X. L. and Liang, P. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">06282cc8998f4b2ea43e0a9522383639</data>
      <data key="d13">886</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, X. L." target="POTTS, C.">
      <data key="d9">2.0</data>
      <data key="d10">Li, X. L. and Potts, C. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">182efa2240c14212bb021746a18936bd</data>
      <data key="d13">887</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, X. L." target="ZAHARIA, M.">
      <data key="d9">2.0</data>
      <data key="d10">Li, X. L. and Zaharia, M. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">727bc610ea9a4393bfa5de453b84340f</data>
      <data key="d13">888</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, X. L." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Li, X. L. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">960c3b508a294332ba7c05ffd897db31</data>
      <data key="d13">889</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HALL, D." target="LIANG, P.">
      <data key="d9">2.0</data>
      <data key="d10">Hall, D. and Liang, P. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">bd0c1d79ef1144a49f3ce09d4cdf099b</data>
      <data key="d13">890</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HALL, D." target="POTTS, C.">
      <data key="d9">2.0</data>
      <data key="d10">Hall, D. and Potts, C. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">b8ae79ed2d6d43f98e0808b5bea884dd</data>
      <data key="d13">891</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HALL, D." target="ZAHARIA, M.">
      <data key="d9">2.0</data>
      <data key="d10">Hall, D. and Zaharia, M. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">a03b33a4ee97467c808946679e240ddf</data>
      <data key="d13">892</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HALL, D." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Hall, D. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">00b685bcb7a54c4493cd78da1f4752ab</data>
      <data key="d13">893</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIANG, P." target="POTTS, C.">
      <data key="d9">2.0</data>
      <data key="d10">Liang, P. and Potts, C. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">9a54e0361b684d24aefdc05fc340cf41</data>
      <data key="d13">894</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIANG, P." target="ZAHARIA, M.">
      <data key="d9">2.0</data>
      <data key="d10">LIANG, P. and ZAHARIA, M. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">d423b97f085947bd89529bc1ed2c41a7</data>
      <data key="d13">895</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIANG, P." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Liang, P. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">6fd2b0d5156c424a89cb1c068cf1e076</data>
      <data key="d13">896</data>
      <data key="d14">1</data>
    </edge>
    <edge source="POTTS, C." target="ZAHARIA, M.">
      <data key="d9">2.0</data>
      <data key="d10">Potts, C. and Zaharia, M. co-authored the paper titled "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive NLP." This paper is mentioned in the text and focuses on integrating retrieval and language models to enhance knowledge-intensive natural language processing tasks.</data>
      <data key="d11">00e8e4e881bd0862022f4dfc913b900b,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">a8c8dd8ddbc44363ac2102b9b8989c6d</data>
      <data key="d13">897</data>
      <data key="d14">1</data>
    </edge>
    <edge source="POTTS, C." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Potts, C. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">00cb0db6e46749f7af97701ad26e23be</data>
      <data key="d13">898</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZAHARIA, M." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Zaharia, M. is an author of the arXiv preprint "Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">4baa53e4336d4807964fa8d186b32bc5</data>
      <data key="d13">899</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KIM, G." target="KIM, S.">
      <data key="d9">1.0</data>
      <data key="d10">Kim, G. and Kim, S. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">f325a83e0c854a7ba5d46663ddff1a29</data>
      <data key="d13">900</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KIM, G." target="JEON, B.">
      <data key="d9">1.0</data>
      <data key="d10">Kim, G. and Jeon, B. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">c2b7e5d9761e423a81149a94537f6def</data>
      <data key="d13">901</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KIM, G." target="PARK, J.">
      <data key="d9">1.0</data>
      <data key="d10">Kim, G. and Park, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">3d1ccd312d3a4e7387e888aaa137c7c2</data>
      <data key="d13">902</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KIM, G." target="KANG, J.">
      <data key="d9">1.0</data>
      <data key="d10">Kim, G. and Kang, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">840966e7ac4a4b14ac912e75102d50b7</data>
      <data key="d13">903</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KIM, G." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Kim, G. is an author of the arXiv preprint "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">f0ede764bdb1437b8cfcc20ca9598712</data>
      <data key="d13">904</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KIM, S." target="JEON, B.">
      <data key="d9">1.0</data>
      <data key="d10">Kim, S. and Jeon, B. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">dd38d562c21f444190768c8a154280da</data>
      <data key="d13">905</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KIM, S." target="PARK, J.">
      <data key="d9">1.0</data>
      <data key="d10">Kim, S. and Park, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">1e66c1cbb56b41269555d27e1505ec92</data>
      <data key="d13">906</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KIM, S." target="KANG, J.">
      <data key="d9">1.0</data>
      <data key="d10">Kim, S. and Kang, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">a653bd47ad3d4009ab6a5b8e6ff18679</data>
      <data key="d13">907</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KIM, S." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Kim, S. is an author of the arXiv preprint "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">37b7cf055e604ec6927a9f0b15b2698d</data>
      <data key="d13">908</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JEON, B." target="PARK, J.">
      <data key="d9">1.0</data>
      <data key="d10">Jeon, B. and Park, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">182e0f3d0abd4181820acdd2bf8e5eaf</data>
      <data key="d13">909</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JEON, B." target="KANG, J.">
      <data key="d9">1.0</data>
      <data key="d10">Jeon, B. and Kang, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">6fd6398a9bfd496f9a0505d9f3190362</data>
      <data key="d13">910</data>
      <data key="d14">1</data>
    </edge>
    <edge source="JEON, B." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Jeon, B. is an author of the arXiv preprint "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">2192d6436ca840a1bce77dbf9fd354af</data>
      <data key="d13">911</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PARK, J." target="KANG, J.">
      <data key="d9">1.0</data>
      <data key="d10">Park, J. and Kang, J. co-authored the paper "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">ef5e0bbdb3774a22900cf45e9b8863ad</data>
      <data key="d13">912</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PARK, J." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Park, J. is an author of the arXiv preprint "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">307de250d35e43a8b122c4232fa8fb7c</data>
      <data key="d13">913</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KANG, J." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Kang, J. is an author of the arXiv preprint "Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">0e2f68c8ff734b279b7aad333bcf2fda</data>
      <data key="d13">914</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KLEIN, G." target="MOON, B.">
      <data key="d9">1.0</data>
      <data key="d10">Klein, G. and Moon, B. co-authored the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">172b0d0fa0794494a3c50b135c1f2cd6</data>
      <data key="d13">915</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KLEIN, G." target="HOFFMAN, R. R.">
      <data key="d9">1.0</data>
      <data key="d10">Klein, G. and Hoffman, R. R. co-authored the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">96f016e343b34ac894b0b7153f474ab0</data>
      <data key="d13">916</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KLEIN, G." target="IEEE INTELLIGENT SYSTEMS">
      <data key="d9">1.0</data>
      <data key="d10">Klein, G. is an author of papers published in IEEE Intelligent Systems</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">d356499ae9a345b6bbfb33b5fa01f47b</data>
      <data key="d13">917</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MOON, B." target="HOFFMAN, R. R.">
      <data key="d9">1.0</data>
      <data key="d10">Moon, B. and Hoffman, R. R. co-authored the papers "Making sense of sensemaking 1: Alternative perspectives" and "Making sense of sensemaking 2: A macrocognitive model"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">d7ebead985b34576821f30d83a416cd2</data>
      <data key="d13">918</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MOON, B." target="IEEE INTELLIGENT SYSTEMS">
      <data key="d9">1.0</data>
      <data key="d10">Moon, B. is an author of papers published in IEEE Intelligent Systems</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">02c1447586fc46dfa65b793e0105a878</data>
      <data key="d13">919</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HOFFMAN, R. R." target="IEEE INTELLIGENT SYSTEMS">
      <data key="d9">1.0</data>
      <data key="d10">Hoffman, R. R. is an author of papers published in IEEE Intelligent Systems</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">1b1560bb4b0447e5860f8ba351af112e</data>
      <data key="d13">920</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KOESTEN, L." target="GREGORY, K.">
      <data key="d9">1.0</data>
      <data key="d10">Koesten, L. and Gregory, K. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">23b929895979486cba3bf6a13f4ce655</data>
      <data key="d13">921</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KOESTEN, L." target="GROTH, P.">
      <data key="d9">1.0</data>
      <data key="d10">Koesten, L. and Groth, P. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">f1ebe367253a4a4088b363a6cc4601a1</data>
      <data key="d13">922</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KOESTEN, L." target="SIMPERL, E.">
      <data key="d9">1.0</data>
      <data key="d10">Koesten, L. and Simperl, E. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">cf575adc3eb140f9aec33757ec040eb8</data>
      <data key="d13">923</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KOESTEN, L." target="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d9">1.0</data>
      <data key="d10">Koesten, L. is an author of a paper published in International Journal of Human-Computer Studies</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">4e581bc7d4424c2fb0023e5b11687e02</data>
      <data key="d13">924</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GREGORY, K." target="GROTH, P.">
      <data key="d9">1.0</data>
      <data key="d10">Gregory, K. and Groth, P. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">ae9f8a02ac0f43d4ba67ccce412989d6</data>
      <data key="d13">925</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GREGORY, K." target="SIMPERL, E.">
      <data key="d9">1.0</data>
      <data key="d10">Gregory, K. and Simperl, E. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">b972541545604529a30cabc262d83dae</data>
      <data key="d13">926</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GREGORY, K." target="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d9">1.0</data>
      <data key="d10">Gregory, K. is an author of a paper published in International Journal of Human-Computer Studies</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">ec3f73ffbb9742e090b65893d040434b</data>
      <data key="d13">927</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GROTH, P." target="SIMPERL, E.">
      <data key="d9">1.0</data>
      <data key="d10">Groth, P. and Simperl, E. co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">20be7b3222174d31839fac6a278f8b61</data>
      <data key="d13">928</data>
      <data key="d14">1</data>
    </edge>
    <edge source="GROTH, P." target="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d9">1.0</data>
      <data key="d10">Groth, P. is an author of a paper published in International Journal of Human-Computer Studies</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">35688e258b0e4cc78c8b92ef8a13d3e3</data>
      <data key="d13">929</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SIMPERL, E." target="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d9">1.0</data>
      <data key="d10">Simperl, E. is an author of a paper published in International Journal of Human-Computer Studies</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">3a9503f2d69343c396c9b1d842d1aa74</data>
      <data key="d13">930</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KURATOV, Y." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Kuratov, Y. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">39516d28d39e49a2b80e6cfac32e2609</data>
      <data key="d13">931</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BULATOV, A." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Bulatov, A. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">43cf2e01543540789eb8781fdb5f287d</data>
      <data key="d13">932</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ANOKHIN, P." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Anokhin, P. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">54beb6d012d844058715f8ef8a91c5da</data>
      <data key="d13">933</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SOROKIN, D." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Sorokin, D. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">5a291bf96ac141b98730ac27c96e829e</data>
      <data key="d13">934</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SOROKIN, A." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Sorokin, A. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">5e572d8b0a614ce1839ec9a568078cdc</data>
      <data key="d13">935</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BURTSEV, M." target="ARXIV PREPRINT">
      <data key="d9">1.0</data>
      <data key="d10">Burtsev, M. is an author of the arXiv preprint "In search of needles in a 11m haystack: Recurrent memory finds what llms miss"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">3f7b36b371da40568ce15510a35b58e7</data>
      <data key="d13">936</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="ADVANCES IN ARTIFICIAL INTELLIGENCE">
      <data key="d9">1.0</data>
      <data key="d10">Laskar, M. T. R. is an author of a paper presented at Advances in Artificial Intelligence</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">6db7771bcc674e4ead899fbdd417930f</data>
      <data key="d13">937</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="HOQUE, E.">
      <data key="d9">2.0</data>
      <data key="d10">Laskar, M. T. R. and Hoque, E. co-authored two significant papers in the field of Natural Language Processing and Information Retrieval. The first paper, titled "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization," explores the use of pre-trained transformer models to enhance the performance of query-focused abstractive summarization through domain adaptation techniques. The second paper, "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models," delves into the integration of query relevance and transfer learning with transformer models to improve the effectiveness of query-focused abstractive summarization. Both works contribute to advancing the application of transformer models in specialized summarization tasks.</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7,71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">176a96262ad64ccbacb1efdfb36bd88a</data>
      <data key="d13">938</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="HUANG, J.">
      <data key="d9">1.0</data>
      <data key="d10">Laskar, M. T. R. and Huang, J. co-authored the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">bd120225f7b84bbdb0567048ca803e3c</data>
      <data key="d13">939</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="HUANG, J. X.">
      <data key="d9">1.0</data>
      <data key="d10">Laskar, M. T. R. and Huang, J. X. co-authored the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">8ecda003a3d044279b1f0bdc1c96c25e</data>
      <data key="d13">940</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="COMPUTATIONAL LINGUISTICS">
      <data key="d9">1.0</data>
      <data key="d10">Laskar, M. T. R. published the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" in Computational Linguistics</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">8e02a61bda6a4470b693e7e234abfc94</data>
      <data key="d13">941</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HOQUE, E." target="ADVANCES IN ARTIFICIAL INTELLIGENCE">
      <data key="d9">1.0</data>
      <data key="d10">Hoque, E. is an author of a paper presented at Advances in Artificial Intelligence</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">b62e3858d801445facc3a501c5100723</data>
      <data key="d13">942</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HOQUE, E." target="HUANG, J.">
      <data key="d9">1.0</data>
      <data key="d10">Hoque, E. and Huang, J. co-authored the paper "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models"</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">64e8971970e94ea79d10e46c55b3e761</data>
      <data key="d13">943</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HOQUE, E." target="HUANG, J. X.">
      <data key="d9">1.0</data>
      <data key="d10">Hoque, E. and Huang, J. X. co-authored the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">b10fd3628e7a45d29a2814771f53ad60</data>
      <data key="d13">944</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HOQUE, E." target="COMPUTATIONAL LINGUISTICS">
      <data key="d9">1.0</data>
      <data key="d10">Hoque, E. published the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" in Computational Linguistics</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">826bb16575a141d683fb871ec94517e0</data>
      <data key="d13">945</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HUANG, J." target="ADVANCES IN ARTIFICIAL INTELLIGENCE">
      <data key="d9">1.0</data>
      <data key="d10">Huang, J. is an author of a paper presented at Advances in Artificial Intelligence</data>
      <data key="d11">71f6daf11e64e5273a3847d46bf228e1</data>
      <data key="d12">52384316108d433397224cb36486407c</data>
      <data key="d13">946</data>
      <data key="d14">1</data>
    </edge>
    <edge source="33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE" target="CANADIAN AI 2020">
      <data key="d9">1.0</data>
      <data key="d10">The 33rd Canadian Conference on Artificial Intelligence is also known as Canadian AI 2020</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">9a27717e1a1b499981031fd69c58aff1</data>
      <data key="d13">947</data>
      <data key="d14">1</data>
    </edge>
    <edge source="33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE" target="SPRINGER">
      <data key="d9">1.0</data>
      <data key="d10">Springer published the proceedings of the 33rd Canadian Conference on Artificial Intelligence</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">4efbe8fc23a64506b36d6cf29f968baa</data>
      <data key="d13">948</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HUANG, J. X." target="COMPUTATIONAL LINGUISTICS">
      <data key="d9">1.0</data>
      <data key="d10">Huang, J. X. published the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" in Computational Linguistics</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">d3b80330258d412f9ac6a7670fe79044</data>
      <data key="d13">949</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEWIS, P." target="PEREZ, E.">
      <data key="d9">1.0</data>
      <data key="d10">Lewis, P. and Perez, E. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">52703e888bf4493b866186b889d85783</data>
      <data key="d13">950</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEWIS, P." target="PIKTUS, A.">
      <data key="d9">1.0</data>
      <data key="d10">Lewis, P. and Piktus, A. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">5e25a814a9a04bcda6017c9cc99880a7</data>
      <data key="d13">951</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEWIS, P." target="PETRONI, F.">
      <data key="d9">1.0</data>
      <data key="d10">Lewis, P. and Petroni, F. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">bb2070d133f74049b88c96510fc807ba</data>
      <data key="d13">952</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEWIS, P." target="KARPUKHIN, V.">
      <data key="d9">1.0</data>
      <data key="d10">Lewis, P. and Karpukhin, V. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">d0734be4aaab40eb9f2be6229f4a803c</data>
      <data key="d13">953</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEWIS, P." target="GOYAL, N.">
      <data key="d9">1.0</data>
      <data key="d10">Lewis, P. and Goyal, N. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">a5839bfcc6c0471c9337257ed05b361b</data>
      <data key="d13">954</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEWIS, P." target="K&#220;TTLER, H.">
      <data key="d9">1.0</data>
      <data key="d10">Lewis, P. and K&#252;ttler, H. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">bee441f5c41e41ff8220254bbf714eb4</data>
      <data key="d13">955</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEWIS, P." target="LEWIS, M.">
      <data key="d9">1.0</data>
      <data key="d10">Lewis, P. and Lewis, M. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">8d93d45adbe547f78460a9ef3eb40ab2</data>
      <data key="d13">956</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEWIS, P." target="YIH, W.-T.">
      <data key="d9">1.0</data>
      <data key="d10">Lewis, P. and Yih, W.-T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">c6f21de31a6f4fbda2eed1780ffed5b1</data>
      <data key="d13">957</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEWIS, P." target="ROCKT&#196;SCHEL, T.">
      <data key="d9">1.0</data>
      <data key="d10">Lewis, P. and Rockt&#228;schel, T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">07c3f03764874b7680710ca030cdb60c</data>
      <data key="d13">958</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PEREZ, E." target="PIKTUS, A.">
      <data key="d9">1.0</data>
      <data key="d10">Perez, E. and Piktus, A. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">7a7990b6045c440ba606d142bd8ddc02</data>
      <data key="d13">959</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PEREZ, E." target="PETRONI, F.">
      <data key="d9">1.0</data>
      <data key="d10">Perez, E. and Petroni, F. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">803cb895664c40319ca40cc9abb6a03d</data>
      <data key="d13">960</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PEREZ, E." target="KARPUKHIN, V.">
      <data key="d9">1.0</data>
      <data key="d10">Perez, E. and Karpukhin, V. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">4c9e4e36560946699b6cb1e67b1437ae</data>
      <data key="d13">961</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PEREZ, E." target="GOYAL, N.">
      <data key="d9">1.0</data>
      <data key="d10">Perez, E. and Goyal, N. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">8a7a2d6266424b9f9006502e82fcd778</data>
      <data key="d13">962</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PEREZ, E." target="K&#220;TTLER, H.">
      <data key="d9">1.0</data>
      <data key="d10">Perez, E. and K&#252;ttler, H. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">6b38285eedc544b08b444ee781db9f0c</data>
      <data key="d13">963</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PEREZ, E." target="LEWIS, M.">
      <data key="d9">1.0</data>
      <data key="d10">Perez, E. and Lewis, M. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">9d59b69c7c984abb9d3e281c04e73510</data>
      <data key="d13">964</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PEREZ, E." target="YIH, W.-T.">
      <data key="d9">1.0</data>
      <data key="d10">Perez, E. and Yih, W.-T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">83ee1d8db753419f8b240f419a139815</data>
      <data key="d13">965</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PEREZ, E." target="ROCKT&#196;SCHEL, T.">
      <data key="d9">1.0</data>
      <data key="d10">Perez, E. and Rockt&#228;schel, T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">9211b015bb074bcd89ae6c75ec10e6da</data>
      <data key="d13">966</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PIKTUS, A." target="PETRONI, F.">
      <data key="d9">1.0</data>
      <data key="d10">Piktus, A. and Petroni, F. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">cbc280dac03a4c19bb6737e3789c928f</data>
      <data key="d13">967</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PIKTUS, A." target="KARPUKHIN, V.">
      <data key="d9">1.0</data>
      <data key="d10">Piktus, A. and Karpukhin, V. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">166cfa435aac4465943f59c2d04a0da1</data>
      <data key="d13">968</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PIKTUS, A." target="GOYAL, N.">
      <data key="d9">1.0</data>
      <data key="d10">Piktus, A. and Goyal, N. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">44bced1d9b184aa29376cf3b0cdac625</data>
      <data key="d13">969</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PIKTUS, A." target="K&#220;TTLER, H.">
      <data key="d9">1.0</data>
      <data key="d10">Piktus, A. and K&#252;ttler, H. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">ca58c4e2fae84899a780ff379e1927eb</data>
      <data key="d13">970</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PIKTUS, A." target="LEWIS, M.">
      <data key="d9">1.0</data>
      <data key="d10">Piktus, A. and Lewis, M. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">2060ce64f028490798a3ed69832e048d</data>
      <data key="d13">971</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PIKTUS, A." target="YIH, W.-T.">
      <data key="d9">1.0</data>
      <data key="d10">Piktus, A. and Yih, W.-T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">fa8fa48e2a7542fc8ff2c43c35e1b32b</data>
      <data key="d13">972</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PIKTUS, A." target="ROCKT&#196;SCHEL, T.">
      <data key="d9">1.0</data>
      <data key="d10">Piktus, A. and Rockt&#228;schel, T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">a37bd07ff1694b6c90572399f084e1ec</data>
      <data key="d13">973</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PETRONI, F." target="KARPUKHIN, V.">
      <data key="d9">1.0</data>
      <data key="d10">Petroni, F. and Karpukhin, V. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">826e32d5ea1d455f8ae2d3b77cd2b41e</data>
      <data key="d13">974</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PETRONI, F." target="GOYAL, N.">
      <data key="d9">1.0</data>
      <data key="d10">Petroni, F. and Goyal, N. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">1a3bd511e04d4929a45a36fb80127353</data>
      <data key="d13">975</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PETRONI, F." target="K&#220;TTLER, H.">
      <data key="d9">1.0</data>
      <data key="d10">Petroni, F. and K&#252;ttler, H. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">d0cd49577d6a49f4a21fdc389aa84805</data>
      <data key="d13">976</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PETRONI, F." target="LEWIS, M.">
      <data key="d9">1.0</data>
      <data key="d10">Petroni, F. and Lewis, M. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">aa667f462aae45a8a700d83a68c1982f</data>
      <data key="d13">977</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PETRONI, F." target="YIH, W.-T.">
      <data key="d9">1.0</data>
      <data key="d10">Petroni, F. and Yih, W.-T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">37f40795969a42b3b50e61b76a96fa07</data>
      <data key="d13">978</data>
      <data key="d14">1</data>
    </edge>
    <edge source="PETRONI, F." target="ROCKT&#196;SCHEL, T.">
      <data key="d9">1.0</data>
      <data key="d10">Petroni, F. and Rockt&#228;schel, T. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">6db48bd5e4ce4337aaac4648376ed07d</data>
      <data key="d13">979</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KARPUKHIN, V." target="GOYAL, N.">
      <data key="d9">1.0</data>
      <data key="d10">Karpukhin, V. and Goyal, N. co-authored the paper "Retrieval-augmented generation for knowledge-intensive NLP tasks"</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7</data>
      <data key="d12">422e6a449e7e4ce69182113a6493a4e5</data>
      <data key="d13">980</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LAPATA, M." target="XU, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Xu, Y. and Lapata, M. co-authored the paper "Text summarization with latent queries"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">68511afc6e204c0b996d76cb75de081c</data>
      <data key="d13">981</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CHEN, W." target="HUANG, M.">
      <data key="d9">1.0</data>
      <data key="d10">Huang, M. and Chen, W. co-authored the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">050f02fbf9e64d08b108c5b921581335</data>
      <data key="d13">982</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CHEN, W." target="DUAN, N.">
      <data key="d9">1.0</data>
      <data key="d10">Duan, N. and Chen, W. co-authored the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">97367a34fd6b4451b6be397496d646ea</data>
      <data key="d13">983</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MARTIN, S." target="BROWN, W. M.">
      <data key="d9">3.0</data>
      <data key="d10">Martin, S. and Brown, W. M. co-authored the paper titled "Openord: An open-source toolbox for large graph layout." This work focuses on providing an open-source solution for the layout of large graphs, which is a significant contribution to the field of graph visualization and analysis. The paper highlights the development and application of the Openord toolbox, which is designed to handle the complexities associated with large graph structures, making it a valuable resource for researchers and practitioners in the domain of graph theory and network analysis.</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">80da3caff5344d56b6ca12660594949a</data>
      <data key="d13">984</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MARTIN, S." target="KLAVANS, R.">
      <data key="d9">3.0</data>
      <data key="d10">Martin, S. and Klavans, R. co-authored the paper "Openord: An open-source toolbox for large graph layout." This work focuses on providing an open-source solution for the layout of large graphs, which is a significant contribution to the field of Natural Language Processing and Information Retrieval. The paper highlights the development and application of Openord, a toolbox designed to handle the complexities associated with visualizing large-scale graph data.</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">e7efb7b459ae4ed4aa412cd20d808970</data>
      <data key="d13">985</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MARTIN, S." target="BOYACK, K.">
      <data key="d9">3.0</data>
      <data key="d10">Martin, S. and Boyack, K. co-authored the paper titled "Openord: An open-source toolbox for large graph layout." This work focuses on providing an open-source solution for the layout of large graphs, which is a significant contribution to the field of graph visualization and analysis. The paper highlights the capabilities and applications of the Openord toolbox, emphasizing its utility in handling extensive graph data efficiently.</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">f0cc756b32314a1aae3e3cbb507850a2</data>
      <data key="d13">986</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, W. M." target="KLAVANS, R.">
      <data key="d9">3.0</data>
      <data key="d10">Brown, W. M. and Klavans, R. co-authored the paper titled "Openord: An open-source toolbox for large graph layout." This work focuses on providing an open-source solution for the layout of large graphs, which is a significant contribution to the field of Natural Language Processing and Information Retrieval. The paper highlights the development and application of the Openord toolbox, which is designed to handle the complexities associated with visualizing large-scale graph data.</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">f3082b58c8a54c538cf3a0110296955b</data>
      <data key="d13">987</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BROWN, W. M." target="BOYACK, K.">
      <data key="d9">3.0</data>
      <data key="d10">Brown, W. M. and Boyack, K. co-authored the paper titled "Openord: An open-source toolbox for large graph layout." This work focuses on providing an open-source solution for the layout of large graphs, which is a significant contribution to the field of Natural Language Processing and Information Retrieval. The paper highlights the development and application of Openord, a toolbox designed to handle the complexities associated with visualizing large-scale graph data.</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">c5f2254b67c04ad4add88875e5623e5a</data>
      <data key="d13">988</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KLAVANS, R." target="BOYACK, K.">
      <data key="d9">3.0</data>
      <data key="d10">KLAVANS, R. and BOYACK, K. co-authored the paper titled "Openord: An open-source toolbox for large graph layout." This work focuses on providing an open-source solution for the layout of large graphs, which is a significant contribution to the field of Natural Language Processing and Information Retrieval. The paper highlights the development and application of the Openord toolbox, which is designed to handle the complexities associated with visualizing large-scale graph data.</data>
      <data key="d11">6cd82819982879bd164547d2773ba5c7,833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">6e151c66c5574df39a7f243858e2ad3f</data>
      <data key="d13">989</data>
      <data key="d14">1</data>
    </edge>
    <edge source="NEWMAN, M. E." target="PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES">
      <data key="d9">2.0</data>
      <data key="d10">Newman, M. E. published the paper "Modularity and community structure in networks" in the Proceedings of the National Academy of Sciences</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">166366ae9ec842ec9a1deeb13c94026e</data>
      <data key="d13">990</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAM, O." target="LEVINE, Y.">
      <data key="d9">2.0</data>
      <data key="d10">Ram, O. and Levine, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">cdecc293edb847ae92c3bf8ff39d1e9a</data>
      <data key="d13">991</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAM, O." target="DALMEDIGOS, I.">
      <data key="d9">2.0</data>
      <data key="d10">Ram, O. and Dalmedigos, I. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">3a615d980a124616a659136b4fd277b7</data>
      <data key="d13">992</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAM, O." target="MUHLGAY, D.">
      <data key="d9">2.0</data>
      <data key="d10">Ram, O. and Muhlgay, D. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">a9b46d1f9ef747b69d6211386b5aaa20</data>
      <data key="d13">993</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAM, O." target="SHASHUA, A.">
      <data key="d9">2.0</data>
      <data key="d10">Ram, O. and Shashua, A. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">891a6dbec2ef4a039efaca78040b00c1</data>
      <data key="d13">994</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAM, O." target="LEYTON-BROWN, K.">
      <data key="d9">2.0</data>
      <data key="d10">Ram, O. and Leyton-Brown, K. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">981d45442a11448097acebc6080da414</data>
      <data key="d13">995</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RAM, O." target="SHOHAM, Y.">
      <data key="d9">2.0</data>
      <data key="d10">Ram, O. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">fad1c8144b504954bea46ede106d93ec</data>
      <data key="d13">996</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEVINE, Y." target="DALMEDIGOS, I.">
      <data key="d9">2.0</data>
      <data key="d10">Levine, Y. and Dalmedigos, I. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">53edb7e587204ed48e523c6f1f8f4056</data>
      <data key="d13">997</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEVINE, Y." target="MUHLGAY, D.">
      <data key="d9">2.0</data>
      <data key="d10">Levine, Y. and Muhlgay, D. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">f386b02e36884167a5db1a12ee6fcb1a</data>
      <data key="d13">998</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEVINE, Y." target="SHASHUA, A.">
      <data key="d9">2.0</data>
      <data key="d10">Levine, Y. and Shashua, A. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">2809d8a73b71495ca4220571dd54ba1e</data>
      <data key="d13">999</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEVINE, Y." target="LEYTON-BROWN, K.">
      <data key="d9">2.0</data>
      <data key="d10">Levine, Y. and Leyton-Brown, K. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">49f82fa775fb466bb9ae3db14db5b29a</data>
      <data key="d13">1000</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEVINE, Y." target="SHOHAM, Y.">
      <data key="d9">2.0</data>
      <data key="d10">Levine, Y. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">f9312ee0bac24ea1b497e16e0958d621</data>
      <data key="d13">1001</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DALMEDIGOS, I." target="MUHLGAY, D.">
      <data key="d9">2.0</data>
      <data key="d10">Dalmedigos, I. and Muhlgay, D. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">c84bc84ffea84df9ad25ae9f972b4ec0</data>
      <data key="d13">1002</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DALMEDIGOS, I." target="SHASHUA, A.">
      <data key="d9">2.0</data>
      <data key="d10">Dalmedigos, I. and Shashua, A. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">be1068c6efb24cde96e5a523eb04aee8</data>
      <data key="d13">1003</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DALMEDIGOS, I." target="LEYTON-BROWN, K.">
      <data key="d9">2.0</data>
      <data key="d10">Dalmedigos, I. and Leyton-Brown, K. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">ecc4f28a7d574a5886f4c80a0b7cddd4</data>
      <data key="d13">1004</data>
      <data key="d14">1</data>
    </edge>
    <edge source="DALMEDIGOS, I." target="SHOHAM, Y.">
      <data key="d9">2.0</data>
      <data key="d10">Dalmedigos, I. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">b506a4813da44600b136e949db4f2832</data>
      <data key="d13">1005</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MUHLGAY, D." target="SHASHUA, A.">
      <data key="d9">2.0</data>
      <data key="d10">Muhlgay, D. and Shashua, A. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">77735209cabb415289c8ae4e102ff6df</data>
      <data key="d13">1006</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MUHLGAY, D." target="LEYTON-BROWN, K.">
      <data key="d9">2.0</data>
      <data key="d10">Muhlgay, D. and Leyton-Brown, K. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">1f1d88a6f6ce46bab94a4b50693c89ff</data>
      <data key="d13">1007</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MUHLGAY, D." target="SHOHAM, Y.">
      <data key="d9">2.0</data>
      <data key="d10">Muhlgay, D. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">03454aaf00c54112a09ea4e52185b195</data>
      <data key="d13">1008</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHASHUA, A." target="LEYTON-BROWN, K.">
      <data key="d9">2.0</data>
      <data key="d10">Shashua, A. and Leyton-Brown, K. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">3c5cd9cbad0d456cab4c76f1dfcde25b</data>
      <data key="d13">1009</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHASHUA, A." target="SHOHAM, Y.">
      <data key="d9">2.0</data>
      <data key="d10">Shashua, A. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">8503eae9f6c746afae0caa58070f25e6</data>
      <data key="d13">1010</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LEYTON-BROWN, K." target="SHOHAM, Y.">
      <data key="d9">2.0</data>
      <data key="d10">Leyton-Brown, K. and Shoham, Y. co-authored the paper "In-context retrieval-augmented language models"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">6e3c655e5b544277a62832a0974aa0ed</data>
      <data key="d13">1011</data>
      <data key="d14">1</data>
    </edge>
    <edge source="RANADE, P." target="JOSHI, A.">
      <data key="d9">2.0</data>
      <data key="d10">Ranade, P. and Joshi, A. co-authored the paper "Fabula: Intelligence report generation using retrieval-augmented narrative construction"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">bd0363bace6b42b0b3879bed5a064274</data>
      <data key="d13">1012</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SARTHI, P." target="ABDULLAH, S.">
      <data key="d9">2.0</data>
      <data key="d10">Sarthi, P. and Abdullah, S. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">99969eec8bf8441eaf9cb004cb61a13e</data>
      <data key="d13">1013</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SARTHI, P." target="TULI, A.">
      <data key="d9">2.0</data>
      <data key="d10">Sarthi, P. and Tuli, A. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">0bcceb946a94486faf935f58dabea978</data>
      <data key="d13">1014</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SARTHI, P." target="KHANNA, S.">
      <data key="d9">2.0</data>
      <data key="d10">Sarthi, P. and Khanna, S. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">4d8421b4a6c74627afaa45aefa08c43a</data>
      <data key="d13">1015</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SARTHI, P." target="GOLDIE, A.">
      <data key="d9">2.0</data>
      <data key="d10">Sarthi, P. and Goldie, A. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">f879674860784f9eb4289aeb91728351</data>
      <data key="d13">1016</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SARTHI, P." target="MANNING, C. D.">
      <data key="d9">2.0</data>
      <data key="d10">Sarthi, P. and Manning, C. D. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">dea50b1765e54936b3d0b1e499ab2053</data>
      <data key="d13">1017</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ABDULLAH, S." target="TULI, A.">
      <data key="d9">2.0</data>
      <data key="d10">Abdullah, S. and Tuli, A. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">26634913d18f4629b39dffa19c1df734</data>
      <data key="d13">1018</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ABDULLAH, S." target="KHANNA, S.">
      <data key="d9">2.0</data>
      <data key="d10">Abdullah, S. and Khanna, S. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">a69bde74fc9d41cfa669f148c7c43dd8</data>
      <data key="d13">1019</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ABDULLAH, S." target="GOLDIE, A.">
      <data key="d9">2.0</data>
      <data key="d10">Abdullah, S. and Goldie, A. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">e65667ec99e145fea2055d6b583cb05b</data>
      <data key="d13">1020</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ABDULLAH, S." target="MANNING, C. D.">
      <data key="d9">2.0</data>
      <data key="d10">Abdullah, S. and Manning, C. D. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">cdfcbba5664d42508cd34df9af42b0dc</data>
      <data key="d13">1021</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TULI, A." target="KHANNA, S.">
      <data key="d9">2.0</data>
      <data key="d10">Tuli, A. and Khanna, S. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">570de818eba04615a6afb3a573e82ff1</data>
      <data key="d13">1022</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TULI, A." target="GOLDIE, A.">
      <data key="d9">2.0</data>
      <data key="d10">Tuli, A. and Goldie, A. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">473533c454d34975a17a0193e39e0bac</data>
      <data key="d13">1023</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TULI, A." target="MANNING, C. D.">
      <data key="d9">2.0</data>
      <data key="d10">Tuli, A. and Manning, C. D. co-authored the paper "Raptor: Recursive abstractive processing for tree-organized retrieval"</data>
      <data key="d11">833e7d67dcd30790b26b71c9b5306f6b</data>
      <data key="d12">e22af264c702440f93070465f45e630e</data>
      <data key="d13">1024</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MANNING, C. D." target="YANG, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Yang, Z. and Manning, C. D. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">ad95fbd957ae4c22859f58446dd8c9cc</data>
      <data key="d13">1025</data>
      <data key="d14">1</data>
    </edge>
    <edge source="HUANG, M." target="DUAN, N.">
      <data key="d9">1.0</data>
      <data key="d10">Huang, M. and Duan, N. co-authored the paper "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">37d42129ca4d49dea240f66d1fdd4b78</data>
      <data key="d13">1026</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SU, D." target="XU, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Su, D. and Xu, Y. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">1f40481f4ee342d4be51d33ffafc17d1</data>
      <data key="d13">1027</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SU, D." target="YU, T.">
      <data key="d9">1.0</data>
      <data key="d10">Su, D. and Yu, T. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">e892d46e07e44bd5a2d1626875cc024f</data>
      <data key="d13">1028</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SU, D." target="SIDDIQUE, F. B.">
      <data key="d9">1.0</data>
      <data key="d10">Su, D. and Siddique, F. B. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">fcb033a54d734ce5a87e0d8ad555867a</data>
      <data key="d13">1029</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SU, D." target="BAREZI, E. J.">
      <data key="d9">1.0</data>
      <data key="d10">Su, D. and Barezi, E. J. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">964fc01bfd9a400eb668761539dc9d9f</data>
      <data key="d13">1030</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SU, D." target="FUNG, P.">
      <data key="d9">1.0</data>
      <data key="d10">Su, D. and Fung, P. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">86b0d920fa504eba81c26cfc3f4d2b9f</data>
      <data key="d13">1031</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XU, Y." target="YU, T.">
      <data key="d9">1.0</data>
      <data key="d10">Xu, Y. and Yu, T. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">e0221df7b7e44dd7956c8d0348d46b6d</data>
      <data key="d13">1032</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XU, Y." target="SIDDIQUE, F. B.">
      <data key="d9">1.0</data>
      <data key="d10">Xu, Y. and Siddique, F. B. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">a20d7f4fee104273b9628d648c05a5ac</data>
      <data key="d13">1033</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XU, Y." target="BAREZI, E. J.">
      <data key="d9">1.0</data>
      <data key="d10">Xu, Y. and Barezi, E. J. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">b352398c5b1742d8a61acd8534ef0f53</data>
      <data key="d13">1034</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XU, Y." target="FUNG, P.">
      <data key="d9">1.0</data>
      <data key="d10">Xu, Y. and Fung, P. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">38b778af3c3f4be2a23e3932c94390c3</data>
      <data key="d13">1035</data>
      <data key="d14">1</data>
    </edge>
    <edge source="YU, T." target="SIDDIQUE, F. B.">
      <data key="d9">1.0</data>
      <data key="d10">Yu, T. and Siddique, F. B. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">35d528e52a6441a58e58385d85bfae4b</data>
      <data key="d13">1036</data>
      <data key="d14">1</data>
    </edge>
    <edge source="YU, T." target="BAREZI, E. J.">
      <data key="d9">1.0</data>
      <data key="d10">Yu, T. and Barezi, E. J. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">06d0d34ab3d043c689044a0fbfc65e10</data>
      <data key="d13">1037</data>
      <data key="d14">1</data>
    </edge>
    <edge source="YU, T." target="FUNG, P.">
      <data key="d9">1.0</data>
      <data key="d10">Yu, T. and Fung, P. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">9e0ec036c91e44daa8e1a2af50df2081</data>
      <data key="d13">1038</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SIDDIQUE, F. B." target="BAREZI, E. J.">
      <data key="d9">1.0</data>
      <data key="d10">Siddique, F. B. and Barezi, E. J. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">580b2395e68442539a606d37ddba691d</data>
      <data key="d13">1039</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SIDDIQUE, F. B." target="FUNG, P.">
      <data key="d9">1.0</data>
      <data key="d10">Siddique, F. B. and Fung, P. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">370fd1c6563045499e1d711fcd9ef9d5</data>
      <data key="d13">1040</data>
      <data key="d14">1</data>
    </edge>
    <edge source="BAREZI, E. J." target="FUNG, P.">
      <data key="d9">1.0</data>
      <data key="d10">Barezi, E. J. and Fung, P. co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">3b6c4319026844ecb645f650e30b7d1a</data>
      <data key="d13">1041</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TANG, Y." target="YANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Tang, Y. and Yang, Y. co-authored the paper "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">e044334b7d2e426ca2cab7eb763d8bc9</data>
      <data key="d13">1042</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOUVRON, H." target="MARTIN, L.">
      <data key="d9">1.0</data>
      <data key="d10">Touvron, H. and Martin, L. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">4a2fa382e77946d2be8e95edc04c6a64</data>
      <data key="d13">1043</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOUVRON, H." target="STONE, K.">
      <data key="d9">1.0</data>
      <data key="d10">Touvron, H. and Stone, K. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">cd015281a069460e844faeb327b7d65f</data>
      <data key="d13">1044</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOUVRON, H." target="ALBERT, P.">
      <data key="d9">1.0</data>
      <data key="d10">Touvron, H. and Albert, P. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">c7a9fbf22a054056bf4f4562eaecfc08</data>
      <data key="d13">1045</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOUVRON, H." target="ALMAHAIRI, A.">
      <data key="d9">1.0</data>
      <data key="d10">Touvron, H. and Almahairi, A. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">44bf341f78d74c4bb15ae209649d0ca9</data>
      <data key="d13">1046</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOUVRON, H." target="BABAEI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Touvron, H. and Babaei, Y. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">045ff6885d424b4caeabc76c50468c7c</data>
      <data key="d13">1047</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOUVRON, H." target="BASHLYKOV, N.">
      <data key="d9">1.0</data>
      <data key="d10">Touvron, H. and Bashlykov, N. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">543a52396f0b4f7f99ea755fba11d290</data>
      <data key="d13">1048</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOUVRON, H." target="BATRA, S.">
      <data key="d9">1.0</data>
      <data key="d10">Touvron, H. and Batra, S. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">33e487870db646e5b3d9c1f2962a7c6a</data>
      <data key="d13">1049</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOUVRON, H." target="BHARGAVA, P.">
      <data key="d9">1.0</data>
      <data key="d10">Touvron, H. and Bhargava, P. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">b5b628d809514bfe9bbb3bd362815e79</data>
      <data key="d13">1050</data>
      <data key="d14">1</data>
    </edge>
    <edge source="TOUVRON, H." target="BHOSALE, S.">
      <data key="d9">1.0</data>
      <data key="d10">Touvron, H. and Bhosale, S. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">9d9ae51d2af44ebe8324dd2dd1dcd83b</data>
      <data key="d13">1051</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MARTIN, L." target="STONE, K.">
      <data key="d9">1.0</data>
      <data key="d10">Martin, L. and Stone, K. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">b7c606aa6ad1416e9f934628acce5f24</data>
      <data key="d13">1052</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MARTIN, L." target="ALBERT, P.">
      <data key="d9">1.0</data>
      <data key="d10">Martin, L. and Albert, P. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">4521342f29774fab85e6acb0490d46e5</data>
      <data key="d13">1053</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MARTIN, L." target="ALMAHAIRI, A.">
      <data key="d9">1.0</data>
      <data key="d10">Martin, L. and Almahairi, A. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">e7ac741e4aa4433ca5f2379726f90b33</data>
      <data key="d13">1054</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MARTIN, L." target="BABAEI, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Martin, L. and Babaei, Y. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">43645eb9258244a8bd334ce77216b1c0</data>
      <data key="d13">1055</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MARTIN, L." target="BASHLYKOV, N.">
      <data key="d9">1.0</data>
      <data key="d10">Martin, L. and Bashlykov, N. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">0c9c52488ad647abbaf2b4589c976957</data>
      <data key="d13">1056</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MARTIN, L." target="BATRA, S.">
      <data key="d9">1.0</data>
      <data key="d10">Martin, L. and Batra, S. co-authored the paper "Llama 2: Open foundation and fine-tuned chat models"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">0e8fb49a531e4ea48fece73957bd8a54</data>
      <data key="d13">1057</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, J." target="LIANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, J. and Liang, Y. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">6187217c38ca4225b97d04d9644dcdf0</data>
      <data key="d13">1058</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, J." target="MENG, F.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, J. and Meng, F. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">8c8330abe276487294eba3a341ee9e0c</data>
      <data key="d13">1059</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, J." target="SUN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, J. and Sun, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">200df54d93964e81ae2dcf727bffb23c</data>
      <data key="d13">1060</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, J." target="SHI, H.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, J. and Shi, H. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">4d0478c05f614675b336a76a0c088b3e</data>
      <data key="d13">1061</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, J." target="LI, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, J. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">c0dc4d618b5e49f7a18efa34dbf450ac</data>
      <data key="d13">1062</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, J." target="XU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, J. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">dec05f79120940b78cd921a0a67f1540</data>
      <data key="d13">1063</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, J." target="QU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, J. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">8edbf3e4f0d94f6ab78127c61bf87b76</data>
      <data key="d13">1064</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, J." target="ZHOU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, J. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">1d722426930a42eeadfa624a6eb2408f</data>
      <data key="d13">1065</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIANG, Y." target="MENG, F.">
      <data key="d9">1.0</data>
      <data key="d10">Liang, Y. and Meng, F. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">6d22f2009f6a4df9a242f03e2642981e</data>
      <data key="d13">1066</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIANG, Y." target="SUN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Liang, Y. and Sun, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">db5035c544214c72987eed4d4d9e327f</data>
      <data key="d13">1067</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIANG, Y." target="SHI, H.">
      <data key="d9">1.0</data>
      <data key="d10">Liang, Y. and Shi, H. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">fd00e337b5c4465cbcbdf07bc294a3a8</data>
      <data key="d13">1068</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIANG, Y." target="LI, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Liang, Y. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">ea1e51b558c149649711a29157f4e604</data>
      <data key="d13">1069</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIANG, Y." target="XU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Liang, Y. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">b888ad14e84347f8831a7dd2cea294fd</data>
      <data key="d13">1070</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIANG, Y." target="QU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Liang, Y. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">0e2323c0256d40579e7526dbdd019a8d</data>
      <data key="d13">1071</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIANG, Y." target="ZHOU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Liang, Y. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">deb3bc5537a14352b22a0a473a59d8c7</data>
      <data key="d13">1072</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MENG, F." target="SUN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Meng, F. and Sun, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">ba445c400c8e405bb646387eab98a62b</data>
      <data key="d13">1073</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MENG, F." target="SHI, H.">
      <data key="d9">1.0</data>
      <data key="d10">Meng, F. and Shi, H. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">95a90d05e82d44ada6f8577ca49dd491</data>
      <data key="d13">1074</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MENG, F." target="LI, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Meng, F. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">fa15140701a54689835604665d187c54</data>
      <data key="d13">1075</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MENG, F." target="XU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Meng, F. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">8346468f7f4c46bebe1eaafd9753d55f</data>
      <data key="d13">1076</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MENG, F." target="QU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Meng, F. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">46ddbfe32d444912b423dd1769fbaa43</data>
      <data key="d13">1077</data>
      <data key="d14">1</data>
    </edge>
    <edge source="MENG, F." target="ZHOU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Meng, F. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">ffce5a64e9394d1399319588d7fd4e3e</data>
      <data key="d13">1078</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUN, Z." target="SHI, H.">
      <data key="d9">1.0</data>
      <data key="d10">Sun, Z. and Shi, H. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">e934202aa3b344ba9fef89ecb42530b4</data>
      <data key="d13">1079</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUN, Z." target="LI, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Sun, Z. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">22d5ff62439047ccaeaa63fd8a30f3e5</data>
      <data key="d13">1080</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUN, Z." target="XU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Sun, Z. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">9b2f77b408ec4147bd5dd67a01d9f439</data>
      <data key="d13">1081</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUN, Z." target="QU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Sun, Z. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">96b1264e89394adfaf026471e3b6ad47</data>
      <data key="d13">1082</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SUN, Z." target="ZHOU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Sun, Z. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">00741dfb8f6d477f913d20406dfcd65d</data>
      <data key="d13">1083</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHI, H." target="LI, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Shi, H. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">3eb344aa8b05448984dacac93482ebc4</data>
      <data key="d13">1084</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHI, H." target="XU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Shi, H. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">8db8a8680d534161b0772d7a771df6bd</data>
      <data key="d13">1085</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHI, H." target="QU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Shi, H. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">7f2c628b4fa54c0b9254049602ed20d2</data>
      <data key="d13">1086</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHI, H." target="ZHOU, J.">
      <data key="d9">1.0</data>
      <data key="d10">Shi, H. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035</data>
      <data key="d12">2f8f5d33916d4824bec6773bacd37d87</data>
      <data key="d13">1087</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="XU, J.">
      <data key="d9">2.0</data>
      <data key="d10">Li, Z. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">b8e1f95f9d3e497393d86e6bd137fe10</data>
      <data key="d13">1088</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="QU, J.">
      <data key="d9">2.0</data>
      <data key="d10">Li, Z. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">13a41e2ff8b847ee8073e1e23b0bffc6</data>
      <data key="d13">1089</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="ZHOU, J.">
      <data key="d9">2.0</data>
      <data key="d10">Li, Z. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">9c61fb5ee44744a48bc5638bd42f654b</data>
      <data key="d13">1090</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="H.">
      <data key="d9">1.0</data>
      <data key="d10">H. and Li, Z. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">946213d345b64cbaa6becb8723b01d87</data>
      <data key="d13">1091</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="ZHENG, L.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">e75c65762f064dfc95787fa331c95392</data>
      <data key="d13">1092</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="CHIANG, W.-L.">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">9a586c1629464133920fb19d8bd1e690</data>
      <data key="d13">1093</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="SHENG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Sheng, Y. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">e7a82e12e4f84f3e82c1ec74d3088235</data>
      <data key="d13">1094</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="ZHUANG, S.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, S. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">51828127e71d40829039e033add265c4</data>
      <data key="d13">1095</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="WU, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Wu, Z. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">04918b80bc714753b00af559d439a4ec</data>
      <data key="d13">1096</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="ZHUANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, Y. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">3b4dbcb1c7c24bf8b6d55485c0304f7e</data>
      <data key="d13">1097</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="LIN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Lin, Z. and Li, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">fdd2a43d9b9f450c899adfb60b05e711</data>
      <data key="d13">1098</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="LI, D.">
      <data key="d9">1.0</data>
      <data key="d10">Li, Z. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">bced585ff9d54fb7acd03f54f5729391</data>
      <data key="d13">1099</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Li, Z. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">50aec048280a4cdb8572993faab794dd</data>
      <data key="d13">1100</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, Z." target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">Li, Z. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">e128a7179b6e476c98d6bbfecf2a3f9a</data>
      <data key="d13">1101</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XU, J." target="QU, J.">
      <data key="d9">2.0</data>
      <data key="d10">Xu, J. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">a3fa60c3370e4d5e8147250e2a18104a</data>
      <data key="d13">1102</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XU, J." target="ZHOU, J.">
      <data key="d9">2.0</data>
      <data key="d10">Xu, J. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">1a7ef91522514b9f8b1ddaf68424351d</data>
      <data key="d13">1103</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XU, J." target="H.">
      <data key="d9">1.0</data>
      <data key="d10">H. and Xu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">e5f094bf02d84a0889cd041199156ad7</data>
      <data key="d13">1104</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QU, J." target="ZHOU, J.">
      <data key="d9">2.0</data>
      <data key="d10">Qu, J. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">8d87efac8c50cf20cdf26bf61e5e2035,fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">5c64fc0a74044110906120ca1d5c7919</data>
      <data key="d13">1105</data>
      <data key="d14">1</data>
    </edge>
    <edge source="QU, J." target="H.">
      <data key="d9">1.0</data>
      <data key="d10">H. and Qu, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">524d1b6a01d34b0098a0da8af056bfc8</data>
      <data key="d13">1106</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHOU, J." target="H.">
      <data key="d9">1.0</data>
      <data key="d10">H. and Zhou, J. co-authored the paper "Is chatgpt a good nlg evaluator? a preliminary study"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">73af37cadd3c4d3dbfb8bfd697aeef58</data>
      <data key="d13">1107</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, S." target="KHRAMTSOVA, E.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, S. and Khramtsova, E. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">c6b26fcc94044c368b2fe0db4b9b72f2</data>
      <data key="d13">1108</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, S." target="ZHUANG, S.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, S. and Zhuang, S. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">36b9f94e17c6481fb83670b70b192eb7</data>
      <data key="d13">1109</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, S." target="ZUCCON, G.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, S. and Zuccon, G. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">24c63641b4e241589336236d5f916e34</data>
      <data key="d13">1110</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KHRAMTSOVA, E." target="ZHUANG, S.">
      <data key="d9">1.0</data>
      <data key="d10">Khramtsova, E. and Zhuang, S. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">718e03207dcd44a080806880d08268ea</data>
      <data key="d13">1111</data>
      <data key="d14">1</data>
    </edge>
    <edge source="KHRAMTSOVA, E." target="ZUCCON, G.">
      <data key="d9">1.0</data>
      <data key="d10">Khramtsova, E. and Zuccon, G. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">6d0efadfba5046eb86869827544c2703</data>
      <data key="d13">1112</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, S." target="ZUCCON, G.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, S. and Zuccon, G. co-authored the paper "Feb4rag: Evaluating federated search in the context of retrieval augmented generation"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">2c33b12183ad4722ab1ab2cbd75f8312</data>
      <data key="d13">1113</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, S." target="ZHENG, L.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. and Zhuang, S. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">f334bc9701204b1b943f9ece317ca68a</data>
      <data key="d13">1114</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, S." target="CHIANG, W.-L.">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. and Zhuang, S. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">4ea3ecb74c91452da866f4c9163386e2</data>
      <data key="d13">1115</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, S." target="SHENG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Sheng, Y. and Zhuang, S. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">a12fe8fd9bc34db69d8de6944283d3c9</data>
      <data key="d13">1116</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, S." target="WU, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, S. and Wu, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">02b877f830cc4bb58dfad02f13a6d6ce</data>
      <data key="d13">1117</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, S." target="ZHUANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, S. and Zhuang, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">abffcf93dc114332a181990ad56b7863</data>
      <data key="d13">1118</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, S." target="LIN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, S. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">f894b0ae91eb412d93b6b06d4a73f350</data>
      <data key="d13">1119</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, S." target="LI, D.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, S. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">75e06eb1f93c4ee38b782965ea905b5b</data>
      <data key="d13">1120</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, S." target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, S. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">70fd5c73bbe34d918b3dca3fc7294d28</data>
      <data key="d13">1121</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, S." target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, S. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">8f1edc1d00764d6fb23859242c659deb</data>
      <data key="d13">1122</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, Y." target="LIPKA, N.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, Y. and Lipka, N. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">c8554314efb44679a898bbce08372abe</data>
      <data key="d13">1123</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, Y." target="ROSSI, R. A.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, Y. and Rossi, R. A. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">a41dbc4319f74bc995a93dbe0f4d9aee</data>
      <data key="d13">1124</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, Y." target="SIU, A.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, Y. and Siu, A. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">ef76a41bf9bf45c893c475a7bd5a2938</data>
      <data key="d13">1125</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, Y." target="ZHANG, R.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, Y. and Zhang, R. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">88f486cbb1904425a5fd5dfa268cf85d</data>
      <data key="d13">1126</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WANG, Y." target="DERR, T.">
      <data key="d9">1.0</data>
      <data key="d10">Wang, Y. and Derr, T. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">ec10a8695b1a4e8787d9d29114e9d5ce</data>
      <data key="d13">1127</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIPKA, N." target="ROSSI, R. A.">
      <data key="d9">1.0</data>
      <data key="d10">Lipka, N. and Rossi, R. A. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">9397185bb4d7492b88eaa20fa10c0ae5</data>
      <data key="d13">1128</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIPKA, N." target="SIU, A.">
      <data key="d9">1.0</data>
      <data key="d10">Lipka, N. and Siu, A. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">2b1b9b1ed49c4ace91ff099752b8c0a5</data>
      <data key="d13">1129</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIPKA, N." target="ZHANG, R.">
      <data key="d9">1.0</data>
      <data key="d10">Lipka, N. and Zhang, R. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">62c66c25992d4974829678313ed60b1d</data>
      <data key="d13">1130</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIPKA, N." target="DERR, T.">
      <data key="d9">1.0</data>
      <data key="d10">Lipka, N. and Derr, T. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">26a889667b614ab890d863c4b8762e69</data>
      <data key="d13">1131</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ROSSI, R. A." target="SIU, A.">
      <data key="d9">1.0</data>
      <data key="d10">Rossi, R. A. and Siu, A. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">30461855b0604128a4f10d0b348ce60f</data>
      <data key="d13">1132</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ROSSI, R. A." target="ZHANG, R.">
      <data key="d9">1.0</data>
      <data key="d10">Rossi, R. A. and Zhang, R. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">edef06de541f493f98d9281a704d785d</data>
      <data key="d13">1133</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ROSSI, R. A." target="DERR, T.">
      <data key="d9">1.0</data>
      <data key="d10">Rossi, R. A. and Derr, T. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">0016a9dec22543e9b203f540860bf2e7</data>
      <data key="d13">1134</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SIU, A." target="ZHANG, R.">
      <data key="d9">1.0</data>
      <data key="d10">Siu, A. and Zhang, R. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">4f79558a259f4de58df5b022b68a459e</data>
      <data key="d13">1135</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SIU, A." target="DERR, T.">
      <data key="d9">1.0</data>
      <data key="d10">Siu, A. and Derr, T. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">ca07919df74f4e5abfbd370c50eacc00</data>
      <data key="d13">1136</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHANG, R." target="DERR, T.">
      <data key="d9">1.0</data>
      <data key="d10">Zhang, R. and Derr, T. co-authored the paper "Knowledge graph prompting for multi-document question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">94b8715919cd49d08ac0ce99b930ea53</data>
      <data key="d13">1137</data>
      <data key="d14">1</data>
    </edge>
    <edge source="YANG, Z." target="QI, P.">
      <data key="d9">1.0</data>
      <data key="d10">Yang, Z. and Qi, P. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">4a10c341918b4d888b8b0466bd101b1d</data>
      <data key="d13">1138</data>
      <data key="d14">1</data>
    </edge>
    <edge source="YANG, Z." target="ZHANG, S.">
      <data key="d9">1.0</data>
      <data key="d10">Yang, Z. and Zhang, S. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">5173ce4188034717b9c90eef40b94932</data>
      <data key="d13">1139</data>
      <data key="d14">1</data>
    </edge>
    <edge source="YANG, Z." target="BENGIO, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Yang, Z. and Bengio, Y. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">cff3415902bf4745992473697570aef0</data>
      <data key="d13">1140</data>
      <data key="d14">1</data>
    </edge>
    <edge source="YANG, Z." target="COHEN, W. W.">
      <data key="d9">1.0</data>
      <data key="d10">Yang, Z. and Cohen, W. W. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">4c0cf727ec2843a288aa00b43f25b2de</data>
      <data key="d13">1141</data>
      <data key="d14">1</data>
    </edge>
    <edge source="YANG, Z." target="SALAKHUTDINOV, R.">
      <data key="d9">1.0</data>
      <data key="d10">Yang, Z. and Salakhutdinov, R. co-authored the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering"</data>
      <data key="d11">fc4b27d64f055b7fc30176ba110dd02e</data>
      <data key="d12">87ece3a4dcc84c98a291c1138ae56544</data>
      <data key="d13">1142</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHENG, L." target="CHIANG, W.-L.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. and Chiang, W.-L. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">143dc5f4cb4b4596900ee5158594b1b0</data>
      <data key="d13">1143</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHENG, L." target="SHENG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. and Sheng, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">3c222c5fdfab46e1ac1352a0f85a5fdd</data>
      <data key="d13">1144</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHENG, L." target="WU, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. and Wu, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">8c13a465b483417691c9b8d40b913da3</data>
      <data key="d13">1145</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHENG, L." target="ZHUANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. and Zhuang, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">51633d2f0adf4123a23eeb292d95e649</data>
      <data key="d13">1146</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHENG, L." target="LIN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">849136ae8c9f4f9589a989bfe4c4155d</data>
      <data key="d13">1147</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHENG, L." target="LI, D.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">84b11b37d1dd4e75b4c453669fbd4df9</data>
      <data key="d13">1148</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHENG, L." target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">373c198a0ed2402cb885b8d9f9de92f3</data>
      <data key="d13">1149</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHENG, L." target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">Zheng, L. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">64ec8c4eb0734d60a5287e3df62652bd</data>
      <data key="d13">1150</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CHIANG, W.-L." target="SHENG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. and Sheng, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">7636104f26794a4e9e74b2d6943c879d</data>
      <data key="d13">1151</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CHIANG, W.-L." target="WU, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. and Wu, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">fc4b406a34ea4b2d9f305600aab14ea3</data>
      <data key="d13">1152</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CHIANG, W.-L." target="ZHUANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. and Zhuang, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">5400473bab9d4105a1517fdc55c58f17</data>
      <data key="d13">1153</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CHIANG, W.-L." target="LIN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">624a1e6ea1d248f8b5126527e82e76c0</data>
      <data key="d13">1154</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CHIANG, W.-L." target="LI, D.">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">66e53a4f6fc740aaaa379aa63d15f0e9</data>
      <data key="d13">1155</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CHIANG, W.-L." target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">e676d0167a3f43478a209ec9526c90df</data>
      <data key="d13">1156</data>
      <data key="d14">1</data>
    </edge>
    <edge source="CHIANG, W.-L." target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">Chiang, W.-L. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">44fa3d2247904198b1c776e060d35eb2</data>
      <data key="d13">1157</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHENG, Y." target="WU, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Sheng, Y. and Wu, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">a135859c7d3d4d3596f1e4ab218eff8a</data>
      <data key="d13">1158</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHENG, Y." target="ZHUANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Sheng, Y. and Zhuang, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">5e6fd98384a24a34b80311842661e00a</data>
      <data key="d13">1159</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHENG, Y." target="LIN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Sheng, Y. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">3a10d5261d4240c7b05b6cdb7838ff24</data>
      <data key="d13">1160</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHENG, Y." target="LI, D.">
      <data key="d9">1.0</data>
      <data key="d10">Sheng, Y. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">ec595c7b07e148dba900040a68ef0fdb</data>
      <data key="d13">1161</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHENG, Y." target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Sheng, Y. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">4b43619c5c6a4ea3826bfd3c06aa6e66</data>
      <data key="d13">1162</data>
      <data key="d14">1</data>
    </edge>
    <edge source="SHENG, Y." target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">Sheng, Y. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">3173671571f14c75bfb9141754424efa</data>
      <data key="d13">1163</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WU, Z." target="ZHUANG, Y.">
      <data key="d9">1.0</data>
      <data key="d10">Wu, Z. and Zhuang, Y. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">1675e75d7b524d4ab236eeaefd2dc992</data>
      <data key="d13">1164</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WU, Z." target="LIN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Wu, Z. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">bb906c8e869141aa9be12118dcd3d3b5</data>
      <data key="d13">1165</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WU, Z." target="LI, D.">
      <data key="d9">1.0</data>
      <data key="d10">Wu, Z. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">27c95f7d6c3d4732897ae7bffd7c5dc8</data>
      <data key="d13">1166</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WU, Z." target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Wu, Z. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">b63c467faf714acd8a006431faf7a141</data>
      <data key="d13">1167</data>
      <data key="d14">1</data>
    </edge>
    <edge source="WU, Z." target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">Wu, Z. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">19a5840a67e14c468f9f3d6851eaee5c</data>
      <data key="d13">1168</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, Y." target="LIN, Z.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, Y. and Lin, Z. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">7a58673144d849e7a784caee9d9d4e99</data>
      <data key="d13">1169</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, Y." target="LI, D.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, Y. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">8076db94b7214fdf9e006ce5a7e1cbe2</data>
      <data key="d13">1170</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, Y." target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, Y. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">e733886404db4d46862bdddb2aee5211</data>
      <data key="d13">1171</data>
      <data key="d14">1</data>
    </edge>
    <edge source="ZHUANG, Y." target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">Zhuang, Y. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">b75594a9d9c8404688a5cfe02272cdfc</data>
      <data key="d13">1172</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIN, Z." target="LI, D.">
      <data key="d9">1.0</data>
      <data key="d10">Lin, Z. and Li, D. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">f253ff2311024729a758bb77b14bf72d</data>
      <data key="d13">1173</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIN, Z." target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Lin, Z. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">1f0cb1e7fae64c238efb659d254d6221</data>
      <data key="d13">1174</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LIN, Z." target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">Lin, Z. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">6740be36e0e14774a5551a17db648a13</data>
      <data key="d13">1175</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, D." target="XING, E.">
      <data key="d9">1.0</data>
      <data key="d10">Li, D. and Xing, E. co-authored the paper "Judging llm-as-a-judge with mt-bench and chatbot arena"</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">0f926e9dfaae4615b16a794e984b85ae</data>
      <data key="d13">1176</data>
      <data key="d14">1</data>
    </edge>
    <edge source="LI, D." target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">Li, D. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">47851446a4df4f5aa4505c999daaaaf7</data>
      <data key="d13">1177</data>
      <data key="d14">1</data>
    </edge>
    <edge source="XING, E." target="CHATBOT ARENA">
      <data key="d9">1.0</data>
      <data key="d10">Xing, E. is an author of the paper that discusses Chatbot Arena</data>
      <data key="d11">b1bbda43309e8e0e2175ea034aa88e13</data>
      <data key="d12">c3e51a2782ba4f86b49b4038a316d9fb</data>
      <data key="d13">1178</data>
      <data key="d14">1</data>
    </edge>
  </graph>
</graphml>