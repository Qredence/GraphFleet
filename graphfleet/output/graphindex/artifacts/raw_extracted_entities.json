{"id":"e8d83e6e7a7c0f57b218cef24976b745","chunk":"From Local to Global: A Graph RAG Approach to\nQuery-Focused Summarization\nDarren Edge1\u2020Ha Trinh1\u2020Newman Cheng2Joshua Bradley2Alex Chao3\nApurva Mody3Steven Truitt2\nJonathan Larson1\n1Microsoft Research\n2Microsoft Strategic Missions and Technologies\n3Microsoft Office of the CTO\n{daedge,trinhha,newmancheng,joshbradley,achao,moapurva,steventruitt,jolarso }\n@microsoft.com\n\u2020These authors contributed equally to this work\nAbstract\nThe use of retrieval-augmented generation (RAG) to retrieve relevant informa-\ntion from an external knowledge source enables large language models (LLMs)\nto answer questions over private and\/or previously unseen document collections.\nHowever, RAG fails on global questions directed at an entire text corpus, such\nas \u201cWhat are the main themes in the dataset?\u201d, since this is inherently a query-\nfocused summarization (QFS) task, rather than an explicit retrieval task. Prior\nQFS methods, meanwhile, fail to scale to the quantities of text indexed by typical\nRAG systems. To combine the strengths of these contrasting methods, we propose\na Graph RAG approach to question answering over private text corpora that scales\nwith both the generality of user questions and the quantity of source text to be in-\ndexed. Our approach uses an LLM to build a graph-based text index in two stages:\nfirst to derive an entity knowledge graph from the source documents, then to pre-\ngenerate community summaries for all groups of closely-related entities. Given a\nquestion, each community summary is used to generate a partial response, before\nall partial responses are again summarized in a final response to the user. For a\nclass of global sensemaking questions over datasets in the 1 million token range,\nwe show that Graph RAG leads to substantial improvements over a na \u00a8\u0131ve RAG\nbaseline for both the comprehensiveness and diversity of generated answers. An\nopen-source, Python-based implementation of both global and local Graph RAG\napproaches is forthcoming at https:\/\/aka .ms\/graphrag .\n1 Introduction\nHuman endeavors across a range of domains rely on our ability to read and reason about large\ncollections of documents, often reaching conclusions that go beyond anything stated in the source\ntexts themselves. With the emergence of large language models (LLMs), we are already witnessing\nattempts to automate human-like sense","chunk_id":"e8d83e6e7a7c0f57b218cef24976b745","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"DARREN EDGE","type":"PERSON","description":"Darren Edge is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"HA TRINH","type":"PERSON","description":"Ha Trinh is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"NEWMAN CHENG","type":"PERSON","description":"Newman Cheng is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"JOSHUA BRADLEY","type":"PERSON","description":"Joshua Bradley is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"ALEX CHAO","type":"PERSON","description":"Alex Chao is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"APURVA MODY","type":"PERSON","description":"Apurva Mody is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"STEVEN TRUITT","type":"PERSON","description":"Steven Truitt is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"JONATHAN LARSON","type":"PERSON","description":"Jonathan Larson is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"MICROSOFT RESEARCH","type":"ORGANIZATION","description":"Microsoft Research is an organization where some of the authors of the paper are affiliated","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES","type":"ORGANIZATION","description":"Microsoft Strategic Missions and Technologies is an organization where some of the authors of the paper are affiliated","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"MICROSOFT OFFICE OF THE CTO","type":"ORGANIZATION","description":"Microsoft Office of the CTO is an organization where some of the authors of the paper are affiliated","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"RAG","type":"METHOD","description":"RAG (Retrieval-Augmented Generation) is a method used to retrieve relevant information from an external knowledge source to enable large language models to answer questions","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"LLM","type":"TECHNOLOGY","description":"LLM (Large Language Model) is a type of model used to automate human-like sensemaking and reasoning over large collections of documents","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"GRAPH RAG","type":"METHOD","description":"Graph RAG is an approach that combines retrieval-augmented generation with graph-based text indexing to answer questions over private text corpora","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"QFS","type":"METHOD","description":"QFS (Query-Focused Summarization) is a method used to generate summaries based on specific user queries","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"COMMUNITY SUMMARIES","type":"CONCEPT","description":"Community summaries are pre-generated summaries for groups of closely-related entities used in the Graph RAG approach","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"GLOBAL SENSEMAKING QUESTIONS","type":"CONCEPT","description":"Global sensemaking questions are questions that require understanding and summarizing large datasets, often beyond the explicit content of the source texts","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"1 MILLION TOKEN RANGE","type":"METRIC","description":"1 million token range refers to the scale of datasets used in the evaluation of the Graph RAG approach","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"PYTHON","type":"TECHNOLOGY","description":"Python is a programming language used to implement the open-source version of the Graph RAG approach","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"HTTPS:\/\/AKA.MS\/GRAPHRAG","type":"URL","description":"The URL where the open-source implementation of the Graph RAG approach will be available","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"QUERY-FOCUSED SUMMARIZATION","type":"METHOD","description":"Query-Focused Summarization (QFS) is a method used to generate summaries based on specific user queries","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"EXTERNAL KNOWLEDGE SOURCE","type":"CONCEPT","description":"An external knowledge source is a repository of information that can be accessed to retrieve relevant data for answering questions","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"TEXT CORPUS","type":"CONCEPT","description":"A text corpus is a large collection of written texts used for analysis and research","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"ENTITY KNOWLEDGE GRAPH","type":"CONCEPT","description":"An entity knowledge graph is a graph-based representation of entities and their relationships derived from source documents","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"SOURCE DOCUMENTS","type":"CONCEPT","description":"Source documents are the original texts from which information is retrieved or summarized","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"PARTIAL RESPONSE","type":"CONCEPT","description":"A partial response is an intermediate answer generated from community summaries before being combined into a final response","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"FINAL RESPONSE","type":"CONCEPT","description":"A final response is the comprehensive answer generated after combining all partial responses","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"COMPREHENSIVENESS","type":"METRIC","description":"Comprehensiveness is a metric used to evaluate the extent to which generated answers cover the relevant information","source_id":"e8d83e6e7a7c0f57b218cef24976b745"},{"name":"DIVERSITY","type":"METRIC","description":"Diversity is a metric used to evaluate the variety of information included in the generated answers","source_id":"e8d83e6e7a7c0f57b218cef24976b745"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"DARREN EDGE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Darren Edge is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"HA TRINH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ha Trinh is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"NEWMAN CHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Newman Cheng is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"JOSHUA BRADLEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joshua Bradley is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"ALEX CHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alex Chao is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"APURVA MODY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Apurva Mody is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"STEVEN TRUITT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Steven Truitt is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"JONATHAN LARSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jonathan Larson is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"MICROSOFT RESEARCH\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft Research is an organization where some of the authors of the paper are affiliated<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft Strategic Missions and Technologies is an organization where some of the authors of the paper are affiliated<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"MICROSOFT OFFICE OF THE CTO\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft Office of the CTO is an organization where some of the authors of the paper are affiliated<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">RAG (Retrieval-Augmented Generation) is a method used to retrieve relevant information from an external knowledge source to enable large language models to answer questions<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">LLM (Large Language Model) is a type of model used to automate human-like sensemaking and reasoning over large collections of documents<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG is an approach that combines retrieval-augmented generation with graph-based text indexing to answer questions over private text corpora<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"QFS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">QFS (Query-Focused Summarization) is a method used to generate summaries based on specific user queries<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Community summaries are pre-generated summaries for groups of closely-related entities used in the Graph RAG approach<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"GLOBAL SENSEMAKING QUESTIONS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Global sensemaking questions are questions that require understanding and summarizing large datasets, often beyond the explicit content of the source texts<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"1 MILLION TOKEN RANGE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">1 million token range refers to the scale of datasets used in the evaluation of the Graph RAG approach<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"PYTHON\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Python is a programming language used to implement the open-source version of the Graph RAG approach<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"HTTPS:\/\/AKA.MS\/GRAPHRAG\">      <data key=\"d0\">URL<\/data>      <data key=\"d1\">The URL where the open-source implementation of the Graph RAG approach will be available<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Query-Focused Summarization (QFS) is a method used to generate summaries based on specific user queries<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"EXTERNAL KNOWLEDGE SOURCE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">An external knowledge source is a repository of information that can be accessed to retrieve relevant data for answering questions<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"TEXT CORPUS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A text corpus is a large collection of written texts used for analysis and research<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"ENTITY KNOWLEDGE GRAPH\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">An entity knowledge graph is a graph-based representation of entities and their relationships derived from source documents<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"SOURCE DOCUMENTS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Source documents are the original texts from which information is retrieved or summarized<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"PARTIAL RESPONSE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A partial response is an intermediate answer generated from community summaries before being combined into a final response<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"FINAL RESPONSE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A final response is the comprehensive answer generated after combining all partial responses<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Comprehensiveness is a metric used to evaluate the extent to which generated answers cover the relevant information<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Diversity is a metric used to evaluate the variety of information included in the generated answers<\/data>      <data key=\"d2\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/node>    <edge source=\"DARREN EDGE\" target=\"HA TRINH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Darren Edge and Ha Trinh co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"NEWMAN CHENG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Darren Edge and Newman Cheng co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"JOSHUA BRADLEY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Darren Edge and Joshua Bradley co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"ALEX CHAO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Darren Edge and Alex Chao co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"APURVA MODY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Darren Edge and Apurva Mody co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"STEVEN TRUITT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Darren Edge and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"JONATHAN LARSON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Darren Edge and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Darren Edge is affiliated with Microsoft Research<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"NEWMAN CHENG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ha Trinh and Newman Cheng co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"JOSHUA BRADLEY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ha Trinh and Joshua Bradley co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"ALEX CHAO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ha Trinh and Alex Chao co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"APURVA MODY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ha Trinh and Apurva Mody co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"STEVEN TRUITT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ha Trinh and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"JONATHAN LARSON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ha Trinh and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ha Trinh is affiliated with Microsoft Research<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"JOSHUA BRADLEY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Newman Cheng and Joshua Bradley co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"ALEX CHAO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Newman Cheng and Alex Chao co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"APURVA MODY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Newman Cheng and Apurva Mody co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"STEVEN TRUITT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Newman Cheng and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"JONATHAN LARSON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Newman Cheng and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Newman Cheng is affiliated with Microsoft Strategic Missions and Technologies<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"JOSHUA BRADLEY\" target=\"ALEX CHAO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Joshua Bradley and Alex Chao co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"JOSHUA BRADLEY\" target=\"APURVA MODY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Joshua Bradley and Apurva Mody co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"JOSHUA BRADLEY\" target=\"STEVEN TRUITT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Joshua Bradley and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"JOSHUA BRADLEY\" target=\"JONATHAN LARSON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Joshua Bradley and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"JOSHUA BRADLEY\" target=\"MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Joshua Bradley is affiliated with Microsoft Strategic Missions and Technologies<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"ALEX CHAO\" target=\"APURVA MODY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alex Chao and Apurva Mody co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"ALEX CHAO\" target=\"STEVEN TRUITT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alex Chao and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"ALEX CHAO\" target=\"JONATHAN LARSON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alex Chao and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"ALEX CHAO\" target=\"MICROSOFT OFFICE OF THE CTO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alex Chao is affiliated with Microsoft Office of the CTO<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"APURVA MODY\" target=\"STEVEN TRUITT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Apurva Mody and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"APURVA MODY\" target=\"JONATHAN LARSON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Apurva Mody and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"APURVA MODY\" target=\"MICROSOFT OFFICE OF THE CTO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Apurva Mody is affiliated with Microsoft Office of the CTO<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"STEVEN TRUITT\" target=\"JONATHAN LARSON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Steven Truitt and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"STEVEN TRUITT\" target=\"MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Steven Truitt is affiliated with Microsoft Strategic Missions and Technologies<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"JONATHAN LARSON\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Jonathan Larson is affiliated with Microsoft Research<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"RAG\" target=\"LLM\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">RAG uses LLMs to retrieve relevant information from external knowledge sources<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"RAG\" target=\"GRAPH RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG combines the strengths of RAG with graph-based text indexing<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"RAG\" target=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Query-Focused Summarization is a task that RAG fails to address effectively<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"RAG\" target=\"EXTERNAL KNOWLEDGE SOURCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">RAG retrieves relevant information from an external knowledge source<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"LLM\" target=\"GRAPH RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses LLMs to build a graph-based text index<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"QFS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is proposed as a method to combine the strengths of RAG and QFS<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community summaries are used in the Graph RAG approach to generate partial responses<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GLOBAL SENSEMAKING QUESTIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is designed to handle global sensemaking questions over large datasets<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"PYTHON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is implemented in Python<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"HTTPS:\/\/AKA.MS\/GRAPHRAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The open-source implementation of Graph RAG will be available at this URL<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ENTITY KNOWLEDGE GRAPH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses an entity knowledge graph to index text<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMPREHENSIVENESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG improves the comprehensiveness of generated answers<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DIVERSITY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG improves the diversity of generated answers<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"PARTIAL RESPONSE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community summaries are used to generate partial responses<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"GLOBAL SENSEMAKING QUESTIONS\" target=\"1 MILLION TOKEN RANGE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Global sensemaking questions are evaluated over datasets in the 1 million token range<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"GLOBAL SENSEMAKING QUESTIONS\" target=\"TEXT CORPUS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Global sensemaking questions are directed at an entire text corpus<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"ENTITY KNOWLEDGE GRAPH\" target=\"SOURCE DOCUMENTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">An entity knowledge graph is derived from source documents<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>    <edge source=\"PARTIAL RESPONSE\" target=\"FINAL RESPONSE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Partial responses are summarized to generate a final response<\/data>      <data key=\"d5\">e8d83e6e7a7c0f57b218cef24976b745<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"f0306814bf64f5c9e79603fc6a52f4ea","chunk":" .\n1 Introduction\nHuman endeavors across a range of domains rely on our ability to read and reason about large\ncollections of documents, often reaching conclusions that go beyond anything stated in the source\ntexts themselves. With the emergence of large language models (LLMs), we are already witnessing\nattempts to automate human-like sensemaking in complex domains like scientific discovery (Mi-\ncrosoft, 2023) and intelligence analysis (Ranade and Joshi, 2023), where sensemaking is defined as\nPreprint. Under review.arXiv:2404.16130v1  [cs.CL]  24 Apr 2024Source Documents\nText Chunkstext extraction\nand chunking\nElement Instancesdomain-tailored\nsummarization\nElement Summariesdomain-tailored\nsummarization\nGraph Communitiescommunity\ndetectionCommunity Summaries\ndomain-tailored\nsummarizationCommunity Answers\nquery-focused\nsummarizationGlobal Answer\nquery-focused\nsummarization\nIndexing Time Query Time Pipeline Stage\nFigure 1: Graph RAG pipeline using an LLM-derived graph index of source document text. This\nindex spans nodes (e.g., entities), edges (e.g., relationships), and covariates (e.g., claims) that have\nbeen detected, extracted, and summarized by LLM prompts tailored to the domain of the dataset.\nCommunity detection (e.g., Leiden, Traag et al., 2019) is used to partition the graph index into\ngroups of elements (nodes, edges, covariates) that the LLM can summarize in parallel at both index-\ning time and query time. The \u201cglobal answer\u201d to a given query is produced using a final round of\nquery-focused summarization over all community summaries reporting relevance to that query.\n\u201ca motivated, continuous effort to understand connections (which can be among people, places, and\nevents) in order to anticipate their trajectories and act effectively \u201d (Klein et al., 2006a). Supporting\nhuman-led sensemaking over entire text corpora, however, needs a way for people to both apply and\nrefine their mental model of the data (Klein et al., 2006b) by asking questions of a global nature.\nRetrieval-augmented generation (RAG, Lewis et al., 2020) is an established approach to answering\nuser questions over entire datasets, but it is designed for situations where these answers are contained\nlocally within regions","chunk_id":"f0306814bf64f5c9e79603fc6a52f4ea","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"HUMAN ENDEAVORS","type":"ACTIVITY","description":"Human endeavors refer to activities and efforts across various domains that rely on reading and reasoning about large collections of documents","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"LARGE LANGUAGE MODELS (LLMS)","type":"TECHNOLOGY","description":"Large language models are advanced AI models designed to understand and generate human-like text, used in automating sensemaking in complex domains","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"SCIENTIFIC DISCOVERY","type":"DOMAIN","description":"Scientific discovery is a complex domain where sensemaking is applied to understand and generate new knowledge from scientific texts","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"INTELLIGENCE ANALYSIS","type":"DOMAIN","description":"Intelligence analysis is a complex domain where sensemaking is applied to understand and generate insights from intelligence data","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"SENSEMAKING","type":"PROCESS","description":"Sensemaking is the process of understanding connections among people, places, and events to anticipate their trajectories and act effectively","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"SOURCE DOCUMENTS","type":"DATA","description":"Source documents are the original texts from which information is extracted and analyzed","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"TEXT CHUNKS","type":"DATA","description":"Text chunks are segments of source documents that are extracted for further analysis","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"ELEMENT INSTANCES","type":"DATA","description":"Element instances are specific pieces of information extracted from text chunks, tailored to the domain","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"ELEMENT SUMMARIES","type":"DATA","description":"Element summaries are concise representations of element instances, tailored to the domain","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"GRAPH COMMUNITIES","type":"DATA","description":"Graph communities are groups of elements (nodes, edges, covariates) detected in a graph index, used for summarization","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"COMMUNITY SUMMARIES","type":"DATA","description":"Community summaries are summaries of graph communities, tailored to the domain","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"COMMUNITY ANSWERS","type":"DATA","description":"Community answers are query-focused summaries of community summaries","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"GLOBAL ANSWER","type":"DATA","description":"Global answer is the final query-focused summary produced from all relevant community summaries","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"INDEXING TIME","type":"TIME","description":"Indexing time refers to the time when the graph index is created and elements are summarized","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"QUERY TIME","type":"TIME","description":"Query time refers to the time when a query is made and the relevant summaries are generated","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"GRAPH RAG PIPELINE","type":"PROCESS","description":"Graph RAG pipeline is a process using an LLM-derived graph index to detect, extract, and summarize nodes, edges, and covariates in source documents","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"NODES","type":"DATA","description":"Nodes are entities detected in the graph index of source documents","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"EDGES","type":"DATA","description":"Edges are relationships detected in the graph index of source documents","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"COVARIATES","type":"DATA","description":"Covariates are claims or additional information detected in the graph index of source documents","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"LEIDEN","type":"METHOD","description":"Leiden is a community detection method used to partition the graph index into groups of elements","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"RETRIEVAL-AUGMENTED GENERATION (RAG)","type":"METHOD","description":"Retrieval-augmented generation is an approach to answering user questions over entire datasets by retrieving and generating relevant information","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"MICROSOFT","type":"ORGANIZATION","description":"Microsoft is an organization involved in automating sensemaking in scientific discovery using LLMs","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"RANADE","type":"PERSON","description":"Ranade is an author involved in research on automating sensemaking in intelligence analysis using LLMs","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"JOSHI","type":"PERSON","description":"Joshi is an author involved in research on automating sensemaking in intelligence analysis using LLMs","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"KLEIN","type":"PERSON","description":"Klein is an author who defined sensemaking and discussed its importance in understanding connections among people, places, and events","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"LEWIS","type":"PERSON","description":"Lewis is an author who contributed to the development of the retrieval-augmented generation (RAG) approach","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"TRAAG","type":"PERSON","description":"Traag is an author who contributed to the development of the Leiden community detection method","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is a repository where the preprint of the discussed research paper is available","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"PREPRINT","type":"PUBLICATION","description":"Preprint refers to the version of the research paper that is under review and available on arXiv","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"CS.CL","type":"CATEGORY","description":"cs.CL is the category under which the research paper is classified on arXiv","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"24 APR 2024","type":"DATE","description":"24 Apr 2024 is the date when the research paper was submitted to arXiv","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"2404.16130V1","type":"IDENTIFIER","description":"2404.16130v1 is the identifier for the research paper on arXiv","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"DOCUMENT COLLECTIONS","type":"DATA","description":"Document collections refer to large sets of documents that are analyzed for sensemaking","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"LLM PROMPTS","type":"TECHNOLOGY","description":"LLM prompts are specific instructions given to large language models to tailor their responses to the domain of the dataset","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"COMMUNITY DETECTION","type":"METHOD","description":"Community detection is a method used to identify groups of related elements within a graph","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"QUERY-FOCUSED SUMMARIZATION","type":"METHOD","description":"Query-focused summarization is a method used to generate summaries that are relevant to a specific query","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"DOMAIN-TAILORED SUMMARIZATION","type":"METHOD","description":"Domain-tailored summarization is a method used to create summaries that are specific to the domain of the dataset","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"KLEIN ET AL.","type":"PERSON","description":"Klein et al. are authors who defined sensemaking and discussed its importance in understanding connections among people, places, and events","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"RANADE AND JOSHI","type":"PERSON","description":"Ranade and Joshi are authors who discussed the use of LLMs in intelligence analysis","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"LEWIS ET AL.","type":"PERSON","description":"Lewis et al. are authors who developed the retrieval-augmented generation (RAG) approach","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"},{"name":"TRAAG ET AL.","type":"PERSON","description":"Traag et al. are authors who developed the Leiden community detection method","source_id":"f0306814bf64f5c9e79603fc6a52f4ea"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"HUMAN ENDEAVORS\">      <data key=\"d0\">ACTIVITY<\/data>      <data key=\"d1\">Human endeavors refer to activities and efforts across various domains that rely on reading and reasoning about large collections of documents<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"LARGE LANGUAGE MODELS (LLMS)\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Large language models are advanced AI models designed to understand and generate human-like text, used in automating sensemaking in complex domains<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"SCIENTIFIC DISCOVERY\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Scientific discovery is a complex domain where sensemaking is applied to understand and generate new knowledge from scientific texts<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"INTELLIGENCE ANALYSIS\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Intelligence analysis is a complex domain where sensemaking is applied to understand and generate insights from intelligence data<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"SENSEMAKING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Sensemaking is the process of understanding connections among people, places, and events to anticipate their trajectories and act effectively<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"SOURCE DOCUMENTS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Source documents are the original texts from which information is extracted and analyzed<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"TEXT CHUNKS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Text chunks are segments of source documents that are extracted for further analysis<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"ELEMENT INSTANCES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Element instances are specific pieces of information extracted from text chunks, tailored to the domain<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"ELEMENT SUMMARIES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Element summaries are concise representations of element instances, tailored to the domain<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"GRAPH COMMUNITIES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Graph communities are groups of elements (nodes, edges, covariates) detected in a graph index, used for summarization<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Community summaries are summaries of graph communities, tailored to the domain<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"COMMUNITY ANSWERS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Community answers are query-focused summaries of community summaries<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"GLOBAL ANSWER\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Global answer is the final query-focused summary produced from all relevant community summaries<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"INDEXING TIME\">      <data key=\"d0\">TIME<\/data>      <data key=\"d1\">Indexing time refers to the time when the graph index is created and elements are summarized<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"QUERY TIME\">      <data key=\"d0\">TIME<\/data>      <data key=\"d1\">Query time refers to the time when a query is made and the relevant summaries are generated<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"GRAPH RAG PIPELINE\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Graph RAG pipeline is a process using an LLM-derived graph index to detect, extract, and summarize nodes, edges, and covariates in source documents<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"NODES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Nodes are entities detected in the graph index of source documents<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"EDGES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Edges are relationships detected in the graph index of source documents<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"COVARIATES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Covariates are claims or additional information detected in the graph index of source documents<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"LEIDEN\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Leiden is a community detection method used to partition the graph index into groups of elements<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"RETRIEVAL-AUGMENTED GENERATION (RAG)\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Retrieval-augmented generation is an approach to answering user questions over entire datasets by retrieving and generating relevant information<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"MICROSOFT\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft is an organization involved in automating sensemaking in scientific discovery using LLMs<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"RANADE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ranade is an author involved in research on automating sensemaking in intelligence analysis using LLMs<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"JOSHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joshi is an author involved in research on automating sensemaking in intelligence analysis using LLMs<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"KLEIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Klein is an author who defined sensemaking and discussed its importance in understanding connections among people, places, and events<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"LEWIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lewis is an author who contributed to the development of the retrieval-augmented generation (RAG) approach<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"TRAAG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Traag is an author who contributed to the development of the Leiden community detection method<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is a repository where the preprint of the discussed research paper is available<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"PREPRINT\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Preprint refers to the version of the research paper that is under review and available on arXiv<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"CS.CL\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">cs.CL is the category under which the research paper is classified on arXiv<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"24 APR 2024\">      <data key=\"d0\">DATE<\/data>      <data key=\"d1\">24 Apr 2024 is the date when the research paper was submitted to arXiv<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"2404.16130V1\">      <data key=\"d0\">IDENTIFIER<\/data>      <data key=\"d1\">2404.16130v1 is the identifier for the research paper on arXiv<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"DOCUMENT COLLECTIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Document collections refer to large sets of documents that are analyzed for sensemaking<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"LLM PROMPTS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">LLM prompts are specific instructions given to large language models to tailor their responses to the domain of the dataset<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"COMMUNITY DETECTION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Community detection is a method used to identify groups of related elements within a graph<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Query-focused summarization is a method used to generate summaries that are relevant to a specific query<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"DOMAIN-TAILORED SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Domain-tailored summarization is a method used to create summaries that are specific to the domain of the dataset<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"KLEIN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Klein et al. are authors who defined sensemaking and discussed its importance in understanding connections among people, places, and events<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"RANADE AND JOSHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ranade and Joshi are authors who discussed the use of LLMs in intelligence analysis<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"LEWIS ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lewis et al. are authors who developed the retrieval-augmented generation (RAG) approach<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <node id=\"TRAAG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Traag et al. are authors who developed the Leiden community detection method<\/data>      <data key=\"d2\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/node>    <edge source=\"HUMAN ENDEAVORS\" target=\"SENSEMAKING\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Human endeavors rely on sensemaking to understand and reason about large collections of documents<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"HUMAN ENDEAVORS\" target=\"DOCUMENT COLLECTIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Human endeavors rely on analyzing document collections for sensemaking<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"SENSEMAKING\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLMs are used to automate sensemaking in complex domains<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"MICROSOFT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Microsoft uses LLMs for automating sensemaking in scientific discovery<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"RANADE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ranade uses LLMs for automating sensemaking in intelligence analysis<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"JOSHI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Joshi uses LLMs for automating sensemaking in intelligence analysis<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"LLM PROMPTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM prompts are used to tailor the responses of large language models<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"RANADE AND JOSHI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ranade and Joshi discussed the use of LLMs in intelligence analysis<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"SCIENTIFIC DISCOVERY\" target=\"SENSEMAKING\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sensemaking is applied in the domain of scientific discovery<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"INTELLIGENCE ANALYSIS\" target=\"SENSEMAKING\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sensemaking is applied in the domain of intelligence analysis<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"SENSEMAKING\" target=\"KLEIN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Klein defined and discussed the importance of sensemaking<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"SENSEMAKING\" target=\"KLEIN ET AL.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Klein et al. defined and discussed the importance of sensemaking<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"SOURCE DOCUMENTS\" target=\"TEXT CHUNKS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Text chunks are extracted from source documents<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"TEXT CHUNKS\" target=\"ELEMENT INSTANCES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Element instances are extracted from text chunks<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"ELEMENT INSTANCES\" target=\"ELEMENT SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Element summaries are created from element instances<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"ELEMENT SUMMARIES\" target=\"DOMAIN-TAILORED SUMMARIZATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Domain-tailored summarization is used to create element summaries<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"GRAPH COMMUNITIES\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community summaries are created from graph communities<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"GRAPH COMMUNITIES\" target=\"COMMUNITY DETECTION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community detection is used to identify graph communities<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"COMMUNITY ANSWERS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community answers are created from community summaries<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"DOMAIN-TAILORED SUMMARIZATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Domain-tailored summarization is used to create community summaries<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"COMMUNITY ANSWERS\" target=\"GLOBAL ANSWER\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Global answer is created from community answers<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"GLOBAL ANSWER\" target=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Query-focused summarization is used to produce the global answer<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"INDEXING TIME\" target=\"GRAPH RAG PIPELINE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG pipeline operates at indexing time<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"QUERY TIME\" target=\"GRAPH RAG PIPELINE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG pipeline operates at query time<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"GRAPH RAG PIPELINE\" target=\"NODES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Nodes are detected in the graph RAG pipeline<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"GRAPH RAG PIPELINE\" target=\"EDGES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Edges are detected in the graph RAG pipeline<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"GRAPH RAG PIPELINE\" target=\"COVARIATES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Covariates are detected in the graph RAG pipeline<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"GRAPH RAG PIPELINE\" target=\"LEIDEN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Leiden method is used in the graph RAG pipeline for community detection<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"GRAPH RAG PIPELINE\" target=\"RETRIEVAL-AUGMENTED GENERATION (RAG)\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG pipeline uses the RAG approach<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"TRAAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Traag contributed to the development of the Leiden method<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"TRAAG ET AL.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Traag et al. developed the Leiden method<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"RETRIEVAL-AUGMENTED GENERATION (RAG)\" target=\"LEWIS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Lewis contributed to the development of the RAG approach<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"RETRIEVAL-AUGMENTED GENERATION (RAG)\" target=\"LEWIS ET AL.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Lewis et al. developed the RAG approach<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Preprint is available on arXiv<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"PREPRINT\" target=\"CS.CL\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Preprint is classified under cs.CL on arXiv<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"PREPRINT\" target=\"24 APR 2024\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Preprint was submitted on 24 Apr 2024<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>    <edge source=\"PREPRINT\" target=\"2404.16130V1\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Preprint has the identifier 2404.16130v1 on arXiv<\/data>      <data key=\"d5\">f0306814bf64f5c9e79603fc6a52f4ea<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"fb3c48579608fa28be585ceb6cd2f0fe","chunk":" et al., 2006b) by asking questions of a global nature.\nRetrieval-augmented generation (RAG, Lewis et al., 2020) is an established approach to answering\nuser questions over entire datasets, but it is designed for situations where these answers are contained\nlocally within regions of text whose retrieval provides sufficient grounding for the generation task.\nInstead, a more appropriate task framing is query-focused summarization (QFS, Dang, 2006), and in\nparticular, query-focused abstractive summarization that generates natural language summaries and\nnot just concatenated excerpts (Baumel et al., 2018; Laskar et al., 2020; Yao et al., 2017) . In recent\nyears, however, such distinctions between summarization tasks that are abstractive versus extractive,\ngeneric versus query-focused, and single-document versus multi-document, have become less rele-\nvant. While early applications of the transformer architecture showed substantial improvements on\nthe state-of-the-art for all such summarization tasks (Goodwin et al., 2020; Laskar et al., 2022; Liu\nand Lapata, 2019), these tasks are now trivialized by modern LLMs, including the GPT (Achiam\net al., 2023; Brown et al., 2020), Llama (Touvron et al., 2023), and Gemini (Anil et al., 2023) series,\nall of which can use in-context learning to summarize any content provided in their context window.\nThe challenge remains, however, for query-focused abstractive summarization over an entire corpus.\nSuch volumes of text can greatly exceed the limits of LLM context windows, and the expansion of\nsuch windows may not be enough given that information can be \u201clost in the middle\u201d of longer\ncontexts (Kuratov et al., 2024; Liu et al., 2023). In addition, although the direct retrieval of text\nchunks in na \u00a8\u0131ve RAG is likely inadequate for QFS tasks, it is possible that an alternative form of\npre-indexing could support a new RAG approach specifically targeting global summarization.\nIn this paper, we present a Graph RAG approach based on global summarization of an LLM-derived\nknowledge graph (Figure 1). In contrast with related work that exploits the structured retrieval\nand traversal affordances of graph indexes (subsection 4.2","chunk_id":"fb3c48579608fa28be585ceb6cd2f0fe","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"RETRIEVAL-AUGMENTED GENERATION (RAG)","type":"METHOD","description":"RAG is an established approach to answering user questions over entire datasets by retrieving relevant text regions to provide grounding for the generation task","source_id":"fb3c48579608fa28be585ceb6cd2f0fe"},{"name":"QUERY-FOCUSED SUMMARIZATION (QFS)","type":"METHOD","description":"QFS is a task framing that focuses on generating summaries based on specific queries, rather than just concatenating excerpts","source_id":"fb3c48579608fa28be585ceb6cd2f0fe"},{"name":"QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION","type":"METHOD","description":"A type of summarization that generates natural language summaries based on specific queries, rather than just extracting text","source_id":"fb3c48579608fa28be585ceb6cd2f0fe"},{"name":"TRANSFORMER ARCHITECTURE","type":"TECHNOLOGY","description":"A neural network architecture that has shown substantial improvements in various summarization tasks","source_id":"fb3c48579608fa28be585ceb6cd2f0fe"},{"name":"LARGE LANGUAGE MODELS (LLMS)","type":"TECHNOLOGY","description":"Modern language models, including GPT, Llama, and Gemini, that can use in-context learning to summarize content","source_id":"fb3c48579608fa28be585ceb6cd2f0fe"},{"name":"GPT","type":"TECHNOLOGY","description":"A series of large language models known for their ability to perform in-context learning and summarization","source_id":"fb3c48579608fa28be585ceb6cd2f0fe"},{"name":"LLAMA","type":"TECHNOLOGY","description":"A series of large language models known for their ability to perform in-context learning and summarization","source_id":"fb3c48579608fa28be585ceb6cd2f0fe"},{"name":"GEMINI","type":"TECHNOLOGY","description":"A series of large language models known for their ability to perform in-context learning and summarization","source_id":"fb3c48579608fa28be585ceb6cd2f0fe"},{"name":"GRAPH RAG","type":"METHOD","description":"A new approach based on global summarization of an LLM-derived knowledge graph, targeting global summarization tasks","source_id":"fb3c48579608fa28be585ceb6cd2f0fe"},{"name":"KNOWLEDGE GRAPH","type":"TECHNOLOGY","description":"A structured representation of knowledge used in the Graph RAG approach for global summarization","source_id":"fb3c48579608fa28be585ceb6cd2f0fe"},{"name":"LEWIS ET AL., 2020","type":"REFERENCE","description":"Authors of a paper on Retrieval-augmented generation (RAG)","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"DANG, 2006","type":"REFERENCE","description":"Author of a paper on query-focused summarization (QFS)","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"BAUMEL ET AL., 2018","type":"REFERENCE","description":"Authors of a paper on query-focused abstractive summarization","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"LASKAR ET AL., 2020","type":"REFERENCE","description":"Authors of a paper on query-focused abstractive summarization","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"YAO ET AL., 2017","type":"REFERENCE","description":"Authors of a paper on query-focused abstractive summarization","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"GOODWIN ET AL., 2020","type":"REFERENCE","description":"Authors of a paper on the early applications of the transformer architecture","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"LASKAR ET AL., 2022","type":"REFERENCE","description":"Authors of a paper on the early applications of the transformer architecture","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"LIU AND LAPATA, 2019","type":"REFERENCE","description":"Authors of a paper on the early applications of the transformer architecture","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"ACHIAM ET AL., 2023","type":"REFERENCE","description":"Authors of a paper on the GPT series of large language models","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"BROWN ET AL., 2020","type":"REFERENCE","description":"Authors of a paper on the GPT series of large language models","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"TOUVRON ET AL., 2023","type":"REFERENCE","description":"Authors of a paper on the Llama series of large language models","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"ANIL ET AL., 2023","type":"REFERENCE","description":"Authors of a paper on the Gemini series of large language models","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"KURATOV ET AL., 2024","type":"REFERENCE","description":"Authors of a paper on the limitations of LLM context windows","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"},{"name":"LIU ET AL., 2023","type":"REFERENCE","description":"Authors of a paper on the limitations of LLM context windows","source_id":"fb3c48579608fa28be585ceb6cd2f0fe","entity_type":"REFERENCE"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"RETRIEVAL-AUGMENTED GENERATION (RAG)\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">RAG is an established approach to answering user questions over entire datasets by retrieving relevant text regions to provide grounding for the generation task<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/node>    <node id=\"QUERY-FOCUSED SUMMARIZATION (QFS)\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">QFS is a task framing that focuses on generating summaries based on specific queries, rather than just concatenating excerpts<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/node>    <node id=\"QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A type of summarization that generates natural language summaries based on specific queries, rather than just extracting text<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/node>    <node id=\"TRANSFORMER ARCHITECTURE\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A neural network architecture that has shown substantial improvements in various summarization tasks<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/node>    <node id=\"LARGE LANGUAGE MODELS (LLMS)\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Modern language models, including GPT, Llama, and Gemini, that can use in-context learning to summarize content<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/node>    <node id=\"GPT\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A series of large language models known for their ability to perform in-context learning and summarization<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/node>    <node id=\"LLAMA\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A series of large language models known for their ability to perform in-context learning and summarization<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/node>    <node id=\"GEMINI\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A series of large language models known for their ability to perform in-context learning and summarization<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A new approach based on global summarization of an LLM-derived knowledge graph, targeting global summarization tasks<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/node>    <node id=\"KNOWLEDGE GRAPH\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A structured representation of knowledge used in the Graph RAG approach for global summarization<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/node>    <node id=\"LEWIS ET AL., 2020\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on Retrieval-augmented generation (RAG)<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"DANG, 2006\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Author of a paper on query-focused summarization (QFS)<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"BAUMEL ET AL., 2018\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on query-focused abstractive summarization<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"LASKAR ET AL., 2020\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on query-focused abstractive summarization<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"YAO ET AL., 2017\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on query-focused abstractive summarization<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"GOODWIN ET AL., 2020\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on the early applications of the transformer architecture<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"LASKAR ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on the early applications of the transformer architecture<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"LIU AND LAPATA, 2019\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on the early applications of the transformer architecture<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"ACHIAM ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on the GPT series of large language models<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"BROWN ET AL., 2020\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on the GPT series of large language models<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"TOUVRON ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on the Llama series of large language models<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"ANIL ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on the Gemini series of large language models<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"KURATOV ET AL., 2024\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on the limitations of LLM context windows<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"LIU ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Authors of a paper on the limitations of LLM context windows<\/data>      <data key=\"d2\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <edge source=\"RETRIEVAL-AUGMENTED GENERATION (RAG)\" target=\"LEWIS ET AL., 2020\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Lewis et al., 2020, are the authors who established the RAG approach<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"QUERY-FOCUSED SUMMARIZATION (QFS)\" target=\"DANG, 2006\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Dang, 2006, is the author who established the QFS approach<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION\" target=\"BAUMEL ET AL., 2018\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Baumel et al., 2018, are the authors who worked on query-focused abstractive summarization<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION\" target=\"LASKAR ET AL., 2020\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Laskar et al., 2020, are the authors who worked on query-focused abstractive summarization<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION\" target=\"YAO ET AL., 2017\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Yao et al., 2017, are the authors who worked on query-focused abstractive summarization<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"TRANSFORMER ARCHITECTURE\" target=\"GOODWIN ET AL., 2020\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Goodwin et al., 2020, are the authors who worked on the early applications of the transformer architecture<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"TRANSFORMER ARCHITECTURE\" target=\"LASKAR ET AL., 2022\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Laskar et al., 2022, are the authors who worked on the early applications of the transformer architecture<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"TRANSFORMER ARCHITECTURE\" target=\"LIU AND LAPATA, 2019\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Liu and Lapata, 2019, are the authors who worked on the early applications of the transformer architecture<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"GPT\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">GPT is a type of large language model<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"LLAMA\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Llama is a type of large language model<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"GEMINI\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Gemini is a type of large language model<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"KURATOV ET AL., 2024\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Kuratov et al., 2024, discussed the limitations of LLM context windows<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"LARGE LANGUAGE MODELS (LLMS)\" target=\"LIU ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Liu et al., 2023, discussed the limitations of LLM context windows<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"GPT\" target=\"ACHIAM ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Achiam et al., 2023, are the authors who worked on the GPT series of large language models<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"GPT\" target=\"BROWN ET AL., 2020\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Brown et al., 2020, are the authors who worked on the GPT series of large language models<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"LLAMA\" target=\"TOUVRON ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Touvron et al., 2023, are the authors who worked on the Llama series of large language models<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"ANIL ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Anil et al., 2023, are the authors who worked on the Gemini series of large language models<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"KNOWLEDGE GRAPH\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG uses a knowledge graph for global summarization<\/data>      <data key=\"d6\">fb3c48579608fa28be585ceb6cd2f0fe<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"21e52bc06a82796b1f4bcd73edda1f2a","chunk":" a new RAG approach specifically targeting global summarization.\nIn this paper, we present a Graph RAG approach based on global summarization of an LLM-derived\nknowledge graph (Figure 1). In contrast with related work that exploits the structured retrieval\nand traversal affordances of graph indexes (subsection 4.2), we focus on a previously unexplored\nquality of graphs in this context: their inherent modularity (Newman, 2006) and the ability of com-\nmunity detection algorithms to partition graphs into modular communities of closely-related nodes\n(e.g., Louvain, Blondel et al., 2008; Leiden, Traag et al., 2019). LLM-generated summaries of these\n20 1 2 30100002000030000\nNumber of gleanings performedEntity references detected600 chunk size\n1200 chunk size\n2400 chunk size\nFigure 2: How the entity references detected in the HotPotQA dataset (Yang et al., 2018)\nvaries with chunk size and gleanings for our generic entity extraction prompt with gpt-4-turbo .\ncommunity descriptions provide complete coverage of the underlying graph index and the input doc-\numents it represents. Query-focused summarization of an entire corpus is then made possible using\na map-reduce approach: first using each community summary to answer the query independently\nand in parallel, then summarizing all relevant partial answers into a final global answer.\nTo evaluate this approach, we used an LLM to generate a diverse set of activity-centered sense-\nmaking questions from short descriptions of two representative real-world datasets, containing pod-\ncast transcripts and news articles respectively. For the target qualities of comprehensiveness, diver-\nsity, and empowerment (defined in subsection 3.4) that develop understanding of broad issues and\nthemes, we both explore the impact of varying the the hierarchical level of community summaries\nused to answer queries, as well as compare to na \u00a8\u0131ve RAG and global map-reduce summarization\nof source texts. We show that all global approaches outperform na \u00a8\u0131ve RAG on comprehensiveness\nand diversity, and that Graph RAG with intermediate- and low-level community summaries shows\nfavorable performance over source text summarization on these same metrics, at lower token costs.\n2 Graph RAG Approach & Pipeline\nWe now unpack the high-level data flow of the Graph RAG approach (Figure 1) and pipeline, de-\nscribing key design parameters","chunk_id":"21e52bc06a82796b1f4bcd73edda1f2a","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"RAG","type":"METHOD","description":"RAG (Retrieval-Augmented Generation) is a method used for generating responses in text generation tasks","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"GRAPH RAG","type":"METHOD","description":"Graph RAG is a specific approach to RAG that focuses on global summarization using a knowledge graph","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"LLM","type":"TECHNOLOGY","description":"LLM (Large Language Model) is a type of AI model used for generating text and answering queries","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"KNOWLEDGE GRAPH","type":"TECHNOLOGY","description":"A knowledge graph is a structured representation of information, used in the Graph RAG approach for summarization","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"COMMUNITY DETECTION ALGORITHMS","type":"TECHNOLOGY","description":"Algorithms used to partition graphs into modular communities of closely-related nodes","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"LOUVAIN","type":"ALGORITHM","description":"Louvain is a community detection algorithm used to partition graphs into modular communities","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"LEIDEN","type":"ALGORITHM","description":"Leiden is a community detection algorithm used to partition graphs into modular communities","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"HOTPOTQA","type":"DATASET","description":"HotPotQA is a dataset used to evaluate the entity extraction prompt with gpt-4-turbo","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"GPT-4-TURBO","type":"TECHNOLOGY","description":"GPT-4-Turbo is a version of the GPT-4 model used for entity extraction in the evaluation","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"PODCAST TRANSCRIPTS","type":"DATASET","description":"A dataset consisting of transcripts from podcasts used for analysis","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"NEWS ARTICLES","type":"DATASET","description":"A dataset consisting of news articles used for analysis","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"MAP-REDUCE","type":"METHOD","description":"Map-reduce is a method used for query-focused summarization of an entire corpus","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"COMPREHENSIVENESS","type":"METRIC","description":"A target quality used to evaluate the summarization approach, focusing on the completeness of the summary","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"DIVERSITY","type":"METRIC","description":"A target quality used to evaluate the summarization approach, focusing on the variety of information in the summary","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"EMPOWERMENT","type":"METRIC","description":"A target quality used to evaluate the summarization approach, focusing on the ability to develop understanding of broad issues and themes","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"NAIVE RAG","type":"METHOD","description":"Naive RAG is a basic approach to RAG used as a baseline for comparison","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"GLOBAL MAP-REDUCE SUMMARIZATION","type":"METHOD","description":"A method for summarizing source texts using a map-reduce approach","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"COMMUNITY SUMMARIES","type":"OUTPUT","description":"Summaries generated from modular communities in the knowledge graph","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"QUERY-FOCUSED SUMMARIZATION","type":"METHOD","description":"A summarization method that focuses on answering specific queries using the entire corpus","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"ACTIVITY-CENTERED SENSEMAKING QUESTIONS","type":"OUTPUT","description":"Questions generated to evaluate the summarization approach, focusing on understanding activities","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"HIERARCHICAL LEVEL","type":"PARAMETER","description":"The level of detail in community summaries used to answer queries","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"TOKEN COSTS","type":"METRIC","description":"The computational cost measured in tokens used in the summarization process","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"DATA FLOW","type":"PROCESS","description":"The high-level process of the Graph RAG approach and pipeline","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"DESIGN PARAMETERS","type":"PARAMETER","description":"Key parameters that influence the design of the Graph RAG approach and pipeline","source_id":"21e52bc06a82796b1f4bcd73edda1f2a","entity_type":"PARAMETER"},{"name":"GLOBAL SUMMARIZATION","type":"METHOD","description":"Global summarization is a method that aims to summarize information from a large dataset or corpus","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"MODULARITY","type":"ATTRIBUTE","description":"Modularity is an inherent quality of graphs that allows them to be partitioned into communities of closely-related nodes","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"COMMUNITY DESCRIPTIONS","type":"OUTPUT","description":"Descriptions generated from modular communities in the knowledge graph","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"QUERY","type":"INPUT","description":"A specific question or request for information that the summarization methods aim to answer","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"CORPUS","type":"DATASET","description":"A large collection of texts or documents used for analysis and summarization","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"PARTIAL ANSWERS","type":"OUTPUT","description":"Intermediate answers generated from community summaries before being combined into a final global answer","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"FINAL GLOBAL ANSWER","type":"OUTPUT","description":"The comprehensive answer generated by combining all relevant partial answers","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"ACTIVITY-CENTERED SENSEMAKING","type":"METHOD","description":"A method that focuses on generating questions to understand activities from datasets","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"SHORT DESCRIPTIONS","type":"INPUT","description":"Brief descriptions of datasets used to generate sensemaking questions","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"REAL-WORLD DATASETS","type":"DATASET","description":"Datasets that represent real-world information, such as podcast transcripts and news articles","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES","type":"PARAMETER","description":"The level of detail in community summaries used to answer queries","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"SOURCE TEXT SUMMARIZATION","type":"METHOD","description":"A method that summarizes the original source texts directly","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"LOW-LEVEL COMMUNITY SUMMARIES","type":"OUTPUT","description":"Summaries generated from lower hierarchical levels of the community in the knowledge graph","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"INTERMEDIATE-LEVEL COMMUNITY SUMMARIES","type":"OUTPUT","description":"Summaries generated from intermediate hierarchical levels of the community in the knowledge graph","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"},{"name":"HIGH-LEVEL COMMUNITY SUMMARIES","type":"OUTPUT","description":"Summaries generated from higher hierarchical levels of the community in the knowledge graph","source_id":"21e52bc06a82796b1f4bcd73edda1f2a"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">RAG (Retrieval-Augmented Generation) is a method used for generating responses in text generation tasks<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG is a specific approach to RAG that focuses on global summarization using a knowledge graph<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">LLM (Large Language Model) is a type of AI model used for generating text and answering queries<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"KNOWLEDGE GRAPH\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A knowledge graph is a structured representation of information, used in the Graph RAG approach for summarization<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"COMMUNITY DETECTION ALGORITHMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Algorithms used to partition graphs into modular communities of closely-related nodes<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"LOUVAIN\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Louvain is a community detection algorithm used to partition graphs into modular communities<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"LEIDEN\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Leiden is a community detection algorithm used to partition graphs into modular communities<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HotPotQA is a dataset used to evaluate the entity extraction prompt with gpt-4-turbo<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"GPT-4-TURBO\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">GPT-4-Turbo is a version of the GPT-4 model used for entity extraction in the evaluation<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"PODCAST TRANSCRIPTS\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of transcripts from podcasts used for analysis<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"NEWS ARTICLES\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of news articles used for analysis<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"MAP-REDUCE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Map-reduce is a method used for query-focused summarization of an entire corpus<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A target quality used to evaluate the summarization approach, focusing on the completeness of the summary<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A target quality used to evaluate the summarization approach, focusing on the variety of information in the summary<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"EMPOWERMENT\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A target quality used to evaluate the summarization approach, focusing on the ability to develop understanding of broad issues and themes<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"NAIVE RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Naive RAG is a basic approach to RAG used as a baseline for comparison<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"GLOBAL MAP-REDUCE SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method for summarizing source texts using a map-reduce approach<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">Summaries generated from modular communities in the knowledge graph<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A summarization method that focuses on answering specific queries using the entire corpus<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"ACTIVITY-CENTERED SENSEMAKING QUESTIONS\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">Questions generated to evaluate the summarization approach, focusing on understanding activities<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"HIERARCHICAL LEVEL\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">The level of detail in community summaries used to answer queries<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"TOKEN COSTS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The computational cost measured in tokens used in the summarization process<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"DATA FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The high-level process of the Graph RAG approach and pipeline<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"DESIGN PARAMETERS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Key parameters that influence the design of the Graph RAG approach and pipeline<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>      <data key=\"d3\">PARAMETER<\/data>    <\/node>    <node id=\"GLOBAL SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Global summarization is a method that aims to summarize information from a large dataset or corpus<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"MODULARITY\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Modularity is an inherent quality of graphs that allows them to be partitioned into communities of closely-related nodes<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"COMMUNITY DESCRIPTIONS\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">Descriptions generated from modular communities in the knowledge graph<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"QUERY\">      <data key=\"d0\">INPUT<\/data>      <data key=\"d1\">A specific question or request for information that the summarization methods aim to answer<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"CORPUS\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A large collection of texts or documents used for analysis and summarization<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"PARTIAL ANSWERS\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">Intermediate answers generated from community summaries before being combined into a final global answer<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"FINAL GLOBAL ANSWER\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">The comprehensive answer generated by combining all relevant partial answers<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"ACTIVITY-CENTERED SENSEMAKING\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method that focuses on generating questions to understand activities from datasets<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"SHORT DESCRIPTIONS\">      <data key=\"d0\">INPUT<\/data>      <data key=\"d1\">Brief descriptions of datasets used to generate sensemaking questions<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"REAL-WORLD DATASETS\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Datasets that represent real-world information, such as podcast transcripts and news articles<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">The level of detail in community summaries used to answer queries<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"SOURCE TEXT SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method that summarizes the original source texts directly<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"LOW-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">Summaries generated from lower hierarchical levels of the community in the knowledge graph<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"INTERMEDIATE-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">Summaries generated from intermediate hierarchical levels of the community in the knowledge graph<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <node id=\"HIGH-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">Summaries generated from higher hierarchical levels of the community in the knowledge graph<\/data>      <data key=\"d2\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/node>    <edge source=\"RAG\" target=\"GRAPH RAG\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Graph RAG is a specific approach to RAG<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"KNOWLEDGE GRAPH\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Graph RAG uses a knowledge graph for global summarization<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"LLM\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">LLM is used in the Graph RAG approach to generate summaries and answer queries<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY DETECTION ALGORITHMS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community detection algorithms are used in the Graph RAG approach to partition graphs<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"PODCAST TRANSCRIPTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Podcast transcripts are used as a dataset to evaluate the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"NEWS ARTICLES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">News articles are used as a dataset to evaluate the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMPREHENSIVENESS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Comprehensiveness is a target quality used to evaluate the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DIVERSITY\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Diversity is a target quality used to evaluate the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"EMPOWERMENT\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Empowerment is a target quality used to evaluate the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"NAIVE RAG\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Graph RAG is compared to naive RAG in the evaluation<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GLOBAL MAP-REDUCE SUMMARIZATION\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Graph RAG is compared to global map-reduce summarization in the evaluation<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community summaries are generated in the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Query-focused summarization is a method used in the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ACTIVITY-CENTERED SENSEMAKING QUESTIONS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Activity-centered sensemaking questions are used to evaluate the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"HIERARCHICAL LEVEL\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Hierarchical level of community summaries is varied to evaluate the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TOKEN COSTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Token costs are measured to evaluate the efficiency of the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DATA FLOW\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Data flow describes the high-level process of the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DESIGN PARAMETERS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Design parameters influence the Graph RAG approach and pipeline<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GLOBAL SUMMARIZATION\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Graph RAG uses global summarization to summarize information from a large dataset<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"QUERY\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Graph RAG aims to answer specific queries<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"CORPUS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Graph RAG uses a corpus for analysis and summarization<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ACTIVITY-CENTERED SENSEMAKING\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Activity-centered sensemaking is used to evaluate the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"REAL-WORLD DATASETS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Real-world datasets are used to evaluate the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Hierarchical level of community summaries is varied to evaluate the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SOURCE TEXT SUMMARIZATION\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Graph RAG is compared to source text summarization in the evaluation<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"LOW-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Low-level community summaries are generated in the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"INTERMEDIATE-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Intermediate-level community summaries are generated in the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"HIGH-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">High-level community summaries are generated in the Graph RAG approach<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"KNOWLEDGE GRAPH\" target=\"MODULARITY\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Modularity is an inherent quality of knowledge graphs<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"COMMUNITY DETECTION ALGORITHMS\" target=\"LOUVAIN\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Louvain is a type of community detection algorithm<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"COMMUNITY DETECTION ALGORITHMS\" target=\"LEIDEN\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Leiden is a type of community detection algorithm<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"GPT-4-TURBO\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">HotPotQA dataset is used to evaluate the entity extraction prompt with gpt-4-turbo<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"MAP-REDUCE\" target=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Map-reduce is used for query-focused summarization of an entire corpus<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"COMMUNITY DESCRIPTIONS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community descriptions are generated from community summaries<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"PARTIAL ANSWERS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Partial answers are generated from community summaries<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"PARTIAL ANSWERS\" target=\"FINAL GLOBAL ANSWER\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Final global answer is generated by combining all relevant partial answers<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>    <edge source=\"ACTIVITY-CENTERED SENSEMAKING\" target=\"SHORT DESCRIPTIONS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Short descriptions are used to generate sensemaking questions<\/data>      <data key=\"d6\">21e52bc06a82796b1f4bcd73edda1f2a<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"bc9e2c9e369c4108cf4f6dd5f60960f4","chunk":" intermediate- and low-level community summaries shows\nfavorable performance over source text summarization on these same metrics, at lower token costs.\n2 Graph RAG Approach & Pipeline\nWe now unpack the high-level data flow of the Graph RAG approach (Figure 1) and pipeline, de-\nscribing key design parameters, techniques, and implementation details for each step.\n2.1 Source Documents \u2192Text Chunks\nA fundamental design decision is the granularity with which input texts extracted from source doc-\numents should be split into text chunks for processing. In the following step, each of these chunks\nwill be passed to a set of LLM prompts designed to extract the various elements of a graph index.\nLonger text chunks require fewer LLM calls for such extraction, but suffer from the recall degrada-\ntion of longer LLM context windows (Kuratov et al., 2024; Liu et al., 2023). This behavior can be\nobserved in Figure 2 in the case of a single extraction round (i.e., with zero gleanings): on a sample\ndataset (HotPotQA, Yang et al., 2018), using a chunk size of 600 token extracted almost twice as\nmany entity references as when using a chunk size of 2400. While more references are generally\nbetter, any extraction process needs to balance recall and precision for the target activity.\n2.2 Text Chunks \u2192Element Instances\nThe baseline requirement for this step is to identify and extract instances of graph nodes and edges\nfrom each chunk of source text. We do this using a multipart LLM prompt that first identifies all\nentities in the text, including their name, type, and description, before identifying all relationships\nbetween clearly-related entities, including the source and target entities and a description of their\nrelationship. Both kinds of element instance are output in a single list of delimited tuples.\nThe primary opportunity to tailor this prompt to the domain of the document corpus lies in the\nchoice of few-shot examples provided to the LLM for in-context learning (Brown et al., 2020).\n3For example, while our default prompt extracting the broad class of \u201cnamed entities\u201d like people,\nplaces, and organizations is generally applicable, domains with specialized knowledge (e.g., science,\nmedicine, law) will benefit from few-shot examples specialized to those domains. We also support\na secondary extraction prompt for any additional covariates we would like to associate with the\nextracted node instances. Our default covariate prompt","chunk_id":"bc9e2c9e369c4108cf4f6dd5f60960f4","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"GRAPH RAG","type":"METHOD, TECHNOLOGY","description":"Graph RAG (Retrieval-Augmented Generation) is an approach that involves a high-level data flow and pipeline for processing and summarizing text","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"PIPELINE","type":"PROCESS, SYSTEM","description":"The pipeline refers to the sequence of steps and processes involved in the Graph RAG approach","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"SOURCE DOCUMENTS","type":"DATA, INPUT","description":"Source documents are the original texts from which input texts are extracted for processing in the Graph RAG approach","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"TEXT CHUNKS","type":"DATA, UNIT","description":"Text chunks are segments of input texts extracted from source documents, used for processing in the Graph RAG approach","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"LLM","type":"TECHNOLOGY, METHOD","description":"LLM (Large Language Model) is used to process text chunks and extract elements of a graph index","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"GRAPH INDEX","type":"DATA STRUCTURE, OUTPUT","description":"Graph index is a data structure that includes various elements extracted from text chunks using LLM prompts","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"HOTPOTQA","type":"DATASET","description":"HotPotQA is a dataset used to observe the behavior of text chunk extraction in the Graph RAG approach","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"ENTITY REFERENCES","type":"DATA, UNIT","description":"Entity references are mentions of entities within text chunks, extracted during the processing","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"RECALL","type":"METRIC","description":"Recall is a metric used to measure the completeness of entity extraction from text chunks","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"PRECISION","type":"METRIC","description":"Precision is a metric used to measure the accuracy of entity extraction from text chunks","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"ELEMENT INSTANCES","type":"DATA, UNIT","description":"Element instances are identified and extracted instances of graph nodes and edges from text chunks","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"FEW-SHOT EXAMPLES","type":"TECHNIQUE, METHOD","description":"Few-shot examples are sample inputs provided to the LLM for in-context learning to tailor the extraction prompt to the document corpus domain","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"NAMED ENTITIES","type":"DATA, UNIT","description":"Named entities are specific types of entities such as people, places, and organizations, extracted from text chunks","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"COVARIATES","type":"DATA, ATTRIBUTE","description":"Covariates are additional attributes associated with extracted node instances in the graph index","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"KURATOV ET AL., 2024","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Kuratov et al. in 2024, discussing the recall degradation of longer LLM context windows","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"LIU ET AL., 2023","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Liu et al. in 2023, discussing the recall degradation of longer LLM context windows","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"YANG ET AL., 2018","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Yang et al. in 2018, introducing the HotPotQA dataset","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"BROWN ET AL., 2020","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Brown et al. in 2020, discussing in-context learning with few-shot examples","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"INTERMEDIATE-LEVEL COMMUNITY SUMMARIES","type":"DATA, UNIT","description":"Intermediate-level community summaries are summaries that provide a mid-level overview of the source text","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"LOW-LEVEL COMMUNITY SUMMARIES","type":"DATA, UNIT","description":"Low-level community summaries are summaries that provide a detailed overview of the source text","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"TOKEN COSTS","type":"METRIC","description":"Token costs refer to the number of tokens required for processing text in the Graph RAG approach","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"DESIGN PARAMETERS","type":"ATTRIBUTE, CONFIGURATION","description":"Design parameters are key settings and configurations in the Graph RAG approach","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"TECHNIQUES","type":"METHOD, APPROACH","description":"Techniques refer to the specific methods used in the Graph RAG approach","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"IMPLEMENTATION DETAILS","type":"ATTRIBUTE, CONFIGURATION","description":"Implementation details are specific configurations and settings used in the Graph RAG approach","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"LLM PROMPTS","type":"TECHNIQUE, METHOD","description":"LLM prompts are specific instructions given to the LLM to extract elements from text chunks","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"SINGLE EXTRACTION ROUND","type":"PROCESS, METHOD","description":"A single extraction round refers to one complete cycle of extracting elements from text chunks using LLM prompts","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"CHUNK SIZE","type":"ATTRIBUTE, CONFIGURATION","description":"Chunk size refers to the length of text chunks used in the extraction process","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"RECALL DEGRADATION","type":"METRIC, ISSUE","description":"Recall degradation refers to the decrease in recall performance when using longer LLM context windows","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"EXTRACTION PROCESS","type":"PROCESS, METHOD","description":"The extraction process involves identifying and extracting elements from text chunks using LLM prompts","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"DOMAIN","type":"ATTRIBUTE, CONFIGURATION","description":"Domain refers to the specific area of knowledge or field to which the document corpus belongs","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"DOCUMENT CORPUS","type":"DATA, INPUT","description":"Document corpus refers to the collection of documents being processed in the Graph RAG approach","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"DEFAULT PROMPT","type":"TECHNIQUE, METHOD","description":"Default prompt is the standard set of instructions given to the LLM for extracting named entities","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"},{"name":"SECONDARY EXTRACTION PROMPT","type":"TECHNIQUE, METHOD","description":"Secondary extraction prompt is an additional set of instructions given to the LLM for extracting covariates","source_id":"bc9e2c9e369c4108cf4f6dd5f60960f4"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD, TECHNOLOGY<\/data>      <data key=\"d1\">Graph RAG (Retrieval-Augmented Generation) is an approach that involves a high-level data flow and pipeline for processing and summarizing text<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"PIPELINE\">      <data key=\"d0\">PROCESS, SYSTEM<\/data>      <data key=\"d1\">The pipeline refers to the sequence of steps and processes involved in the Graph RAG approach<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"SOURCE DOCUMENTS\">      <data key=\"d0\">DATA, INPUT<\/data>      <data key=\"d1\">Source documents are the original texts from which input texts are extracted for processing in the Graph RAG approach<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"TEXT CHUNKS\">      <data key=\"d0\">DATA, UNIT<\/data>      <data key=\"d1\">Text chunks are segments of input texts extracted from source documents, used for processing in the Graph RAG approach<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">LLM (Large Language Model) is used to process text chunks and extract elements of a graph index<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"GRAPH INDEX\">      <data key=\"d0\">DATA STRUCTURE, OUTPUT<\/data>      <data key=\"d1\">Graph index is a data structure that includes various elements extracted from text chunks using LLM prompts<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HotPotQA is a dataset used to observe the behavior of text chunk extraction in the Graph RAG approach<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"ENTITY REFERENCES\">      <data key=\"d0\">DATA, UNIT<\/data>      <data key=\"d1\">Entity references are mentions of entities within text chunks, extracted during the processing<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"RECALL\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Recall is a metric used to measure the completeness of entity extraction from text chunks<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"PRECISION\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Precision is a metric used to measure the accuracy of entity extraction from text chunks<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"ELEMENT INSTANCES\">      <data key=\"d0\">DATA, UNIT<\/data>      <data key=\"d1\">Element instances are identified and extracted instances of graph nodes and edges from text chunks<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"FEW-SHOT EXAMPLES\">      <data key=\"d0\">TECHNIQUE, METHOD<\/data>      <data key=\"d1\">Few-shot examples are sample inputs provided to the LLM for in-context learning to tailor the extraction prompt to the document corpus domain<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"NAMED ENTITIES\">      <data key=\"d0\">DATA, UNIT<\/data>      <data key=\"d1\">Named entities are specific types of entities such as people, places, and organizations, extracted from text chunks<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"COVARIATES\">      <data key=\"d0\">DATA, ATTRIBUTE<\/data>      <data key=\"d1\">Covariates are additional attributes associated with extracted node instances in the graph index<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"KURATOV ET AL., 2024\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Kuratov et al. in 2024, discussing the recall degradation of longer LLM context windows<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"LIU ET AL., 2023\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Liu et al. in 2023, discussing the recall degradation of longer LLM context windows<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"YANG ET AL., 2018\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Yang et al. in 2018, introducing the HotPotQA dataset<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"BROWN ET AL., 2020\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Brown et al. in 2020, discussing in-context learning with few-shot examples<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"INTERMEDIATE-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d0\">DATA, UNIT<\/data>      <data key=\"d1\">Intermediate-level community summaries are summaries that provide a mid-level overview of the source text<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"LOW-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d0\">DATA, UNIT<\/data>      <data key=\"d1\">Low-level community summaries are summaries that provide a detailed overview of the source text<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"TOKEN COSTS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Token costs refer to the number of tokens required for processing text in the Graph RAG approach<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"DESIGN PARAMETERS\">      <data key=\"d0\">ATTRIBUTE, CONFIGURATION<\/data>      <data key=\"d1\">Design parameters are key settings and configurations in the Graph RAG approach<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"TECHNIQUES\">      <data key=\"d0\">METHOD, APPROACH<\/data>      <data key=\"d1\">Techniques refer to the specific methods used in the Graph RAG approach<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"IMPLEMENTATION DETAILS\">      <data key=\"d0\">ATTRIBUTE, CONFIGURATION<\/data>      <data key=\"d1\">Implementation details are specific configurations and settings used in the Graph RAG approach<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"LLM PROMPTS\">      <data key=\"d0\">TECHNIQUE, METHOD<\/data>      <data key=\"d1\">LLM prompts are specific instructions given to the LLM to extract elements from text chunks<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"SINGLE EXTRACTION ROUND\">      <data key=\"d0\">PROCESS, METHOD<\/data>      <data key=\"d1\">A single extraction round refers to one complete cycle of extracting elements from text chunks using LLM prompts<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"CHUNK SIZE\">      <data key=\"d0\">ATTRIBUTE, CONFIGURATION<\/data>      <data key=\"d1\">Chunk size refers to the length of text chunks used in the extraction process<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"RECALL DEGRADATION\">      <data key=\"d0\">METRIC, ISSUE<\/data>      <data key=\"d1\">Recall degradation refers to the decrease in recall performance when using longer LLM context windows<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"EXTRACTION PROCESS\">      <data key=\"d0\">PROCESS, METHOD<\/data>      <data key=\"d1\">The extraction process involves identifying and extracting elements from text chunks using LLM prompts<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"DOMAIN\">      <data key=\"d0\">ATTRIBUTE, CONFIGURATION<\/data>      <data key=\"d1\">Domain refers to the specific area of knowledge or field to which the document corpus belongs<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"DOCUMENT CORPUS\">      <data key=\"d0\">DATA, INPUT<\/data>      <data key=\"d1\">Document corpus refers to the collection of documents being processed in the Graph RAG approach<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"DEFAULT PROMPT\">      <data key=\"d0\">TECHNIQUE, METHOD<\/data>      <data key=\"d1\">Default prompt is the standard set of instructions given to the LLM for extracting named entities<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <node id=\"SECONDARY EXTRACTION PROMPT\">      <data key=\"d0\">TECHNIQUE, METHOD<\/data>      <data key=\"d1\">Secondary extraction prompt is an additional set of instructions given to the LLM for extracting covariates<\/data>      <data key=\"d2\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/node>    <edge source=\"GRAPH RAG\" target=\"PIPELINE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The Graph RAG approach involves a specific pipeline for processing and summarizing text<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TOKEN COSTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Token costs are a consideration in the performance of the Graph RAG approach<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DESIGN PARAMETERS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Design parameters are key settings in the Graph RAG approach<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TECHNIQUES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Techniques are specific methods used in the Graph RAG approach<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"IMPLEMENTATION DETAILS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Implementation details are specific configurations used in the Graph RAG approach<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"SOURCE DOCUMENTS\" target=\"TEXT CHUNKS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Text chunks are extracted from source documents for processing in the Graph RAG approach<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"SOURCE DOCUMENTS\" target=\"INTERMEDIATE-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Intermediate-level community summaries are derived from source documents<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"SOURCE DOCUMENTS\" target=\"LOW-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Low-level community summaries are derived from source documents<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"SOURCE DOCUMENTS\" target=\"DOCUMENT CORPUS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Document corpus consists of source documents being processed<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"TEXT CHUNKS\" target=\"LLM\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Text chunks are processed using LLM to extract elements of a graph index<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"TEXT CHUNKS\" target=\"ENTITY REFERENCES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Entity references are extracted from text chunks during processing<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"TEXT CHUNKS\" target=\"ELEMENT INSTANCES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Element instances are extracted from text chunks<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"TEXT CHUNKS\" target=\"CHUNK SIZE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chunk size refers to the length of text chunks used in the extraction process<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"GRAPH INDEX\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM is used to extract elements of a graph index from text chunks<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"FEW-SHOT EXAMPLES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Few-shot examples are provided to the LLM for in-context learning to tailor the extraction prompt<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"NAMED ENTITIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM extracts named entities from text chunks<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"KURATOV ET AL., 2024\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kuratov et al. (2024) discuss the recall degradation of longer LLM context windows<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"LIU ET AL., 2023\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Liu et al. (2023) discuss the recall degradation of longer LLM context windows<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"LLM PROMPTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM prompts are instructions given to the LLM for extracting elements from text chunks<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"RECALL DEGRADATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Recall degradation occurs with longer LLM context windows<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"EXTRACTION PROCESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The extraction process involves using LLM to identify and extract elements from text chunks<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"DEFAULT PROMPT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Default prompt is the standard set of instructions given to the LLM<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"SECONDARY EXTRACTION PROMPT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Secondary extraction prompt is an additional set of instructions given to the LLM<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"YANG ET AL., 2018\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Yang et al. (2018) introduced the HotPotQA dataset<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"ENTITY REFERENCES\" target=\"RECALL\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Recall measures the completeness of entity references extracted from text chunks<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"ENTITY REFERENCES\" target=\"PRECISION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Precision measures the accuracy of entity references extracted from text chunks<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"ELEMENT INSTANCES\" target=\"COVARIATES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Covariates are additional attributes associated with extracted element instances<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"FEW-SHOT EXAMPLES\" target=\"BROWN ET AL., 2020\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Brown et al. (2020) discuss in-context learning with few-shot examples<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"FEW-SHOT EXAMPLES\" target=\"DEFAULT PROMPT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Few-shot examples are used to tailor the default prompt to the domain<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"FEW-SHOT EXAMPLES\" target=\"SECONDARY EXTRACTION PROMPT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Few-shot examples are used to tailor the secondary extraction prompt to the domain<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"SINGLE EXTRACTION ROUND\" target=\"EXTRACTION PROCESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">A single extraction round is part of the extraction process<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>    <edge source=\"DOMAIN\" target=\"DOCUMENT CORPUS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Domain refers to the specific area of knowledge of the document corpus<\/data>      <data key=\"d5\">bc9e2c9e369c4108cf4f6dd5f60960f4<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"2c6ed90897310eea2f28e33fff1c32b0","chunk":", and organizations is generally applicable, domains with specialized knowledge (e.g., science,\nmedicine, law) will benefit from few-shot examples specialized to those domains. We also support\na secondary extraction prompt for any additional covariates we would like to associate with the\nextracted node instances. Our default covariate prompt aims to extract claims linked to detected\nentities, including the subject, object, type, description, source text span, and start and end dates.\nTo balance the needs of efficiency and quality, we use multiple rounds of \u201cgleanings\u201d, up to a\nspecified maximum, to encourage the LLM to detect any additional entities it may have missed\non prior extraction rounds. This is a multi-stage process in which we first ask the LLM to assess\nwhether all entities were extracted, using a logit bias of 100 to force a yes\/no decision. If the LLM\nresponds that entities were missed, then a continuation indicating that \u201cMANY entities were missed\nin the last extraction\u201d encourages the LLM to glean these missing entities. This approach allows us\nto use larger chunk sizes without a drop in quality (Figure 2) or the forced introduction of noise.\n2.3 Element Instances \u2192Element Summaries\nThe use of an LLM to \u201cextract\u201d descriptions of entities, relationships, and claims represented in\nsource texts is already a form of abstractive summarization, relying on the LLM to create inde-\npendently meaningful summaries of concepts that may be implied but not stated by the text itself\n(e.g., the presence of implied relationships). To convert all such instance-level summaries into sin-\ngle blocks of descriptive text for each graph element (i.e., entity node, relationship edge, and claim\ncovariate) requires a further round of LLM summarization over matching groups of instances.\nA potential concern at this stage is that the LLM may not consistently extract references to the\nsame entity in the same text format, resulting in duplicate entity elements and thus duplicate nodes\nin the entity graph. However, since all closely-related \u201ccommunities\u201d of entities will be detected\nand summarized in the following step, and given that LLMs can understand the common entity\nbehind multiple name variations, our overall approach is resilient to such variations provided there\nis sufficient connectivity from all variations to a shared set of closely-related entities.\nOverall, our use of rich descriptive text for homogeneous nodes in a potentially noisy graph structure\nis aligned with both the capabilities of LLMs and","chunk_id":"2c6ed90897310eea2f28e33fff1c32b0","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"LLM","type":"TECHNOLOGY","description":"LLM (Large Language Model) is a type of artificial intelligence used for tasks such as entity extraction, summarization, and understanding relationships in text","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"FEW-SHOT EXAMPLES","type":"METHOD","description":"Few-shot examples are specialized instances provided to the LLM to improve its performance in domains with specialized knowledge such as science, medicine, and law","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"COVARIATE PROMPT","type":"METHOD","description":"A covariate prompt is used to extract additional attributes associated with detected entities, including claims linked to the entities","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"CLAIMS","type":"CONCEPT","description":"Claims are statements or assertions linked to detected entities, including details such as subject, object, type, description, source text span, and start and end dates","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"GLEANINGS","type":"METHOD","description":"Gleanings refer to multiple rounds of entity extraction to ensure that no entities are missed in the process","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"LOGIT BIAS","type":"TECHNIQUE","description":"Logit bias is a technique used to force a yes\/no decision from the LLM during the entity extraction process","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"ELEMENT INSTANCES","type":"CONCEPT","description":"Element instances are individual occurrences of entities, relationships, and claims extracted from source texts","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"ELEMENT SUMMARIES","type":"CONCEPT","description":"Element summaries are descriptive texts created by the LLM to summarize entities, relationships, and claims extracted from source texts","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"ENTITY NODE","type":"CONCEPT","description":"An entity node is a representation of an entity in a graph structure","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"RELATIONSHIP EDGE","type":"CONCEPT","description":"A relationship edge is a representation of a relationship between entities in a graph structure","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"CLAIM COVARIATE","type":"CONCEPT","description":"A claim covariate is an additional attribute or variable associated with a claim in a graph structure","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"COMMUNITIES OF ENTITIES","type":"CONCEPT","description":"Communities of entities are groups of closely-related entities detected and summarized by the LLM","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"NOISY GRAPH STRUCTURE","type":"CONCEPT","description":"A noisy graph structure is a graph that may contain duplicate or inconsistent entity elements due to variations in text format","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"SCIENCE","type":"DOMAIN","description":"Science is a specialized domain that benefits from few-shot examples to improve LLM performance","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"MEDICINE","type":"DOMAIN","description":"Medicine is a specialized domain that benefits from few-shot examples to improve LLM performance","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"LAW","type":"DOMAIN","description":"Law is a specialized domain that benefits from few-shot examples to improve LLM performance","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"SOURCE TEXT SPAN","type":"ATTRIBUTE","description":"Source text span is an attribute of a claim that indicates the specific portion of text from which the claim was extracted","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"START DATE","type":"ATTRIBUTE","description":"Start date is an attribute of a claim that indicates when the event or fact described in the claim began","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"END DATE","type":"ATTRIBUTE","description":"End date is an attribute of a claim that indicates when the event or fact described in the claim ended","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"DESCRIPTION","type":"ATTRIBUTE","description":"Description is an attribute of a claim that provides a detailed explanation of the claim","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"SUBJECT","type":"ATTRIBUTE","description":"Subject is an attribute of a claim that indicates the main entity involved in the claim","source_id":"2c6ed90897310eea2f28e33fff1c32b0"},{"name":"OBJECT","type":"ATTRIBUTE","description":"Object is an attribute of a claim that indicates the entity that is affected by the subject in the claim","source_id":"2c6ed90897310eea2f28e33fff1c32b0"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">LLM (Large Language Model) is a type of artificial intelligence used for tasks such as entity extraction, summarization, and understanding relationships in text<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"FEW-SHOT EXAMPLES\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Few-shot examples are specialized instances provided to the LLM to improve its performance in domains with specialized knowledge such as science, medicine, and law<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"COVARIATE PROMPT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A covariate prompt is used to extract additional attributes associated with detected entities, including claims linked to the entities<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"CLAIMS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Claims are statements or assertions linked to detected entities, including details such as subject, object, type, description, source text span, and start and end dates<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"GLEANINGS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Gleanings refer to multiple rounds of entity extraction to ensure that no entities are missed in the process<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"LOGIT BIAS\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Logit bias is a technique used to force a yes\/no decision from the LLM during the entity extraction process<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"ELEMENT INSTANCES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Element instances are individual occurrences of entities, relationships, and claims extracted from source texts<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"ELEMENT SUMMARIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Element summaries are descriptive texts created by the LLM to summarize entities, relationships, and claims extracted from source texts<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"ENTITY NODE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">An entity node is a representation of an entity in a graph structure<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"RELATIONSHIP EDGE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A relationship edge is a representation of a relationship between entities in a graph structure<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"CLAIM COVARIATE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A claim covariate is an additional attribute or variable associated with a claim in a graph structure<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"COMMUNITIES OF ENTITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Communities of entities are groups of closely-related entities detected and summarized by the LLM<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"NOISY GRAPH STRUCTURE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A noisy graph structure is a graph that may contain duplicate or inconsistent entity elements due to variations in text format<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"SCIENCE\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Science is a specialized domain that benefits from few-shot examples to improve LLM performance<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"MEDICINE\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Medicine is a specialized domain that benefits from few-shot examples to improve LLM performance<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"LAW\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Law is a specialized domain that benefits from few-shot examples to improve LLM performance<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"SOURCE TEXT SPAN\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Source text span is an attribute of a claim that indicates the specific portion of text from which the claim was extracted<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"START DATE\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Start date is an attribute of a claim that indicates when the event or fact described in the claim began<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"END DATE\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">End date is an attribute of a claim that indicates when the event or fact described in the claim ended<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"DESCRIPTION\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Description is an attribute of a claim that provides a detailed explanation of the claim<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"SUBJECT\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Subject is an attribute of a claim that indicates the main entity involved in the claim<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <node id=\"OBJECT\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Object is an attribute of a claim that indicates the entity that is affected by the subject in the claim<\/data>      <data key=\"d2\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/node>    <edge source=\"LLM\" target=\"FEW-SHOT EXAMPLES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Few-shot examples are used to improve the performance of the LLM in specialized domains<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"LLM\" target=\"COVARIATE PROMPT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM uses covariate prompts to extract additional attributes associated with detected entities<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"LLM\" target=\"GLEANINGS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM uses multiple rounds of gleanings to ensure no entities are missed<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"LLM\" target=\"LOGIT BIAS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Logit bias is used to force a yes\/no decision from the LLM during entity extraction<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"LLM\" target=\"ELEMENT INSTANCES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM extracts element instances from source texts<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"LLM\" target=\"COMMUNITIES OF ENTITIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM detects and summarizes communities of entities<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"FEW-SHOT EXAMPLES\" target=\"SCIENCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Few-shot examples are used to improve LLM performance in the domain of science<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"FEW-SHOT EXAMPLES\" target=\"MEDICINE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Few-shot examples are used to improve LLM performance in the domain of medicine<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"FEW-SHOT EXAMPLES\" target=\"LAW\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Few-shot examples are used to improve LLM performance in the domain of law<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"COVARIATE PROMPT\" target=\"CLAIMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Covariate prompts are used to extract claims linked to detected entities<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"CLAIMS\" target=\"SOURCE TEXT SPAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Source text span is an attribute of claims<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"CLAIMS\" target=\"START DATE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Start date is an attribute of claims<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"CLAIMS\" target=\"END DATE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">End date is an attribute of claims<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"CLAIMS\" target=\"DESCRIPTION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Description is an attribute of claims<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"CLAIMS\" target=\"SUBJECT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Subject is an attribute of claims<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"CLAIMS\" target=\"OBJECT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Object is an attribute of claims<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"ELEMENT INSTANCES\" target=\"ELEMENT SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Element instances are converted into element summaries by the LLM<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"ELEMENT SUMMARIES\" target=\"ENTITY NODE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Element summaries include descriptions of entity nodes<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"ELEMENT SUMMARIES\" target=\"RELATIONSHIP EDGE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Element summaries include descriptions of relationship edges<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"ELEMENT SUMMARIES\" target=\"CLAIM COVARIATE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Element summaries include descriptions of claim covariates<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>    <edge source=\"COMMUNITIES OF ENTITIES\" target=\"NOISY GRAPH STRUCTURE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Communities of entities help manage variations in a noisy graph structure<\/data>      <data key=\"d5\">2c6ed90897310eea2f28e33fff1c32b0<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"7fb7d9ce2da9c940a32afdd87d1d9e56","chunk":" common entity\nbehind multiple name variations, our overall approach is resilient to such variations provided there\nis sufficient connectivity from all variations to a shared set of closely-related entities.\nOverall, our use of rich descriptive text for homogeneous nodes in a potentially noisy graph structure\nis aligned with both the capabilities of LLMs and the needs of global, query-focused summarization.\nThese qualities also differentiate our graph index from typical knowledge graphs, which rely on\nconcise and consistent knowledge triples (subject, predicate, object) for downstream reasoning tasks.\n2.4 Element Summaries \u2192Graph Communities\nThe index created in the previous step can be modelled as an homogeneous undirected weighted\ngraph in which entity nodes are connected by relationship edges, with edge weights representing the\nnormalized counts of detected relationship instances. Given such a graph, a variety of community\ndetection algorithms may be used to partition the graph into communities of nodes with stronger\nconnections to one another than to the other nodes in the graph (e.g., see the surveys by Fortu-\nnato, 2010 and Jin et al., 2021). In our pipeline, we use Leiden (Traag et al., 2019) on account of\nits ability to recover hierarchical community structure of large-scale graphs efficiently (Figure 3).\nEach level of this hierarchy provides a community partition that covers the nodes of the graph in a\nmutually-exclusive, collective-exhaustive way, enabling divide-and-conquer global summarization.\n2.5 Graph Communities \u2192Community Summaries\nThe next step is to create report-like summaries of each community in the Leiden hierarchy, using\na method designed to scale to very large datasets. These summaries are independently useful in\ntheir own right as a way to understand the global structure and semantics of the dataset, and may\nthemselves be used to make sense of a corpus in the absence of a question. For example, a user\nmay scan through community summaries at one level looking for general themes of interest, then\nfollow links to the reports at the lower level that provide more details for each of the subtopics. Here,\nhowever, we focus on their utility as part of a graph-based index used for answering global queries.\nCommunity summaries are generated in the following way:\n4(a) Root communities at level 0 (b) Sub-communities at level 1\nFigure 3: Graph communities detected using the Leiden algorithm (Traag et al., 2019) over the\nMultiHop-RAG (T","chunk_id":"7fb7d9ce2da9c940a32afdd87d1d9e56","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"COMMON ENTITY","type":"CONCEPT","description":"A concept referring to an entity that has multiple name variations but is resilient to such variations due to sufficient connectivity to closely-related entities","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"LLMS","type":"TECHNOLOGY","description":"Large Language Models (LLMs) are advanced AI models capable of understanding and generating human-like text","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"KNOWLEDGE GRAPHS","type":"TECHNOLOGY","description":"Structured representations of knowledge in the form of triples (subject, predicate, object) used for reasoning tasks","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"HOMOGENEOUS NODES","type":"CONCEPT","description":"Nodes in a graph that are of the same type and are described using rich descriptive text","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"NOISY GRAPH STRUCTURE","type":"CONCEPT","description":"A graph structure that may contain inconsistencies or errors, making it challenging to analyze","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"GRAPH INDEX","type":"TECHNOLOGY","description":"An index created from a graph structure, used for query-focused summarization and other tasks","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"RELATIONSHIP EDGES","type":"CONCEPT","description":"Edges in a graph that represent relationships between entity nodes","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"EDGE WEIGHTS","type":"METRIC","description":"Weights assigned to edges in a graph, representing the normalized counts of detected relationship instances","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"COMMUNITY DETECTION ALGORITHMS","type":"TECHNOLOGY","description":"Algorithms used to partition a graph into communities of nodes with stronger connections to one another","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"LEIDEN","type":"TECHNOLOGY","description":"A community detection algorithm known for its ability to recover hierarchical community structure efficiently","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"HIERARCHICAL COMMUNITY STRUCTURE","type":"CONCEPT","description":"A structure in which communities are organized in a hierarchy, with each level providing a partition of the graph nodes","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"COMMUNITY PARTITION","type":"CONCEPT","description":"A division of graph nodes into mutually-exclusive, collectively-exhaustive communities","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"GLOBAL SUMMARIZATION","type":"TECHNOLOGY","description":"A method for summarizing the overall structure and semantics of a dataset","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"COMMUNITY SUMMARIES","type":"TECHNOLOGY","description":"Report-like summaries of each community in a hierarchical structure, useful for understanding the dataset","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"MULTIHOP-RAG","type":"TECHNOLOGY","description":"A specific implementation or variant of Retrieval-Augmented Generation (RAG) used in the context of graph communities","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"FORTUNATO","type":"PERSON","description":"An author who has conducted surveys on community detection algorithms","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"JIN ET AL.","type":"PERSON","description":"Authors who have conducted surveys on community detection algorithms","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"TRAAG ET AL.","type":"PERSON","description":"Authors of the Leiden algorithm, known for its efficiency in recovering hierarchical community structures","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"DATASET","type":"CONCEPT","description":"A collection of data used for analysis and summarization","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"QUERY-FOCUSED SUMMARIZATION","type":"TECHNOLOGY","description":"A method for summarizing information based on specific queries","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"GLOBAL QUERIES","type":"CONCEPT","description":"Queries that aim to retrieve information from a global perspective, covering the entire dataset","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"ROOT COMMUNITIES","type":"CONCEPT","description":"The top-level communities in a hierarchical community structure","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"SUB-COMMUNITIES","type":"CONCEPT","description":"Lower-level communities in a hierarchical community structure, providing more detailed information","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"REPORTS","type":"TECHNOLOGY","description":"Detailed documents that provide information about specific subtopics within a community","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"ELEMENT SUMMARIES","type":"TECHNOLOGY","description":"Summaries of elements within a graph, used to understand the structure and semantics of the dataset","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"GRAPH COMMUNITIES","type":"TECHNOLOGY","description":"Groups of nodes within a graph that have stronger connections to each other than to other nodes","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"COMMUNITY DETECTION","type":"TECHNOLOGY","description":"The process of identifying communities within a graph","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"PARTITION","type":"CONCEPT","description":"The division of a graph into distinct communities","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"HIERARCHY","type":"CONCEPT","description":"A system in which elements are ranked or organized in levels","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"PIPELINE","type":"TECHNOLOGY","description":"A series of processes or steps used to analyze and summarize a dataset","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"LEVEL 0","type":"CONCEPT","description":"The root level in a hierarchical community structure","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"LEVEL 1","type":"CONCEPT","description":"A sub-level in a hierarchical community structure, providing more detailed information","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"},{"name":"FIGURE 3","type":"CONCEPT","description":"A visual representation of graph communities detected using the Leiden algorithm","source_id":"7fb7d9ce2da9c940a32afdd87d1d9e56"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"COMMON ENTITY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A concept referring to an entity that has multiple name variations but is resilient to such variations due to sufficient connectivity to closely-related entities<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"LLMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Large Language Models (LLMs) are advanced AI models capable of understanding and generating human-like text<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"KNOWLEDGE GRAPHS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Structured representations of knowledge in the form of triples (subject, predicate, object) used for reasoning tasks<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"HOMOGENEOUS NODES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Nodes in a graph that are of the same type and are described using rich descriptive text<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"NOISY GRAPH STRUCTURE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A graph structure that may contain inconsistencies or errors, making it challenging to analyze<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"GRAPH INDEX\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">An index created from a graph structure, used for query-focused summarization and other tasks<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"RELATIONSHIP EDGES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Edges in a graph that represent relationships between entity nodes<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"EDGE WEIGHTS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Weights assigned to edges in a graph, representing the normalized counts of detected relationship instances<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"COMMUNITY DETECTION ALGORITHMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Algorithms used to partition a graph into communities of nodes with stronger connections to one another<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"LEIDEN\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A community detection algorithm known for its ability to recover hierarchical community structure efficiently<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"HIERARCHICAL COMMUNITY STRUCTURE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A structure in which communities are organized in a hierarchy, with each level providing a partition of the graph nodes<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"COMMUNITY PARTITION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A division of graph nodes into mutually-exclusive, collectively-exhaustive communities<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"GLOBAL SUMMARIZATION\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A method for summarizing the overall structure and semantics of a dataset<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Report-like summaries of each community in a hierarchical structure, useful for understanding the dataset<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"MULTIHOP-RAG\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A specific implementation or variant of Retrieval-Augmented Generation (RAG) used in the context of graph communities<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"FORTUNATO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author who has conducted surveys on community detection algorithms<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"JIN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Authors who have conducted surveys on community detection algorithms<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"TRAAG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Authors of the Leiden algorithm, known for its efficiency in recovering hierarchical community structures<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"DATASET\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A collection of data used for analysis and summarization<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A method for summarizing information based on specific queries<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"GLOBAL QUERIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Queries that aim to retrieve information from a global perspective, covering the entire dataset<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"ROOT COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The top-level communities in a hierarchical community structure<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"SUB-COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Lower-level communities in a hierarchical community structure, providing more detailed information<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"REPORTS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Detailed documents that provide information about specific subtopics within a community<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"ELEMENT SUMMARIES\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Summaries of elements within a graph, used to understand the structure and semantics of the dataset<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"GRAPH COMMUNITIES\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Groups of nodes within a graph that have stronger connections to each other than to other nodes<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"COMMUNITY DETECTION\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">The process of identifying communities within a graph<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"PARTITION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The division of a graph into distinct communities<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"HIERARCHY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A system in which elements are ranked or organized in levels<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"PIPELINE\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A series of processes or steps used to analyze and summarize a dataset<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"LEVEL 0\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The root level in a hierarchical community structure<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"LEVEL 1\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A sub-level in a hierarchical community structure, providing more detailed information<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <node id=\"FIGURE 3\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A visual representation of graph communities detected using the Leiden algorithm<\/data>      <data key=\"d2\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/node>    <edge source=\"COMMON ENTITY\" target=\"HOMOGENEOUS NODES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Common entities are described using rich descriptive text for homogeneous nodes<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"LLMS\" target=\"GRAPH INDEX\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The use of rich descriptive text for homogeneous nodes in a graph index aligns with the capabilities of LLMs<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"KNOWLEDGE GRAPHS\" target=\"GRAPH INDEX\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph indexes differ from typical knowledge graphs in their use of rich descriptive text instead of concise knowledge triples<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"HOMOGENEOUS NODES\" target=\"RELATIONSHIP EDGES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Relationship edges connect homogeneous nodes in a graph<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"GRAPH INDEX\" target=\"COMMUNITY DETECTION ALGORITHMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community detection algorithms are used to partition the graph index into communities<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"RELATIONSHIP EDGES\" target=\"EDGE WEIGHTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Edge weights represent the normalized counts of detected relationship instances on relationship edges<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"COMMUNITY DETECTION ALGORITHMS\" target=\"LEIDEN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Leiden is a specific community detection algorithm used in the pipeline<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"COMMUNITY DETECTION ALGORITHMS\" target=\"FORTUNATO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Fortunato has conducted surveys on community detection algorithms<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"COMMUNITY DETECTION ALGORITHMS\" target=\"JIN ET AL.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Jin et al. have conducted surveys on community detection algorithms<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"HIERARCHICAL COMMUNITY STRUCTURE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Leiden is known for its ability to recover hierarchical community structures efficiently<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"MULTIHOP-RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The Leiden algorithm is used to detect graph communities in the MultiHop-RAG<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"TRAAG ET AL.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Traag et al. are the authors of the Leiden algorithm<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"FIGURE 3\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Figure 3 shows graph communities detected using the Leiden algorithm<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"HIERARCHICAL COMMUNITY STRUCTURE\" target=\"COMMUNITY PARTITION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Each level of the hierarchical community structure provides a community partition<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"HIERARCHICAL COMMUNITY STRUCTURE\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community summaries are created for each level in the hierarchical community structure<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"HIERARCHICAL COMMUNITY STRUCTURE\" target=\"ROOT COMMUNITIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Root communities are the top-level communities in a hierarchical community structure<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"HIERARCHICAL COMMUNITY STRUCTURE\" target=\"SUB-COMMUNITIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sub-communities are lower-level communities in a hierarchical community structure<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"COMMUNITY PARTITION\" target=\"GLOBAL SUMMARIZATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community partitions enable divide-and-conquer global summarization<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"GLOBAL SUMMARIZATION\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community summaries are useful for understanding the global structure and semantics of the dataset<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"QUERY-FOCUSED SUMMARIZATION\" target=\"GLOBAL QUERIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Query-focused summarization is used for answering global queries<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"SUB-COMMUNITIES\" target=\"REPORTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Reports provide detailed information about specific subtopics within sub-communities<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"ELEMENT SUMMARIES\" target=\"GRAPH COMMUNITIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Element summaries are used to understand the structure and semantics of graph communities<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"GRAPH COMMUNITIES\" target=\"COMMUNITY DETECTION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph communities are identified through community detection<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"COMMUNITY DETECTION\" target=\"PARTITION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community detection results in the partition of a graph into distinct communities<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"COMMUNITY DETECTION\" target=\"PIPELINE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The pipeline includes a step for community detection<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"PARTITION\" target=\"HIERARCHY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Partitions can be organized into a hierarchy<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"HIERARCHY\" target=\"LEVEL 0\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Level 0 is the root level in a hierarchy<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>    <edge source=\"HIERARCHY\" target=\"LEVEL 1\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Level 1 is a sub-level in a hierarchy<\/data>      <data key=\"d5\">7fb7d9ce2da9c940a32afdd87d1d9e56<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"843fc5421e086120ffa1c75856ecf6cd","chunk":" answering global queries.\nCommunity summaries are generated in the following way:\n4(a) Root communities at level 0 (b) Sub-communities at level 1\nFigure 3: Graph communities detected using the Leiden algorithm (Traag et al., 2019) over the\nMultiHop-RAG (Tang and Yang, 2024) dataset as indexed. Circles represent entity nodes with size\nproportional to their degree. Node layout was performed via OpenORD (Martin et al., 2011) and\nForce Atlas 2 (Jacomy et al., 2014). Node colors represent entity communities, shown at two levels\nof hierarchical clustering: (a) Level 0, corresponding to the hierarchical partition with maximum\nmodularity, and (b) Level 1, which reveals internal structure within these root-level communities.\n\u2022Leaf-level communities . The element summaries of a leaf-level community (nodes, edges,\ncovariates) are prioritized and then iteratively added to the LLM context window until\nthe token limit is reached. The prioritization is as follows: for each community edge in\ndecreasing order of combined source and target node degree (i.e., overall prominance), add\ndescriptions of the source node, target node, linked covariates, and the edge itself.\n\u2022Higher-level communities . If all element summaries fit within the token limit of the con-\ntext window, proceed as for leaf-level communities and summarize all element summaries\nwithin the community. Otherwise, rank sub-communities in decreasing order of element\nsummary tokens and iteratively substitute sub-community summaries (shorter) for their\nassociated element summaries (longer) until fit within the context window is achieved.\n2.6 Community Summaries \u2192Community Answers \u2192Global Answer\nGiven a user query, the community summaries generated in the previous step can be used to generate\na final answer in a multi-stage process. The hierarchical nature of the community structure also\nmeans that questions can be answered using the community summaries from different levels, raising\nthe question of whether a particular level in the hierarchical community structure offers the best\nbalance of summary detail and scope for general sensemaking questions (evaluated in section 3).\nFor a given community level, the global answer to any user query is generated as follows:\n\u2022Prepare community summaries . Community summaries are randomly shuffled and divided\ninto chunks of pre-specified token size. This ensures relevant information is distributed\nacross chunks, rather than concentrated (and potentially lost)","chunk_id":"843fc5421e086120ffa1c75856ecf6cd","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"GLOBAL QUERIES","type":"CONCEPT","description":"Global queries refer to questions or inquiries that require comprehensive answers derived from multiple sources or datasets","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"COMMUNITY SUMMARIES","type":"CONCEPT","description":"Community summaries are generated summaries of data clusters or communities, used to answer queries","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"ROOT COMMUNITIES","type":"CONCEPT","description":"Root communities are the top-level clusters in a hierarchical community structure","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"SUB-COMMUNITIES","type":"CONCEPT","description":"Sub-communities are lower-level clusters within root communities in a hierarchical community structure","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"LEIDEN ALGORITHM","type":"METHOD","description":"The Leiden algorithm is a method used for detecting communities in large networks","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"MULTIHOP-RAG","type":"DATASET","description":"MultiHop-RAG is a dataset used for community detection and analysis","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"OPENORD","type":"TOOL","description":"OpenORD is a tool used for node layout in graph visualizations","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"FORCE ATLAS 2","type":"TOOL","description":"Force Atlas 2 is a tool used for node layout in graph visualizations","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"NODE","type":"ELEMENT","description":"Nodes represent entities in a graph, with size proportional to their degree","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"EDGE","type":"ELEMENT","description":"Edges represent connections between nodes in a graph","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"COVARIATE","type":"ELEMENT","description":"Covariates are variables that are linked to nodes and edges in a graph","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"LLM CONTEXT WINDOW","type":"CONCEPT","description":"The LLM context window is the token limit within which summaries are added for processing by a language model","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"HIERARCHICAL CLUSTERING","type":"METHOD","description":"Hierarchical clustering is a method of clustering data into a tree-like structure with multiple levels","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"COMMUNITY ANSWERS","type":"CONCEPT","description":"Community answers are responses generated from community summaries to answer user queries","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"GLOBAL ANSWER","type":"CONCEPT","description":"A global answer is a comprehensive response generated from multiple community summaries to answer a user query","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"TOKEN LIMIT","type":"CONCEPT","description":"The token limit is the maximum number of tokens that can be processed in a single context window by a language model","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"SUMMARY DETAIL","type":"CONCEPT","description":"Summary detail refers to the level of detail provided in a summary","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"SCOPE","type":"CONCEPT","description":"Scope refers to the range or extent of information covered in a summary","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"SENSEMAKING","type":"CONCEPT","description":"Sensemaking is the process of understanding and making sense of complex information","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"USER QUERY","type":"CONCEPT","description":"A user query is a question or inquiry posed by a user seeking information","source_id":"843fc5421e086120ffa1c75856ecf6cd","entity_type":"CONCEPT"},{"name":"CHUNK","type":"ELEMENT","description":"Chunks are segments of community summaries divided into pre-specified token sizes","source_id":"843fc5421e086120ffa1c75856ecf6cd","entity_type":"ELEMENT"},{"name":"LEVEL 0","type":"CATEGORY","description":"Level 0 represents the root-level communities in the hierarchical clustering with maximum modularity","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"LEVEL 1","type":"CATEGORY","description":"Level 1 represents sub-communities within the root-level communities, revealing internal structure","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"ELEMENT SUMMARIES","type":"CONCEPT","description":"Element summaries are detailed descriptions of nodes, edges, and covariates within a community","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"PROMINENCE","type":"METRIC","description":"Prominence is a metric used to prioritize community edges based on the combined degree of source and target nodes","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"COMBINED SOURCE AND TARGET NODE DEGREE","type":"METRIC","description":"Combined source and target node degree is a metric used to measure the overall prominence of community edges","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"COMMUNITY EDGE","type":"ELEMENT","description":"Community edges are connections between nodes within a community, prioritized based on prominence","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"SUB-COMMUNITY SUMMARIES","type":"CONCEPT","description":"Sub-community summaries are shorter summaries of sub-communities used when element summaries exceed the token limit","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"HIERARCHICAL COMMUNITY STRUCTURE","type":"CONCEPT","description":"Hierarchical community structure is a multi-level clustering of communities used to generate community summaries","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"SUMMARY DETAIL AND SCOPE","type":"CONCEPT","description":"Summary detail and scope refer to the balance of detail and range of information in community summaries for sensemaking","source_id":"843fc5421e086120ffa1c75856ecf6cd"},{"name":"COMMUNITY LEVEL","type":"CATEGORY","description":"Community level refers to the different levels in the hierarchical community structure used to generate summaries","source_id":"843fc5421e086120ffa1c75856ecf6cd"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"GLOBAL QUERIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Global queries refer to questions or inquiries that require comprehensive answers derived from multiple sources or datasets<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Community summaries are generated summaries of data clusters or communities, used to answer queries<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"ROOT COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Root communities are the top-level clusters in a hierarchical community structure<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"SUB-COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Sub-communities are lower-level clusters within root communities in a hierarchical community structure<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"LEIDEN ALGORITHM\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">The Leiden algorithm is a method used for detecting communities in large networks<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"MULTIHOP-RAG\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MultiHop-RAG is a dataset used for community detection and analysis<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"OPENORD\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">OpenORD is a tool used for node layout in graph visualizations<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"FORCE ATLAS 2\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">Force Atlas 2 is a tool used for node layout in graph visualizations<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"NODE\">      <data key=\"d0\">ELEMENT<\/data>      <data key=\"d1\">Nodes represent entities in a graph, with size proportional to their degree<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"EDGE\">      <data key=\"d0\">ELEMENT<\/data>      <data key=\"d1\">Edges represent connections between nodes in a graph<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"COVARIATE\">      <data key=\"d0\">ELEMENT<\/data>      <data key=\"d1\">Covariates are variables that are linked to nodes and edges in a graph<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"LLM CONTEXT WINDOW\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The LLM context window is the token limit within which summaries are added for processing by a language model<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"HIERARCHICAL CLUSTERING\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Hierarchical clustering is a method of clustering data into a tree-like structure with multiple levels<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"COMMUNITY ANSWERS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Community answers are responses generated from community summaries to answer user queries<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"GLOBAL ANSWER\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A global answer is a comprehensive response generated from multiple community summaries to answer a user query<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"TOKEN LIMIT\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The token limit is the maximum number of tokens that can be processed in a single context window by a language model<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"SUMMARY DETAIL\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Summary detail refers to the level of detail provided in a summary<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"SCOPE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Scope refers to the range or extent of information covered in a summary<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"SENSEMAKING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Sensemaking is the process of understanding and making sense of complex information<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"USER QUERY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A user query is a question or inquiry posed by a user seeking information<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"CHUNK\">      <data key=\"d0\">ELEMENT<\/data>      <data key=\"d1\">Chunks are segments of community summaries divided into pre-specified token sizes<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>      <data key=\"d3\">ELEMENT<\/data>    <\/node>    <node id=\"LEVEL 0\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Level 0 represents the root-level communities in the hierarchical clustering with maximum modularity<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"LEVEL 1\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Level 1 represents sub-communities within the root-level communities, revealing internal structure<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"ELEMENT SUMMARIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Element summaries are detailed descriptions of nodes, edges, and covariates within a community<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"PROMINENCE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Prominence is a metric used to prioritize community edges based on the combined degree of source and target nodes<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"COMBINED SOURCE AND TARGET NODE DEGREE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Combined source and target node degree is a metric used to measure the overall prominence of community edges<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"COMMUNITY EDGE\">      <data key=\"d0\">ELEMENT<\/data>      <data key=\"d1\">Community edges are connections between nodes within a community, prioritized based on prominence<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"SUB-COMMUNITY SUMMARIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Sub-community summaries are shorter summaries of sub-communities used when element summaries exceed the token limit<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"HIERARCHICAL COMMUNITY STRUCTURE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Hierarchical community structure is a multi-level clustering of communities used to generate community summaries<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"SUMMARY DETAIL AND SCOPE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Summary detail and scope refer to the balance of detail and range of information in community summaries for sensemaking<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <node id=\"COMMUNITY LEVEL\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Community level refers to the different levels in the hierarchical community structure used to generate summaries<\/data>      <data key=\"d2\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/node>    <edge source=\"GLOBAL QUERIES\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community summaries are used to answer global queries<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"ROOT COMMUNITIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community summaries are generated from root communities<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"SUB-COMMUNITIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community summaries are generated from sub-communities<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"LLM CONTEXT WINDOW\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community summaries are added to the LLM context window until the token limit is reached<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"COMMUNITY ANSWERS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community answers are generated from community summaries<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"GLOBAL ANSWER\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Global answers are generated from community summaries<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"SUMMARY DETAIL\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The level of summary detail affects the content of community summaries<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"SCOPE\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The scope of information affects the content of community summaries<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"SENSEMAKING\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community summaries are used for sensemaking<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"CHUNK\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Community summaries are divided into chunks of pre-specified token size<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"SUMMARY DETAIL AND SCOPE\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Summary detail and scope affect the content of community summaries<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"ROOT COMMUNITIES\" target=\"HIERARCHICAL CLUSTERING\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Root communities are identified through hierarchical clustering<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"ROOT COMMUNITIES\" target=\"LEVEL 0\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Level 0 represents the root-level communities in the hierarchical clustering<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"ROOT COMMUNITIES\" target=\"HIERARCHICAL COMMUNITY STRUCTURE\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Root communities are part of the hierarchical community structure<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"SUB-COMMUNITIES\" target=\"HIERARCHICAL CLUSTERING\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Sub-communities are identified through hierarchical clustering<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"SUB-COMMUNITIES\" target=\"LEVEL 1\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Level 1 represents sub-communities within the root-level communities<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"SUB-COMMUNITIES\" target=\"HIERARCHICAL COMMUNITY STRUCTURE\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Sub-communities are part of the hierarchical community structure<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"LEIDEN ALGORITHM\" target=\"MULTIHOP-RAG\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The Leiden algorithm is used to detect communities in the MultiHop-RAG dataset<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"MULTIHOP-RAG\" target=\"OPENORD\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">OpenORD is used for node layout in the MultiHop-RAG dataset<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"MULTIHOP-RAG\" target=\"FORCE ATLAS 2\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Force Atlas 2 is used for node layout in the MultiHop-RAG dataset<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"MULTIHOP-RAG\" target=\"NODE\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Nodes represent entities in the MultiHop-RAG dataset<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"MULTIHOP-RAG\" target=\"EDGE\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Edges represent connections between nodes in the MultiHop-RAG dataset<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"MULTIHOP-RAG\" target=\"COVARIATE\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Covariates are variables linked to nodes and edges in the MultiHop-RAG dataset<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"NODE\" target=\"ELEMENT SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Element summaries include descriptions of nodes<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"EDGE\" target=\"ELEMENT SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Element summaries include descriptions of edges<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"COVARIATE\" target=\"ELEMENT SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Element summaries include descriptions of covariates<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"LLM CONTEXT WINDOW\" target=\"TOKEN LIMIT\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The token limit defines the maximum number of tokens in the LLM context window<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"GLOBAL ANSWER\" target=\"USER QUERY\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Global answers are generated in response to user queries<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"ELEMENT SUMMARIES\" target=\"SUB-COMMUNITY SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Sub-community summaries are used when element summaries exceed the token limit<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"PROMINENCE\" target=\"COMMUNITY EDGE\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Prominence is used to prioritize community edges<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"PROMINENCE\" target=\"COMBINED SOURCE AND TARGET NODE DEGREE\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Combined source and target node degree is used to measure prominence<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>    <edge source=\"HIERARCHICAL COMMUNITY STRUCTURE\" target=\"COMMUNITY LEVEL\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community levels are part of the hierarchical community structure<\/data>      <data key=\"d6\">843fc5421e086120ffa1c75856ecf6cd<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"1d07b4248c2655081c7af0e373bd70c9","chunk":" in section 3).\nFor a given community level, the global answer to any user query is generated as follows:\n\u2022Prepare community summaries . Community summaries are randomly shuffled and divided\ninto chunks of pre-specified token size. This ensures relevant information is distributed\nacross chunks, rather than concentrated (and potentially lost) in a single context window.\n\u2022Map community answers . Generate intermediate answers in parallel, one for each chunk.\nThe LLM is also asked to generate a score between 0-100 indicating how helpful the gen-\nerated answer is in answering the target question. Answers with score 0 are filtered out.\n\u2022Reduce to global answer . Intermediate community answers are sorted in descending order\nof helpfulness score and iteratively added into a new context window until the token limit\nis reached. This final context is used to generate the global answer returned to the user.\n5Dataset Example activity framing and generation of global sensemaking questions\nPodcast\ntranscriptsUser : A tech journalist looking for insights and trends in the tech industry\nTask: Understanding how tech leaders view the role of policy and regulation\nQuestions :\n1. Which episodes deal primarily with tech policy and government regulation?\n2. How do guests perceive the impact of privacy laws on technology development?\n3. Do any guests discuss the balance between innovation and ethical considerations?\n4. What are the suggested changes to current policies mentioned by the guests?\n5. Are collaborations between tech companies and governments discussed and how?\nNews\narticlesUser : Educator incorporating current affairs into curricula\nTask: Teaching about health and wellness\nQuestions :\n1. What current topics in health can be integrated into health education curricula?\n2. How do news articles address the concepts of preventive medicine and wellness?\n3. Are there examples of health articles that contradict each other, and if so, why?\n4. What insights can be gleaned about public health priorities based on news coverage?\n5. How can educators use the dataset to highlight the importance of health literacy?\nTable 1: Examples of potential users, tasks, and questions generated by the LLM based on short\ndescriptions of the target datasets. Questions target global understanding rather than specific details.\n3 Evaluation\n3.1 Datasets\nWe selected two datasets in the one million token range, each equivalent to about 10 novels of text\nand representative of the kind of corpora that users may encounter in their real world activities:\n\u2022Podcast transcripts . Compiled transcripts of podcast conversations between Kevin Scott,\nMicrosoft CTO, and other technology leaders (","chunk_id":"1d07b4248c2655081c7af0e373bd70c9","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"COMMUNITY SUMMARIES","type":"DATA","description":"Community summaries are randomly shuffled and divided into chunks of pre-specified token size to ensure relevant information is distributed across chunks","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"CHUNKS","type":"DATA","description":"Chunks are segments of community summaries divided based on a pre-specified token size","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"LLM","type":"TECHNOLOGY","description":"LLM (Large Language Model) is used to generate intermediate answers and scores for each chunk","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"HELPFULNESS SCORE","type":"METRIC","description":"A score between 0-100 generated by the LLM to indicate how helpful an answer is in addressing the target question","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"GLOBAL ANSWER","type":"OUTPUT","description":"The final answer generated by combining intermediate community answers based on their helpfulness scores","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"PODCAST TRANSCRIPTS","type":"DATASET","description":"A dataset consisting of compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"NEWS ARTICLES","type":"DATASET","description":"A dataset consisting of news articles used for analysis","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"TECH JOURNALIST","type":"USER","description":"A user looking for insights and trends in the tech industry","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"EDUCATOR","type":"USER","description":"A user incorporating current affairs into curricula","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"TECH POLICY","type":"TOPIC","description":"A topic dealing with tech policy and government regulation","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"PRIVACY LAWS","type":"TOPIC","description":"A topic discussing the impact of privacy laws on technology development","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"INNOVATION AND ETHICS","type":"TOPIC","description":"A topic discussing the balance between innovation and ethical considerations","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"POLICY CHANGES","type":"TOPIC","description":"A topic discussing suggested changes to current policies","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"COLLABORATIONS","type":"TOPIC","description":"A topic discussing collaborations between tech companies and governments","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"HEALTH TOPICS","type":"TOPIC","description":"Current topics in health that can be integrated into health education curricula","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"PREVENTIVE MEDICINE","type":"TOPIC","description":"A topic addressing the concepts of preventive medicine and wellness","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"CONTRADICTORY ARTICLES","type":"TOPIC","description":"Examples of health articles that contradict each other","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"PUBLIC HEALTH PRIORITIES","type":"TOPIC","description":"Insights about public health priorities based on news coverage","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"HEALTH LITERACY","type":"TOPIC","description":"The importance of health literacy highlighted through the dataset","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"USER QUERY","type":"INPUT","description":"A query from the user that the system aims to answer","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"INTERMEDIATE ANSWERS","type":"OUTPUT","description":"Answers generated for each chunk of community summaries","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"TOKEN SIZE","type":"METRIC","description":"The pre-specified size of tokens used to divide community summaries into chunks","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"CONTEXT WINDOW","type":"TECHNOLOGY","description":"A window of text used to generate answers, limited by token size","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"KEVIN SCOTT","type":"PERSON","description":"Kevin Scott is the CTO of Microsoft and a participant in the podcast conversations","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"MICROSOFT","type":"ORGANIZATION","description":"Microsoft is a technology company whose CTO, Kevin Scott, participates in the podcast conversations","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"TECHNOLOGY LEADERS","type":"PERSON","description":"Individuals who are leaders in the technology industry and participate in the podcast conversations","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"TASK","type":"INPUT","description":"A specific activity or goal that the user aims to achieve using the datasets","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"QUESTIONS","type":"INPUT","description":"Specific questions generated by the LLM based on the user's task and the target datasets","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"DATASET","type":"DATA","description":"A collection of data used for analysis, such as podcast transcripts or news articles","source_id":"1d07b4248c2655081c7af0e373bd70c9"},{"name":"USER","type":"","description":"","source_id":"1d07b4248c2655081c7af0e373bd70c9"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Community summaries are randomly shuffled and divided into chunks of pre-specified token size to ensure relevant information is distributed across chunks<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"CHUNKS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Chunks are segments of community summaries divided based on a pre-specified token size<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">LLM (Large Language Model) is used to generate intermediate answers and scores for each chunk<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"HELPFULNESS SCORE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A score between 0-100 generated by the LLM to indicate how helpful an answer is in addressing the target question<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"GLOBAL ANSWER\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">The final answer generated by combining intermediate community answers based on their helpfulness scores<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"PODCAST TRANSCRIPTS\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"NEWS ARTICLES\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of news articles used for analysis<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"TECH JOURNALIST\">      <data key=\"d0\">USER<\/data>      <data key=\"d1\">A user looking for insights and trends in the tech industry<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"EDUCATOR\">      <data key=\"d0\">USER<\/data>      <data key=\"d1\">A user incorporating current affairs into curricula<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"TECH POLICY\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">A topic dealing with tech policy and government regulation<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"PRIVACY LAWS\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">A topic discussing the impact of privacy laws on technology development<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"INNOVATION AND ETHICS\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">A topic discussing the balance between innovation and ethical considerations<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"POLICY CHANGES\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">A topic discussing suggested changes to current policies<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"COLLABORATIONS\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">A topic discussing collaborations between tech companies and governments<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"HEALTH TOPICS\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">Current topics in health that can be integrated into health education curricula<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"PREVENTIVE MEDICINE\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">A topic addressing the concepts of preventive medicine and wellness<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"CONTRADICTORY ARTICLES\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">Examples of health articles that contradict each other<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"PUBLIC HEALTH PRIORITIES\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">Insights about public health priorities based on news coverage<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"HEALTH LITERACY\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">The importance of health literacy highlighted through the dataset<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"USER QUERY\">      <data key=\"d0\">INPUT<\/data>      <data key=\"d1\">A query from the user that the system aims to answer<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"INTERMEDIATE ANSWERS\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">Answers generated for each chunk of community summaries<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"TOKEN SIZE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The pre-specified size of tokens used to divide community summaries into chunks<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"CONTEXT WINDOW\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A window of text used to generate answers, limited by token size<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"KEVIN SCOTT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kevin Scott is the CTO of Microsoft and a participant in the podcast conversations<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"MICROSOFT\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft is a technology company whose CTO, Kevin Scott, participates in the podcast conversations<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"TECHNOLOGY LEADERS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Individuals who are leaders in the technology industry and participate in the podcast conversations<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"TASK\">      <data key=\"d0\">INPUT<\/data>      <data key=\"d1\">A specific activity or goal that the user aims to achieve using the datasets<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"QUESTIONS\">      <data key=\"d0\">INPUT<\/data>      <data key=\"d1\">Specific questions generated by the LLM based on the user's task and the target datasets<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"DATASET\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">A collection of data used for analysis, such as podcast transcripts or news articles<\/data>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <node id=\"USER\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/node>    <edge source=\"COMMUNITY SUMMARIES\" target=\"CHUNKS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community summaries are divided into chunks<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"USER QUERY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community summaries are prepared to answer user queries<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"INTERMEDIATE ANSWERS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Intermediate answers are generated from community summaries<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"CHUNKS\" target=\"LLM\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM generates intermediate answers and scores for each chunk<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"CHUNKS\" target=\"TOKEN SIZE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chunks are divided based on a pre-specified token size<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"LLM\" target=\"HELPFULNESS SCORE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM generates a helpfulness score for each answer<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"HELPFULNESS SCORE\" target=\"GLOBAL ANSWER\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Global answer is generated by sorting intermediate answers based on helpfulness scores<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"HELPFULNESS SCORE\" target=\"INTERMEDIATE ANSWERS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Helpfulness scores are assigned to intermediate answers<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"GLOBAL ANSWER\" target=\"INTERMEDIATE ANSWERS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Intermediate answers are combined to form the global answer<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"GLOBAL ANSWER\" target=\"CONTEXT WINDOW\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The final context window is used to generate the global answer<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"TECH JOURNALIST\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Tech journalist uses podcast transcripts to look for insights and trends in the tech industry<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"KEVIN SCOTT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kevin Scott's conversations are part of the podcast transcripts<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"TECHNOLOGY LEADERS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Technology leaders participate in the podcast conversations<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"EDUCATOR\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Educator uses news articles to incorporate current affairs into curricula<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"TECH JOURNALIST\" target=\"TECH POLICY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Tech journalist is interested in episodes dealing with tech policy and government regulation<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"TECH JOURNALIST\" target=\"PRIVACY LAWS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Tech journalist is interested in how guests perceive the impact of privacy laws on technology development<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"TECH JOURNALIST\" target=\"INNOVATION AND ETHICS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Tech journalist is interested in discussions about the balance between innovation and ethical considerations<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"TECH JOURNALIST\" target=\"POLICY CHANGES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Tech journalist is interested in suggested changes to current policies<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"TECH JOURNALIST\" target=\"COLLABORATIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Tech journalist is interested in discussions about collaborations between tech companies and governments<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"EDUCATOR\" target=\"HEALTH TOPICS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Educator is interested in current topics in health that can be integrated into health education curricula<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"EDUCATOR\" target=\"PREVENTIVE MEDICINE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Educator is interested in how news articles address the concepts of preventive medicine and wellness<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"EDUCATOR\" target=\"CONTRADICTORY ARTICLES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Educator is interested in examples of health articles that contradict each other<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"EDUCATOR\" target=\"PUBLIC HEALTH PRIORITIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Educator is interested in insights about public health priorities based on news coverage<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"EDUCATOR\" target=\"HEALTH LITERACY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Educator is interested in highlighting the importance of health literacy through the dataset<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"KEVIN SCOTT\" target=\"MICROSOFT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kevin Scott is the CTO of Microsoft<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"TASK\" target=\"USER\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The task is an activity or goal that the user aims to achieve<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"TASK\" target=\"QUESTIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Questions are generated based on the user's task<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>    <edge source=\"QUESTIONS\" target=\"DATASET\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Questions are generated based on the target datasets<\/data>      <data key=\"d5\">1d07b4248c2655081c7af0e373bd70c9<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"922778ce1cb2fdd6dbab1746c8795620","chunk":"atasets\nWe selected two datasets in the one million token range, each equivalent to about 10 novels of text\nand representative of the kind of corpora that users may encounter in their real world activities:\n\u2022Podcast transcripts . Compiled transcripts of podcast conversations between Kevin Scott,\nMicrosoft CTO, and other technology leaders (Behind the Tech, Scott, 2024). Size: 1669\n\u00d7600-token text chunks, with 100-token overlaps between chunks ( \u223c1 million tokens).\n\u2022News articles . Benchmark dataset comprising news articles published from September\n2013 to December 2023 in a range of categories, including entertainment, business, sports,\ntechnology, health, and science (MultiHop-RAG; Tang and Yang, 2024). Size: 3197 \u00d7\n600-token text chunks, with 100-token overlaps between chunks ( \u223c1.7 million tokens).\n3.2 Queries\nMany benchmark datasets for open-domain question answering exist, including HotPotQA (Yang\net al., 2018), MultiHop-RAG (Tang and Yang, 2024), and MT-Bench (Zheng et al., 2024). However,\nthe associated question sets target explicit fact retrieval rather than summarization for the purpose\nof data sensemaking, i.e., the process though which people inspect, engage with, and contextualize\ndata within the broader scope of real-world activities (Koesten et al., 2021). Similarly, methods for\nextracting latent summarization queries from source texts also exist (Xu and Lapata, 2021), but such\nextracted questions can target details that betray prior knowledge of the texts.\nTo evaluate the effectiveness of RAG systems for more global sensemaking tasks, we need questions\nthat convey only a high-level understanding of dataset contents, and not the details of specific texts.\nWe used an activity-centered approach to automate the generation of such questions: given a short\ndescription of a dataset, we asked the LLM to identify Npotential users and Ntasks per user,\nthen for each (user, task) combination, we asked the LLM to generate Nquestions that require\nunderstanding of the entire corpus. For our evaluation, a value of N= 5 resulted in 125 test questions\nper dataset. Table 1 shows example questions for each of the two evaluation datasets.\n63.3 Conditions\nWe compare six different conditions in our analysis, including Graph RAG using four levels of graph\ncommunities ( C","chunk_id":"922778ce1cb2fdd6dbab1746c8795620","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"PODCAST TRANSCRIPTS","type":"DATASET","description":"Compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders. Size: 1669 \u00d7 600-token text chunks, with 100-token overlaps between chunks, approximately 1 million tokens","source_id":"922778ce1cb2fdd6dbab1746c8795620"},{"name":"NEWS ARTICLES","type":"DATASET","description":"Benchmark dataset comprising news articles published from September 2013 to December 2023 in a range of categories, including entertainment, business, sports, technology, health, and science. Size: 3197 \u00d7 600-token text chunks, with 100-token overlaps between chunks, approximately 1.7 million tokens","source_id":"922778ce1cb2fdd6dbab1746c8795620"},{"name":"HOTPOTQA","type":"DATASET","description":"A benchmark dataset for open-domain question answering, targeting explicit fact retrieval","source_id":"922778ce1cb2fdd6dbab1746c8795620"},{"name":"MULTIHOP-RAG","type":"DATASET","description":"A benchmark dataset comprising news articles published from September 2013 to December 2023 in a range of categories, including entertainment, business, sports, technology, health, and science\nA benchmark dataset for open-domain question answering, targeting explicit fact retrieval","source_id":"922778ce1cb2fdd6dbab1746c8795620","entity_type":"DATASET"},{"name":"MT-BENCH","type":"DATASET","description":"A benchmark dataset for open-domain question answering, targeting explicit fact retrieval","source_id":"922778ce1cb2fdd6dbab1746c8795620","entity_type":"DATASET"},{"name":"DATA SENSEMAKING","type":"PROCESS","description":"The process through which people inspect, engage with, and contextualize data within the broader scope of real-world activities","source_id":"922778ce1cb2fdd6dbab1746c8795620","entity_type":"PROCESS"},{"name":"RAG SYSTEMS","type":"TECHNOLOGY","description":"Retrieval-Augmented Generation systems used for global sensemaking tasks","source_id":"922778ce1cb2fdd6dbab1746c8795620","entity_type":"TECHNOLOGY"},{"name":"LLM","type":"TECHNOLOGY","description":"Large Language Model used to automate the generation of questions for dataset evaluation","source_id":"922778ce1cb2fdd6dbab1746c8795620","entity_type":"TECHNOLOGY"},{"name":"KEVIN SCOTT","type":"PERSON","description":"Microsoft CTO who participates in podcast conversations compiled in the dataset","source_id":"922778ce1cb2fdd6dbab1746c8795620"},{"name":"KOESTEN ET AL.","type":"AUTHORS","description":"Authors of a paper on data sensemaking behaviors","source_id":"922778ce1cb2fdd6dbab1746c8795620","entity_type":"AUTHORS"},{"name":"XU AND LAPATA","type":"AUTHORS","description":"Authors of a paper on methods for extracting latent summarization queries from source texts","source_id":"922778ce1cb2fdd6dbab1746c8795620","entity_type":"AUTHORS"},{"name":"TANG AND YANG","type":"AUTHORS","description":"Authors associated with the MultiHop-RAG dataset","source_id":"922778ce1cb2fdd6dbab1746c8795620"},{"name":"YANG ET AL.","type":"AUTHORS","description":"Authors associated with the HotPotQA dataset","source_id":"922778ce1cb2fdd6dbab1746c8795620","entity_type":"AUTHORS"},{"name":"ZHENG ET AL.","type":"AUTHORS","description":"Authors associated with the MT-Bench dataset","source_id":"922778ce1cb2fdd6dbab1746c8795620","entity_type":"AUTHORS"},{"name":"GRAPH RAG","type":"TECHNOLOGY","description":"A specific implementation of RAG using four levels of graph communities","source_id":"922778ce1cb2fdd6dbab1746c8795620","entity_type":"TECHNOLOGY"},{"name":"LATENT SUMMARIZATION QUERIES","type":"","description":"","source_id":"922778ce1cb2fdd6dbab1746c8795620"},{"name":"BEHIND THE TECH","type":"PODCAST","description":"A podcast series featuring conversations between Kevin Scott and other technology leaders","source_id":"922778ce1cb2fdd6dbab1746c8795620"},{"name":"SCOTT","type":"PERSON","description":"Kevin Scott, Microsoft CTO, who participates in the podcast conversations compiled in the dataset","source_id":"922778ce1cb2fdd6dbab1746c8795620"},{"name":"TANG","type":"PERSON","description":"An author associated with the MultiHop-RAG dataset","source_id":"922778ce1cb2fdd6dbab1746c8795620"},{"name":"YANG","type":"PERSON","description":"An author associated with the MultiHop-RAG dataset","source_id":"922778ce1cb2fdd6dbab1746c8795620"},{"name":"HOTSPOTQA","type":"DATASET","description":"A benchmark dataset for open-domain question answering, targeting explicit fact retrieval","source_id":"922778ce1cb2fdd6dbab1746c8795620"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"PODCAST TRANSCRIPTS\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders. Size: 1669 &#215; 600-token text chunks, with 100-token overlaps between chunks, approximately 1 million tokens<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <node id=\"NEWS ARTICLES\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Benchmark dataset comprising news articles published from September 2013 to December 2023 in a range of categories, including entertainment, business, sports, technology, health, and science. Size: 3197 &#215; 600-token text chunks, with 100-token overlaps between chunks, approximately 1.7 million tokens<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A benchmark dataset for open-domain question answering, targeting explicit fact retrieval<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <node id=\"MULTIHOP-RAG\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A benchmark dataset comprising news articles published from September 2013 to December 2023 in a range of categories, including entertainment, business, sports, technology, health, and scienceA benchmark dataset for open-domain question answering, targeting explicit fact retrieval<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"MT-BENCH\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A benchmark dataset for open-domain question answering, targeting explicit fact retrieval<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"DATA SENSEMAKING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process through which people inspect, engage with, and contextualize data within the broader scope of real-world activities<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"RAG SYSTEMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Retrieval-Augmented Generation systems used for global sensemaking tasks<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Large Language Model used to automate the generation of questions for dataset evaluation<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"KEVIN SCOTT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Microsoft CTO who participates in podcast conversations compiled in the dataset<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <node id=\"KOESTEN ET AL.\">      <data key=\"d0\">AUTHORS<\/data>      <data key=\"d1\">Authors of a paper on data sensemaking behaviors<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>      <data key=\"d3\">AUTHORS<\/data>    <\/node>    <node id=\"XU AND LAPATA\">      <data key=\"d0\">AUTHORS<\/data>      <data key=\"d1\">Authors of a paper on methods for extracting latent summarization queries from source texts<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>      <data key=\"d3\">AUTHORS<\/data>    <\/node>    <node id=\"TANG AND YANG\">      <data key=\"d0\">AUTHORS<\/data>      <data key=\"d1\">Authors associated with the MultiHop-RAG dataset<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <node id=\"YANG ET AL.\">      <data key=\"d0\">AUTHORS<\/data>      <data key=\"d1\">Authors associated with the HotPotQA dataset<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>      <data key=\"d3\">AUTHORS<\/data>    <\/node>    <node id=\"ZHENG ET AL.\">      <data key=\"d0\">AUTHORS<\/data>      <data key=\"d1\">Authors associated with the MT-Bench dataset<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>      <data key=\"d3\">AUTHORS<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A specific implementation of RAG using four levels of graph communities<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"LATENT SUMMARIZATION QUERIES\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <node id=\"BEHIND THE TECH\">      <data key=\"d0\">PODCAST<\/data>      <data key=\"d1\">A podcast series featuring conversations between Kevin Scott and other technology leaders<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <node id=\"SCOTT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kevin Scott, Microsoft CTO, who participates in the podcast conversations compiled in the dataset<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <node id=\"TANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author associated with the MultiHop-RAG dataset<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <node id=\"YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author associated with the MultiHop-RAG dataset<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <node id=\"HOTSPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A benchmark dataset for open-domain question answering, targeting explicit fact retrieval<\/data>      <data key=\"d2\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/node>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"KEVIN SCOTT\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Kevin Scott is a participant in the podcast conversations compiled in the Podcast Transcripts dataset<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"RAG SYSTEMS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">RAG systems are used to evaluate the Podcast Transcripts dataset for global sensemaking tasks<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"LLM\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LLM is used to generate questions for evaluating the Podcast Transcripts dataset<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"RAG SYSTEMS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">RAG systems are used to evaluate the News Articles dataset for global sensemaking tasks<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"LLM\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LLM is used to generate questions for evaluating the News Articles dataset<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"YANG ET AL.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Yang et al. are the authors associated with the HotPotQA dataset<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>    <edge source=\"MULTIHOP-RAG\" target=\"TANG AND YANG\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Tang and Yang are the authors associated with the MultiHop-RAG dataset<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>    <edge source=\"MT-BENCH\" target=\"ZHENG ET AL.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Zheng et al. are the authors associated with the MT-Bench dataset<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>    <edge source=\"DATA SENSEMAKING\" target=\"KOESTEN ET AL.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Koesten et al. authored a paper on data sensemaking behaviors<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>    <edge source=\"RAG SYSTEMS\" target=\"GRAPH RAG\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG is a specific implementation of RAG systems<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>    <edge source=\"XU AND LAPATA\" target=\"LATENT SUMMARIZATION QUERIES\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Xu and Lapata authored a paper on methods for extracting latent summarization queries from source texts<\/data>      <data key=\"d6\">922778ce1cb2fdd6dbab1746c8795620<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"973164fa90bf2b4ee267f4fd795916bf","chunk":". For our evaluation, a value of N= 5 resulted in 125 test questions\nper dataset. Table 1 shows example questions for each of the two evaluation datasets.\n63.3 Conditions\nWe compare six different conditions in our analysis, including Graph RAG using four levels of graph\ncommunities ( C0,C1,C2,C3), a text summarization method applying our map-reduce approach\ndirectly to source texts ( TS), and a na \u00a8\u0131ve \u201csemantic search\u201d RAG approach ( SS):\n\u2022CO. Uses root-level community summaries (fewest in number) to answer user queries.\n\u2022C1. Uses high-level community summaries to answer queries. These are sub-communities\nof C0, if present, otherwise C0 communities projected down.\n\u2022C2. Uses intermediate-level community summaries to answer queries. These are sub-\ncommunities of C1, if present, otherwise C1 communities projected down.\n\u2022C3. Uses low-level community summaries (greatest in number) to answer queries. These\nare sub-communities of C2, if present, otherwise C2 communities projected down.\n\u2022TS. The same method as in subsection 2.6, except source texts (rather than community\nsummaries) are shuffled and chunked for the map-reduce summarization stages.\n\u2022SS. An implementation of na \u00a8\u0131ve RAG in which text chunks are retrieved and added to the\navailable context window until the specified token limit is reached.\nThe size of the context window and the prompts used for answer generation are the same across\nall six conditions (except for minor modifications to reference styles to match the types of context\ninformation used). Conditions only differ in how the contents of the context window are created.\nThe graph index supporting conditions C0-C3was created using our generic prompts for entity and\nrelationship extraction only, with entity types and few-shot examples tailored to the domain of the\ndata. The graph indexing process used a context window size of 600 tokens with 1 gleaning for the\nPodcast dataset and 0 gleanings for the News dataset.\n3.4 Metrics\nLLMs have been shown to be good evaluators of natural language generation, achieving state-of-\nthe-art or competitive results compared against human judgements (Wang et al., 2023a; Zheng et al.,\n2024). While this approach can generate reference-based metrics when gold standard answers are\nknown, it is also capable of measuring the qualities of generated texts","chunk_id":"973164fa90bf2b4ee267f4fd795916bf","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"N","type":"METRIC","description":"N represents the number of test questions per dataset used in the evaluation","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"DATASET","type":"DATASET","description":"A collection of data used for evaluation, including the Podcast and News datasets","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"GRAPH RAG","type":"METHOD","description":"Graph RAG is a method using graph communities at different levels to answer user queries","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"TEXT SUMMARIZATION","type":"METHOD","description":"A method applying a map-reduce approach directly to source texts for summarization","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"SEMANTIC SEARCH RAG","type":"METHOD","description":"A na\u00a8\u0131ve RAG approach where text chunks are retrieved and added to the context window until the token limit is reached","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"C0","type":"CATEGORY","description":"Root-level community summaries used to answer user queries, representing the fewest number of summaries","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"C1","type":"CATEGORY","description":"High-level community summaries used to answer user queries, representing sub-communities of C0","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"C2","type":"CATEGORY","description":"Intermediate-level community summaries used to answer user queries, representing sub-communities of C1","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"C3","type":"CATEGORY","description":"Low-level community summaries used to answer user queries, representing sub-communities of C2","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"TS","type":"METHOD","description":"A text summarization method applying a map-reduce approach directly to source texts","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"SS","type":"METHOD","description":"A na\u00a8\u0131ve RAG approach where text chunks are retrieved and added to the context window until the token limit is reached","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"CONTEXT WINDOW","type":"CONCEPT","description":"The size of the context window used for answer generation, which is the same across all conditions","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"PROMPTS","type":"CONCEPT","description":"The prompts used for answer generation, which are the same across all conditions with minor modifications","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"GRAPH INDEX","type":"TECHNOLOGY","description":"The graph index supporting conditions C0-C3, created using generic prompts for entity and relationship extraction","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"PODCAST DATASET","type":"DATASET","description":"A dataset consisting of podcast transcripts used in the evaluation","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"NEWS DATASET","type":"DATASET","description":"A dataset consisting of news articles used in the evaluation","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"METRICS","type":"CONCEPT","description":"Metrics used to evaluate natural language generation, including reference-based metrics and qualities of generated texts","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"LLMS","type":"TECHNOLOGY","description":"Large Language Models used as evaluators of natural language generation","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"WANG ET AL., 2023A","type":"REFERENCE","description":"A reference to a study by Wang et al. in 2023, indicating the effectiveness of LLMs in evaluation","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"ZHENG ET AL., 2024","type":"REFERENCE","description":"A reference to a study by Zheng et al. in 2024, indicating the effectiveness of LLMs in evaluation","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"TABLE 1","type":"REFERENCE","description":"Table 1 shows example questions for each of the two evaluation datasets","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"CONDITIONS","type":"CONCEPT","description":"Different conditions compared in the analysis, including Graph RAG, text summarization, and semantic search RAG","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"MAP-REDUCE","type":"METHOD","description":"A method used for text summarization by applying a map-reduce approach directly to source texts","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"USER QUERIES","type":"CONCEPT","description":"Queries made by users that are answered using different methods and conditions","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"ENTITY TYPES","type":"CONCEPT","description":"Types of entities extracted during the graph indexing process","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"FEW-SHOT EXAMPLES","type":"CONCEPT","description":"Examples tailored to the domain of the data used in the graph indexing process","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"CONTEXT WINDOW SIZE","type":"METRIC","description":"The size of the context window used in the graph indexing process, set to 600 tokens","source_id":"973164fa90bf2b4ee267f4fd795916bf"},{"name":"GLEANING","type":"CONCEPT","description":"The process of extracting information, with 1 gleaning for the Podcast dataset and 0 gleanings for the News dataset","source_id":"973164fa90bf2b4ee267f4fd795916bf"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"N\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">N represents the number of test questions per dataset used in the evaluation<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A collection of data used for evaluation, including the Podcast and News datasets<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG is a method using graph communities at different levels to answer user queries<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"TEXT SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method applying a map-reduce approach directly to source texts for summarization<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"SEMANTIC SEARCH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A na&#168;&#305;ve RAG approach where text chunks are retrieved and added to the context window until the token limit is reached<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"C0\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Root-level community summaries used to answer user queries, representing the fewest number of summaries<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"C1\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">High-level community summaries used to answer user queries, representing sub-communities of C0<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"C2\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Intermediate-level community summaries used to answer user queries, representing sub-communities of C1<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"C3\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Low-level community summaries used to answer user queries, representing sub-communities of C2<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"TS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A text summarization method applying a map-reduce approach directly to source texts<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"SS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A na&#168;&#305;ve RAG approach where text chunks are retrieved and added to the context window until the token limit is reached<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"CONTEXT WINDOW\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The size of the context window used for answer generation, which is the same across all conditions<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"PROMPTS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The prompts used for answer generation, which are the same across all conditions with minor modifications<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"GRAPH INDEX\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">The graph index supporting conditions C0-C3, created using generic prompts for entity and relationship extraction<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"PODCAST DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of podcast transcripts used in the evaluation<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"NEWS DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of news articles used in the evaluation<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"METRICS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Metrics used to evaluate natural language generation, including reference-based metrics and qualities of generated texts<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"LLMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Large Language Models used as evaluators of natural language generation<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"WANG ET AL., 2023A\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study by Wang et al. in 2023, indicating the effectiveness of LLMs in evaluation<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"ZHENG ET AL., 2024\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study by Zheng et al. in 2024, indicating the effectiveness of LLMs in evaluation<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"TABLE 1\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Table 1 shows example questions for each of the two evaluation datasets<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"CONDITIONS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Different conditions compared in the analysis, including Graph RAG, text summarization, and semantic search RAG<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"MAP-REDUCE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method used for text summarization by applying a map-reduce approach directly to source texts<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"USER QUERIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Queries made by users that are answered using different methods and conditions<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"ENTITY TYPES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Types of entities extracted during the graph indexing process<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"FEW-SHOT EXAMPLES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Examples tailored to the domain of the data used in the graph indexing process<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"CONTEXT WINDOW SIZE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The size of the context window used in the graph indexing process, set to 600 tokens<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <node id=\"GLEANING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The process of extracting information, with 1 gleaning for the Podcast dataset and 0 gleanings for the News dataset<\/data>      <data key=\"d2\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/node>    <edge source=\"N\" target=\"DATASET\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">N represents the number of test questions per dataset<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"DATASET\" target=\"TABLE 1\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Table 1 shows example questions for each of the two evaluation datasets<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"C0\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses root-level community summaries (C0) to answer user queries<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"C1\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses high-level community summaries (C1) to answer user queries<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"C2\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses intermediate-level community summaries (C2) to answer user queries<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"C3\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses low-level community summaries (C3) to answer user queries<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"CONDITIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is one of the conditions compared in the analysis<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"USER QUERIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses different levels of graph communities to answer user queries<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"TEXT SUMMARIZATION\" target=\"TS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Text summarization method applies a map-reduce approach directly to source texts (TS)<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"TEXT SUMMARIZATION\" target=\"CONDITIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Text summarization is one of the conditions compared in the analysis<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"TEXT SUMMARIZATION\" target=\"MAP-REDUCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Map-reduce is the method used in the text summarization condition<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"SEMANTIC SEARCH RAG\" target=\"SS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Semantic search RAG is a na&#168;&#305;ve RAG approach where text chunks are retrieved and added to the context window until the token limit is reached (SS)<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"SEMANTIC SEARCH RAG\" target=\"CONDITIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Semantic search RAG is one of the conditions compared in the analysis<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"C0\" target=\"GRAPH INDEX\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The graph index supports condition C0<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"C0\" target=\"USER QUERIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C0 uses root-level community summaries to answer user queries<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"C1\" target=\"GRAPH INDEX\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The graph index supports condition C1<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"C1\" target=\"USER QUERIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C1 uses high-level community summaries to answer user queries<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"C2\" target=\"GRAPH INDEX\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The graph index supports condition C2<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"C2\" target=\"USER QUERIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C2 uses intermediate-level community summaries to answer user queries<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"C3\" target=\"GRAPH INDEX\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The graph index supports condition C3<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"C3\" target=\"USER QUERIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C3 uses low-level community summaries to answer user queries<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW\" target=\"PROMPTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The size of the context window and the prompts used for answer generation are the same across all conditions<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH INDEX\" target=\"PODCAST DATASET\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The graph indexing process used a context window size of 600 tokens with 1 gleaning for the Podcast dataset<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH INDEX\" target=\"NEWS DATASET\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The graph indexing process used a context window size of 600 tokens with 0 gleanings for the News dataset<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH INDEX\" target=\"ENTITY TYPES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The graph index was created using generic prompts for entity and relationship extraction<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH INDEX\" target=\"FEW-SHOT EXAMPLES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Few-shot examples tailored to the domain of the data were used in the graph indexing process<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"GRAPH INDEX\" target=\"CONTEXT WINDOW SIZE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The graph indexing process used a context window size of 600 tokens<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"GLEANING\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The graph indexing process used 1 gleaning for the Podcast dataset<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"GLEANING\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The graph indexing process used 0 gleanings for the News dataset<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"METRICS\" target=\"LLMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLMs are used to generate metrics for evaluating natural language generation<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"LLMS\" target=\"WANG ET AL., 2023A\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Wang et al. (2023) indicated the effectiveness of LLMs in evaluation<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>    <edge source=\"LLMS\" target=\"ZHENG ET AL., 2024\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng et al. (2024) indicated the effectiveness of LLMs in evaluation<\/data>      <data key=\"d5\">973164fa90bf2b4ee267f4fd795916bf<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"322e02986c8724eedbcf3ebfa20b989c","chunk":" of natural language generation, achieving state-of-\nthe-art or competitive results compared against human judgements (Wang et al., 2023a; Zheng et al.,\n2024). While this approach can generate reference-based metrics when gold standard answers are\nknown, it is also capable of measuring the qualities of generated texts (e.g., fluency) in a reference-\nfree style (Wang et al., 2023a) as well as in head-to-head comparison of competing outputs (LLM-\nas-a-judge, Zheng et al., 2024). LLMs have also shown promise at evaluating the performance of\nconventional RAG systems, automatically evaluating qualities like context relevance, faithfulness,\nand answer relevance (RAGAS, Es et al., 2023).\nGiven the multi-stage nature of our Graph RAG mechanism, the multiple conditions we wanted to\ncompare, and the lack of gold standard answers to our activity-based sensemaking questions, we\ndecided to adopt a head-to-head comparison approach using an LLM evaluator. We selected three\ntarget metrics capturing qualities that are desirable for sensemaking activities, as well as a control\nmetric (directness) used as a indicator of validity. Since directness is effectively in opposition to\ncomprehensiveness and diversity, we would not expect any method to win across all four metrics.\nOur head-to-head measures computed using an LLM evaluator are as follows:\n\u2022Comprehensiveness . How much detail does the answer provide to cover all aspects and\ndetails of the question?\n\u2022Diversity . How varied and rich is the answer in providing different perspectives and insights\non the question?\n\u2022Empowerment . How well does the answer help the reader understand and make informed\njudgements about the topic?\n\u2022Directness . How specifically and clearly does the answer address the question?\nFor our evaluation, the LLM is provided with the question, target metric, and a pair of answers, and\nasked to assess which answer is better according to the metric, as well as why. It returns the winner\nif one exists, otherwise a tie if they are fundamentally similar and the differences are negligible.\nTo account for the stochasticity of LLMs, we run each comparison five times and use mean scores.\nTable 2 shows an example of LLM-generated assessment.\n7Question Which public figures are repeatedly mentioned across various entertainment articles?\nGraph\nRAGOverview of Prominent Public Figures in Entertainment\nThe entertainment industry is vast and diverse, encompass","chunk_id":"322e02986c8724eedbcf3ebfa20b989c","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"NATURAL LANGUAGE GENERATION","type":"TECHNOLOGY","description":"Natural Language Generation (NLG) is a subfield of artificial intelligence that focuses on generating human-like text from data","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"WANG ET AL., 2023A","type":"PUBLICATION","description":"A reference to a study or paper authored by Wang and others in 2023","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"ZHENG ET AL., 2024","type":"PUBLICATION","description":"A reference to a study or paper authored by Zheng and others in 2024","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"LLM-AS-A-JUDGE","type":"METHOD","description":"A method where a Large Language Model (LLM) is used to compare and evaluate competing outputs","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"RAGAS","type":"METHOD","description":"A method for evaluating the performance of Retrieval-Augmented Generation (RAG) systems, focusing on context relevance, faithfulness, and answer relevance","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"ES ET AL., 2023","type":"PUBLICATION","description":"A reference to a study or paper authored by Es and others in 2023","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"GRAPH RAG","type":"METHOD","description":"A multi-stage mechanism for Retrieval-Augmented Generation (RAG) that involves comparing multiple conditions","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"LLM EVALUATOR","type":"TOOL","description":"A Large Language Model (LLM) used to evaluate and compare generated texts based on specific metrics","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"COMPREHENSIVENESS","type":"METRIC","description":"A metric that measures how much detail an answer provides to cover all aspects and details of a question","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"DIVERSITY","type":"METRIC","description":"A metric that measures how varied and rich an answer is in providing different perspectives and insights on a question","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"EMPOWERMENT","type":"METRIC","description":"A metric that measures how well an answer helps the reader understand and make informed judgements about a topic","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"DIRECTNESS","type":"METRIC","description":"A metric that measures how specifically and clearly an answer addresses a question","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"TABLE 2","type":"DATA","description":"An example of LLM-generated assessment shown in a table format","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"QUESTION","type":"DATA","description":"A specific query used in the evaluation process","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"PUBLIC FIGURES","type":"ENTITY","description":"Individuals who are well-known in the entertainment industry and are mentioned across various articles","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"ENTERTAINMENT ARTICLES","type":"DATASET","description":"A collection of articles focused on the entertainment industry","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"ENTERTAINMENT INDUSTRY","type":"DOMAIN","description":"A sector that encompasses various forms of entertainment, including movies, music, and television","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"STATE-OF-THE-ART","type":"METRIC","description":"A metric indicating the highest level of development or achievement in a particular field","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"COMPETITIVE RESULTS","type":"METRIC","description":"A metric indicating results that are comparable to or better than those of others in the same field","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"HUMAN JUDGEMENTS","type":"METRIC","description":"A metric based on evaluations made by humans","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"REFERENCE-BASED METRICS","type":"METRIC","description":"Metrics that require a gold standard or reference answers for evaluation","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"REFERENCE-FREE STYLE","type":"METHOD","description":"An evaluation method that does not require reference answers","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"CONTEXT RELEVANCE","type":"METRIC","description":"A metric that measures how relevant the generated text is to the given context","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"FAITHFULNESS","type":"METRIC","description":"A metric that measures how accurately the generated text reflects the source information","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"ANSWER RELEVANCE","type":"METRIC","description":"A metric that measures how relevant the generated answer is to the question","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"MULTI-STAGE","type":"METHOD","description":"A method involving multiple stages or steps","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"CONDITIONS","type":"DATA","description":"Different scenarios or variables that are compared in an experiment","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"GOLD STANDARD ANSWERS","type":"DATA","description":"The correct or ideal answers used as a benchmark in evaluations","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"SENSEMAKING QUESTIONS","type":"DATA","description":"Questions designed to help understand and make sense of complex information","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"HEAD-TO-HEAD COMPARISON","type":"METHOD","description":"A method where two items are directly compared against each other","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"TARGET METRICS","type":"DATA","description":"Specific metrics that are the focus of an evaluation","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"CONTROL METRIC","type":"DATA","description":"A metric used as a baseline or standard for comparison","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"VALIDITY","type":"METRIC","description":"A metric that measures the accuracy and reliability of a method or result","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"STOCHASTICITY","type":"METRIC","description":"A metric that measures the randomness or variability in a process","source_id":"322e02986c8724eedbcf3ebfa20b989c"},{"name":"MEAN SCORES","type":"DATA","description":"The average scores obtained from multiple evaluations","source_id":"322e02986c8724eedbcf3ebfa20b989c"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"NATURAL LANGUAGE GENERATION\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Natural Language Generation (NLG) is a subfield of artificial intelligence that focuses on generating human-like text from data<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"WANG ET AL., 2023A\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to a study or paper authored by Wang and others in 2023<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"ZHENG ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to a study or paper authored by Zheng and others in 2024<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"LLM-AS-A-JUDGE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method where a Large Language Model (LLM) is used to compare and evaluate competing outputs<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"RAGAS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method for evaluating the performance of Retrieval-Augmented Generation (RAG) systems, focusing on context relevance, faithfulness, and answer relevance<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"ES ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to a study or paper authored by Es and others in 2023<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A multi-stage mechanism for Retrieval-Augmented Generation (RAG) that involves comparing multiple conditions<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"LLM EVALUATOR\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">A Large Language Model (LLM) used to evaluate and compare generated texts based on specific metrics<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric that measures how much detail an answer provides to cover all aspects and details of a question<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric that measures how varied and rich an answer is in providing different perspectives and insights on a question<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"EMPOWERMENT\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric that measures how well an answer helps the reader understand and make informed judgements about a topic<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"DIRECTNESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric that measures how specifically and clearly an answer addresses a question<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"TABLE 2\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">An example of LLM-generated assessment shown in a table format<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"QUESTION\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">A specific query used in the evaluation process<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"PUBLIC FIGURES\">      <data key=\"d0\">ENTITY<\/data>      <data key=\"d1\">Individuals who are well-known in the entertainment industry and are mentioned across various articles<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"ENTERTAINMENT ARTICLES\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A collection of articles focused on the entertainment industry<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"ENTERTAINMENT INDUSTRY\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">A sector that encompasses various forms of entertainment, including movies, music, and television<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"STATE-OF-THE-ART\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric indicating the highest level of development or achievement in a particular field<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"COMPETITIVE RESULTS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric indicating results that are comparable to or better than those of others in the same field<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"HUMAN JUDGEMENTS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric based on evaluations made by humans<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"REFERENCE-BASED METRICS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Metrics that require a gold standard or reference answers for evaluation<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"REFERENCE-FREE STYLE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">An evaluation method that does not require reference answers<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"CONTEXT RELEVANCE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric that measures how relevant the generated text is to the given context<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"FAITHFULNESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric that measures how accurately the generated text reflects the source information<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"ANSWER RELEVANCE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric that measures how relevant the generated answer is to the question<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"MULTI-STAGE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method involving multiple stages or steps<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"CONDITIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Different scenarios or variables that are compared in an experiment<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"GOLD STANDARD ANSWERS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">The correct or ideal answers used as a benchmark in evaluations<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"SENSEMAKING QUESTIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Questions designed to help understand and make sense of complex information<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"HEAD-TO-HEAD COMPARISON\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method where two items are directly compared against each other<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"TARGET METRICS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Specific metrics that are the focus of an evaluation<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"CONTROL METRIC\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">A metric used as a baseline or standard for comparison<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"VALIDITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric that measures the accuracy and reliability of a method or result<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"STOCHASTICITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric that measures the randomness or variability in a process<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <node id=\"MEAN SCORES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">The average scores obtained from multiple evaluations<\/data>      <data key=\"d2\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/node>    <edge source=\"NATURAL LANGUAGE GENERATION\" target=\"WANG ET AL., 2023A\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Wang et al., 2023a discusses the state-of-the-art results achieved by Natural Language Generation<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"NATURAL LANGUAGE GENERATION\" target=\"ZHENG ET AL., 2024\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng et al., 2024 discusses the competitive results achieved by Natural Language Generation<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"NATURAL LANGUAGE GENERATION\" target=\"STATE-OF-THE-ART\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Natural Language Generation achieves state-of-the-art results<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"NATURAL LANGUAGE GENERATION\" target=\"COMPETITIVE RESULTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Natural Language Generation achieves competitive results<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"NATURAL LANGUAGE GENERATION\" target=\"HUMAN JUDGEMENTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Natural Language Generation is compared against human judgements<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"NATURAL LANGUAGE GENERATION\" target=\"REFERENCE-BASED METRICS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Natural Language Generation can generate reference-based metrics<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"NATURAL LANGUAGE GENERATION\" target=\"REFERENCE-FREE STYLE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Natural Language Generation can measure qualities in a reference-free style<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"ZHENG ET AL., 2024\" target=\"LLM-AS-A-JUDGE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng et al., 2024 discusses the LLM-as-a-judge method<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"RAGAS\" target=\"ES ET AL., 2023\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Es et al., 2023 discusses the RAGAS method<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"RAGAS\" target=\"CONTEXT RELEVANCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">RAGAS evaluates context relevance<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"RAGAS\" target=\"FAITHFULNESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">RAGAS evaluates faithfulness<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"RAGAS\" target=\"ANSWER RELEVANCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">RAGAS evaluates answer relevance<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"LLM EVALUATOR\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The Graph RAG mechanism uses an LLM evaluator for head-to-head comparison<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MULTI-STAGE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is a multi-stage mechanism<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"CONDITIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG compares multiple conditions<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"COMPREHENSIVENESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM evaluator assesses answers based on the comprehensiveness metric<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"DIVERSITY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM evaluator assesses answers based on the diversity metric<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"EMPOWERMENT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM evaluator assesses answers based on the empowerment metric<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"DIRECTNESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM evaluator assesses answers based on the directness metric<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"TABLE 2\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Table 2 shows an example of LLM-generated assessment<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"HEAD-TO-HEAD COMPARISON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM evaluator uses a head-to-head comparison approach<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"TARGET METRICS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM evaluator assesses answers based on target metrics<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"CONTROL METRIC\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM evaluator uses a control metric for validity<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"STOCHASTICITY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM evaluator accounts for stochasticity<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"MEAN SCORES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The LLM evaluator uses mean scores from multiple comparisons<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"QUESTION\" target=\"PUBLIC FIGURES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The question asks about public figures mentioned in entertainment articles<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Public figures are repeatedly mentioned across various entertainment articles<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT ARTICLES\" target=\"ENTERTAINMENT INDUSTRY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Entertainment articles cover topics related to the entertainment industry<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"REFERENCE-BASED METRICS\" target=\"GOLD STANDARD ANSWERS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Reference-based metrics require gold standard answers<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"GOLD STANDARD ANSWERS\" target=\"SENSEMAKING QUESTIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Gold standard answers are lacking for sensemaking questions<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>    <edge source=\"CONTROL METRIC\" target=\"VALIDITY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The control metric is used as an indicator of validity<\/data>      <data key=\"d5\">322e02986c8724eedbcf3ebfa20b989c<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"e8c8f911135faf3ff35f24107eb3f99c","chunk":"ity of LLMs, we run each comparison five times and use mean scores.\nTable 2 shows an example of LLM-generated assessment.\n7Question Which public figures are repeatedly mentioned across various entertainment articles?\nGraph\nRAGOverview of Prominent Public Figures in Entertainment\nThe entertainment industry is vast and diverse, encompassing film, television, music, sports, and\ndigital media. Certain public figures stand out due to their significant contributions and influence\nacross these sectors. The following summary highlights key individuals who are repeatedly\nmentioned in various entertainment articles, reflecting their impact and presence within the industry.\nActors and Directors [...]Public Figures in Controversy [...]Musicians and Executives [...]\nAthletes and Coaches [...]Influencers and Entrepreneurs [...]\nThe repeated mention of these figures in entertainment articles signifies their ongoing relevance and\nthe public\u2019s interest in their work. Their influence spans across various aspects of entertainment, from\nshaping cultural narratives in film and television to driving trends in music and digital media. These\nindividuals not only contribute to their respective fields but also influence the broader cultural\nlandscape, often becoming central figures in social discussions and public discourse.\nNa\u00a8\u0131ve\nRAGPublic figures who are repeatedly mentioned across various entertainment articles include Taylor\nSwift, Travis Kelce, Britney Spears, and Justin Timberlake. These individuals have been highlighted\nfor various reasons, ranging from their professional achievements to their personal lives.\nTaylor Swift [...]Travis Kelce [...]Britney Spears [...]Justin Timberlake [...]\nThese figures are frequently covered due to their high-profile status and the public\u2019s interest in their\ncareers and personal lives. Their activities, whether in music, sports, or personal relationships, have\nsignificant cultural and economic impacts, as evidenced by the media coverage and public reactions.\nLLM\nDecisionComprehensiveness: Winner=1 (Graph RAG)\nAnswer 1 is better because it provides a more comprehensive and detailed list of public figures from a\nwider range of entertainment sectors, including film, television, music, sports, gaming, and digital\nmedia. It also includes specific examples of their contributions and the impact they have on their\nrespective fields, as well as mentions of controversies and their implications. Answer 2, while\ndetailed in its coverage of a few individuals, is limited to a smaller number of public figures and\nfocuses primarily on their personal lives and relationships rather than a broad spectrum of their\nprofessional influence across the entertainment industry.\nDiversity: Winner=","chunk_id":"e8c8f911135faf3ff35f24107eb3f99c","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"LLM","type":"TECHNOLOGY","description":"LLM (Large Language Model) is a type of artificial intelligence used for generating and assessing text","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"RAG","type":"METHOD","description":"RAG (Retrieval-Augmented Generation) is a method that produces direct responses in text generation tasks","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"GRAPH RAG","type":"METHOD","description":"Graph RAG is a method that provides a comprehensive overview of public figures in the entertainment industry","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"NAIVE RAG","type":"METHOD","description":"Naive RAG is a method that lists public figures mentioned in entertainment articles, focusing on their professional achievements and personal lives","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"TAYLOR SWIFT","type":"PERSON","description":"Taylor Swift is a public figure frequently mentioned in entertainment articles, known for her contributions to music and her high-profile personal life","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"TRAVIS KELCE","type":"PERSON","description":"Travis Kelce is a public figure frequently mentioned in entertainment articles, known for his contributions to sports and his high-profile personal life","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"BRITNEY SPEARS","type":"PERSON","description":"Britney Spears is a public figure frequently mentioned in entertainment articles, known for her contributions to music and her high-profile personal life","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"JUSTIN TIMBERLAKE","type":"PERSON","description":"Justin Timberlake is a public figure frequently mentioned in entertainment articles, known for his contributions to music and his high-profile personal life","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"ENTERTAINMENT INDUSTRY","type":"SECTOR","description":"The entertainment industry encompasses film, television, music, sports, and digital media","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"ACTORS AND DIRECTORS","type":"CATEGORY","description":"A category of public figures in the entertainment industry, including those involved in film and television","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"MUSICIANS AND EXECUTIVES","type":"CATEGORY","description":"A category of public figures in the entertainment industry, including those involved in music","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"ATHLETES AND COACHES","type":"CATEGORY","description":"A category of public figures in the entertainment industry, including those involved in sports","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"INFLUENCERS AND ENTREPRENEURS","type":"CATEGORY","description":"A category of public figures in the entertainment industry, including those involved in digital media and business","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"PUBLIC FIGURES IN CONTROVERSY","type":"CATEGORY","description":"A category of public figures in the entertainment industry who are involved in controversies","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"COMPREHENSIVENESS","type":"METRIC","description":"A metric used to evaluate the comprehensiveness of the generated responses","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"DECISION","type":"METRIC","description":"A metric used to determine the winner in the comparison of generated responses","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"QUESTION","type":"METRIC","description":"A metric used to evaluate the generated responses by asking specific questions","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"ASSESSMENT","type":"METRIC","description":"A metric used to evaluate the quality of LLM-generated responses","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"ENTERTAINMENT ARTICLES","type":"DATASET","description":"A dataset consisting of articles related to the entertainment industry","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"FILM","type":"SECTOR","description":"A sector within the entertainment industry that includes movies and cinema","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"TELEVISION","type":"SECTOR","description":"A sector within the entertainment industry that includes TV shows and series","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"MUSIC","type":"SECTOR","description":"A sector within the entertainment industry that includes musical performances and recordings","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"SPORTS","type":"SECTOR","description":"A sector within the entertainment industry that includes athletic events and competitions","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"DIGITAL MEDIA","type":"SECTOR","description":"A sector within the entertainment industry that includes online content and social media","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"CULTURAL NARRATIVES","type":"CATEGORY","description":"A category within the entertainment industry that includes stories and themes that shape culture","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"TRENDS","type":"CATEGORY","description":"A category within the entertainment industry that includes popular movements and styles","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"SOCIAL DISCUSSIONS","type":"CATEGORY","description":"A category within the entertainment industry that includes public conversations and debates","source_id":"e8c8f911135faf3ff35f24107eb3f99c"},{"name":"PUBLIC DISCOURSE","type":"CATEGORY","description":"A category within the entertainment industry that includes formal discussions and communications","source_id":"e8c8f911135faf3ff35f24107eb3f99c"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">LLM (Large Language Model) is a type of artificial intelligence used for generating and assessing text<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">RAG (Retrieval-Augmented Generation) is a method that produces direct responses in text generation tasks<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG is a method that provides a comprehensive overview of public figures in the entertainment industry<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"NAIVE RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Naive RAG is a method that lists public figures mentioned in entertainment articles, focusing on their professional achievements and personal lives<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"TAYLOR SWIFT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Taylor Swift is a public figure frequently mentioned in entertainment articles, known for her contributions to music and her high-profile personal life<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"TRAVIS KELCE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Travis Kelce is a public figure frequently mentioned in entertainment articles, known for his contributions to sports and his high-profile personal life<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"BRITNEY SPEARS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Britney Spears is a public figure frequently mentioned in entertainment articles, known for her contributions to music and her high-profile personal life<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"JUSTIN TIMBERLAKE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Justin Timberlake is a public figure frequently mentioned in entertainment articles, known for his contributions to music and his high-profile personal life<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"ENTERTAINMENT INDUSTRY\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">The entertainment industry encompasses film, television, music, sports, and digital media<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"ACTORS AND DIRECTORS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category of public figures in the entertainment industry, including those involved in film and television<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"MUSICIANS AND EXECUTIVES\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category of public figures in the entertainment industry, including those involved in music<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"ATHLETES AND COACHES\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category of public figures in the entertainment industry, including those involved in sports<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"INFLUENCERS AND ENTREPRENEURS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category of public figures in the entertainment industry, including those involved in digital media and business<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"PUBLIC FIGURES IN CONTROVERSY\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category of public figures in the entertainment industry who are involved in controversies<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the comprehensiveness of the generated responses<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"DECISION\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to determine the winner in the comparison of generated responses<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"QUESTION\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the generated responses by asking specific questions<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"ASSESSMENT\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the quality of LLM-generated responses<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"ENTERTAINMENT ARTICLES\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of articles related to the entertainment industry<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"FILM\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">A sector within the entertainment industry that includes movies and cinema<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"TELEVISION\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">A sector within the entertainment industry that includes TV shows and series<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"MUSIC\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">A sector within the entertainment industry that includes musical performances and recordings<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"SPORTS\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">A sector within the entertainment industry that includes athletic events and competitions<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"DIGITAL MEDIA\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">A sector within the entertainment industry that includes online content and social media<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"CULTURAL NARRATIVES\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category within the entertainment industry that includes stories and themes that shape culture<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"TRENDS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category within the entertainment industry that includes popular movements and styles<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"SOCIAL DISCUSSIONS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category within the entertainment industry that includes public conversations and debates<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <node id=\"PUBLIC DISCOURSE\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category within the entertainment industry that includes formal discussions and communications<\/data>      <data key=\"d2\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/node>    <edge source=\"LLM\" target=\"RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM uses RAG to generate and assess text<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"LLM\" target=\"GRAPH RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM uses Graph RAG to provide a comprehensive overview of public figures in the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"LLM\" target=\"NAIVE RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM uses Naive RAG to list public figures mentioned in entertainment articles<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"LLM\" target=\"ASSESSMENT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM-generated responses are evaluated using assessment metrics<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"LLM\" target=\"QUESTION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM-generated responses are evaluated using specific questions<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"RAG\" target=\"GRAPH RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is a specific implementation of RAG<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"RAG\" target=\"NAIVE RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Naive RAG is a specific implementation of RAG<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TAYLOR SWIFT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG mentions Taylor Swift as a prominent public figure<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TRAVIS KELCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG mentions Travis Kelce as a prominent public figure<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"BRITNEY SPEARS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG mentions Britney Spears as a prominent public figure<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"JUSTIN TIMBERLAKE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG mentions Justin Timberlake as a prominent public figure<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMPREHENSIVENESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is evaluated for comprehensiveness<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DECISION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is determined to be the winner based on the decision metric<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"NAIVE RAG\" target=\"TAYLOR SWIFT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Naive RAG mentions Taylor Swift as a public figure<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"NAIVE RAG\" target=\"TRAVIS KELCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Naive RAG mentions Travis Kelce as a public figure<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"NAIVE RAG\" target=\"BRITNEY SPEARS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Naive RAG mentions Britney Spears as a public figure<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"NAIVE RAG\" target=\"JUSTIN TIMBERLAKE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Naive RAG mentions Justin Timberlake as a public figure<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"NAIVE RAG\" target=\"COMPREHENSIVENESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Naive RAG is evaluated for comprehensiveness<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"NAIVE RAG\" target=\"DECISION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Naive RAG is determined to be the loser based on the decision metric<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"ENTERTAINMENT INDUSTRY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Taylor Swift is a significant figure in the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Taylor Swift is frequently mentioned in entertainment articles<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"ENTERTAINMENT INDUSTRY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Travis Kelce is a significant figure in the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Travis Kelce is frequently mentioned in entertainment articles<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"ENTERTAINMENT INDUSTRY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Britney Spears is a significant figure in the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Britney Spears is frequently mentioned in entertainment articles<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"ENTERTAINMENT INDUSTRY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Justin Timberlake is a significant figure in the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Justin Timberlake is frequently mentioned in entertainment articles<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"ACTORS AND DIRECTORS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Actors and Directors are a category within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"MUSICIANS AND EXECUTIVES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Musicians and Executives are a category within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"ATHLETES AND COACHES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Athletes and Coaches are a category within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"INFLUENCERS AND ENTREPRENEURS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Influencers and Entrepreneurs are a category within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"PUBLIC FIGURES IN CONTROVERSY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Public Figures in Controversy are a category within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"FILM\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Film is a sector within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"TELEVISION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Television is a sector within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"MUSIC\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Music is a sector within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"SPORTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sports is a sector within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"DIGITAL MEDIA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Digital Media is a sector within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"CULTURAL NARRATIVES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Cultural Narratives are a category within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"TRENDS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Trends are a category within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"SOCIAL DISCUSSIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Social Discussions are a category within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"ENTERTAINMENT INDUSTRY\" target=\"PUBLIC DISCOURSE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Public Discourse is a category within the entertainment industry<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>    <edge source=\"COMPREHENSIVENESS\" target=\"DECISION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Comprehensiveness is a metric used to determine the decision<\/data>      <data key=\"d5\">e8c8f911135faf3ff35f24107eb3f99c<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"718017a4871c909420f84b85b8ba969d","chunk":" as mentions of controversies and their implications. Answer 2, while\ndetailed in its coverage of a few individuals, is limited to a smaller number of public figures and\nfocuses primarily on their personal lives and relationships rather than a broad spectrum of their\nprofessional influence across the entertainment industry.\nDiversity: Winner=1 (Graph RAG)\nAnswer 1 is better because it provides a more varied and rich response by covering a wide range of\npublic figures from different sectors of the entertainment industry, including film, television, music,\nsports, gaming, and digital media. It offers insights into the contributions and influence of these\nfigures, as well as controversies and their impact on public discourse. The answer also cites specific\ndata sources for each mentioned figure, indicating a diverse range of evidence to support the claims.\nIn contrast, Answer 2 focuses on a smaller group of public figures, primarily from the music industry\nand sports, and relies heavily on a single source for data, which makes it less diverse in perspectives\nand insights.\nEmpowerment: Winner=1 (Graph RAG)\nAnswer 1 is better because it provides a comprehensive and structured overview of public figures\nacross various sectors of the entertainment industry, including film, television, music, sports, and\ndigital media. It lists multiple individuals, providing specific examples of their contributions and the\ncontext in which they are mentioned in entertainment articles, along with references to data reports\nfor each claim. This approach helps the reader understand the breadth of the topic and make informed\njudgments without being misled. In contrast, Answer 2 focuses on a smaller group of public figures\nand primarily discusses their personal lives and relationships, which may not provide as broad an\nunderstanding of the topic. While Answer 2 also cites sources, it does not match the depth and variety\nof Answer 1.\nDirectness: Winner=2 (Na \u00a8\u0131ve RAG)\nAnswer 2 is better because it directly lists specific public figures who are repeatedly mentioned\nacross various entertainment articles, such as Taylor Swift, Travis Kelce, Britney Spears, and Justin\nTimberlake, and provides concise explanations for their frequent mentions. Answer 1, while\ncomprehensive, includes a lot of detailed information about various figures in different sectors of\nentertainment, which, while informative, does not directly answer the question with the same level of\nconciseness and specificity as Answer 2.\nTable 2: Example question for the News article dataset, with generated answers","chunk_id":"718017a4871c909420f84b85b8ba969d","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"ANSWER 1","type":"RESPONSE","description":"Answer 1 provides a varied and rich response by covering a wide range of public figures from different sectors of the entertainment industry, including film, television, music, sports, gaming, and digital media. It offers insights into the contributions and influence of these figures, as well as controversies and their impact on public discourse. The answer also cites specific data sources for each mentioned figure, indicating a diverse range of evidence to support the claims.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"ANSWER 2","type":"RESPONSE","description":"Answer 2 focuses on a smaller group of public figures, primarily from the music industry and sports, and relies heavily on a single source for data. It provides concise explanations for the frequent mentions of specific public figures such as Taylor Swift, Travis Kelce, Britney Spears, and Justin Timberlake.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"GRAPH RAG","type":"METHOD","description":"Graph RAG is a method used to generate responses that provide a comprehensive and structured overview of public figures across various sectors of the entertainment industry.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"NA\u00cfVE RAG","type":"METHOD","description":"Na\u00efve RAG is a method used to generate responses that directly list specific public figures who are repeatedly mentioned across various entertainment articles.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"TAYLOR SWIFT","type":"PERSON","description":"Taylor Swift is a public figure frequently mentioned in entertainment articles, known for her contributions to the music industry.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"TRAVIS KELCE","type":"PERSON","description":"Travis Kelce is a public figure frequently mentioned in entertainment articles, known for his contributions to the sports industry.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"BRITNEY SPEARS","type":"PERSON","description":"Britney Spears is a public figure frequently mentioned in entertainment articles, known for her contributions to the music industry.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"JUSTIN TIMBERLAKE","type":"PERSON","description":"Justin Timberlake is a public figure frequently mentioned in entertainment articles, known for his contributions to the music industry.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"NEWS ARTICLE DATASET","type":"DATASET","description":"A dataset consisting of news articles used for generating responses to questions about public figures in the entertainment industry.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"CONTROVERSIES","type":"TOPIC","description":"Controversies are events or issues involving public figures that generate public debate and impact public discourse.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"PUBLIC FIGURES","type":"CATEGORY","description":"Public figures are individuals who have gained fame or notoriety in various sectors such as entertainment, sports, and digital media.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"FILM","type":"SECTOR","description":"The film sector includes public figures involved in the movie industry, including actors, directors, and producers.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"TELEVISION","type":"SECTOR","description":"The television sector includes public figures involved in TV shows, including actors, hosts, and producers.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"MUSIC","type":"SECTOR","description":"The music sector includes public figures involved in the music industry, including singers, musicians, and producers.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"SPORTS","type":"SECTOR","description":"The sports sector includes public figures involved in sports, including athletes, coaches, and sports commentators.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"GAMING","type":"SECTOR","description":"The gaming sector includes public figures involved in the gaming industry, including gamers, developers, and streamers.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"DIGITAL MEDIA","type":"SECTOR","description":"The digital media sector includes public figures involved in online platforms, including influencers, content creators, and digital marketers.","source_id":"718017a4871c909420f84b85b8ba969d"},{"name":"DATA SOURCES","type":"RESOURCE","description":"Data sources are references or reports used to support claims about public figures and their influence.","source_id":"718017a4871c909420f84b85b8ba969d"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ANSWER 1\">      <data key=\"d0\">RESPONSE<\/data>      <data key=\"d1\">Answer 1 provides a varied and rich response by covering a wide range of public figures from different sectors of the entertainment industry, including film, television, music, sports, gaming, and digital media. It offers insights into the contributions and influence of these figures, as well as controversies and their impact on public discourse. The answer also cites specific data sources for each mentioned figure, indicating a diverse range of evidence to support the claims.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"ANSWER 2\">      <data key=\"d0\">RESPONSE<\/data>      <data key=\"d1\">Answer 2 focuses on a smaller group of public figures, primarily from the music industry and sports, and relies heavily on a single source for data. It provides concise explanations for the frequent mentions of specific public figures such as Taylor Swift, Travis Kelce, Britney Spears, and Justin Timberlake.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG is a method used to generate responses that provide a comprehensive and structured overview of public figures across various sectors of the entertainment industry.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"NA&#207;VE RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Na&#239;ve RAG is a method used to generate responses that directly list specific public figures who are repeatedly mentioned across various entertainment articles.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"TAYLOR SWIFT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Taylor Swift is a public figure frequently mentioned in entertainment articles, known for her contributions to the music industry.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"TRAVIS KELCE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Travis Kelce is a public figure frequently mentioned in entertainment articles, known for his contributions to the sports industry.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"BRITNEY SPEARS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Britney Spears is a public figure frequently mentioned in entertainment articles, known for her contributions to the music industry.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"JUSTIN TIMBERLAKE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Justin Timberlake is a public figure frequently mentioned in entertainment articles, known for his contributions to the music industry.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"NEWS ARTICLE DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of news articles used for generating responses to questions about public figures in the entertainment industry.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"CONTROVERSIES\">      <data key=\"d0\">TOPIC<\/data>      <data key=\"d1\">Controversies are events or issues involving public figures that generate public debate and impact public discourse.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"PUBLIC FIGURES\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Public figures are individuals who have gained fame or notoriety in various sectors such as entertainment, sports, and digital media.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"FILM\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">The film sector includes public figures involved in the movie industry, including actors, directors, and producers.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"TELEVISION\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">The television sector includes public figures involved in TV shows, including actors, hosts, and producers.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"MUSIC\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">The music sector includes public figures involved in the music industry, including singers, musicians, and producers.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"SPORTS\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">The sports sector includes public figures involved in sports, including athletes, coaches, and sports commentators.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"GAMING\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">The gaming sector includes public figures involved in the gaming industry, including gamers, developers, and streamers.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"DIGITAL MEDIA\">      <data key=\"d0\">SECTOR<\/data>      <data key=\"d1\">The digital media sector includes public figures involved in online platforms, including influencers, content creators, and digital marketers.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <node id=\"DATA SOURCES\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">Data sources are references or reports used to support claims about public figures and their influence.<\/data>      <data key=\"d2\">718017a4871c909420f84b85b8ba969d<\/data>    <\/node>    <edge source=\"ANSWER 1\" target=\"GRAPH RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 was generated using the Graph RAG method, which provides a comprehensive and structured overview of public figures across various sectors of the entertainment industry.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 1\" target=\"NEWS ARTICLE DATASET\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 cites specific data sources from the News article dataset for each mentioned figure.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 1\" target=\"CONTROVERSIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 provides insights into controversies involving public figures and their impact on public discourse.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 1\" target=\"PUBLIC FIGURES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 covers a wide range of public figures from different sectors of the entertainment industry.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 1\" target=\"FILM\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 includes public figures from the film sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 1\" target=\"TELEVISION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 includes public figures from the television sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 1\" target=\"MUSIC\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 includes public figures from the music sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 1\" target=\"SPORTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 includes public figures from the sports sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 1\" target=\"GAMING\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 includes public figures from the gaming sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 1\" target=\"DIGITAL MEDIA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 includes public figures from the digital media sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 1\" target=\"DATA SOURCES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 1 cites specific data sources for each mentioned figure.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 2\" target=\"NA&#207;VE RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 2 was generated using the Na&#239;ve RAG method, which directly lists specific public figures who are repeatedly mentioned across various entertainment articles.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 2\" target=\"NEWS ARTICLE DATASET\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 2 relies heavily on a single source from the News article dataset for data.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 2\" target=\"TAYLOR SWIFT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Taylor Swift is one of the specific public figures mentioned in Answer 2.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 2\" target=\"TRAVIS KELCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Travis Kelce is one of the specific public figures mentioned in Answer 2.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 2\" target=\"BRITNEY SPEARS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Britney Spears is one of the specific public figures mentioned in Answer 2.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 2\" target=\"JUSTIN TIMBERLAKE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Justin Timberlake is one of the specific public figures mentioned in Answer 2.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 2\" target=\"PUBLIC FIGURES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 2 focuses on a smaller group of public figures, primarily from the music industry and sports.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 2\" target=\"MUSIC\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 2 focuses on public figures primarily from the music sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 2\" target=\"SPORTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 2 focuses on public figures primarily from the sports sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"ANSWER 2\" target=\"DATA SOURCES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 2 relies heavily on a single data source.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"MUSIC\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Taylor Swift is a public figure in the music sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"SPORTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Travis Kelce is a public figure in the sports sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"MUSIC\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Britney Spears is a public figure in the music sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"MUSIC\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Justin Timberlake is a public figure in the music sector.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>    <edge source=\"CONTROVERSIES\" target=\"PUBLIC FIGURES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Controversies involve public figures and impact public discourse.<\/data>      <data key=\"d5\">718017a4871c909420f84b85b8ba969d<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"ebf5249c888e07fedce6572a4c03f88c","chunk":" while\ncomprehensive, includes a lot of detailed information about various figures in different sectors of\nentertainment, which, while informative, does not directly answer the question with the same level of\nconciseness and specificity as Answer 2.\nTable 2: Example question for the News article dataset, with generated answers from Graph RAG\n(C2) and Na \u00a8\u0131ve RAG, as well as LLM-generated assessments.\n8Podcast transcripts\n501728252221\n835050484344\n725050535049\n755247505250\n785750485052\n795651504850SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nComprehensiveness501823251919\n825050504346\n775050504644\n755050504445\n815754565048\n815456555250SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDiversity504257524951\n585059555251\n434150494748\n484551504950\n514853515051\n494952504950SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nEmpowerment505665606060\n445055525152\n354550474848\n404853505050\n404952505050\n404852505050SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDirectness\nNews articles\n502028252121\n805044413836\n725650525452\n755948505855\n796246425059\n796448454150SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nComprehensiveness503338352931\n675053454440\n624750404141\n655560505050\n715659505051\n696059504950SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDiversity504757495050\n535058505048\n434250424544\n515058505251\n505055485050\n505256495050SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nEmpowerment505459555554\n465055535252","chunk_id":"ebf5249c888e07fedce6572a4c03f88c","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"NEWS ARTICLE DATASET","type":"DATASET","description":"A dataset consisting of news articles used for analysis","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"GRAPH RAG","type":"METHOD","description":"Graph RAG is a method used to generate answers for questions in the News article dataset","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"NA\u00cfVE RAG","type":"METHOD","description":"Na\u00efve RAG is a method used to generate answers for questions in the News article dataset","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"LLM-GENERATED ASSESSMENTS","type":"METHOD","description":"Assessments generated by large language models (LLMs) to evaluate the answers produced by different methods","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"PODCAST TRANSCRIPTS","type":"DATASET","description":"A dataset consisting of transcripts from podcasts used for analysis","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"C0","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"C1","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"C2","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"C3","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"TS","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"COMPREHENSIVENESS","type":"METRIC","description":"A metric used to evaluate the thoroughness of the generated answers","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"DIVERSITY","type":"METRIC","description":"A metric used to evaluate the variety in the generated answers","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"EMPOWERMENT","type":"METRIC","description":"A metric used to evaluate how empowering the generated answers are","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"DIRECTNESS","type":"METRIC","description":"A metric used to evaluate the straightforwardness of the generated answers","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"ANSWER 2","type":"METHOD","description":"Answer 2 is a generated answer for the example question in the News article dataset","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"EXAMPLE QUESTION","type":"DATASET","description":"An example question used in the News article dataset for analysis","source_id":"ebf5249c888e07fedce6572a4c03f88c"},{"name":"SS","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"ebf5249c888e07fedce6572a4c03f88c"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"NEWS ARTICLE DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of news articles used for analysis<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG is a method used to generate answers for questions in the News article dataset<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"NA&#207;VE RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Na&#239;ve RAG is a method used to generate answers for questions in the News article dataset<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"LLM-GENERATED ASSESSMENTS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Assessments generated by large language models (LLMs) to evaluate the answers produced by different methods<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"PODCAST TRANSCRIPTS\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of transcripts from podcasts used for analysis<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"C0\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"C1\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"C2\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"C3\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"TS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the thoroughness of the generated answers<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the variety in the generated answers<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"EMPOWERMENT\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate how empowering the generated answers are<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"DIRECTNESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the straightforwardness of the generated answers<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"ANSWER 2\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Answer 2 is a generated answer for the example question in the News article dataset<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"EXAMPLE QUESTION\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">An example question used in the News article dataset for analysis<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <node id=\"SS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/node>    <edge source=\"NEWS ARTICLE DATASET\" target=\"GRAPH RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is used to generate answers for questions in the News article dataset<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"NA&#207;VE RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Na&#239;ve RAG is used to generate answers for questions in the News article dataset<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"LLM-GENERATED ASSESSMENTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLM-generated assessments are used to evaluate the answers produced for questions in the News article dataset<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"C0\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C0 is a category used in the analysis of news articles<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"C1\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C1 is a category used in the analysis of news articles<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"C2\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C2 is a category used in the analysis of news articles<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"C3\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C3 is a category used in the analysis of news articles<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"TS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">TS is a category used in the analysis of news articles<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"COMPREHENSIVENESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Comprehensiveness is used to evaluate the thoroughness of the generated answers for news articles<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"DIVERSITY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Diversity is used to evaluate the variety in the generated answers for news articles<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"EMPOWERMENT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Empowerment is used to evaluate how empowering the generated answers are for news articles<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"DIRECTNESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Directness is used to evaluate the straightforwardness of the generated answers for news articles<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"ANSWER 2\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer 2 is a generated answer for a question in the News article dataset<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"EXAMPLE QUESTION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Example question is part of the News article dataset used for analysis<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"NEWS ARTICLE DATASET\" target=\"SS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">SS is a category used in the analysis of news articles<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"C0\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C0 is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"C1\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C1 is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"C2\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C2 is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"C3\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C3 is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"TS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">TS is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"COMPREHENSIVENESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Comprehensiveness is used to evaluate the thoroughness of the generated answers for podcast transcripts<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"DIVERSITY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Diversity is used to evaluate the variety in the generated answers for podcast transcripts<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"EMPOWERMENT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Empowerment is used to evaluate how empowering the generated answers are for podcast transcripts<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"SS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">SS is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d5\">ebf5249c888e07fedce6572a4c03f88c<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"4c855404ee3d3c94aa2136f1513c666f","chunk":"050\n535058505048\n434250424544\n515058505251\n505055485050\n505256495050SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nEmpowerment505459555554\n465055535252\n414550484847\n454752504949\n454852515049\n464853515150SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDirectness\nFigure 4: Head-to-head win rate percentages of (row condition) over (column condition) across two\ndatasets, four metrics, and 125 questions per comparison (each repeated five times and averaged).\nThe overall winner per dataset and metric is shown in bold. Self-win rates were not computed but\nare shown as the expected 50% for reference. All Graph RAG conditions outperformed na \u00a8\u0131ve RAG\non comprehensiveness and diversity. Conditions C1-C3 also showed slight improvements in answer\ncomprehensiveness and diversity over TS (global text summarization without a graph index).\n3.5 Configuration\nThe effect of context window size on any particular task is unclear, especially for models like\ngpt-4-turbo with a large context size of 128k tokens. Given the potential for information to\nbe \u201clost in the middle\u201d of longer contexts (Kuratov et al., 2024; Liu et al., 2023), we wanted to ex-\nplore the effects of varying the context window size for our combinations of datasets, questions, and\nmetrics. In particular, our goal was to determine the optimum context size for our baseline condition\n(SS) and then use this uniformly for all query-time LLM use. To that end, we tested four context\nwindow sizes: 8k, 16k, 32k and 64k. Surprisingly, the smallest context window size tested (8k)\nwas universally better for all comparisons on comprehensiveness (average win rate of 58.1%), while\nperforming comparably with larger context sizes on diversity (average win rate = 52.4%), and em-\npowerment (average win rate = 51.3%). Given our preference for more comprehensive and diverse\nanswers, we therefore used a fixed context window size of 8k tokens for the final evaluation.\n3.6 Results\nThe indexing process resulted in","chunk_id":"4c855404ee3d3c94aa2136f1513c666f","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"GRAPH RAG","type":"METHOD","description":"Graph RAG is a method that outperformed naive RAG on comprehensiveness and diversity in text generation tasks","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"NAIVE RAG","type":"METHOD","description":"Naive RAG is a baseline method used for comparison in text generation tasks","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"C0","type":"CATEGORY","description":"A category or condition used in the analysis, representing a specific subset of the data","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"C1","type":"CATEGORY","description":"A category or condition used in the analysis, representing a specific subset of the data","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"C2","type":"CATEGORY","description":"A category or condition used in the analysis, representing a specific subset of the data","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"C3","type":"CATEGORY","description":"A category or condition used in the analysis, representing a specific subset of the data","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"TS","type":"CATEGORY","description":"A category or condition used in the analysis, representing a specific subset of the data","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"SS","type":"CATEGORY","description":"A baseline condition used in the analysis, representing a specific subset of the data","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"GPT-4-TURBO","type":"MODEL","description":"GPT-4-Turbo is a model with a large context size of 128k tokens used in the analysis","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"CONTEXT WINDOW SIZE","type":"PARAMETER","description":"The size of the context window used in the analysis, tested at 8k, 16k, 32k, and 64k tokens","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"COMPREHENSIVENESS","type":"METRIC","description":"A metric used to evaluate the quality of answers in terms of their completeness","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"DIVERSITY","type":"METRIC","description":"A metric used to evaluate the variety of answers generated","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"EMPOWERMENT","type":"METRIC","description":"A metric used to evaluate the effectiveness of answers in empowering users","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"KURATOV ET AL., 2024","type":"REFERENCE","description":"A reference to a study by Kuratov et al. in 2024, discussing the potential for information to be lost in longer contexts","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"LIU ET AL., 2023","type":"REFERENCE","description":"A reference to a study by Liu et al. in 2023, discussing the potential for information to be lost in longer contexts","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"DATASETS","type":"DATA","description":"The datasets used in the analysis, consisting of various text sources","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"QUESTIONS","type":"DATA","description":"The questions used in the analysis to evaluate the performance of different methods","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"METRICS","type":"DATA","description":"The metrics used in the analysis to evaluate the performance of different methods","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"HEAD-TO-HEAD WIN RATE","type":"METRIC","description":"A metric used to compare the performance of different conditions in the analysis","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"CONDITION","type":"CATEGORY","description":"A specific setup or scenario used in the analysis, such as C0, C1, C2, C3, TS, and SS","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"WIN RATE","type":"METRIC","description":"The percentage of times a condition outperformed another in the analysis","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"OVERALL WINNER","type":"METRIC","description":"The condition that performed the best across all comparisons in the analysis","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"SELF-WIN RATE","type":"METRIC","description":"The expected win rate of a condition when compared to itself, shown as 50% for reference","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"QUERY-TIME LLM USE","type":"METHOD","description":"The use of large language models (LLMs) at the time of querying, evaluated in the analysis","source_id":"4c855404ee3d3c94aa2136f1513c666f"},{"name":"FINAL EVALUATION","type":"METHOD","description":"The last stage of the analysis where the best performing context window size was used","source_id":"4c855404ee3d3c94aa2136f1513c666f"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG is a method that outperformed naive RAG on comprehensiveness and diversity in text generation tasks<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"NAIVE RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Naive RAG is a baseline method used for comparison in text generation tasks<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"C0\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or condition used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"C1\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or condition used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"C2\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or condition used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"C3\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or condition used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"TS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or condition used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"SS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A baseline condition used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"GPT-4-TURBO\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4-Turbo is a model with a large context size of 128k tokens used in the analysis<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"CONTEXT WINDOW SIZE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">The size of the context window used in the analysis, tested at 8k, 16k, 32k, and 64k tokens<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the quality of answers in terms of their completeness<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the variety of answers generated<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"EMPOWERMENT\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the effectiveness of answers in empowering users<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"KURATOV ET AL., 2024\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study by Kuratov et al. in 2024, discussing the potential for information to be lost in longer contexts<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"LIU ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study by Liu et al. in 2023, discussing the potential for information to be lost in longer contexts<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"DATASETS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">The datasets used in the analysis, consisting of various text sources<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"QUESTIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">The questions used in the analysis to evaluate the performance of different methods<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"METRICS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">The metrics used in the analysis to evaluate the performance of different methods<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"HEAD-TO-HEAD WIN RATE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to compare the performance of different conditions in the analysis<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"CONDITION\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A specific setup or scenario used in the analysis, such as C0, C1, C2, C3, TS, and SS<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"WIN RATE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The percentage of times a condition outperformed another in the analysis<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"OVERALL WINNER\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The condition that performed the best across all comparisons in the analysis<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"SELF-WIN RATE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The expected win rate of a condition when compared to itself, shown as 50% for reference<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"QUERY-TIME LLM USE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">The use of large language models (LLMs) at the time of querying, evaluated in the analysis<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <node id=\"FINAL EVALUATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">The last stage of the analysis where the best performing context window size was used<\/data>      <data key=\"d2\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/node>    <edge source=\"GRAPH RAG\" target=\"NAIVE RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG outperformed naive RAG on comprehensiveness and diversity<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"C1\" target=\"TS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C1 showed slight improvements in answer comprehensiveness and diversity over TS<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"C2\" target=\"TS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C2 showed slight improvements in answer comprehensiveness and diversity over TS<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"C3\" target=\"TS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C3 showed slight improvements in answer comprehensiveness and diversity over TS<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"GPT-4-TURBO\" target=\"CONTEXT WINDOW SIZE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">GPT-4-Turbo was tested with varying context window sizes<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"COMPREHENSIVENESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The smallest context window size (8k) was universally better for comprehensiveness<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"DIVERSITY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The smallest context window size (8k) performed comparably with larger context sizes on diversity<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"EMPOWERMENT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The smallest context window size (8k) performed comparably with larger context sizes on empowerment<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"KURATOV ET AL., 2024\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kuratov et al. discussed the potential for information to be lost in longer contexts<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"LIU ET AL., 2023\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Liu et al. discussed the potential for information to be lost in longer contexts<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"QUERY-TIME LLM USE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Query-time LLM use was evaluated with different context window sizes<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"FINAL EVALUATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The final evaluation used a fixed context window size of 8k tokens<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"COMPREHENSIVENESS\" target=\"FINAL EVALUATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The final evaluation prioritized comprehensiveness in answers<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"DIVERSITY\" target=\"FINAL EVALUATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The final evaluation prioritized diversity in answers<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"DATASETS\" target=\"QUESTIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Datasets were used in combination with questions for the analysis<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"DATASETS\" target=\"METRICS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Datasets were evaluated using various metrics<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"QUESTIONS\" target=\"METRICS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Questions were evaluated using various metrics<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"HEAD-TO-HEAD WIN RATE\" target=\"CONDITION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Head-to-head win rate percentages were used to compare different conditions<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"CONDITION\" target=\"WIN RATE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Win rate percentages were used to measure the performance of different conditions<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"CONDITION\" target=\"OVERALL WINNER\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The overall winner per dataset and metric was determined for each condition<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>    <edge source=\"CONDITION\" target=\"SELF-WIN RATE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Self-win rates were shown as the expected 50% for each condition<\/data>      <data key=\"d5\">4c855404ee3d3c94aa2136f1513c666f<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"36db32c37e1987e2c5863898ad882190","chunk":" (average win rate = 52.4%), and em-\npowerment (average win rate = 51.3%). Given our preference for more comprehensive and diverse\nanswers, we therefore used a fixed context window size of 8k tokens for the final evaluation.\n3.6 Results\nThe indexing process resulted in a graph consisting of 8564 nodes and 20691 edges for the Podcast\ndataset, and a larger graph of 15754 nodes and 19520 edges for the News dataset. Table 3 shows the\nnumber of community summaries at different levels of each graph community hierarchy.\nGlobal approaches vs. na \u00a8\u0131ve RAG . As shown in Figure 4, global approaches consistently out-\nperformed the na \u00a8\u0131ve RAG ( SS) approach in both comprehensiveness and diversity metrics across\ndatasets. Specifically, global approaches achieved comprehensiveness win rates between 72-83%\nfor Podcast transcripts and 72-80% for News articles, while diversity win rates ranged from 75-82%\nand 62-71% respectively. Our use of directness as a validity test also achieved the expected results,\ni.e., that na \u00a8\u0131ve RAG produces the most direct responses across all comparisons.\n9Podcast Transcripts News Articles\nC0 C1 C2 C3 TS C0 C1 C2 C3 TS\nUnits 34 367 969 1310 1669 55 555 1797 2142 3197\nTokens 26657 225756 565720 746100 1014611 39770 352641 980898 1140266 1707694\n% Max 2.6 22.2 55.8 73.5 100 2.3 20.7 57.4 66.8 100\nTable 3: Number of context units (community summaries for C0-C3 and text chunks for TS), corre-\nsponding token counts, and percentage of the maximum token count. Map-reduce summarization of\nsource texts is the most resource-intensive approach requiring the highest number of context tokens.\nRoot-level community summaries ( C0) require dramatically fewer tokens per query (9x-43x).\nCommunity summaries vs. source texts. When comparing community summaries to source texts\nusing Graph RAG, community summaries generally provided a small but consistent improvement\nin answer comprehensiveness and diversity, except for root-level summaries. Intermediate-level\nsumm","chunk_id":"36db32c37e1987e2c5863898ad882190","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"WIN RATE","type":"METRIC","description":"The percentage of times a particular approach or method achieves a win in a given context","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"EMPOWERMENT","type":"CONCEPT","description":"A concept or metric used in the evaluation, with an average win rate of 51.3%","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"CONTEXT WINDOW SIZE","type":"PARAMETER","description":"The fixed size of the context window used for the final evaluation, set to 8k tokens","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"INDEXING PROCESS","type":"PROCESS","description":"The process that resulted in the creation of graphs for the Podcast and News datasets","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"GRAPH","type":"STRUCTURE","description":"A data structure consisting of nodes and edges, used to represent the Podcast and News datasets","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"PODCAST DATASET","type":"DATASET","description":"A dataset consisting of podcast transcripts, used in the analysis","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"NEWS DATASET","type":"DATASET","description":"A dataset consisting of news articles, used in the analysis","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"NODES","type":"COMPONENT","description":"The individual elements or points in a graph, with 8564 nodes for the Podcast dataset and 15754 nodes for the News dataset","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"EDGES","type":"COMPONENT","description":"The connections or links between nodes in a graph, with 20691 edges for the Podcast dataset and 19520 edges for the News dataset","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"COMMUNITY SUMMARIES","type":"DATA","description":"Summaries of different levels of each graph community hierarchy","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"GLOBAL APPROACHES","type":"METHOD","description":"Approaches that consistently outperformed the naive RAG in comprehensiveness and diversity metrics","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"NAIVE RAG","type":"METHOD","description":"A method that produces the most direct responses but is outperformed by global approaches in comprehensiveness and diversity","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"COMPREHENSIVENESS","type":"METRIC","description":"A metric used to evaluate the thoroughness of responses, with win rates between 72-83% for Podcast transcripts and 72-80% for News articles","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"DIVERSITY","type":"METRIC","description":"A metric used to evaluate the variety of responses, with win rates ranging from 75-82% for Podcast transcripts and 62-71% for News articles","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"DIRECTNESS","type":"METRIC","description":"A validity test metric used to measure the directness of responses, with naive RAG producing the most direct responses","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"C0","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"36db32c37e1987e2c5863898ad882190","entity_type":"CATEGORY"},{"name":"C1","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"36db32c37e1987e2c5863898ad882190","entity_type":"CATEGORY"},{"name":"C2","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"36db32c37e1987e2c5863898ad882190","entity_type":"CATEGORY"},{"name":"C3","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"36db32c37e1987e2c5863898ad882190","entity_type":"CATEGORY"},{"name":"TS","type":"CATEGORY","description":"A category or cluster used in the analysis, representing a specific subset of the data","source_id":"36db32c37e1987e2c5863898ad882190","entity_type":"CATEGORY"},{"name":"UNITS","type":"METRIC","description":"The number of context units, such as community summaries or text chunks, used in the analysis","source_id":"36db32c37e1987e2c5863898ad882190","entity_type":"METRIC"},{"name":"TOKENS","type":"METRIC","description":"The number of tokens, or individual words, used in the analysis","source_id":"36db32c37e1987e2c5863898ad882190","entity_type":"METRIC"},{"name":"% MAX","type":"METRIC","description":"The percentage of the maximum token count used in the analysis","source_id":"36db32c37e1987e2c5863898ad882190","entity_type":"METRIC"},{"name":"MAP-REDUCE SUMMARIZATION","type":"METHOD","description":"A summarization approach that is the most resource-intensive, requiring the highest number of context tokens","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"ROOT-LEVEL COMMUNITY SUMMARIES","type":"DATA","description":"Summaries at the root level of the community hierarchy, requiring dramatically fewer tokens per query","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"GRAPH RAG","type":"METHOD","description":"A method used to compare community summaries to source texts, generally providing a small but consistent improvement in answer comprehensiveness and diversity","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"FINAL EVALUATION","type":"","description":"","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"PODCAST TRANSCRIPTS","type":"DATASET","description":"A dataset consisting of transcripts from podcasts used for analysis","source_id":"36db32c37e1987e2c5863898ad882190"},{"name":"NEWS ARTICLES","type":"DATASET","description":"A dataset consisting of news articles used for analysis","source_id":"36db32c37e1987e2c5863898ad882190"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"WIN RATE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The percentage of times a particular approach or method achieves a win in a given context<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"EMPOWERMENT\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A concept or metric used in the evaluation, with an average win rate of 51.3%<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"CONTEXT WINDOW SIZE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">The fixed size of the context window used for the final evaluation, set to 8k tokens<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"INDEXING PROCESS\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process that resulted in the creation of graphs for the Podcast and News datasets<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"GRAPH\">      <data key=\"d0\">STRUCTURE<\/data>      <data key=\"d1\">A data structure consisting of nodes and edges, used to represent the Podcast and News datasets<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"PODCAST DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of podcast transcripts, used in the analysis<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"NEWS DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of news articles, used in the analysis<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"NODES\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">The individual elements or points in a graph, with 8564 nodes for the Podcast dataset and 15754 nodes for the News dataset<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"EDGES\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">The connections or links between nodes in a graph, with 20691 edges for the Podcast dataset and 19520 edges for the News dataset<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Summaries of different levels of each graph community hierarchy<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"GLOBAL APPROACHES\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Approaches that consistently outperformed the naive RAG in comprehensiveness and diversity metrics<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"NAIVE RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method that produces the most direct responses but is outperformed by global approaches in comprehensiveness and diversity<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the thoroughness of responses, with win rates between 72-83% for Podcast transcripts and 72-80% for News articles<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the variety of responses, with win rates ranging from 75-82% for Podcast transcripts and 62-71% for News articles<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"DIRECTNESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A validity test metric used to measure the directness of responses, with naive RAG producing the most direct responses<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"C0\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>      <data key=\"d3\">CATEGORY<\/data>    <\/node>    <node id=\"C1\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>      <data key=\"d3\">CATEGORY<\/data>    <\/node>    <node id=\"C2\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>      <data key=\"d3\">CATEGORY<\/data>    <\/node>    <node id=\"C3\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>      <data key=\"d3\">CATEGORY<\/data>    <\/node>    <node id=\"TS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category or cluster used in the analysis, representing a specific subset of the data<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>      <data key=\"d3\">CATEGORY<\/data>    <\/node>    <node id=\"UNITS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The number of context units, such as community summaries or text chunks, used in the analysis<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <node id=\"TOKENS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The number of tokens, or individual words, used in the analysis<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <node id=\"% MAX\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The percentage of the maximum token count used in the analysis<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <node id=\"MAP-REDUCE SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A summarization approach that is the most resource-intensive, requiring the highest number of context tokens<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"ROOT-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Summaries at the root level of the community hierarchy, requiring dramatically fewer tokens per query<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method used to compare community summaries to source texts, generally providing a small but consistent improvement in answer comprehensiveness and diversity<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"FINAL EVALUATION\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"PODCAST TRANSCRIPTS\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of transcripts from podcasts used for analysis<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <node id=\"NEWS ARTICLES\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of news articles used for analysis<\/data>      <data key=\"d2\">36db32c37e1987e2c5863898ad882190<\/data>    <\/node>    <edge source=\"WIN RATE\" target=\"EMPOWERMENT\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Empowerment has an average win rate of 51.3%<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"FINAL EVALUATION\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">A fixed context window size of 8k tokens was used for the final evaluation<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"INDEXING PROCESS\" target=\"GRAPH\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The indexing process resulted in the creation of graphs<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"GRAPH\" target=\"PODCAST DATASET\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">A graph was created for the Podcast dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"GRAPH\" target=\"NEWS DATASET\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">A graph was created for the News dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"GRAPH\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Community summaries are part of the graph community hierarchy<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"NODES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The Podcast dataset graph consists of 8564 nodes<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"EDGES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The Podcast dataset graph consists of 20691 edges<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"C0\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C0 is a category used in the analysis of the Podcast dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"C1\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C1 is a category used in the analysis of the Podcast dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"C2\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C2 is a category used in the analysis of the Podcast dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"C3\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C3 is a category used in the analysis of the Podcast dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"TS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">TS is a category used in the analysis of the Podcast dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"UNITS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Units are used to measure the context in the Podcast dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"TOKENS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Tokens are used to measure the word count in the Podcast dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"% MAX\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">% Max is used to measure the percentage of maximum token count in the Podcast dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"NODES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The News dataset graph consists of 15754 nodes<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"EDGES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The News dataset graph consists of 19520 edges<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"C0\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C0 is a category used in the analysis of the News dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"C1\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C1 is a category used in the analysis of the News dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"C2\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C2 is a category used in the analysis of the News dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"C3\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C3 is a category used in the analysis of the News dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"TS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">TS is a category used in the analysis of the News dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"UNITS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Units are used to measure the context in the News dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"TOKENS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Tokens are used to measure the word count in the News dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"% MAX\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">% Max is used to measure the percentage of maximum token count in the News dataset<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"GRAPH RAG\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Graph RAG is used to compare community summaries to source texts<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"GLOBAL APPROACHES\" target=\"NAIVE RAG\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Global approaches consistently outperformed the naive RAG<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"GLOBAL APPROACHES\" target=\"COMPREHENSIVENESS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Global approaches achieved higher comprehensiveness win rates<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"GLOBAL APPROACHES\" target=\"DIVERSITY\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Global approaches achieved higher diversity win rates<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"NAIVE RAG\" target=\"DIRECTNESS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Naive RAG produces the most direct responses<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"C0\" target=\"PODCAST TRANSCRIPTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C0 is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"C0\" target=\"NEWS ARTICLES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C0 is a category used in the analysis of news articles<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"C1\" target=\"PODCAST TRANSCRIPTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C1 is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"C1\" target=\"NEWS ARTICLES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C1 is a category used in the analysis of news articles<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"C2\" target=\"PODCAST TRANSCRIPTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C2 is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"C2\" target=\"NEWS ARTICLES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C2 is a category used in the analysis of news articles<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"C3\" target=\"PODCAST TRANSCRIPTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C3 is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"C3\" target=\"NEWS ARTICLES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">C3 is a category used in the analysis of news articles<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"TS\" target=\"PODCAST TRANSCRIPTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">TS is a category used in the analysis of podcast transcripts<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"TS\" target=\"NEWS ARTICLES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">TS is a category used in the analysis of news articles<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"UNITS\" target=\"PODCAST TRANSCRIPTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Units are used to measure the context in podcast transcripts<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"UNITS\" target=\"NEWS ARTICLES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Units are used to measure the context in news articles<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"TOKENS\" target=\"MAP-REDUCE SUMMARIZATION\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Map-reduce summarization requires the highest number of context tokens<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"TOKENS\" target=\"ROOT-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Root-level community summaries require dramatically fewer tokens per query<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"TOKENS\" target=\"PODCAST TRANSCRIPTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Tokens are used to measure the word count in podcast transcripts<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"TOKENS\" target=\"NEWS ARTICLES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Tokens are used to measure the word count in news articles<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"% MAX\" target=\"PODCAST TRANSCRIPTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">% Max is used to measure the percentage of maximum token count in podcast transcripts<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"% MAX\" target=\"NEWS ARTICLES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">% Max is used to measure the percentage of maximum token count in news articles<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"NEWS ARTICLES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Both are datasets used in the analysis<\/data>      <data key=\"d6\">36db32c37e1987e2c5863898ad882190<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"6f33a085ff3304e5994f7fbb86c881a4","chunk":" C0) require dramatically fewer tokens per query (9x-43x).\nCommunity summaries vs. source texts. When comparing community summaries to source texts\nusing Graph RAG, community summaries generally provided a small but consistent improvement\nin answer comprehensiveness and diversity, except for root-level summaries. Intermediate-level\nsummaries in the Podcast dataset and low-level community summaries in the News dataset achieved\ncomprehensiveness win rates of 57% and 64%, respectively. Diversity win rates were 57% for\nPodcast intermediate-level summaries and 60% for News low-level community summaries. Table 3\nalso illustrates the scalability advantages of Graph RAG compared to source text summarization: for\nlow-level community summaries ( C3), Graph RAG required 26-33% fewer context tokens, while\nfor root-level community summaries ( C0), it required over 97% fewer tokens. For a modest drop in\nperformance compared with other global methods, root-level Graph RAG offers a highly efficient\nmethod for the iterative question answering that characterizes sensemaking activity, while retaining\nadvantages in comprehensiveness (72% win rate) and diversity (62% win rate) over na \u00a8\u0131ve RAG.\nEmpowerment . Empowerment comparisons showed mixed results for both global approaches versus\nna\u00a8\u0131ve RAG ( SS) and Graph RAG approaches versus source text summarization ( TS). Ad-hoc LLM\nuse to analyze LLM reasoning for this measure indicated that the ability to provide specific exam-\nples, quotes, and citations was judged to be key to helping users reach an informed understanding.\nTuning element extraction prompts may help to retain more of these details in the Graph RAG index.\n4 Related Work\n4.1 RAG Approaches and Systems\nWhen using LLMs, RAG involves first retrieving relevant information from external data sources,\nthen adding this information to the context window of the LLM along with the original query (Ram\net al., 2023). Na \u00a8\u0131ve RAG approaches (Gao et al., 2023) do this by converting documents to text,\nsplitting text into chunks, and embedding these chunks into a vector space in which similar positions\nrepresent similar semantics. Queries are then embedded into the same vector space, with the text\nchunks of the nearest kvectors used as context. More advanced variations exist, but all solve the\nproblem of what to do when an external dataset of interest exceeds the LLM","chunk_id":"6f33a085ff3304e5994f7fbb86c881a4","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"GRAPH RAG","type":"METHOD","description":"Graph RAG is a method that uses community summaries to improve answer comprehensiveness and diversity while requiring fewer tokens compared to source text summarization","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"COMMUNITY SUMMARIES","type":"DATASET","description":"Community summaries are summaries derived from community-generated content, used in the analysis to compare with source texts","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"SOURCE TEXTS","type":"DATASET","description":"Source texts are the original texts used for comparison with community summaries in the analysis","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"PODCAST DATASET","type":"DATASET","description":"A dataset consisting of podcast transcripts used for analysis","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"NEWS DATASET","type":"DATASET","description":"A dataset consisting of news articles used for analysis","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"C0","type":"CATEGORY","description":"A category representing root-level community summaries in the analysis","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"C3","type":"CATEGORY","description":"A category representing low-level community summaries in the analysis","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"NAIVE RAG","type":"METHOD","description":"Naive RAG is a basic retrieval-augmented generation method that converts documents to text, splits them into chunks, and embeds these chunks into a vector space for query matching","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"SS","type":"CATEGORY","description":"A category representing na\u00a8\u0131ve RAG in the analysis","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"TS","type":"CATEGORY","description":"A category representing source text summarization in the analysis","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"LLM","type":"TECHNOLOGY","description":"Large Language Models (LLMs) are used to analyze and generate text based on retrieved information and queries","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"EMPOWERMENT","type":"METRIC","description":"Empowerment is a measure used to evaluate the ability of different methods to help users reach an informed understanding","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"RAM ET AL., 2023","type":"REFERENCE","description":"A reference to a paper by Ram et al. in 2023 discussing RAG approaches","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"GAO ET AL., 2023","type":"REFERENCE","description":"A reference to a paper by Gao et al. in 2023 discussing naive RAG approaches","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"RAG","type":"","description":"","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"INTERMEDIATE-LEVEL SUMMARIES","type":"CATEGORY","description":"Intermediate-level summaries are a type of community summary used in the Podcast dataset for analysis","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"LOW-LEVEL COMMUNITY SUMMARIES","type":"CATEGORY","description":"Low-level community summaries are a type of community summary used in the News dataset for analysis","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"ROOT-LEVEL SUMMARIES","type":"CATEGORY","description":"Root-level summaries are a type of community summary used in the analysis","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"ANSWER COMPREHENSIVENESS","type":"METRIC","description":"Answer comprehensiveness is a measure used to evaluate the completeness of answers provided by different methods","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"DIVERSITY","type":"METRIC","description":"Diversity is a measure used to evaluate the variety of answers provided by different methods","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"WIN RATE","type":"METRIC","description":"Win rate is a measure used to evaluate the success rate of different methods in providing comprehensive and diverse answers","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"AD-HOC LLM USE","type":"TECHNOLOGY","description":"Ad-hoc LLM use refers to the spontaneous use of large language models to analyze reasoning and provide specific examples, quotes, and citations","source_id":"6f33a085ff3304e5994f7fbb86c881a4"},{"name":"ELEMENT EXTRACTION PROMPTS","type":"TECHNOLOGY","description":"Element extraction prompts are used to extract specific details in the Graph RAG index","source_id":"6f33a085ff3304e5994f7fbb86c881a4"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG is a method that uses community summaries to improve answer comprehensiveness and diversity while requiring fewer tokens compared to source text summarization<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Community summaries are summaries derived from community-generated content, used in the analysis to compare with source texts<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"SOURCE TEXTS\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Source texts are the original texts used for comparison with community summaries in the analysis<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"PODCAST DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of podcast transcripts used for analysis<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"NEWS DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of news articles used for analysis<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"C0\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category representing root-level community summaries in the analysis<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"C3\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category representing low-level community summaries in the analysis<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"NAIVE RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Naive RAG is a basic retrieval-augmented generation method that converts documents to text, splits them into chunks, and embeds these chunks into a vector space for query matching<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"SS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category representing na&#168;&#305;ve RAG in the analysis<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"TS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A category representing source text summarization in the analysis<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Large Language Models (LLMs) are used to analyze and generate text based on retrieved information and queries<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"EMPOWERMENT\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Empowerment is a measure used to evaluate the ability of different methods to help users reach an informed understanding<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"RAM ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a paper by Ram et al. in 2023 discussing RAG approaches<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"GAO ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a paper by Gao et al. in 2023 discussing naive RAG approaches<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"INTERMEDIATE-LEVEL SUMMARIES\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Intermediate-level summaries are a type of community summary used in the Podcast dataset for analysis<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"LOW-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Low-level community summaries are a type of community summary used in the News dataset for analysis<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"ROOT-LEVEL SUMMARIES\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Root-level summaries are a type of community summary used in the analysis<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"ANSWER COMPREHENSIVENESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Answer comprehensiveness is a measure used to evaluate the completeness of answers provided by different methods<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Diversity is a measure used to evaluate the variety of answers provided by different methods<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"WIN RATE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Win rate is a measure used to evaluate the success rate of different methods in providing comprehensive and diverse answers<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"AD-HOC LLM USE\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Ad-hoc LLM use refers to the spontaneous use of large language models to analyze reasoning and provide specific examples, quotes, and citations<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <node id=\"ELEMENT EXTRACTION PROMPTS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Element extraction prompts are used to extract specific details in the Graph RAG index<\/data>      <data key=\"d2\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/node>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses community summaries to improve answer comprehensiveness and diversity<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SOURCE TEXTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is compared with source texts for answer comprehensiveness and diversity<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"C0\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C0 represents root-level community summaries in the Graph RAG analysis<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"C3\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">C3 represents low-level community summaries in the Graph RAG analysis<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">TS represents source text summarization in the Graph RAG analysis<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"LLM\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LLMs are used in Graph RAG to analyze and generate text based on retrieved information and queries<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"EMPOWERMENT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Empowerment is used to evaluate Graph RAG's ability to help users reach an informed understanding<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ROOT-LEVEL SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Root-level summaries are used in the Graph RAG analysis<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ANSWER COMPREHENSIVENESS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Answer comprehensiveness is used to evaluate the performance of Graph RAG<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DIVERSITY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Diversity is used to evaluate the performance of Graph RAG<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"WIN RATE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Win rate is used to measure the success rate of Graph RAG in providing comprehensive and diverse answers<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ELEMENT EXTRACTION PROMPTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Element extraction prompts are used in Graph RAG to retain specific details in the index<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"PODCAST DATASET\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community summaries are derived from the Podcast dataset for analysis<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"NEWS DATASET\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Community summaries are derived from the News dataset for analysis<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"INTERMEDIATE-LEVEL SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Intermediate-level summaries are derived from the Podcast dataset for analysis<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"LOW-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Low-level community summaries are derived from the News dataset for analysis<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"NAIVE RAG\" target=\"SS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">SS represents naive RAG in the analysis<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"NAIVE RAG\" target=\"GAO ET AL., 2023\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Gao et al., 2023 discusses naive RAG approaches<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"LLM\" target=\"AD-HOC LLM USE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ad-hoc LLM use involves the use of large language models to analyze reasoning and provide specific examples, quotes, and citations<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>    <edge source=\"RAM ET AL., 2023\" target=\"RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ram et al., 2023 discusses RAG approaches<\/data>      <data key=\"d5\">6f33a085ff3304e5994f7fbb86c881a4<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"f35de4d9fb65f1d5a392064b20545c19","chunk":" these chunks into a vector space in which similar positions\nrepresent similar semantics. Queries are then embedded into the same vector space, with the text\nchunks of the nearest kvectors used as context. More advanced variations exist, but all solve the\nproblem of what to do when an external dataset of interest exceeds the LLM\u2019s context window.\nAdvanced RAG systems include pre-retrieval, retrieval, post-retrieval strategies designed to over-\ncome the drawbacks of Na \u00a8\u0131ve RAG, while Modular RAG systems include patterns for iterative and\ndynamic cycles of interleaved retrieval and generation (Gao et al., 2023). Our implementation of\nGraph RAG incorporates multiple concepts related to other systems. For example, our community\nsummaries are a kind of self-memory (Selfmem, Cheng et al., 2024) for generation-augmented re-\ntrieval (GAR, Mao et al., 2020) that facilitates future generation cycles, while our parallel generation\nof community answers from these summaries is a kind of iterative (Iter-RetGen, Shao et al., 2023)\nor federated (FeB4RAG, Wang et al., 2024) retrieval-generation strategy. Other systems have also\ncombined these concepts for multi-document summarization (CAiRE-COVID, Su et al., 2020) and\nmulti-hop question answering (ITRG, Feng et al., 2023; IR-CoT, Trivedi et al., 2022; DSP, Khattab\net al., 2022). Our use of a hierarchical index and summarization also bears resemblance to further\napproaches, such as generating a hierarchical index of text chunks by clustering the vectors of text\nembeddings (RAPTOR, Sarthi et al., 2024) or generating a \u201ctree of clarifications\u201d to answer mul-\ntiple interpretations of ambiguous questions (Kim et al., 2023). However, none of these iterative or\nhierarchical approaches use the kind of self-generated graph index that enables Graph RAG.\n104.2 Graphs and LLMs\nUse of graphs in connection with LLMs and RAG is a developing research area, with multiple\ndirections already established. These include using LLMs for knowledge graph creation (Tra-\njanoska et al., 2023) and completion (Yao et al., 2023), as well as for the extraction of causal\ngraphs (Ban et","chunk_id":"f35de4d9fb65f1d5a392064b20545c19","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"VECTOR SPACE","type":"CONCEPT, TECHNOLOGY","description":"A mathematical space in which text chunks and queries are embedded to represent similar semantics","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"QUERIES","type":"CONCEPT, DATA","description":"Search inputs that are embedded into the same vector space as text chunks to find relevant context","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"LLM","type":"TECHNOLOGY, CONCEPT","description":"Large Language Model, a type of AI model with a context window that can be exceeded by external datasets","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"RAG","type":"TECHNOLOGY, METHOD","description":"Retrieval-Augmented Generation, a method that incorporates retrieval of relevant data to augment text generation","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"NA\u00cfVE RAG","type":"TECHNOLOGY, METHOD","description":"A basic form of RAG that has certain drawbacks which advanced RAG systems aim to overcome","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"MODULAR RAG","type":"TECHNOLOGY, METHOD","description":"A type of RAG system that includes patterns for iterative and dynamic cycles of interleaved retrieval and generation","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"GRAPH RAG","type":"TECHNOLOGY, METHOD","description":"An implementation of RAG that incorporates multiple concepts from other systems, including self-memory and parallel generation of community answers","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"SELF-MEMORY (SELFMEM)","type":"TECHNOLOGY, CONCEPT","description":"A concept related to generation-augmented retrieval that facilitates future generation cycles","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"GENERATION-AUGMENTED RETRIEVAL (GAR)","type":"TECHNOLOGY, METHOD","description":"A method that facilitates future generation cycles by using self-memory","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)","type":"TECHNOLOGY, METHOD","description":"A strategy for iterative retrieval and generation","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"FEDERATED RETRIEVAL-GENERATION (FEB4RAG)","type":"TECHNOLOGY, METHOD","description":"A federated strategy for retrieval and generation","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"MULTI-DOCUMENT SUMMARIZATION","type":"TECHNOLOGY, METHOD","description":"A method that combines multiple concepts for summarizing multiple documents","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"MULTI-HOP QUESTION ANSWERING","type":"TECHNOLOGY, METHOD","description":"A method for answering questions that require multiple steps or \"hops\" to gather information","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"HIERARCHICAL INDEX","type":"TECHNOLOGY, METHOD","description":"An approach that involves generating a hierarchical index of text chunks by clustering the vectors of text embeddings","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"RAPTOR","type":"TECHNOLOGY, METHOD","description":"A method for generating a hierarchical index of text chunks by clustering the vectors of text embeddings","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"TREE OF CLARIFICATIONS","type":"TECHNOLOGY, METHOD","description":"A method for answering multiple interpretations of ambiguous questions by generating a hierarchical structure","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"GRAPH INDEX","type":"TECHNOLOGY, METHOD","description":"A self-generated index that enables Graph RAG","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"KNOWLEDGE GRAPH CREATION","type":"TECHNOLOGY, METHOD","description":"A process that involves using LLMs to create knowledge graphs","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"KNOWLEDGE GRAPH COMPLETION","type":"TECHNOLOGY, METHOD","description":"A process that involves using LLMs to complete existing knowledge graphs","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"CAUSAL GRAPHS","type":"TECHNOLOGY, METHOD","description":"Graphs that represent causal relationships, which can be extracted using LLMs","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"GAO ET AL., 2023","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Gao et al. in 2023","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"CHENG ET AL., 2024","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Cheng et al. in 2024","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"MAO ET AL., 2020","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Mao et al. in 2020","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"SHAO ET AL., 2023","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Shao et al. in 2023","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"WANG ET AL., 2024","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Wang et al. in 2024","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"SU ET AL., 2020","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Su et al. in 2020","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"FENG ET AL., 2023","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Feng et al. in 2023","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"TRIVEDI ET AL., 2022","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Trivedi et al. in 2022","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"KHATTAB ET AL., 2022","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Khattab et al. in 2022","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"SARTHI ET AL., 2024","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Sarthi et al. in 2024","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"KIM ET AL., 2023","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Kim et al. in 2023","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"TRAJANOSKA ET AL., 2023","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Trajanoska et al. in 2023","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"YAO ET AL., 2023","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Yao et al. in 2023","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"BAN ET AL.","type":"REFERENCE, PUBLICATION","description":"A reference to a publication by Ban et al.","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"REFERENCE, PUBLICATION"},{"name":"COMMUNITY SUMMARIES","type":"TECHNOLOGY, METHOD","description":"Summaries that act as a kind of self-memory for generation-augmented retrieval","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"COMMUNITY ANSWERS","type":"TECHNOLOGY, METHOD","description":"Answers generated in parallel from community summaries","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"MULTI-DOCUMENT SUMMARIZATION (CAIRE-COVID)","type":"TECHNOLOGY, METHOD","description":"A system that combines multiple concepts for multi-document summarization","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"MULTI-HOP QUESTION ANSWERING (ITRG)","type":"TECHNOLOGY, METHOD","description":"A system for multi-hop question answering","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"MULTI-HOP QUESTION ANSWERING (IR-COT)","type":"TECHNOLOGY, METHOD","description":"A system for multi-hop question answering","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"MULTI-HOP QUESTION ANSWERING (DSP)","type":"TECHNOLOGY, METHOD","description":"A system for multi-hop question answering","source_id":"f35de4d9fb65f1d5a392064b20545c19","entity_type":"TECHNOLOGY, METHOD"},{"name":"TEXT CHUNKS","type":"DATA, CONCEPT","description":"Segments of text that are embedded into a vector space for analysis","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"PRE-RETRIEVAL STRATEGIES","type":"TECHNOLOGY, METHOD","description":"Strategies used before the retrieval process in advanced RAG systems","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"RETRIEVAL STRATEGIES","type":"TECHNOLOGY, METHOD","description":"Strategies used during the retrieval process in advanced RAG systems","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"POST-RETRIEVAL STRATEGIES","type":"TECHNOLOGY, METHOD","description":"Strategies used after the retrieval process in advanced RAG systems","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"INTERLEAVED RETRIEVAL AND GENERATION","type":"TECHNOLOGY, METHOD","description":"A pattern in Modular RAG systems for iterative and dynamic cycles of retrieval and generation","source_id":"f35de4d9fb65f1d5a392064b20545c19"},{"name":"GENERATION CYCLES","type":"TECHNOLOGY, METHOD","description":"Cycles of generation that are facilitated by self-memory in Graph RAG","source_id":"f35de4d9fb65f1d5a392064b20545c19"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"VECTOR SPACE\">      <data key=\"d0\">CONCEPT, TECHNOLOGY<\/data>      <data key=\"d1\">A mathematical space in which text chunks and queries are embedded to represent similar semantics<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"QUERIES\">      <data key=\"d0\">CONCEPT, DATA<\/data>      <data key=\"d1\">Search inputs that are embedded into the same vector space as text chunks to find relevant context<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY, CONCEPT<\/data>      <data key=\"d1\">Large Language Model, a type of AI model with a context window that can be exceeded by external datasets<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">Retrieval-Augmented Generation, a method that incorporates retrieval of relevant data to augment text generation<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"NA&#207;VE RAG\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A basic form of RAG that has certain drawbacks which advanced RAG systems aim to overcome<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"MODULAR RAG\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A type of RAG system that includes patterns for iterative and dynamic cycles of interleaved retrieval and generation<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">An implementation of RAG that incorporates multiple concepts from other systems, including self-memory and parallel generation of community answers<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"SELF-MEMORY (SELFMEM)\">      <data key=\"d0\">TECHNOLOGY, CONCEPT<\/data>      <data key=\"d1\">A concept related to generation-augmented retrieval that facilitates future generation cycles<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"GENERATION-AUGMENTED RETRIEVAL (GAR)\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A method that facilitates future generation cycles by using self-memory<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A strategy for iterative retrieval and generation<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"FEDERATED RETRIEVAL-GENERATION (FEB4RAG)\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A federated strategy for retrieval and generation<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"MULTI-DOCUMENT SUMMARIZATION\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A method that combines multiple concepts for summarizing multiple documents<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"MULTI-HOP QUESTION ANSWERING\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A method for answering questions that require multiple steps or \"hops\" to gather information<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"HIERARCHICAL INDEX\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">An approach that involves generating a hierarchical index of text chunks by clustering the vectors of text embeddings<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"RAPTOR\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A method for generating a hierarchical index of text chunks by clustering the vectors of text embeddings<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"TREE OF CLARIFICATIONS\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A method for answering multiple interpretations of ambiguous questions by generating a hierarchical structure<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"GRAPH INDEX\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A self-generated index that enables Graph RAG<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"KNOWLEDGE GRAPH CREATION\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A process that involves using LLMs to create knowledge graphs<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"KNOWLEDGE GRAPH COMPLETION\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A process that involves using LLMs to complete existing knowledge graphs<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"CAUSAL GRAPHS\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">Graphs that represent causal relationships, which can be extracted using LLMs<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"GAO ET AL., 2023\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Gao et al. in 2023<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"CHENG ET AL., 2024\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Cheng et al. in 2024<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"MAO ET AL., 2020\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Mao et al. in 2020<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"SHAO ET AL., 2023\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Shao et al. in 2023<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"WANG ET AL., 2024\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Wang et al. in 2024<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"SU ET AL., 2020\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Su et al. in 2020<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"FENG ET AL., 2023\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Feng et al. in 2023<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"TRIVEDI ET AL., 2022\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Trivedi et al. in 2022<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"KHATTAB ET AL., 2022\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Khattab et al. in 2022<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"SARTHI ET AL., 2024\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Sarthi et al. in 2024<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"KIM ET AL., 2023\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Kim et al. in 2023<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"TRAJANOSKA ET AL., 2023\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Trajanoska et al. in 2023<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"YAO ET AL., 2023\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Yao et al. in 2023<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"BAN ET AL.\">      <data key=\"d0\">REFERENCE, PUBLICATION<\/data>      <data key=\"d1\">A reference to a publication by Ban et al.<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">REFERENCE, PUBLICATION<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">Summaries that act as a kind of self-memory for generation-augmented retrieval<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"COMMUNITY ANSWERS\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">Answers generated in parallel from community summaries<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"MULTI-DOCUMENT SUMMARIZATION (CAIRE-COVID)\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A system that combines multiple concepts for multi-document summarization<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"MULTI-HOP QUESTION ANSWERING (ITRG)\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A system for multi-hop question answering<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"MULTI-HOP QUESTION ANSWERING (IR-COT)\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A system for multi-hop question answering<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"MULTI-HOP QUESTION ANSWERING (DSP)\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A system for multi-hop question answering<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>      <data key=\"d3\">TECHNOLOGY, METHOD<\/data>    <\/node>    <node id=\"TEXT CHUNKS\">      <data key=\"d0\">DATA, CONCEPT<\/data>      <data key=\"d1\">Segments of text that are embedded into a vector space for analysis<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"PRE-RETRIEVAL STRATEGIES\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">Strategies used before the retrieval process in advanced RAG systems<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"RETRIEVAL STRATEGIES\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">Strategies used during the retrieval process in advanced RAG systems<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"POST-RETRIEVAL STRATEGIES\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">Strategies used after the retrieval process in advanced RAG systems<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"INTERLEAVED RETRIEVAL AND GENERATION\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">A pattern in Modular RAG systems for iterative and dynamic cycles of retrieval and generation<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <node id=\"GENERATION CYCLES\">      <data key=\"d0\">TECHNOLOGY, METHOD<\/data>      <data key=\"d1\">Cycles of generation that are facilitated by self-memory in Graph RAG<\/data>      <data key=\"d2\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/node>    <edge source=\"VECTOR SPACE\" target=\"QUERIES\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Queries are embedded into the same vector space as text chunks to find relevant context<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"LLM\" target=\"RAG\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">RAG is used to augment the capabilities of LLMs<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"LLM\" target=\"KNOWLEDGE GRAPH CREATION\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LLMs are used for knowledge graph creation<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"LLM\" target=\"KNOWLEDGE GRAPH COMPLETION\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LLMs are used for knowledge graph completion<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"LLM\" target=\"CAUSAL GRAPHS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LLMs are used for the extraction of causal graphs<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"LLM\" target=\"TRAJANOSKA ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LLMs are used for knowledge graph creation as per Trajanoska et al., 2023<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"LLM\" target=\"YAO ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LLMs are used for knowledge graph completion as per Yao et al., 2023<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"LLM\" target=\"BAN ET AL.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LLMs are used for the extraction of causal graphs as per Ban et al.<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"RAG\" target=\"NA&#207;VE RAG\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Na&#239;ve RAG is a basic form of RAG<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"RAG\" target=\"MODULAR RAG\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Modular RAG is an advanced form of RAG<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"RAG\" target=\"GRAPH RAG\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG is an implementation of RAG<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SELF-MEMORY (SELFMEM)\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates the concept of self-memory<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates the concept of iterative retrieval-generation<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"FEDERATED RETRIEVAL-GENERATION (FEB4RAG)\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates the concept of federated retrieval-generation<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MULTI-DOCUMENT SUMMARIZATION\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts used in multi-document summarization<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MULTI-HOP QUESTION ANSWERING\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts used in multi-hop question answering<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"HIERARCHICAL INDEX\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG uses a hierarchical index<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TREE OF CLARIFICATIONS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates the concept of a tree of clarifications<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GRAPH INDEX\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG uses a self-generated graph index<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GAO ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Gao et al., 2023<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"CHENG ET AL., 2024\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Cheng et al., 2024<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MAO ET AL., 2020\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Mao et al., 2020<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SHAO ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Shao et al., 2023<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"WANG ET AL., 2024\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Wang et al., 2024<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SU ET AL., 2020\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Su et al., 2020<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"FENG ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Feng et al., 2023<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TRIVEDI ET AL., 2022\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Trivedi et al., 2022<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"KHATTAB ET AL., 2022\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Khattab et al., 2022<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SARTHI ET AL., 2024\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Sarthi et al., 2024<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"KIM ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from Kim et al., 2023<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG uses community summaries as a kind of self-memory<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY ANSWERS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG generates community answers in parallel<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"SELF-MEMORY (SELFMEM)\" target=\"GENERATION-AUGMENTED RETRIEVAL (GAR)\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Self-memory is related to generation-augmented retrieval<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"MULTI-DOCUMENT SUMMARIZATION\" target=\"MULTI-DOCUMENT SUMMARIZATION (CAIRE-COVID)\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">CAiRE-COVID is a system for multi-document summarization<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"MULTI-HOP QUESTION ANSWERING\" target=\"MULTI-HOP QUESTION ANSWERING (ITRG)\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">ITRG is a system for multi-hop question answering<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"MULTI-HOP QUESTION ANSWERING\" target=\"MULTI-HOP QUESTION ANSWERING (IR-COT)\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">IR-CoT is a system for multi-hop question answering<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"MULTI-HOP QUESTION ANSWERING\" target=\"MULTI-HOP QUESTION ANSWERING (DSP)\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">DSP is a system for multi-hop question answering<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>    <edge source=\"HIERARCHICAL INDEX\" target=\"RAPTOR\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">RAPTOR is a method for generating a hierarchical index<\/data>      <data key=\"d6\">f35de4d9fb65f1d5a392064b20545c19<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"92e93fc6449756c0a60200636b297f65","chunk":" RAG is a developing research area, with multiple\ndirections already established. These include using LLMs for knowledge graph creation (Tra-\njanoska et al., 2023) and completion (Yao et al., 2023), as well as for the extraction of causal\ngraphs (Ban et al., 2023; Zhang et al., 2024) from source texts. They also include forms of ad-\nvanced RAG (Gao et al., 2023) where the index is a knowledge graph (KAPING, Baek et al., 2023),\nwhere subsets of the graph structure (G-Retriever, He et al., 2024) or derived graph metrics (Graph-\nToolFormer, Zhang, 2023) are the objects of enquiry, where narrative outputs are strongly grounded\nin the facts of retrieved subgraphs (SURGE, Kang et al., 2023), where retrieved event-plot sub-\ngraphs are serialized using narrative templates (FABULA, Ranade and Joshi, 2023), and where the\nsystem supports both creation and traversal of text-relationship graphs for multi-hop question an-\nswering (Wang et al., 2023b). In terms of open-source software, a variety a graph databases are\nsupported by both the LangChain (LangChain, 2024) and LlamaIndex (LlamaIndex, 2024) libraries,\nwhile a more general class of graph-based RAG applications is also emerging, including systems that\ncan create and reason over knowledge graphs in both Neo4J (NaLLM, Neo4J, 2024) and Nebula-\nGraph (GraphRAG, NebulaGraph, 2024) formats. Unlike our Graph RAG approach, however, none\nof these systems use the natural modularity of graphs to partition data for global summarization.\n5 Discussion\nLimitations of evaluation approach . Our evaluation to date has only examined a certain class of\nsensemaking questions for two corpora in the region of 1 million tokens. More work is needed\nto understand how performance varies across different ranges of question types, data types, and\ndataset sizes, as well as to validate our sensemaking questions and target metrics with end users.\nComparison of fabrication rates, e.g., using approaches like SelfCheckGPT (Manakul et al., 2023),\nwould also improve on the current analysis.\nTrade-offs of building a graph index . We consistently observed","chunk_id":"92e93fc6449756c0a60200636b297f65","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"RAG","type":"METHOD","description":"RAG (Retrieval-Augmented Generation) is a developing research area with multiple established directions, including knowledge graph creation, completion, and extraction of causal graphs","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METHOD"},{"name":"LLMS","type":"TECHNOLOGY","description":"Large Language Models (LLMs) are used for various tasks such as knowledge graph creation and completion","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"TECHNOLOGY"},{"name":"TRAJANOSKA ET AL., 2023","type":"PUBLICATION","description":"A paper by Trajanoska et al. published in 2023, focusing on using LLMs for knowledge graph creation","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"YAO ET AL., 2023","type":"PUBLICATION","description":"A paper by Yao et al. published in 2023, focusing on using LLMs for knowledge graph completion","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"BAN ET AL., 2023","type":"PUBLICATION","description":"A paper by Ban et al. published in 2023, focusing on the extraction of causal graphs from source texts","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"ZHANG ET AL., 2024","type":"PUBLICATION","description":"A paper by Zhang et al. published in 2024, focusing on the extraction of causal graphs from source texts","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"GAO ET AL., 2023","type":"PUBLICATION","description":"A paper by Gao et al. published in 2023, focusing on advanced RAG where the index is a knowledge graph","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"KAPING","type":"METHOD","description":"A method where the index is a knowledge graph, developed by Baek et al. in 2023","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METHOD"},{"name":"BAEK ET AL., 2023","type":"PUBLICATION","description":"A paper by Baek et al. published in 2023, focusing on the KAPING method","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"G-RETRIEVER","type":"METHOD","description":"A method where subsets of the graph structure are the objects of enquiry, developed by He et al. in 2024","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METHOD"},{"name":"HE ET AL., 2024","type":"PUBLICATION","description":"A paper by He et al. published in 2024, focusing on the G-Retriever method","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"GRAPH-TOOLFORMER","type":"METHOD","description":"A method where derived graph metrics are the objects of enquiry, developed by Zhang in 2023","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METHOD"},{"name":"ZHANG, 2023","type":"PUBLICATION","description":"A paper by Zhang published in 2023, focusing on the Graph-ToolFormer method","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"SURGE","type":"METHOD","description":"A method where narrative outputs are strongly grounded in the facts of retrieved subgraphs, developed by Kang et al. in 2023","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METHOD"},{"name":"KANG ET AL., 2023","type":"PUBLICATION","description":"A paper by Kang et al. published in 2023, focusing on the SURGE method","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"FABULA","type":"METHOD","description":"A method where retrieved event-plot subgraphs are serialized using narrative templates, developed by Ranade and Joshi in 2023","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METHOD"},{"name":"RANADE AND JOSHI, 2023","type":"PUBLICATION","description":"A paper by Ranade and Joshi published in 2023, focusing on the FABULA method","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"WANG ET AL., 2023B","type":"PUBLICATION","description":"A paper by Wang et al. published in 2023, focusing on a system that supports both creation and traversal of text-relationship graphs for multi-hop question answering","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"LANGCHAIN","type":"ORGANIZATION","description":"LangChain is an organization that supports a variety of graph databases","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"ORGANIZATION"},{"name":"LLAMAINDEX","type":"ORGANIZATION","description":"LlamaIndex is an organization that supports a variety of graph databases","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"ORGANIZATION"},{"name":"NEO4J","type":"TECHNOLOGY","description":"Neo4J is a graph database format supported by various RAG applications","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"TECHNOLOGY"},{"name":"NALLM","type":"METHOD","description":"A method that can create and reason over knowledge graphs in Neo4J format, developed by Neo4J in 2024","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METHOD"},{"name":"NEBULAGRAPH","type":"TECHNOLOGY","description":"NebulaGraph is a graph database format supported by various RAG applications","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"TECHNOLOGY"},{"name":"GRAPHRAG","type":"METHOD","description":"A method that can create and reason over knowledge graphs in NebulaGraph format, developed by NebulaGraph in 2024","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METHOD"},{"name":"SELFCHECKGPT","type":"METHOD","description":"A method for comparing fabrication rates, developed by Manakul et al. in 2023","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METHOD"},{"name":"MANAKUL ET AL., 2023","type":"PUBLICATION","description":"A paper by Manakul et al. published in 2023, focusing on the SelfCheckGPT method","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PUBLICATION"},{"name":"GRAPH RAG","type":"METHOD","description":"A method that uses the natural modularity of graphs to partition data for global summarization","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METHOD"},{"name":"SENSEMAKING QUESTIONS","type":"CONCEPT","description":"A class of questions used to evaluate the performance of RAG systems","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"CONCEPT"},{"name":"TOKENS","type":"METRIC","description":"The number of individual words used in the analysis, with the evaluation focusing on corpora in the region of 1 million tokens","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METRIC"},{"name":"END USERS","type":"STAKEHOLDER","description":"Individuals who validate sensemaking questions and target metrics","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"STAKEHOLDER"},{"name":"TRADE-OFFS","type":"CONCEPT","description":"Considerations and compromises involved in building a graph index","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"CONCEPT"},{"name":"GRAPH INDEX","type":"TECHNOLOGY","description":"A data structure used in RAG systems to organize and retrieve information","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"TECHNOLOGY"},{"name":"PERFORMANCE","type":"METRIC","description":"The effectiveness of RAG systems, which varies across different ranges of question types, data types, and dataset sizes","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METRIC"},{"name":"DATA TYPES","type":"CONCEPT","description":"Various forms of data used in RAG systems","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"CONCEPT"},{"name":"DATASET SIZES","type":"METRIC","description":"The scale of datasets used in RAG systems, which affects performance","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METRIC"},{"name":"EVALUATION","type":"PROCESS","description":"The process of assessing the performance of RAG systems","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"PROCESS"},{"name":"CORPORA","type":"DATASET","description":"Collections of texts used in the evaluation of RAG systems","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"DATASET"},{"name":"QUESTION TYPES","type":"CONCEPT","description":"Different categories of questions used to evaluate RAG systems","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"CONCEPT"},{"name":"TARGET METRICS","type":"METRIC","description":"Specific measures used to evaluate the performance of RAG systems","source_id":"92e93fc6449756c0a60200636b297f65","entity_type":"METRIC"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">RAG (Retrieval-Augmented Generation) is a developing research area with multiple established directions, including knowledge graph creation, completion, and extraction of causal graphs<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"LLMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Large Language Models (LLMs) are used for various tasks such as knowledge graph creation and completion<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"TRAJANOSKA ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Trajanoska et al. published in 2023, focusing on using LLMs for knowledge graph creation<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"YAO ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Yao et al. published in 2023, focusing on using LLMs for knowledge graph completion<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"BAN ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Ban et al. published in 2023, focusing on the extraction of causal graphs from source texts<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"ZHANG ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Zhang et al. published in 2024, focusing on the extraction of causal graphs from source texts<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"GAO ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Gao et al. published in 2023, focusing on advanced RAG where the index is a knowledge graph<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"KAPING\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method where the index is a knowledge graph, developed by Baek et al. in 2023<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"BAEK ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Baek et al. published in 2023, focusing on the KAPING method<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"G-RETRIEVER\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method where subsets of the graph structure are the objects of enquiry, developed by He et al. in 2024<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"HE ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by He et al. published in 2024, focusing on the G-Retriever method<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"GRAPH-TOOLFORMER\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method where derived graph metrics are the objects of enquiry, developed by Zhang in 2023<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"ZHANG, 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Zhang published in 2023, focusing on the Graph-ToolFormer method<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"SURGE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method where narrative outputs are strongly grounded in the facts of retrieved subgraphs, developed by Kang et al. in 2023<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"KANG ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Kang et al. published in 2023, focusing on the SURGE method<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"FABULA\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method where retrieved event-plot subgraphs are serialized using narrative templates, developed by Ranade and Joshi in 2023<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"RANADE AND JOSHI, 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Ranade and Joshi published in 2023, focusing on the FABULA method<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"WANG ET AL., 2023B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Wang et al. published in 2023, focusing on a system that supports both creation and traversal of text-relationship graphs for multi-hop question answering<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"LANGCHAIN\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">LangChain is an organization that supports a variety of graph databases<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"LLAMAINDEX\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">LlamaIndex is an organization that supports a variety of graph databases<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"NEO4J\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Neo4J is a graph database format supported by various RAG applications<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"NALLM\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method that can create and reason over knowledge graphs in Neo4J format, developed by Neo4J in 2024<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"NEBULAGRAPH\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">NebulaGraph is a graph database format supported by various RAG applications<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"GRAPHRAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method that can create and reason over knowledge graphs in NebulaGraph format, developed by NebulaGraph in 2024<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"SELFCHECKGPT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method for comparing fabrication rates, developed by Manakul et al. in 2023<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"MANAKUL ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Manakul et al. published in 2023, focusing on the SelfCheckGPT method<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method that uses the natural modularity of graphs to partition data for global summarization<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"SENSEMAKING QUESTIONS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A class of questions used to evaluate the performance of RAG systems<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"TOKENS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The number of individual words used in the analysis, with the evaluation focusing on corpora in the region of 1 million tokens<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <node id=\"END USERS\">      <data key=\"d0\">STAKEHOLDER<\/data>      <data key=\"d1\">Individuals who validate sensemaking questions and target metrics<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">STAKEHOLDER<\/data>    <\/node>    <node id=\"TRADE-OFFS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Considerations and compromises involved in building a graph index<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"GRAPH INDEX\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A data structure used in RAG systems to organize and retrieve information<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"PERFORMANCE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The effectiveness of RAG systems, which varies across different ranges of question types, data types, and dataset sizes<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <node id=\"DATA TYPES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Various forms of data used in RAG systems<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"DATASET SIZES\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The scale of datasets used in RAG systems, which affects performance<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <node id=\"EVALUATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of assessing the performance of RAG systems<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"CORPORA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Collections of texts used in the evaluation of RAG systems<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"QUESTION TYPES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Different categories of questions used to evaluate RAG systems<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"TARGET METRICS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Specific measures used to evaluate the performance of RAG systems<\/data>      <data key=\"d2\">92e93fc6449756c0a60200636b297f65<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <edge source=\"RAG\" target=\"LLMS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LLMs are used in various RAG tasks such as knowledge graph creation and completion<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"TRAJANOSKA ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Trajanoska et al. discusses using LLMs for knowledge graph creation, which is a direction in RAG<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"YAO ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Yao et al. discusses using LLMs for knowledge graph completion, which is a direction in RAG<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"BAN ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Ban et al. discusses the extraction of causal graphs, which is a direction in RAG<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"ZHANG ET AL., 2024\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Zhang et al. discusses the extraction of causal graphs, which is a direction in RAG<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"GAO ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Gao et al. discusses advanced RAG where the index is a knowledge graph<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"KAPING\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">KAPING is a method where the index is a knowledge graph, which is a direction in RAG<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"G-RETRIEVER\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">G-Retriever is a method where subsets of the graph structure are the objects of enquiry, which is a direction in RAG<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"GRAPH-TOOLFORMER\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph-ToolFormer is a method where derived graph metrics are the objects of enquiry, which is a direction in RAG<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"SURGE\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">SURGE is a method where narrative outputs are strongly grounded in the facts of retrieved subgraphs, which is a direction in RAG<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"FABULA\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">FABULA is a method where retrieved event-plot subgraphs are serialized using narrative templates, which is a direction in RAG<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"WANG ET AL., 2023B\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Wang et al. discusses a system that supports both creation and traversal of text-relationship graphs for multi-hop question answering, which is a direction in RAG<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"GRAPH RAG\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Graph RAG is a method that uses the natural modularity of graphs to partition data for global summarization<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"SENSEMAKING QUESTIONS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Sensemaking questions are used to evaluate the performance of RAG systems<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"TOKENS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The evaluation of RAG systems focuses on corpora in the region of 1 million tokens<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"TRADE-OFFS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Trade-offs are considerations involved in building a graph index for RAG systems<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"GRAPH INDEX\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">A graph index is a data structure used in RAG systems to organize and retrieve information<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"PERFORMANCE\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Performance of RAG systems varies across different ranges of question types, data types, and dataset sizes<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"DATA TYPES\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Different data types are used in RAG systems<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"DATASET SIZES\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Dataset sizes affect the performance of RAG systems<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"EVALUATION\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Evaluation is the process of assessing the performance of RAG systems<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"CORPORA\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Corpora are collections of texts used in the evaluation of RAG systems<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"QUESTION TYPES\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Different question types are used to evaluate RAG systems<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"RAG\" target=\"TARGET METRICS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Target metrics are specific measures used to evaluate the performance of RAG systems<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"KAPING\" target=\"BAEK ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Baek et al. discusses the KAPING method<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"G-RETRIEVER\" target=\"HE ET AL., 2024\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by He et al. discusses the G-Retriever method<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"GRAPH-TOOLFORMER\" target=\"ZHANG, 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Zhang discusses the Graph-ToolFormer method<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"SURGE\" target=\"KANG ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Kang et al. discusses the SURGE method<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"FABULA\" target=\"RANADE AND JOSHI, 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Ranade and Joshi discusses the FABULA method<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"LLAMAINDEX\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Both LangChain and LlamaIndex support a variety of graph databases<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"NEO4J\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LangChain supports graph databases in Neo4J format<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"NEBULAGRAPH\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LangChain supports graph databases in NebulaGraph format<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"LLAMAINDEX\" target=\"NEO4J\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LlamaIndex supports graph databases in Neo4J format<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"LLAMAINDEX\" target=\"NEBULAGRAPH\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">LlamaIndex supports graph databases in NebulaGraph format<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"NEO4J\" target=\"NALLM\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">NaLLM is a method that can create and reason over knowledge graphs in Neo4J format<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"NEBULAGRAPH\" target=\"GRAPHRAG\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">GraphRAG is a method that can create and reason over knowledge graphs in NebulaGraph format<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"SELFCHECKGPT\" target=\"MANAKUL ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The paper by Manakul et al. discusses the SelfCheckGPT method<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>    <edge source=\"SENSEMAKING QUESTIONS\" target=\"END USERS\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">End users validate sensemaking questions and target metrics<\/data>      <data key=\"d6\">92e93fc6449756c0a60200636b297f65<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"e4d9b12cf2b4c691c74019eefff4fb39","chunk":"dataset sizes, as well as to validate our sensemaking questions and target metrics with end users.\nComparison of fabrication rates, e.g., using approaches like SelfCheckGPT (Manakul et al., 2023),\nwould also improve on the current analysis.\nTrade-offs of building a graph index . We consistently observed Graph RAG achieve the best head-\nto-head results against other methods, but in many cases the graph-free approach to global summa-\nrization of source texts performed competitively. The real-world decision about whether to invest in\nbuilding a graph index depends on multiple factors, including the compute budget, expected number\nof lifetime queries per dataset, and value obtained from other aspects of the graph index (including\nthe generic community summaries and the use of other graph-related RAG approaches).\nFuture work . The graph index, rich text annotations, and hierarchical community structure support-\ning the current Graph RAG approach offer many possibilities for refinement and adaptation. This\nincludes RAG approaches that operate in a more local manner, via embedding-based matching of\nuser queries and graph annotations, as well as the possibility of hybrid RAG schemes that combine\nembedding-based matching against community reports before employing our map-reduce summa-\nrization mechanisms. This \u201croll-up\u201d operation could also be extended across more levels of the\ncommunity hierarchy, as well as implemented as a more exploratory \u201cdrill down\u201d mechanism that\nfollows the information scent contained in higher-level community summaries.\n6 Conclusion\nWe have presented a global approach to Graph RAG, combining knowledge graph generation,\nretrieval-augmented generation (RAG), and query-focused summarization (QFS) to support human\nsensemaking over entire text corpora. Initial evaluations show substantial improvements over a\nna\u00a8\u0131ve RAG baseline for both the comprehensiveness and diversity of answers, as well as favorable\ncomparisons to a global but graph-free approach using map-reduce source text summarization. For\nsituations requiring many global queries over the same dataset, summaries of root-level communi-\nties in the entity-based graph index provide a data index that is both superior to na \u00a8\u0131ve RAG and\nachieves competitive performance to other global methods at a fraction of the token cost.\nAn open-source, Python-based implementation of both global and local Graph RAG approaches is\nforthcoming at https:\/\/aka .ms\/graphrag .\n11Acknowledgements\nWe would also like to thank the following people who contributed to the work: Alonso","chunk_id":"e4d9b12cf2b4c691c74019eefff4fb39","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"SELFHECKGPT","type":"METHOD","description":"SelfCheckGPT is an approach used to compare fabrication rates in text generation tasks","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"MANAKUL ET AL., 2023","type":"REFERENCE","description":"A reference to the work by Manakul and colleagues published in 2023, related to SelfCheckGPT","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"GRAPH RAG","type":"METHOD","description":"Graph RAG is a method that combines knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) to support human sensemaking over text corpora","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"GRAPH-FREE APPROACH","type":"METHOD","description":"A method for global summarization of source texts that does not use a graph index","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"COMPUTE BUDGET","type":"RESOURCE","description":"The amount of computational resources allocated for a task","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"LIFETIME QUERIES","type":"METRIC","description":"The expected number of queries over the lifetime of a dataset","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"COMMUNITY SUMMARIES","type":"DATA","description":"Summaries of root-level communities in an entity-based graph index","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"MAP-REDUCE SUMMARIZATION","type":"METHOD","description":"A method for summarizing source texts using a map-reduce approach","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"RICH TEXT ANNOTATIONS","type":"DATA","description":"Annotations that provide detailed information about the text","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"HIERARCHICAL COMMUNITY STRUCTURE","type":"DATA","description":"A structure that organizes data into a hierarchy of communities","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"EMBEDDING-BASED MATCHING","type":"METHOD","description":"A method that uses embeddings to match user queries with graph annotations","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"HYBRID RAG SCHEMES","type":"METHOD","description":"RAG schemes that combine embedding-based matching with other approaches","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"MAP-REDUCE SUMMARIZATION MECHANISMS","type":"METHOD","description":"Mechanisms used in map-reduce summarization","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"COMMUNITY HIERARCHY","type":"DATA","description":"A hierarchical organization of communities","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"GLOBAL APPROACH TO GRAPH RAG","type":"METHOD","description":"A method that combines knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) for global text summarization","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"NA\u00cfVE RAG","type":"METHOD","description":"A baseline method for retrieval-augmented generation (RAG) that does not use advanced techniques","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"TOKEN COST","type":"METRIC","description":"The cost associated with the number of tokens used in a text generation task","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"PYTHON-BASED IMPLEMENTATION","type":"TECHNOLOGY","description":"An implementation of Graph RAG approaches using the Python programming language","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"ALONSO","type":"PERSON","description":"A person who contributed to the work mentioned in the acknowledgements","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"HTTPS:\/\/AKA.MS\/GRAPHRAG","type":"URL","description":"A URL where the open-source, Python-based implementation of Graph RAG approaches will be available","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"FABRICATION RATES","type":"METRIC","description":"The rates at which fabrications occur in text generation tasks","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"SENSEMAKING QUESTIONS","type":"DATA","description":"Questions designed to validate the understanding and interpretation of data","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"TARGET METRICS","type":"METRIC","description":"Specific metrics aimed to be achieved or measured in the analysis","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"END USERS","type":"PERSON","description":"Individuals who are the final users of the system or analysis","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"GRAPH INDEX","type":"DATA","description":"An index built using a graph structure to organize and retrieve information","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"GLOBAL SUMMARIZATION","type":"METHOD","description":"A method for summarizing information on a global scale","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"SOURCE TEXTS","type":"DATA","description":"Original texts from which summaries or analyses are derived","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"LIFETIME QUERIES PER DATASET","type":"METRIC","description":"The expected number of queries over the lifetime of a specific dataset","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"VALUE FROM GRAPH INDEX","type":"METRIC","description":"The benefits or value obtained from using a graph index","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"OTHER GRAPH-RELATED RAG APPROACHES","type":"METHOD","description":"Different methods related to retrieval-augmented generation that utilize graph structures","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"LOCAL GRAPH RAG APPROACHES","type":"METHOD","description":"Graph RAG approaches that operate in a more localized manner","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"USER QUERIES","type":"DATA","description":"Queries made by users to retrieve information","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"GRAPH ANNOTATIONS","type":"DATA","description":"Annotations made on the graph to provide additional information","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"COMMUNITY REPORTS","type":"DATA","description":"Reports generated from community summaries","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"ROLL-UP OPERATION","type":"METHOD","description":"An operation that aggregates information across multiple levels of a hierarchy","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"DRILL DOWN MECHANISM","type":"METHOD","description":"A mechanism that allows for exploring detailed information by following higher-level summaries","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"INFORMATION SCENT","type":"DATA","description":"The trail of information that guides users to more detailed data","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"ROOT-LEVEL COMMUNITIES","type":"DATA","description":"The top-level communities in a hierarchical structure","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"ENTITY-BASED GRAPH INDEX","type":"DATA","description":"A graph index organized around entities","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"},{"name":"OPEN-SOURCE IMPLEMENTATION","type":"TECHNOLOGY","description":"A publicly available implementation of a technology","source_id":"e4d9b12cf2b4c691c74019eefff4fb39"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"SELFHECKGPT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">SelfCheckGPT is an approach used to compare fabrication rates in text generation tasks<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"MANAKUL ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to the work by Manakul and colleagues published in 2023, related to SelfCheckGPT<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG is a method that combines knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) to support human sensemaking over text corpora<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"GRAPH-FREE APPROACH\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method for global summarization of source texts that does not use a graph index<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"COMPUTE BUDGET\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">The amount of computational resources allocated for a task<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"LIFETIME QUERIES\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The expected number of queries over the lifetime of a dataset<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Summaries of root-level communities in an entity-based graph index<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"MAP-REDUCE SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method for summarizing source texts using a map-reduce approach<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"RICH TEXT ANNOTATIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Annotations that provide detailed information about the text<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"HIERARCHICAL COMMUNITY STRUCTURE\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">A structure that organizes data into a hierarchy of communities<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"EMBEDDING-BASED MATCHING\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method that uses embeddings to match user queries with graph annotations<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"HYBRID RAG SCHEMES\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">RAG schemes that combine embedding-based matching with other approaches<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"MAP-REDUCE SUMMARIZATION MECHANISMS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Mechanisms used in map-reduce summarization<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"COMMUNITY HIERARCHY\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">A hierarchical organization of communities<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"GLOBAL APPROACH TO GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method that combines knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) for global text summarization<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"NA&#207;VE RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A baseline method for retrieval-augmented generation (RAG) that does not use advanced techniques<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"TOKEN COST\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The cost associated with the number of tokens used in a text generation task<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"PYTHON-BASED IMPLEMENTATION\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">An implementation of Graph RAG approaches using the Python programming language<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"ALONSO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A person who contributed to the work mentioned in the acknowledgements<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"HTTPS:\/\/AKA.MS\/GRAPHRAG\">      <data key=\"d0\">URL<\/data>      <data key=\"d1\">A URL where the open-source, Python-based implementation of Graph RAG approaches will be available<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"FABRICATION RATES\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The rates at which fabrications occur in text generation tasks<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"SENSEMAKING QUESTIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Questions designed to validate the understanding and interpretation of data<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"TARGET METRICS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Specific metrics aimed to be achieved or measured in the analysis<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"END USERS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Individuals who are the final users of the system or analysis<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"GRAPH INDEX\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">An index built using a graph structure to organize and retrieve information<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"GLOBAL SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method for summarizing information on a global scale<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"SOURCE TEXTS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Original texts from which summaries or analyses are derived<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"LIFETIME QUERIES PER DATASET\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The expected number of queries over the lifetime of a specific dataset<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"VALUE FROM GRAPH INDEX\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The benefits or value obtained from using a graph index<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"OTHER GRAPH-RELATED RAG APPROACHES\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Different methods related to retrieval-augmented generation that utilize graph structures<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"LOCAL GRAPH RAG APPROACHES\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG approaches that operate in a more localized manner<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"USER QUERIES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Queries made by users to retrieve information<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"GRAPH ANNOTATIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Annotations made on the graph to provide additional information<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"COMMUNITY REPORTS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Reports generated from community summaries<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"ROLL-UP OPERATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">An operation that aggregates information across multiple levels of a hierarchy<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"DRILL DOWN MECHANISM\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A mechanism that allows for exploring detailed information by following higher-level summaries<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"INFORMATION SCENT\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">The trail of information that guides users to more detailed data<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"ROOT-LEVEL COMMUNITIES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">The top-level communities in a hierarchical structure<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"ENTITY-BASED GRAPH INDEX\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">A graph index organized around entities<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <node id=\"OPEN-SOURCE IMPLEMENTATION\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A publicly available implementation of a technology<\/data>      <data key=\"d2\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/node>    <edge source=\"SELFHECKGPT\" target=\"MANAKUL ET AL., 2023\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">SelfCheckGPT is an approach mentioned in the work by Manakul et al., 2023<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"SELFHECKGPT\" target=\"FABRICATION RATES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">SelfCheckGPT is used to compare fabrication rates<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GRAPH-FREE APPROACH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is compared to a graph-free approach for global summarization<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses summaries of root-level communities in an entity-based graph index<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MAP-REDUCE SUMMARIZATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is compared to map-reduce summarization<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"RICH TEXT ANNOTATIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses rich text annotations<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"HIERARCHICAL COMMUNITY STRUCTURE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses a hierarchical community structure<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"EMBEDDING-BASED MATCHING\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG can operate using embedding-based matching<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"HYBRID RAG SCHEMES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG can be part of hybrid RAG schemes<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MAP-REDUCE SUMMARIZATION MECHANISMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG can employ map-reduce summarization mechanisms<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY HIERARCHY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG can extend operations across the community hierarchy<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ALONSO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso contributed to the work on Graph RAG<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GRAPH INDEX\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses a graph index<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"LOCAL GRAPH RAG APPROACHES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG includes local graph RAG approaches<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ENTITY-BASED GRAPH INDEX\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG uses an entity-based graph index<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH-FREE APPROACH\" target=\"GLOBAL SUMMARIZATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Global summarization can be performed using a graph-free approach<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"ROOT-LEVEL COMMUNITIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Summaries of root-level communities are used in Graph RAG<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"EMBEDDING-BASED MATCHING\" target=\"USER QUERIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Embedding-based matching is used to match user queries<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"EMBEDDING-BASED MATCHING\" target=\"GRAPH ANNOTATIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Embedding-based matching is used to match user queries with graph annotations<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"HYBRID RAG SCHEMES\" target=\"COMMUNITY REPORTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Hybrid RAG schemes combine embedding-based matching against community reports<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"MAP-REDUCE SUMMARIZATION MECHANISMS\" target=\"ROLL-UP OPERATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The roll-up operation can be extended using map-reduce summarization mechanisms<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"COMMUNITY HIERARCHY\" target=\"DRILL DOWN MECHANISM\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The drill down mechanism follows the information scent in the community hierarchy<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GLOBAL APPROACH TO GRAPH RAG\" target=\"NA&#207;VE RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The global approach to Graph RAG shows improvements over na&#239;ve RAG<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GLOBAL APPROACH TO GRAPH RAG\" target=\"TOKEN COST\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The global approach to Graph RAG achieves competitive performance at a fraction of the token cost<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"PYTHON-BASED IMPLEMENTATION\" target=\"HTTPS:\/\/AKA.MS\/GRAPHRAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The Python-based implementation of Graph RAG approaches will be available at this URL<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"PYTHON-BASED IMPLEMENTATION\" target=\"OPEN-SOURCE IMPLEMENTATION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The open-source implementation of Graph RAG approaches is Python-based<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"SENSEMAKING QUESTIONS\" target=\"END USERS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sensemaking questions are validated with end users<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"TARGET METRICS\" target=\"END USERS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Target metrics are validated with end users<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH INDEX\" target=\"LIFETIME QUERIES PER DATASET\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The decision to build a graph index depends on the expected number of lifetime queries per dataset<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH INDEX\" target=\"VALUE FROM GRAPH INDEX\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The decision to build a graph index depends on the value obtained from it<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GRAPH INDEX\" target=\"OTHER GRAPH-RELATED RAG APPROACHES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The decision to build a graph index depends on the value obtained from other graph-related RAG approaches<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"GLOBAL SUMMARIZATION\" target=\"SOURCE TEXTS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Source texts are used in global summarization<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>    <edge source=\"DRILL DOWN MECHANISM\" target=\"INFORMATION SCENT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The drill down mechanism follows the information scent<\/data>      <data key=\"d5\">e4d9b12cf2b4c691c74019eefff4fb39<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"086021a89900a39bcb62036981737bfa","chunk":"ieves competitive performance to other global methods at a fraction of the token cost.\nAn open-source, Python-based implementation of both global and local Graph RAG approaches is\nforthcoming at https:\/\/aka .ms\/graphrag .\n11Acknowledgements\nWe would also like to thank the following people who contributed to the work: Alonso Guevara\nFern \u00b4andez, Amber Hoak, Andr \u00b4es Morales Esquivel, Ben Cutler, Billie Rinaldi, Chris Sanchez,\nChris Trevino, Christine Caggiano, David Tittsworth, Dayenne de Souza, Douglas Orbaker, Ed\nClark, Gabriel Nieves-Ponce, Gaudy Blanco Meneses, Kate Lytvynets, Katy Smith, M \u00b4onica Carva-\njal, Nathan Evans, Richard Ortega, Rodrigo Racanicci, Sarah Smith, and Shane Solomon.\nReferences\nAchiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Al-\ntenschmidt, J., Altman, S., Anadkat, S., et al. (2023). Gpt-4 technical report. arXiv preprint\narXiv:2303.08774 .\nAnil, R., Borgeaud, S., Wu, Y ., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M.,\nHauth, A., et al. (2023). Gemini: a family of highly capable multimodal models. arXiv preprint\narXiv:2312.11805 .\nBaek, J., Aji, A. F., and Saffari, A. (2023). Knowledge-augmented language model prompting for\nzero-shot knowledge graph question answering. arXiv preprint arXiv:2306.04136 .\nBan, T., Chen, L., Wang, X., and Chen, H. (2023). From query tools to causal architects: Harnessing\nlarge language models for advanced causal discovery from data.\nBaumel, T., Eyal, M., and Elhadad, M. (2018). Query focused abstractive summarization: Incorpo-\nrating query relevance, multi-document coverage, and summary length constraints into seq2seq\nmodels. arXiv preprint arXiv:180","chunk_id":"086021a89900a39bcb62036981737bfa","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"GRAPH RAG","type":"METHOD","description":"Graph RAG (Retrieval-Augmented Generation) is a method that combines global and local approaches for efficient token usage in text generation tasks","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"PYTHON","type":"TECHNOLOGY","description":"Python is a programming language used for implementing both global and local Graph RAG approaches","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"ALONSO GUEVARA FERN\u00c1NDEZ","type":"PERSON","description":"Alonso Guevara Fern\u00e1ndez is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"AMBER HOAK","type":"PERSON","description":"Amber Hoak is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"ANDR\u00c9S MORALES ESQUIVEL","type":"PERSON","description":"Andr\u00e9s Morales Esquivel is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"BEN CUTLER","type":"PERSON","description":"Ben Cutler is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"BILLIE RINALDI","type":"PERSON","description":"Billie Rinaldi is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"CHRIS SANCHEZ","type":"PERSON","description":"Chris Sanchez is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"CHRIS TREVINO","type":"PERSON","description":"Chris Trevino is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"CHRISTINE CAGGIANO","type":"PERSON","description":"Christine Caggiano is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"DAVID TITTSWORTH","type":"PERSON","description":"David Tittsworth is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"DAYENNE DE SOUZA","type":"PERSON","description":"Dayenne de Souza is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"DOUGLAS ORBAKER","type":"PERSON","description":"Douglas Orbaker is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"ED CLARK","type":"PERSON","description":"Ed Clark is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"GABRIEL NIEVES-PONCE","type":"PERSON","description":"Gabriel Nieves-Ponce is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"GAUDY BLANCO MENESES","type":"PERSON","description":"Gaudy Blanco Meneses is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"KATE LYTVYNETS","type":"PERSON","description":"Kate Lytvynets is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"KATY SMITH","type":"PERSON","description":"Katy Smith is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"M\u00d3NICA CARVAJAL","type":"PERSON","description":"M\u00f3nica Carvajal is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"NATHAN EVANS","type":"PERSON","description":"Nathan Evans is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"RICHARD ORTEGA","type":"PERSON","description":"Richard Ortega is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"RODRIGO RACANICCI","type":"PERSON","description":"Rodrigo Racanicci is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"SARAH SMITH","type":"PERSON","description":"Sarah Smith is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"SHANE SOLOMON","type":"PERSON","description":"Shane Solomon is a contributor to the work acknowledged in the document","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"GPT-4 TECHNICAL REPORT","type":"PUBLICATION","description":"A technical report on GPT-4 published as an arXiv preprint","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"GEMINI","type":"TECHNOLOGY","description":"Gemini is a family of highly capable multimodal models described in an arXiv preprint","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING","type":"METHOD","description":"A method for zero-shot knowledge graph question answering described in an arXiv preprint","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"QUERY TOOLS TO CAUSAL ARCHITECTS","type":"METHOD","description":"A method for harnessing large language models for advanced causal discovery from data","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"QUERY FOCUSED ABSTRACTIVE SUMMARIZATION","type":"METHOD","description":"A method incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"J. ACHIAM","type":"PERSON","description":"J. Achiam is an author of the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"S. ADLER","type":"PERSON","description":"S. Adler is an author of the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"S. AGARWAL","type":"PERSON","description":"S. Agarwal is an author of the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"L. AHMAD","type":"PERSON","description":"L. Ahmad is an author of the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"I. AKKAYA","type":"PERSON","description":"I. Akkaya is an author of the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"F. L. ALEMAN","type":"PERSON","description":"F. L. Aleman is an author of the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"D. ALMEIDA","type":"PERSON","description":"D. Almeida is an author of the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"J. ALTENSCHMIDT","type":"PERSON","description":"J. Altenschmidt is an author of the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"S. ALTMAN","type":"PERSON","description":"S. Altman is an author of the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"S. ANADKAT","type":"PERSON","description":"S. Anadkat is an author of the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"R. ANIL","type":"PERSON","description":"R. Anil is an author of the Gemini paper","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"S. BORGEAUD","type":"PERSON","description":"S. Borgeaud is an author of the Gemini paper","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"Y. WU","type":"PERSON","description":"Y. Wu is an author of the Gemini paper","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"J.-B. ALAYRAC","type":"PERSON","description":"J.-B. Alayrac is an author of the Gemini paper","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"J. YU","type":"PERSON","description":"J. Yu is an author of the Gemini paper","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"R. SORICUT","type":"PERSON","description":"R. Soricut is an author of the Gemini paper","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"J. SCHALKWYK","type":"PERSON","description":"J. Schalkwyk is an author of the Gemini paper","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"A. M. DAI","type":"PERSON","description":"A. M. Dai is an author of the Gemini paper","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"A. HAUTH","type":"PERSON","description":"A. Hauth is an author of the Gemini paper","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"J. BAEK","type":"PERSON","description":"J. Baek is an author of the paper on knowledge-augmented language model prompting","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"A. F. AJI","type":"PERSON","description":"A. F. Aji is an author of the paper on knowledge-augmented language model prompting","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"A. SAFFARI","type":"PERSON","description":"A. Saffari is an author of the paper on knowledge-augmented language model prompting","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"T. BAN","type":"PERSON","description":"T. Ban is an author of the paper on query tools to causal architects","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"L. CHEN","type":"PERSON","description":"L. Chen is an author of the paper on query tools to causal architects","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"X. WANG","type":"PERSON","description":"X. Wang is an author of the paper on query tools to causal architects","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"H. CHEN","type":"PERSON","description":"H. Chen is an author of the paper on query tools to causal architects","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"T. BAUMEL","type":"PERSON","description":"T. Baumel is an author of the paper on query focused abstractive summarization","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"M. EYAL","type":"PERSON","description":"M. Eyal is an author of the paper on query focused abstractive summarization","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"M. ELHADAD","type":"PERSON","description":"M. Elhadad is an author of the paper on query focused abstractive summarization","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is a repository where the mentioned papers are published as preprints","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"ARXIV:2303.08774","type":"PUBLICATION","description":"The arXiv preprint identifier for the GPT-4 technical report","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"ARXIV:2312.11805","type":"PUBLICATION","description":"The arXiv preprint identifier for the Gemini paper","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"ARXIV:2306.04136","type":"PUBLICATION","description":"The arXiv preprint identifier for the paper on knowledge-augmented language model prompting","source_id":"086021a89900a39bcb62036981737bfa"},{"name":"ARXIV:180","type":"PUBLICATION","description":"The arXiv preprint identifier for the paper on query focused abstractive summarization","source_id":"086021a89900a39bcb62036981737bfa"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Graph RAG (Retrieval-Augmented Generation) is a method that combines global and local approaches for efficient token usage in text generation tasks<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"PYTHON\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Python is a programming language used for implementing both global and local Graph RAG approaches<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"ALONSO GUEVARA FERN&#193;NDEZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alonso Guevara Fern&#225;ndez is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"AMBER HOAK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amber Hoak is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"ANDR&#201;S MORALES ESQUIVEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andr&#233;s Morales Esquivel is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"BEN CUTLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ben Cutler is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"BILLIE RINALDI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Billie Rinaldi is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"CHRIS SANCHEZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chris Sanchez is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"CHRIS TREVINO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chris Trevino is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"CHRISTINE CAGGIANO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Christine Caggiano is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"DAVID TITTSWORTH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Tittsworth is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"DAYENNE DE SOUZA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dayenne de Souza is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"DOUGLAS ORBAKER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Douglas Orbaker is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"ED CLARK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ed Clark is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"GABRIEL NIEVES-PONCE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gabriel Nieves-Ponce is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"GAUDY BLANCO MENESES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gaudy Blanco Meneses is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"KATE LYTVYNETS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kate Lytvynets is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"KATY SMITH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Katy Smith is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"M&#211;NICA CARVAJAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">M&#243;nica Carvajal is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"NATHAN EVANS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nathan Evans is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"RICHARD ORTEGA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Richard Ortega is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"RODRIGO RACANICCI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rodrigo Racanicci is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"SARAH SMITH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sarah Smith is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"SHANE SOLOMON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shane Solomon is a contributor to the work acknowledged in the document<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"GPT-4 TECHNICAL REPORT\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A technical report on GPT-4 published as an arXiv preprint<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"GEMINI\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Gemini is a family of highly capable multimodal models described in an arXiv preprint<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method for zero-shot knowledge graph question answering described in an arXiv preprint<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"QUERY TOOLS TO CAUSAL ARCHITECTS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method for harnessing large language models for advanced causal discovery from data<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"QUERY FOCUSED ABSTRACTIVE SUMMARIZATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">A method incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"J. ACHIAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J. Achiam is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"S. ADLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">S. Adler is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"S. AGARWAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">S. Agarwal is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"L. AHMAD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">L. Ahmad is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"I. AKKAYA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">I. Akkaya is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"F. L. ALEMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">F. L. Aleman is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"D. ALMEIDA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">D. Almeida is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"J. ALTENSCHMIDT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J. Altenschmidt is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"S. ALTMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">S. Altman is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"S. ANADKAT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">S. Anadkat is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"R. ANIL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">R. Anil is an author of the Gemini paper<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"S. BORGEAUD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">S. Borgeaud is an author of the Gemini paper<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"Y. WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Y. Wu is an author of the Gemini paper<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"J.-B. ALAYRAC\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J.-B. Alayrac is an author of the Gemini paper<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"J. YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J. Yu is an author of the Gemini paper<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"R. SORICUT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">R. Soricut is an author of the Gemini paper<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"J. SCHALKWYK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J. Schalkwyk is an author of the Gemini paper<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"A. M. DAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A. M. Dai is an author of the Gemini paper<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"A. HAUTH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A. Hauth is an author of the Gemini paper<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"J. BAEK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J. Baek is an author of the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"A. F. AJI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A. F. Aji is an author of the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"A. SAFFARI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A. Saffari is an author of the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"T. BAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">T. Ban is an author of the paper on query tools to causal architects<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"L. CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">L. Chen is an author of the paper on query tools to causal architects<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"X. WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">X. Wang is an author of the paper on query tools to causal architects<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"H. CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">H. Chen is an author of the paper on query tools to causal architects<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"T. BAUMEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">T. Baumel is an author of the paper on query focused abstractive summarization<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"M. EYAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">M. Eyal is an author of the paper on query focused abstractive summarization<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"M. ELHADAD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">M. Elhadad is an author of the paper on query focused abstractive summarization<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is a repository where the mentioned papers are published as preprints<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"ARXIV:2303.08774\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The arXiv preprint identifier for the GPT-4 technical report<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"ARXIV:2312.11805\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The arXiv preprint identifier for the Gemini paper<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"ARXIV:2306.04136\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The arXiv preprint identifier for the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <node id=\"ARXIV:180\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The arXiv preprint identifier for the paper on query focused abstractive summarization<\/data>      <data key=\"d2\">086021a89900a39bcb62036981737bfa<\/data>    <\/node>    <edge source=\"GRAPH RAG\" target=\"PYTHON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG is implemented using Python<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"AMBER HOAK\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Amber Hoak both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"ANDR&#201;S MORALES ESQUIVEL\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Andr&#233;s Morales Esquivel both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"BEN CUTLER\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Ben Cutler both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"BILLIE RINALDI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Billie Rinaldi both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"CHRIS SANCHEZ\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Chris Sanchez both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"CHRIS TREVINO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Chris Trevino both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"CHRISTINE CAGGIANO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Christine Caggiano both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"DAVID TITTSWORTH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and David Tittsworth both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"DAYENNE DE SOUZA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Dayenne de Souza both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"DOUGLAS ORBAKER\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Douglas Orbaker both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"ED CLARK\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Ed Clark both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"GABRIEL NIEVES-PONCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Gabriel Nieves-Ponce both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"GAUDY BLANCO MENESES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Gaudy Blanco Meneses both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"KATE LYTVYNETS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Kate Lytvynets both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"KATY SMITH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Katy Smith both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"M&#211;NICA CARVAJAL\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and M&#243;nica Carvajal both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"NATHAN EVANS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Nathan Evans both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"RICHARD ORTEGA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Richard Ortega both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"RODRIGO RACANICCI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Rodrigo Racanicci both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"SARAH SMITH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Sarah Smith both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"ALONSO GUEVARA FERN&#193;NDEZ\" target=\"SHANE SOLOMON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez and Shane Solomon both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"ANDR&#201;S MORALES ESQUIVEL\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Andr&#233;s Morales Esquivel both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"BEN CUTLER\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Ben Cutler both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"BILLIE RINALDI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Billie Rinaldi both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"CHRIS SANCHEZ\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Chris Sanchez both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"CHRIS TREVINO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Chris Trevino both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"CHRISTINE CAGGIANO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Christine Caggiano both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"DAVID TITTSWORTH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and David Tittsworth both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"DAYENNE DE SOUZA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Dayenne de Souza both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"DOUGLAS ORBAKER\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Douglas Orbaker both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"ED CLARK\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Ed Clark both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"GABRIEL NIEVES-PONCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Gabriel Nieves-Ponce both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"GAUDY BLANCO MENESES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Gaudy Blanco Meneses both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"KATE LYTVYNETS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Kate Lytvynets both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"KATY SMITH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Katy Smith both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"M&#211;NICA CARVAJAL\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and M&#243;nica Carvajal both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"NATHAN EVANS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Nathan Evans both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"RICHARD ORTEGA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Richard Ortega both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"AMBER HOAK\" target=\"RODRIGO RACANICCI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Amber Hoak and Rodrigo Racanicci both contributed to the work acknowledged in the document<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ACHIAM\" target=\"S. ADLER\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Achiam and S. Adler co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ACHIAM\" target=\"S. AGARWAL\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Achiam and S. Agarwal co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ACHIAM\" target=\"L. AHMAD\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Achiam and L. Ahmad co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ACHIAM\" target=\"I. AKKAYA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Achiam and I. Akkaya co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ACHIAM\" target=\"F. L. ALEMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Achiam and F. L. Aleman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ACHIAM\" target=\"D. ALMEIDA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Achiam and D. Almeida co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ACHIAM\" target=\"J. ALTENSCHMIDT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Achiam and J. Altenschmidt co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ACHIAM\" target=\"S. ALTMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Achiam and S. Altman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ACHIAM\" target=\"S. ANADKAT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Achiam and S. Anadkat co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. ADLER\" target=\"S. AGARWAL\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Adler and S. Agarwal co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. ADLER\" target=\"L. AHMAD\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Adler and L. Ahmad co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. ADLER\" target=\"I. AKKAYA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Adler and I. Akkaya co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. ADLER\" target=\"F. L. ALEMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Adler and F. L. Aleman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. ADLER\" target=\"D. ALMEIDA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Adler and D. Almeida co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. ADLER\" target=\"J. ALTENSCHMIDT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Adler and J. Altenschmidt co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. ADLER\" target=\"S. ALTMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Adler and S. Altman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. ADLER\" target=\"S. ANADKAT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Adler and S. Anadkat co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. AGARWAL\" target=\"L. AHMAD\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Agarwal and L. Ahmad co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. AGARWAL\" target=\"I. AKKAYA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Agarwal and I. Akkaya co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. AGARWAL\" target=\"F. L. ALEMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Agarwal and F. L. Aleman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. AGARWAL\" target=\"D. ALMEIDA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Agarwal and D. Almeida co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. AGARWAL\" target=\"J. ALTENSCHMIDT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Agarwal and J. Altenschmidt co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. AGARWAL\" target=\"S. ALTMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Agarwal and S. Altman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. AGARWAL\" target=\"S. ANADKAT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Agarwal and S. Anadkat co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"L. AHMAD\" target=\"I. AKKAYA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">L. Ahmad and I. Akkaya co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"L. AHMAD\" target=\"F. L. ALEMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">L. Ahmad and F. L. Aleman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"L. AHMAD\" target=\"D. ALMEIDA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">L. Ahmad and D. Almeida co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"L. AHMAD\" target=\"J. ALTENSCHMIDT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">L. Ahmad and J. Altenschmidt co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"L. AHMAD\" target=\"S. ALTMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">L. Ahmad and S. Altman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"L. AHMAD\" target=\"S. ANADKAT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">L. Ahmad and S. Anadkat co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"I. AKKAYA\" target=\"F. L. ALEMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">I. Akkaya and F. L. Aleman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"I. AKKAYA\" target=\"D. ALMEIDA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">I. Akkaya and D. Almeida co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"I. AKKAYA\" target=\"J. ALTENSCHMIDT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">I. Akkaya and J. Altenschmidt co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"I. AKKAYA\" target=\"S. ALTMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">I. Akkaya and S. Altman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"I. AKKAYA\" target=\"S. ANADKAT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">I. Akkaya and S. Anadkat co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"F. L. ALEMAN\" target=\"D. ALMEIDA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">F. L. Aleman and D. Almeida co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"F. L. ALEMAN\" target=\"J. ALTENSCHMIDT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">F. L. Aleman and J. Altenschmidt co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"F. L. ALEMAN\" target=\"S. ALTMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">F. L. Aleman and S. Altman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"F. L. ALEMAN\" target=\"S. ANADKAT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">F. L. Aleman and S. Anadkat co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"D. ALMEIDA\" target=\"J. ALTENSCHMIDT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">D. Almeida and J. Altenschmidt co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"D. ALMEIDA\" target=\"S. ALTMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">D. Almeida and S. Altman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"D. ALMEIDA\" target=\"S. ANADKAT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">D. Almeida and S. Anadkat co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ALTENSCHMIDT\" target=\"S. ALTMAN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Altenschmidt and S. Altman co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. ALTENSCHMIDT\" target=\"S. ANADKAT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Altenschmidt and S. Anadkat co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. ALTMAN\" target=\"S. ANADKAT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Altman and S. Anadkat co-authored the GPT-4 technical report<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. ANIL\" target=\"S. BORGEAUD\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Anil and S. Borgeaud co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. ANIL\" target=\"Y. WU\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Anil and Y. Wu co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. ANIL\" target=\"J.-B. ALAYRAC\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Anil and J.-B. Alayrac co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. ANIL\" target=\"J. YU\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Anil and J. Yu co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. ANIL\" target=\"R. SORICUT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Anil and R. Soricut co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. ANIL\" target=\"J. SCHALKWYK\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Anil and J. Schalkwyk co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. ANIL\" target=\"A. M. DAI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Anil and A. M. Dai co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. ANIL\" target=\"A. HAUTH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Anil and A. Hauth co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. BORGEAUD\" target=\"Y. WU\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Borgeaud and Y. Wu co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. BORGEAUD\" target=\"J.-B. ALAYRAC\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Borgeaud and J.-B. Alayrac co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. BORGEAUD\" target=\"J. YU\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Borgeaud and J. Yu co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. BORGEAUD\" target=\"R. SORICUT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Borgeaud and R. Soricut co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. BORGEAUD\" target=\"J. SCHALKWYK\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Borgeaud and J. Schalkwyk co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. BORGEAUD\" target=\"A. M. DAI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Borgeaud and A. M. Dai co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"S. BORGEAUD\" target=\"A. HAUTH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">S. Borgeaud and A. Hauth co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"Y. WU\" target=\"J.-B. ALAYRAC\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Y. Wu and J.-B. Alayrac co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"Y. WU\" target=\"J. YU\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Y. Wu and J. Yu co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"Y. WU\" target=\"R. SORICUT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Y. Wu and R. Soricut co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"Y. WU\" target=\"J. SCHALKWYK\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Y. Wu and J. Schalkwyk co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"Y. WU\" target=\"A. M. DAI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Y. Wu and A. M. Dai co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"Y. WU\" target=\"A. HAUTH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Y. Wu and A. Hauth co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J.-B. ALAYRAC\" target=\"J. YU\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J.-B. Alayrac and J. Yu co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J.-B. ALAYRAC\" target=\"R. SORICUT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J.-B. Alayrac and R. Soricut co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J.-B. ALAYRAC\" target=\"J. SCHALKWYK\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J.-B. Alayrac and J. Schalkwyk co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J.-B. ALAYRAC\" target=\"A. M. DAI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J.-B. Alayrac and A. M. Dai co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J.-B. ALAYRAC\" target=\"A. HAUTH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J.-B. Alayrac and A. Hauth co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. YU\" target=\"R. SORICUT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Yu and R. Soricut co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. YU\" target=\"J. SCHALKWYK\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Yu and J. Schalkwyk co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. YU\" target=\"A. M. DAI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Yu and A. M. Dai co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. YU\" target=\"A. HAUTH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Yu and A. Hauth co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. SORICUT\" target=\"J. SCHALKWYK\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Soricut and J. Schalkwyk co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. SORICUT\" target=\"A. M. DAI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Soricut and A. M. Dai co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"R. SORICUT\" target=\"A. HAUTH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">R. Soricut and A. Hauth co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. SCHALKWYK\" target=\"A. M. DAI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Schalkwyk and A. M. Dai co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. SCHALKWYK\" target=\"A. HAUTH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Schalkwyk and A. Hauth co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"A. M. DAI\" target=\"A. HAUTH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">A. M. Dai and A. Hauth co-authored the Gemini paper<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. BAEK\" target=\"A. F. AJI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Baek and A. F. Aji co-authored the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"J. BAEK\" target=\"A. SAFFARI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">J. Baek and A. Saffari co-authored the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"A. F. AJI\" target=\"A. SAFFARI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">A. F. Aji and A. Saffari co-authored the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>    <edge source=\"T. BAN\" target=\"L. CHEN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">T. Ban and L. Chen co-authored the paper on query tools to causal architects<\/data>      <data key=\"d5\">086021a89900a39bcb62036981737bfa<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"58ae80c41cfe46db39da26b6a83584e5","chunk":".\nBaumel, T., Eyal, M., and Elhadad, M. (2018). Query focused abstractive summarization: Incorpo-\nrating query relevance, multi-document coverage, and summary length constraints into seq2seq\nmodels. arXiv preprint arXiv:1801.07704 .\nBlondel, V . D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E. (2008). Fast unfolding of\ncommunities in large networks. Journal of statistical mechanics: theory and experiment ,\n2008(10):P10008.\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam,\nP., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Advances in\nneural information processing systems , 33:1877\u20131901.\nCheng, X., Luo, D., Chen, X., Liu, L., Zhao, D., and Yan, R. (2024). Lift yourself up: Retrieval-\naugmented text generation with self-memory. Advances in Neural Information Processing Sys-\ntems, 36.\nDang, H. T. (2006). Duc 2005: Evaluation of question-focused summarization systems. In Proceed-\nings of the Workshop on Task-Focused Summarization and Question Answering , pages 48\u201355.\nEs, S., James, J., Espinosa-Anke, L., and Schockaert, S. (2023). Ragas: Automated evaluation of\nretrieval augmented generation. arXiv preprint arXiv:2309.15217 .\nFeng, Z., Feng, X., Zhao, D., Yang, M., and Qin, B. (2023). Retrieval-generation synergy augmented\nlarge language models. arXiv preprint arXiv:2310.05149 .\nFortunato, S. (2010). Community detection in graphs. Physics reports , 486(3-5):75\u2013174.\nGao, Y ., Xiong, Y ., Gao, X., Jia, K., Pan, J., Bi, Y ., Dai, Y ., Sun, J., and Wang, H. (2023). Retrieval-\naugmented generation","chunk_id":"58ae80c41cfe46db39da26b6a83584e5","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"BAUMEL, T.","type":"PERSON","description":"Baumel, T. is an author of the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"EYAL, M.","type":"PERSON","description":"Eyal, M. is an author of the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"ELHADAD, M.","type":"PERSON","description":"Elhadad, M. is an author of the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"ARXIV","type":"PUBLICATION","description":"The platform where the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\" was published","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"BLONDEL, V. D.","type":"PERSON","description":"Blondel, V. D. is an author of the paper \"Fast unfolding of communities in large networks\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"GUILLAUME, J.-L.","type":"PERSON","description":"Guillaume, J.-L. is an author of the paper \"Fast unfolding of communities in large networks\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"LAMBIOTTE, R.","type":"PERSON","description":"Lambiotte, R. is an author of the paper \"Fast unfolding of communities in large networks\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"LEFEBVRE, E.","type":"PERSON","description":"Lefebvre, E. is an author of the paper \"Fast unfolding of communities in large networks\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT","type":"PUBLICATION","description":"The journal where the paper \"Fast unfolding of communities in large networks\" was published","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"BROWN, T.","type":"PERSON","description":"Brown, T. is an author of the paper \"Language models are few-shot learners\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"MANN, B.","type":"PERSON","description":"Mann, B. is an author of the paper \"Language models are few-shot learners\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"RYDER, N.","type":"PERSON","description":"Ryder, N. is an author of the paper \"Language models are few-shot learners\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"SUBBIAH, M.","type":"PERSON","description":"Subbiah, M. is an author of the paper \"Language models are few-shot learners\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"KAPLAN, J. D.","type":"PERSON","description":"Kaplan, J. D. is an author of the paper \"Language models are few-shot learners\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"DHARIWAL, P.","type":"PERSON","description":"Dhariwal, P. is an author of the paper \"Language models are few-shot learners\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"NEELAKANTAN, A.","type":"PERSON","description":"Neelakantan, A. is an author of the paper \"Language models are few-shot learners\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"SHYAM, P.","type":"PERSON","description":"Shyam, P. is an author of the paper \"Language models are few-shot learners\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"SASTRY, G.","type":"PERSON","description":"Sastry, G. is an author of the paper \"Language models are few-shot learners\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"ASKELL, A.","type":"PERSON","description":"Askell, A. is an author of the paper \"Language models are few-shot learners\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS","type":"PUBLICATION","description":"The conference where the paper \"Language models are few-shot learners\" was presented","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"CHENG, X.","type":"PERSON","description":"Cheng, X. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"LUO, D.","type":"PERSON","description":"Luo, D. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"CHEN, X.","type":"PERSON","description":"Chen, X. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"LIU, L.","type":"PERSON","description":"Liu, L. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"ZHAO, D.","type":"PERSON","description":"Zhao, D. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"\nZhao, D. is an author of the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"58ae80c41cfe46db39da26b6a83584e5","entity_type":"PERSON"},{"name":"YAN, R.","type":"PERSON","description":"Yan, R. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"DANG, H. T.","type":"PERSON","description":"Dang, H. T. is an author of the paper \"Duc 2005: Evaluation of question-focused summarization systems\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"PROCEEDINGS OF THE WORKSHOP ON TASK-FOCUSED SUMMARIZATION AND QUESTION ANSWERING","type":"PUBLICATION","description":"The conference where the paper \"Duc 2005: Evaluation of question-focused summarization systems\" was presented","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"ES, S.","type":"PERSON","description":"Es, S. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"JAMES, J.","type":"PERSON","description":"James, J. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"ESPINOSA-ANKE, L.","type":"PERSON","description":"Espinosa-Anke, L. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"SCHOCKAERT, S.","type":"PERSON","description":"Schockaert, S. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"FENG, Z.","type":"PERSON","description":"Feng, Z. is an author of the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"FENG, X.","type":"PERSON","description":"Feng, X. is an author of the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"YANG, M.","type":"PERSON","description":"Yang, M. is an author of the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"QIN, B.","type":"PERSON","description":"Qin, B. is an author of the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"FORTUNATO, S.","type":"PERSON","description":"Fortunato, S. is an author of the paper \"Community detection in graphs\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"PHYSICS REPORTS","type":"PUBLICATION","description":"The journal where the paper \"Community detection in graphs\" was published","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"GAO, Y.","type":"PERSON","description":"Gao, Y. is an author of the paper \"Retrieval-augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"XIONG, Y.","type":"PERSON","description":"Xiong, Y. is an author of the paper \"Retrieval-augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"GAO, X.","type":"PERSON","description":"Gao, X. is an author of the paper \"Retrieval-augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"JIA, K.","type":"PERSON","description":"Jia, K. is an author of the paper \"Retrieval-augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"PAN, J.","type":"PERSON","description":"Pan, J. is an author of the paper \"Retrieval-augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"BI, Y.","type":"PERSON","description":"Bi, Y. is an author of the paper \"Retrieval-augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"DAI, Y.","type":"PERSON","description":"Dai, Y. is an author of the paper \"Retrieval-augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"SUN, J.","type":"PERSON","description":"Sun, J. is an author of the paper \"Retrieval-augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"WANG, H.","type":"PERSON","description":"Wang, H. is an author of the paper \"Retrieval-augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"ARXIV:1801.07704","type":"PUBLICATION","description":"The arXiv identifier for the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"ARXIV:2309.15217","type":"PUBLICATION","description":"The arXiv identifier for the paper \"Ragas: Automated evaluation of retrieval augmented generation\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"},{"name":"ARXIV:2310.05149","type":"PUBLICATION","description":"The arXiv identifier for the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"58ae80c41cfe46db39da26b6a83584e5"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"BAUMEL, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Baumel, T. is an author of the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"EYAL, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Eyal, M. is an author of the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"ELHADAD, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Elhadad, M. is an author of the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The platform where the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\" was published<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"BLONDEL, V. D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Blondel, V. D. is an author of the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"GUILLAUME, J.-L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guillaume, J.-L. is an author of the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"LAMBIOTTE, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lambiotte, R. is an author of the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"LEFEBVRE, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lefebvre, E. is an author of the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Fast unfolding of communities in large networks\" was published<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"BROWN, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brown, T. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"MANN, B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mann, B. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"RYDER, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ryder, N. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"SUBBIAH, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Subbiah, M. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"KAPLAN, J. D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kaplan, J. D. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"DHARIWAL, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dhariwal, P. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"NEELAKANTAN, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Neelakantan, A. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"SHYAM, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shyam, P. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"SASTRY, G.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sastry, G. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"ASKELL, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Askell, A. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Language models are few-shot learners\" was presented<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"CHENG, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cheng, X. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"LUO, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luo, D. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"CHEN, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen, X. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"LIU, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu, L. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"ZHAO, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhao, D. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"Zhao, D. is an author of the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YAN, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yan, R. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"DANG, H. T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dang, H. T. is an author of the paper \"Duc 2005: Evaluation of question-focused summarization systems\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"PROCEEDINGS OF THE WORKSHOP ON TASK-FOCUSED SUMMARIZATION AND QUESTION ANSWERING\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Duc 2005: Evaluation of question-focused summarization systems\" was presented<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"ES, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Es, S. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"JAMES, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">James, J. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"ESPINOSA-ANKE, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Espinosa-Anke, L. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"SCHOCKAERT, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Schockaert, S. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"FENG, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Feng, Z. is an author of the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"FENG, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Feng, X. is an author of the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"YANG, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang, M. is an author of the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"QIN, B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qin, B. is an author of the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"FORTUNATO, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fortunato, S. is an author of the paper \"Community detection in graphs\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"PHYSICS REPORTS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Community detection in graphs\" was published<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"GAO, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao, Y. is an author of the paper \"Retrieval-augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"XIONG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiong, Y. is an author of the paper \"Retrieval-augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"GAO, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao, X. is an author of the paper \"Retrieval-augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"JIA, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jia, K. is an author of the paper \"Retrieval-augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"PAN, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pan, J. is an author of the paper \"Retrieval-augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"BI, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bi, Y. is an author of the paper \"Retrieval-augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"DAI, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dai, Y. is an author of the paper \"Retrieval-augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"SUN, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sun, J. is an author of the paper \"Retrieval-augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"WANG, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, H. is an author of the paper \"Retrieval-augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"ARXIV:1801.07704\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The arXiv identifier for the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"ARXIV:2309.15217\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The arXiv identifier for the paper \"Ragas: Automated evaluation of retrieval augmented generation\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <node id=\"ARXIV:2310.05149\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The arXiv identifier for the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/node>    <edge source=\"BAUMEL, T.\" target=\"EYAL, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Baumel, T. and Eyal, M. co-authored the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BAUMEL, T.\" target=\"ELHADAD, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Baumel, T. and Elhadad, M. co-authored the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BAUMEL, T.\" target=\"ARXIV\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Baumel, T. published the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BAUMEL, T.\" target=\"ARXIV:1801.07704\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Baumel, T. is an author of the paper with arXiv identifier 1801.07704<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"EYAL, M.\" target=\"ELHADAD, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Eyal, M. and Elhadad, M. co-authored the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"EYAL, M.\" target=\"ARXIV\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Eyal, M. published the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"EYAL, M.\" target=\"ARXIV:1801.07704\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Eyal, M. is an author of the paper with arXiv identifier 1801.07704<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ELHADAD, M.\" target=\"ARXIV\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Elhadad, M. published the paper \"Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ELHADAD, M.\" target=\"ARXIV:1801.07704\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Elhadad, M. is an author of the paper with arXiv identifier 1801.07704<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ES, S.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Es, S. published the paper \"Ragas: Automated evaluation of retrieval augmented generation\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"JAMES, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">James, J. published the paper \"Ragas: Automated evaluation of retrieval augmented generation\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ESPINOSA-ANKE, L.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Espinosa-Anke, L. published the paper \"Ragas: Automated evaluation of retrieval augmented generation\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"SCHOCKAERT, S.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Schockaert, S. published the paper \"Ragas: Automated evaluation of retrieval augmented generation\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"FENG, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Feng, Z. published the paper \"Retrieval-generation synergy augmented large language models\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"FENG, X.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Feng, X. published the paper \"Retrieval-generation synergy augmented large language models\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ZHAO, D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zhao, D. published the paper \"Retrieval-generation synergy augmented large language models\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"YANG, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yang, M. published the paper \"Retrieval-generation synergy augmented large language models\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"QIN, B.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Qin, B. published the paper \"Retrieval-generation synergy augmented large language models\" on arXiv<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BLONDEL, V. D.\" target=\"GUILLAUME, J.-L.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Blondel, V. D. and Guillaume, J.-L. co-authored the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BLONDEL, V. D.\" target=\"LAMBIOTTE, R.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Blondel, V. D. and Lambiotte, R. co-authored the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BLONDEL, V. D.\" target=\"LEFEBVRE, E.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Blondel, V. D. and Lefebvre, E. co-authored the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"GUILLAUME, J.-L.\" target=\"LAMBIOTTE, R.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Guillaume, J.-L. and Lambiotte, R. co-authored the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"GUILLAUME, J.-L.\" target=\"LEFEBVRE, E.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Guillaume, J.-L. and Lefebvre, E. co-authored the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"LAMBIOTTE, R.\" target=\"LEFEBVRE, E.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lambiotte, R. and Lefebvre, E. co-authored the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BROWN, T.\" target=\"MANN, B.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, T. and Mann, B. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BROWN, T.\" target=\"RYDER, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, T. and Ryder, N. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BROWN, T.\" target=\"SUBBIAH, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, T. and Subbiah, M. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BROWN, T.\" target=\"KAPLAN, J. D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, T. and Kaplan, J. D. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BROWN, T.\" target=\"DHARIWAL, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, T. and Dhariwal, P. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BROWN, T.\" target=\"NEELAKANTAN, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, T. and Neelakantan, A. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BROWN, T.\" target=\"SHYAM, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, T. and Shyam, P. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BROWN, T.\" target=\"SASTRY, G.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, T. and Sastry, G. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"BROWN, T.\" target=\"ASKELL, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, T. and Askell, A. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"MANN, B.\" target=\"RYDER, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Mann, B. and Ryder, N. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"MANN, B.\" target=\"SUBBIAH, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Mann, B. and Subbiah, M. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"MANN, B.\" target=\"KAPLAN, J. D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Mann, B. and Kaplan, J. D. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"MANN, B.\" target=\"DHARIWAL, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Mann, B. and Dhariwal, P. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"MANN, B.\" target=\"NEELAKANTAN, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Mann, B. and Neelakantan, A. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"MANN, B.\" target=\"SHYAM, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Mann, B. and Shyam, P. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"MANN, B.\" target=\"SASTRY, G.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Mann, B. and Sastry, G. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"MANN, B.\" target=\"ASKELL, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Mann, B. and Askell, A. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"RYDER, N.\" target=\"SUBBIAH, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Ryder, N. and Subbiah, M. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"RYDER, N.\" target=\"KAPLAN, J. D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Ryder, N. and Kaplan, J. D. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"RYDER, N.\" target=\"DHARIWAL, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Ryder, N. and Dhariwal, P. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"RYDER, N.\" target=\"NEELAKANTAN, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Ryder, N. and Neelakantan, A. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"RYDER, N.\" target=\"SHYAM, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Ryder, N. and Shyam, P. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"RYDER, N.\" target=\"SASTRY, G.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Ryder, N. and Sastry, G. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"RYDER, N.\" target=\"ASKELL, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Ryder, N. and Askell, A. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"SUBBIAH, M.\" target=\"KAPLAN, J. D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Subbiah, M. and Kaplan, J. D. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"SUBBIAH, M.\" target=\"DHARIWAL, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Subbiah, M. and Dhariwal, P. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"SUBBIAH, M.\" target=\"NEELAKANTAN, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Subbiah, M. and Neelakantan, A. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"SUBBIAH, M.\" target=\"SHYAM, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Subbiah, M. and Shyam, P. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"SUBBIAH, M.\" target=\"SASTRY, G.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Subbiah, M. and Sastry, G. co-authored the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ZHAO, D.\" target=\"ARXIV:2310.05149\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zhao, D. is an author of the paper with arXiv identifier 2310.05149<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ES, S.\" target=\"ARXIV:2309.15217\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Es, S. is an author of the paper with arXiv identifier 2309.15217<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"JAMES, J.\" target=\"ARXIV:2309.15217\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">James, J. is an author of the paper with arXiv identifier 2309.15217<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"ESPINOSA-ANKE, L.\" target=\"ARXIV:2309.15217\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Espinosa-Anke, L. is an author of the paper with arXiv identifier 2309.15217<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"SCHOCKAERT, S.\" target=\"ARXIV:2309.15217\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Schockaert, S. is an author of the paper with arXiv identifier 2309.15217<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"FENG, Z.\" target=\"ARXIV:2310.05149\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Feng, Z. is an author of the paper with arXiv identifier 2310.05149<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"FENG, X.\" target=\"ARXIV:2310.05149\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Feng, X. is an author of the paper with arXiv identifier 2310.05149<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"YANG, M.\" target=\"ARXIV:2310.05149\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yang, M. is an author of the paper with arXiv identifier 2310.05149<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>    <edge source=\"QIN, B.\" target=\"ARXIV:2310.05149\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Qin, B. is an author of the paper with arXiv identifier 2310.05149<\/data>      <data key=\"d6\">58ae80c41cfe46db39da26b6a83584e5<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"00e8e4e881bd0862022f4dfc913b900b","chunk":"3-5):75\u2013174.\nGao, Y ., Xiong, Y ., Gao, X., Jia, K., Pan, J., Bi, Y ., Dai, Y ., Sun, J., and Wang, H. (2023). Retrieval-\naugmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997 .\nGoodwin, T. R., Savery, M. E., and Demner-Fushman, D. (2020). Flight of the pegasus? comparing\ntransformers on few-shot and zero-shot multi-document abstractive summarization. In Proceed-\nings of COLING. International Conference on Computational Linguistics , volume 2020, page\n5640. NIH Public Access.\nHe, X., Tian, Y ., Sun, Y ., Chawla, N. V ., Laurent, T., LeCun, Y ., Bresson, X., and Hooi, B. (2024).\nG-retriever: Retrieval-augmented generation for textual graph understanding and question an-\nswering. arXiv preprint arXiv:2402.07630 .\n12Jacomy, M., Venturini, T., Heymann, S., and Bastian, M. (2014). Forceatlas2, a continuous graph\nlayout algorithm for handy network visualization designed for the gephi software. PLoS ONE\n9(6): e98679. https:\/\/doi.org\/10.1371\/journal.pone.0098679 .\nJin, D., Yu, Z., Jiao, P., Pan, S., He, D., Wu, J., Philip, S. Y ., and Zhang, W. (2021). A survey of\ncommunity detection approaches: From statistical modeling to deep learning. IEEE Transactions\non Knowledge and Data Engineering , 35(2):1149\u20131170.\nKang, M., Kwak, J. M., Baek, J., and Hwang, S. J. (2023). Knowledge graph-augmented language\nmodels for knowledge-grounded dialogue generation. arXiv preprint arXiv:2305.18846 .\nKhattab, O., Santhanam, K., Li, X. L., Hall, D., Liang, P., Potts, C., and Zaharia, M. (2022).\n","chunk_id":"00e8e4e881bd0862022f4dfc913b900b","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"GAO, Y.","type":"PERSON","description":"Gao, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"XIONG, Y.","type":"PERSON","description":"Xiong, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"GAO, X.","type":"PERSON","description":"Gao, X. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"JIA, K.","type":"PERSON","description":"Jia, K. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"PAN, J.","type":"PERSON","description":"Pan, J. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"BI, Y.","type":"PERSON","description":"Bi, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"DAI, Y.","type":"PERSON","description":"Dai, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"SUN, J.","type":"PERSON","description":"Sun, J. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"WANG, H.","type":"PERSON","description":"Wang, H. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is the platform where the paper \"Retrieval-augmented generation for large language models: A survey\" was published\narXiv is the platform where the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\" was published","source_id":"00e8e4e881bd0862022f4dfc913b900b","entity_type":"PUBLICATION"},{"name":"GOODWIN, T. R.","type":"PERSON","description":"Goodwin, T. R. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"SAVERY, M. E.","type":"PERSON","description":"Savery, M. E. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"DEMNER-FUSHMAN, D.","type":"PERSON","description":"Demner-Fushman, D. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"COLING","type":"CONFERENCE","description":"COLING (International Conference on Computational Linguistics) is the conference where the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\" was presented","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"HE, X.","type":"PERSON","description":"He, X. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"TIAN, Y.","type":"PERSON","description":"Tian, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"SUN, Y.","type":"PERSON","description":"Sun, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"CHAWLA, N. V.","type":"PERSON","description":"Chawla, N. V. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"LAURENT, T.","type":"PERSON","description":"Laurent, T. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"LECUN, Y.","type":"PERSON","description":"LeCun, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"BRESSON, X.","type":"PERSON","description":"Bresson, X. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"HOOI, B.","type":"PERSON","description":"Hooi, B. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"JACOMY, M.","type":"PERSON","description":"Jacomy, M. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"VENTURINI, T.","type":"PERSON","description":"Venturini, T. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"HEYMANN, S.","type":"PERSON","description":"Heymann, S. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"BASTIAN, M.","type":"PERSON","description":"Bastian, M. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"PLOS ONE","type":"PUBLICATION","description":"PLOS ONE is the journal where the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\" was published","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"JIN, D.","type":"PERSON","description":"Jin, D. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"YU, Z.","type":"PERSON","description":"Yu, Z. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"JIAO, P.","type":"PERSON","description":"Jiao, P. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"PAN, S.","type":"PERSON","description":"Pan, S. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"HE, D.","type":"PERSON","description":"He, D. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"WU, J.","type":"PERSON","description":"Wu, J. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"PHILIP, S. Y.","type":"PERSON","description":"Philip, S. Y. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"ZHANG, W.","type":"PERSON","description":"Zhang, W. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING","type":"PUBLICATION","description":"IEEE Transactions on Knowledge and Data Engineering is the journal where the paper \"A survey of community detection approaches: From statistical modeling to deep learning\" was published","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"KANG, M.","type":"PERSON","description":"Kang, M. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"KWAK, J. M.","type":"PERSON","description":"Kwak, J. M. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"BAEK, J.","type":"PERSON","description":"Baek, J. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"HWANG, S. J.","type":"PERSON","description":"Hwang, S. J. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"KHATTAB, O.","type":"PERSON","description":"Khattab, O. is an author of the paper mentioned in the text","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"SANTHANAM, K.","type":"PERSON","description":"Santhanam, K. is an author of the paper mentioned in the text","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"LI, X. L.","type":"PERSON","description":"Li, X. L. is an author of the paper mentioned in the text","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"HALL, D.","type":"PERSON","description":"Hall, D. is an author of the paper mentioned in the text","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"LIANG, P.","type":"PERSON","description":"Liang, P. is an author of the paper mentioned in the text","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"POTTS, C.","type":"PERSON","description":"Potts, C. is an author of the paper mentioned in the text","source_id":"00e8e4e881bd0862022f4dfc913b900b"},{"name":"ZAHARIA, M.","type":"PERSON","description":"Zaharia, M. is an author of the paper mentioned in the text","source_id":"00e8e4e881bd0862022f4dfc913b900b"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"GAO, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"XIONG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiong, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"GAO, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao, X. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"JIA, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jia, K. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"PAN, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pan, J. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"BI, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bi, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"DAI, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dai, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"SUN, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sun, J. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"WANG, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, H. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is the platform where the paper \"Retrieval-augmented generation for large language models: A survey\" was publishedarXiv is the platform where the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\" was published<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"GOODWIN, T. R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Goodwin, T. R. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"SAVERY, M. E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Savery, M. E. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"DEMNER-FUSHMAN, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Demner-Fushman, D. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"COLING\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">COLING (International Conference on Computational Linguistics) is the conference where the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\" was presented<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"HE, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">He, X. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"TIAN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tian, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"SUN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sun, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"CHAWLA, N. V.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chawla, N. V. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"LAURENT, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Laurent, T. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"LECUN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">LeCun, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"BRESSON, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bresson, X. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"HOOI, B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hooi, B. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"JACOMY, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacomy, M. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"VENTURINI, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Venturini, T. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"HEYMANN, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Heymann, S. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"BASTIAN, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bastian, M. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"PLOS ONE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">PLOS ONE is the journal where the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\" was published<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"JIN, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jin, D. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"YU, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yu, Z. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"JIAO, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiao, P. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"PAN, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pan, S. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"HE, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">He, D. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"WU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wu, J. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"PHILIP, S. Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Philip, S. Y. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"ZHANG, W.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang, W. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">IEEE Transactions on Knowledge and Data Engineering is the journal where the paper \"A survey of community detection approaches: From statistical modeling to deep learning\" was published<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"KANG, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kang, M. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"KWAK, J. M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kwak, J. M. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"BAEK, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Baek, J. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"HWANG, S. J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hwang, S. J. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"KHATTAB, O.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Khattab, O. is an author of the paper mentioned in the text<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"SANTHANAM, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Santhanam, K. is an author of the paper mentioned in the text<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"LI, X. L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li, X. L. is an author of the paper mentioned in the text<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"HALL, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hall, D. is an author of the paper mentioned in the text<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"LIANG, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liang, P. is an author of the paper mentioned in the text<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"POTTS, C.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Potts, C. is an author of the paper mentioned in the text<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <node id=\"ZAHARIA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zaharia, M. is an author of the paper mentioned in the text<\/data>      <data key=\"d2\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/node>    <edge source=\"GAO, Y.\" target=\"XIONG, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, Y. and Xiong, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, Y.\" target=\"GAO, X.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, Y. and Gao, X. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, Y.\" target=\"JIA, K.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, Y. and Jia, K. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, Y.\" target=\"PAN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, Y. and Pan, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, Y.\" target=\"BI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, Y. and Bi, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, Y.\" target=\"DAI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, Y. and Dai, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, Y.\" target=\"SUN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, Y. and Sun, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, Y.\" target=\"WANG, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, Y. and Wang, H. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"XIONG, Y.\" target=\"GAO, X.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xiong, Y. and Gao, X. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"XIONG, Y.\" target=\"JIA, K.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xiong, Y. and Jia, K. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"XIONG, Y.\" target=\"PAN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xiong, Y. and Pan, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"XIONG, Y.\" target=\"BI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xiong, Y. and Bi, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"XIONG, Y.\" target=\"DAI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xiong, Y. and Dai, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"XIONG, Y.\" target=\"SUN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xiong, Y. and Sun, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"XIONG, Y.\" target=\"WANG, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xiong, Y. and Wang, H. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, X.\" target=\"JIA, K.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, X. and Jia, K. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, X.\" target=\"PAN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, X. and Pan, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, X.\" target=\"BI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, X. and Bi, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, X.\" target=\"DAI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, X. and Dai, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, X.\" target=\"SUN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, X. and Sun, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GAO, X.\" target=\"WANG, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gao, X. and Wang, H. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"JIA, K.\" target=\"PAN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Jia, K. and Pan, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"JIA, K.\" target=\"BI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Jia, K. and Bi, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"JIA, K.\" target=\"DAI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Jia, K. and Dai, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"JIA, K.\" target=\"SUN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Jia, K. and Sun, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"JIA, K.\" target=\"WANG, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Jia, K. and Wang, H. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"PAN, J.\" target=\"BI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Pan, J. and Bi, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"PAN, J.\" target=\"DAI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Pan, J. and Dai, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"PAN, J.\" target=\"SUN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Pan, J. and Sun, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"PAN, J.\" target=\"WANG, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Pan, J. and Wang, H. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"BI, Y.\" target=\"DAI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Bi, Y. and Dai, Y. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"BI, Y.\" target=\"SUN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Bi, Y. and Sun, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"BI, Y.\" target=\"WANG, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Bi, Y. and Wang, H. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"DAI, Y.\" target=\"SUN, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Dai, Y. and Sun, J. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"DAI, Y.\" target=\"WANG, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Dai, Y. and Wang, H. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"SUN, J.\" target=\"WANG, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Sun, J. and Wang, H. co-authored the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GOODWIN, T. R.\" target=\"SAVERY, M. E.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Goodwin, T. R. and Savery, M. E. co-authored the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"GOODWIN, T. R.\" target=\"DEMNER-FUSHMAN, D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Goodwin, T. R. and Demner-Fushman, D. co-authored the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"SANTHANAM, K.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Khattab, O. and Santhanam, K. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"LI, X. L.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Khattab, O. and Li, X. L. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"HALL, D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Khattab, O. and Hall, D. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"LIANG, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Khattab, O. and Liang, P. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"POTTS, C.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Khattab, O. and Potts, C. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"ZAHARIA, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Khattab, O. and Zaharia, M. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"LI, X. L.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Santhanam, K. and Li, X. L. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"HALL, D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Santhanam, K. and Hall, D. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"LIANG, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Santhanam, K. and Liang, P. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"POTTS, C.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Santhanam, K. and Potts, C. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"ZAHARIA, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Santhanam, K. and Zaharia, M. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"LI, X. L.\" target=\"HALL, D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, X. L. and Hall, D. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"LI, X. L.\" target=\"LIANG, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, X. L. and Liang, P. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"LI, X. L.\" target=\"POTTS, C.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, X. L. and Potts, C. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"LI, X. L.\" target=\"ZAHARIA, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, X. L. and Zaharia, M. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"HALL, D.\" target=\"LIANG, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Hall, D. and Liang, P. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"HALL, D.\" target=\"POTTS, C.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Hall, D. and Potts, C. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"HALL, D.\" target=\"ZAHARIA, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Hall, D. and Zaharia, M. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"LIANG, P.\" target=\"POTTS, C.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Liang, P. and Potts, C. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"LIANG, P.\" target=\"ZAHARIA, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Liang, P. and Zaharia, M. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>    <edge source=\"POTTS, C.\" target=\"ZAHARIA, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Potts, C. and Zaharia, M. co-authored a paper mentioned in the text<\/data>      <data key=\"d6\">00e8e4e881bd0862022f4dfc913b900b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"71f6daf11e64e5273a3847d46bf228e1","chunk":" for knowledge-grounded dialogue generation. arXiv preprint arXiv:2305.18846 .\nKhattab, O., Santhanam, K., Li, X. L., Hall, D., Liang, P., Potts, C., and Zaharia, M. (2022).\nDemonstrate-search-predict: Composing retrieval and language models for knowledge-intensive\nnlp. arXiv preprint arXiv:2212.14024 .\nKim, G., Kim, S., Jeon, B., Park, J., and Kang, J. (2023). Tree of clarifications: Answering ambigu-\nous questions with retrieval-augmented large language models. arXiv preprint arXiv:2310.14696 .\nKlein, G., Moon, B., and Hoffman, R. R. (2006a). Making sense of sensemaking 1: Alternative\nperspectives. IEEE intelligent systems , 21(4):70\u201373.\nKlein, G., Moon, B., and Hoffman, R. R. (2006b). Making sense of sensemaking 2: A macrocogni-\ntive model. IEEE Intelligent systems , 21(5):88\u201392.\nKoesten, L., Gregory, K., Groth, P., and Simperl, E. (2021). Talking datasets\u2013understanding data\nsensemaking behaviours. International journal of human-computer studies , 146:102562.\nKuratov, Y ., Bulatov, A., Anokhin, P., Sorokin, D., Sorokin, A., and Burtsev, M. (2024). In search\nof needles in a 11m haystack: Recurrent memory finds what llms miss.\nLangChain (2024). Langchain graphs. https:\/\/python .langchain .com\/docs\/use cases\/graph\/.\nLaskar, M. T. R., Hoque, E., and Huang, J. (2020). Query focused abstractive summarization via\nincorporating query relevance and transfer learning with transformer models. In Advances in\nArtificial Intelligence: 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020,\nOttawa, ON, Canada, May 13\u201315, 2020, Proceedings 33 , pages 342\u2013348. Springer.\nLaskar, M. T. R., Hoque, E., and Huang, J.","chunk_id":"71f6daf11e64e5273a3847d46bf228e1","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"KHATTAB, O.","type":"PERSON","description":"Khattab, O. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"SANTHANAM, K.","type":"PERSON","description":"Santhanam, K. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"LI, X. L.","type":"PERSON","description":"Li, X. L. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"HALL, D.","type":"PERSON","description":"Hall, D. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"LIANG, P.","type":"PERSON","description":"Liang, P. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"POTTS, C.","type":"PERSON","description":"Potts, C. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"ZAHARIA, M.","type":"PERSON","description":"Zaharia, M. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"KIM, G.","type":"PERSON","description":"Kim, G. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"KIM, S.","type":"PERSON","description":"Kim, S. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"JEON, B.","type":"PERSON","description":"Jeon, B. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"PARK, J.","type":"PERSON","description":"Park, J. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"KANG, J.","type":"PERSON","description":"Kang, J. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"KLEIN, G.","type":"PERSON","description":"Klein, G. is an author of the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"MOON, B.","type":"PERSON","description":"Moon, B. is an author of the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"HOFFMAN, R. R.","type":"PERSON","description":"Hoffman, R. R. is an author of the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"IEEE INTELLIGENT SYSTEMS","type":"PUBLICATION","description":"The journal where the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\" were published","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"KOESTEN, L.","type":"PERSON","description":"Koesten, L. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"GREGORY, K.","type":"PERSON","description":"Gregory, K. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"GROTH, P.","type":"PERSON","description":"Groth, P. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"SIMPERL, E.","type":"PERSON","description":"Simperl, E. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES","type":"PUBLICATION","description":"The journal where the paper \"Talking datasets\u2013understanding data sensemaking behaviours\" was published","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"KURATOV, Y.","type":"PERSON","description":"Kuratov, Y. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"BULATOV, A.","type":"PERSON","description":"Bulatov, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"ANOKHIN, P.","type":"PERSON","description":"Anokhin, P. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"SOROKIN, D.","type":"PERSON","description":"Sorokin, D. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"SOROKIN, A.","type":"PERSON","description":"Sorokin, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"BURTSEV, M.","type":"PERSON","description":"Burtsev, M. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"LANGCHAIN","type":"ORGANIZATION","description":"LangChain is an organization that developed Langchain graphs","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"LANGCHAIN GRAPHS","type":"TECHNOLOGY","description":"Langchain graphs is a technology developed by LangChain","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"LASKAR, M. T. R.","type":"PERSON","description":"Laskar, M. T. R. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"HOQUE, E.","type":"PERSON","description":"Hoque, E. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"HUANG, J.","type":"PERSON","description":"Huang, J. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"ADVANCES IN ARTIFICIAL INTELLIGENCE","type":"PUBLICATION","description":"The conference where the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\" was presented","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is a repository of electronic preprints (known as e-prints) approved for publication after moderation, but not full peer review","source_id":"71f6daf11e64e5273a3847d46bf228e1"},{"name":"ARXIV PREPRINT","type":"PUBLICATION","description":"arXiv preprint refers to a preprint of a paper that is available on the arXiv repository","source_id":"71f6daf11e64e5273a3847d46bf228e1"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"KHATTAB, O.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Khattab, O. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"SANTHANAM, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Santhanam, K. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"LI, X. L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li, X. L. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"HALL, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hall, D. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"LIANG, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liang, P. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"POTTS, C.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Potts, C. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"ZAHARIA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zaharia, M. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"KIM, G.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kim, G. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"KIM, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kim, S. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"JEON, B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeon, B. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"PARK, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Park, J. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"KANG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kang, J. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"KLEIN, G.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Klein, G. is an author of the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"MOON, B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Moon, B. is an author of the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"HOFFMAN, R. R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hoffman, R. R. is an author of the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"IEEE INTELLIGENT SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\" were published<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"KOESTEN, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Koesten, L. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"GREGORY, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gregory, K. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"GROTH, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Groth, P. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"SIMPERL, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Simperl, E. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\" was published<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"KURATOV, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kuratov, Y. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"BULATOV, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bulatov, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"ANOKHIN, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anokhin, P. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"SOROKIN, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sorokin, D. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"SOROKIN, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sorokin, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"BURTSEV, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Burtsev, M. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"LANGCHAIN\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">LangChain is an organization that developed Langchain graphs<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"LANGCHAIN GRAPHS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Langchain graphs is a technology developed by LangChain<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"LASKAR, M. T. R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Laskar, M. T. R. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"HOQUE, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hoque, E. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"HUANG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huang, J. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"ADVANCES IN ARTIFICIAL INTELLIGENCE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\" was presented<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is a repository of electronic preprints (known as e-prints) approved for publication after moderation, but not full peer review<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <node id=\"ARXIV PREPRINT\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv preprint refers to a preprint of a paper that is available on the arXiv repository<\/data>      <data key=\"d2\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/node>    <edge source=\"KHATTAB, O.\" target=\"SANTHANAM, K.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Khattab, O. and Santhanam, K. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"LI, X. L.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Khattab, O. and Li, X. L. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"HALL, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Khattab, O. and Hall, D. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"LIANG, P.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Khattab, O. and Liang, P. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"POTTS, C.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Khattab, O. and Potts, C. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"ZAHARIA, M.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Khattab, O. and Zaharia, M. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KHATTAB, O.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Khattab, O. is an author of the arXiv preprint \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"LI, X. L.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Santhanam, K. and Li, X. L. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"HALL, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Santhanam, K. and Hall, D. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"LIANG, P.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Santhanam, K. and Liang, P. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"POTTS, C.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Santhanam, K. and Potts, C. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"ZAHARIA, M.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Santhanam, K. and Zaharia, M. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"SANTHANAM, K.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Santhanam, K. is an author of the arXiv preprint \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LI, X. L.\" target=\"HALL, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, X. L. and Hall, D. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LI, X. L.\" target=\"LIANG, P.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, X. L. and Liang, P. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LI, X. L.\" target=\"POTTS, C.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, X. L. and Potts, C. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LI, X. L.\" target=\"ZAHARIA, M.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, X. L. and Zaharia, M. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LI, X. L.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, X. L. is an author of the arXiv preprint \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"HALL, D.\" target=\"LIANG, P.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Hall, D. and Liang, P. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"HALL, D.\" target=\"POTTS, C.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Hall, D. and Potts, C. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"HALL, D.\" target=\"ZAHARIA, M.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Hall, D. and Zaharia, M. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"HALL, D.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Hall, D. is an author of the arXiv preprint \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LIANG, P.\" target=\"POTTS, C.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Liang, P. and Potts, C. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LIANG, P.\" target=\"ZAHARIA, M.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Liang, P. and Zaharia, M. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LIANG, P.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Liang, P. is an author of the arXiv preprint \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"POTTS, C.\" target=\"ZAHARIA, M.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Potts, C. and Zaharia, M. co-authored the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"POTTS, C.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Potts, C. is an author of the arXiv preprint \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"ZAHARIA, M.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zaharia, M. is an author of the arXiv preprint \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KIM, G.\" target=\"KIM, S.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kim, G. and Kim, S. co-authored the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KIM, G.\" target=\"JEON, B.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kim, G. and Jeon, B. co-authored the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KIM, G.\" target=\"PARK, J.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kim, G. and Park, J. co-authored the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KIM, G.\" target=\"KANG, J.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kim, G. and Kang, J. co-authored the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KIM, G.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kim, G. is an author of the arXiv preprint \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KIM, S.\" target=\"JEON, B.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kim, S. and Jeon, B. co-authored the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KIM, S.\" target=\"PARK, J.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kim, S. and Park, J. co-authored the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KIM, S.\" target=\"KANG, J.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kim, S. and Kang, J. co-authored the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KIM, S.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kim, S. is an author of the arXiv preprint \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"JEON, B.\" target=\"PARK, J.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Jeon, B. and Park, J. co-authored the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"JEON, B.\" target=\"KANG, J.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Jeon, B. and Kang, J. co-authored the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"JEON, B.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Jeon, B. is an author of the arXiv preprint \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"PARK, J.\" target=\"KANG, J.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Park, J. and Kang, J. co-authored the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"PARK, J.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Park, J. is an author of the arXiv preprint \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KANG, J.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kang, J. is an author of the arXiv preprint \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KLEIN, G.\" target=\"MOON, B.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Klein, G. and Moon, B. co-authored the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KLEIN, G.\" target=\"HOFFMAN, R. R.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Klein, G. and Hoffman, R. R. co-authored the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KLEIN, G.\" target=\"IEEE INTELLIGENT SYSTEMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Klein, G. is an author of papers published in IEEE Intelligent Systems<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"MOON, B.\" target=\"HOFFMAN, R. R.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Moon, B. and Hoffman, R. R. co-authored the papers \"Making sense of sensemaking 1: Alternative perspectives\" and \"Making sense of sensemaking 2: A macrocognitive model\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"MOON, B.\" target=\"IEEE INTELLIGENT SYSTEMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Moon, B. is an author of papers published in IEEE Intelligent Systems<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"HOFFMAN, R. R.\" target=\"IEEE INTELLIGENT SYSTEMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Hoffman, R. R. is an author of papers published in IEEE Intelligent Systems<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KOESTEN, L.\" target=\"GREGORY, K.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Koesten, L. and Gregory, K. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KOESTEN, L.\" target=\"GROTH, P.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Koesten, L. and Groth, P. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KOESTEN, L.\" target=\"SIMPERL, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Koesten, L. and Simperl, E. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KOESTEN, L.\" target=\"INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Koesten, L. is an author of a paper published in International Journal of Human-Computer Studies<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"GREGORY, K.\" target=\"GROTH, P.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Gregory, K. and Groth, P. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"GREGORY, K.\" target=\"SIMPERL, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Gregory, K. and Simperl, E. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"GREGORY, K.\" target=\"INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Gregory, K. is an author of a paper published in International Journal of Human-Computer Studies<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"GROTH, P.\" target=\"SIMPERL, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Groth, P. and Simperl, E. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"GROTH, P.\" target=\"INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Groth, P. is an author of a paper published in International Journal of Human-Computer Studies<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"SIMPERL, E.\" target=\"INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Simperl, E. is an author of a paper published in International Journal of Human-Computer Studies<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Kuratov, Y. is an author of the arXiv preprint \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"BULATOV, A.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Bulatov, A. is an author of the arXiv preprint \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"ANOKHIN, P.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Anokhin, P. is an author of the arXiv preprint \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"SOROKIN, D.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sorokin, D. is an author of the arXiv preprint \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"SOROKIN, A.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sorokin, A. is an author of the arXiv preprint \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"BURTSEV, M.\" target=\"ARXIV PREPRINT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Burtsev, M. is an author of the arXiv preprint \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"ARXIV\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LangChain is an organization that has published on arXiv<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"LANGCHAIN GRAPHS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">LangChain developed Langchain graphs<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LASKAR, M. T. R.\" target=\"ADVANCES IN ARTIFICIAL INTELLIGENCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Laskar, M. T. R. is an author of a paper presented at Advances in Artificial Intelligence<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LASKAR, M. T. R.\" target=\"HOQUE, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Laskar, M. T. R. and Hoque, E. co-authored the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"LASKAR, M. T. R.\" target=\"HUANG, J.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Laskar, M. T. R. and Huang, J. co-authored the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"HOQUE, E.\" target=\"ADVANCES IN ARTIFICIAL INTELLIGENCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Hoque, E. is an author of a paper presented at Advances in Artificial Intelligence<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"HOQUE, E.\" target=\"HUANG, J.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Hoque, E. and Huang, J. co-authored the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>    <edge source=\"HUANG, J.\" target=\"ADVANCES IN ARTIFICIAL INTELLIGENCE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Huang, J. is an author of a paper presented at Advances in Artificial Intelligence<\/data>      <data key=\"d5\">71f6daf11e64e5273a3847d46bf228e1<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"6cd82819982879bd164547d2773ba5c7","chunk":"33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020,\nOttawa, ON, Canada, May 13\u201315, 2020, Proceedings 33 , pages 342\u2013348. Springer.\nLaskar, M. T. R., Hoque, E., and Huang, J. X. (2022). Domain adaptation with pre-trained transform-\ners for query-focused abstractive text summarization. Computational Linguistics , 48(2):279\u2013320.\nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V ., Goyal, N., K \u00a8uttler, H., Lewis, M., Yih,\nW.-t., Rockt \u00a8aschel, T., et al. (2020). Retrieval-augmented generation for knowledge-intensive nlp\ntasks. Advances in Neural Information Processing Systems , 33:9459\u20139474.\nLiu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., and Liang, P. (2023). Lost\nin the middle: How language models use long contexts. arXiv:2307.03172.\nLiu, Y . and Lapata, M. (2019). Hierarchical transformers for multi-document summarization. arXiv\npreprint arXiv:1905.13164 .\nLlamaIndex (2024). LlamaIndex Knowledge Graph Index. https:\/\/docs .llamaindex .ai\/en\/stable\/\nexamples\/index structs\/knowledge graph\/KnowledgeGraphDemo .html.\nManakul, P., Liusie, A., and Gales, M. J. (2023). Selfcheckgpt: Zero-resource black-box hallucina-\ntion detection for generative large language models. arXiv preprint arXiv:2303.08896 .\nMao, Y ., He, P., Liu, X., Shen, Y ., Gao, J., Han, J., and Chen, W. (2020). Generation-augmented\nretrieval for open-domain question answering. arXiv preprint arXiv:2009.08553 .\nMartin, S., Brown, W. M., Klavans, R., and Boyack, K. (2011). Openord: An open-source toolbox\nfor large graph","chunk_id":"6cd82819982879bd164547d2773ba5c7","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE","type":"EVENT","description":"The 33rd Canadian Conference on Artificial Intelligence, held in Ottawa, ON, Canada, from May 13\u201315, 2020","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"CANADIAN AI 2020","type":"EVENT","description":"The 2020 edition of the Canadian Conference on Artificial Intelligence","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"SPRINGER","type":"PUBLISHER","description":"Springer is the publisher of the proceedings of the 33rd Canadian Conference on Artificial Intelligence","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LASKAR, M. T. R.","type":"PERSON","description":"Laskar, M. T. R. is an author of the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"HOQUE, E.","type":"PERSON","description":"Hoque, E. is an author of the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"HUANG, J. X.","type":"PERSON","description":"Huang, J. X. is an author of the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"COMPUTATIONAL LINGUISTICS","type":"PUBLICATION","description":"The journal where the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\" was published","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LEWIS, P.","type":"PERSON","description":"Lewis, P. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"PEREZ, E.","type":"PERSON","description":"Perez, E. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"PIKTUS, A.","type":"PERSON","description":"Piktus, A. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"PETRONI, F.","type":"PERSON","description":"Petroni, F. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"\nPetroni, F. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"6cd82819982879bd164547d2773ba5c7","entity_type":"PERSON"},{"name":"KARPUKHIN, V.","type":"PERSON","description":"Karpukhin, V. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"GOYAL, N.","type":"PERSON","description":"Goyal, N. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"K\u00dcTTLER, H.","type":"PERSON","description":"K\u00fcttler, H. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LEWIS, M.","type":"PERSON","description":"Lewis, M. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"YIH, W.-T.","type":"PERSON","description":"Yih, W.-T. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"ROCKT\u00c4SCHEL, T.","type":"PERSON","description":"Rockt\u00e4schel, T. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS","type":"PUBLICATION","description":"The conference where the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\" was presented","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LIU, N. F.","type":"PERSON","description":"Liu, N. F. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LIN, K.","type":"PERSON","description":"Lin, K. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"HEWITT, J.","type":"PERSON","description":"Hewitt, J. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"PARANJAPE, A.","type":"PERSON","description":"Paranjape, A. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"BEVILACQUA, M.","type":"PERSON","description":"Bevilacqua, M. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LIANG, P.","type":"PERSON","description":"Liang, P. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"ARXIV","type":"PUBLICATION","description":"The preprint server where the paper \"Lost in the middle: How language models use long contexts\" was published","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LIU, Y.","type":"PERSON","description":"Liu, Y. is an author of the paper \"Hierarchical transformers for multi-document summarization\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LAPATA, M.","type":"PERSON","description":"Lapata, M. is an author of the paper \"Hierarchical transformers for multi-document summarization\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LLAMAINDEX","type":"ORGANIZATION","description":"LlamaIndex is an organization that developed the LlamaIndex Knowledge Graph Index","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LLAMAINDEX KNOWLEDGE GRAPH INDEX","type":"TECHNOLOGY","description":"LlamaIndex Knowledge Graph Index is a technology developed by LlamaIndex","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"MANAKUL, P.","type":"PERSON","description":"Manakul, P. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LIUSIE, A.","type":"PERSON","description":"Liusie, A. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"GALES, M. J.","type":"PERSON","description":"Gales, M. J. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"MAO, Y.","type":"PERSON","description":"Mao, Y. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"HE, P.","type":"PERSON","description":"He, P. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"LIU, X.","type":"PERSON","description":"Liu, X. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"SHEN, Y.","type":"PERSON","description":"Shen, Y. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"GAO, J.","type":"PERSON","description":"Gao, J. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"HAN, J.","type":"PERSON","description":"Han, J. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"CHEN, W.","type":"PERSON","description":"Chen, W. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"MARTIN, S.","type":"PERSON","description":"Martin, S. is an author of the paper \"Openord: An open-source toolbox for large graph\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"BROWN, W. M.","type":"PERSON","description":"Brown, W. M. is an author of the paper \"Openord: An open-source toolbox for large graph\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"KLAVANS, R.","type":"PERSON","description":"Klavans, R. is an author of the paper \"Openord: An open-source toolbox for large graph\"","source_id":"6cd82819982879bd164547d2773ba5c7"},{"name":"BOYACK, K.","type":"PERSON","description":"Boyack, K. is an author of the paper \"Openord: An open-source toolbox for large graph\"","source_id":"6cd82819982879bd164547d2773ba5c7"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The 33rd Canadian Conference on Artificial Intelligence, held in Ottawa, ON, Canada, from May 13&#8211;15, 2020<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"CANADIAN AI 2020\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The 2020 edition of the Canadian Conference on Artificial Intelligence<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"SPRINGER\">      <data key=\"d0\">PUBLISHER<\/data>      <data key=\"d1\">Springer is the publisher of the proceedings of the 33rd Canadian Conference on Artificial Intelligence<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LASKAR, M. T. R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Laskar, M. T. R. is an author of the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"HOQUE, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hoque, E. is an author of the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"HUANG, J. X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huang, J. X. is an author of the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"COMPUTATIONAL LINGUISTICS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\" was published<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LEWIS, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lewis, P. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"PEREZ, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Perez, E. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"PIKTUS, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Piktus, A. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"PETRONI, F.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Petroni, F. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"Petroni, F. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KARPUKHIN, V.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karpukhin, V. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"GOYAL, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Goyal, N. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"K&#220;TTLER, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">K&#252;ttler, H. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LEWIS, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lewis, M. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"YIH, W.-T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yih, W.-T. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"ROCKT&#196;SCHEL, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rockt&#228;schel, T. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\" was presented<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LIU, N. F.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu, N. F. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LIN, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lin, K. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"HEWITT, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hewitt, J. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"PARANJAPE, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Paranjape, A. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"BEVILACQUA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bevilacqua, M. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LIANG, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liang, P. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The preprint server where the paper \"Lost in the middle: How language models use long contexts\" was published<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LIU, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu, Y. is an author of the paper \"Hierarchical transformers for multi-document summarization\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LAPATA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lapata, M. is an author of the paper \"Hierarchical transformers for multi-document summarization\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LLAMAINDEX\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">LlamaIndex is an organization that developed the LlamaIndex Knowledge Graph Index<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LLAMAINDEX KNOWLEDGE GRAPH INDEX\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">LlamaIndex Knowledge Graph Index is a technology developed by LlamaIndex<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"MANAKUL, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Manakul, P. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LIUSIE, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liusie, A. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"GALES, M. J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gales, M. J. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"MAO, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mao, Y. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"HE, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">He, P. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"LIU, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu, X. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"SHEN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shen, Y. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"GAO, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao, J. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"HAN, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Han, J. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"CHEN, W.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen, W. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"MARTIN, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Martin, S. is an author of the paper \"Openord: An open-source toolbox for large graph\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"BROWN, W. M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brown, W. M. is an author of the paper \"Openord: An open-source toolbox for large graph\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"KLAVANS, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Klavans, R. is an author of the paper \"Openord: An open-source toolbox for large graph\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <node id=\"BOYACK, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Boyack, K. is an author of the paper \"Openord: An open-source toolbox for large graph\"<\/data>      <data key=\"d2\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/node>    <edge source=\"33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE\" target=\"CANADIAN AI 2020\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The 33rd Canadian Conference on Artificial Intelligence is also known as Canadian AI 2020<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"33RD CANADIAN CONFERENCE ON ARTIFICIAL INTELLIGENCE\" target=\"SPRINGER\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Springer published the proceedings of the 33rd Canadian Conference on Artificial Intelligence<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LASKAR, M. T. R.\" target=\"HOQUE, E.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Laskar, M. T. R. and Hoque, E. co-authored the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LASKAR, M. T. R.\" target=\"HUANG, J. X.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Laskar, M. T. R. and Huang, J. X. co-authored the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LASKAR, M. T. R.\" target=\"COMPUTATIONAL LINGUISTICS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Laskar, M. T. R. published the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\" in Computational Linguistics<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"HOQUE, E.\" target=\"HUANG, J. X.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Hoque, E. and Huang, J. X. co-authored the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"HOQUE, E.\" target=\"COMPUTATIONAL LINGUISTICS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Hoque, E. published the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\" in Computational Linguistics<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"HUANG, J. X.\" target=\"COMPUTATIONAL LINGUISTICS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Huang, J. X. published the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\" in Computational Linguistics<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LEWIS, P.\" target=\"PEREZ, E.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lewis, P. and Perez, E. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LEWIS, P.\" target=\"PIKTUS, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lewis, P. and Piktus, A. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LEWIS, P.\" target=\"PETRONI, F.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lewis, P. and Petroni, F. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LEWIS, P.\" target=\"KARPUKHIN, V.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lewis, P. and Karpukhin, V. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LEWIS, P.\" target=\"GOYAL, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lewis, P. and Goyal, N. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LEWIS, P.\" target=\"K&#220;TTLER, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lewis, P. and K&#252;ttler, H. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LEWIS, P.\" target=\"LEWIS, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lewis, P. and Lewis, M. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LEWIS, P.\" target=\"YIH, W.-T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lewis, P. and Yih, W.-T. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"LEWIS, P.\" target=\"ROCKT&#196;SCHEL, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lewis, P. and Rockt&#228;schel, T. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PEREZ, E.\" target=\"PIKTUS, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Perez, E. and Piktus, A. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PEREZ, E.\" target=\"PETRONI, F.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Perez, E. and Petroni, F. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PEREZ, E.\" target=\"KARPUKHIN, V.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Perez, E. and Karpukhin, V. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PEREZ, E.\" target=\"GOYAL, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Perez, E. and Goyal, N. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PEREZ, E.\" target=\"K&#220;TTLER, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Perez, E. and K&#252;ttler, H. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PEREZ, E.\" target=\"LEWIS, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Perez, E. and Lewis, M. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PEREZ, E.\" target=\"YIH, W.-T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Perez, E. and Yih, W.-T. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PEREZ, E.\" target=\"ROCKT&#196;SCHEL, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Perez, E. and Rockt&#228;schel, T. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PIKTUS, A.\" target=\"PETRONI, F.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Piktus, A. and Petroni, F. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PIKTUS, A.\" target=\"KARPUKHIN, V.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Piktus, A. and Karpukhin, V. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PIKTUS, A.\" target=\"GOYAL, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Piktus, A. and Goyal, N. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PIKTUS, A.\" target=\"K&#220;TTLER, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Piktus, A. and K&#252;ttler, H. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PIKTUS, A.\" target=\"LEWIS, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Piktus, A. and Lewis, M. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PIKTUS, A.\" target=\"YIH, W.-T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Piktus, A. and Yih, W.-T. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PIKTUS, A.\" target=\"ROCKT&#196;SCHEL, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Piktus, A. and Rockt&#228;schel, T. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PETRONI, F.\" target=\"KARPUKHIN, V.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Petroni, F. and Karpukhin, V. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PETRONI, F.\" target=\"GOYAL, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Petroni, F. and Goyal, N. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PETRONI, F.\" target=\"K&#220;TTLER, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Petroni, F. and K&#252;ttler, H. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PETRONI, F.\" target=\"LEWIS, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Petroni, F. and Lewis, M. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PETRONI, F.\" target=\"YIH, W.-T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Petroni, F. and Yih, W.-T. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"PETRONI, F.\" target=\"ROCKT&#196;SCHEL, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Petroni, F. and Rockt&#228;schel, T. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"KARPUKHIN, V.\" target=\"GOYAL, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Karpukhin, V. and Goyal, N. co-authored the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"MARTIN, S.\" target=\"BROWN, W. M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Martin, S. and Brown, W. M. co-authored the paper \"Openord: An open-source toolbox for large graph\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"MARTIN, S.\" target=\"KLAVANS, R.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Martin, S. and Klavans, R. co-authored the paper \"Openord: An open-source toolbox for large graph\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"MARTIN, S.\" target=\"BOYACK, K.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Martin, S. and Boyack, K. co-authored the paper \"Openord: An open-source toolbox for large graph\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"BROWN, W. M.\" target=\"KLAVANS, R.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, W. M. and Klavans, R. co-authored the paper \"Openord: An open-source toolbox for large graph\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"BROWN, W. M.\" target=\"BOYACK, K.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Brown, W. M. and Boyack, K. co-authored the paper \"Openord: An open-source toolbox for large graph\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>    <edge source=\"KLAVANS, R.\" target=\"BOYACK, K.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Klavans, R. and Boyack, K. co-authored the paper \"Openord: An open-source toolbox for large graph\"<\/data>      <data key=\"d6\">6cd82819982879bd164547d2773ba5c7<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"833e7d67dcd30790b26b71c9b5306f6b","chunk":"ugmented\nretrieval for open-domain question answering. arXiv preprint arXiv:2009.08553 .\nMartin, S., Brown, W. M., Klavans, R., and Boyack, K. (2011). Openord: An open-source toolbox\nfor large graph layout. SPIE Conference on Visualization and Data Analysis (VDA) .\nMicrosoft (2023). The impact of large language models on scientific discovery: a preliminary study\nusing gpt-4.\n13NebulaGraph (2024). Nebulagraph launches industry-first graph rag: Retrieval-augmented genera-\ntion with llm based on knowledge graphs. https:\/\/www .nebula-graph .io\/posts\/graph-RAG.\nNeo4J (2024). Project NaLLM. https:\/\/github .com\/neo4j\/NaLLM.\nNewman, M. E. (2006). Modularity and community structure in networks. Proceedings of the\nnational academy of sciences , 103(23):8577\u20138582.\nRam, O., Levine, Y ., Dalmedigos, I., Muhlgay, D., Shashua, A., Leyton-Brown, K., and Shoham,\nY . (2023). In-context retrieval-augmented language models. Transactions of the Association for\nComputational Linguistics , 11:1316\u20131331.\nRanade, P. and Joshi, A. (2023). Fabula: Intelligence report generation using retrieval-augmented\nnarrative construction. arXiv preprint arXiv:2310.13848 .\nSarthi, P., Abdullah, S., Tuli, A., Khanna, S., Goldie, A., and Manning, C. D. (2024). Raptor:\nRecursive abstractive processing for tree-organized retrieval. arXiv preprint arXiv:2401.18059 .\nScott, K. (2024). Behind the Tech. https:\/\/www .microsoft .com\/en-us\/behind-the-tech.\nShao, Z., Gong, Y ., Shen, Y ., Huang, M., Duan, N., and Chen, W. (2023). Enhancing retrieval-\naugmented large language models with iterative retrieval-generation synergy. arXiv preprint\narXiv:2305.15294 .\nSu, D., Xu, Y ., Yu, T., Sidd","chunk_id":"833e7d67dcd30790b26b71c9b5306f6b","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"MARTIN, S.","type":"PERSON","description":"Martin, S. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"BROWN, W. M.","type":"PERSON","description":"Brown, W. M. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"KLAVANS, R.","type":"PERSON","description":"Klavans, R. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"BOYACK, K.","type":"PERSON","description":"Boyack, K. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"SPIE CONFERENCE ON VISUALIZATION AND DATA ANALYSIS (VDA)","type":"EVENT","description":"The conference where the paper \"Openord: An open-source toolbox for large graph layout\" was presented","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"EVENT"},{"name":"MICROSOFT","type":"ORGANIZATION","description":"Microsoft is an organization that conducted a study on the impact of large language models on scientific discovery using GPT-4","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"ORGANIZATION"},{"name":"GPT-4","type":"TECHNOLOGY","description":"GPT-4 is a large language model used in Microsoft's study on scientific discovery","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"TECHNOLOGY"},{"name":"NEBULAGRAPH","type":"ORGANIZATION","description":"NebulaGraph is an organization that launched the industry-first graph RAG: Retrieval-augmented generation with LLM based on knowledge graphs","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"ORGANIZATION"},{"name":"GRAPH RAG","type":"TECHNOLOGY","description":"Graph RAG is a retrieval-augmented generation technology based on knowledge graphs launched by NebulaGraph","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"TECHNOLOGY"},{"name":"NEO4J","type":"ORGANIZATION","description":"Neo4J is an organization that developed Project NaLLM","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"ORGANIZATION"},{"name":"PROJECT NALLM","type":"TECHNOLOGY","description":"Project NaLLM is a project developed by Neo4J","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"TECHNOLOGY"},{"name":"NEWMAN, M. E.","type":"PERSON","description":"Newman, M. E. is the author of the paper \"Modularity and community structure in networks\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES","type":"PUBLICATION","description":"The journal where the paper \"Modularity and community structure in networks\" was published","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PUBLICATION"},{"name":"RAM, O.","type":"PERSON","description":"Ram, O. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"LEVINE, Y.","type":"PERSON","description":"Levine, Y. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"DALMEDIGOS, I.","type":"PERSON","description":"Dalmedigos, I. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"MUHLGAY, D.","type":"PERSON","description":"Muhlgay, D. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"SHASHUA, A.","type":"PERSON","description":"Shashua, A. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"LEYTON-BROWN, K.","type":"PERSON","description":"Leyton-Brown, K. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"SHOHAM, Y.","type":"PERSON","description":"Shoham, Y. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS","type":"PUBLICATION","description":"The journal where the paper \"In-context retrieval-augmented language models\" was published","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PUBLICATION"},{"name":"RANADE, P.","type":"PERSON","description":"Ranade, P. is an author of the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"JOSHI, A.","type":"PERSON","description":"Joshi, A. is an author of the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"SARTHI, P.","type":"PERSON","description":"Sarthi, P. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"ABDULLAH, S.","type":"PERSON","description":"Abdullah, S. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"TULI, A.","type":"PERSON","description":"Tuli, A. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"KHANNA, S.","type":"PERSON","description":"Khanna, S. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"GOLDIE, A.","type":"PERSON","description":"Goldie, A. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"MANNING, C. D.","type":"PERSON","description":"Manning, C. D. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"SCOTT, K.","type":"PERSON","description":"Scott, K. is associated with \"Behind the Tech\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"BEHIND THE TECH","type":"MEDIA","description":"Behind the Tech is a media platform associated with Scott, K.","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"MEDIA"},{"name":"SHAO, Z.","type":"PERSON","description":"Shao, Z. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"GONG, Y.","type":"PERSON","description":"Gong, Y. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"SHEN, Y.","type":"PERSON","description":"Shen, Y. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"HUANG, M.","type":"PERSON","description":"Huang, M. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"DUAN, N.","type":"PERSON","description":"Duan, N. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"CHEN, W.","type":"PERSON","description":"Chen, W. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PERSON"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is a preprint repository where several papers mentioned in the text were published","source_id":"833e7d67dcd30790b26b71c9b5306f6b","entity_type":"PUBLICATION"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"MARTIN, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Martin, S. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BROWN, W. M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brown, W. M. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KLAVANS, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Klavans, R. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BOYACK, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Boyack, K. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SPIE CONFERENCE ON VISUALIZATION AND DATA ANALYSIS (VDA)\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The conference where the paper \"Openord: An open-source toolbox for large graph layout\" was presented<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">EVENT<\/data>    <\/node>    <node id=\"MICROSOFT\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft is an organization that conducted a study on the impact of large language models on scientific discovery using GPT-4<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">GPT-4 is a large language model used in Microsoft's study on scientific discovery<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"NEBULAGRAPH\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">NebulaGraph is an organization that launched the industry-first graph RAG: Retrieval-augmented generation with LLM based on knowledge graphs<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Graph RAG is a retrieval-augmented generation technology based on knowledge graphs launched by NebulaGraph<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"NEO4J\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Neo4J is an organization that developed Project NaLLM<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"PROJECT NALLM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Project NaLLM is a project developed by Neo4J<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"NEWMAN, M. E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Newman, M. E. is the author of the paper \"Modularity and community structure in networks\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Modularity and community structure in networks\" was published<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"RAM, O.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ram, O. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LEVINE, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Levine, Y. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DALMEDIGOS, I.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dalmedigos, I. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MUHLGAY, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Muhlgay, D. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHASHUA, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shashua, A. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LEYTON-BROWN, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Leyton-Brown, K. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHOHAM, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shoham, Y. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"In-context retrieval-augmented language models\" was published<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"RANADE, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ranade, P. is an author of the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOSHI, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joshi, A. is an author of the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SARTHI, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sarthi, P. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ABDULLAH, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Abdullah, S. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TULI, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tuli, A. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KHANNA, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Khanna, S. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GOLDIE, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Goldie, A. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MANNING, C. D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Manning, C. D. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SCOTT, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Scott, K. is associated with \"Behind the Tech\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BEHIND THE TECH\">      <data key=\"d0\">MEDIA<\/data>      <data key=\"d1\">Behind the Tech is a media platform associated with Scott, K.<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">MEDIA<\/data>    <\/node>    <node id=\"SHAO, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shao, Z. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GONG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gong, Y. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHEN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shen, Y. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HUANG, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huang, M. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DUAN, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Duan, N. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHEN, W.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen, W. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is a preprint repository where several papers mentioned in the text were published<\/data>      <data key=\"d2\">833e7d67dcd30790b26b71c9b5306f6b<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <edge source=\"MARTIN, S.\" target=\"BROWN, W. M.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Martin, S. and Brown, W. M. co-authored the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"MARTIN, S.\" target=\"KLAVANS, R.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Martin, S. and Klavans, R. co-authored the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"MARTIN, S.\" target=\"BOYACK, K.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Martin, S. and Boyack, K. co-authored the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"BROWN, W. M.\" target=\"KLAVANS, R.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Brown, W. M. and Klavans, R. co-authored the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"BROWN, W. M.\" target=\"BOYACK, K.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Brown, W. M. and Boyack, K. co-authored the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"KLAVANS, R.\" target=\"BOYACK, K.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Klavans, R. and Boyack, K. co-authored the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"MICROSOFT\" target=\"GPT-4\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Microsoft conducted a study on the impact of large language models on scientific discovery using GPT-4<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"NEBULAGRAPH\" target=\"GRAPH RAG\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">NebulaGraph launched the industry-first graph RAG: Retrieval-augmented generation with LLM based on knowledge graphs<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"NEO4J\" target=\"PROJECT NALLM\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Neo4J developed Project NaLLM<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"NEWMAN, M. E.\" target=\"PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Newman, M. E. published the paper \"Modularity and community structure in networks\" in the Proceedings of the National Academy of Sciences<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"RAM, O.\" target=\"LEVINE, Y.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Ram, O. and Levine, Y. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"RAM, O.\" target=\"DALMEDIGOS, I.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Ram, O. and Dalmedigos, I. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"RAM, O.\" target=\"MUHLGAY, D.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Ram, O. and Muhlgay, D. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"RAM, O.\" target=\"SHASHUA, A.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Ram, O. and Shashua, A. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"RAM, O.\" target=\"LEYTON-BROWN, K.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Ram, O. and Leyton-Brown, K. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"RAM, O.\" target=\"SHOHAM, Y.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Ram, O. and Shoham, Y. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"LEVINE, Y.\" target=\"DALMEDIGOS, I.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Levine, Y. and Dalmedigos, I. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"LEVINE, Y.\" target=\"MUHLGAY, D.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Levine, Y. and Muhlgay, D. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"LEVINE, Y.\" target=\"SHASHUA, A.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Levine, Y. and Shashua, A. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"LEVINE, Y.\" target=\"LEYTON-BROWN, K.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Levine, Y. and Leyton-Brown, K. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"LEVINE, Y.\" target=\"SHOHAM, Y.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Levine, Y. and Shoham, Y. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"DALMEDIGOS, I.\" target=\"MUHLGAY, D.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Dalmedigos, I. and Muhlgay, D. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"DALMEDIGOS, I.\" target=\"SHASHUA, A.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Dalmedigos, I. and Shashua, A. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"DALMEDIGOS, I.\" target=\"LEYTON-BROWN, K.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Dalmedigos, I. and Leyton-Brown, K. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"DALMEDIGOS, I.\" target=\"SHOHAM, Y.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Dalmedigos, I. and Shoham, Y. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"MUHLGAY, D.\" target=\"SHASHUA, A.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Muhlgay, D. and Shashua, A. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"MUHLGAY, D.\" target=\"LEYTON-BROWN, K.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Muhlgay, D. and Leyton-Brown, K. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"MUHLGAY, D.\" target=\"SHOHAM, Y.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Muhlgay, D. and Shoham, Y. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"SHASHUA, A.\" target=\"LEYTON-BROWN, K.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Shashua, A. and Leyton-Brown, K. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"SHASHUA, A.\" target=\"SHOHAM, Y.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Shashua, A. and Shoham, Y. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"LEYTON-BROWN, K.\" target=\"SHOHAM, Y.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Leyton-Brown, K. and Shoham, Y. co-authored the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"RANADE, P.\" target=\"JOSHI, A.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Ranade, P. and Joshi, A. co-authored the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"SARTHI, P.\" target=\"ABDULLAH, S.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Sarthi, P. and Abdullah, S. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"SARTHI, P.\" target=\"TULI, A.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Sarthi, P. and Tuli, A. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"SARTHI, P.\" target=\"KHANNA, S.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Sarthi, P. and Khanna, S. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"SARTHI, P.\" target=\"GOLDIE, A.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Sarthi, P. and Goldie, A. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"SARTHI, P.\" target=\"MANNING, C. D.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Sarthi, P. and Manning, C. D. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"ABDULLAH, S.\" target=\"TULI, A.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Abdullah, S. and Tuli, A. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"ABDULLAH, S.\" target=\"KHANNA, S.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Abdullah, S. and Khanna, S. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"ABDULLAH, S.\" target=\"GOLDIE, A.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Abdullah, S. and Goldie, A. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"ABDULLAH, S.\" target=\"MANNING, C. D.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Abdullah, S. and Manning, C. D. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"TULI, A.\" target=\"KHANNA, S.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Tuli, A. and Khanna, S. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"TULI, A.\" target=\"GOLDIE, A.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Tuli, A. and Goldie, A. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>    <edge source=\"TULI, A.\" target=\"MANNING, C. D.\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Tuli, A. and Manning, C. D. co-authored the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d6\">833e7d67dcd30790b26b71c9b5306f6b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"8d87efac8c50cf20cdf26bf61e5e2035","chunk":", Huang, M., Duan, N., and Chen, W. (2023). Enhancing retrieval-\naugmented large language models with iterative retrieval-generation synergy. arXiv preprint\narXiv:2305.15294 .\nSu, D., Xu, Y ., Yu, T., Siddique, F. B., Barezi, E. J., and Fung, P. (2020). Caire-covid: A ques-\ntion answering and query-focused multi-document summarization system for covid-19 scholarly\ninformation management. arXiv preprint arXiv:2005.03975 .\nTang, Y . and Yang, Y . (2024). MultiHop-RAG: Benchmarking retrieval-augmented generation for\nmulti-hop queries. arXiv preprint arXiv:2401.15391 .\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y ., Bashlykov, N., Batra, S.,\nBhargava, P., Bhosale, S., et al. (2023). Llama 2: Open foundation and fine-tuned chat models.\narXiv preprint arXiv:2307.09288 .\nTraag, V . A., Waltman, L., and Van Eck, N. J. (2019). From Louvain to Leiden: guaranteeing\nwell-connected communities. Scientific Reports , 9(1).\nTrajanoska, M., Stojanov, R., and Trajanov, D. (2023). Enhancing knowledge graph construction\nusing large language models. ArXiv , abs\/2305.04676.\nTrivedi, H., Balasubramanian, N., Khot, T., and Sabharwal, A. (2022). Interleaving retrieval\nwith chain-of-thought reasoning for knowledge-intensive multi-step questions. arXiv preprint\narXiv:2212.10509 .\nWang, J., Liang, Y ., Meng, F., Sun, Z., Shi, H., Li, Z., Xu, J., Qu, J., and Zhou, J. (2023a). Is chatgpt\na good nlg evaluator? a preliminary study. arXiv preprint arXiv:2303.04048 .\nWang, S., Khramtsova","chunk_id":"8d87efac8c50cf20cdf26bf61e5e2035","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"HUANG, M.","type":"PERSON","description":"Huang, M. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"DUAN, N.","type":"PERSON","description":"Duan, N. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"CHEN, W.","type":"PERSON","description":"Chen, W. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is a repository where the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\" was published\narXiv is a repository where the paper \"Llama 2: Open foundation and fine-tuned chat models\" was published\narXiv is a repository where the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\" was published\narXiv is a repository where the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\" was published\narXiv is a repository where the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\" was published\narXiv is a repository where the paper \"Enhancing knowledge graph construction using large language models\" was published\narXiv is a repository where the paper \"Is chatgpt a good nlg evaluator? a preliminary study\" was published","source_id":"8d87efac8c50cf20cdf26bf61e5e2035","entity_type":"PUBLICATION"},{"name":"SU, D.","type":"PERSON","description":"Su, D. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"XU, Y.","type":"PERSON","description":"Xu, Y. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"YU, T.","type":"PERSON","description":"Yu, T. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"SIDDIQUE, F. B.","type":"PERSON","description":"Siddique, F. B. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"BAREZI, E. J.","type":"PERSON","description":"Barezi, E. J. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"FUNG, P.","type":"PERSON","description":"Fung, P. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"TANG, Y.","type":"PERSON","description":"Tang, Y. is an author of the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"YANG, Y.","type":"PERSON","description":"Yang, Y. is an author of the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"TOUVRON, H.","type":"PERSON","description":"Touvron, H. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"MARTIN, L.","type":"PERSON","description":"Martin, L. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"STONE, K.","type":"PERSON","description":"Stone, K. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"ALBERT, P.","type":"PERSON","description":"Albert, P. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"ALMAHAIRI, A.","type":"PERSON","description":"Almahairi, A. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"BABAEI, Y.","type":"PERSON","description":"Babaei, Y. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"BASHLYKOV, N.","type":"PERSON","description":"Bashlykov, N. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"BATRA, S.","type":"PERSON","description":"Batra, S. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"BHARGAVA, P.","type":"PERSON","description":"Bhargava, P. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"BHOSALE, S.","type":"PERSON","description":"Bhosale, S. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"TRAAG, V. A.","type":"PERSON","description":"Traag, V. A. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"WALTMAN, L.","type":"PERSON","description":"Waltman, L. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"VAN ECK, N. J.","type":"PERSON","description":"Van Eck, N. J. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"SCIENTIFIC REPORTS","type":"PUBLICATION","description":"Scientific Reports is the journal where the paper \"From Louvain to Leiden: guaranteeing well-connected communities\" was published","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"TRAJANOSKA, M.","type":"PERSON","description":"Trajanoska, M. is an author of the paper \"Enhancing knowledge graph construction using large language models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"STOJANOV, R.","type":"PERSON","description":"Stojanov, R. is an author of the paper \"Enhancing knowledge graph construction using large language models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"TRAJANOV, D.","type":"PERSON","description":"Trajanov, D. is an author of the paper \"Enhancing knowledge graph construction using large language models\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"TRIVEDI, H.","type":"PERSON","description":"Trivedi, H. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"BALASUBRAMANIAN, N.","type":"PERSON","description":"Balasubramanian, N. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"KHOT, T.","type":"PERSON","description":"Khot, T. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"SABHARWAL, A.","type":"PERSON","description":"Sabharwal, A. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"WANG, J.","type":"PERSON","description":"Wang, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"LIANG, Y.","type":"PERSON","description":"Liang, Y. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"MENG, F.","type":"PERSON","description":"Meng, F. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"SUN, Z.","type":"PERSON","description":"Sun, Z. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"SHI, H.","type":"PERSON","description":"Shi, H. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"LI, Z.","type":"PERSON","description":"Li, Z. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"XU, J.","type":"PERSON","description":"Xu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"QU, J.","type":"PERSON","description":"Qu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"ZHOU, J.","type":"PERSON","description":"Zhou, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"WANG, S.","type":"PERSON","description":"Wang, S. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"},{"name":"KHRAMTSOVA","type":"PERSON","description":"Khramtsova is an author mentioned in the text","source_id":"8d87efac8c50cf20cdf26bf61e5e2035"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"HUANG, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huang, M. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"DUAN, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Duan, N. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"CHEN, W.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen, W. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is a repository where the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\" was publishedarXiv is a repository where the paper \"Llama 2: Open foundation and fine-tuned chat models\" was publishedarXiv is a repository where the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\" was publishedarXiv is a repository where the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\" was publishedarXiv is a repository where the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\" was publishedarXiv is a repository where the paper \"Enhancing knowledge graph construction using large language models\" was publishedarXiv is a repository where the paper \"Is chatgpt a good nlg evaluator? a preliminary study\" was published<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"SU, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Su, D. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"XU, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu, Y. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"YU, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yu, T. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"SIDDIQUE, F. B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Siddique, F. B. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"BAREZI, E. J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Barezi, E. J. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"FUNG, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fung, P. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"TANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tang, Y. is an author of the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"YANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang, Y. is an author of the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"TOUVRON, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Touvron, H. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"MARTIN, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Martin, L. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"STONE, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Stone, K. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"ALBERT, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Albert, P. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"ALMAHAIRI, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Almahairi, A. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"BABAEI, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Babaei, Y. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"BASHLYKOV, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bashlykov, N. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"BATRA, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Batra, S. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"BHARGAVA, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bhargava, P. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"BHOSALE, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bhosale, S. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"TRAAG, V. A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Traag, V. A. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"WALTMAN, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Waltman, L. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"VAN ECK, N. J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Van Eck, N. J. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"SCIENTIFIC REPORTS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Scientific Reports is the journal where the paper \"From Louvain to Leiden: guaranteeing well-connected communities\" was published<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"TRAJANOSKA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Trajanoska, M. is an author of the paper \"Enhancing knowledge graph construction using large language models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"STOJANOV, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Stojanov, R. is an author of the paper \"Enhancing knowledge graph construction using large language models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"TRAJANOV, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Trajanov, D. is an author of the paper \"Enhancing knowledge graph construction using large language models\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"TRIVEDI, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Trivedi, H. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"BALASUBRAMANIAN, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Balasubramanian, N. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"KHOT, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Khot, T. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"SABHARWAL, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sabharwal, A. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"WANG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"LIANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liang, Y. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"MENG, F.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Meng, F. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"SUN, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sun, Z. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"SHI, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shi, H. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"LI, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li, Z. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"XU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"QU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"ZHOU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhou, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"WANG, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, S. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <node id=\"KHRAMTSOVA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Khramtsova is an author mentioned in the text<\/data>      <data key=\"d2\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/node>    <edge source=\"HUANG, M.\" target=\"DUAN, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Huang, M. and Duan, N. co-authored the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"HUANG, M.\" target=\"CHEN, W.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Huang, M. and Chen, W. co-authored the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"DUAN, N.\" target=\"CHEN, W.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Duan, N. and Chen, W. co-authored the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SU, D.\" target=\"XU, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Su, D. and Xu, Y. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SU, D.\" target=\"YU, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Su, D. and Yu, T. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SU, D.\" target=\"SIDDIQUE, F. B.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Su, D. and Siddique, F. B. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SU, D.\" target=\"BAREZI, E. J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Su, D. and Barezi, E. J. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SU, D.\" target=\"FUNG, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Su, D. and Fung, P. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"XU, Y.\" target=\"YU, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xu, Y. and Yu, T. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"XU, Y.\" target=\"SIDDIQUE, F. B.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xu, Y. and Siddique, F. B. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"XU, Y.\" target=\"BAREZI, E. J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xu, Y. and Barezi, E. J. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"XU, Y.\" target=\"FUNG, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xu, Y. and Fung, P. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"YU, T.\" target=\"SIDDIQUE, F. B.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yu, T. and Siddique, F. B. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"YU, T.\" target=\"BAREZI, E. J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yu, T. and Barezi, E. J. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"YU, T.\" target=\"FUNG, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yu, T. and Fung, P. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SIDDIQUE, F. B.\" target=\"BAREZI, E. J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Siddique, F. B. and Barezi, E. J. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SIDDIQUE, F. B.\" target=\"FUNG, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Siddique, F. B. and Fung, P. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"BAREZI, E. J.\" target=\"FUNG, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Barezi, E. J. and Fung, P. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"TANG, Y.\" target=\"YANG, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Tang, Y. and Yang, Y. co-authored the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"TOUVRON, H.\" target=\"MARTIN, L.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Touvron, H. and Martin, L. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"TOUVRON, H.\" target=\"STONE, K.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Touvron, H. and Stone, K. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"TOUVRON, H.\" target=\"ALBERT, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Touvron, H. and Albert, P. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"TOUVRON, H.\" target=\"ALMAHAIRI, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Touvron, H. and Almahairi, A. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"TOUVRON, H.\" target=\"BABAEI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Touvron, H. and Babaei, Y. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"TOUVRON, H.\" target=\"BASHLYKOV, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Touvron, H. and Bashlykov, N. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"TOUVRON, H.\" target=\"BATRA, S.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Touvron, H. and Batra, S. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"TOUVRON, H.\" target=\"BHARGAVA, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Touvron, H. and Bhargava, P. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"TOUVRON, H.\" target=\"BHOSALE, S.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Touvron, H. and Bhosale, S. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MARTIN, L.\" target=\"STONE, K.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Martin, L. and Stone, K. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MARTIN, L.\" target=\"ALBERT, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Martin, L. and Albert, P. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MARTIN, L.\" target=\"ALMAHAIRI, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Martin, L. and Almahairi, A. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MARTIN, L.\" target=\"BABAEI, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Martin, L. and Babaei, Y. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MARTIN, L.\" target=\"BASHLYKOV, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Martin, L. and Bashlykov, N. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MARTIN, L.\" target=\"BATRA, S.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Martin, L. and Batra, S. co-authored the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"WANG, J.\" target=\"LIANG, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, J. and Liang, Y. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"WANG, J.\" target=\"MENG, F.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, J. and Meng, F. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"WANG, J.\" target=\"SUN, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, J. and Sun, Z. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"WANG, J.\" target=\"SHI, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, J. and Shi, H. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"WANG, J.\" target=\"LI, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, J. and Li, Z. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"WANG, J.\" target=\"XU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, J. and Xu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"WANG, J.\" target=\"QU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, J. and Qu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"WANG, J.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, J. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"LIANG, Y.\" target=\"MENG, F.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Liang, Y. and Meng, F. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"LIANG, Y.\" target=\"SUN, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Liang, Y. and Sun, Z. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"LIANG, Y.\" target=\"SHI, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Liang, Y. and Shi, H. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"LIANG, Y.\" target=\"LI, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Liang, Y. and Li, Z. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"LIANG, Y.\" target=\"XU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Liang, Y. and Xu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"LIANG, Y.\" target=\"QU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Liang, Y. and Qu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"LIANG, Y.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Liang, Y. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MENG, F.\" target=\"SUN, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Meng, F. and Sun, Z. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MENG, F.\" target=\"SHI, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Meng, F. and Shi, H. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MENG, F.\" target=\"LI, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Meng, F. and Li, Z. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MENG, F.\" target=\"XU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Meng, F. and Xu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MENG, F.\" target=\"QU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Meng, F. and Qu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"MENG, F.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Meng, F. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SUN, Z.\" target=\"SHI, H.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Sun, Z. and Shi, H. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SUN, Z.\" target=\"LI, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Sun, Z. and Li, Z. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SUN, Z.\" target=\"XU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Sun, Z. and Xu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SUN, Z.\" target=\"QU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Sun, Z. and Qu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SUN, Z.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Sun, Z. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SHI, H.\" target=\"LI, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Shi, H. and Li, Z. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SHI, H.\" target=\"XU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Shi, H. and Xu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SHI, H.\" target=\"QU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Shi, H. and Qu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"SHI, H.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Shi, H. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"LI, Z.\" target=\"XU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, Z. and Xu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"LI, Z.\" target=\"QU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, Z. and Qu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"LI, Z.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, Z. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"XU, J.\" target=\"QU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xu, J. and Qu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"XU, J.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xu, J. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>    <edge source=\"QU, J.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Qu, J. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">8d87efac8c50cf20cdf26bf61e5e2035<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"fc4b27d64f055b7fc30176ba110dd02e","chunk":" H., Li, Z., Xu, J., Qu, J., and Zhou, J. (2023a). Is chatgpt\na good nlg evaluator? a preliminary study. arXiv preprint arXiv:2303.04048 .\nWang, S., Khramtsova, E., Zhuang, S., and Zuccon, G. (2024). Feb4rag: Evaluating federated search\nin the context of retrieval augmented generation. arXiv preprint arXiv:2402.11891 .\nWang, Y ., Lipka, N., Rossi, R. A., Siu, A., Zhang, R., and Derr, T. (2023b). Knowledge graph\nprompting for multi-document question answering.\nXu, Y . and Lapata, M. (2021). Text summarization with latent queries. arXiv preprint\narXiv:2106.00104 .\nYang, Z., Qi, P., Zhang, S., Bengio, Y ., Cohen, W. W., Salakhutdinov, R., and Manning, C. D. (2018).\nHotpotQA: A dataset for diverse, explainable multi-hop question answering. In Conference on\nEmpirical Methods in Natural Language Processing (EMNLP) .\nYao, J.-g., Wan, X., and Xiao, J. (2017). Recent advances in document summarization. Knowledge\nand Information Systems , 53:297\u2013336.\n14Yao, L., Peng, J., Mao, C., and Luo, Y . (2023). Exploring large language models for knowledge\ngraph completion.\nZhang, J. (2023). Graph-toolformer: To empower llms with graph reasoning ability via prompt\naugmented by chatgpt. arXiv preprint arXiv:2304.11116 .\nZhang, Y ., Zhang, Y ., Gan, Y ., Yao, L., and Wang, C. (2024). Causal graph discovery with retrieval-\naugmented generation based large language models. arXiv preprint arXiv:2402.15301 .\nZheng, L., Chiang, W.-L., Sheng, Y ., Zhuang, S., Wu, Z., Zhuang, Y ., Lin, Z., Li, Z., Li, D., Xing,\nE., et al. (202","chunk_id":"fc4b27d64f055b7fc30176ba110dd02e","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":512,"entities":[{"name":"H.","type":"PERSON","description":"H. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"LI, Z.","type":"PERSON","description":"Li, Z. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"XU, J.","type":"PERSON","description":"Xu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"QU, J.","type":"PERSON","description":"Qu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"ZHOU, J.","type":"PERSON","description":"Zhou, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is the platform where the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\" was published\narXiv is the platform where the paper \"Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt\" was published\narXiv is the platform where the paper \"Is chatgpt a good nlg evaluator? a preliminary study\" was published\narXiv is the platform where the paper \"Causal graph discovery with retrieval-augmented generation based large language models\" was published\narXiv is the platform where the paper \"Knowledge graph prompting for multi-document question answering\" was published\narXiv is the platform where the paper \"Text summarization with latent queries\" was published","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PUBLICATION"},{"name":"WANG, S.","type":"PERSON","description":"Wang, S. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"KHRAMTSOVA, E.","type":"PERSON","description":"Khramtsova, E. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"ZHUANG, S.","type":"PERSON","description":"Zhuang, S. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"ZUCCON, G.","type":"PERSON","description":"Zuccon, G. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"WANG, Y.","type":"PERSON","description":"Wang, Y. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"LIPKA, N.","type":"PERSON","description":"Lipka, N. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"ROSSI, R. A.","type":"PERSON","description":"Rossi, R. A. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"SIU, A.","type":"PERSON","description":"Siu, A. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"ZHANG, R.","type":"PERSON","description":"Zhang, R. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"DERR, T.","type":"PERSON","description":"Derr, T. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"XU, Y.","type":"PERSON","description":"Xu, Y. is an author of the paper \"Text summarization with latent queries\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"LAPATA, M.","type":"PERSON","description":"Lapata, M. is an author of the paper \"Text summarization with latent queries\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"YANG, Z.","type":"PERSON","description":"Yang, Z. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"QI, P.","type":"PERSON","description":"Qi, P. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"ZHANG, S.","type":"PERSON","description":"Zhang, S. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"BENGIO, Y.","type":"PERSON","description":"Bengio, Y. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"COHEN, W. W.","type":"PERSON","description":"Cohen, W. W. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"SALAKHUTDINOV, R.","type":"PERSON","description":"Salakhutdinov, R. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"MANNING, C. D.","type":"PERSON","description":"Manning, C. D. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"EMNLP","type":"CONFERENCE","description":"The conference where the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\" was presented","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"YAO, J.-G.","type":"PERSON","description":"Yao, J.-g. is an author of the paper \"Recent advances in document summarization\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"WAN, X.","type":"PERSON","description":"Wan, X. is an author of the paper \"Recent advances in document summarization\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"XIAO, J.","type":"PERSON","description":"Xiao, J. is an author of the paper \"Recent advances in document summarization\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"KNOWLEDGE AND INFORMATION SYSTEMS","type":"PUBLICATION","description":"The journal where the paper \"Recent advances in document summarization\" was published","source_id":"fc4b27d64f055b7fc30176ba110dd02e"},{"name":"YAO, L.","type":"PERSON","description":"Yao, L. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"\nYao, L. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"PENG, J.","type":"PERSON","description":"Peng, J. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"MAO, C.","type":"PERSON","description":"Mao, C. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"LUO, Y.","type":"PERSON","description":"Luo, Y. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"ZHANG, J.","type":"PERSON","description":"Zhang, J. is an author of the paper \"Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"ZHANG, Y.","type":"PERSON","description":"Zhang, Y. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"GAN, Y.","type":"PERSON","description":"Gan, Y. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"WANG, C.","type":"PERSON","description":"Wang, C. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"ZHENG, L.","type":"PERSON","description":"Zheng, L. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"CHIANG, W.-L.","type":"PERSON","description":"Chiang, W.-L. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"SHENG, Y.","type":"PERSON","description":"Sheng, Y. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"WU, Z.","type":"PERSON","description":"Wu, Z. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"ZHUANG, Y.","type":"PERSON","description":"Zhuang, Y. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"LIN, Z.","type":"PERSON","description":"Lin, Z. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"LI, D.","type":"PERSON","description":"Li, D. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"},{"name":"XING, E.","type":"PERSON","description":"Xing, E. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"fc4b27d64f055b7fc30176ba110dd02e","entity_type":"PERSON"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">H. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"LI, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li, Z. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"XU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"QU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"ZHOU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhou, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is the platform where the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\" was publishedarXiv is the platform where the paper \"Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt\" was publishedarXiv is the platform where the paper \"Is chatgpt a good nlg evaluator? a preliminary study\" was publishedarXiv is the platform where the paper \"Causal graph discovery with retrieval-augmented generation based large language models\" was publishedarXiv is the platform where the paper \"Knowledge graph prompting for multi-document question answering\" was publishedarXiv is the platform where the paper \"Text summarization with latent queries\" was published<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"WANG, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, S. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"KHRAMTSOVA, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Khramtsova, E. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"ZHUANG, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhuang, S. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"ZUCCON, G.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zuccon, G. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"WANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, Y. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"LIPKA, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lipka, N. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"ROSSI, R. A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rossi, R. A. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"SIU, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Siu, A. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"ZHANG, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang, R. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"DERR, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Derr, T. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"XU, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu, Y. is an author of the paper \"Text summarization with latent queries\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"LAPATA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lapata, M. is an author of the paper \"Text summarization with latent queries\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"YANG, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang, Z. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"QI, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qi, P. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"ZHANG, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang, S. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"BENGIO, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bengio, Y. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"COHEN, W. W.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cohen, W. W. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"SALAKHUTDINOV, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Salakhutdinov, R. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"MANNING, C. D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Manning, C. D. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"EMNLP\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\" was presented<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"YAO, J.-G.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yao, J.-g. is an author of the paper \"Recent advances in document summarization\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"WAN, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wan, X. is an author of the paper \"Recent advances in document summarization\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"XIAO, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiao, J. is an author of the paper \"Recent advances in document summarization\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"KNOWLEDGE AND INFORMATION SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Recent advances in document summarization\" was published<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/node>    <node id=\"YAO, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yao, L. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"Yao, L. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PENG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peng, J. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MAO, C.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mao, C. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LUO, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luo, Y. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHANG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang, J. is an author of the paper \"Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang, Y. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GAN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gan, Y. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WANG, C.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, C. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHENG, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zheng, L. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHIANG, W.-L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chiang, W.-L. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHENG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sheng, Y. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WU, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wu, Z. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHUANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhuang, Y. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIN, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lin, Z. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LI, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li, D. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XING, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xing, E. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">fc4b27d64f055b7fc30176ba110dd02e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <edge source=\"H.\" target=\"LI, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">H. and Li, Z. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"H.\" target=\"XU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">H. and Xu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"H.\" target=\"QU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">H. and Qu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"H.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">H. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"LI, Z.\" target=\"XU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, Z. and Xu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"LI, Z.\" target=\"QU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, Z. and Qu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"LI, Z.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, Z. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"XU, J.\" target=\"QU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xu, J. and Qu, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"XU, J.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xu, J. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"QU, J.\" target=\"ZHOU, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Qu, J. and Zhou, J. co-authored the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"WANG, S.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, S. published the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"KHRAMTSOVA, E.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Khramtsova, E. published the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ZHUANG, S.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zhuang, S. published the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ZUCCON, G.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zuccon, G. published the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"WANG, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, Y. published the paper \"Knowledge graph prompting for multi-document question answering\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"LIPKA, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lipka, N. published the paper \"Knowledge graph prompting for multi-document question answering\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ROSSI, R. A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Rossi, R. A. published the paper \"Knowledge graph prompting for multi-document question answering\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"SIU, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Siu, A. published the paper \"Knowledge graph prompting for multi-document question answering\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ZHANG, R.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zhang, R. published the paper \"Knowledge graph prompting for multi-document question answering\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"DERR, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Derr, T. published the paper \"Knowledge graph prompting for multi-document question answering\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"XU, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xu, Y. published the paper \"Text summarization with latent queries\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"LAPATA, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lapata, M. published the paper \"Text summarization with latent queries\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ZHANG, J.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zhang, J. published the paper \"Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ZHANG, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zhang, Y. published the paper \"Causal graph discovery with retrieval-augmented generation based large language models\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"GAN, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gan, Y. published the paper \"Causal graph discovery with retrieval-augmented generation based large language models\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"YAO, L.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yao, L. published the paper \"Causal graph discovery with retrieval-augmented generation based large language models\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"WANG, C.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, C. published the paper \"Causal graph discovery with retrieval-augmented generation based large language models\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ZHENG, L.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zheng, L. published the paper \"Exploring large language models for knowledge graph completion\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"CHIANG, W.-L.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Chiang, W.-L. published the paper \"Exploring large language models for knowledge graph completion\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"SHENG, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Sheng, Y. published the paper \"Exploring large language models for knowledge graph completion\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"WU, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wu, Z. published the paper \"Exploring large language models for knowledge graph completion\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"ZHUANG, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zhuang, Y. published the paper \"Exploring large language models for knowledge graph completion\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"LIN, Z.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lin, Z. published the paper \"Exploring large language models for knowledge graph completion\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"LI, D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Li, D. published the paper \"Exploring large language models for knowledge graph completion\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ARXIV\" target=\"XING, E.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xing, E. published the paper \"Exploring large language models for knowledge graph completion\" on arXiv<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"WANG, S.\" target=\"KHRAMTSOVA, E.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, S. and Khramtsova, E. co-authored the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"WANG, S.\" target=\"ZHUANG, S.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, S. and Zhuang, S. co-authored the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"WANG, S.\" target=\"ZUCCON, G.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, S. and Zuccon, G. co-authored the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"KHRAMTSOVA, E.\" target=\"ZHUANG, S.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Khramtsova, E. and Zhuang, S. co-authored the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"KHRAMTSOVA, E.\" target=\"ZUCCON, G.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Khramtsova, E. and Zuccon, G. co-authored the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ZHUANG, S.\" target=\"ZUCCON, G.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zhuang, S. and Zuccon, G. co-authored the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"WANG, Y.\" target=\"LIPKA, N.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, Y. and Lipka, N. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"WANG, Y.\" target=\"ROSSI, R. A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, Y. and Rossi, R. A. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"WANG, Y.\" target=\"SIU, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, Y. and Siu, A. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"WANG, Y.\" target=\"ZHANG, R.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, Y. and Zhang, R. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"WANG, Y.\" target=\"DERR, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Wang, Y. and Derr, T. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"LIPKA, N.\" target=\"ROSSI, R. A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lipka, N. and Rossi, R. A. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"LIPKA, N.\" target=\"SIU, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lipka, N. and Siu, A. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"LIPKA, N.\" target=\"ZHANG, R.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lipka, N. and Zhang, R. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"LIPKA, N.\" target=\"DERR, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Lipka, N. and Derr, T. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ROSSI, R. A.\" target=\"SIU, A.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Rossi, R. A. and Siu, A. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ROSSI, R. A.\" target=\"ZHANG, R.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Rossi, R. A. and Zhang, R. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ROSSI, R. A.\" target=\"DERR, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Rossi, R. A. and Derr, T. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"SIU, A.\" target=\"ZHANG, R.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Siu, A. and Zhang, R. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"SIU, A.\" target=\"DERR, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Siu, A. and Derr, T. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"ZHANG, R.\" target=\"DERR, T.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zhang, R. and Derr, T. co-authored the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"XU, Y.\" target=\"LAPATA, M.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Xu, Y. and Lapata, M. co-authored the paper \"Text summarization with latent queries\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"YANG, Z.\" target=\"QI, P.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yang, Z. and Qi, P. co-authored the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"YANG, Z.\" target=\"ZHANG, S.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yang, Z. and Zhang, S. co-authored the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"YANG, Z.\" target=\"BENGIO, Y.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yang, Z. and Bengio, Y. co-authored the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"YANG, Z.\" target=\"COHEN, W. W.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yang, Z. and Cohen, W. W. co-authored the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"YANG, Z.\" target=\"SALAKHUTDINOV, R.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yang, Z. and Salakhutdinov, R. co-authored the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>    <edge source=\"YANG, Z.\" target=\"MANNING, C. D.\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Yang, Z. and Manning, C. D. co-authored the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d6\">fc4b27d64f055b7fc30176ba110dd02e<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"b1bbda43309e8e0e2175ea034aa88e13","chunk":"Xiv:2402.15301 .\nZheng, L., Chiang, W.-L., Sheng, Y ., Zhuang, S., Wu, Z., Zhuang, Y ., Lin, Z., Li, Z., Li, D., Xing,\nE., et al. (2024). Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural\nInformation Processing Systems , 36.\n15","chunk_id":"b1bbda43309e8e0e2175ea034aa88e13","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":95,"entities":[{"name":"ZHENG, L.","type":"PERSON","description":"Zheng, L. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"CHIANG, W.-L.","type":"PERSON","description":"Chiang, W.-L. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"SHENG, Y.","type":"PERSON","description":"Sheng, Y. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"ZHUANG, S.","type":"PERSON","description":"Zhuang, S. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"WU, Z.","type":"PERSON","description":"Wu, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"ZHUANG, Y.","type":"PERSON","description":"Zhuang, Y. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"LIN, Z.","type":"PERSON","description":"Lin, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"LI, Z.","type":"PERSON","description":"Li, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"LI, D.","type":"PERSON","description":"Li, D. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"XING, E.","type":"PERSON","description":"Xing, E. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS","type":"PUBLICATION","description":"The journal where the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\" was published","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"MT-BENCH","type":"TECHNOLOGY","description":"MT-Bench is a benchmarking tool used in the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"},{"name":"CHATBOT ARENA","type":"TECHNOLOGY","description":"Chatbot Arena is a platform or tool used in the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"b1bbda43309e8e0e2175ea034aa88e13"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ZHENG, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zheng, L. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"CHIANG, W.-L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chiang, W.-L. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"SHENG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sheng, Y. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"ZHUANG, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhuang, S. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"WU, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wu, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"ZHUANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhuang, Y. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"LIN, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lin, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"LI, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"LI, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li, D. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"XING, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xing, E. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\" was published<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"MT-BENCH\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">MT-Bench is a benchmarking tool used in the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <node id=\"CHATBOT ARENA\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Chatbot Arena is a platform or tool used in the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/node>    <edge source=\"ZHENG, L.\" target=\"CHIANG, W.-L.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. and Chiang, W.-L. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHENG, L.\" target=\"SHENG, Y.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. and Sheng, Y. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHENG, L.\" target=\"ZHUANG, S.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. and Zhuang, S. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHENG, L.\" target=\"WU, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. and Wu, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHENG, L.\" target=\"ZHUANG, Y.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. and Zhuang, Y. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHENG, L.\" target=\"LIN, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. and Lin, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHENG, L.\" target=\"LI, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. and Li, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHENG, L.\" target=\"LI, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. and Li, D. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHENG, L.\" target=\"XING, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. and Xing, E. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHENG, L.\" target=\"MT-BENCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. is an author of the paper that discusses MT-Bench<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHENG, L.\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zheng, L. is an author of the paper that discusses Chatbot Arena<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"CHIANG, W.-L.\" target=\"SHENG, Y.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chiang, W.-L. and Sheng, Y. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"CHIANG, W.-L.\" target=\"ZHUANG, S.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chiang, W.-L. and Zhuang, S. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"CHIANG, W.-L.\" target=\"WU, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chiang, W.-L. and Wu, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"CHIANG, W.-L.\" target=\"ZHUANG, Y.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chiang, W.-L. and Zhuang, Y. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"CHIANG, W.-L.\" target=\"LIN, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chiang, W.-L. and Lin, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"CHIANG, W.-L.\" target=\"LI, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chiang, W.-L. and Li, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"CHIANG, W.-L.\" target=\"LI, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chiang, W.-L. and Li, D. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"CHIANG, W.-L.\" target=\"XING, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chiang, W.-L. and Xing, E. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"CHIANG, W.-L.\" target=\"MT-BENCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chiang, W.-L. is an author of the paper that discusses MT-Bench<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"CHIANG, W.-L.\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Chiang, W.-L. is an author of the paper that discusses Chatbot Arena<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"SHENG, Y.\" target=\"ZHUANG, S.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sheng, Y. and Zhuang, S. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"SHENG, Y.\" target=\"WU, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sheng, Y. and Wu, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"SHENG, Y.\" target=\"ZHUANG, Y.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sheng, Y. and Zhuang, Y. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"SHENG, Y.\" target=\"LIN, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sheng, Y. and Lin, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"SHENG, Y.\" target=\"LI, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sheng, Y. and Li, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"SHENG, Y.\" target=\"LI, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sheng, Y. and Li, D. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"SHENG, Y.\" target=\"XING, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sheng, Y. and Xing, E. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"SHENG, Y.\" target=\"MT-BENCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sheng, Y. is an author of the paper that discusses MT-Bench<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"SHENG, Y.\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Sheng, Y. is an author of the paper that discusses Chatbot Arena<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, S.\" target=\"WU, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, S. and Wu, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, S.\" target=\"ZHUANG, Y.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, S. and Zhuang, Y. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, S.\" target=\"LIN, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, S. and Lin, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, S.\" target=\"LI, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, S. and Li, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, S.\" target=\"LI, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, S. and Li, D. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, S.\" target=\"XING, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, S. and Xing, E. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, S.\" target=\"MT-BENCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, S. is an author of the paper that discusses MT-Bench<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, S.\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, S. is an author of the paper that discusses Chatbot Arena<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"WU, Z.\" target=\"ZHUANG, Y.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Wu, Z. and Zhuang, Y. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"WU, Z.\" target=\"LIN, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Wu, Z. and Lin, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"WU, Z.\" target=\"LI, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Wu, Z. and Li, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"WU, Z.\" target=\"LI, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Wu, Z. and Li, D. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"WU, Z.\" target=\"XING, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Wu, Z. and Xing, E. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"WU, Z.\" target=\"MT-BENCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Wu, Z. is an author of the paper that discusses MT-Bench<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"WU, Z.\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Wu, Z. is an author of the paper that discusses Chatbot Arena<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, Y.\" target=\"LIN, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, Y. and Lin, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, Y.\" target=\"LI, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, Y. and Li, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, Y.\" target=\"LI, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, Y. and Li, D. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, Y.\" target=\"XING, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, Y. and Xing, E. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, Y.\" target=\"MT-BENCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, Y. is an author of the paper that discusses MT-Bench<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"ZHUANG, Y.\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Zhuang, Y. is an author of the paper that discusses Chatbot Arena<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LIN, Z.\" target=\"LI, Z.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Lin, Z. and Li, Z. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LIN, Z.\" target=\"LI, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Lin, Z. and Li, D. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LIN, Z.\" target=\"XING, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Lin, Z. and Xing, E. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LIN, Z.\" target=\"MT-BENCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Lin, Z. is an author of the paper that discusses MT-Bench<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LIN, Z.\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Lin, Z. is an author of the paper that discusses Chatbot Arena<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LI, Z.\" target=\"LI, D.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, Z. and Li, D. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LI, Z.\" target=\"XING, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, Z. and Xing, E. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LI, Z.\" target=\"MT-BENCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, Z. is an author of the paper that discusses MT-Bench<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LI, Z.\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, Z. is an author of the paper that discusses Chatbot Arena<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LI, D.\" target=\"XING, E.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, D. and Xing, E. co-authored the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LI, D.\" target=\"MT-BENCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, D. is an author of the paper that discusses MT-Bench<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"LI, D.\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Li, D. is an author of the paper that discusses Chatbot Arena<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"XING, E.\" target=\"MT-BENCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Xing, E. is an author of the paper that discusses MT-Bench<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"XING, E.\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Xing, E. is an author of the paper that discusses Chatbot Arena<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>    <edge source=\"MT-BENCH\" target=\"CHATBOT ARENA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">MT-Bench and Chatbot Arena are both tools used in the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d5\">b1bbda43309e8e0e2175ea034aa88e13<\/data>    <\/edge>  <\/graph><\/graphml>"}
