<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d6" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d5" for="edge" attr.name="description" attr.type="string" />
  <key id="d4" for="edge" attr.name="weight" attr.type="double" />
  <key id="d3" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d2" for="node" attr.name="source_id" attr.type="string" />
  <key id="d1" for="node" attr.name="description" attr.type="string" />
  <key id="d0" for="node" attr.name="type" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="DARREN EDGE">
      <data key="d0">PERSON</data>
      <data key="d1">Darren Edge is one of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="HA TRINH">
      <data key="d0">PERSON</data>
      <data key="d1">Ha Trinh is one of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="NEWMAN CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Newman Cheng is one of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="JOSHUA BRADLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Bradley is one of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="ALEX CHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Chao is one of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="APURVA MODY">
      <data key="d0">PERSON</data>
      <data key="d1">Apurva Mody is one of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="STEVEN TRUITT">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Truitt is one of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="JONATHAN LARSON">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Larson is one of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="MICROSOFT RESEARCH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Research is a prominent organization affiliated with the authors of several influential papers in the field of Artificial Intelligence and Machine Learning. Notably, it is the affiliation of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization," which explores advanced techniques in query-focused summarization using a graph-based approach. Additionally, Microsoft Research is the organization where the authors of the paper "AgentInstruct: Toward Generative Teaching with Agentic Flows" are affiliated, indicating its significant contributions to the development of generative teaching methodologies. These affiliations highlight Microsoft Research's pivotal role in advancing AI and ML research through innovative and impactful studies.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Strategic Missions and Technologies is one of the affiliations of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="MICROSOFT OFFICE OF THE CTO">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Office of the CTO is one of the affiliations of the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="GRAPH RAG">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Graph RAG is a method that leverages a graph-based approach to enhance the comprehensiveness and diversity of responses. It utilizes graph communities to answer user queries, offering different levels of community summaries. This system provides scalability advantages in summarization by requiring fewer context tokens and enabling efficient iterative question answering while maintaining comprehensiveness and diversity. Graph RAG is also employed to generate detailed lists of public figures and their contributions across various entertainment sectors. The approach is based on the global summarization of an LLM-derived knowledge graph, focusing on the natural modularity of graphs and community detection algorithms to partition data for effective summarization. Additionally, Graph RAG scales with both the generality of user questions and the quantity of source text to be indexed, making it a versatile tool for question answering over private text corpora.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Retrieval-augmented generation (RAG) is a method that retrieves relevant information from an external knowledge source to enable large language models (LLMs) to answer questions over private and/or previously unseen document collections</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Query-focused summarization (QFS) is a task that generates natural language summaries based on specific user queries, rather than just retrieving relevant text excerpts</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Large language models (LLMs) are advanced AI models capable of understanding and generating human-like text, used in various applications including question answering and summarization</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="LEIDEN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Leiden is a community detection algorithm mentioned in the text, renowned for its ability to partition graphs into modular communities of closely-related nodes. It is utilized to partition graph indexes into groups of elements that can be summarized in parallel, thereby enhancing computational efficiency. Additionally, Leiden excels in recovering the hierarchical community structure of large-scale graphs, making it a powerful tool for analyzing complex networks and understanding the intricate relationships within communities.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="KLEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Klein is an author referenced in the context of sensemaking and understanding connections among people, places, and events</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="LEWIS">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis is an author mentioned in the text, contributing significantly to the development of memory structures and retrieval-augmented generation (RAG). He is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks," published in Advances in Neural Information Processing Systems in 2020. His work is associated with external memory and RAG, highlighting his influence in the field of knowledge-intensive natural language processing tasks.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c932f7def033fa2b1bf210fbb771e7d,6bdf681c0bd9e401ac72344a6a0ae479,c3d0436082aada237ee4bee645f16059,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="DANG">
      <data key="d0">PERSON</data>
      <data key="d1">Dang is an author referenced in the context of query-focused summarization (QFS)</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="BAUMEL">
      <data key="d0">PERSON</data>
      <data key="d1">Baumel is an author referenced in the context of query-focused abstractive summarization</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="LASKAR">
      <data key="d0">PERSON</data>
      <data key="d1">Laskar is an author referenced in the context of query-focused abstractive summarization. Laskar is one of the authors mentioned in the text, associated with summarization tasks in 2022. Additionally, Laskar is one of the authors of the paper titled "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models," which was published in the Advances in Artificial Intelligence: 33rd Canadian Conference on Artificial Intelligence in 2020.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yao is an author who has made significant contributions to the fields of chain-of-thought planning and reasoning, query-focused abstractive summarization, and the development of various prompting techniques. Yao's work includes advancements in chain-of-thought (CoT) prompting, search algorithms, and tree-of-thought (ToT) prompting. Additionally, Yao has contributed to multiple methods such as ToT, ReAct, and IL+RL, and has been involved in the development of datasets and methods like WebShop and Game of 24. Yao has also explored the use of large language models (LLMs) for knowledge graph completion and has co-authored several notable papers, including "Recent advances in document summarization" (2017), "Exploring large language models for knowledge graph completion" (2023), and "Causal graph discovery with retrieval-augmented generation based large language models" (2024).</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c932f7def033fa2b1bf210fbb771e7d,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="GOODWIN">
      <data key="d0">PERSON</data>
      <data key="d1">Goodwin is an author referenced in the context of transformer architecture improvements in summarization tasks. Specifically, Goodwin is one of the authors mentioned in the text, associated with summarization tasks in 2020.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Liu is an author mentioned in the text who has made significant contributions to various research areas within the field of Artificial Intelligence and Machine Learning. Liu's work spans agentic systems, transformer architecture improvements in summarization tasks, and the exploration of text-based environments and acting-based prompting techniques for language models. Notably, Liu has investigated the effects of context window size and the issue of information loss in longer contexts. Liu has also contributed to the development of DyLAN in 2023 and has worked on combining search algorithms with language model agents, as well as previous search approaches using language models as world models. Liu is one of the authors of several influential papers, including "Lost in the middle: How language models use long contexts" (2023), "Generation-augmented retrieval for open-domain question answering" (2020), and "Hierarchical transformers for multi-document summarization" (2019), all published on arXiv.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,42de130f5b6144472a86a4c8260a87c7,4884e8429ca1e567dadf5e22b4b68274,64476a39d7d8b87b399e3bd3cead79c7,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,c95e02c0dca4a4a36b701cbc7dd14da6,dc55f071b95dec721a9820d39cdb3ccd,df50c95dff7da074cbb2f68e88686f88,ede7063998065122cf7a7152979c1909,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LAPATA">
      <data key="d0">PERSON</data>
      <data key="d1">Lapata is an author prominently referenced in the field of summarization tasks, particularly in the context of transformer architecture improvements. In 2019, Lapata co-authored a paper titled "Hierarchical transformers for multi-document summarization," which was published on arXiv. Additionally, Lapata has worked on methods for extracting latent summarization queries from source texts, as evidenced by the 2021 paper titled "Text summarization with latent queries." These contributions highlight Lapata's significant role in advancing summarization techniques within the AI and ML communities.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT is a Foundation Model developed by OpenAI, recognized as a powerful general-purpose agent. It is a series of Large Language Models (LLMs) that have been referenced in the context of modern LLMs, which trivialize various summarization tasks. GPT is particularly noted for its capability to use in-context learning to effectively summarize content.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="LLAMA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLAMA is a series of Large Language Models (LLMs) referenced in the context of modern LLMs trivializing various summarization tasks. These models are capable of using in-context learning to effectively summarize content, showcasing their advanced capabilities in natural language processing.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="GEMINI">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Gemini is a family of highly capable multimodal models, referenced in the context of modern Large Language Models (LLMs). These models are particularly noted for their proficiency in using in-context learning to summarize content, effectively trivializing various summarization tasks.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SENSEMAKING">
      <data key="d0" />
      <data key="d1">Sensemaking is defined as a motivated, continuous effort to understand connections among people, places, and events in order to anticipate their trajectories and act effectively</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="TRANSFORMER ARCHITECTURE">
      <data key="d0" />
      <data key="d1">Transformer architecture is a type of neural network architecture that has shown substantial improvements in various summarization tasks</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="MICROSOFT">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft is the company affiliated with the authors of the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization." It is also the organization behind Azure, which provides various AI-related services, including transparency notes. In 2023, Microsoft conducted the study titled "The impact of large language models on scientific discovery: a preliminary study using GPT-4" and published the technical report "ChatGPT for robotics: Design principles and model abilities" in February 2023.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,34d0bb2211fc795fe1096442e086a2b3,dd9a46950237e49ef9b1c7ef08e08d42,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="RANADE">
      <data key="d0">PERSON</data>
      <data key="d1">Ranade is an author referenced in the context of intelligence analysis and sensemaking. They have contributed to the development of FABULA, a system where retrieved event-plot subgraphs are serialized using narrative templates. Ranade is also one of the authors of the paper titled "Fabula: Intelligence report generation using retrieval-augmented narrative construction," which was published on arXiv in 2023.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Joshi is an author referenced in the context of intelligence analysis and sensemaking. Joshi has worked on FABULA, a system where retrieved event-plot subgraphs are serialized using narrative templates. Additionally, Joshi is one of the authors of the paper titled "Fabula: Intelligence report generation using retrieval-augmented narrative construction," which was published on arXiv in 2023.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="KLEIN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Klein et al. are authors referenced in the context of sensemaking and understanding connections among people, places, and events</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="TRAAG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Traag et al. are authors referenced in the context of community detection using the Leiden algorithm</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="ACHIAM ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Achiam et al. are authors referenced in the context of the GPT large language model</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="BROWN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Brown et al. are authors referenced in the context of the GPT large language model. They are noted for their significant contributions to the field of language models, as highlighted in various academic papers.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,93cb0d0456e0822b5fe30a3e627405f8,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TOUVRON ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Touvron et al. are authors referenced in the context of the Llama large language model. They are noted for their contributions to the field of language models, as highlighted in their referenced paper.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="ANIL ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Anil et al. are authors referenced in the context of the Gemini large language model</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="ACHIAM">
      <data key="d0">PERSON</data>
      <data key="d1">Achiam is one of the authors mentioned in the text, associated with the GPT series in 2023</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="BROWN">
      <data key="d0">PERSON</data>
      <data key="d1">Brown is an author who has significantly contributed to the research on in-context learning abilities of language models, particularly in the context of the GPT series in 2020. Brown's work has been pivotal in advancing the understanding and development of in-context learning for large language models (LLMs).</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,c95e02c0dca4a4a36b701cbc7dd14da6,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TOUVRON">
      <data key="d0">PERSON</data>
      <data key="d1">Touvron is one of the authors mentioned in the text, associated with the Llama series in 2023. Specifically, Touvron is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," published in 2023.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ANIL">
      <data key="d0">PERSON</data>
      <data key="d1">Anil is one of the authors mentioned in the text, associated with the Gemini series in 2023</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="KURATOV">
      <data key="d0">PERSON</data>
      <data key="d1">Kuratov is an author who has worked on the effects of context window size and is associated with the issue of information loss in longer contexts in 2024. He is one of the authors of the paper titled "In search of needles in a 11m haystack: Recurrent memory finds what LLMs miss," published in 2024.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,df50c95dff7da074cbb2f68e88686f88,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="RAG">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">RAG (Retrieval-Augmented Generation) is a skill that boosts the capacity of language models to generate informed, contextually precise responses. It involves retrieving relevant information from external data sources and adding it to the context window of the LLM along with the original query. RAG is a building block used in agentic systems within the LangChain framework and is employed for query-focused summarization tasks. This technique enhances model performance by incorporating retrieved documents into their responses. Additionally, RAG is mentioned as a potential building block for ADAS and is one of the general capabilities that can be taught to an LLM using AgentInstruct.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,64476a39d7d8b87b399e3bd3cead79c7,6bdf681c0bd9e401ac72344a6a0ae479,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="NEWMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Newman is an author prominently mentioned in the context of graph modularity, particularly in the year 2006. He is the author of the influential paper titled "Modularity and community structure in networks," which was published in the Proceedings of the National Academy of Sciences in 2006. This work is significant in the study of network science and has contributed to the understanding of community structures within complex networks.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LOUVAIN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Louvain is a community detection algorithm mentioned in the text, used to partition graphs into modular communities of closely-related nodes</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="BLONDEL">
      <data key="d0">PERSON</data>
      <data key="d1">Blondel is one of the authors mentioned in the text, associated with the Louvain algorithm in 2008</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="TRAAG">
      <data key="d0">PERSON</data>
      <data key="d1">Traag is an author who significantly contributed to the development of the Leiden algorithm in 2019. Traag is one of the authors mentioned in the text, associated with the Leiden algorithm, and co-authored the paper titled "From Louvain to Leiden: guaranteeing well-connected communities," published in 2019.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HOTPOTQA">
      <data key="d0">DATASET</data>
      <data key="d1">HotPotQA is a comprehensive benchmark dataset designed for open-domain question answering, specifically targeting explicit fact retrieval. It is widely used to evaluate various aspects of language models and algorithms, including entity extraction with gpt-4-turbo, the performance of the LATS algorithm, and reasoning-based prompting results. HotPotQA is particularly notable for its requirement of multi-hop reasoning, necessitating retrieval over two or more Wikipedia passages to answer questions. The dataset comprises 113,000 question-answer pairs based on Wikipedia, crafted by crowdworkers to ensure diversity, multi-hop complexity, and explainability. It is employed in empirical evaluations to demonstrate the effectiveness of decision-making and reasoning strategies, compare the cost and performance of different methods, and test internal reasoning and external retrieval strategies. HotPotQA serves as a critical tool for measuring the performance of LATS and its baseline variants, with evaluations often based on Exact Match (EM) metrics.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,4930fce6da868f894757a9da465807ba,594449768ae2dea9b2efbe677075096b,64476a39d7d8b87b399e3bd3cead79c7,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yang is an author who has made significant contributions to the field of multi-hop question answering and retrieval-augmented generation. In 2018, Yang co-authored the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering," which introduced the HotPotQA dataset, a benchmark for multi-hop question-answering. In 2024, Yang continued to advance the field by contributing to the MultiHop-RAG dataset and co-authoring the paper "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries." Additionally, Yang has worked on ADAS methods focusing on designing prompts and has been involved in the development of the OPRO framework. Yang's work spans several key datasets and methodologies, highlighting their role as a pivotal figure in the AI and ML research community.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,81c504ffbcc5ed882e234802135295ba,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,dc55f071b95dec721a9820d39cdb3ccd,e66ed885a08f92cc69f4895302c33047,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="MAP-REDUCE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Map-Reduce is an approach mentioned in the text, used for query-focused summarization of an entire corpus by summarizing community summaries in parallel</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="PODCAST TRANSCRIPTS">
      <data key="d0">DATASET</data>
      <data key="d1">Podcast transcripts are compiled records of podcast conversations, serving as a dataset for evaluating sensemaking questions. These written records of spoken content from podcasts are often used as data sources in media coverage. Additionally, podcast transcripts are one of the real-world datasets utilized to generate activity-centered sense-making questions, highlighting their importance in both media analysis and research contexts.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="NEWS ARTICLES">
      <data key="d0">DATASET</data>
      <data key="d1">The "NEWS ARTICLES" dataset is a benchmark collection comprising various categories of news published over a decade. It is utilized for evaluating sensemaking questions and generating activity-centered sense-making questions. These news articles are written pieces that report on current events and topics, including those related to public figures and entertainment. This real-world dataset serves as a valuable resource for analyzing and understanding the dynamics of news reporting and its impact on public perception.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="COMPREHENSIVENESS">
      <data key="d0">QUALITY</data>
      <data key="d1">Comprehensiveness is a metric that measures the extent to which information is complete and covers all relevant aspects of a topic. It evaluates the completeness and detail of answers, ensuring that all aspects and details of a question are thoroughly addressed. In the context of the Graph RAG approach, comprehensiveness is one of the target qualities for evaluating the thoroughness of summaries.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DIVERSITY">
      <data key="d0">QUALITY</data>
      <data key="d1">Diversity is a metric that measures how varied and rich an answer is in providing different perspectives and insights on a question. It is used to evaluate the variety of answers and is one of the target qualities for evaluating the Graph RAG approach, focusing on the variety of perspectives in the summaries. Additionally, diversity refers to the inclusion of a wide range of different perspectives, sectors, and individuals in media coverage.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="EMPOWERMENT">
      <data key="d0">QUALITY</data>
      <data key="d1">Empowerment is a metric that measures how well an answer helps the reader understand and make informed judgments about a topic. It is used to evaluate the degree to which answers enable further action or understanding. Empowerment is one of the target qualities for evaluating the Graph RAG approach, focusing on the ability to develop understanding of broad issues and themes. Comparisons of empowerment showed mixed results for both global approaches versus na&#239;ve RAG and Graph RAG approaches versus source text summarization. Additionally, empowerment refers to the process of providing individuals with the information and tools they need to make informed decisions.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="GRAPH RAG APPROACH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Graph RAG Approach is a method that involves the high-level data flow and pipeline for global summarization using graph indexes</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="TEXT CHUNKS">
      <data key="d0">DATA</data>
      <data key="d1">Text chunks are segments of input texts extracted from source documents, used for processing in the Graph RAG approach. They are the split parts of documents that are embedded into a vector space in na&#239;ve RAG approaches.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="ELEMENT INSTANCES">
      <data key="d0">DATA</data>
      <data key="d1">Element instances are descriptions of entities, relationships, and claims extracted from source texts by large language models (LLMs). They are instances of graph nodes and edges extracted from text chunks in the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="NAMED ENTITIES">
      <data key="d0">DATA</data>
      <data key="d1">Named entities are a broad class of entities, including people, places, and organizations, that are extracted from text using Large Language Model (LLM) prompts. These specific types of entities are identified and categorized to facilitate the analysis and understanding of textual data.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="FEW-SHOT EXAMPLES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Few-Shot Examples are specialized examples used in various experiments to evaluate different methods, such as on a subset of 100 questions for HotPotQA. They are particularly useful in training or prompting large language models (LLMs) in domains requiring specialized knowledge, including science, medicine, and law. Additionally, few-shot examples are employed in LLM prompts for in-context learning, tailored to the specific domain of the document corpus.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="IN-CONTEXT LEARNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">In-context learning is a capability of modern language models, including GPT, Llama, and Gemini, that allows them to learn from the context provided in the input without additional training. This method enables these models to summarize any content provided in their context window. Additionally, in-context learning is leveraged by Learning Agent Trajectory Synthesis (LATS) to refine the agent and value function by integrating failed trajectories and corresponding reflections as additional context.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,64476a39d7d8b87b399e3bd3cead79c7,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="PRE-INDEXING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Pre-indexing is an alternative form of indexing mentioned as a potential support for a new RAG approach targeting global summarization</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="KNOWLEDGE GRAPH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A knowledge graph is a structured representation of knowledge, utilized in the Graph RAG approach for global summarization. It serves as an index in advanced Retrieval-Augmented Generation (RAG) systems such as KAPING, enhancing the efficiency and accuracy of information retrieval and summarization processes.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="COMMUNITY DETECTION ALGORITHMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Community detection algorithms are used to partition a graph into communities of nodes with stronger connections to each other. These algorithms identify modular communities of closely-related nodes, facilitating the understanding of the structure and dynamics within complex networks. Notable examples of such algorithms include Louvain and Leiden, which are widely recognized for their efficiency and effectiveness in detecting community structures in large-scale graphs.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Activity-centered sense-making questions are generated from short descriptions of datasets to evaluate the Graph RAG approach</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="SOURCE DOCUMENTS">
      <data key="d0">DATA</data>
      <data key="d1">Source documents are the original texts from which input texts are extracted and split into text chunks for processing in the Graph RAG approach</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LLM PROMPTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM prompts are used to extract various elements of a graph index from text chunks in the Graph RAG approach</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="RECALL">
      <data key="d0">QUALITY</data>
      <data key="d1">Recall is a quality metric that needs to be balanced with precision in the extraction process of the Graph RAG approach</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="PRECISION">
      <data key="d0">QUALITY</data>
      <data key="d1">Precision is a quality metric that needs to be balanced with recall in the extraction process of the Graph RAG approach</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="DOMAIN-SPECIFIC KNOWLEDGE">
      <data key="d0">DATA</data>
      <data key="d1">Domain-specific knowledge refers to specialized knowledge in fields like science, medicine, and law, which can benefit from tailored few-shot examples in LLM prompts</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="COVARIATES">
      <data key="d0">DATA</data>
      <data key="d1">Covariates are additional variables that can be associated with extracted node instances in the Graph RAG approach. They are linked attributes or variables associated with nodes and edges within a community structure, described and prioritized in the context window.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LLM-DEBATE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM-Debate is a state-of-the-art hand-designed agent baseline for experiments on ARC. It is a system that enables different Large Language Models (LLMs) to debate with each other to leverage diverse perspectives and find better answers. In this system, each debate module is assigned a unique role, such as Physics Expert or Chemistry Expert, and the debate lasts for two rounds.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,97457e990eb6e3c88c11c862f9e3265b,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="QUALITY-DIVERSITY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Quality-Diversity, referenced by Lu et al., 2024c, is a state-of-the-art, manually designed agent used for comparison in various studies. It is a simplified version of Intelligent Go-Explore, designed to produce and ensemble diverse answers to better explore potential solutions. This agent performs tasks such as Math, Reading Comprehension, Multi-task, and Science, and serves as a baseline for experiments on ARC. The system operates through three iterations to collect diverse answers based on previously proposed ones, enhancing its ability to explore and solve complex problems.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="INTELLIGENT GO-EXPLORE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Intelligent Go-Explore is a system described in the paper "Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models," published on arXiv in 2024. This system is designed to explore potential solutions by producing and combining diverse answers, leveraging the capabilities of advanced foundation models to enhance its exploratory processes.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,1b1399c76420a477c0c97893d258ae69,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="META AGENT SEARCH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Meta Agent Search is a method that progressively discovers high-performance agents based on an ever-growing archive of previous discoveries. It uses various baselines as initial seeds in the archive to iteratively program new agents, consistently outperforming state-of-the-art hand-designed baselines. This method employs GPT-4 as the meta agent and GPT-3.5 for the discovered agents and baselines, running for 25 iterations to evaluate agents on the ARC challenge. Meta Agent Search is an algorithm in ADAS that enables the complete design of agentic systems in code space, adopting foundational models (FMs) as meta agents to iteratively create and evaluate new agents, thereby enhancing their performance on diverse tasks, including non-math domains.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,103d98395c393552cc954c89d4e59f50,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,2901d5e2711fa4f32d39cd8eea36cd71,357f3442ba581c9d2bdf84d90509056f,449db721e37968e073e3579b59e023b2,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,ab04427ae0415a1c812a35cf8d3ee1a2,ac21ebe9a9d70d691c717f961d3f10c8,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937,dc55f071b95dec721a9820d39cdb3ccd,dd9a46950237e49ef9b1c7ef08e08d42,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="FALDOR">
      <data key="d0">PERSON</data>
      <data key="d1">Faldor is an author who has significantly contributed to research in OMNI-EPIC and open-endedness algorithms, particularly in the year 2024. Their work encompasses discussions and advancements in both OMNI-EPIC and AI-Generative Algorithms (AI-GAs), highlighting their expertise and influence in these areas of artificial intelligence.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,594449768ae2dea9b2efbe677075096b,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,ab04427ae0415a1c812a35cf8d3ee1a2,dc55f071b95dec721a9820d39cdb3ccd,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="LEHMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Lehman is an author mentioned in the text who has worked on open-endedness and AI-GAs.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,594449768ae2dea9b2efbe677075096b,6bdf681c0bd9e401ac72344a6a0ae479,ab04427ae0415a1c812a35cf8d3ee1a2,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="STANLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Stanley is an author mentioned in the text who has worked on open-endedness and AI-GAs.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,594449768ae2dea9b2efbe677075096b,6bdf681c0bd9e401ac72344a6a0ae479,ab04427ae0415a1c812a35cf8d3ee1a2,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Wang is an author extensively involved in various cutting-edge research areas within the field of Artificial Intelligence and Machine Learning. Wang has contributed significantly to the development of agentic systems, particularly the COT-SC state-of-the-art hand-designed agent and its variants, such as chain-of-thought (CoT) prompting for reasoning in language models. Additionally, Wang has worked on self-consistency in language models, Meta-RL, and POET, as well as evaluating natural language generation and retrieval-augmented generation (RAG) systems. Wang's research also includes federated retrieval-generation (FeB4RAG), multi-hop question answering, open-endedness, and AI-generative algorithms (AI-GAs). Notably, Wang is one of the authors of the Phi-3 technical report, which discusses a highly capable language model that can operate locally on a phone, and the paper titled "Causal graph discovery with retrieval-augmented generation based large language models," both published in 2024.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,26b2dad01a219bc034ac7d6a32d07582,2901d5e2711fa4f32d39cd8eea36cd71,594449768ae2dea9b2efbe677075096b,7c08d98f503d722d7de13be55375c8cb,ab04427ae0415a1c812a35cf8d3ee1a2,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,cc20c99cad8edecc66b82ac751ff7172,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,e66ed885a08f92cc69f4895302c33047,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="LLM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM (Large Language Model) is a type of artificial intelligence model designed to understand and generate human language. It powers agents in various flows and is capable of using tools like search APIs, code interpreters, or calculators. LLMs are used for natural language processing tasks and can generate assessments and responses in different contexts. They are also employed in tasks such as debating, content transformation, and API synthesis.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,427e98b00e49b6a8f8649054122dd45b,c8e8019de153e439d6a79dcf209b943b,e66ed885a08f92cc69f4895302c33047,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CLAIMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Claims are statements linked to detected entities, including attributes like subject, object, type, description, source text span, and start and end dates</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LOGIT BIAS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Logit bias is a technique used to force a yes/no decision in LLMs during the entity extraction process</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ELEMENT SUMMARIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Element summaries are single blocks of descriptive text for each graph element, created by further summarizing instance-level summaries</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="GRAPH COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Graph communities are groups of nodes in a graph that have stronger connections to one another than to other nodes, detected using community detection algorithms</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="FORTUNATO">
      <data key="d0">PERSON</data>
      <data key="d1">Fortunato is an author who has conducted surveys on community detection algorithms</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="JIN">
      <data key="d0">PERSON</data>
      <data key="d1">Jin is an author who has conducted surveys on community detection algorithms</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="MULTIHOP-RAG">
      <data key="d0">DATASET</data>
      <data key="d1">MultiHop-RAG is a benchmark dataset of news articles used for evaluating sensemaking questions, published by Tang and Yang in 2024. It serves multiple purposes, including indexing and graph community detection. Additionally, MultiHop-RAG is a system designed for benchmarking retrieval-augmented generation for multi-hop queries, making it a versatile tool in the field of AI and ML for assessing and improving the performance of complex information retrieval and generation tasks.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Tang is an author who has significantly contributed to the field of retrieval-augmented generation, particularly through their work on the MultiHop-RAG dataset. In 2024, Tang co-authored the paper titled "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries," which has been instrumental in advancing the understanding and development of multi-hop query processing.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="OPENORD">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">OpenORD is a node layout algorithm used for visualizing graph communities</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="FORCE ATLAS 2">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Force Atlas 2 is a node layout algorithm used for visualizing graph communities</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="MARTIN">
      <data key="d0">PERSON</data>
      <data key="d1">Martin is an author who has made significant contributions to the field of Artificial Intelligence and Machine Learning. In 2011, Martin played a pivotal role in the development of the OpenORD algorithm, showcasing his expertise in algorithm design and optimization. More recently, in 2023, Martin co-authored the influential paper titled "Llama 2: Open foundation and fine-tuned chat models," further cementing his position as a key contributor to advancements in AI and ML. Through these works, Martin has demonstrated a consistent ability to drive innovation and contribute valuable insights to the community.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="JACOMY">
      <data key="d0">PERSON</data>
      <data key="d1">Jacomy is an author who contributed to the development of the Force Atlas 2 algorithm in 2014</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LEAF-LEVEL COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Leaf-level communities are the most granular level of graph communities, representing the smallest units within a hierarchical community structure. In these communities, element summaries of nodes, edges, and covariates are prioritized and iteratively added to the LLM context window until the token limit is reached. This process ensures that the most detailed and specific information is included, providing a comprehensive understanding of the intricate relationships and dynamics within these communities.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="NODE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A node represents an entity in a graph, characterized by attributes such as degree, which indicates its prominence. Additionally, in the context of tree search, a node signifies a state that encapsulates the original input, action sequence, and observation sequence.</data>
      <data key="d2">c234cb83764b899335af0950677ad024,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="EDGE">
      <data key="d0">CONCEPT</data>
      <data key="d1">An edge represents a relationship between two nodes in a graph, with weights indicating the strength of the relationship</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="COVARIATE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A covariate is an additional variable associated with nodes and edges in a graph, used for more detailed analysis</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="EXTRACTION PROMPT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">An extraction prompt is used to extract specific types of information, such as named entities or covariates, from text</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="COVARIATE PROMPT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A covariate prompt is used to extract additional variables associated with detected entities, such as claims</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="GLEANINGS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Gleanings are multiple rounds of extraction used to detect any additional entities that may have been missed in prior rounds</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LOGIT BIAS OF 100">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A logit bias of 100 is used to force a yes/no decision in LLMs during the entity extraction process</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="YES/NO DECISION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A yes/no decision is a binary choice used to determine if all entities were extracted</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="CONTINUATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A continuation is a follow-up prompt used to encourage the LLM to glean missing entities</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="CHUNK SIZES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chunk sizes refer to the amount of text processed in each round of extraction to balance efficiency and quality</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="NOISE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Noise refers to irrelevant or extraneous information that can be introduced during the extraction process</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Abstractive Summarization is a task for language models to generate independently meaningful summaries of concepts implied but not explicitly stated by the text. This method is evaluated using metrics such as hallucinations and quality, ensuring that the generated summaries are both accurate and coherent.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="INSTANCE-LEVEL SUMMARIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Instance-level summaries are initial summaries of entities, relationships, and claims extracted from text</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="DUPLICATE ENTITY ELEMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Duplicate entity elements are multiple references to the same entity in different formats, which can result in duplicate nodes in the entity graph</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ENTITY GRAPH">
      <data key="d0">CONCEPT</data>
      <data key="d1">An entity graph is a graph structure where nodes represent entities and edges represent relationships between them</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="CLOSELY-RELATED COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Closely-related communities are groups of entities with strong connections to each other, detected and summarized to handle variations in entity names</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="GLOBAL, QUERY-FOCUSED SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Global, query-focused summarization is a method that uses rich descriptive text for nodes in a graph to answer global queries</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="KNOWLEDGE GRAPHS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Knowledge graphs are graph structures that rely on concise and consistent knowledge triples for reasoning tasks</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HOMOGENEOUS UNDIRECTED WEIGHTED GRAPH">
      <data key="d0">CONCEPT</data>
      <data key="d1">A homogeneous undirected weighted graph is a type of graph where nodes are connected by edges with weights representing the strength of relationships</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="EDGE WEIGHTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Edge weights are values that represent the normalized counts of detected relationship instances between nodes in a graph</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Hierarchical community structure is a multi-level organization of graph communities, where each level provides a partition of the nodes</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HIERARCHICAL PARTITION">
      <data key="d0">CONCEPT</data>
      <data key="d1">A hierarchical partition is a division of graph nodes into mutually-exclusive, collectively-exhaustive communities at different levels</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="DIVIDE-AND-CONQUER GLOBAL SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Divide-and-conquer global summarization is a method that uses hierarchical community structure to enable efficient summarization of large datasets</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="REPORT-LIKE SUMMARIES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Report-like summaries are detailed summaries of each community in a graph, useful for understanding the global structure and semantics of the dataset</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ROOT COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Root communities are the top-level communities in a hierarchical community structure, corresponding to the partition with maximum modularity</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="SUB-COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Sub-communities are lower-level communities within root communities, revealing internal structure</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HIGHER-LEVEL COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Higher-level communities are larger units within a hierarchical community structure, where element summaries are summarized and ranked to fit within the context window if they exceed the token limit</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="COMMUNITY SUMMARIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Community summaries are a kind of self-memory for generation-augmented retrieval in Graph RAG. They are generated descriptions of elements within a community, used to answer user queries in a multi-stage process. These summaries are created at different levels of a graph community hierarchy, providing a structured and hierarchical understanding of the community's elements and their relationships.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="GLOBAL ANSWER">
      <data key="d0">CONCEPT</data>
      <data key="d1">The global answer is the final response generated from community summaries to answer a user query, ensuring a balance of summary detail and scope</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="KEVIN SCOTT">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin Scott is the CTO of Microsoft and a participant in the podcast conversations compiled in the podcast transcripts dataset</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="MT-BENCH">
      <data key="d0">DATASET</data>
      <data key="d1">MT-Bench is a benchmark dataset designed to evaluate the performance of various models, including Orca-3 and other baselines, in open-domain question answering and multi-turn conversations. It targets explicit fact retrieval and assesses the competence of chat assistants by evaluating model responses to first-turn and second-turn queries, scoring each turn from 1 to 10 using GPT-4 as the evaluator. Published in 2023, MT-Bench provides a comprehensive framework for assessing the capabilities of AI models in handling complex conversational dynamics.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,4930fce6da868f894757a9da465807ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="KOESTEN">
      <data key="d0">PERSON</data>
      <data key="d1">KOESTEN is an author who has made significant contributions to the field of data sensemaking. Notably, Koesten is one of the authors of the paper titled "Talking datasets&#8211;understanding data sensemaking behaviours," which was published in the International Journal of Human-Computer Studies in 2021. This work delves into the processes and behaviors associated with making sense of data, highlighting Koesten's expertise and influence in this area of study.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="XU">
      <data key="d0">PERSON</data>
      <data key="d1">Xu is an author who has made significant contributions to the field of artificial intelligence and machine learning, particularly in the areas of role assignment and text summarization. Xu is associated with the state-of-the-art hand-designed agent for Role Assignment and has demonstrated the benefits of assigning personas or roles to agents in 2023. Xu has also worked on methods for extracting latent summarization queries from source texts. Notably, Xu is one of the authors of several influential papers, including "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management" published in 2020, "Text summarization with latent queries" published in 2021, and "Is chatgpt a good nlg evaluator? a preliminary study" published in 2023. Xu's work has been referenced in the context of Role Assignment techniques and baselines, highlighting their impact on the field.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,4930fce6da868f894757a9da465807ba,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,dc55f071b95dec721a9820d39cdb3ccd,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="DATA SENSEMAKING">
      <data key="d0" />
      <data key="d1">Data sensemaking is the process through which people inspect, engage with, and contextualize data within the broader scope of real-world activities</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="NODES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Nodes are components in search algorithms that store and retrieve external feedback, playing a crucial role in LATS (Learning and Adaptive Systems). Additionally, nodes are elements within a community structure that are described and prioritized in the context window based on their degree of prominence. This dual functionality highlights the importance of nodes in both algorithmic processes and community dynamics, making them essential for understanding and optimizing complex systems.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="EDGES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Edges are connections between nodes within a community structure, described and prioritized in the context window based on their degree of prominence</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="COMMUNITY ANSWERS">
      <data key="d0">CONCEPT</data>
      <data key="d1">COMMUNITY ANSWERS are generated in parallel from community summaries in Graph RAG. These intermediate responses are scored for helpfulness and used to form the global answer.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="USER">
      <data key="d0">CONCEPT</data>
      <data key="d1">The USER is an individual or entity interacting with the system to generate queries and receive answers based on community summaries. This individual engages with the system or dataset to perform tasks or gain information. Specifically, the USER interacts with the AI assistant to achieve specific goals such as creating a meal plan, tracking meals, getting food recommendations, and updating food item details.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,26b2dad01a219bc034ac7d6a32d07582,4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="TECH JOURNALIST">
      <data key="d0">PERSON</data>
      <data key="d1">A tech journalist is a user looking for insights and trends in the tech industry, particularly regarding tech policy and regulation</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="EDUCATOR">
      <data key="d0">PERSON</data>
      <data key="d1">An educator is a user incorporating current affairs into curricula, particularly focusing on health and wellness</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="BEHIND THE TECH">
      <data key="d0">DATASET</data>
      <data key="d1">Behind the Tech is a podcast series featuring conversations between Kevin Scott and other technology leaders, compiled into the podcast transcripts dataset</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="SCOTT">
      <data key="d0">PERSON</data>
      <data key="d1">Scott is an author who compiled the podcast transcripts dataset, featuring conversations with technology leaders. Additionally, Scott is the author of the document titled "Behind the Tech," published in 2024.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SENSEMAKING QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Sensemaking questions are queries generated to evaluate the effectiveness of RAG systems for global understanding of dataset contents</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="RAG SYSTEMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">RAG systems are retrieval-augmented generation systems used for answering sensemaking questions by summarizing large datasets</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="PRIVACY LAWS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Privacy laws are regulations discussed by guests in the podcast transcripts, focusing on their impact on technology development</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="INNOVATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Innovation is a concept discussed by guests in the podcast transcripts, particularly in relation to ethical considerations and policy</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="ETHICAL CONSIDERATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Ethical considerations are discussed by guests in the podcast transcripts, particularly in relation to innovation and policy</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="POLICIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Policies are regulations and guidelines discussed by guests in the podcast transcripts, with suggestions for changes</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="COLLABORATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Collaborations between tech companies and governments are discussed by guests in the podcast transcripts</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="HEALTH EDUCATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Health education is a topic discussed in news articles, focusing on integrating current health topics into curricula</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="PREVENTIVE MEDICINE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Preventive medicine is a concept addressed in news articles, focusing on wellness and health education</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="PUBLIC HEALTH">
      <data key="d0">CONCEPT</data>
      <data key="d1">Public health is a priority discussed in news articles, providing insights for health education</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="HEALTH LITERACY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Health literacy is a concept highlighted in news articles, emphasizing its importance in health education</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="ROOT-LEVEL COMMUNITIES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="DATASET">
      <data key="d0">DATA</data>
      <data key="d1">A dataset is a collection of data, often used for analysis or training machine learning models. The term "dataset" is general and refers to the various datasets employed for evaluating language models.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="TASK">
      <data key="d0">ACTIVITY</data>
      <data key="d1">A task is an activity or piece of work that a user performs, often involving interaction with a dataset or system.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="QUESTION">
      <data key="d0">INFORMATION</data>
      <data key="d1">A question is a query or inquiry made to gain information, test knowledge, or assess comprehension. It is often used in various contexts such as evaluating the correctness of a trajectory in a question-answering task, understanding a dataset, or refining complexity based on a passage. In educational settings, a question serves as a prompt provided to the student, which is used along with the student&#8217;s response to extract the selected option in the evaluation of Multiple Choice Questions or to solve a given problem.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,1d8835c0ce90e56be22873bcf2740a5d,26b2dad01a219bc034ac7d6a32d07582,357f3442ba581c9d2bdf84d90509056f,5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">INFORMATION</data>
    </node>
    <node id="TEXT SUMMARIZATION (TS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Text Summarization (TS) is a method that applies a map-reduce approach directly to source texts to create summaries</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="SEMANTIC SEARCH (SS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Semantic Search (SS) is a naive RAG approach where text chunks are retrieved and added to the context window until a token limit is reached</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="CONTEXT WINDOW">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The CONTEXT WINDOW is a segment of text used by a model to generate answers or perform tasks, with a specified token limit. It is the part of the Large Language Model (LLM) where relevant information and the original query are added in Retrieval-Augmented Generation (RAG) approaches.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="PODCAST DATASET">
      <data key="d0">DATA</data>
      <data key="d1">The Podcast dataset is a collection of podcast data, including podcast transcripts, used for analysis and evaluation in the study.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="NEWS DATASET">
      <data key="d0">DATA</data>
      <data key="d1">The News dataset is a collection of news articles used for analysis and evaluation in the study.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DIRECTNESS">
      <data key="d0">METRIC</data>
      <data key="d1">Directness is a metric that measures how specifically and clearly an answer addresses a question. It is used to evaluate the straightforwardness of answers, ensuring that information is presented with clarity and conciseness, directly addressing the topic or question at hand.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="LLM EVALUATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">An LLM evaluator is a Large Language Model used to assess the quality of generated answers based on specific metrics</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="RAGAS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">RAGAS is a system designed for the automated evaluation of Retrieval Augmented Generation (RAG) systems. It assesses various qualities such as context relevance, faithfulness, and answer relevance, ensuring that the generated content meets high standards of accuracy and pertinence.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zheng is an author who has made significant contributions to the field of artificial intelligence and machine learning. Zheng is notably associated with the Step-back Abstraction state-of-the-art hand-designed agent and has been referenced in research related to this technique in 2023. Additionally, Zheng has contributed to evaluating natural language generation and retrieval-augmented generation (RAG) systems. Zheng is also one of the authors of the paper titled "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena," published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,26b2dad01a219bc034ac7d6a32d07582,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="PUBLIC FIGURE">
      <data key="d0">PERSON</data>
      <data key="d1">A public figure is an individual who is well-known and often mentioned in various entertainment articles due to their significant contributions and influence</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ENTERTAINMENT INDUSTRY">
      <data key="d0">INDUSTRY</data>
      <data key="d1">The entertainment industry encompasses film, television, music, sports, and digital media, and includes various public figures who influence cultural narratives and trends</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ACTIVITY-CENTERED APPROACH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">An activity-centered approach is a method used to automate the generation of questions based on a short description of a dataset</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="N">
      <data key="d0">INFORMATION</data>
      <data key="d1">N is a parameter in LATS that represents the visit counter for states. Additionally, N is a variable representing the number of potential users, tasks per user, or questions generated per (user, task) combination.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="TABLE 1">
      <data key="d0">INFORMATION</data>
      <data key="d1">TABLE 1 provides a comprehensive overview of the 17 different skills implemented in the described workflows. Additionally, TABLE 1 includes example questions for each of the two evaluation datasets, offering a detailed insight into the practical applications and assessment criteria used in the study.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CONDITION">
      <data key="d0">INFORMATION</data>
      <data key="d1">A condition is a specific setup or method used in the analysis, such as Graph RAG, text summarization, or semantic search</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="C0">
      <data key="d0">INFORMATION</data>
      <data key="d1">C0 is a condition used in the study, representing root-level community summaries. It utilizes these summaries to answer user queries, providing insights into the structure and dynamics of AI and ML communities.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C1">
      <data key="d0">INFORMATION</data>
      <data key="d1">C1 is a condition that utilizes high-level community summaries to answer user queries, which are sub-communities of C0. Additionally, C1 is employed in studies to represent intermediate-level community summaries.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C2">
      <data key="d0">INFORMATION</data>
      <data key="d1">C2 is a condition that uses intermediate-level community summaries to answer user queries, which are sub-communities of C1. Additionally, C2 is a condition used in the study, representing low-level community summaries.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C3">
      <data key="d0">INFORMATION</data>
      <data key="d1">C3 is a condition used in the study, representing the lowest level of community summaries. It utilizes low-level community summaries to answer user queries, which are sub-communities of C2.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="SUBSECTION 2.6">
      <data key="d0">INFORMATION</data>
      <data key="d1">Subsection 2.6 describes the method used for text summarization, where source texts are shuffled and chunked for the map-reduce summarization stages</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="CONTEXT INFORMATION">
      <data key="d0">INFORMATION</data>
      <data key="d1">Context information refers to the types of data used in the context window for answer generation</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="GRAPH INDEX">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A graph index is a structure created using generic prompts for entity and relationship extraction, tailored to the domain of the data</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="CONTEXT WINDOW SIZE">
      <data key="d0">INFORMATION</data>
      <data key="d1">CONTEXT WINDOW SIZE refers to the number of tokens considered in a single context window for the graph indexing process. It is tested at various sizes, including 8k, 16k, 32k, and 64k, to determine the optimal number of tokens used in the context window.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="GLEANING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Gleaning is a process used in the graph indexing method to extract relevant information from the dataset</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="METRIC">
      <data key="d0">INFORMATION</data>
      <data key="d1">A metric is a standard of measurement used to evaluate the quality of generated answers, such as comprehensiveness, diversity, empowerment, and directness</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="HEAD-TO-HEAD COMPARISON">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Head-to-head comparison is an approach where an LLM evaluator assesses pairs of answers based on specific metrics to determine which is better</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="TABLE 2">
      <data key="d0">INFORMATION</data>
      <data key="d1">Table 2 shows an example of LLM-generated assessment</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ANSWER">
      <data key="d0">INFORMATION</data>
      <data key="d1">An answer is a response generated to address a question, evaluated based on metrics like comprehensiveness, diversity, empowerment, and directness. In the context of coding, "Answer" is a variable used to store the final solution obtained from the code. Within the HotPotQA framework, "Answer" represents the final response to a question. It is also the final solution to the original problem after integrating sub-problem solutions, often generated by the Chain-of-Thought module.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,b8dd0300033963bb4a3e1bad37f8e7b9,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="PROMINENT PUBLIC FIGURES">
      <data key="d0">PERSON</data>
      <data key="d1">Prominent public figures are key individuals repeatedly mentioned in various entertainment articles due to their significant contributions and influence</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ACTORS AND DIRECTORS">
      <data key="d0">PERSON</data>
      <data key="d1">Actors and directors are public figures in the entertainment industry known for their work in film and television</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="MUSICIANS AND EXECUTIVES">
      <data key="d0">PERSON</data>
      <data key="d1">Musicians and executives are public figures in the entertainment industry known for their contributions to music and the business side of the industry</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ATHLETES AND COACHES">
      <data key="d0">PERSON</data>
      <data key="d1">Athletes and coaches are public figures in the entertainment industry known for their involvement in sports</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="INFLUENCERS AND ENTREPRENEURS">
      <data key="d0">PERSON</data>
      <data key="d1">Influencers and entrepreneurs are public figures in the entertainment industry known for their impact on digital media and business ventures</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PUBLIC FIGURES">
      <data key="d0">GROUP</data>
      <data key="d1">Public figures are individuals who are well-known in society and often covered in media, including those involved in controversies</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MUSICIANS">
      <data key="d0">GROUP</data>
      <data key="d1">Musicians are individuals who create and perform music</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="EXECUTIVES">
      <data key="d0">GROUP</data>
      <data key="d1">Executives are individuals who hold high-level management positions in organizations, often within the entertainment industry</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ATHLETES">
      <data key="d0">GROUP</data>
      <data key="d1">Athletes are individuals who compete in sports</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="COACHES">
      <data key="d0">GROUP</data>
      <data key="d1">Coaches are individuals who train and guide athletes or sports teams</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="INFLUENCERS">
      <data key="d0">GROUP</data>
      <data key="d1">Influencers are individuals who have the power to affect the purchasing decisions of others because of their authority, knowledge, position, or relationship with their audience</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTREPRENEURS">
      <data key="d0">GROUP</data>
      <data key="d1">Entrepreneurs are individuals who create and manage businesses, often within the entertainment and digital media sectors</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TAYLOR SWIFT">
      <data key="d0">PERSON</data>
      <data key="d1">Taylor Swift is a musician and public figure frequently mentioned in entertainment articles for her professional achievements and personal life</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TRAVIS KELCE">
      <data key="d0">PERSON</data>
      <data key="d1">Travis Kelce is an athlete and public figure frequently mentioned in entertainment articles for his professional achievements and personal life</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="BRITNEY SPEARS">
      <data key="d0">PERSON</data>
      <data key="d1">Britney Spears is a musician and public figure frequently mentioned in entertainment articles for her professional achievements and personal life</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="JUSTIN TIMBERLAKE">
      <data key="d0">PERSON</data>
      <data key="d1">Justin Timberlake is a musician and public figure frequently mentioned in entertainment articles for his professional achievements and personal life</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTERTAINMENT ARTICLES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Entertainment articles are written pieces that cover various aspects of the entertainment industry, including the activities and lives of public figures</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MEDIA COVERAGE">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Media coverage refers to the reporting and discussion of events, activities, and individuals in the media</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PUBLIC INTEREST">
      <data key="d0">CONCEPT</data>
      <data key="d1">Public interest refers to the level of attention and concern that the general public has towards certain topics, events, or individuals</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="CULTURAL NARRATIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Cultural narratives are the stories and ideas that shape and reflect the values, beliefs, and experiences of a culture</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="DIGITAL MEDIA">
      <data key="d0">MEDIUM</data>
      <data key="d1">Digital media refers to content that is created, distributed, and consumed through digital platforms, including social media, websites, and streaming services</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="SOCIAL DISCUSSIONS">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Social discussions are conversations and debates that occur within society, often influenced by media coverage and public figures</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PUBLIC DISCOURSE">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Public discourse refers to the exchange of ideas and opinions in the public sphere, often involving media, public figures, and the general public</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTERTAINMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Entertainment encompasses various forms of media and activities designed to amuse or engage an audience, including film, television, music, sports, and digital media</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="FILM">
      <data key="d0">MEDIUM</data>
      <data key="d1">Film is a medium of entertainment that involves the production and screening of movies</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TELEVISION">
      <data key="d0">MEDIUM</data>
      <data key="d1">Television is a medium of entertainment that involves the broadcasting of programs, series, and news</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MUSIC">
      <data key="d0">MEDIUM</data>
      <data key="d1">Music is a medium of entertainment that involves the creation and performance of songs and instrumental pieces</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="SPORTS">
      <data key="d0">MEDIUM</data>
      <data key="d1">Sports are competitive physical activities that entertain and engage audiences</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TREND">
      <data key="d0">CONCEPT</data>
      <data key="d1">A trend is a general direction in which something is developing or changing, often influenced by public figures and media</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="CULTURAL LANDSCAPE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The cultural landscape refers to the cultural features and social dynamics of a society, shaped by public figures and media</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PROFESSIONAL ACHIEVEMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Professional achievements refer to the accomplishments and successes individuals attain in their careers</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PERSONAL LIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Personal lives refer to the private aspects of individuals' lives, often covered in media when involving public figures</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ECONOMIC IMPACTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Economic impacts refer to the financial effects that public figures and their activities have on the economy</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MEDIA">
      <data key="d0">MEDIUM</data>
      <data key="d1">Media refers to the various channels of communication, including print, digital, and broadcast, that disseminate information to the public</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="DATA SOURCES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Data sources are the origins of information used to support claims and reports in media coverage</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="NA&#207;VE RAG">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Na&#239;ve RAG is a basic retrieval-augmented generation approach that converts documents to text, splits the text into chunks, and embeds these chunks into a vector space for context retrieval. It is a simpler approach that does not use a graph index and is often used as a baseline in comparisons. Additionally, Na&#239;ve RAG is utilized to generate lists of public figures, focusing on their personal lives and relationships.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DECISION">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Decision refers to the process of choosing between different options or answers, often involving assessments and comparisons</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MAP-REDUCE SUMMARIZATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Map-reduce summarization is a resource-intensive approach requiring a high number of context tokens</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ROOT-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ROOT-LEVEL COMMUNITY SUMMARIES are summaries generated at the root level of a graph community hierarchy. These summaries encapsulate the content at the root level, achieving a significant reduction in token usage&#8212;over 97% fewer tokens compared to other methods. This efficiency makes them highly effective for providing concise and comprehensive overviews of complex datasets.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Intermediate-level summaries are summaries generated at intermediate levels of a graph community hierarchy</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Low-level community summaries are summaries generated at low levels of a graph community hierarchy</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="SS">
      <data key="d0">PARAMETER</data>
      <data key="d1">SS is a baseline condition used in the study</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="TS">
      <data key="d0">PARAMETER</data>
      <data key="d1">TS is a global text summarization approach without a graph index</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="PODCAST INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Podcast intermediate-level summaries are summaries of podcast content at an intermediate level of detail, with a diversity win rate of 57%</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="NEWS LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">News low-level community summaries are summaries of news content at a low level of detail, with a diversity win rate of 60%</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="MODULAR RAG">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Modular RAG is a system that includes patterns for iterative and dynamic cycles of interleaved retrieval and generation to overcome the drawbacks of Na&#239;ve RAG</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SELF-MEMORY (SELFMEM)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Self-memory (Selfmem) is a concept related to generation-augmented retrieval that facilitates future generation cycles</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GENERATION-AUGMENTED RETRIEVAL (GAR)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Generation-augmented retrieval (GAR) is a system that combines retrieval and generation to enhance the retrieval process</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Iterative retrieval-generation (Iter-RetGen) is a strategy that involves iterative cycles of retrieval and generation</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="FEDERATED RETRIEVAL-GENERATION (FEB4RAG)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Federated retrieval-generation (FeB4RAG) is a strategy that involves federated cycles of retrieval and generation</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="CAIRE-COVID">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">CAIRE-COVID is a sophisticated system designed for managing COVID-19 scholarly information. It integrates multiple concepts to provide both question answering and query-focused multi-document summarization. This dual functionality allows CAIRE-COVID to effectively handle and synthesize vast amounts of COVID-19 related research, making it a valuable tool for researchers and healthcare professionals seeking comprehensive and concise information.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="ITRG">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ITRG is a system for multi-hop question answering</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="IR-COT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">IR-CoT is a system for multi-hop question answering</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="DSP">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">DSP is a system for multi-hop question answering</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="RAPTOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">RAPTOR is a system that generates a hierarchical index of text chunks by clustering the vectors of text embeddings</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TREE OF CLARIFICATIONS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Tree of clarifications is a system that generates a hierarchical structure to answer multiple interpretations of ambiguous questions</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="KAPING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">KAPING is an advanced RAG system where the index is a knowledge graph</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="G-RETRIEVER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">G-Retriever is a system designed for retrieval-augmented generation, specifically aimed at enhancing textual graph understanding and question answering. It operates by focusing on subsets of the graph structure as the primary objects of enquiry, thereby facilitating more precise and contextually relevant information retrieval.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GRAPH-TOOLFORMER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Graph-ToolFormer is a system where derived graph metrics are the objects of enquiry</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SURGE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">SURGE is a system where narrative outputs are strongly grounded in the facts of retrieved subgraphs</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="FABULA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">FABULA is a system where retrieved event-plot subgraphs are serialized using narrative templates</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="LANGCHAIN">
      <data key="d0">SOFTWARE</data>
      <data key="d1">LangChain is an organization and technology that supports a variety of graph databases. It provides tools for creating and managing graphs, as detailed in the 2024 document "Langchain graphs." LangChain is also an existing open-source agent framework that facilitates building upon existing building blocks like RAG and search engine tools. Additionally, it is a tool for building context-aware reasoning applications, developed by LangChainAI and published on GitHub in 2022. LangChain is mentioned as a potential building block for ADAS (Advanced Driver Assistance Systems).</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6109537356a2ce2339f77c827aa3668e,6bdf681c0bd9e401ac72344a6a0ae479,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="LLAMAINDEX">
      <data key="d0">SOFTWARE</data>
      <data key="d1">LlamaIndex is a versatile technology and organization that supports a variety of graph databases. It provides tools for creating and managing knowledge graphs, as highlighted in the 2024 document "LlamaIndex Knowledge Graph Index."</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NEO4J">
      <data key="d0">SOFTWARE</data>
      <data key="d1">Neo4J is a technology and organization that supports the NaLLM system for creating and reasoning over knowledge graphs. It is a format for knowledge graphs used in graph-based RAG (Retrieval-Augmented Generation) applications. Neo4J developed Project NaLLM, as mentioned in the 2024 document.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NALLM">
      <data key="d0">SOFTWARE</data>
      <data key="d1">NaLLM is a system designed to create and reason over knowledge graphs using the Neo4J format. This system leverages the capabilities of Neo4J to structure and analyze complex datasets, enabling users to map out intricate relationships and dynamics within various communities of interest.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE</data>
    </node>
    <node id="NEBULA-GRAPH">
      <data key="d0">SOFTWARE</data>
      <data key="d1">Nebula-Graph is a graph database format supported by GraphRAG</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE</data>
    </node>
    <node id="GRAPHRAG">
      <data key="d0">SOFTWARE</data>
      <data key="d1">GraphRAG is a system designed to create and reason over knowledge graphs using the Nebula-Graph format. This system leverages the NebulaGraph format to structure and manage complex datasets, enabling advanced reasoning capabilities over the generated knowledge graphs.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE</data>
    </node>
    <node id="RAM">
      <data key="d0">PERSON</data>
      <data key="d1">Ram is an author who has worked on Retrieval-Augmented Generation (RAG) approaches and systems. He is one of the authors of the paper titled "In-context retrieval-augmented language models," which was published in the Transactions of the Association for Computational Linguistics in 2023.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Gao is an author referenced in the text, associated with the GSM-Hard dataset in 2023. Gao has discussed the GSM-Hard math task in 2023 and has worked on Na&#239;ve RAG and Modular RAG systems. Additionally, Gao is one of the authors of the paper titled "Generation-augmented retrieval for open-domain question answering," which was published on arXiv in 2020.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,81c504ffbcc5ed882e234802135295ba,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Cheng is an author who has worked on Self-memory (Selfmem) for generation-augmented retrieval</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAO">
      <data key="d0">PERSON</data>
      <data key="d1">Mao is an author who has contributed significantly to the field of Artificial Intelligence and Machine Learning. Mao has worked on generation-augmented retrieval (GAR) and is one of the authors of the paper titled "Generation-augmented retrieval for open-domain question answering," which was published on arXiv in 2020. Additionally, Mao co-authored the paper "Exploring large language models for knowledge graph completion," published in 2023. These works highlight Mao's involvement in advancing techniques for knowledge graph completion and open-domain question answering, showcasing their expertise in leveraging large language models and innovative retrieval methods.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Shao is an author who has contributed to the field of iterative retrieval-generation (Iter-RetGen). Shao is one of the authors of the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy," which was published on arXiv in 2023.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SU">
      <data key="d0">PERSON</data>
      <data key="d1">Su is an author who has worked on CAiRE-COVID for multi-document summarization. Su is one of the authors of the paper titled "CAiRE-COVID: A Question Answering and Query-Focused Multi-Document Summarization System for COVID-19 Scholarly Information Management," published in 2020.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Feng is an author who has worked on ITRG for multi-hop question answering</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TRIVEDI">
      <data key="d0">PERSON</data>
      <data key="d1">Trivedi is an author who has contributed significantly to the field of multi-hop question answering. Notably, Trivedi is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions," which was published in 2022. This work, often referred to as IR-CoT, focuses on enhancing the process of answering complex, multi-step questions by interleaving information retrieval with chain-of-thought reasoning, thereby advancing the capabilities of knowledge-intensive systems.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KHATTAB">
      <data key="d0">PERSON</data>
      <data key="d1">Khattab is an author who has contributed to the field of Digital Signal Processing (DSP) with a focus on multi-hop question answering. In 2024, Khattab further extended their expertise by working on DSPy, showcasing their ongoing commitment to advancing the domain of DSP.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SARTHI">
      <data key="d0">PERSON</data>
      <data key="d1">Sarthi is an author who has contributed significantly to the field of text processing and retrieval. Notably, Sarthi has worked on RAPTOR, a system designed for generating a hierarchical index of text chunks. Additionally, Sarthi is one of the authors of the paper titled "Raptor: Recursive Abstractive Processing for Tree-Organized Retrieval," which was published on arXiv in 2024. This work highlights Sarthi's expertise in developing advanced methodologies for organizing and retrieving textual information efficiently.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KIM">
      <data key="d0">PERSON</data>
      <data key="d1">Kim is an author who has worked on the tree of clarifications for answering multiple interpretations of ambiguous questions</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BAEK">
      <data key="d0">PERSON</data>
      <data key="d1">Baek is an author who has worked on KAPING where the index is a knowledge graph</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HE">
      <data key="d0">PERSON</data>
      <data key="d1">HE is an author who has contributed significantly to the field of open-domain question answering. He has worked on G-Retriever, a project where subsets of the graph structure are the objects of enquiry. Additionally, he is one of the authors of the paper titled "Generation-augmented retrieval for open-domain question answering," which was published on arXiv in 2020.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang is an author extensively mentioned in the text, contributing significantly to various areas within the field of Artificial Intelligence and Machine Learning. Zhang has worked on the development of memory structures, particularly external memory and Retrieval-Augmented Generation (RAG), as referenced in 2024c. Additionally, Zhang has discussed open-endedness algorithms in 2024a, focusing on leveraging human notions of interestingness and AI-Generative Algorithms (AI-GAs). In 2024, Zhang contributed to the development of AgentOptimizer and has also worked on Graph-ToolFormer, where derived graph metrics are the primary objects of enquiry. Zhang is one of the authors of several notable papers, including "Knowledge graph prompting for multi-document question answering" published in 2023, "HotpotQA: A dataset for diverse, explainable multi-hop question answering" published in 2018, "Causal graph discovery with retrieval-augmented generation based large language models" published in 2024, and "Graph-toolformer: To empower LLMs with graph reasoning ability via prompt augmented by ChatGPT" published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,6bdf681c0bd9e401ac72344a6a0ae479,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,dc55f071b95dec721a9820d39cdb3ccd,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KANG">
      <data key="d0">PERSON</data>
      <data key="d1">Kang is an author who has worked on SURGE where narrative outputs are grounded in the facts of retrieved subgraphs</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TRAJANOSKA">
      <data key="d0">PERSON</data>
      <data key="d1">Trajanoska is an author who has made significant contributions to the field of knowledge graph creation through the use of large language models (LLMs). In 2023, Trajanoska co-authored a paper titled "Enhancing knowledge graph construction using large language models," which highlights innovative methodologies for improving the construction of knowledge graphs by leveraging the capabilities of LLMs.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ban is an author who has worked on the extraction of causal graphs from source texts</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NEBULAGRAPH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">NebulaGraph is a format for knowledge graphs used in graph-based Retrieval-Augmented Generation (RAG) applications. It is a pioneering technology that launched the industry's first graph RAG, which integrates Large Language Models (LLMs) with knowledge graphs, as highlighted in a 2024 document. Additionally, NebulaGraph is an organization that supports the GraphRAG system, facilitating the creation and reasoning over knowledge graphs.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="TABLE 3">
      <data key="d0">DOCUMENT</data>
      <data key="d1">TABLE 3 illustrates the scalability advantages of Graph RAG compared to source text summarization.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SENSEMAKING ACTIVITY">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Sensemaking activity involves iterative question answering and is characterized by the use of root-level Graph RAG for efficiency</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="AD-HOC LLM USE">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Ad-hoc LLM use involves analyzing LLM reasoning to provide specific examples, quotes, and citations to help users reach an informed understanding</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TUNING ELEMENT EXTRACTION PROMPTS">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Tuning element extraction prompts may help retain more details in the Graph RAG index</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="EXTERNAL DATA SOURCES">
      <data key="d0">DATA</data>
      <data key="d1">External data sources are used in RAG to retrieve relevant information for the context window of the LLM</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="DOCUMENTS">
      <data key="d0">DATA</data>
      <data key="d1">Documents are converted to text, split into chunks, and embedded into a vector space in na&#239;ve RAG approaches</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="VECTOR SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Vector space is where text chunks are embedded, and similar positions represent similar semantics in na&#239;ve RAG approaches</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="QUERIES">
      <data key="d0">DATA</data>
      <data key="d1">Queries are embedded into the same vector space as text chunks, with the nearest vectors used as context in na&#239;ve RAG approaches</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="PRE-RETRIEVAL STRATEGIES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Pre-retrieval strategies are part of advanced RAG systems designed to overcome the drawbacks of na&#239;ve RAG</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="RETRIEVAL STRATEGIES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Retrieval strategies are part of advanced RAG systems designed to overcome the drawbacks of na&#239;ve RAG</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="POST-RETRIEVAL STRATEGIES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Post-retrieval strategies are part of advanced RAG systems designed to overcome the drawbacks of na&#239;ve RAG</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="HIERARCHICAL INDEX">
      <data key="d0">CONCEPT</data>
      <data key="d1">Hierarchical index is used in Graph RAG and other systems to organize text chunks by clustering the vectors of text embeddings</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TEXT EMBEDDINGS">
      <data key="d0">DATA</data>
      <data key="d1">Text embeddings are the vector representations of text chunks used in hierarchical indexing</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SUBGRAPHS">
      <data key="d0">DATA</data>
      <data key="d1">Subgraphs are subsets of the graph structure used in systems like G-Retriever and SURGE</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="NARRATIVE TEMPLATES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Narrative templates are used in systems like FABULA to serialize retrieved event-plot subgraphs</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="INDEX">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Index is a library mentioned in the text, likely used for graph-based RAG applications</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GRAPH-BASED RAG APPLICATIONS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Graph-based RAG applications are systems that create and reason over knowledge graphs in various formats</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SELFCHECKGPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">SelfCheckGPT is a system used for comparing fabrication rates</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Alonso Guevara Fern&#225;ndez is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="AMBER HOAK">
      <data key="d0">PERSON</data>
      <data key="d1">Amber Hoak is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d0">PERSON</data>
      <data key="d1">Andr&#233;s Morales Esquivel is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BEN CUTLER">
      <data key="d0">PERSON</data>
      <data key="d1">Ben Cutler is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BILLIE RINALDI">
      <data key="d0">PERSON</data>
      <data key="d1">Billie Rinaldi is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRIS SANCHEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Sanchez is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRIS TREVINO">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Trevino is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRISTINE CAGGIANO">
      <data key="d0">PERSON</data>
      <data key="d1">Christine Caggiano is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DAVID TITTSWORTH">
      <data key="d0">PERSON</data>
      <data key="d1">David Tittsworth is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DAYENNE DE SOUZA">
      <data key="d0">PERSON</data>
      <data key="d1">Dayenne de Souza is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DOUGLAS ORBAKER">
      <data key="d0">PERSON</data>
      <data key="d1">Douglas Orbaker is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ED CLARK">
      <data key="d0">PERSON</data>
      <data key="d1">Ed Clark is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GABRIEL NIEVES-PONCE">
      <data key="d0">PERSON</data>
      <data key="d1">Gabriel Nieves-Ponce is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GAUDY BLANCO MENESES">
      <data key="d0">PERSON</data>
      <data key="d1">Gaudy Blanco Meneses is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATE LYTVYNETS">
      <data key="d0">PERSON</data>
      <data key="d1">Kate Lytvynets is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATY SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Katy Smith is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="M&#211;NICA CARVAJAL">
      <data key="d0">PERSON</data>
      <data key="d1">M&#243;nica Carvajal is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="NATHAN EVANS">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Evans is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RICHARD ORTEGA">
      <data key="d0">PERSON</data>
      <data key="d1">Richard Ortega is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RODRIGO RACANICCI">
      <data key="d0">PERSON</data>
      <data key="d1">Rodrigo Racanicci is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SARAH SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Smith is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SHANE SOLOMON">
      <data key="d0">PERSON</data>
      <data key="d1">Shane Solomon is one of the contributors to the work mentioned in the text</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SAMUEL ADLER">
      <data key="d0">PERSON</data>
      <data key="d1">Samuel Adler is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SHIVANI AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Shivani Agarwal is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="LAILA AHMAD">
      <data key="d0">PERSON</data>
      <data key="d1">Laila Ahmad is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ILYA AKKAYA">
      <data key="d0">PERSON</data>
      <data key="d1">Ilya Akkaya is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="FERNANDO L. ALEMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Fernando L. Aleman is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DANIEL ALMEIDA">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Almeida is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="JULIA ALTENSCHMIDT">
      <data key="d0">PERSON</data>
      <data key="d1">Julia Altenschmidt is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SAM ALTMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Sam Altman is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SAMEER ANADKAT">
      <data key="d0">PERSON</data>
      <data key="d1">Sameer Anadkat is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RISHI ANIL">
      <data key="d0">PERSON</data>
      <data key="d1">Rishi Anil is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SEBASTIAN BORGEAUD">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Borgeaud is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="YONGJUN WU">
      <data key="d0">PERSON</data>
      <data key="d1">Yongjun Wu is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="JEAN-BAPTISTE ALAYRAC">
      <data key="d0">PERSON</data>
      <data key="d1">Jean-Baptiste Alayrac is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="JUNYU YU">
      <data key="d0">PERSON</data>
      <data key="d1">Junyu Yu is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RADU SORICUT">
      <data key="d0">PERSON</data>
      <data key="d1">Radu Soricut is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="JOHAN SCHALKWYK">
      <data key="d0">PERSON</data>
      <data key="d1">Johan Schalkwyk is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ANDREW M. DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew M. Dai is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ANDREAS HAUTH">
      <data key="d0">PERSON</data>
      <data key="d1">Andreas Hauth is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="JUNSU BAEK">
      <data key="d0">PERSON</data>
      <data key="d1">Junsu Baek is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ALFIAN F. AJI">
      <data key="d0">PERSON</data>
      <data key="d1">Alfian F. Aji is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ALI SAFFARI">
      <data key="d0">PERSON</data>
      <data key="d1">Ali Saffari is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="TAKASHI BAN">
      <data key="d0">PERSON</data>
      <data key="d1">Takashi Ban is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="LI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Li Chen is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="XIAOWEI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaowei Wang is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="HONG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Hong Chen is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="TAL BAUMEL">
      <data key="d0">PERSON</data>
      <data key="d1">Tal Baumel is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="MICHAL EYAL">
      <data key="d0">PERSON</data>
      <data key="d1">Michal Eyal is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="MICHAEL ELHADAD">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Elhadad is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="VINCENT D. BLONDEL">
      <data key="d0">PERSON</data>
      <data key="d1">Vincent D. Blondel is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="JEAN-LOUP GUILLAUME">
      <data key="d0">PERSON</data>
      <data key="d1">Jean-Loup Guillaume is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="R&#201;MY LAMBIOTTE">
      <data key="d0">PERSON</data>
      <data key="d1">R&#233;my Lambiotte is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ETIENNE LEFEBVRE">
      <data key="d0">PERSON</data>
      <data key="d1">Etienne Lefebvre is one of the authors of a referenced paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GPT-4 TECHNICAL REPORT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The GPT-4 technical report is a document published by OpenAI on arXiv in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Knowledge-augmented language model prompting is a technique for zero-shot knowledge graph question answering</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="QUERY FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Query focused abstractive summarization is a technique that incorporates query relevance, multi-document coverage, and summary length constraints into seq2seq models</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="FAST UNFOLDING OF COMMUNITIES IN LARGE NETWORKS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">"Fast Unfolding of Communities in Large Networks" is a method for community detection in large networks. The paper titled "Fast Unfolding of Communities in Large Networks" discusses these methods and was published in the Journal of Statistical Mechanics: Theory and Experiment in 2008.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="JOSH ACHIAM">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BLONDEL, V. D.">
      <data key="d0">PERSON</data>
      <data key="d1">Blondel, V. D. is one of the authors of the paper titled "Fast unfolding of communities in large networks" published in the Journal of Statistical Mechanics: Theory and Experiment in 2008</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GUILLAUME, J.-L.">
      <data key="d0">PERSON</data>
      <data key="d1">Guillaume, J.-L. is one of the authors of the paper titled "Fast unfolding of communities in large networks" published in the Journal of Statistical Mechanics: Theory and Experiment in 2008</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LAMIOTTE, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Lambiotte, R. is one of the authors of the paper titled "Fast unfolding of communities in large networks" published in the Journal of Statistical Mechanics: Theory and Experiment in 2008</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LEFEBVRE, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Lefebvre, E. is one of the authors of the paper titled "Fast unfolding of communities in large networks" published in the Journal of Statistical Mechanics: Theory and Experiment in 2008</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BROWN, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Brown, T. is one of the authors of the paper titled "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MANN, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Mann, B. is one of the authors of the paper titled "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RYDER, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Ryder, N. is one of the authors of the paper titled "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUBBIAH, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Subbiah, M. is one of the authors of the paper titled "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KAPLAN, J. D.">
      <data key="d0">PERSON</data>
      <data key="d1">Kaplan, J. D. is one of the authors of the paper titled "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DHARIWAL, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Dhariwal, P. is one of the authors of the paper titled "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NEELAKANTAN, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Neelakantan, A. is one of the authors of the paper titled "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SHYAM, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Shyam, P. is one of the authors of the paper titled "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SASTRY, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Sastry, G. is one of the authors of the paper titled "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ASKELL, A.">
      <data key="d0">PERSON</data>
      <data key="d1">Askell, A. is one of the authors of the paper titled "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHENG, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Cheng, X. is one of the authors of the paper titled "Lift yourself up: Retrieval-augmented text generation with self-memory" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LUO, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Luo, D. is one of the authors of the paper titled "Lift yourself up: Retrieval-augmented text generation with self-memory" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHEN, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Chen, X. is one of the authors of the paper titled "Lift yourself up: Retrieval-augmented text generation with self-memory" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIU, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Liu, L. is one of the authors of the paper titled "Lift yourself up: Retrieval-augmented text generation with self-memory" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZHAO, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhao, D. is one of the authors of the paper titled "Lift yourself up: Retrieval-augmented text generation with self-memory" published in Advances in Neural Information Processing Systems in 2024Zhao, D. is one of the authors of the paper titled "Retrieval-generation synergy augmented large language models" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YAN, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Yan, R. is one of the authors of the paper titled "Lift yourself up: Retrieval-augmented text generation with self-memory" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DANG, H. T.">
      <data key="d0">PERSON</data>
      <data key="d1">Dang, H. T. is the author of the paper titled "Duc 2005: Evaluation of question-focused summarization systems" published in the Proceedings of the Workshop on Task-Focused Summarization and Question Answering in 2006</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ES, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Es, S. is one of the authors of the paper titled "Ragas: Automated evaluation of retrieval augmented generation" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JAMES, J.">
      <data key="d0">PERSON</data>
      <data key="d1">James, J. is one of the authors of the paper titled "Ragas: Automated evaluation of retrieval augmented generation" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ESPINOSA-ANKE, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Espinosa-Anke, L. is one of the authors of the paper titled "Ragas: Automated evaluation of retrieval augmented generation" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SCHOCKAERT, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Schockaert, S. is one of the authors of the paper titled "Ragas: Automated evaluation of retrieval augmented generation" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FENG, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Feng, Z. is one of the authors of the paper titled "Retrieval-generation synergy augmented large language models" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FENG, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Feng, X. is one of the authors of the paper titled "Retrieval-generation synergy augmented large language models" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Yang, M. is one of the authors of the paper titled "Retrieval-generation synergy augmented large language models" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="QIN, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Qin, B. is one of the authors of the paper titled "Retrieval-generation synergy augmented large language models" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FORTUNATO, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Fortunato, S. is the author of the paper titled "Community detection in graphs" published in Physics Reports in 2010</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GAO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Gao, Y. is one of the authors of the paper titled "Retrieval-augmented generation for large language models: A survey" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="XIONG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Xiong, Y. is one of the authors of the paper titled "Retrieval-augmented generation for large language models: A survey" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GAO, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Gao, X. is one of the authors of the paper titled "Retrieval-augmented generation for large language models: A survey" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIA, K.">
      <data key="d0">PERSON</data>
      <data key="d1">Jia, K. is one of the authors of the paper titled "Retrieval-augmented generation for large language models: A survey" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PAN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Pan, J. is one of the authors of the paper titled "Retrieval-augmented generation for large language models: A survey" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Bi, Y. is one of the authors of the paper titled "Retrieval-augmented generation for large language models: A survey" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DAI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Dai, Y. is one of the authors of the paper titled "Retrieval-augmented generation for large language models: A survey" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Sun, J. is one of the authors of the paper titled "Retrieval-augmented generation for large language models: A survey" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WANG, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, H. is one of the authors of the paper titled "Retrieval-augmented generation for large language models: A survey" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GOODWIN, T. R.">
      <data key="d0">PERSON</data>
      <data key="d1">Goodwin, T. R. is one of the authors of the paper titled "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization" published in the Proceedings of COLING in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SAVERY, M. E.">
      <data key="d0">PERSON</data>
      <data key="d1">Savery, M. E. is one of the authors of the paper titled "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization" published in the Proceedings of COLING in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEMNER-FUSHMAN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Demner-Fushman, D. is one of the authors of the paper titled "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization" published in the Proceedings of COLING in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HE, X.">
      <data key="d0">PERSON</data>
      <data key="d1">He, X. is one of the authors of the paper titled "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering" published as an arXiv preprint in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TIAN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Tian, Y. is one of the authors of the paper titled "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering" published as an arXiv preprint in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Sun, Y. is one of the authors of the paper titled "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering" published as an arXiv preprint in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHAWLA, N. V.">
      <data key="d0">PERSON</data>
      <data key="d1">Chawla, N. V. is one of the authors of the paper titled "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering" published as an arXiv preprint in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LAURENT, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Laurent, T. is one of the authors of the paper titled "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering" published as an arXiv preprint in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LECUN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">LeCun, Y. is one of the authors of the paper titled "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering" published as an arXiv preprint in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BRESSON, X.">
      <data key="d0">PERSON</data>
      <data key="d1">Bresson, X. is one of the authors of the paper titled "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering" published as an arXiv preprint in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HOOI, B.">
      <data key="d0">PERSON</data>
      <data key="d1">Hooi, B. is one of the authors of the paper titled "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering" published as an arXiv preprint in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JACOMY, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Jacomy, M. is one of the authors of the paper titled "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software" published in PLoS ONE in 2014</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="VENTURINI, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Venturini, T. is one of the authors of the paper titled "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software" published in PLoS ONE in 2014</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HEYMANN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Heymann, S. is one of the authors of the paper titled "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software" published in PLoS ONE in 2014</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BASTIAN, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Bastian, M. is one of the authors of the paper titled "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software" published in PLoS ONE in 2014</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">Jin, D. is one of the authors of the paper titled "A survey of community detection approaches: From statistical modeling to deep learning" published in IEEE Transactions on Knowledge and Data Engineering in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YU, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Yu, Z. is one of the authors of the paper titled "A survey of community detection approaches: From statistical modeling to deep learning" published in IEEE Transactions on Knowledge and Data Engineering in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIAO, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Jiao, P. is one of the authors of the paper titled "A survey of community detection approaches: From statistical modeling to deep learning" published in IEEE Transactions on Knowledge and Data Engineering in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PAN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Pan, S. is one of the authors of the paper titled "A survey of community detection approaches: From statistical modeling to deep learning" published in IEEE Transactions on Knowledge and Data Engineering in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HE, D.">
      <data key="d0">PERSON</data>
      <data key="d1">He, D. is one of the authors of the paper titled "A survey of community detection approaches: From statistical modeling to deep learning" published in IEEE Transactions on Knowledge and Data Engineering in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Wu, J. is one of the authors of the paper titled "A survey of community detection approaches: From statistical modeling to deep learning" published in IEEE Transactions on Knowledge and Data Engineering in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PHILIP, S. Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Philip, S. Y. is one of the authors of the paper titled "A survey of community detection approaches: From statistical modeling to deep learning" published in IEEE Transactions on Knowledge and Data Engineering in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZHANG, W.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, W. is one of the authors of the paper titled "A survey of community detection approaches: From statistical modeling to deep learning" published in IEEE Transactions on Knowledge and Data Engineering in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Kang, M. is one of the authors of the paper titled "Knowledge graph-augmented language models for knowledge-grounded dialogue generation" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KWAK, J. M.">
      <data key="d0">PERSON</data>
      <data key="d1">Kwak, J. M. is one of the authors of the paper titled "Knowledge graph-augmented language models for knowledge-grounded dialogue generation" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BAEK, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Baek, J. is one of the authors of the paper titled "Knowledge graph-augmented language models for knowledge-grounded dialogue generation" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HWANG, S. J.">
      <data key="d0">PERSON</data>
      <data key="d1">Hwang, S. J. is one of the authors of the paper titled "Knowledge graph-augmented language models for knowledge-grounded dialogue generation" published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KHATTAB, O.">
      <data key="d0">PERSON</data>
      <data key="d1">Khattab, O.("entity"</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT">
      <data key="d0">JOURNAL</data>
      <data key="d1">The Journal of Statistical Mechanics: Theory and Experiment is a scientific journal where the paper "Fast unfolding of communities in large networks" was published in 2008</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d0">CONFERENCE</data>
      <data key="d1">Advances in Neural Information Processing Systems (NeurIPS) is a prominent conference in the field of artificial intelligence and machine learning. It serves as a platform for the dissemination of cutting-edge research and has been the venue for significant publications. Notably, the paper "Language models are few-shot learners" was published at NeurIPS in 2020, highlighting advancements in natural language processing. Additionally, the paper "Thought Cloning: Learning to think while acting by imitating human thinking" was published at NeurIPS in 2024, showcasing innovative approaches in the intersection of cognitive modeling and machine learning. NeurIPS continues to be a critical event for researchers and practitioners to share and discuss groundbreaking work in AI and ML.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PROCEEDINGS OF THE WORKSHOP ON TASK-FOCUSED SUMMARIZATION AND QUESTION ANSWERING">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The Proceedings of the Workshop on Task-Focused Summarization and Question Answering is a conference where the paper "Duc 2005: Evaluation of question-focused summarization systems" was published in 2006</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PHYSICS REPORTS">
      <data key="d0">JOURNAL</data>
      <data key="d1">Physics Reports is a scientific journal where the paper "Community detection in graphs" was published in 2010</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PROCEEDINGS OF COLING">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The Proceedings of COLING is a conference where the paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization" was published in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PLOS ONE">
      <data key="d0">JOURNAL</data>
      <data key="d1">PLoS ONE is a scientific journal where the paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software" was published in 2014</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING">
      <data key="d0">JOURNAL</data>
      <data key="d1">IEEE Transactions on Knowledge and Data Engineering is a scientific journal where the paper "A survey of community detection approaches: From statistical modeling to deep learning" was published in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DUC 2005">
      <data key="d0">EVENT</data>
      <data key="d1">DUC 2005 is an event where the evaluation of question-focused summarization systems was conducted</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-GENERATION SYNERGY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Retrieval-Generation Synergy is a method for augmenting large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Retrieval-Augmented Generation is a method for enhancing large language models by integrating retrieval mechanisms</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FORCEATLAS2">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ForceAtlas2 is a continuous graph layout algorithm designed for network visualization in the Gephi software</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GEPHI">
      <data key="d0">SOFTWARE</data>
      <data key="d1">Gephi is a software designed for network visualization</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIFT YOURSELF UP">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Lift Yourself Up is a method for retrieval-augmented text generation with self-memory</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Language models are few-shot learners" discusses the capabilities of language models in few-shot learning and was published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Lift yourself up: Retrieval-augmented text generation with self-memory" discusses methods for enhancing text generation and was published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DUC 2005: EVALUATION OF QUESTION-FOCUSED SUMMARIZATION SYSTEMS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Duc 2005: Evaluation of question-focused summarization systems" discusses the evaluation of summarization systems and was published in the Proceedings of the Workshop on Task-Focused Summarization and Question Answering in 2006</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RAGAS: AUTOMATED EVALUATION OF RETRIEVAL AUGMENTED GENERATION">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Ragas: Automated evaluation of retrieval augmented generation" discusses methods for evaluating retrieval-augmented generation and was published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Retrieval-generation synergy augmented large language models" discusses methods for enhancing large language models and was published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COMMUNITY DETECTION IN GRAPHS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Community detection in graphs" discusses methods for detecting communities in graphs and was published in Physics Reports in 2010</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Retrieval-augmented generation for large language models: A survey" discusses various methods for enhancing large language models and was published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FLIGHT OF THE PEGASUS? COMPARING TRANSFORMERS ON FEW-SHOT AND ZERO-SHOT MULTI-DOCUMENT ABSTRACTIVE SUMMARIZATION">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization" discusses the performance of transformers in summarization tasks and was published in the Proceedings of COLING in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="G-RETRIEVER: RETRIEVAL-AUGMENTED GENERATION FOR TEXTUAL GRAPH UNDERSTANDING AND QUESTION ANSWERING">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "G-retriever: Retrieval-augmented generation for textual graph understanding and question answering" discusses methods for enhancing text generation and was published as an arXiv preprint in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FORCEATLAS2, A CONTINUOUS GRAPH LAYOUT ALGORITHM FOR HANDY NETWORK VISUALIZATION DESIGNED FOR THE GEPHI SOFTWARE">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software" discusses methods for network visualization and was published in PLoS ONE in 2014</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="A SURVEY OF COMMUNITY DETECTION APPROACHES: FROM STATISTICAL MODELING TO DEEP LEARNING">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "A survey of community detection approaches: From statistical modeling to deep learning" discusses various methods for community detection and was published in IEEE Transactions on Knowledge and Data Engineering in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KNOWLEDGE GRAPH-AUGMENTED LANGUAGE MODELS FOR KNOWLEDGE-GROUNDED DIALOGUE GENERATION">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Knowledge graph-augmented language models for knowledge-grounded dialogue generation" discusses methods for enhancing dialogue generation and was published as an arXiv preprint in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GREGORY">
      <data key="d0">PERSON</data>
      <data key="d1">Gregory is one of the authors of the paper titled "Talking datasets&#8211;understanding data sensemaking behaviours" published in the International Journal of Human-Computer Studies in 2021</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GROTH">
      <data key="d0">PERSON</data>
      <data key="d1">Groth is one of the authors of the paper titled "Talking datasets&#8211;understanding data sensemaking behaviours" published in the International Journal of Human-Computer Studies in 2021</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SIMPERL">
      <data key="d0">PERSON</data>
      <data key="d1">Simperl is one of the authors of the paper titled "Talking datasets&#8211;understanding data sensemaking behaviours" published in the International Journal of Human-Computer Studies in 2021</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BULATOV">
      <data key="d0">PERSON</data>
      <data key="d1">Bulatov is one of the authors of the paper titled "In search of needles in a 11m haystack: Recurrent memory finds what LLMs miss" published in 2024</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ANOKHIN">
      <data key="d0">PERSON</data>
      <data key="d1">Anokhin is one of the authors of the paper titled "In search of needles in a 11m haystack: Recurrent memory finds what LLMs miss" published in 2024</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SOROKIN">
      <data key="d0">PERSON</data>
      <data key="d1">Sorokin is one of the authors of the paper titled "In search of needles in a 11m haystack: Recurrent memory finds what LLMs miss" published in 2024</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BURTSEV">
      <data key="d0">PERSON</data>
      <data key="d1">Burtsev is one of the authors of the paper titled "In search of needles in a 11m haystack: Recurrent memory finds what LLMs miss" published in 2024</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HOQUE">
      <data key="d0">PERSON</data>
      <data key="d1">Hoque is one of the authors of the paper titled "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" published in Computational Linguistics in 2022Hoque is one of the authors of the paper titled "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models" published in the Advances in Artificial Intelligence: 33rd Canadian Conference on Artificial Intelligence in 2020</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Huang is an author who has made significant contributions to the field of Artificial Intelligence and Machine Learning. Huang's research focuses on improving value assignment in language models by incorporating environmental feedback and has suggested that language models cannot self-correct their internal reasoning, making external feedback critical. Additionally, Huang has worked on adapting language models as high-level controllers in robotics. Huang has co-authored several notable papers, including "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" published in Computational Linguistics in 2022, "Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models" presented at the 33rd Canadian Conference on Artificial Intelligence in 2020, and "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy" published on arXiv in 2023.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,6bdf681c0bd9e401ac72344a6a0ae479,c95e02c0dca4a4a36b701cbc7dd14da6,df50c95dff7da074cbb2f68e88686f88,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PEREZ">
      <data key="d0">PERSON</data>
      <data key="d1">Perez is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PIKTUS">
      <data key="d0">PERSON</data>
      <data key="d1">Piktus is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PETRONI">
      <data key="d0">PERSON</data>
      <data key="d1">Petroni is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KARPUKHIN">
      <data key="d0">PERSON</data>
      <data key="d1">Karpukhin is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GOYAL">
      <data key="d0">PERSON</data>
      <data key="d1">Goyal is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KUTTLER">
      <data key="d0">PERSON</data>
      <data key="d1">Kuttler is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="YIH">
      <data key="d0">PERSON</data>
      <data key="d1">Yih is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ROCKTASCHEL">
      <data key="d0">PERSON</data>
      <data key="d1">Rocktaschel is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Lin is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena" published in 2024. Additionally, Lin contributed to the paper "Lost in the middle: How language models use long contexts," which was published on arXiv in 2023.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HEWITT">
      <data key="d0">PERSON</data>
      <data key="d1">Hewitt is one of the authors of the paper titled "Lost in the middle: How language models use long contexts" published on arXiv in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PARANJAPE">
      <data key="d0">PERSON</data>
      <data key="d1">Paranjape is one of the authors of the paper titled "Lost in the middle: How language models use long contexts" published on arXiv in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BEVILACQUA">
      <data key="d0">PERSON</data>
      <data key="d1">Bevilacqua is one of the authors of the paper titled "Lost in the middle: How language models use long contexts" published on arXiv in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Liang is one of the authors of two notable papers published in 2023. The first paper, titled "Is chatgpt a good nlg evaluator? a preliminary study," explores the effectiveness of ChatGPT as a natural language generation evaluator. The second paper, "Lost in the middle: How language models use long contexts," was published on arXiv and investigates the utilization of long contexts by language models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MANAKUL">
      <data key="d0">PERSON</data>
      <data key="d1">Manakul is one of the authors of the paper titled "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models" published on arXiv in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIUSIE">
      <data key="d0">PERSON</data>
      <data key="d1">Liusie is one of the authors of the paper titled "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models" published on arXiv in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GALES">
      <data key="d0">PERSON</data>
      <data key="d1">Gales is one of the authors of the paper titled "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models" published on arXiv in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Shen is an author who has made significant contributions to the field of Artificial Intelligence and Machine Learning. In 2023, Shen discussed Neural Architecture Search (NAS) and worked on providing external tools to enhance language models. Additionally, Shen co-authored the paper titled "Generation-augmented retrieval for open-domain question answering," published on arXiv in 2020, and another paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy," published on arXiv in 2023.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c95e02c0dca4a4a36b701cbc7dd14da6,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAN">
      <data key="d0">PERSON</data>
      <data key="d1">Han is one of the authors of the paper titled "Generation-augmented retrieval for open-domain question answering" published on arXiv in 2020</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Chen is an author extensively involved in various research areas within the field of Artificial Intelligence and Machine Learning. Chen has contributed to prompting techniques in 2023 and has addressed safety concerns when executing untrusted model-generated code in Meta Agent Search in 2021. Additionally, Chen has worked on programming domains and tasks, including the HumanEval dataset and synthetic test suite generation for programming tasks, as well as error propagation in chain-of-thought (CoT) prompting for language models.

Chen is also one of the authors of several notable papers, including "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors," presented at The Twelfth International Conference on Learning Representations in 2023, and "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy," published in 2023. Furthermore, Chen contributed to the paper "Generation-augmented retrieval for open-domain question answering," published on arXiv in 2020. Chen's work spans a broad spectrum of AI and ML topics, highlighting their significant role in advancing the field.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,02ef0185bbeaaef92c3a8ee18b7a38cf,0b6b4880e77d40e284702da16be4ef64,42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,dc55f071b95dec721a9820d39cdb3ccd,df50c95dff7da074cbb2f68e88686f88,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEVINE">
      <data key="d0">PERSON</data>
      <data key="d1">Levine is one of the authors of the paper titled "In-context retrieval-augmented language models" published in the Transactions of the Association for Computational Linguistics in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="DALMEDIGOS">
      <data key="d0">PERSON</data>
      <data key="d1">Dalmedigos is one of the authors of the paper titled "In-context retrieval-augmented language models" published in the Transactions of the Association for Computational Linguistics in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MUHLGAY">
      <data key="d0">PERSON</data>
      <data key="d1">Muhlgay is one of the authors of the paper titled "In-context retrieval-augmented language models" published in the Transactions of the Association for Computational Linguistics in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SHASHUA">
      <data key="d0">PERSON</data>
      <data key="d1">Shashua is one of the authors of the paper titled "In-context retrieval-augmented language models" published in the Transactions of the Association for Computational Linguistics in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LEYTON-BROWN">
      <data key="d0">PERSON</data>
      <data key="d1">Leyton-Brown is one of the authors of the paper titled "In-context retrieval-augmented language models" published in the Transactions of the Association for Computational Linguistics in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SHOHAM">
      <data key="d0">PERSON</data>
      <data key="d1">Shoham is one of the authors of the paper titled "In-context retrieval-augmented language models" published in the Transactions of the Association for Computational Linguistics in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ABDULLAH">
      <data key="d0">PERSON</data>
      <data key="d1">Abdullah is one of the authors of the paper titled "Raptor: Recursive abstractive processing for tree-organized retrieval" published on arXiv in 2024</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="TULI">
      <data key="d0">PERSON</data>
      <data key="d1">Tuli is one of the authors of the paper titled "Raptor: Recursive abstractive processing for tree-organized retrieval" published on arXiv in 2024</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KHANNA">
      <data key="d0">PERSON</data>
      <data key="d1">Khanna is one of the authors of the paper titled "Raptor: Recursive abstractive processing for tree-organized retrieval" published on arXiv in 2024</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GOLDIE">
      <data key="d0">PERSON</data>
      <data key="d1">Goldie is one of the authors of the paper titled "Raptor: Recursive abstractive processing for tree-organized retrieval" published on arXiv in 2024</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MANNING">
      <data key="d0">PERSON</data>
      <data key="d1">Manning is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering" published in 2018. Additionally, Manning is also one of the authors of the paper titled "Raptor: Recursive abstractive processing for tree-organized retrieval" published on arXiv in 2024.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GONG">
      <data key="d0">PERSON</data>
      <data key="d1">Gong is one of the authors of the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy" published on arXiv in 2023</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="DUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Duan is an author who has contributed to research in Meta-RL. In 2023, Duan co-authored the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy," which was published on arXiv.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="YU">
      <data key="d0">PERSON</data>
      <data key="d1">Yu is an author who has made significant contributions to research in the field of Language-to-Reward, particularly in 2023. Additionally, Yu is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management," which was published in 2020.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,dc55f071b95dec721a9820d39cdb3ccd,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SIDDIQUE">
      <data key="d0">PERSON</data>
      <data key="d1">Siddique is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management" published in 2020.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BAREZI">
      <data key="d0">PERSON</data>
      <data key="d1">Barezi is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management" published in 2020.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="FUNG">
      <data key="d0">PERSON</data>
      <data key="d1">Fung is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management" published in 2020.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="STONE">
      <data key="d0">PERSON</data>
      <data key="d1">Stone is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALBERT">
      <data key="d0">PERSON</data>
      <data key="d1">Albert is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALMAHAIRI">
      <data key="d0">PERSON</data>
      <data key="d1">Almahairi is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BABAEI">
      <data key="d0">PERSON</data>
      <data key="d1">Babaei is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BASHLYKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Bashlykov is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BATRA">
      <data key="d0">PERSON</data>
      <data key="d1">Batra is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BHARGAVA">
      <data key="d0">PERSON</data>
      <data key="d1">Bhargava is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BHOSALE">
      <data key="d0">PERSON</data>
      <data key="d1">Bhosale is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WALTMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Waltman is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities" published in 2019</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VAN ECK">
      <data key="d0">PERSON</data>
      <data key="d1">Van Eck is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities" published in 2019</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="STOJANOV">
      <data key="d0">PERSON</data>
      <data key="d1">Stojanov is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TRAJANOV">
      <data key="d0">PERSON</data>
      <data key="d1">Trajanov is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BALASUBRAMANIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Balasubramanian is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions" published in 2022</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KHOT">
      <data key="d0">PERSON</data>
      <data key="d1">Khot is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions" published in 2022</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SABHARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Sabharwal is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions" published in 2022</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WANG J">
      <data key="d0">PERSON</data>
      <data key="d1">Wang J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MENG">
      <data key="d0">PERSON</data>
      <data key="d1">Meng is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Sun is an author who has contributed to the development of the AdaPlanner method. Additionally, Sun is one of the authors of the paper titled "Is ChatGPT a Good NLG Evaluator? A Preliminary Study," which was published in 2023.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Shi is an author associated with the MGSM benchmark for evaluating Math capability under a multi-lingual setting. In 2023, Shi discussed the MGSM math task and contributed to the discovery of the Verified Multimodal Agent within the Math domain (MGSM). Additionally, Shi is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study," published in 2023.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LI">
      <data key="d0">PERSON</data>
      <data key="d1">Li is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study" published in 2023Li is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena" published in 2024</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QU">
      <data key="d0">PERSON</data>
      <data key="d1">Qu is an author mentioned in the text, contributing to the development of tool use in agentic systems. Qu is also referenced in association with tool use in 2024. Additionally, Qu is one of the authors of the paper titled "Is ChatGPT a Good NLG Evaluator? A Preliminary Study," published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhou is an author mentioned in the text who has made significant contributions to the field of Artificial Intelligence and Machine Learning. In 2024, Zhou worked on Agent Symbolic Learning and Self-Discover, showcasing expertise in these advanced AI topics. Additionally, Zhou has contributed to research on least-to-most prompting for multi-step decomposition in language models. Zhou is also one of the authors of the paper titled "Is ChatGPT a Good NLG Evaluator? A Preliminary Study," published in 2023.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,dc55f071b95dec721a9820d39cdb3ccd,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WANG S">
      <data key="d0">PERSON</data>
      <data key="d1">Wang S. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" published in 2024</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KHRAMTSOVA">
      <data key="d0">PERSON</data>
      <data key="d1">Khramtsova is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" published in 2024</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHUANG S">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuang S. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" published in 2024</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZUCCON">
      <data key="d0">PERSON</data>
      <data key="d1">Zuccon is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation" published in 2024</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WANG Y">
      <data key="d0">PERSON</data>
      <data key="d1">Wang Y. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LIPKA">
      <data key="d0">PERSON</data>
      <data key="d1">Lipka is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ROSSI">
      <data key="d0">PERSON</data>
      <data key="d1">Rossi is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SIU">
      <data key="d0">PERSON</data>
      <data key="d1">Siu is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DERR">
      <data key="d0">PERSON</data>
      <data key="d1">Derr is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QI">
      <data key="d0">PERSON</data>
      <data key="d1">Qi is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering" published in 2018</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BENGIO">
      <data key="d0">PERSON</data>
      <data key="d1">Bengio is an influential author in the field of Artificial Intelligence, known for his contributions to discussions on the pursuit of Artificial General Intelligence (AGI) and AI-GA in 2024. He is also one of the authors of the notable paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering," which was published in 2018. This paper has made significant strides in the development of datasets that enhance the explainability and diversity of multi-hop question answering systems.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="COHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Cohen is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering" published in 2018</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SALAKHUTDINOV">
      <data key="d0">PERSON</data>
      <data key="d1">Salakhutdinov is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering" published in 2018</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WAN">
      <data key="d0">PERSON</data>
      <data key="d1">Wan is one of the authors of the paper titled "Recent advances in document summarization" published in 2017</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Xiao is one of the authors of the paper titled "Recent advances in document summarization" published in 2017</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PENG">
      <data key="d0">PERSON</data>
      <data key="d1">Peng is one of the authors of the paper titled "Exploring large language models for knowledge graph completion" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Luo is one of the authors of the paper titled "Exploring large language models for knowledge graph completion" published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GAN">
      <data key="d0">PERSON</data>
      <data key="d1">Gan is one of the authors of the paper titled "Causal graph discovery with retrieval-augmented generation based large language models" published in 2024</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chiang is an author mentioned in the text and is one of the authors of the paper titled "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena," published in 2024.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Sheng is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena" published in 2024</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuang is an author who has made significant contributions to the field of search algorithms, particularly in the development and application of the A* algorithm. In 2024, Zhuang co-authored a paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena," showcasing their expertise and ongoing research in the domain of artificial intelligence and machine learning.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WU">
      <data key="d0">PERSON</data>
      <data key="d1">Wu is an author referenced in the text, known for assigning FM modules in the agentic system with different roles in 2023. Wu has also contributed to the field of reinforcement learning algorithms. Additionally, Wu is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena," published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c95e02c0dca4a4a36b701cbc7dd14da6,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XING">
      <data key="d0">PERSON</data>
      <data key="d1">Xing is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena" published in 2024</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ENHANCING RETRIEVAL-AUGMENTED LARGE LANGUAGE MODELS WITH ITERATIVE RETRIEVAL-GENERATION SYNERGY">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy" was published in 2023</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="LLAMA(&quot;ENTITY&quot;">
      <data key="d0">DUAN</data>
      <data key="d1">PERSON</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LLAMA 2">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLAMA 2 is a set of open foundation and fine-tuned chat models, as described in a paper published on arXiv in 2023.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Language Agent Tree Search (LATS) is a general framework that integrates the capabilities of language models (LMs) in reasoning, acting, and planning by leveraging Monte Carlo Tree Search, LM-powered value functions, and self-reflections for proficient exploration and enhanced decision-making</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="ANDY ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Andy Zhou is one of the authors of the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="KAI YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Kai Yan is one of the authors of the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="MICHAL SHLAPENTOKH-ROTHMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Michal Shlapentokh-Rothman is one of the authors of the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="HAOHAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Haohan Wang is one of the authors of the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="YU-XIONG WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yu-Xiong Wang is one of the authors of the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">University of Illinois Urbana-Champaign is the institution affiliated with the authors of the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="LAPIS LABS">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Lapis Labs is the institution affiliated with Andy Zhou, one of the authors of the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="MONTE CARLO TREE SEARCH (MCTS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Monte Carlo Tree Search (MCTS) is a heuristic search algorithm that builds a decision tree where every node represents a state and every edge represents an action. It is widely used in various decision-making environments and involves steps such as expansion and selection to explore and expand the tree. Inspired by its success in model-based reinforcement learning, MCTS has been adapted in LATS (Language Agents for Text-based Simulations) to enable language models to act as agents, facilitating proficient exploration and enhanced decision-making.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="GPT-4">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4 is a language model developed by OpenAI, widely recognized for its advanced capabilities and high performance across various tasks and benchmarks. It serves as a foundational model in numerous experimental evaluations, including those involving LATS and Reflexion, where it has achieved state-of-the-art results, such as a 92.7% pass@1 accuracy on HumanEval. GPT-4 is utilized as a baseline for scoring the performance of models evaluated with the Orca-Bench dataset and is known for its high performance in reading comprehension and math. It is also employed in the evaluation of summarization abilities and other tasks, acting as a judge in various benchmarks to assess model responses.

In the context of Meta Agent Search, GPT-4 is used by the meta agent to test the transferability of agents discovered by the system, showing improved performance on ARC tasks when compared to GPT-3.5. Additionally, GPT-4 is involved in the experimental evaluation of LATS, setting new standards in programming tasks. It is also used to generate responses for creating synthetic data and is coupled with tools like search and code interpreters by AgentInstruct to produce high-quality data.

Furthermore, GPT-4 has been evaluated on the MIRAGE Datasets, demonstrating high performance in both CoT and RAG tasks. It is used as a benchmark for evaluating the performance of a 7B model in reading comprehension sections of the LSAT and has been instrumental in various experiments, including those involving the ARC challenge. Overall, GPT-4 stands out as a powerful and versatile language model, integral to numerous AI and ML research and applications.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,0cf2e43f324fa4175b9b00b90e5e90ba,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,4b43decac6833d1515992f8869ecada7,5819b66e04fd77fa705574edc49395bb,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="GPT-3.5">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-3.5, developed by OpenAI in 2022, is a versatile language model extensively used in various experimental evaluations and benchmarks. It serves as a foundation model and baseline for testing the performance of agents discovered by Meta Agent Search. GPT-3.5 has been employed in numerous contexts, including the Game of 24, where it tests different configurations of LATS, and in web navigation tasks on WebShop, demonstrating gradient-free performance comparable to gradient-based fine-tuning.

The model has been evaluated on MBPP, where LATS achieved the highest performance, and on HumanEval, assessing performance over successive iterations. It has also been used to evaluate reasoning-based prompting results on the HotpotQA dataset. In the context of agentic systems, GPT-3.5 is noted for its complex feedback mechanisms and has been a reference point in experiments involving prompting methods such as ReAct, Reflexion, CoT, ToT, and RAP.

Additionally, GPT-3.5 has been instrumental in the ARC challenge, where it was used to evaluate discovered agents and baselines, and in the transfer of discovered agents to GPT-4, showing improved performance on ARC tasks. Despite its robust capabilities, it has been outperformed by Orca-3 on multiple benchmarks. Overall, GPT-3.5 is a critical tool in the AI and ML community for evaluating and enhancing the performance of various agentic and reasoning systems.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,4b43decac6833d1515992f8869ecada7,594449768ae2dea9b2efbe677075096b,7de66b94cf868b37b1df51dc545c415f,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b88745a13b69cecbc0ee9c3af41389bf,b8dd0300033963bb4a3e1bad37f8e7b9,bc26e68b0b2783ba912b9e5606d9eb0b,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="HUMANEVAL">
      <data key="d0">DATASET</data>
      <data key="d1">HumanEval is a dataset of 164 handwritten programming problems designed to evaluate the functional correctness of models that synthesize programs from natural language descriptions. It is used to measure the performance of various methods, including the LATS algorithm, particularly in programming tasks. Notably, when evaluated with GPT-4, HumanEval achieved a state-of-the-art Pass@1 accuracy rate of 92.7%, highlighting its effectiveness in assessing the programming performance and correctness of synthesized Python programs from natural language docstrings.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="WEBSHOP">
      <data key="d0">DATASET</data>
      <data key="d1">WebShop is an interactive web-based environment designed to evaluate agents on grounded language understanding and decision-making, simulating an e-commerce shopping task. It is composed of a website featuring 1.18 million real-world products and 12,000 human instructions, providing a complex decision-making environment. WebShop serves as a dataset for evaluating the performance of various prompting and training methods in language models, including the web navigation performance of LATS with GPT-3.5, where it demonstrated gradient-free performance comparable to gradient-based fine-tuning. The action space within WebShop includes actions such as searching, choosing items, and buying items, making it a comprehensive tool for assessing methods requiring reasoning and acting. It is specifically used to evaluate the performance of the LATS algorithm and other methods in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="REACT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ReAct is a prompting method used in various experiments, including those involving GPT-3.5 and LATS, achieving high performance on tasks like HotPotQA, HumanEval, and programming. It is a technique that augments language models with feedback or observations from an external environment, enhancing reasoning and decision-making. ReAct constructs an action space that includes both permissible actions and the language space of reasoning traces, extending language models to tasks where the mapping from input to output is enhanced by or requires interactions with an external environment, such as a game or API. While ReAct is simpler compared to LATS and has seen success in enhancing reasoning and decision-making, it is limited by its simplicity and cannot effectively adapt to changing environment conditions.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="INTERNATIONAL CONFERENCE ON MACHINE LEARNING (ICML)">
      <data key="d0">EVENT</data>
      <data key="d1">The International Conference on Machine Learning (ICML) is the conference where the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models" was presented</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="PMLR">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">PMLR (Proceedings of Machine Learning Research) is the publisher of the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="VIENNA, AUSTRIA">
      <data key="d0">LOCATION</data>
      <data key="d1">Vienna, Austria is the location where the 41st International Conference on Machine Learning (ICML) was held</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="CHOWDHERY ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Chowdhery et al. are authors referenced in the paper for their work on language models</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OPENAI">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">OpenAI is an organization renowned for its pioneering work on language models, including the development of the GPT Foundation Model. They are the creators of the GPT-4 and GPT-3.5 models, which have been utilized in various experiments and challenges such as the Meta Agent Search and the ARC challenge. OpenAI provides API services that are integral to numerous applications, including the get_json_response_from_gpt function. In addition to their technical contributions, OpenAI has published significant documentation, including the GPT-4 technical report on arXiv in 2023 and a blog post titled "Introducing ChatGPT" in November 2022.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,93cb0d0456e0822b5fe30a3e627405f8,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937,ef75d2c866bee783577ed9f65707cf13</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NALLAPATI ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Nallapati et al. are authors referenced in the paper for their work on summarization using language models</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BOWMAN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Bowman et al. are authors referenced in the paper for their work on language inference using language models</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="COBBE ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Cobbe et al. are authors referenced in the paper for their work on tasks requiring advanced common-sense reasoning or quantitative skills using language models</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAPAROV AND HE">
      <data key="d0">PERSON</data>
      <data key="d1">Saparov and He are authors referenced in the paper for their work on tasks requiring advanced common-sense reasoning or quantitative skills using language models</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YAO ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Yao et al. are authors referenced in the paper for their work on web navigation using language models. They have also conducted previous work related to the experiments mentioned in the text.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DENG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Deng et al. are authors referenced in the paper for their work on web navigation using language models</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SCHICK ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Schick et al. are authors referenced in the paper for their work on tool-use using language models</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FAN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Fan et al. are authors referenced in the paper for their work on open-ended games using language models</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GAO ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Gao et al. are authors referenced in the paper for their work on prompting techniques that augment language models with feedback or observations from an external environment</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHINN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Shinn et al. are authors referenced in the paper for their work on prompting techniques that augment language models with feedback or observations from an external environment</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SLOMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Sloman is an author referenced in the paper for their work on deliberate and thoughtful decision-making characteristics in humans</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="EVANS">
      <data key="d0">PERSON</data>
      <data key="d1">Evans is an author referenced in the paper for their work on deliberate and thoughtful decision-making characteristics in humans. They have contributed significantly to the understanding of complex decision-making tasks, highlighting the range of potential trajectories or reasoning paths that are correct.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,c234cb83764b899335af0950677ad024</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIE ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Xie et al. are authors referenced in the paper for their work on search-guided language models</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAO ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Hao et al. are authors referenced in the paper for their work on search-guided language models</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WOOLDRIDGE AND JENNINGS">
      <data key="d0">PERSON</data>
      <data key="d1">Wooldridge and Jennings are authors referenced in the paper for their work on general autonomous agents capable of reasoning and decision-making</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LATS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LATS (Language Agent Tree Search) is a comprehensive framework designed to enhance the performance of language models (LM) through interactions with an environment, thereby improving autonomous decision-making and interpretability. It unifies reasoning, acting, and planning in language models by adapting Monte Carlo Tree Search (MCTS) to language agents. This method combines internal reasoning and external retrieval strategies, optimizing performance with various parameters such as exploration weight, depth, and value function. LATS has been shown to outperform other methods in terms of performance and efficiency, particularly in tasks like HotPotQA, programming with HumanEval and MBPP, and the Game of 24, where it improves success rates using self-consistency scores. Additionally, LATS enhances score and success rates in WebShop, surpassing RL-based training methods. By constructing the best trajectory from sampled actions, LATS enables more flexible and adaptive problem-solving compared to reflexive prompting methods.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,4ae237a491bc8a84cc720e40c59a7464,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SELF-REFINEMENT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Self-refinement is a heuristic incorporated into LATS to guide the search process and improve model sensibility</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SELF-CONSISTENCY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Self-consistency is a heuristic incorporated into LATS (Learning and Action Transfer System) to guide the search process and improve model sensibility. In this context, self-consistency ensures that actions sampled multiple times at the same state tend to be more accurate, thereby enhancing the reliability and precision of the model's predictions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="COBEE">
      <data key="d0">PERSON</data>
      <data key="d1">Cobbe is an author who has worked on reasoning for language models, particularly in decomposing complex inputs into sequential intermediate stepsCobbe is an author who has worked on reasoning for language models</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WEI">
      <data key="d0">PERSON</data>
      <data key="d1">Wei is an author associated with the Chain-of-Thought (CoT) state-of-the-art hand-designed agent. Wei has contributed significantly to the development of chain-of-thought planning and reasoning, as well as various prompting methods used in language models. Notably, Wei's work includes contributions to CoT prompting and its variants, which are employed in numerous experiments to enhance reasoning capabilities. Additionally, Wei has been involved in the development of the ReAct prompting method, further advancing the field of AI and ML.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,594449768ae2dea9b2efbe677075096b,7c08d98f503d722d7de13be55375c8cb,99d90aededb61e04241516ed9ec656cc,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KOJIMA">
      <data key="d0">PERSON</data>
      <data key="d1">Kojima is an author who has worked on chain-of-thought (CoT) prompting and its variants for reasoning in language models</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GUO">
      <data key="d0">PERSON</data>
      <data key="d1">Guo is an author who has worked on addressing error propagation in chain-of-thought (CoT) prompting for language models</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAO">
      <data key="d0">PERSON</data>
      <data key="d1">Hao is an author who has contributed significantly to the development and application of Reasoning via Planning (RAP) techniques. His work encompasses various aspects of RAP, including prompting methods and search approaches. Notably, Hao has utilized Monte Carlo Tree Search (MCTS) with rollouts simulated by language models in his research on RAP, which has been employed in numerous experiments.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BESTA">
      <data key="d0">PERSON</data>
      <data key="d1">Besta is an author who has worked on improving chain-of-thought (CoT) prompting with search algorithms</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AHN">
      <data key="d0">PERSON</data>
      <data key="d1">Ahn is an author who has worked on adapting language models as high-level controllers in robotics</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DRIESS">
      <data key="d0">PERSON</data>
      <data key="d1">Driess is an author who has worked on adapting language models as high-level controllers in robotics</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BAKER">
      <data key="d0">PERSON</data>
      <data key="d1">Baker is an author who has worked on adapting language model agents to complex multimodal games such as Minecraft</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GUSS">
      <data key="d0">PERSON</data>
      <data key="d1">Guss is an author who has worked on the Minecraft gameGuss is an author who has worked on complex multimodal games such as Minecraft</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FAN">
      <data key="d0">PERSON</data>
      <data key="d1">Fan is an author who has worked on complex multimodal games such as Minecraft. They have contributed to the development of the Minecraft game and have also explored using planning-based prompting methods in environments like Minecraft.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHRIDHAR">
      <data key="d0">PERSON</data>
      <data key="d1">Shridhar is an author who has made significant contributions to the field of language models, particularly in text-based environments and acting-based prompting techniques. Additionally, Shridhar has worked on text-based manipulation tasks, including projects like Alfworld.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MADAAN">
      <data key="d0">PERSON</data>
      <data key="d1">Madaan is an author associated with the Self-Refine state-of-the-art hand-designed agent and has significantly contributed to the development of self-reflection in agentic systems. In 2024, Madaan's work on self-reflection and self-refinement techniques for language models was notable, particularly in the context of the Self-Refine method. Madaan's research includes contributions to self-reflection iterations in meta agents and the broader concept of self-refinement in language models.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHINN">
      <data key="d0">PERSON</data>
      <data key="d1">Shinn is an author mentioned in the text, contributing significantly to the development of self-reflection in agentic systems. In 2023, Shinn's work focused on the concept of self-reflection, particularly in language models. Shinn has been associated with Reflexion, a prompting method and self-improvement technique used in various experiments, and has also contributed to the research on Self-Refine and self-reflection iterations in meta agents.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SILVER">
      <data key="d0">PERSON</data>
      <data key="d1">Silver is an author who has made significant contributions to the field of artificial intelligence and machine learning. In 2017, Silver contributed to research on learned heuristics, showcasing their expertise in developing advanced problem-solving techniques. Additionally, Silver has worked extensively on model-based reinforcement learning and Monte Carlo Tree Search (MCTS), further highlighting their role in advancing AI methodologies.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="YA0">
      <data key="d0">PERSON</data>
      <data key="d1">Yao is an author who has made significant contributions to the field of Artificial Intelligence and Machine Learning. Yao has worked on various innovative methods and datasets, including the ReAct prompting technique, the ToT prompting technique, and the WebShop dataset. These contributions highlight Yao's expertise and influence in developing advanced AI and ML methodologies.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SEARCH ALGORITHMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Search Algorithms are methods used to navigate through data or problem spaces to find solutions. They are integrated with LM agents in experiments, extending ToT and RAP with ReAct prompting to handle external observations. In the context of LATS (Language Agents), search algorithms are adapted to construct trajectories and improve decision-making. However, in custom search spaces like graphs, search algorithms may be less efficient due to the absence of priors.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="PROMPTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">PROMPTS are inputs given to language models to guide their responses. They play a crucial role in various applications, such as being used in LATS (Language and Task Systems) to store and retrieve external feedback. Additionally, prompts are utilized by the meta agent in the Meta Agent Search algorithm to program new agents. In the context of datasets generated by AgentInstruct, prompts refer to the initial inputs or questions given to a model to generate responses.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,dd9a46950237e49ef9b1c7ef08e08d42,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="VALUE ASSIGNMENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Value assignment is a process in search algorithms where values are assigned to nodes based on heuristics, and is incorporated in LATS</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="INTERNAL REASONING PERFORMANCE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Internal reasoning performance refers to the ability of a language model to reason and solve problems without external feedback, which LATS aims to surpass</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MODEL-BASED REINFORCEMENT LEARNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Model-based reinforcement learning is a type of machine learning where models are used to simulate environments and make decisions, inspiring the use of MCTS in LATS</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LM-POWERED VALUE FUNCTIONS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LM-powered value functions are value functions powered by language models, used in LATS for cleverer exploration</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SELF-REFLECTIONS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Self-reflections are techniques where language models reflect on their own outputs to improve performance, used in LATS</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="PLANNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Planning is the process of creating a sequence of actions to achieve a goal and is a key component of LATS. In the context of AI and language models, planning involves making detailed plans to guide the development and implementation of these technologies.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="REASONING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Reasoning is one of the skills covered in the synthetic post-training dataset created by AgentInstruct. It is the process of thinking about something in a logical way to form a conclusion or judgment. This cognitive skill is further enhanced by LATS, which contributes to more effective and structured logical thinking.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f,b88745a13b69cecbc0ee9c3af41389bf,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="ACTING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Acting is the process of performing actions based on instructions or decisions. It refers to the execution of actions based on decisions made by language models and is a component of LATS (Language Action Transformation Systems).</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="DECISION-MAKING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Decision-making is the process of making choices by identifying a decision, gathering information, and assessing alternative resolutions, and is enhanced by LATS</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="PROGRAMMING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Programming is the process of creating a set of instructions that tell a computer how to perform a task. It involves writing code to solve problems and is evaluated using datasets like HumanEval and MBPP to measure the correctness of synthesized programs in Python from natural language docstrings. Programming is also one of the domains evaluated by the LATS algorithm to demonstrate its general applicability and performance.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="INTERACTIVE QUESTION-ANSWERING (QA)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Interactive question-answering (QA) is a task where language models answer questions based on interaction with the environment, and is one of the domains where LATS is tested</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WEB NAVIGATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">WEB NAVIGATION is an environment where LATS (Learning and Adaptive Trajectory Systems) determines the success of a trajectory, such as finalizing a purchase. It is also the process of browsing the web to find information, and is one of the domains where LATS is tested.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MATH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">MATH is a domain where agents are tested and evaluated for their performance. It serves as one of the benchmarks used to assess the agent's abilities in various experiments. Additionally, Math is one of the skills covered in the synthetic post-training dataset created by AgentInstruct. Fundamentally, Math is the abstract science of number, quantity, and space, and is one of the domains where LATS (Learning and Testing Systems) is tested.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb,b88745a13b69cecbc0ee9c3af41389bf,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (COT) PROMPTING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Chain-of-thought (CoT) prompting is a method for reasoning in language models that involves decomposing complex inputs into sequential intermediate steps. This technique is particularly useful in scenarios where the direct mapping from input to output is intricate, such as mathematical queries or challenging questions. By creating intermediate thoughts that act as stepping stones between the input and the output, CoT prompting facilitates a more structured and effective problem-solving process.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="ERROR PROPAGATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Error propagation refers to the accumulation of errors in a process, which can occur in chain-of-thought (CoT) prompting as the number of steps increases</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MAJORITY VOTING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Majority voting is a technique where the most common output among multiple samples is chosen, used in self-consistency to mitigate error propagation</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MULTI-STEP DECOMPOSITION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Multi-step decomposition is a method for breaking down complex tasks into smaller, manageable steps, used in least-to-most prompting</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LEAST-TO-MOST PROMPTING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Least-to-most prompting is a method for multi-step decomposition in language models</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="TREE-OF-THOUGHT (TOT) PROMPTING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Tree-of-thought (ToT) prompting extends chain-of-thought (CoT) prompting by exploring multiple reasoning paths over thoughts. It frames problems as a search over a tree, where each node represents a partial solution state. This method employs depth-first or breadth-first search, guided by a language model-generated heuristic, to enhance reasoning in language models.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="REASONING VIA PLANNING (RAP)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Reasoning via planning (RAP) is a method that uses Monte Carlo Tree Search (MCTS) with rollouts simulated by language models for reasoning</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="DFS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">DFS (Depth-First Search) is a fundamental search algorithm utilized in various contexts within the field of Artificial Intelligence and Machine Learning. It is prominently used in the Tree-of-Thought (ToT) method for HotPotQA, a question-answering task. Additionally, DFS is often compared to Monte Carlo Tree Search (MCTS) as a variant search algorithm. Its application in ToT prompting highlights its importance in exploring and mapping out complex decision trees, making it a critical tool for AI researchers and practitioners.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="BFS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">BFS (Breadth-First Search) is a search algorithm used in tree-of-thought (ToT) prompting</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="POLICY MODEL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A policy model is a model used to make decisions or take actions in an environment, used in interactive tasks for language models</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ROBOTICS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Robotics is a multifaceted domain that encompasses the design, construction, operation, and application of robots. In this field, Foundation Models play a crucial role in writing reward functions for reinforcement learning and creating learning environments. Additionally, language models are employed as high-level controllers, enhancing the capabilities and functionalities of robotic systems. This integration of advanced AI techniques underscores the dynamic and evolving nature of robotics, highlighting its significance in both technological innovation and practical applications.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CONTROL POLICIES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Control policies are strategies used to control the actions of robots or other systems, where language models have been used as high-level controllers</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="MULTIMODAL GAMES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Multimodal games are games that involve multiple modes of interaction, such as visual and textual, where language model agents have been adapted</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="MINECRAFT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Minecraft is a complex multimodal game where language model agents have been adapted. It is also an environment suggested for future work using planning-based prompting methods like LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TEXT-BASED ENVIRONMENTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Text-based environments are environments where interactions are primarily through text, where language models have been used for acting-based prompting techniques</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="REFLEXION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Reflexion is a self-improvement technique for language models that focuses on enhancing reasoning and decision-making. It is a prompting method used in various experiments, including those with GPT-3.5, and has demonstrated high performance in tasks such as HotPotQA and HumanEval. Reflexion is competitive with other advanced prompting methods like ToT and RAP, and it is simpler compared to LATS. It is particularly effective in decision-making tasks where reverting between iterations is feasible, and it shares similarities with the ReAct method.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="EXTERNAL FEEDBACK">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">External feedback is incorporated into LATS to improve decision-making. It is information from the environment that is used to enhance the performance of language models, thereby contributing to the overall effectiveness of LATS.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="SELF-IMPROVEMENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Self-improvement refers to techniques where language models improve their own performance, such as self-refinement and Reflexion</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ENVIRONMENTAL CONDITIONS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Environmental conditions refer to the state of the environment that language models must adapt to, which LATS can handle without additional training</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORIES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">TRAJECTORIES refer to the sequences of actions or steps taken to achieve a goal, constructed by LATS from sampled actions. In the context of LATS, "Trajectories (k)" is a parameter that determines the number of trajectories sampled, which in turn affects performance over time. Essentially, trajectories represent the number of paths sampled in the search process, playing a crucial role in the efficiency and effectiveness of the system.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,48e423e2baf2ed485872756f5b4d87d8,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="HEURISTICS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Heuristics are strategies or principles used to guide decision-making or problem-solving, incorporated in LATS for value assignment and search processes</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="SAMPLED CHAINS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Sampled chains are sequences of steps generated by language models, used in self-consistency for majority voting</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ROLLOUTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Rollouts are simulations of actions or steps taken to predict outcomes, used in reasoning via planning (RAP) with Monte Carlo Tree Search (MCTS)</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="LM-GENERATED HEURISTIC">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">An LM-generated heuristic is a heuristic generated by a language model to guide search processes, used in tree-of-thought (ToT) prompting</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="COT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Chain-of-Thought (CoT) is a prompting method used in language models to enhance reasoning accuracy and performance on complex tasks. This technique involves prompting the model to think step by step before answering a question, which is particularly useful in scenarios where the direct mapping from input to output is intricate. CoT is employed in environments without feedback, such as reasoning tasks, and has been used in various experiments, including those involving LATS, achieving high performance in tasks like HotPotQA, HumanEval, and the Game of 24.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,97457e990eb6e3c88c11c862f9e3265b,99d90aededb61e04241516ed9ec656cc,ab04427ae0415a1c812a35cf8d3ee1a2,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="SELF-REFINE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Self-Refine, as described by Madaan et al. (2024), is a state-of-the-art, manually designed agent framework that serves as a baseline for various experimental studies, including those on the ARC dataset. This system is capable of performing tasks such as Math, Reading Comprehension, Multi-task, and Science. It employs a method of iterative self-reflection and refinement, allowing up to five iterations with an early stop if the critic deems the answer correct. Self-Refine enhances reasoning and decision-making in language models through self-improvement and self-feedback mechanisms. It is also utilized in Meta Agent Search to refine generated agents, and its detailed methodology is documented in a paper published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,1b1399c76420a477c0c97893d258ae69,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ADAPLANNER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AdaPlanner is a method that incorporates both positive and negative feedback to enhance reasoning and decision-making in language models</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="EXTERNAL TOOLS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">External tools, also referred to as tools or APIs, are integral components used in reasoning tasks as part of the action space. These tools, which include APIs, search engines, calculators, and other models, are employed to enhance the reasoning and practical abilities of language models. By leveraging these external resources, language models can perform more complex and accurate tasks, thereby improving their overall functionality and effectiveness in various applications.</data>
      <data key="d2">c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TREE-BASED SEARCH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Tree-based search is a method where multiple branches of outcomes are explored during search, widely used in planning and reinforcement learning algorithms for its good exploration-exploitation trade-off</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="MCTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">MCTS (Monte Carlo Tree Search) is a principled, tree-based search algorithm that serves as the foundation for observed performance gains in various applications. It requires an environment model to undo previous steps and form a searching tree, ensuring a structured and efficient search process. MCTS is notably used in the LATS framework to select high-value options while exploring promising alternatives, thereby fully unlocking the potential of language models.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Xie is an author who has worked on Beam Search techniques</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SWIECHOWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Swiechowski is an author who has worked on tree-based search algorithms</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LAVALLE">
      <data key="d0">PERSON</data>
      <data key="d1">LaValle is an author who has worked on planning algorithms</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAFNER">
      <data key="d0">PERSON</data>
      <data key="d1">Hafner is an author who has worked on reinforcement learning algorithms</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DU">
      <data key="d0">PERSON</data>
      <data key="d1">Du is an author associated with the LLM Debate state-of-the-art hand-designed agent and has contributed to research in LLM Debate techniques in 2023. Additionally, Du has worked on reinforcement learning algorithms, showcasing a broad expertise in advanced AI methodologies.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VODOPIVEC">
      <data key="d0">PERSON</data>
      <data key="d1">Vodopivec is an author who has worked on environment models for tree-based search</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TOT">
      <data key="d0" />
      <data key="d1">ToT (Tree of Thoughts) is a prompting and search method that incorporates language model (LM)-based heuristics to prune branches with low values. It is compared to LATS in terms of sample complexity and performance, and it inspires the value function in LATS by prompting the language model to reason about a given state. ToT is used in various experiments, including those involving LATS, and has achieved high performance in tasks such as HotPotQA and HumanEval. By sampling and exploring more outputs, ToT demonstrates significant gains in performance on reasoning tasks.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="RAP">
      <data key="d0" />
      <data key="d1">RAP (Reasoning and Planning) is a method used in language models to enhance reasoning and planning capabilities. It is a prompting method employed in various experiments, including those involving LATS, and has demonstrated high performance in tasks such as HotPotQA and HumanEval. RAP is a reasoning-based method that relies solely on the internal representations of the language model, which means it cannot consider external observations. This method is used in planning strategies but has limitations in flexibility and adaptability. Additionally, RAP is a search method that performs well on reasoning tasks, utilizing a search algorithm similar to LATS. It is also a variant of Monte Carlo Tree Search (MCTS) that relies on internal dynamics models to facilitate simulation.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="BEAM SEARCH">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="PLANNING ALGORITHMS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="REINFORCEMENT LEARNING">
      <data key="d0" />
      <data key="d1">Reinforcement Learning is a research area focused on how agents should take actions in an environment to maximize cumulative reward. It is a type of machine learning where agents learn to make decisions by receiving rewards, as demonstrated in methods like Eureka and Language-to-Reward. However, it is also noted that some approaches, such as those employed by LATS, aim to avoid traditional reinforcement learning by using self-reflection and in-context learning for optimization.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="ENVIRONMENT MODELS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="SCHICK">
      <data key="d0">PERSON</data>
      <data key="d1">Schick is an author mentioned in the text, contributing significantly to the development of tool use in agentic systems. In 2023, Schick's work is particularly noted for providing external tools to enhance language models, showcasing their expertise in advancing the capabilities of AI and ML technologies.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="SUR&#205;S">
      <data key="d0">PERSON</data>
      <data key="d1">Sur&#237;s is an author who has worked on providing external tools to enhance language models</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="LANGUAGE MODELS (LMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Language Models (LMs) are models that transform input prompts into outputs. They are used in various prompting techniques like CoT, ToT, and ReAct to improve reasoning and decision-making tasks</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="WEI ET AL., 2022">
      <data key="d0">REFERENCE</data>
      <data key="d1">Wei et al., 2022 is a reference to the authors who introduced Chain-of-thought (CoT) prompting</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="YAO ET AL., 2023A">
      <data key="d0">REFERENCE</data>
      <data key="d1">Yao et al., 2023a is a reference to the authors who introduced Tree-of-thought (ToT) prompting</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="YAO ET AL., 2023B">
      <data key="d0">REFERENCE</data>
      <data key="d1">Yao et al., 2023b is a reference to the authors who introduced ReAct</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="HAO ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">Hao et al., 2023 is a reference to the authors who introduced RAP</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="SHINN ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">Shinn et al., 2023 is a reference to the authors who introduced Reflexion</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="KOCSIS AND SZEPESV&#193;RI, 2006">
      <data key="d0">REFERENCE</data>
      <data key="d1">Kocsis and Szepesv&#225;ri, 2006 is a reference to the authors who introduced the UCT (Upper Confidence bounds applied to Trees) value used in MCTS</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="YE ET AL., 2021">
      <data key="d0">REFERENCE</data>
      <data key="d1">Ye et al., 2021 is a reference to the authors who applied MCTS to decision-making environments like Atari</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="SILVER ET AL., 2016">
      <data key="d0">REFERENCE</data>
      <data key="d1">Silver et al., 2016 is a reference to the authors who applied MCTS to decision-making environments like Go</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="INPUT X">
      <data key="d0">DATA</data>
      <data key="d1">Input x is the initial data or query provided to the language model for processing</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="OUTPUT Y">
      <data key="d0">DATA</data>
      <data key="d1">Output y is the final result produced by the language model after processing the input and prompt</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="THOUGHTS Z">
      <data key="d0">DATA</data>
      <data key="d1">Thoughts z are intermediate language sequences created during the Chain-of-thought (CoT) prompting process to act as stepping stones between the input and the output</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="DECISION-MAKING TASKS">
      <data key="d0">TASK</data>
      <data key="d1">Decision-making tasks are complex problems that involve multifaceted decision-making and require advanced reasoning, acting, and planning techniques. These tasks necessitate a comprehensive approach to reasoning and planning, highlighting the intricate nature of the decision-making process.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="ENVIRONMENTAL FEEDBACK">
      <data key="d0">DATA</data>
      <data key="d1">Environmental feedback refers to observations and data from the external environment used to improve reasoning and acting in techniques like ReAct. It is also utilized in LATS (Learning and Adaptation Through Simulation) to enhance value assignment and scaling to more challenging environments. This feedback mechanism plays a crucial role in refining AI and ML models by incorporating real-world data, thereby enabling more accurate and effective decision-making processes.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)">
      <data key="d0">ALGORITHM</data>
      <data key="d1">Upper Confidence bounds applied to Trees (UCT) is a value used in Monte Carlo Tree Search (MCTS) to select the best child node for expansion based on exploration and exploitation</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="EXPANSION">
      <data key="d0">PROCESS</data>
      <data key="d1">"Expansion" refers to multiple concepts within different contexts. In the realm of Monte Carlo Tree Search (MCTS), Expansion is a step where multiple children states are explored from the current parent state by sampling actions. This process is crucial for the algorithm to evaluate potential future states and make informed decisions. Additionally, in the context of LATS (likely referring to a specific algorithm or framework), Expansion is the second operation where the tree is expanded by sampling actions from P&#952; and adding new child nodes, further enhancing the decision-making process. Outside of these algorithmic contexts, Expansion can also refer to a text modification task that involves adding more information to the text, thereby enriching its content and providing greater detail.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SELECTION">
      <data key="d0">PROCESS</data>
      <data key="d1">Selection is a crucial step in both Monte Carlo Tree Search (MCTS) and Learning Automata Tree Search (LATS). In MCTS, selection involves choosing the child node with the highest Upper Confidence Bound for Trees (UCT) value for expansion in the next iteration. In LATS, selection is the first operation where the algorithm identifies a segment of the current tree most suitable for subsequent expansion, choosing the best action based on the value function and exploration weight.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="BACKPROPAGATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Backpropagation is a crucial operation in both Monte Carlo Tree Search (MCTS) and Learning Automata Tree Search (LATS). In MCTS, backpropagation is the step where the return is used to update the value function of every node along the path after the end of an episode. Similarly, in LATS, backpropagation involves updating the value function based on the rewards received, where the resulting value from a terminal node is used to update the value function along the path.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="RETURN R">
      <data key="d0">DATA</data>
      <data key="d1">Return r is the reward or outcome used in the backpropagation step of Monte Carlo Tree Search (MCTS) to update the value function of nodes</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="VALUE FUNCTION V(S)">
      <data key="d0">DATA</data>
      <data key="d1">Value function V(s) is the expected return from the subtree of a node s in Monte Carlo Tree Search (MCTS)</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="EXPLORATION WEIGHT W">
      <data key="d0">DATA</data>
      <data key="d1">Exploration weight w is a parameter used in the UCT calculation to balance exploration and exploitation in Monte Carlo Tree Search (MCTS)</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="PARENT NODE P">
      <data key="d0">DATA</data>
      <data key="d1">Parent node p is the current state from which child states are explored in the expansion step of Monte Carlo Tree Search (MCTS)</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="CHILD NODE S">
      <data key="d0">DATA</data>
      <data key="d1">Child node s is a state explored from the parent node in the expansion step of Monte Carlo Tree Search (MCTS)</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="PROMPT">
      <data key="d0" />
      <data key="d1">PROMPT is a specific instruction given to a language model to generate a response. It is a technique used in HotPotQA to guide the language model through a series of Thought, Action, and Observation steps to solve a question answering task. Additionally, the prompt serves as a set of instructions given to the meta agent to guide its output and improve the quality of the generated code. The prompt is constructed in a structured format by concatenating all input Info objects, each titled by its metadata.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,8ee9617c145e19fa95f1f9349bfbe69b,9bb90746134619cad9a3e649b8b35f24,b8dd0300033963bb4a3e1bad37f8e7b9,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="LM TASKS">
      <data key="d0">TASK</data>
      <data key="d1">LM tasks refer to tasks involving language models, which can conveniently reset to any step by simply copy-pasting historical text input</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="LM AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LM Agent is a system that supports sequential reasoning or decision-making tasks by leveraging language models as base decision-makers</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="P&#920;">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">P&#952; is a language model utilized within the LATS (Learning Agent Trajectory System) framework. It serves multiple roles, including acting as an agent, state evaluator, and feedback generator. Specifically, P&#952; is employed to reason about a given state and provide a scalar value that indicates the correctness of the trajectory. Additionally, P&#952; functions as a parameter in LATS that represents the action generator, contributing to the overall decision-making process within the system.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="UCT ALGORITHM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">UCT (Upper Confidence bounds applied to Trees) is an algorithm used to balance exploration and exploitation in tree search</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="EVALUATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Evaluation is a multifaceted process integral to various domains, including the LATS framework and the assessment of language models. In the context of LATS, Evaluation is an action that scores states based on the value function, serving as the third operation where a scalar value is assigned to each new child node to quantify the agent&#8217;s progress in task completion. Additionally, Evaluation encompasses the broader process of assessing the performance of language models on various benchmarks and tasks, ensuring that these models meet the required standards and perform effectively across different applications.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,8ee9617c145e19fa95f1f9349bfbe69b,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SIMULATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Simulation is an operation in LATS where the algorithm simulates actions until a terminal node is reached</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="REFLECTION">
      <data key="d0">PROCESS</data>
      <data key="d1">"REFLECTION" is a critical action within the Learning from Agentic Trial and Simulation (LATS) framework, enabling agents to learn from experience. It involves evaluating the outcome of a previous attempt, identifying mistakes, and planning for future actions. When a state is not successful, reflection generates additional context for future trials, thereby enhancing the learning process. This process is essential for agentic systems, as highlighted by Madaan et al. (2024) and Shinn et al. (2023). Reflection serves as a building block for these systems, ensuring continuous improvement and adaptation by reviewing proposed architectures and suggesting necessary improvements.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,282313a8340c6792e8c35f53ed157cd0,48e423e2baf2ed485872756f5b4d87d8,4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7,c234cb83764b899335af0950677ad024,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="EXPLORATION WEIGHT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Exploration weight (w) is a parameter used in both the LATS and MCTS algorithms. In the context of LATS, it affects the effectiveness of the search, with various values tested in experiments to optimize performance. In the MCTS algorithm, exploration weight is crucial for balancing exploration and exploitation, ensuring that the search process is both thorough and efficient.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="PARENT NODE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Parent node is a node in the MCTS tree from which child nodes are derived</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="RETURN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Return is a value used in the backpropagation process of MCTS to update the value function</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="VALUE FUNCTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Value Function is a critical component utilized across various applications to evaluate the performance and desirability of actions or states based on certain hyperparameters. In WebShop and the Game of 24, the Value Function assesses the performance of actions. In Monte Carlo Tree Search (MCTS), it evaluates the desirability of a state. Additionally, the Value Function is integral to the scoring mechanism in Language Model (LM) scoring used in LATS, where it is proposed based on a self-generated LM score and other components.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ENVIRONMENT MODEL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Environment model is a model required by MCTS to undo previous steps and form a searching tree</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="HISTORICAL TEXT INPUT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Historical text input is used in LM tasks to reset to any step by copy-pasting</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="BASE PROMPTING FRAMEWORK">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Base prompting framework is the initial design framework for LM Agent to support reasoning or decision-making tasks</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="OBSERVATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">OBSERVATION is an action where the user or agent notes the results or feedback from a previous action. In the context of HotPotQA, it refers to the model receiving information based on the previous action. More broadly, an observation is an environmental input or feedback about the situation in a trajectory of a question-answering task. It is the input received by an agent from the environment at each time step, providing crucial information for subsequent actions.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="ACTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ACTION refers to the steps taken by an agent or user during a question-answering task, particularly in the context of HotPotQA. These steps, known as actions, can involve searching for an entity, looking up a keyword, or finishing with an answer. In this setting, an action is the output taken by an agent following a policy in response to an observation, and it is a crucial part of the trajectory in the search process.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,5d356b8ff719763a38cecff22c4e17b7,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="POLICY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Policy is a strategy used by an agent to determine actions based on observations and previous actions</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="LANGUAGE REPRESENTATIONS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Language representations are useful features of a language model leveraged by LM Agent for decision-making</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="ACTION SPACE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Action space is the set of all possible actions an agent can take, including permissible actions and reasoning traces</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="REASONING TRACES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Reasoning traces are thoughts used to formalize decisions by organizing information, planning future actions, or injecting internal knowledge</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="TRAJECTORY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">TRAJECTORY refers to the path or sequence of actions taken by an agent or user during a process. It encompasses a sequence of actions or reasoning paths sampled by an agent, highlighting the steps or decisions made throughout the search or decision-making process.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SEARCH ALGORITHM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Search algorithm is the main component of LATS that controls the problem-solving process with planning</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="TREE SEARCH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Tree search is a method used in LATS to frame decision-making as a search through a tree of possible states</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="STATE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">STATE is a general term for different stages or conditions in WebShop. Additionally, STATE represents the current situation in the tree search, encompassing input, actions, and observations.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="LONG-TERM MEMORY STRUCTURE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Long-term memory structure is an external storage used to store the tree in LATS</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SCALAR VALUE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Scalar value is a value assigned to each new child node during evaluation to quantify the agent&#8217;s progress</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="HEURISTIC">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Heuristic is a method used to steer the search algorithm towards the most promising regions of the tree</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="CAMPBELL">
      <data key="d0">PERSON</data>
      <data key="d1">Campbell is an author who contributed to the research on programmed heuristics in 2002</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AUSTIN">
      <data key="d0">PERSON</data>
      <data key="d1">Austin is an author who has made significant contributions to the research on programming domains. He has been actively involved in programming-related tasks that were evaluated in various experiments. Additionally, Austin has worked on the MBPP dataset, further showcasing his expertise and involvement in the field of programming and data analysis.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="UCT FORMULA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The UCT (Upper Confidence bounds applied to Trees) formula is used in LATS to guide the selection of the next node based on updated values</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="SELF-REFLECTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Self-Reflection is a technique used in various agentic systems and frameworks to enhance task performance through iterative self-assessment and feedback analysis. It involves the process where the AI or meta agent reviews its previous attempts, identifies errors, and proposes superior alternatives. In the context of LATS (Language Agent Task Systems), self-reflection includes providing a verbal summary of errors and suggesting improvements after encountering unsuccessful terminal nodes. Additionally, in AI Python assistants, self-reflection entails reviewing previous implementations to identify issues and make the code novel and error-free. This technique is crucial for continuous improvement and optimization in AI systems.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,282313a8340c6792e8c35f53ed157cd0,785ad59c6a37896a4676ec5c1689735f,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="GAME OF 24">
      <data key="d0">DATASET</data>
      <data key="d1">The "Game of 24" is a dataset used to evaluate methods requiring reasoning and acting. It is a mathematical reasoning challenge where the goal is to use basic arithmetic operations to construct the number 24 from four given numbers. This task involves an agent constructing the number 24 from a set of numbers using basic operations, making it a valuable tool for assessing mathematical reasoning capabilities.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="COT-SC">
      <data key="d0" />
      <data key="d1">COT-SC (Wang et al., 2023b) is a state-of-the-art, manually designed agent technique used for comparison in various studies. It performs tasks such as Math, Reading Comprehension, Multi-task, and Science, serving as a baseline for comparison in the text. The method involves sampling five answers and then performing an ensemble using either majority voting or an FM query. COT-SC is a strategy employed in Meta Agent Search for generating and refining answers. It is also known as Chain of Thought with Self-Consistency (CoT-SC), a variant of the Chain of Thought (CoT) prompting method, and is compared to LATS in terms of efficiency. The technique is referenced by Wang et al., 2023b, and is noted for its specific performance metrics in various experiments.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,42de130f5b6144472a86a4c8260a87c7,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="EXPERIMENTS">
      <data key="d0">EVENT</data>
      <data key="d1">Experiments are conducted to demonstrate the general applicability of LATS across various domains requiring reasoning and acting. Additionally, experiments refer to the tests conducted to validate the effectiveness of Meta Agent Search in discovering new agents.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="PROMPT METHOD">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Prompt Method is a versatile technique employed in various contexts to guide language models through specific tasks. It is used in the Game of 24 to assist the model in task execution and in experiments to evaluate performance on HotPotQA. The Prompt Method encompasses different configurations and techniques, including ReAct, Reflexion, ToT, RAP, and LATS, to achieve various performance metrics on HotPotQA.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="EXACT MATCH (EM)">
      <data key="d0">METRIC</data>
      <data key="d1">Exact Match (EM) is a metric used to evaluate the performance of various methods, including LATS and its baseline variants, on HotpotQA.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="PASS@1">
      <data key="d0">METRIC</data>
      <data key="d1">Pass@1 is a metric used to evaluate the performance of different methods on HumanEval</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="API CALLS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">API Calls are used to search and retrieve information in the HotPotQA setup, forming part of the observation space for the agent</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="ORACLE SETUP">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Oracle Setup is used in HotPotQA to provide feedback about the answer&#8217;s correctness, enabling fair comparison between methods</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="INTERNAL REASONING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Internal Reasoning refers to strategies that rely solely on the agent&#8217;s existing knowledge to answer questions, evaluated in the experiments</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="EXTERNAL RETRIEVAL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">External Retrieval refers to strategies that augment the agent with an interactive API environment to evaluate its information retrieval abilities</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="INTERNAL AND EXTERNAL REASONING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Internal and External Reasoning is a combined approach in LATS that uses CoT-based prompts and switches to ReAct-based prompts upon failure</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="MODERN LMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Modern LMs refer to large-scale language models that already encode factual information due to their extensive training corpus</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="MBPP">
      <data key="d0">DATASET</data>
      <data key="d1">MBPP (Mostly Basic Python Problems) is a dataset used to measure the correctness of synthesized programs in Python from natural language docstrings</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="IL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">IL (Imitation Learning) is a method used in combination with RL for training language models</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="RL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">RL (Reinforcement Learning) is a method used in combination with IL for training language models</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="FURUTA">
      <data key="d0">PERSON</data>
      <data key="d1">Furuta is an author who has made significant contributions to the field of fine-tuning methods for language models. Their work on fine-tuning, as mentioned in the text, highlights their expertise and impact in this specialized area of artificial intelligence and machine learning.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SEARCH METHODS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Search methods like ToT and RAP are used to sample and explore more outputs, showing larger gains in performance on reasoning tasks</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="HUMANEVAL DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">HumanEval is a dataset used to measure the correctness of synthesized programs in Python from natural language docstrings</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="MBPP DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">MBPP (Mostly Basic Python Problems) is a dataset used to measure the correctness of synthesized programs in Python from natural language docstrings</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="GPT-3.5 MODEL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-3.5 is a language model evaluated on MBPP, where LATS achieves the highest performance</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="GPT-4 MODEL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4 is a more advanced language model that, when used with LATS, sets the state of the art for HumanEval</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="FINE-TUNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Fine-tuning is a method used to improve the performance of language models, as demonstrated by Furuta et al. in 2024. This technique, mentioned in the text, was contributed by Furuta et al., highlighting its significance in enhancing the capabilities of language models.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="EXPERT">
      <data key="d0">PERSON</data>
      <data key="d1">EXPERT refers to a human expert whose performance is used as a benchmark in the WebShop dataset. This human performance benchmark is mentioned in the text, serving as a standard for evaluating the effectiveness and accuracy of other entities or systems within the dataset.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="WEBSHOP DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">WebShop is a dataset used to evaluate the performance of various prompting and training methods in language models</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="CHAIN OF THOUGHT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="A*">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A* is a search algorithm mentioned as a variant compared to MCTS</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="IL+RL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">IL+RL is a method mentioned in the text, contributed by Yao et al., 2022</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="LANGUAGE AGENT TREE SEARCH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Language Agent Tree Search (LATS) is a framework that unifies reasoning, acting, and planning in language models. The document titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models" includes the appendix and details of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="PERFORMANCE">
      <data key="d0">METRIC</data>
      <data key="d1">Performance is a general term referring to how well language models perform on various benchmarks and tasks. It is a metric used to evaluate the effectiveness of different methods. Performance is evaluated across multiple domains, particularly when transferring top agents from the Math domain to non-math domains.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,8ee9617c145e19fa95f1f9349bfbe69b,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SAMPLE COMPLEXITY">
      <data key="d0">METRIC</data>
      <data key="d1">Sample complexity is a metric used to evaluate the computational cost of different methods</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TOKEN CONSUMPTION">
      <data key="d0">METRIC</data>
      <data key="d1">Token consumption is a metric used to evaluate the number of tokens used by different methods</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="NUMBER OF NODES">
      <data key="d0">METRIC</data>
      <data key="d1">Number of nodes is a metric used to evaluate the number of nodes expanded by different methods</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="GROUND-TRUTH FEEDBACK">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Ground-truth feedback is used by LATS, ToT, and RAP to improve performance</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SYSTEM-2 LM APPROACHES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">SYSTEM-2 LM APPROACHES refer to advanced language model methods that involve high-level reasoning and decision-making processes. These approaches encompass sophisticated techniques such as LATS, which are designed to enhance the model's ability to perform complex cognitive tasks.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="INFERENCE-TIME COMPUTE COSTS">
      <data key="d0">METRIC</data>
      <data key="d1">Inference-time compute costs refer to the computational costs incurred during the inference phase of language models</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="COMPUTATIONAL BUDGET">
      <data key="d0">METRIC</data>
      <data key="d1">Computational budget refers to the limit of computational resources allocated for a task</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="REVERSION PROPERTY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Reversion property allows LATS to revert to earlier states in decision-making environments</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="PROMPTING TECHNIQUES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">PROMPTING TECHNIQUES are important building blocks for agentic systems, as referenced by Chen et al., 2023a and Schulhoff et al., 2024. These techniques are methods used to guide language models in generating responses, playing a crucial role in the functionality and effectiveness of AI-driven systems.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY CONSTRUCTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory construction is a process in LATS that involves building paths for decision-makingTrajectory construction is a process used in LATS to deliberately construct paths with search algorithms</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="INTERACTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Interaction is a component of LATS that enables agents to learn from experience</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="REASONING ABILITY">
      <data key="d0">METRIC</data>
      <data key="d1">Reasoning ability is a metric used to evaluate the problem-solving capabilities of language models</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="AUTONOMOUS DECISION-MAKING">
      <data key="d0">TASK</data>
      <data key="d1">Autonomous decision-making is a task that LATS aims to improve in language models</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="GENERALIST AGENTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Generalist agents refer to language models that can perform a variety of tasks</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="COMPUTATIONAL COST">
      <data key="d0">METRIC</data>
      <data key="d1">Computational cost refers to the resources required to run a method or algorithm</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="NODES EXPANDED">
      <data key="d0">METRIC</data>
      <data key="d1">Nodes expanded is a metric used to evaluate the efficiency of search methods</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SUCCESS RATE">
      <data key="d0">METRIC</data>
      <data key="d1">Success Rate is a performance metric used to evaluate the effectiveness of different methods across various domains. In the Game of 24, it measures the success of the agent in producing the correct equation. In WebShop, Success Rate (SR) is defined as the portion of instructions where the reward equals 1. Additionally, it is used to evaluate the performance of generated agents in the Meta Agent Search algorithm.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,b8dd0300033963bb4a3e1bad37f8e7b9,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY SAMPLING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory sampling is a process in LATS that involves selecting paths to exploreTrajectory sampling is a process used in LATS to explore different paths</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="COMPUTATIONAL EFFICIENCY">
      <data key="d0">METRIC</data>
      <data key="d1">Computational efficiency refers to the effectiveness of a method in using computational resources</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="LM SCORING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LM scoring is a component of LATS's value function that leverages external feedback</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="ASYMPTOTIC TOKEN COST">
      <data key="d0">METRIC</data>
      <data key="d1">Asymptotic token cost refers to the long-term token consumption of a method</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="FAILED TRAJECTORIES">
      <data key="d0">METRIC</data>
      <data key="d1">FAILED TRAJECTORIES refer to paths that do not lead to successful outcomes. In the context of question-answering tasks, failed trajectories are examples of solutions that did not correctly answer the question. These trajectories highlight the importance of understanding and improving the mechanisms behind AI and ML models to ensure more accurate and successful results in various applications.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="COMPUTATIONAL BUDGET LIMIT">
      <data key="d0">METRIC</data>
      <data key="d1">Computational budget limit refers to the maximum computational resources allocated for a task</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="PRIOR PROMPTING TECHNIQUES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Prior prompting techniques refer to earlier methods used to guide language models</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="EXPERIENCE LEARNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Experience learning is a process in LATS that enables agents to learn from their actions and outcomes</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="DECISION-MAKING ENVIRONMENTS">
      <data key="d0">ENVIRONMENT</data>
      <data key="d1">Decision-making environments are contexts in which LATS operates to make decisions</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="INFERENCE-TIME">
      <data key="d0">METRIC</data>
      <data key="d1">Inference-time refers to the phase when a language model generates responses based on input</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SYSTEM-2">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">System-2 refers to advanced, deliberate, and logical thinking processes in language models</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SYSTEM-1">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">System-1 refers to fast, automatic, and intuitive thinking processes in language models</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="COMPUTATIONAL RESOURCES">
      <data key="d0">METRIC</data>
      <data key="d1">Computational resources refer to the hardware and software resources required to run a method or algorithm</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY EXPLORATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory exploration is a process in LATS that involves exploring different paths to find optimal solutions</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY PRUNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory pruning is a process in LATS that involves removing less promising paths to improve efficiency</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY EVALUATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory evaluation is a process in LATS that involves assessing the quality of paths</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY SELECTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory selection is a process in LATS that involves choosing the best paths to follow</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY BACKPROPAGATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory backpropagation is a process in LATS that involves updating the value of paths based on outcomes</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY UPDATING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory updating is a process in LATS that involves modifying paths based on new information</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY OPTIMIZATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory optimization is a process in LATS that involves improving paths to achieve better outcomes</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY PLANNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory planning is a process in LATS that involves designing paths for decision-making</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORY EXECUTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory execution is a process in LATS that involves carrying out paths to achieve goals</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY MONITORING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory monitoring is a process in LATS that involves tracking the progress of paths</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY ANALYSIS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory analysis is a process in LATS that involves examining paths to understand their effectiveness</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY ADJUSTMENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory adjustment is a process in LATS that involves modifying paths based on feedback</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY CONTROL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory control is a process in LATS that involves managing paths to achieve desired outcomes</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY MANAGEMENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory management is a process in LATS that involves overseeing paths to ensure they are effective</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY COORDINATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory coordination is a process in LATS that involves aligning paths to achieve goals</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY SYNCHRONIZATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory synchronization is a process in LATS that involves aligning paths to work together effectively</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY INTEGRATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory integration is a process in LATS that involves combining paths to achieve better outcomes</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY FUSION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory fusion is a process in LATS that involves merging paths to create a unified approach</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY AGGREGATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory aggregation is a process in LATS that involves combining multiple paths to achieve better results</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY CONSOLIDATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory consolidation is a process in LATS that involves unifying paths to create a cohesive strategy</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY SYNTHESIS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory synthesis is a process in LATS that involves creating new paths based on existing ones</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY GENERATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory generation is a process in LATS that involves creating new paths for decision-making</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY FORMULATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory formulation is a process in LATS that involves designing paths for specific goals</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY DESIGN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory design is a process in LATS that involves creating paths to achieve objectives</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY DEVELOPMENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory development is a process in LATS that involves building paths for decision-making</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAJECTORY IMPLEMENTATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Trajectory implementation is a process in LATS that involves putting paths into action</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DANIEL CAMPOS">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Campos provided useful feedback on earlier versions of the paper discussing LATS</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NSF GRANT 2106825">
      <data key="d0">FUNDING</data>
      <data key="d1">NSF Grant 2106825 is one of the funding sources that supported the work on LATS</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NIFA AWARD 2020-67021-32799">
      <data key="d0">FUNDING</data>
      <data key="d1">NIFA Award 2020-67021-32799 is one of the funding sources that supported the work on LATS</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JUMP ARCHES ENDOWMENT">
      <data key="d0">FUNDING</data>
      <data key="d1">The Jump ARCHES endowment through the Health Care Engineering Systems Center at Illinois and the OSF Foundation is one of the funding sources that supported the work on LATS</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="IBM-ILLINOIS DISCOVERY ACCELERATOR INSTITUTE">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The IBM-Illinois Discovery Accelerator Institute is one of the organizations that supported the work on LATS</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NVIDIA GPUS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">NVIDIA GPUs were used in the research on LATS through allocations from the ACCESS program</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NCSA DELTA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">NCSA Delta is a computing resource used in the research on LATS through allocations from the ACCESS program</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ACCESS PROGRAM">
      <data key="d0">PROGRAM</data>
      <data key="d1">The ACCESS program provided allocations for the use of NVIDIA GPUs and NCSA Delta in the research on LATS</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="MICHAEL AHN">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Ahn is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ANTHONY BROHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Anthony Brohan is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NOAH BROWN">
      <data key="d0">PERSON</data>
      <data key="d1">Noah Brown is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YEVGEN CHEBOTAR">
      <data key="d0">PERSON</data>
      <data key="d1">Yevgen Chebotar is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OMAR CORTES">
      <data key="d0">PERSON</data>
      <data key="d1">Omar Cortes is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BYRON DAVID">
      <data key="d0">PERSON</data>
      <data key="d1">Byron David is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHELSEA FINN">
      <data key="d0">PERSON</data>
      <data key="d1">Chelsea Finn is a prominent researcher in the field of Artificial Intelligence and Machine Learning. She has co-authored several influential papers, including "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022, "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024, and "Model-agnostic meta-learning for fast adaptation of deep networks" published in the International Conference on Machine Learning in 2017. Her work spans various aspects of AI and ML, contributing significantly to the understanding and development of robotic affordances, language models, and meta-learning techniques.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,34d0bb2211fc795fe1096442e086a2b3,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHUYUAN FU">
      <data key="d0">PERSON</data>
      <data key="d1">Chuyuan Fu is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022. Additionally, Chuyuan Fu co-authored the paper titled "Language to rewards for robotic skill synthesis" presented at the Conference on Robot Learning in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KEERTHANA GOPALAKRISHNAN">
      <data key="d0">PERSON</data>
      <data key="d1">Keerthana Gopalakrishnan is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KAROL HAUSMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Karol Hausman is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEX HERZOG">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Herzog is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DANIEL HO">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Ho is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JASMINE HSU">
      <data key="d0">PERSON</data>
      <data key="d1">Jasmine Hsu is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JULIAN IBARZ">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Ibarz is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BRIAN ICHTER">
      <data key="d0">PERSON</data>
      <data key="d1">Brian Ichter is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEX IRPAN">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Irpan is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ROSARIO JAUREGUI RUANO">
      <data key="d0">PERSON</data>
      <data key="d1">Rosario Jauregui Ruano is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KYLE JEFFREY">
      <data key="d0">PERSON</data>
      <data key="d1">Kyle Jeffrey is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SALLY JESMONTH">
      <data key="d0">PERSON</data>
      <data key="d1">Sally Jesmonth is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NIKHIL J JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Nikhil J Joshi is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RYAN JULIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ryan Julian is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DMITRY KALASHNIKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Dmitry Kalashnikov is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUHENG KUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuheng Kuang is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KUANG-HUEI LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Kuang-Huei Lee is a notable researcher in the field of Artificial Intelligence and Machine Learning. He has co-authored significant papers, including "Do as I can, not as I say: Grounding language in robotic affordances," published in CoRL 2022, and "Multimodal web navigation with instruction-finetuned foundation models," published in ICLR 2024. His work contributes to the understanding and advancement of language grounding in robotics and multimodal web navigation, showcasing his expertise and influence in these cutting-edge areas of AI research.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SERGEY LEVINE">
      <data key="d0">PERSON</data>
      <data key="d1">Sergey Levine is a prominent researcher in the field of Artificial Intelligence and Machine Learning, contributing significantly to various high-impact publications. He is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances," published in CoRL 2022, which explores the integration of language and robotic capabilities. Additionally, he co-authored the influential paper "Model-agnostic meta-learning for fast adaptation of deep networks," presented at the International Conference on Machine Learning in 2017, which addresses rapid adaptation in deep learning models. More recently, in 2023, he contributed to the paper "The false promise of imitating proprietary LLMs," published on arXiv, which critically examines the limitations of imitating proprietary large language models. Through these works, Sergey Levine has established himself as a key influencer in the AI and ML communities, driving forward research on language grounding, meta-learning, and the evaluation of large language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4ae237a491bc8a84cc720e40c59a7464,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YAO LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yao Lu is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LINDA LUU">
      <data key="d0">PERSON</data>
      <data key="d1">Linda Luu is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CAROLINA PARADA">
      <data key="d0">PERSON</data>
      <data key="d1">Carolina Parada is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PETER PASTOR">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Pastor is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JORNELL QUIAMBAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jornell Quiambao is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KANISHKA RAO">
      <data key="d0">PERSON</data>
      <data key="d1">Kanishka Rao is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JAREK RETTINGHOUSE">
      <data key="d0">PERSON</data>
      <data key="d1">Jarek Rettinghouse is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DIEGO REYES">
      <data key="d0">PERSON</data>
      <data key="d1">Diego Reyes is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PIERRE SERMANET">
      <data key="d0">PERSON</data>
      <data key="d1">Pierre Sermanet is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NICOLAS SIEVERS">
      <data key="d0">PERSON</data>
      <data key="d1">Nicolas Sievers is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CLAYTON TAN">
      <data key="d0">PERSON</data>
      <data key="d1">Clayton Tan is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEXANDER TOSHEV">
      <data key="d0">PERSON</data>
      <data key="d1">Alexander Toshev is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VINCENT VANHOUCKE">
      <data key="d0">PERSON</data>
      <data key="d1">Vincent Vanhoucke is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FEI XIA">
      <data key="d0">PERSON</data>
      <data key="d1">Fei Xia is a notable researcher in the field of Artificial Intelligence and Machine Learning. In 2022, Fei Xia co-authored two significant papers. The first paper, titled "Do as I can, not as I say: Grounding language in robotic affordances," was published in the Conference on Robot Learning (CoRL) 2022. This work explores the grounding of language in the context of robotic affordances. The second paper, "Chain-of-thought prompting elicits reasoning in large language models," was published in Advances in Neural Information Processing Systems (NeurIPS) 2022, and it investigates the elicitation of reasoning in large language models through chain-of-thought prompting. These contributions highlight Fei Xia's active involvement in advancing the understanding and capabilities of AI and ML systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TED XIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Ted Xiao is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PENG XU">
      <data key="d0">PERSON</data>
      <data key="d1">Peng Xu is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SICHUN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Sichun Xu is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MENGYUAN YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Mengyuan Yan is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANDY ZENG">
      <data key="d0">PERSON</data>
      <data key="d1">Andy Zeng is one of the authors of the paper "Do as I can, not as I say: Grounding language in robotic affordances" published in CoRL 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JACOB AUSTIN">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Austin is one of the authors of the paper "Program synthesis with large language models" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AUGUSTUS ODENA">
      <data key="d0">PERSON</data>
      <data key="d1">Augustus Odena is one of the authors of the paper "Program synthesis with large language models" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAXWELL NYE">
      <data key="d0">PERSON</data>
      <data key="d1">Maxwell Nye is one of the authors of the paper "Program synthesis with large language models" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAARTEN BOSMA">
      <data key="d0">PERSON</data>
      <data key="d1">Maarten Bosma is a notable researcher in the field of Artificial Intelligence and Machine Learning. He has co-authored several influential papers, including "Program synthesis with large language models" and "Chain of thought prompting elicits reasoning in large language models," both published in NeurIPS 2022. Additionally, he contributed to the paper "Chain-of-thought prompting elicits reasoning in large language models," which appeared in Advances in Neural Information Processing Systems in 2022. In 2023, he co-authored "PaLM: Scaling language modeling with pathways," published in the Journal of Machine Learning Research (JMLR). His work primarily focuses on leveraging large language models to enhance program synthesis and reasoning capabilities.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HENRYK MICHALEWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Henryk Michalewski is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper "Program synthesis with large language models," which was published in NeurIPS 2022. Additionally, he contributed to the paper titled "Promptbreeder: Self-referential self-improvement via prompt evolution," published in 2024. These works highlight his involvement in cutting-edge research on leveraging large language models for program synthesis and exploring innovative methods for self-improvement in AI through prompt evolution.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAVID DOHAN">
      <data key="d0">PERSON</data>
      <data key="d1">David Dohan is one of the authors of the paper "Program synthesis with large language models" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ELLEN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ellen Jiang is one of the authors of the paper "Program synthesis with large language models" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CARRIE CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Carrie Cai is one of the authors of the paper "Program synthesis with large language models" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MICHAEL TERRY">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Terry is one of the authors of the paper "Program synthesis with large language models" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QUOC LE">
      <data key="d0">PERSON</data>
      <data key="d1">Quoc Le is a prominent researcher in the field of Artificial Intelligence and Machine Learning. He has co-authored several influential papers, including "Program synthesis with large language models" published in NeurIPS 2022, "Least-to-most prompting enables complex reasoning in large language models" published in ICLR 2022, and "Self-consistency improves chain of thought reasoning in language models" also published in ICLR 2022. His work focuses on enhancing the capabilities of large language models, particularly in the areas of program synthesis, complex reasoning, and improving reasoning consistency.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,4ae237a491bc8a84cc720e40c59a7464,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHARLES SUTTON">
      <data key="d0">PERSON</data>
      <data key="d1">Charles Sutton is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper "Program synthesis with large language models," which was published in NeurIPS 2022. Additionally, he contributed to the paper titled "PaLM: Scaling language modeling with pathways," published in JMLR 2023. His work focuses on advancing the capabilities of language models, demonstrating his significant role in the AI and ML research community.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BOWEN BAKER">
      <data key="d0">PERSON</data>
      <data key="d1">Bowen Baker is one of the authors of the paper "Video pretraining (VPT): Learning to act by watching unlabeled online videos" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ILGE AKKAYA">
      <data key="d0">PERSON</data>
      <data key="d1">Ilge Akkaya is one of the authors of the paper "Video pretraining (VPT): Learning to act by watching unlabeled online videos" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PETER ZHOKHOV">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Zhokhov is one of the authors of the paper "Video pretraining (VPT): Learning to act by watching unlabeled online videos" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOOST HUIZINGA">
      <data key="d0">PERSON</data>
      <data key="d1">Joost Huizinga is one of the authors of the paper "Video pretraining (VPT): Learning to act by watching unlabeled online videos" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIE TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jie Tang is one of the authors of the paper "Video pretraining (VPT): Learning to act by watching unlabeled online videos" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ADRIEN ECOFFET">
      <data key="d0">PERSON</data>
      <data key="d1">Adrien Ecoffet is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper "Video pretraining (VPT): Learning to act by watching unlabeled online videos," which was published in NeurIPS 2022. Additionally, he co-authored the paper titled "Open questions in creating safe open-ended AI: Tensions between control and creativity," presented at the Conference on Artificial Life in 2020. His work spans significant contributions to understanding AI learning processes and addressing the challenges of creating safe, open-ended AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BRANDON HOUGHTON">
      <data key="d0">PERSON</data>
      <data key="d1">Brandon Houghton is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper "Video pretraining (VPT): Learning to act by watching unlabeled online videos," which was published in NeurIPS 2022. Additionally, he contributed to the paper titled "MineRL: A large-scale dataset of Minecraft demonstrations," published in IJCAI 2019. His work spans significant contributions to understanding and leveraging large-scale datasets for training AI models, particularly in the context of video and gaming environments.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RAUL SAMPEDRO">
      <data key="d0">PERSON</data>
      <data key="d1">Raul Sampedro is one of the authors of the paper "Video pretraining (VPT): Learning to act by watching unlabeled online videos" published in NeurIPS 2022</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JEFF CLUNE">
      <data key="d0">PERSON</data>
      <data key="d1">Jeff Clune is a prominent researcher in the field of Artificial Intelligence and Machine Learning, affiliated with the University of British Columbia, the Vector Institute, and the Canada CIFAR AI Chair. He has made significant contributions to the field through a variety of influential papers. Notably, he co-authored the paper "Video pretraining (VPT): Learning to act by watching unlabeled online videos," published in NeurIPS 2022. His work includes the paper "Automated Design of Agentic Systems," and he has explored the design of neural networks through neuroevolution in his 2019 publication in Nature Machine Intelligence.

Jeff Clune has also contributed to the understanding of intelligent exploration and meta-learning, as evidenced by his 2023 arXiv paper "First-explore, then exploit: Meta-learning intelligent exploration." In 2024, he co-authored "Intelligent go-explore: Standing on the shoulders of giant foundation models" and "OMNI: Open-endedness via models of human notions of interestingness," presented at The Twelfth International Conference on Learning Representations. His earlier work includes "Illuminating search spaces by mapping elites" (arXiv, 2015) and "Poet: open-ended coevolution of environments and their optimized solutions," published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019.

Additionally, Jeff Clune has delved into the concept of thought cloning with his 2024 paper "Thought Cloning: Learning to think while acting by imitating human thinking," published in Advances in Neural Information Processing Systems. He also authored "Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence," published on arXiv in 2019. His extensive body of work highlights his role as a key influencer and thought leader in the AI and ML communities.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,4ae237a491bc8a84cc720e40c59a7464,6109537356a2ce2339f77c827aa3668e,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MACIEJ BESTA">
      <data key="d0">PERSON</data>
      <data key="d1">Maciej Besta is one of the authors of the paper "Graph of thoughts: Solving elaborate problems with large language models" published on arXiv in 2023</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NILS BLACH">
      <data key="d0">PERSON</data>
      <data key="d1">Nils Blach is one of the authors of the paper "Graph of thoughts: Solving elaborate problems with large language models" published on arXiv in 2023</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ALES KUBICEK">
      <data key="d0">PERSON</data>
      <data key="d1">Ales Kubicek is one of the authors of the paper "Graph of thoughts: Solving elaborate problems with large language models" published on arXiv in 2023</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ROBERT GERSTENBERGER">
      <data key="d0">PERSON</data>
      <data key="d1">Robert Gerstenberger is one of the authors of the paper "Graph of thoughts: Solving elaborate problems with large language models" published on arXiv in 2023</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="LUKAS GIANINAZZI">
      <data key="d0">PERSON</data>
      <data key="d1">Lukas Gianinazzi is one of the authors of the paper "Graph of thoughts: Solving elaborate problems with large language models" published on arXiv in 2023</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JOANNA GAJDA">
      <data key="d0">PERSON</data>
      <data key="d1">Joanna Gajda is one of the authors of the paper "Graph of thoughts: Solving elaborate problems with large language models" published on arXiv in 2023</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="TOMASZ LEHMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Tomasz Lehmann is one of the authors of the paper "Graph of thoughts: Solving elaborate problems with large language models" published on arXiv in 2023</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="MICHAL PODSTAWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Michal Podstawski is one of the authors of the paper "Graph of thoughts: Solving elaborate problems with large language models" published on arXiv in 2023</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="HUBERT NIEWIADOMSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Hubert Niewiadomski is one of the authors of the paper "Graph of thoughts: Solving elaborate problems with large language models" published on arXiv in</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="AMODEI">
      <data key="d0">PERSON</data>
      <data key="d1">Amodei is an author of the paper titled "Language models are few-shot learners" published in NeurIPS 2020</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NEURIPS">
      <data key="d0">EVENT</data>
      <data key="d1">NeurIPS, also known as the Conference on Neural Information Processing Systems, is a prominent conference in the field of artificial intelligence and machine learning. It has been a platform for groundbreaking research and influential papers. In 2020, the paper "Language models are few-shot learners" was published at NeurIPS, highlighting advancements in few-shot learning capabilities of language models. In 2022, the conference featured the paper "Chain of thought prompting elicits reasoning in large language models," which explored the reasoning abilities of large language models through chain of thought prompting. In 2023, NeurIPS showcased two significant papers: "Learning universal policies via text-guided video generation," which delved into the generation of video content guided by textual descriptions, and "Self-refine: Iterative refinement with self-feedback," which focused on iterative refinement techniques using self-feedback mechanisms. NeurIPS continues to be a key venue for the dissemination of cutting-edge research in AI and ML.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MURRAY CAMPBELL">
      <data key="d0">PERSON</data>
      <data key="d1">Murray Campbell is one of the authors of the paper titled "Deep blue" published in Artificial Intelligence in 2002</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="A JOSEPH HOANE JR">
      <data key="d0">PERSON</data>
      <data key="d1">A Joseph Hoane Jr is one of the authors of the paper titled "Deep blue" published in Artificial Intelligence in 2002</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FENG-HSIUNG HSU">
      <data key="d0">PERSON</data>
      <data key="d1">Feng-hsiung Hsu is one of the authors of the paper titled "Deep blue" published in Artificial Intelligence in 2002</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE">
      <data key="d0">JOURNAL</data>
      <data key="d1">Artificial Intelligence is the journal where the paper "Deep blue" was published in 2002</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BEI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Bei Chen is one of the authors of the paper titled "CodeT: Code generation with generated tests" published in ICLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FENGJI ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Fengji Zhang is one of the authors of the paper titled "CodeT: Code generation with generated tests" published in ICLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANH NGUYEN">
      <data key="d0">PERSON</data>
      <data key="d1">Anh Nguyen is a notable author in the field of Artificial Intelligence and Machine Learning. He has contributed to the Phi-3 technical report and co-authored the paper titled "CodeT: Code generation with generated tests," which was published in ICLR 2023. His work demonstrates a strong focus on advancing AI methodologies, particularly in the area of code generation and testing.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DAOGUANG ZAN">
      <data key="d0">PERSON</data>
      <data key="d1">Daoguang Zan is one of the authors of the paper titled "CodeT: Code generation with generated tests" published in ICLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZEQI LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Zeqi Lin is a notable contributor in the field of Artificial Intelligence and Machine Learning. Lin is one of the authors of the Phi-3 technical report, showcasing expertise in advanced AI methodologies. Additionally, Lin co-authored the paper titled "CodeT: Code generation with generated tests," which was published in ICLR 2023, a prestigious conference in the AI and ML community. This work highlights Lin's involvement in cutting-edge research on code generation, emphasizing the importance of automated testing in software development.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIAN-GUANG LOU">
      <data key="d0">PERSON</data>
      <data key="d1">Jian-Guang Lou is one of the authors of the paper titled "CodeT: Code generation with generated tests" published in ICLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WEIZHU CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Weizhu Chen is a notable author in the field of Artificial Intelligence and Machine Learning. He has contributed to several significant publications, including the Phi-3 technical report. In 2023, he co-authored the paper titled "Agieval: A human-centric benchmark for evaluating foundation models." Additionally, he was one of the authors of the paper "CodeT: Code generation with generated tests," which was published in ICLR 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ICLR">
      <data key="d0">EVENT</data>
      <data key="d1">ICLR is a prominent conference in the field of Artificial Intelligence and Machine Learning, known for publishing influential research papers. Notable papers presented at ICLR include "CodeT: Code generation with generated tests" in 2023, "Least-to-most prompting enables complex reasoning in large language models" and "Self-consistency improves chain of thought reasoning in language models" both in 2022, and "Multimodal web navigation with instruction-finetuned foundation models" and "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" in 2024. These publications highlight ICLR's role in advancing research on code generation, complex reasoning in language models, multimodal web navigation, and the utilization of large language models with real-world APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="MARK CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Mark Chen is one of the authors of the paper titled "Evaluating Large Language Models Trained on Code" published on arXiv in 2021. Additionally, he is also one of the authors of the paper titled "Training Verifiers to Solve Math Word Problems," which was also published on arXiv in 2021.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JERRY TWOREK">
      <data key="d0">PERSON</data>
      <data key="d1">Jerry Tworek is one of the authors of the papers titled "Evaluating Large Language Models Trained on Code" and "Training Verifiers to Solve Math Word Problems," both published on arXiv in 2021.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HEEWOO JUN">
      <data key="d0">PERSON</data>
      <data key="d1">Heewoo Jun is one of the authors of the papers titled "Evaluating Large Language Models Trained on Code" and "Training Verifiers to Solve Math Word Problems," both published on arXiv in 2021.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QIMING YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Qiming Yuan is one of the authors of the paper titled "Evaluating Large Language Models Trained on Code," which was published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HENRIQUE PONDE">
      <data key="d0">PERSON</data>
      <data key="d1">Henrique Ponde is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JARED KAPLAN">
      <data key="d0">PERSON</data>
      <data key="d1">Jared Kaplan is one of the authors of the paper titled "Evaluating Large Language Models Trained on Code," which was published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HARRISON EDWARDS">
      <data key="d0">PERSON</data>
      <data key="d1">Harrison Edwards is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YURA BURDA">
      <data key="d0">PERSON</data>
      <data key="d1">Yura Burda is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NICHOLAS JOSEPH">
      <data key="d0">PERSON</data>
      <data key="d1">Nicholas Joseph is one of the authors of the paper titled "Evaluating Large Language Models Trained on Code," which was published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GREG BROCKMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Greg Brockman is one of the authors of the paper titled "Evaluating Large Language Models Trained on Code," which was published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEX RAY">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Ray is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RAUL PURI">
      <data key="d0">PERSON</data>
      <data key="d1">Raul Puri is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GRETCHEN KRUEGER">
      <data key="d0">PERSON</data>
      <data key="d1">Gretchen Krueger is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MICHAEL PETROV">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Petrov is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HEIDY KHLAAF">
      <data key="d0">PERSON</data>
      <data key="d1">Heidy Khlaaf is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GIRISH SASTRY">
      <data key="d0">PERSON</data>
      <data key="d1">Girish Sastry is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PAMELA MISHKIN">
      <data key="d0">PERSON</data>
      <data key="d1">Pamela Mishkin is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BROOKE CHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Brooke Chan is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SCOTT GRAY">
      <data key="d0">PERSON</data>
      <data key="d1">Scott Gray is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NICK RYDER">
      <data key="d0">PERSON</data>
      <data key="d1">Nick Ryder is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MIKHAIL PAVLOV">
      <data key="d0">PERSON</data>
      <data key="d1">Mikhail Pavlov is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALETHEA POWER">
      <data key="d0">PERSON</data>
      <data key="d1">Alethea Power is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LUKASZ KAISER">
      <data key="d0">PERSON</data>
      <data key="d1">Lukasz Kaiser is a notable researcher in the field of Artificial Intelligence and Machine Learning. In 2021, he co-authored two significant papers published on arXiv. The first paper, titled "Evaluating large language models trained on code," explores the performance and capabilities of large language models specifically trained on programming code. The second paper, "Training verifiers to solve math word problems," delves into the development of verifiers designed to tackle mathematical word problems. These contributions highlight Lukasz Kaiser's active involvement in advancing AI and ML research, particularly in the areas of language models and problem-solving algorithms.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MOHAMMAD BAVARIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammad Bavarian is one of the authors of two notable papers published on arXiv in 2021. The first paper, titled "Evaluating large language models trained on code," explores the performance and capabilities of large language models specifically trained on programming code. The second paper, "Training verifiers to solve math word problems," delves into the development of verifiers designed to tackle mathematical word problems. Both contributions highlight Mohammad Bavarian's involvement in advancing the field of artificial intelligence and machine learning, particularly in the areas of language models and problem-solving algorithms.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CLEMENS WINTER">
      <data key="d0">PERSON</data>
      <data key="d1">Clemens Winter is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PHILIPPE TILLET">
      <data key="d0">PERSON</data>
      <data key="d1">Philippe Tillet is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FELIPE PETROSKI SUCH">
      <data key="d0">PERSON</data>
      <data key="d1">Felipe Petroski Such is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAVID W. CUMMINGS">
      <data key="d0">PERSON</data>
      <data key="d1">David W. Cummings is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MATTHIAS PLAPPERT">
      <data key="d0">PERSON</data>
      <data key="d1">Matthias Plappert is a notable researcher in the field of Artificial Intelligence and Machine Learning. In 2021, he co-authored two significant papers published on arXiv. The first paper, titled "Evaluating large language models trained on code," delves into the performance and capabilities of language models specifically trained on programming code. The second paper, "Training verifiers to solve math word problems," explores methodologies for enhancing the ability of AI systems to solve mathematical word problems through the training of verifiers. These contributions highlight Matthias Plappert's active involvement in advancing the understanding and application of AI in specialized domains.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FOTIOS CHANTZIS">
      <data key="d0">PERSON</data>
      <data key="d1">Fotios Chantzis is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ELIZABETH BARNES">
      <data key="d0">PERSON</data>
      <data key="d1">Elizabeth Barnes is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ARIEL HERBERT-VOSS">
      <data key="d0">PERSON</data>
      <data key="d1">Ariel Herbert-Voss is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WILLIAM H. GUSS">
      <data key="d0">PERSON</data>
      <data key="d1">William H. Guss is a notable researcher in the field of Artificial Intelligence and Machine Learning. He has contributed significantly to the academic community through his authorship of influential papers. In 2021, he co-authored the paper titled "Evaluating large language models trained on code," which was published on arXiv. Additionally, in 2019, he co-authored the paper "MineRL: A large-scale dataset of Minecraft demonstrations," which was published in the International Joint Conference on Artificial Intelligence (IJCAI). His work spans the evaluation of large language models and the creation of extensive datasets for AI research, highlighting his expertise and impact in these areas.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEX NICHOL">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Nichol is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="IGOR BABUSCHKIN">
      <data key="d0">PERSON</data>
      <data key="d1">Igor Babuschkin is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SUCHIR BALAJI">
      <data key="d0">PERSON</data>
      <data key="d1">Suchir Balaji is one of the authors of two notable papers published on arXiv in 2021. The first paper, titled "Evaluating large language models trained on code," delves into the performance and capabilities of large language models specifically trained on programming code. The second paper, "WebGPT: Browser-assisted question-answering with human feedback," explores the development of a question-answering system that leverages web browsing and human feedback to improve its responses. Both contributions highlight Suchir Balaji's involvement in advancing the field of artificial intelligence and machine learning, particularly in the areas of language models and human-computer interaction.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHANTANU JAIN">
      <data key="d0">PERSON</data>
      <data key="d1">Shantanu Jain is one of the authors of two notable papers published on arXiv in 2021. The first paper, titled "Evaluating large language models trained on code," delves into the performance and capabilities of large language models specifically trained on programming code. The second paper, "WebGPT: Browser-assisted question-answering with human feedback," explores the development of a question-answering system that leverages web browsing and human feedback to enhance its accuracy and reliability. Both contributions highlight Shantanu Jain's active involvement in advancing the field of artificial intelligence and machine learning, particularly in the areas of language models and human-computer interaction.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANDREW CARR">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Carr is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JAN LEIKE">
      <data key="d0">PERSON</data>
      <data key="d1">Jan Leike is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOSHUA ACHIAM">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Achiam is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VEDANT MISRA">
      <data key="d0">PERSON</data>
      <data key="d1">Vedant Misra is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="EVAN MORIKAWA">
      <data key="d0">PERSON</data>
      <data key="d1">Evan Morikawa is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEC RADFORD">
      <data key="d0">PERSON</data>
      <data key="d1">Alec Radford is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MATTHEW M. KNIGHT">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew M. Knight is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MILES BRUNDAGE">
      <data key="d0">PERSON</data>
      <data key="d1">Miles Brundage is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MIRA MURATI">
      <data key="d0">PERSON</data>
      <data key="d1">Mira Murati is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KATIE MAYER">
      <data key="d0">PERSON</data>
      <data key="d1">Katie Mayer is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PETER WELINDER">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Welinder is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BOB MCGREW">
      <data key="d0">PERSON</data>
      <data key="d1">Bob McGrew is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DARIO AMODEI">
      <data key="d0">PERSON</data>
      <data key="d1">Dario Amodei is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAM MCCANDLISH">
      <data key="d0">PERSON</data>
      <data key="d1">Sam McCandlish is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ILYA SUTSKEVER">
      <data key="d0">PERSON</data>
      <data key="d1">Ilya Sutskever is a prominent figure in the field of artificial intelligence and machine learning, known for his significant contributions to various groundbreaking research papers. He co-authored the paper "Evaluating large language models trained on code," published on arXiv in 2021, which explores the capabilities of large language models in understanding and generating code. Sutskever also contributed to the influential paper "Imagenet classification with deep convolutional neural networks," published in Advances in Neural Information Processing Systems in 2012, which played a pivotal role in advancing deep learning techniques for image recognition.

In addition, he co-authored the seminal paper "Mastering the game of Go with deep neural networks and tree search," published in Nature in 2016, and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm," published on arXiv in 2017. These works demonstrated the power of deep neural networks and reinforcement learning in mastering complex board games. Furthermore, Sutskever contributed to the paper "RL^2: Fast reinforcement learning via slow reinforcement learning," published in the International Conference on Learning Representations in 2017, which introduced innovative methods for accelerating reinforcement learning processes.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,2d4672dfb7bd4283f0b5f23ab4f26653,6109537356a2ce2339f77c827aa3668e,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WOJCIECH ZAREMBA">
      <data key="d0">PERSON</data>
      <data key="d1">Wojciech Zaremba is one of the authors of the paper titled "Evaluating large language models trained on code" published on arXiv in 2021</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ARXIV">
      <data key="d0">PLATFORM</data>
      <data key="d1">arXiv is a platform known for publishing a wide range of academic papers. Notable publications on arXiv include "Automated Design of Agentic Systems," "Mastering diverse domains through world models" published in 2023, and "Evaluating large language models trained on code" published in 2021. This platform serves as a significant repository for cutting-edge research across various domains, particularly in the fields of Artificial Intelligence and Machine Learning.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">PLATFORM</data>
    </node>
    <node id="WENHU CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Wenhu Chen is one of the authors of the paper titled "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XUEGUANG MA">
      <data key="d0">PERSON</data>
      <data key="d1">Xueguang Ma is one of the authors of the paper titled "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XINYI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyi Wang is one of the authors of the paper titled "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WILLIAM W. COHEN">
      <data key="d0">PERSON</data>
      <data key="d1">William W. Cohen is one of the authors of the paper titled "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TMLR">
      <data key="d0">JOURNAL</data>
      <data key="d1">TMLR is the journal where the paper "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" was published in 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">JOURNAL</data>
    </node>
    <node id="AAKANKSHA CHOWDHERY">
      <data key="d0">PERSON</data>
      <data key="d1">Aakanksha Chowdhery is a notable researcher in the field of Artificial Intelligence and Machine Learning. She has co-authored several influential papers, including "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022, "PaLM: Scaling language modeling with pathways" published in the Journal of Machine Learning Research (JMLR) in 2023, and "Self-consistency improves chain of thought reasoning in language models" presented at The Eleventh International Conference on Learning Representations in 2023. Her work primarily focuses on advancing language modeling and improving reasoning capabilities in AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHARAN NARANG">
      <data key="d0">PERSON</data>
      <data key="d1">Sharan Narang is a notable researcher in the field of Artificial Intelligence and Machine Learning. In 2023, he co-authored several influential papers, including "Llama 2: Open foundation and fine-tuned chat models" published on arXiv, "PaLM: Scaling language modeling with pathways" published in the Journal of Machine Learning Research (JMLR), and "Self-consistency improves chain of thought reasoning in language models" presented at The Eleventh International Conference on Learning Representations. His work significantly contributes to advancements in language modeling and reasoning within AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JACOB DEVLIN">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Devlin is one of the authors of the paper titled "PaLM: Scaling language modeling with pathways" published in JMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GAURAV MISHRA">
      <data key="d0">PERSON</data>
      <data key="d1">Gaurav Mishra is one of the authors of the paper titled "PaLM: Scaling language modeling with pathways" published in JMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ADAM ROBERTS">
      <data key="d0">PERSON</data>
      <data key="d1">Adam Roberts is one of the authors of the paper titled "PaLM: Scaling language modeling with pathways" published in JMLAdam Roberts is one of the authors of the paper titled "PaLM: Scaling language modeling with pathways" published in JMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PAUL BARHAM">
      <data key="d0">PERSON</data>
      <data key="d1">Paul Barham is one of the authors of the paper titled "PaLM: Scaling language modeling with pathways" published in JMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HYUNG WON CHUNG">
      <data key="d0">PERSON</data>
      <data key="d1">Hyung Won Chung is a notable researcher in the field of Artificial Intelligence and Machine Learning. He has co-authored several influential papers, including "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022, "Language models are multilingual chain-of-thought reasoners" presented at The Eleventh International Conference on Learning Representations in 2023, and "PaLM: Scaling language modeling with pathways" published in the Journal of Machine Learning Research (JMLR) in 2023. His work primarily focuses on advancing language models and exploring the capabilities of chain-of-thought reasoning in multilingual contexts.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SEBASTIAN GEHRMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Gehrmann is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022. Additionally, he contributed to the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR) in 2023. His work focuses on advancing language modeling and exploring innovative approaches to solving complex AI tasks.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="PARKER SCHUH">
      <data key="d0">PERSON</data>
      <data key="d1">Parker Schuh is one of the authors of the paper titled "PaLM: Scaling language modeling with pathways" published in JMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KENSEN SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Kensen Shi is one of the authors of the paper titled "PaLM: Scaling language modeling with pathways" published in JMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SASHA TSVYASHCHENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Sasha Tsvyashchenko is one of the authors of the paper titled "PaLM: Scaling language modeling with pathways" published in JMLR 2023</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA MAYNEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Maynez is one of the authors of the paper titled "PaLM: Scaling language modeling with pathways" published in JMLR</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YILUN DU">
      <data key="d0">PERSON</data>
      <data key="d1">Yilun Du is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "Improving factuality and reasoning in language models through multiagent debate," which was published on arXiv in 2023. Additionally, he contributed to the paper "Learning universal policies via text-guided video generation," published in NeurIPS 2023. These works highlight his involvement in advancing the capabilities of language models and exploring innovative methods for policy learning through video generation.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MENGJIAO YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Mengjiao Yang is one of the authors of the paper titled "Learning universal policies via text-guided video generation" published in NeurIPS 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BO DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Bo Dai is one of the authors of two notable papers published in NeurIPS 2023. The first paper, titled "AdaPlanner: Adaptive planning from feedback with language models," explores innovative methods for adaptive planning using feedback mechanisms in conjunction with language models. The second paper, "Learning universal policies via text-guided video generation," delves into the development of universal policies through the integration of text-guided video generation techniques. Bo Dai's contributions to these cutting-edge research topics highlight his significant role in advancing the fields of adaptive planning and policy learning within the AI and ML communities.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HANJUN DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Hanjun Dai is one of the authors of the paper titled "Learning universal policies via text-guided video generation" published in NeurIPS 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OFIR NACHUM">
      <data key="d0">PERSON</data>
      <data key="d1">Ofir Nachum is one of the authors of the paper titled "Learning universal policies via text-guided video generation" published in NeurIPS 2023Ofir Nachum is one of the authors of the paper titled "Multimodal web navigation with instruction-finetuned foundation models" published in ICLR 2024</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOSHUA B. TENENBAUM">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua B. Tenenbaum is one of the authors of the paper titled "Learning universal policies via text-guided video generation" published in NeurIPS 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DALE SCHUURMANS">
      <data key="d0">PERSON</data>
      <data key="d1">Dale Schuurmans is a prolific author in the field of Artificial Intelligence and Machine Learning, contributing to several significant research papers. He co-authored the paper titled "Learning universal policies via text-guided video generation," which was published in NeurIPS 2023. Additionally, he has made notable contributions to the understanding of reasoning in language models, as evidenced by his co-authorship of the paper "Self-consistency improves chain of thought reasoning in language models," published in both ICLR 2022 and The Eleventh International Conference on Learning Representations in 2023. Furthermore, he co-authored the paper "Least-to-most prompting enables complex reasoning in large language models," also published in ICLR 2022.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PIETER ABBEEL">
      <data key="d0">PERSON</data>
      <data key="d1">Pieter Abbeel is a prominent researcher in the field of Artificial Intelligence and Machine Learning, contributing significantly to various high-impact publications. He co-authored the paper "Managing Extreme AI Risks Amid Rapid Progress," published in Science in 2024, which addresses the critical issue of AI risk management. In 2023, he contributed to the paper "Daydreamer: World models for physical robot learning," presented at CoRL, and "Learning universal policies via text-guided video generation," published in NeurIPS. His work on "Mastering Atari games with limited data," published in NeurIPS 2021, showcases advancements in reinforcement learning with constrained datasets. Additionally, Abbeel co-authored "RL^2: Fast reinforcement learning via slow reinforcement learning," presented at the International Conference on Learning Representations in 2017, and "The false promise of imitating proprietary LLMs," published on arXiv in 2023, which critiques the limitations of proprietary language models. His extensive research portfolio highlights his influence and contributions to the AI and ML communities.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598,7de66b94cf868b37b1df51dc545c415f,8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JONATHAN ST BT EVANS">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan St BT Evans is the author of the paper titled "Intuition and reasoning: A dual-process perspective" published in Psychological Inquiry in 2010</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PSYCHOLOGICAL INQUIRY">
      <data key="d0">JOURNAL</data>
      <data key="d1">Psychological Inquiry is a journal where the paper "Intuition and reasoning: A dual-process perspective" was published in 2010</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">JOURNAL</data>
    </node>
    <node id="LINXI FAN">
      <data key="d0">PERSON</data>
      <data key="d1">Linxi Fan is a notable researcher in the field of Artificial Intelligence and Machine Learning, contributing to several significant publications. In 2023, Linxi Fan co-authored the paper "Eureka: Human-level reward design via coding large language models," which was presented at the Twelfth International Conference on Learning Representations. Additionally, in 2022, Linxi Fan co-authored "MineDojo: Building open-ended embodied agents with internet-scale knowledge," published in the NeurIPS Datasets and Benchmarks Track. Furthermore, in 2023, Linxi Fan contributed to the paper "Voyager: An open-ended embodied agent with large language models," which was published on arXiv. These works highlight Linxi Fan's expertise and active involvement in advancing the development of embodied agents and large language models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GUANZHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Guanzhi Wang is a notable researcher in the field of Artificial Intelligence and Machine Learning. He has co-authored several influential papers, including "Eureka: Human-level reward design via coding large language models," presented at the Twelfth International Conference on Learning Representations in 2023. Additionally, he contributed to "MineDojo: Building open-ended embodied agents with internet-scale knowledge," which was published in the NeurIPS Datasets and Benchmarks Track in 2022. In 2023, he also co-authored "Voyager: An open-ended embodied agent with large language models," which was published on arXiv. These works highlight his significant contributions to the development of advanced AI systems and the exploration of large language models in creating sophisticated, open-ended embodied agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUNFAN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yunfan Jiang is one of the authors of the paper titled "MineDojo: Building open-ended embodied agents with internet-scale knowledge" published in NeurIPS Datasets and Benchmarks Track in 2022. Additionally, Yunfan Jiang is also one of the authors of the paper titled "Voyager: An open-ended embodied agent with large language models" published on arXiv in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AJAY MANDLEKAR">
      <data key="d0">PERSON</data>
      <data key="d1">Ajay Mandlekar is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "MineDojo: Building open-ended embodied agents with internet-scale knowledge," which was published in the NeurIPS Datasets and Benchmarks Track in 2022. Additionally, he contributed to the paper "Voyager: An open-ended embodied agent with large language models," published on arXiv in 2023. These works highlight his focus on developing advanced embodied agents utilizing large-scale knowledge and language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUNCONG YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuncong Yang is one of the authors of the paper titled "MineDojo: Building open-ended embodied agents with internet-scale knowledge" published in NeurIPS Datasets and Benchmarks Track in 2022</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAOYI ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Haoyi Zhu is one of the authors of the paper titled "MineDojo: Building open-ended embodied agents with internet-scale knowledge" published in NeurIPS Datasets and Benchmarks Track in 2022</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANDREW TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Tang is one of the authors of the paper titled "MineDojo: Building open-ended embodied agents with internet-scale knowledge" published in NeurIPS Datasets and Benchmarks Track in 2022</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DE-AN HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">De-An Huang is a notable researcher in the field of Artificial Intelligence and Machine Learning. Huang is one of the authors of the paper titled "Eureka: Human-level reward design via coding large language models," which was published in the Twelfth International Conference on Learning Representations in 2023. Additionally, Huang contributed to the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge," published in the NeurIPS Datasets and Benchmarks Track in 2022. These contributions highlight Huang's involvement in advancing AI through innovative research on reward design and the development of embodied agents utilizing extensive internet-scale knowledge.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUKE ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Yuke Zhu is a prominent researcher in the field of Artificial Intelligence and Machine Learning, contributing significantly to the development of embodied agents and reward design. He is one of the authors of several influential papers, including "Eureka: Human-level reward design via coding large language models," published at the Twelfth International Conference on Learning Representations in 2023, "MineDojo: Building open-ended embodied agents with internet-scale knowledge," published in NeurIPS Datasets and Benchmarks Track in 2022, and "Voyager: An open-ended embodied agent with large language models," published on arXiv in 2023. His work focuses on leveraging large language models to advance the capabilities of AI agents in open-ended environments.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANIMA ANANDKUMAR">
      <data key="d0">PERSON</data>
      <data key="d1">Anima Anandkumar is a prolific researcher in the field of Artificial Intelligence and Machine Learning. She is one of the authors of several significant papers, including "Eureka: Human-level reward design via coding large language models," published at the Twelfth International Conference on Learning Representations in 2023, "MineDojo: Building open-ended embodied agents with internet-scale knowledge," published in NeurIPS Datasets and Benchmarks Track in 2022, and "Voyager: An open-ended embodied agent with large language models," published on arXiv in 2023. Her work focuses on leveraging large language models to design advanced AI systems and embodied agents, contributing to the cutting-edge research in AI and ML.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NEURIPS DATASETS AND BENCHMARKS TRACK">
      <data key="d0">EVENT</data>
      <data key="d1">NeurIPS Datasets and Benchmarks Track is a track within the NeurIPS conference where the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" was published in 2022</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="HIROKI FURUTA">
      <data key="d0">PERSON</data>
      <data key="d1">Hiroki Furuta is one of the authors of the paper titled "Multimodal web navigation with instruction-finetuned foundation models" published in ICLR 2024</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUTAKA MATSUO">
      <data key="d0">PERSON</data>
      <data key="d1">Yutaka Matsuo is one of the authors of the paper titled "Multimodal web navigation with instruction-finetuned foundation models" published in ICLR 2024</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHIXIANG SHANE GU">
      <data key="d0">PERSON</data>
      <data key="d1">Shixiang Shane Gu is one of the authors of the paper titled "Multimodal web navigation with instruction-finetuned foundation models" published in ICLR 2024</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="IZZEDDIN GUR">
      <data key="d0">PERSON</data>
      <data key="d1">Izzeddin Gur is one of the authors of the paper titled "Multimodal web navigation with instruction-finetuned foundation models" published in ICLR 2024</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LUYU GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Luyu Gao is one of the authors of the paper titled "PAL: Program-aided language models" published in the International Conference on Machine Learning (ICML) in 2023. Additionally, Luyu Gao co-authored the paper "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AMAN MADAAN">
      <data key="d0">PERSON</data>
      <data key="d1">Aman Madaan is a notable author in the field of Artificial Intelligence and Machine Learning. He co-authored the paper titled "PAL: Program-aided language models," which was published at the International Conference on Machine Learning (ICML) in 2023. Additionally, he contributed to the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHUYAN ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Shuyan Zhou is one of the authors of the paper titled "PAL: Program-aided language models," which was published in the International Conference on Machine Learning (ICML) in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="URI ALON">
      <data key="d0">PERSON</data>
      <data key="d1">Uri Alon is a notable author in the field of Artificial Intelligence and Machine Learning. He has contributed to significant research, including the paper titled "PAL: Program-aided language models," which was published at the International Conference on Machine Learning (ICML) in 2023. Additionally, Uri Alon co-authored the paper "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PENGFEI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Pengfei Liu is a notable researcher in the field of Artificial Intelligence and Machine Learning. He has co-authored several influential papers, including "Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization" published in 2023, "Infobench: Evaluating instruction following ability in large language models" published in 2024, and "PAL: Program-aided language models" presented at the International Conference on Machine Learning (ICML) in 2023. His work primarily focuses on the capabilities and evaluation of large language models, contributing significantly to the understanding and advancement of instruction controllable summarization and program-aided language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,3d1f6634f93f8a4c296dc8df7e59859e,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIMING YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yiming Yang is one of the authors of the paper titled "PAL: Program-aided language models" published in the International Conference on Machine Learning (ICML) in 2023. Additionally, Yiming Yang is also one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback" published in Advances in Neural Information Processing Systems (NeurIPS) in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JAMIE CALLAN">
      <data key="d0">PERSON</data>
      <data key="d1">Jamie Callan is one of the authors of the paper titled "PAL: Program-aided language models," which was published in the International Conference on Machine Learning (ICML) in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GRAHAM NEUBIG">
      <data key="d0">PERSON</data>
      <data key="d1">Graham Neubig is one of the authors of the paper titled "PAL: Program-aided language models," which was published in the International Conference on Machine Learning (ICML) in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIAXIAN GUO">
      <data key="d0">PERSON</data>
      <data key="d1">Jiaxian Guo is one of the authors of the paper titled "Long text generation via adversarial training with leaked information" published in AAAI 2018</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SIDI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Sidi Lu is one of the authors of the paper titled "Long text generation via adversarial training with leaked information" published in AAAI 2018</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Han Cai is one of the authors of the paper titled "Long text generation via adversarial training with leaked information" published in AAAI 2018</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WEINAN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Weinan Zhang is one of the authors of the paper titled "Long text generation via adversarial training with leaked information" published in AAAI 2018</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YONG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Yong Yu is one of the authors of the paper titled "Long text generation via adversarial training with leaked information" published in AAAI 2018</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JUN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jun Wang is one of the authors of the paper titled "Long text generation via adversarial training with leaked information" published in AAAI 2018</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AAAI">
      <data key="d0">EVENT</data>
      <data key="d1">AAAI is a conference where the paper "Long text generation via adversarial training with leaked information" was published in 2018</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="NICHOLAY TOPIN">
      <data key="d0">PERSON</data>
      <data key="d1">Nicholay Topin is one of the authors of the paper titled "MineRL: A large-scale dataset of Minecraft demonstrations" published in IJCAI 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PHILLIP WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Phillip Wang is one of the authors of the paper titled "MineRL: A large-scale dataset of Minecraft demonstrations" published in IJCAI 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CAYDEN CODEL">
      <data key="d0">PERSON</data>
      <data key="d1">Cayden Codel is one of the authors of the paper titled "MineRL: A large-scale dataset of Minecraft demonstrations" published in IJCAI 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MANUELA VELOSO">
      <data key="d0">PERSON</data>
      <data key="d1">Manuela Veloso is one of the authors of the paper titled "MineRL: A large-scale dataset of Minecraft demonstrations" published in IJCAI 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RUSLAN SALAKHUTDINOV">
      <data key="d0">PERSON</data>
      <data key="d1">Ruslan Salakhutdinov is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering," which was published in EMNLP 2018. Additionally, he contributed to the paper "MineRL: A large-scale dataset of Minecraft demonstrations," published in IJCAI 2019. These contributions highlight his involvement in developing significant datasets that advance the capabilities of AI in understanding complex questions and learning from large-scale demonstrations.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="IJCAI">
      <data key="d0">EVENT</data>
      <data key="d1">IJCAI is a conference where the paper "MineRL: A large-scale dataset of Minecraft demonstrations" was published in 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="DANIJAR HAFNER">
      <data key="d0">PERSON</data>
      <data key="d1">Danijar Hafner is a prominent researcher in the field of Artificial Intelligence and Machine Learning. He has contributed significantly to the development of world models for physical robot learning, as evidenced by his co-authorship of the paper titled "Daydreamer: World models for physical robot learning" published in CoRL 2023. Additionally, Hafner has explored the realm of learning latent dynamics for planning from pixels, which is detailed in his paper published in ICML 2019. His work also extends to mastering diverse domains through world models, as demonstrated in his 2023 publication on arXiv. Hafner's research highlights his expertise in leveraging world models to advance the capabilities of AI and ML in various applications.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TIMOTHY LILLICRAP">
      <data key="d0">PERSON</data>
      <data key="d1">Timothy Lillicrap is one of the authors of the paper titled "Mastering diverse domains through world models" published on arXiv in 2023Timothy Lillicrap is one of the authors of the paper titled "Learning latent dynamics for planning from pixels" published in ICML 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="IAN FISCHER">
      <data key="d0">PERSON</data>
      <data key="d1">Ian Fischer is one of the authors of the paper titled "Learning latent dynamics for planning from pixels" published in ICML 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RUBEN VILLEGAS">
      <data key="d0">PERSON</data>
      <data key="d1">Ruben Villegas is one of the authors of the paper titled "Learning latent dynamics for planning from pixels" published in ICML 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAVID HA">
      <data key="d0">PERSON</data>
      <data key="d1">David Ha is one of the authors of the paper titled "Learning latent dynamics for planning from pixels" published in ICML 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HONGLAK LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Honglak Lee is one of the authors of the paper titled "Learning latent dynamics for planning from pixels" published in ICML 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JAMES DAVIDSON">
      <data key="d0">PERSON</data>
      <data key="d1">James Davidson is one of the authors of the paper titled "Learning latent dynamics for planning from pixels" published in ICML 2019</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JURGIS PASUKONIS">
      <data key="d0">PERSON</data>
      <data key="d1">Jurgis Pasukonis is one of the authors of the paper titled "Mastering diverse domains through world models" published on arXiv in 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIMMY BA">
      <data key="d0">PERSON</data>
      <data key="d1">Jimmy Ba is one of the authors of the paper titled "Mastering diverse domains through world models" published on arXiv in 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHIBO HAO">
      <data key="d0">PERSON</data>
      <data key="d1">Shibo Hao is one of the authors of the paper titled "Reasoning with language model is planning with world model" published in EMNLP 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YI GU">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Gu is one of the authors of the paper titled "Reasoning with language model is planning with world model" published in EMNLP 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAODI MA">
      <data key="d0">PERSON</data>
      <data key="d1">Haodi Ma is one of the authors of the paper titled "Reasoning with language model is planning with world model" published in EMNLP 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOSHUA JIAHUA HONG">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Jiahua Hong is one of the authors of the paper titled "Reasoning with language model is planning with world model" published in EMNLP 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHEN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhen Wang is one of the authors of the paper titled "Reasoning with language model is planning with world model" published in EMNLP 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAISY ZHE WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Daisy Zhe Wang is one of the authors of the paper titled "Reasoning with language model is planning with world model" published in EMNLP 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHTING HU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiting Hu is one of the authors of the paper titled "Reasoning with language model is planning with world model" published in EMNLP 2023</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="EMNLP">
      <data key="d0">EVENT</data>
      <data key="d1">EMNLP, or the Conference on Empirical Methods in Natural Language Processing, is a prominent conference in the field of Natural Language Processing (NLP). It serves as a platform for the dissemination of significant research findings. Notably, in 2018, EMNLP featured the publication of the paper "HotpotQA: A dataset for diverse, explainable multi-hop question answering," which introduced a dataset aimed at enhancing the explainability and diversity of multi-hop question answering systems. More recently, in 2023, the conference included the paper "Reasoning with language model is planning with world model," which explores the integration of language models with world models to improve reasoning capabilities. EMNLP continues to be a key venue for cutting-edge research and advancements in NLP.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="JIE HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jie Huang is one of the authors of the paper titled "Large language models cannot self-correct reasoning yet" published in ICLR 2024</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XINYUN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyun Chen is a prolific researcher in the field of Artificial Intelligence and Machine Learning, contributing significantly to the understanding and development of large language models. In 2024, Chen co-authored several influential papers, including "Large language models as optimizers" presented at The Twelfth International Conference on Learning Representations, "Large language models cannot self-correct reasoning yet" published in ICLR, and "Self-discover: Large language models self-compose reasoning structures" available on arXiv. Additionally, in 2023, Chen co-authored the paper "Take a step back: Evoking reasoning via abstraction in large language models," also published on arXiv. These works collectively explore the capabilities and limitations of large language models in optimization, self-correction, and reasoning, highlighting Chen's significant contributions to advancing the field.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SWAROOP MISHRA">
      <data key="d0">PERSON</data>
      <data key="d1">Swaroop Mishra is a prolific researcher in the field of Artificial Intelligence and Machine Learning, contributing significantly to the understanding and development of large language models. He is one of the authors of several influential papers, including "Instruction-following evaluation for large language models" published in 2023, "Large language models cannot self-correct reasoning yet" presented at ICLR 2024, "Self-discover: Large language models self-compose reasoning structures" published on arXiv in 2024, and "Take a step back: Evoking reasoning via abstraction in large language models" also published on arXiv in 2023. His work focuses on the evaluation, self-correction, and reasoning capabilities of large language models, highlighting both their potential and current limitations.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HUAIXIU STEVEN ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Huaixiu Steven Zheng is a notable researcher in the field of Artificial Intelligence and Machine Learning. He has co-authored significant papers, including "Large language models cannot self-correct reasoning yet," published in ICLR 2024, and "Take a step back: Evoking reasoning via abstraction in large language models," published on arXiv in 2023. His work focuses on the capabilities and limitations of large language models, particularly in the context of reasoning and abstraction.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NIKET TANDON">
      <data key="d0">PERSON</data>
      <data key="d1">Niket Tandon is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PRAKHAR GUPTA">
      <data key="d0">PERSON</data>
      <data key="d1">Prakhar Gupta is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SKYLER HALLINAN">
      <data key="d0">PERSON</data>
      <data key="d1">Skyler Hallinan is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SARAH WIEGREFFE">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Wiegreffe is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NOUHA DZIRI">
      <data key="d0">PERSON</data>
      <data key="d1">Nouha Dziri is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SHRIMAI PRABHUMOYE">
      <data key="d0">PERSON</data>
      <data key="d1">Shrimai Prabhumoye is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SHASHANK GUPTA">
      <data key="d0">PERSON</data>
      <data key="d1">Shashank Gupta is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BODHISATTWA PRASAD MAJUMDER">
      <data key="d0">PERSON</data>
      <data key="d1">Bodhisattwa Prasad Majumder is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KATHERINE HERMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Katherine Hermann is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SEAN WELLECK">
      <data key="d0">PERSON</data>
      <data key="d1">Sean Welleck is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="AMIR YAZDANBAKHSH">
      <data key="d0">PERSON</data>
      <data key="d1">Amir Yazdanbakhsh is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PETER CLARK">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Clark is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "Self-refine: Iterative refinement with self-feedback," published in NeurIPS 2023. Additionally, he contributed to the paper "Think you have solved question answering? try arc, the ai2 reasoning challenge," which was published on arXiv in 2018. These contributions highlight his involvement in advancing AI research, particularly in the areas of iterative refinement and question answering challenges.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RAMESH NALLAPATI">
      <data key="d0">PERSON</data>
      <data key="d1">Ramesh Nallapati is one of the authors of the paper titled "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning in 2016</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BOWEN ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Bowen Zhou is a notable author in the field of Natural Language Processing and Machine Learning. He co-authored the paper titled "Abstractive text summarization using sequence-to-sequence RNNs and beyond," which was published in the Special Interest Group on Natural Language Learning in 2016. Additionally, he contributed to the paper "Enhancing chat language models by scaling high-quality instructional conversations," published on arXiv in 2023. These works highlight his involvement in advancing techniques for text summarization and improving the quality of conversational AI models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CICERO DOS SANTOS">
      <data key="d0">PERSON</data>
      <data key="d1">Cicero dos Santos is one of the authors of the paper titled "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning in 2016</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CAGLAR GULCEHRE">
      <data key="d0">PERSON</data>
      <data key="d1">Caglar Gulcehre is one of the authors of the paper titled "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning in 2016</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BING XIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Bing Xiang is one of the authors of the paper titled "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning in 2016</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SPECIAL INTEREST GROUP ON NATURAL LANGUAGE LEARNING">
      <data key="d0">EVENT</data>
      <data key="d1">The Special Interest Group on Natural Language Learning is an event where the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" was published in 2016</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUJIA QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Yujia Qin is one of the authors of the paper titled "Enhancing chat language models by scaling high-quality instructional conversations" published on arXiv in 2023. Additionally, Yujia Qin co-authored the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in 2023 and later presented at ICLR 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHIHAO LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shihao Liang is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in 2023 and will be presented at ICLR 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YINING YE">
      <data key="d0">PERSON</data>
      <data key="d1">Yining Ye is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in 2023 and is set to be presented at the International Conference on Learning Representations (ICLR) in 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KUNLUN ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Kunlun Zhu is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in 2023 and is set to be presented at the International Conference on Learning Representations (ICLR) in 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LAN YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Lan Yan is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in 2023 and is set to be presented at the International Conference on Learning Representations (ICLR) in 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YAXI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yaxi Lu is one of the authors of the paper "Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors" published in the Twelfth International Conference on Learning Representations in 2023. Additionally, Yaxi Lu co-authored the paper "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-World APIs," which was published in 2023 and is set to be presented at ICLR 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="YANKAI LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Yankai Lin is one of the authors of the paper titled "A survey on large language model based autonomous agents" published in Frontiers of Computer Science in 2024. Additionally, Yankai Lin co-authored the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in 2023 and presented at ICLR 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XIN CONG">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Cong is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in 2023 and is set to be presented at ICLR 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XIANGRU TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiangru Tang is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in ICLR 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BILL QIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Bill Qian is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR 2024</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SIHAN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Sihan Zhao is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR 2024</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="RUNCHU TIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Runchu Tian is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR 2024</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="RUOBING XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Ruobing Xie is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR 2024</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JIE ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Jie Zhou is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR 2024</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARK GERSTEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Mark Gerstein is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR 2024</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DAHAI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Dahai Li is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR 2024</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ZHIYUAN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Liu is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "Enhancing chat language models by scaling high-quality instructional conversations," which was published on arXiv in 2023. Additionally, he contributed to the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," published in ICLR 2024. These works highlight his involvement in advancing the capabilities of language models and their practical applications in real-world scenarios.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MAOSONG SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Maosong Sun is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "Enhancing chat language models by scaling high-quality instructional conversations," published on arXiv in 2023. Additionally, he contributed to the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in ICLR 2024. These contributions highlight his involvement in advancing the capabilities of language models and their applications in real-world scenarios.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ABULHAIR SAPAROV">
      <data key="d0">PERSON</data>
      <data key="d1">Abulhair Saparov is one of the authors of the paper titled "Language models are greedy reasoners: A systematic formal analysis of chain-of-thought" published in ICLR 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HE HE">
      <data key="d0">PERSON</data>
      <data key="d1">He He is one of the authors of the paper titled "Language models are greedy reasoners: A systematic formal analysis of chain-of-thought" published in ICLR 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="TIMO SCHICK">
      <data key="d0">PERSON</data>
      <data key="d1">Timo Schick is one of the authors of the paper titled "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JANE DWIVEDI-YU">
      <data key="d0">PERSON</data>
      <data key="d1">Jane Dwivedi-Yu is one of the authors of the paper titled "Toolformer: Language models can teach themselves to use tools," which was published in NeurIPS 2023, also known as the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROBERTO DESSI">
      <data key="d0">PERSON</data>
      <data key="d1">Roberto Dessi is one of the authors of the paper titled "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROBERTA RAILEANU">
      <data key="d0">PERSON</data>
      <data key="d1">Roberta Raileanu is one of the authors of the paper titled "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MARIA LOMELI">
      <data key="d0">PERSON</data>
      <data key="d1">Maria Lomeli is one of the authors of the paper titled "Toolformer: Language models can teach themselves to use tools," which was published in NeurIPS 2023, also known as the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LUKE ZETTLEMOYER">
      <data key="d0">PERSON</data>
      <data key="d1">Luke Zettlemoyer is one of the authors of the paper titled "Toolformer: Language models can teach themselves to use tools," which was published in NeurIPS 2023, also known as the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NICOLA CANCEDDA">
      <data key="d0">PERSON</data>
      <data key="d1">Nicola Cancedda is one of the authors of the paper titled "Toolformer: Language models can teach themselves to use tools," which was published in NeurIPS 2023, also known as the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="THOMAS SCIALOM">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Scialom is a notable author in the field of Artificial Intelligence and Machine Learning. He contributed to the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023. Additionally, he co-authored the paper "Toolformer: Language models can teach themselves to use tools," which was published in NeurIPS 2023 and also presented at the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YONGLIANG SHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yongliang Shen is one of the authors of the paper titled "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KAITAO SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Kaitao Song is one of the authors of the paper titled "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XU TAN">
      <data key="d0">PERSON</data>
      <data key="d1">Xu Tan is one of the authors of the paper titled "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DONGSHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Dongsheng Li is one of the authors of the paper titled "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="WEIMING LU">
      <data key="d0">PERSON</data>
      <data key="d1">Weiming Lu is one of the authors of the paper titled "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUETING ZHUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yueting Zhuang is one of the authors of the paper titled "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NOAH SHINN">
      <data key="d0">PERSON</data>
      <data key="d1">Noah Shinn is one of the authors of the paper titled "Reflexion: Language agents with verbal reinforcement learning," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FEDERICO CASSANO">
      <data key="d0">PERSON</data>
      <data key="d1">Federico Cassano is one of the authors of the paper titled "Reflexion: Language agents with verbal reinforcement learning," published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BECK LABASH">
      <data key="d0">PERSON</data>
      <data key="d1">Beck Labash is one of the authors of the paper titled "Reflexion: Language agents with verbal reinforcement learning" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ASHWIN GOPINATH">
      <data key="d0">PERSON</data>
      <data key="d1">Ashwin Gopinath is one of the authors of the paper titled "Reflexion: Language agents with verbal reinforcement learning," published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="KARTHIK NARASIMHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Karthik Narasimhan is one of the authors of two significant papers published in Advances in Neural Information Processing Systems (NeurIPS) in 2023. The first paper is titled "Reflexion: Language agents with verbal reinforcement learning," and the second paper is titled "Tree of thoughts: deliberate problem solving with large language models."</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SHUNYU YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Shunyu Yao is a prolific researcher in the field of Artificial Intelligence and Machine Learning, contributing to several significant publications. In 2023, Shunyu Yao co-authored the paper "React: Synergizing reasoning and acting in language models," which was presented at The Eleventh International Conference on Learning Representations. Additionally, in the same year, Yao co-authored "Reflexion: Language agents with verbal reinforcement learning," published in Advances in Neural Information Processing Systems (NeurIPS 2023). Another notable work from 2023 includes "Tree of thoughts: deliberate problem solving with large language models," also published in NeurIPS. Furthermore, in 2022, Shunyu Yao contributed to the paper "WebShop: Towards scalable real-world web interaction with grounded language agents," which was featured in NeurIPS. These contributions highlight Shunyu Yao's active role in advancing the understanding and capabilities of language models and AI agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MOHIT SHRIDHAR">
      <data key="d0">PERSON</data>
      <data key="d1">Mohit Shridhar is one of the authors of the paper titled "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR 2020</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XINGDI YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Xingdi Yuan is one of the authors of the paper titled "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR 2020</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARC-ALEXANDRE COTE">
      <data key="d0">PERSON</data>
      <data key="d1">Marc-Alexandre Cote is one of the authors of the paper titled "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR 2020</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YONATAN BISK">
      <data key="d0">PERSON</data>
      <data key="d1">Yonatan Bisk is one of the authors of the paper titled "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR 2020</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ADAM TRISCHLER">
      <data key="d0">PERSON</data>
      <data key="d1">Adam Trischler is one of the authors of the paper titled "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR 2020</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DAVID SILVER">
      <data key="d0">PERSON</data>
      <data key="d1">David Silver is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="AJA HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Aja Huang is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CHRIS J. MADDISON">
      <data key="d0">PERSON</data>
      <data key="d1">Chris J. Maddison is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ARTHUR GUEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Arthur Guez is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="L. SIFRE">
      <data key="d0">PERSON</data>
      <data key="d1">L. Sifre is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="GEORGE VAN DEN DRIESSCHE">
      <data key="d0">PERSON</data>
      <data key="d1">George van den Driessche is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JULIAN SCHRITTWIESER">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Schrittwieser is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="IOANNIS ANTONOGLOU">
      <data key="d0">PERSON</data>
      <data key="d1">Ioannis Antonoglou is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="VEDAVYAS PANNEERSHELVAM">
      <data key="d0">PERSON</data>
      <data key="d1">Vedavyas Panneershelvam is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARC LANCTOT">
      <data key="d0">PERSON</data>
      <data key="d1">Marc Lanctot is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SANDER DIELEMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Sander Dieleman is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DOMINIK GREWE">
      <data key="d0">PERSON</data>
      <data key="d1">Dominik Grewe is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JOHN NHAM">
      <data key="d0">PERSON</data>
      <data key="d1">John Nham is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NAL KALCHBRENNER">
      <data key="d0">PERSON</data>
      <data key="d1">Nal Kalchbrenner is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="TIMOTHY P. LILLICRAP">
      <data key="d0">PERSON</data>
      <data key="d1">Timothy P. Lillicrap is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MADELEINE LEACH">
      <data key="d0">PERSON</data>
      <data key="d1">Madeleine Leach is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KORAY KAVUKCUOGLU">
      <data key="d0">PERSON</data>
      <data key="d1">Koray Kavukcuoglu is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="THORE GRAEPEL">
      <data key="d0">PERSON</data>
      <data key="d1">Thore Graepel is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DEMIS HASSABIS">
      <data key="d0">PERSON</data>
      <data key="d1">Demis Hassabis is one of the authors of the paper titled "Mastering the game of Go with deep neural networks and tree search" published in Nature in 2016 and "Mastering chess and Shogi by self-play with a general reinforcement learning algorithm" published on arXiv in 2017</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NATURE">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Nature is a prestigious journal known for publishing groundbreaking research in various scientific fields. Notably, it published the paper "Mathematical discoveries from program search with large language models" in 2024, highlighting advancements in AI and machine learning. Additionally, Nature is recognized for publishing the influential paper "Mastering the game of Go with deep neural networks and tree search" in 2016, which showcased significant progress in AI's ability to tackle complex games. These publications underscore Nature's role in disseminating pivotal research that shapes the future of artificial intelligence and machine learning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="STEVEN A. SLOMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Steven A. Sloman is the author of the paper titled "The empirical case for two systems of reasoning" published in Psychological Bulletin in 1996</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PSYCHOLOGICAL BULLETIN">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Psychological Bulletin is the journal where the paper "The empirical case for two systems of reasoning" was published in 1996</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HAOTIAN SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Haotian Sun is one of the authors of the paper titled "AdaPlanner: Adaptive planning from feedback with language models" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUCHEN ZHUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuchen Zhuang is one of the authors of the paper titled "AdaPlanner: Adaptive planning from feedback with language models" published in NeurIPS 2023. Additionally, Yuchen Zhuang co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search," which was published in ICLR 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LINGKAI KONG">
      <data key="d0">PERSON</data>
      <data key="d1">Lingkai Kong is one of the authors of the paper titled "AdaPlanner: Adaptive planning from feedback with language models" published in NeurIPS 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CHAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chao Zhang is a notable researcher in the field of Artificial Intelligence and Machine Learning. He has co-authored significant papers, including "AdaPlanner: Adaptive planning from feedback with language models," published in NeurIPS 2023, and "ToolChain*: Efficient action space navigation in large language models with A* search," published in ICLR 2023. His work focuses on innovative approaches to planning and action space navigation within large language models, contributing to advancements in adaptive planning and efficient search algorithms.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="DIDAC SURIS">
      <data key="d0">PERSON</data>
      <data key="d1">Didac Suris is one of the authors of the paper titled "ViperGPT: Visual inference via Python execution for reasoning" published in ICCV 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SACHIT MENON">
      <data key="d0">PERSON</data>
      <data key="d1">Sachit Menon is one of the authors of the paper titled "ViperGPT: Visual inference via Python execution for reasoning" published in ICCV 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CARL VONDRICK">
      <data key="d0">PERSON</data>
      <data key="d1">Carl Vondrick is one of the authors of the paper titled "ViperGPT: Visual inference via Python execution for reasoning" published in ICCV 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ICCV">
      <data key="d0">EVENT</data>
      <data key="d1">ICCV is a conference where the paper "ViperGPT: Visual inference via Python execution for reasoning" was published in 2023</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MACIEJ SWIECHOWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Maciej Swiechowski is one of the authors of the paper titled "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review in 2021</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KONRAD GODLEWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Konrad Godlewski is one of the authors of the paper titled "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review in 2021</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BARTOSZ SAWICKI">
      <data key="d0">PERSON</data>
      <data key="d1">Bartosz Sawicki is one of the authors of the paper titled "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review in 2021</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JACEK MA'NDZIUK">
      <data key="d0">PERSON</data>
      <data key="d1">Jacek Ma'ndziuk is one of the authors of the paper titled "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review in 2021</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE REVIEW">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Artificial Intelligence Review is the journal where the paper "Monte Carlo tree search: A review of recent modifications and applications" was published in 2021</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HUGO TOUVRON">
      <data key="d0">PERSON</data>
      <data key="d1">Hugo Touvron is one of the authors of the paper mentioned in the text</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="LOUIS MARTIN">
      <data key="d0">PERSON</data>
      <data key="d1">Louis Martin is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KEVIN R. STONE">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin R. Stone is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PETER ALBERT">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Albert is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AMJAD ALMAHAIRI">
      <data key="d0">PERSON</data>
      <data key="d1">Amjad Almahairi is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YASMINE BABAEI">
      <data key="d0">PERSON</data>
      <data key="d1">Yasmine Babaei is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NIKOLAY BASHLYKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Nikolay Bashlykov is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SOUMYA BATRA">
      <data key="d0">PERSON</data>
      <data key="d1">Soumya Batra is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PRAJJWAL BHARGAVA">
      <data key="d0">PERSON</data>
      <data key="d1">Prajjwal Bhargava is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SHRUTI BHOSALE">
      <data key="d0">PERSON</data>
      <data key="d1">Shruti Bhosale is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DANIEL M. BIKEL">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel M. Bikel is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LUKAS BLECHER">
      <data key="d0">PERSON</data>
      <data key="d1">Lukas Blecher is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CRISTIAN CANTON FERRER">
      <data key="d0">PERSON</data>
      <data key="d1">Cristian Canton Ferrer is one of the authors of the paper mentioned in the text</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MOYA CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Moya Chen is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="GUILLEM CUCURULL">
      <data key="d0">PERSON</data>
      <data key="d1">Guillem Cucurull is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models," which was published on arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CRISTIAN CANT&#211;N FERRER">
      <data key="d0">PERSON</data>
      <data key="d1">Cristian Cant&#243;n Ferrer is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DAVID ESIOBU">
      <data key="d0">PERSON</data>
      <data key="d1">David Esiobu is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JUDE FERNANDES">
      <data key="d0">PERSON</data>
      <data key="d1">Jude Fernandes is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEREMY FU">
      <data key="d0">PERSON</data>
      <data key="d1">Jeremy Fu is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WENYIN FU">
      <data key="d0">PERSON</data>
      <data key="d1">Wenyin Fu is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BRIAN FULLER">
      <data key="d0">PERSON</data>
      <data key="d1">Brian Fuller is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CYNTHIA GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Cynthia Gao is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VEDANUJ GOSWAMI">
      <data key="d0">PERSON</data>
      <data key="d1">Vedanuj Goswami is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NAMAN GOYAL">
      <data key="d0">PERSON</data>
      <data key="d1">Naman Goyal is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023. Additionally, he is also one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks."</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANTHONY S. HARTSHORN">
      <data key="d0">PERSON</data>
      <data key="d1">Anthony S. Hartshorn is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SAGHAR HOSSEINI">
      <data key="d0">PERSON</data>
      <data key="d1">Saghar Hosseini is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RUI HOU">
      <data key="d0">PERSON</data>
      <data key="d1">Rui Hou is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="HAKAN INAN">
      <data key="d0">PERSON</data>
      <data key="d1">Hakan Inan is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MARCIN KARDAS">
      <data key="d0">PERSON</data>
      <data key="d1">Marcin Kardas is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VIKTOR KERKEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Viktor Kerkez is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MADIAN KHABSA">
      <data key="d0">PERSON</data>
      <data key="d1">Madian Khabsa is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ISABEL M. KLOUMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Isabel M. Kloumann is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="A. V. KORENEV">
      <data key="d0">PERSON</data>
      <data key="d1">A. V. Korenev is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUNIT SINGH KOURA">
      <data key="d0">PERSON</data>
      <data key="d1">Punit Singh Koura is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MARIE-ANNE LACHAUX">
      <data key="d0">PERSON</data>
      <data key="d1">Marie-Anne Lachaux is one of the authors of two significant papers published on arXiv in 2023. The first paper is titled "Llama 2: Open foundation and fine-tuned chat models," and the second paper is titled "Mistral 7b." Both papers contribute to the field of artificial intelligence and machine learning, showcasing advancements in open foundation models and fine-tuned chat models, as well as developments in the Mistral 7b model.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="THIBAUT LAVRIL">
      <data key="d0">PERSON</data>
      <data key="d1">Thibaut Lavril is one of the authors of two significant papers published on arXiv in 2023. The first paper is titled "Llama 2: Open foundation and fine-tuned chat models," and the second paper is titled "Mistral 7b."</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JENYA LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Jenya Lee is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DIANA LISKOVICH">
      <data key="d0">PERSON</data>
      <data key="d1">Diana Liskovich is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YINGHAI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yinghai Lu is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUNING MAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yuning Mao is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XAVIER MARTINET">
      <data key="d0">PERSON</data>
      <data key="d1">Xavier Martinet is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TODOR MIHAYLOV">
      <data key="d0">PERSON</data>
      <data key="d1">Todor Mihaylov is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUSHKAR MISHRA">
      <data key="d0">PERSON</data>
      <data key="d1">Pushkar Mishra is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="IGOR MOLYBOG">
      <data key="d0">PERSON</data>
      <data key="d1">Igor Molybog is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YIXIN NIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yixin Nie is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANDREW POULTON">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Poulton is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEREMY REIZENSTEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Jeremy Reizenstein is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RASHI RUNGTA">
      <data key="d0">PERSON</data>
      <data key="d1">Rashi Rungta is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KALYAN SALADI">
      <data key="d0">PERSON</data>
      <data key="d1">Kalyan Saladi is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ALAN SCHELTEN">
      <data key="d0">PERSON</data>
      <data key="d1">Alan Schelten is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RUAN SILVA">
      <data key="d0">PERSON</data>
      <data key="d1">Ruan Silva is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ERIC MICHAEL SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Michael Smith is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="R. SUBRAMANIAN">
      <data key="d0">PERSON</data>
      <data key="d1">R. Subramanian is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XIA TAN">
      <data key="d0">PERSON</data>
      <data key="d1">Xia Tan is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BINH TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Binh Tang is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROSS TAYLOR">
      <data key="d0">PERSON</data>
      <data key="d1">Ross Taylor is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ADINA WILLIAMS">
      <data key="d0">PERSON</data>
      <data key="d1">Adina Williams is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JIAN XIANG KUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Jian Xiang Kuan is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUXIN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Puxin Xu is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ZHENGXU YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Zhengxu Yan is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ILIYAN ZAROV">
      <data key="d0">PERSON</data>
      <data key="d1">Iliyan Zarov is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUCHEN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuchen Zhang is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANGELA FAN">
      <data key="d0">PERSON</data>
      <data key="d1">Angela Fan is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MELANIE KAMBADUR">
      <data key="d0">PERSON</data>
      <data key="d1">Melanie Kambadur is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AURELIEN RODRIGUEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Aurelien Rodriguez is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROBERT STOJNIC">
      <data key="d0">PERSON</data>
      <data key="d1">Robert Stojnic is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SERGEY EDUNOV">
      <data key="d0">PERSON</data>
      <data key="d1">Sergey Edunov is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TOM VODOPIVEC">
      <data key="d0">PERSON</data>
      <data key="d1">Tom Vodopivec is one of the authors of the paper titled "On Monte Carlo tree search and reinforcement learning" published in the Journal of Artificial Intelligence Research in 2017</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BRANKO STER">
      <data key="d0">PERSON</data>
      <data key="d1">Branko Ster is one of the authors of the paper titled "On Monte Carlo tree search and reinforcement learning" published in the Journal of Artificial Intelligence Research in 2017</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The Journal of Artificial Intelligence Research is a publication where the paper "On Monte Carlo tree search and reinforcement learning" was published in 2017</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUQI XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yuqi Xie is one of the authors of the paper titled "Voyager: An open-ended embodied agent with large language models" published on arXiv in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHAOWEI XIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Chaowei Xiao is one of the authors of the paper titled "Voyager: An open-ended embodied agent with large language models" published on arXiv in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VOYAGER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">VOYAGER is an open-ended embodied agent that utilizes large language models, as detailed in a paper published on arXiv in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XUEZHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xuezhi Wang is a notable researcher in the field of Artificial Intelligence and Machine Learning, contributing significantly to the development of language models. Wang is one of the authors of several influential papers, including "Language models are multilingual chain-of-thought reasoners" and "Self-consistency improves chain of thought reasoning in language models," both published in The Eleventh International Conference on Learning Representations in 2023. Additionally, Wang co-authored the paper "Least-to-most prompting enables complex reasoning in large language models," published in ICLR 2022. These works highlight Wang's focus on enhancing the reasoning capabilities of language models through innovative techniques such as chain-of-thought reasoning and self-consistency.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JASON WEI">
      <data key="d0">PERSON</data>
      <data key="d1">Jason Wei is a prolific researcher in the field of Artificial Intelligence and Machine Learning, contributing significantly to the understanding and advancement of language models. He is one of the authors of several influential papers, including "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022. Additionally, he co-authored "Language models are multilingual chain-of-thought reasoners," presented at The Eleventh International Conference on Learning Representations (ICLR) in 2023. His work also includes "Self-consistency improves chain of thought reasoning in language models," which was published both in ICLR 2022 and The Eleventh International Conference on Learning Representations in 2023. Furthermore, Jason Wei contributed to the paper "Least-to-most prompting enables complex reasoning in large language models," also published in ICLR 2022. His research focuses on enhancing the reasoning capabilities of language models through innovative techniques such as chain-of-thought and self-consistency.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ED CHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ed Chi is one of the authors of the papers titled "Least-to-most prompting enables complex reasoning in large language models" and "Self-consistency improves chain of thought reasoning in language models," both published in ICLR 2022.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DENNY ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Denny Zhou is a prolific author in the field of Artificial Intelligence and Machine Learning, contributing to several significant papers. In 2022, he co-authored "Challenging big-bench tasks and whether chain-of-thought can solve them" and "Least-to-most prompting enables complex reasoning in large language models," both published in the International Conference on Learning Representations (ICLR). Additionally, he co-authored "Self-consistency improves chain of thought reasoning in language models," which was published in both ICLR 2022 and The Eleventh International Conference on Learning Representations in 2023. In 2023, he also contributed to "Instruction-following evaluation for large language models" and "Language models are multilingual chain-of-thought reasoners," presented at the same conference. His recent works include "Take a step back: Evoking reasoning via abstraction in large language models" published on arXiv in 2023 and "Self-discover: Large language models self-compose reasoning structures" published on arXiv in 2024. Denny Zhou's research primarily focuses on enhancing the reasoning capabilities of large language models through innovative prompting techniques and self-consistency methods.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MICHAEL WOOLDRIDGE">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Wooldridge is one of the authors of the paper titled "Intelligent agents: Theory and practice" published in The Knowledge Engineering Review in 1995</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NICHOLAS R JENNINGS">
      <data key="d0">PERSON</data>
      <data key="d1">Nicholas R Jennings is one of the authors of the paper titled "Intelligent agents: Theory and practice" published in The Knowledge Engineering Review in 1995</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="THE KNOWLEDGE ENGINEERING REVIEW">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The Knowledge Engineering Review is a publication where the paper "Intelligent agents: Theory and practice" was published in 1995</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PHILIPP WU">
      <data key="d0">PERSON</data>
      <data key="d1">Philipp Wu is one of the authors of the paper titled "Daydreamer: World models for physical robot learning" published in CoRL 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ALEJANDRO ESCONTRELA">
      <data key="d0">PERSON</data>
      <data key="d1">Alejandro Escontrela is one of the authors of the paper titled "Daydreamer: World models for physical robot learning" published in CoRL 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KEN GOLDBERG">
      <data key="d0">PERSON</data>
      <data key="d1">Ken Goldberg is one of the authors of the paper titled "Daydreamer: World models for physical robot learning" published in CoRL 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CORL">
      <data key="d0">EVENT</data>
      <data key="d1">CoRL is a conference where the paper "Daydreamer: World models for physical robot learning" was published in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUXI XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yuxi Xie is one of the authors of the paper titled "Decomposition enhances reasoning via self-evaluation guided decoding" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KENJI KAWAGUCHI">
      <data key="d0">PERSON</data>
      <data key="d1">Kenji Kawaguchi is one of the authors of the paper titled "Decomposition enhances reasoning via self-evaluation guided decoding" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YIRAN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiran Zhao is one of the authors of the paper titled "Decomposition enhances reasoning via self-evaluation guided decoding" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XU ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Xu Zhao is one of the authors of the paper titled "Decomposition enhances reasoning via self-evaluation guided decoding" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MIN-YEN KAN">
      <data key="d0">PERSON</data>
      <data key="d1">Min-Yen Kan is one of the authors of the paper titled "Decomposition enhances reasoning via self-evaluation guided decoding" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JUNXIAN HE">
      <data key="d0">PERSON</data>
      <data key="d1">Junxian He is one of the authors of the paper titled "Decomposition enhances reasoning via self-evaluation guided decoding" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="QIZHE XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Qizhe Xie is one of the authors of the paper titled "Decomposition enhances reasoning via self-evaluation guided decoding" published on arXiv in 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ZHILIN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhilin Yang is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering" published in EMNLP 2018</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PENG QI">
      <data key="d0">PERSON</data>
      <data key="d1">Peng Qi is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering" published in EMNLP 2018</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SAIZHENG ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Saizheng Zhang is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering" published in EMNLP 2018</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YOSHUA BENGIO">
      <data key="d0">PERSON</data>
      <data key="d1">Yoshua Bengio is a prominent figure in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper "Managing Extreme AI Risks Amid Rapid Progress," published in Science in 2024, which addresses the critical issue of managing the risks associated with rapid advancements in AI technology. Additionally, he co-authored the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering," published in EMNLP 2018, contributing to the development of datasets that enhance the explainability and diversity of multi-hop question answering systems. These contributions highlight his significant role in advancing both the theoretical and practical aspects of AI and ML.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WILLIAM W COHEN">
      <data key="d0">PERSON</data>
      <data key="d1">William W Cohen is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering" published in EMNLP 2018</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHRISTOPHER D MANNING">
      <data key="d0">PERSON</data>
      <data key="d1">Christopher D. Manning is a prominent researcher in the field of Artificial Intelligence and Machine Learning. He has co-authored significant papers, including "Direct preference optimization: Your language model is secretly a reward model," published in Advances in Neural Information Processing Systems in 2024, and "HotpotQA: A dataset for diverse, explainable multi-hop question answering," published in EMNLP 2018. His work spans critical areas such as language models and multi-hop question answering, contributing to advancements in understanding and developing AI systems.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="HOWARD CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Howard Chen is one of the authors of the paper titled "WebShop: Towards scalable real-world web interaction with grounded language agents" published in NeurIPS 2022</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JOHN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">John Yang is one of the authors of the paper titled "WebShop: Towards scalable real-world web interaction with grounded language agents" published in NeurIPS 2022</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KARTHIK R NARASIMHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Karthik R Narasimhan is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "React: Synergizing reasoning and acting in language models," which was published at The Eleventh International Conference on Learning Representations in 2023. Additionally, he co-authored the paper "WebShop: Towards scalable real-world web interaction with grounded language agents," presented at NeurIPS 2022. His work focuses on advancing the capabilities of language models and exploring scalable real-world web interactions through grounded language agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DIAN YU">
      <data key="d0">PERSON</data>
      <data key="d1">Dian Yu is one of the authors of the paper titled "React: Synergizing reasoning and acting in language models" published in The Eleventh International Conference on Learning Representations in 2023. Additionally, Dian Yu is also one of the authors of the paper titled "Tree of thoughts: deliberate problem solving with large language models" published in NeurIPS 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEFFREY ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jeffrey Zhao is one of the authors of the paper titled "React: Synergizing reasoning and acting in language models" published in The Eleventh International Conference on Learning Representations in 2023. Additionally, he is also one of the authors of the paper titled "Tree of thoughts: deliberate problem solving with large language models" published in NeurIPS 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="IZHAK SHAFRAN">
      <data key="d0">PERSON</data>
      <data key="d1">Izhak Shafran is one of the authors of the paper titled "React: Synergizing reasoning and acting in language models" published in The Eleventh International Conference on Learning Representations in 2023. Additionally, he is also one of the authors of the paper titled "Tree of thoughts: deliberate problem solving with large language models" published in NeurIPS 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="THOMAS L. GRIFFITHS">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas L. Griffiths is one of the authors of the paper titled "Tree of thoughts: deliberate problem solving with large language models" published in NeurIPS 2023</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUAN CAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yuan Cao is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "React: Synergizing reasoning and acting in language models," which was published at The Eleventh International Conference on Learning Representations in 2023. Additionally, Yuan Cao contributed to the paper "Tree of thoughts: deliberate problem solving with large language models," published in NeurIPS 2023. His work focuses on enhancing the capabilities of language models through innovative approaches to reasoning and problem-solving.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NAN DU">
      <data key="d0">PERSON</data>
      <data key="d1">Nan Du is one of the authors of the paper titled "ReAct: Synergizing reasoning and acting in language models," which was published in The Eleventh International Conference on Learning Representations (ICLR) in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WEIRUI YE">
      <data key="d0">PERSON</data>
      <data key="d1">Weirui Ye is one of the authors of the paper titled "Mastering Atari games with limited data" published in NeurIPS 2021</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SHAOHUAI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Shaohuai Liu is one of the authors of the paper titled "Mastering Atari games with limited data" published in NeurIPS 2021</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="THANARD KURUTACH">
      <data key="d0">PERSON</data>
      <data key="d1">Thanard Kurutach is one of the authors of the paper titled "Mastering Atari games with limited data" published in NeurIPS 2021</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YANG GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yang Gao is one of the authors of the paper titled "Mastering Atari games with limited data" published in NeurIPS 2021</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NATHANAEL SCHARLI">
      <data key="d0">PERSON</data>
      <data key="d1">Nathanael Sch&#228;rli is one of the authors of the paper titled "Least-to-most prompting enables complex reasoning in large language models" published in ICLR 2022</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LE HOU">
      <data key="d0">PERSON</data>
      <data key="d1">Le Hou is a notable researcher in the field of Artificial Intelligence and Machine Learning. Le Hou has contributed to significant advancements in the domain, as evidenced by their authorship of influential papers. In 2023, Le Hou co-authored the paper titled "Instruction-following evaluation for large language models," which delves into the assessment of large language models' ability to follow instructions. Additionally, Le Hou co-authored another pivotal paper, "Least-to-most prompting enables complex reasoning in large language models," published in the International Conference on Learning Representations (ICLR) in 2022. This work explores innovative prompting techniques that enhance the reasoning capabilities of large language models. Through these contributions, Le Hou has demonstrated a profound impact on the development and understanding of advanced AI and ML methodologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NATHAN SCALES">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Scales is one of the authors of two significant papers in the field of Artificial Intelligence and Machine Learning. The first paper, titled "Challenging big-bench tasks and whether chain-of-thought can solve them," was published in 2022. The second paper, "Least-to-most prompting enables complex reasoning in large language models," was published in the International Conference on Learning Representations (ICLR) in 2022. These contributions highlight Nathan Scales' involvement in advancing complex reasoning capabilities in large language models and addressing challenging tasks within the AI community.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="OLIVIER BOUSQUET">
      <data key="d0">PERSON</data>
      <data key="d1">Olivier Bousquet is one of the authors of the paper titled "Least-to-most prompting enables complex reasoning in large language models" published in ICLR 2022</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XIANG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xiang Chen is one of the authors of the paper titled "ToolChain*: Efficient action space navigation in large language models with A* search," which was published in ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TONG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Tong Yu is one of the authors of the paper titled "ToolChain*: Efficient action space navigation in large language models with A* search," which was published in ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SAAYAN MITRA">
      <data key="d0">PERSON</data>
      <data key="d1">Saayan Mitra is one of the authors of the paper titled "ToolChain*: Efficient action space navigation in large language models with A* search," which was published in ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VICTOR BURSZTYN">
      <data key="d0">PERSON</data>
      <data key="d1">Victor Bursztyn is one of the authors of the paper titled "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="RYAN A. ROSSI">
      <data key="d0">PERSON</data>
      <data key="d1">Ryan A. Rossi is one of the authors of the paper titled "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SOMDEB SARKHEL">
      <data key="d0">PERSON</data>
      <data key="d1">Somdeb Sarkhel is one of the authors of the paper titled "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Qin is an author who has worked on LM-based environments like ToolBench</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALFWORLD">
      <data key="d0">ENVIRONMENT</data>
      <data key="d1">Alfworld is an environment used for text-based manipulation tasks</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">ENVIRONMENT</data>
    </node>
    <node id="TOOLBENCH">
      <data key="d0">ENVIRONMENT</data>
      <data key="d1">ToolBench is an LM-based environment involving API-based tools</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">ENVIRONMENT</data>
    </node>
    <node id="APPENDIX">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">The appendix of the document "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models" contains additional details and renamed variables to match the terminologies used in the main text. It includes pseudocode, discussions, experimental results, and environment details, providing comprehensive supplementary information to support the main content of the document.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,d66dc9ce4a9545b44f7486ea057b5937</data>
      <data key="d3">DOCUMENT SECTION</data>
    </node>
    <node id="SEC. A">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Section A of the appendix shows the pseudocode of the LATS algorithm</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">DOCUMENT SECTION</data>
    </node>
    <node id="SEC. B">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Section B of the appendix provides further discussion of the limitations of the LATS method</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">DOCUMENT SECTION</data>
    </node>
    <node id="SEC. C">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Section C of the appendix presents additional experimental results of the LATS method</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">DOCUMENT SECTION</data>
    </node>
    <node id="SEC. D">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Section D of the appendix specifies the environment details in the experiments</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">DOCUMENT SECTION</data>
    </node>
    <node id="SEC. E">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Section E of the appendix lists the prompts used for the HotPotQA environment</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">DOCUMENT SECTION</data>
    </node>
    <node id="SEC. F">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Section F of the appendix lists the prompts used for the Programming environment</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">DOCUMENT SECTION</data>
    </node>
    <node id="SEC. G">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Section G of the appendix lists the prompts used for the WebShop environment</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">DOCUMENT SECTION</data>
    </node>
    <node id="SEARCH APPROACHES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="WIKIPEDIA">
      <data key="d0">PLATFORM</data>
      <data key="d1">Wikipedia is a platform used as a source of information for the HotPotQA dataset. It provides paragraphs for retrieval and supporting facts for questions, making it an essential dataset for searching entities and returning relevant information.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">PLATFORM</data>
    </node>
    <node id="LM VALUE FUNCTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The LM value function scores states based on expected future reward, guiding the search process in LATS</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="CROWDWORKERS">
      <data key="d0">PERSON</data>
      <data key="d1">Crowdworkers are individuals who crafted the question-answer pairs in the HotPotQA dataset and provided supporting facts from documents</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALGORITHM 1">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Algorithm 1 is a specific implementation of LATS, detailing the steps and parameters required for its operation</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="FIG. 3">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Fig. 3 is a figure in the document that shows the results of the HumanEval experiments and the performance of LATS over time</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="FIG. 4">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Fig. 4 is a figure in the document that illustrates how ReAct and LATS work on an example task of HotPotQA, providing a qualitative comparison</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="YANG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Yang et al. are authors who created the HotPotQA dataset in 2018</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="&#923;">
      <data key="d0">PARAMETER</data>
      <data key="d1">&#955; is a hyperparameter used in the value function for LATS, set to 0.5 for the LM score and self-consistency score</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="DEPTH">
      <data key="d0">PARAMETER</data>
      <data key="d1">Depth (d) is a parameter in LATS that limits the number of steps in the search process, with different values tested in the experiments</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="SAMPLING SIZE">
      <data key="d0">PARAMETER</data>
      <data key="d1">Sampling size (n) is a parameter in LATS that determines the number of actions generated, with different values tested in the experiments</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="VALUE FUNCTION WEIGHT">
      <data key="d0">PARAMETER</data>
      <data key="d1">Value function weight (&#955;) is a parameter in LATS that balances the LM score and self-consistency score</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="STATE SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">State space is the environment complexity that affects the optimal settings for LATS parameters</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SEARCH [ENTITY]">
      <data key="d0">ACTION</data>
      <data key="d1">Search [entity] is an action in LATS that returns the first 5 sentences from the corresponding entity's Wikipedia page or suggests top-5 similar entities</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="LOOKUP [STRING]">
      <data key="d0">ACTION</data>
      <data key="d1">Lookup [string] is an action in LATS that returns the next sentence in the Wikipedia page for the given string</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="EXPANSION &amp; SIMULATION">
      <data key="d0">ACTION</data>
      <data key="d1">Expansion &amp; Simulation is an action in LATS that involves generating actions and evaluating them</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="TERMINAL STATE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Terminal state is a state in LATS where no further actions can be taken</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="INITIAL STATE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Initial state is the starting point for the LATS algorithm</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SUCCESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Success is the desired outcome in LATS, often determined by environment rewards</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="ENVIRONMENT REWARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Environment rewards are signals from the environment that guide the search process in LATS</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SUPPORTING FACTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Supporting facts are pieces of information provided by crowdworkers in the HotPotQA dataset to justify the answers</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="QUESTION-ANSWER PAIRS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Question-answer pairs are the main components of the HotPotQA dataset, requiring reasoning over multiple documents</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="WIKIPEDIA WEB API">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Wikipedia web API is a tool used in LATS to support interactive information retrieval from Wikipedia</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="EM">
      <data key="d0">METRIC</data>
      <data key="d1">EM (Exact Match) is a metric used to evaluate the performance of models on the HotPotQA dataset</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="TAB. 8">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Tab. 8 is a table in the document that shows the results of the HotPotQA experiments</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="A">
      <data key="d0">PARAMETER</data>
      <data key="d1">A is a parameter in LATS that represents the action space</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="O">
      <data key="d0">PARAMETER</data>
      <data key="d1">O is a parameter in LATS that represents the observation space</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="S">
      <data key="d0">PARAMETER</data>
      <data key="d1">S is a parameter in LATS that represents the state space</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="PV">
      <data key="d0">PARAMETER</data>
      <data key="d1">PV is a parameter in LATS that represents the value function</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="PREF">
      <data key="d0">PARAMETER</data>
      <data key="d1">PREF is a parameter in LATS that represents the reflection generator</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="K">
      <data key="d0">PARAMETER</data>
      <data key="d1">K is a parameter in LATS that represents the number of roll-outs</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="L">
      <data key="d0">PARAMETER</data>
      <data key="d1">L is a parameter in LATS that represents the depth limit</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="C">
      <data key="d0">PARAMETER</data>
      <data key="d1">C is a parameter in LATS that represents the context</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="R">
      <data key="d0">PARAMETER</data>
      <data key="d1">R is a parameter in LATS that represents the reward</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="T">
      <data key="d0">PARAMETER</data>
      <data key="d1">T is a parameter in LATS that represents the actual number of steps</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="ST">
      <data key="d0">PARAMETER</data>
      <data key="d1">ST is a parameter in LATS that represents the state at time t</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="AT">
      <data key="d0">PARAMETER</data>
      <data key="d1">AT is a parameter in LATS that represents the action at time t</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="OT">
      <data key="d0">PARAMETER</data>
      <data key="d1">OT is a parameter in LATS that represents the observation at time t</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="CT">
      <data key="d0">PARAMETER</data>
      <data key="d1">CT is a parameter in LATS that represents the context at time t</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="SC">
      <data key="d0">PARAMETER</data>
      <data key="d1">SC is a parameter in LATS that represents the self-consistency score</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="SEARCH">
      <data key="d0">ACTION</data>
      <data key="d1">SEARCH is an action taken to find specific products or information. It involves looking for products that meet specific criteria and is a task in reading comprehension that requires finding specific information within a text or across multiple texts. In the context of Interactive Information Retrieval, search returns the first 5 sentences from the corresponding entity's wiki page if it exists, or suggests the top-5 similar entities from the Wikipedia search engine.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7,b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="LOOKUP">
      <data key="d0">ACTION</data>
      <data key="d1">Lookup is an action in Interactive Information Retrieval that returns the next sentence in the page containing the specified string</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="FINISH">
      <data key="d0">ACTION</data>
      <data key="d1">"Finish" is an action in both HotPotQA and Interactive Information Retrieval. In HotPotQA, it signifies the model providing the final answer and completing the task. Similarly, in Interactive Information Retrieval, "Finish" denotes the completion of the current task with the provided answer.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d0">DATASET</data>
      <data key="d1">The Mostly Basic Programming Problems (MBPP) benchmark contains 974 short Python functions designed to evaluate program synthesis techniques</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="AMAZON">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Amazon is the source of over 1 million real-world products used in the WebShop environment</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="TASK SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">Task Score is an evaluation metric in WebShop defined as (100&#215;avg. reward), capturing the average reward obtained across episodes</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="SUCCESS RATE (SR)">
      <data key="d0">METRIC</data>
      <data key="d1">Success Rate (SR) is an evaluation metric in WebShop defined as the portion of successful episodes</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="INTERACTIVE INFORMATION RETRIEVAL">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="CHEN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Chen et al. are the authors who introduced the HumanEval dataset in 2021</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="AUSTIN ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Austin et al. are the authors who introduced the Mostly Basic Programming Problems (MBPP) benchmark in 2022</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="YA0 ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Yao et al. are the authors who introduced the WebShop environment in 2022. Additionally, Yao et al. is a reference to a group of authors who have worked on the setup for the Game of 24.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="QUERY">
      <data key="d0">ACTION</data>
      <data key="d1">Query is an action in WebShop that involves searching for a specific term or item</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="RESULTS">
      <data key="d0">STATE</data>
      <data key="d1">Results is a state in WebShop that displays the outcomes of a search query</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PRODUCT TITLE">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Product title is an attribute in WebShop that represents the name of an item in the search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="OPTION">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Option is an attribute in WebShop that represents different choices available for a selected item</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="DESC/OVERVIEW">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Desc/Overview is an attribute in WebShop that provides a description or overview of a selected item</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITEM">
      <data key="d0">STATE</data>
      <data key="d1">Item is a state in WebShop that represents a selected product from the search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITEM-DETAIL">
      <data key="d0">STATE</data>
      <data key="d1">Item-Detail is a state in WebShop that provides detailed information about a selected item</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EPISODE END">
      <data key="d0">STATE</data>
      <data key="d1">Episode End is a state in WebShop that signifies the end of a buying episode</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="REWARD">
      <data key="d0">METRIC</data>
      <data key="d1">Reward is a metric in WebShop calculated based on the number of attributes satisfied by the selected item</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT">
      <data key="d0">ACTION</data>
      <data key="d1">THOUGHT: A thought is a reasoning process about the current situation in a trajectory of a question-answering task. In the context of HotPotQA, thought is an action where the model reasons about the current situation.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ARTHUR'S MAGAZINE">
      <data key="d0">ENTITY</data>
      <data key="d1">Arthur's Magazine is an American literary periodical published in the 19th century. It was based in Philadelphia and edited by Timothy Shay Arthur. The magazine featured work by various authors and is mentioned in a HotPotQA example.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="FIRST FOR WOMEN">
      <data key="d0">ENTITY</data>
      <data key="d1">First for Women is a woman's magazine published by Bauer Media Group in the USA. It is mentioned in the context of a question about which magazine was started first, as well as in a HotPotQA example.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="COLORADO OROGENY">
      <data key="d0">ENTITY</data>
      <data key="d1">Colorado orogeny is a geological event mentioned in a HotPotQA example</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HIGH PLAINS">
      <data key="d0">ENTITY</data>
      <data key="d1">High Plains is a region that rises in elevation from around 1,800 to 7,000 ft, mentioned in a HotPotQA example</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">LOCATION</data>
    </node>
    <node id="PREV/NEXT PAGE">
      <data key="d0">ACTION</data>
      <data key="d1">Prev/Next page is an action in WebShop that allows navigation through search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="CHOOSE">
      <data key="d0">ACTION</data>
      <data key="d1">Choose is an action in WebShop that involves selecting an item or option</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BACK TO SEARCH">
      <data key="d0">ACTION</data>
      <data key="d1">"BACK TO SEARCH" is an option in WebShop that allows users to return to the search page, effectively bringing them back to the search state.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EPISODE">
      <data key="d0">STATE</data>
      <data key="d1">Episode is a state in WebShop that represents a complete sequence of actions from search to purchase</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="INSTRUCTIONS">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">INSTRUCTIONS in WebShop are attributes designed to guide the user through various actions. These instructions are iteratively refined in the Instruction Refinement Flow, a process aimed at enhancing their quality, diversity, and complexity.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ATTRIBUTES">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Attributes are characteristics or features of items in WebShop</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ENVIRONMENTS">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Environments are different settings or conditions under which experiments are conducted in WebShop</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="DEPTH LIMIT">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Depth limit is an attribute in WebShop that sets a maximum limit for the depth of actions or searches</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HYPERPARAMETERS">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Hyperparameters are attributes in WebShop that define the settings for value functions and other components</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="LM SCORE">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">LM score is an attribute in WebShop that represents the score given by the language model</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SELF-CONSISTENCY SCORE">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Self-consistency score is an attribute in WebShop that measures the consistency of actions or decisions</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITERATIONS">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Iterations are attributes in the Game of 24 that represent the number of times the process is repeated. Additionally, iterations are used in the Meta Agent Search algorithm to refine the novelty and correctness of the proposed agents.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SELF-CONSISTENCY TERM">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Self-consistency term is an attribute in the Game of 24 that validates the design of the self-consistency score</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HOTPOTQA PROMPTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">HotPotQA Prompts are techniques used in HotPotQA to guide the language model through question answering tasks</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BASE ACTING PROMPT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Base Acting Prompt is a technique in HotPotQA that involves interleaving Thought, Action, and Observation steps</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BASE REASONING PROMPT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Base Reasoning Prompt is a technique in HotPotQA that involves reasoning about the current situation and finishing with an answer</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="VALUE FUNCTION PROMPT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Value Function Prompt is a technique used in HotPotQA that involves analyzing the trajectories of a solution to a question-answering task, focusing on thoughts, actions, and observations. It serves as a set of instructions for evaluating the correctness of these trajectories, particularly in the context of purchasing an item based on a given specification, and scores the performance on a scale from 1 to 10.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,6f486e20e3102c7a285e357d356417ad,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="KEYWORD">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Keyword is an attribute in HotPotQA used to look up specific terms in the current passage</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="TIMOTHY SHAY ARTHUR">
      <data key="d0">PERSON</data>
      <data key="d1">Timothy Shay Arthur was the editor of Arthur's Magazine, an American literary periodical published in Philadelphia in the 19th century. He is mentioned in a HotPotQA example, highlighting his role in the literary community of that era.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EDGAR A. POE">
      <data key="d0">PERSON</data>
      <data key="d1">Edgar A. Poe is an author whose work was featured in Arthur's Magazine, mentioned in a HotPotQA example</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="J.H. INGRAHAM">
      <data key="d0">PERSON</data>
      <data key="d1">J.H. Ingraham is an author whose work was featured in Arthur's Magazine, mentioned in a HotPotQA example</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SARAH JOSEPHA HALE">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Josepha Hale is an author whose work was featured in Arthur's Magazine, mentioned in a HotPotQA example</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOMAS G. SPEAR">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas G. Spear is an author whose work was featured in Arthur's Magazine, mentioned in a HotPotQA example</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="GODEY'S LADY'S BOOK">
      <data key="d0">ENTITY</data>
      <data key="d1">Godey's Lady's Book is a publication that gained prominence when Arthur's Magazine was merged into it in May 1846. This merger is noted in a HotPotQA example, highlighting the historical significance of Godey's Lady's Book in the realm of periodicals.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BAUER MEDIA GROUP">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Bauer Media Group is the publisher of First for Women, mentioned in a HotPotQA example</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ENGLEWOOD CLIFFS">
      <data key="d0">LOCATION</data>
      <data key="d1">Englewood Cliffs is the location where First for Women is based, mentioned in a HotPotQA example</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="CIRCULATION">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Circulation is an attribute in HotPotQA that represents the number of copies distributed, mentioned in the context of First for Women</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ELEVATION">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Elevation is an attribute in HotPotQA that represents the height above sea level, mentioned in the context of the High Plains</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PLAINS">
      <data key="d0">GEOGRAPHICAL FEATURE</data>
      <data key="d1">Plains are large areas of flat or gently rolling land that rise in elevation from around 1,800 to 7,000 feet</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="SEARCH[ENTITY]">
      <data key="d0">ACTION</data>
      <data key="d1">Search[entity] is an action that searches for the exact entity on Wikipedia and returns the first paragraph if it exists, or similar entities if it does not</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="LOOKUP[KEYWORD]">
      <data key="d0">ACTION</data>
      <data key="d1">Lookup[keyword] is an action that returns the next sentence containing the specified keyword in the current passage</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="FINISH[ANSWER]">
      <data key="d0">ACTION</data>
      <data key="d1">Finish[answer] is an action that returns the answer and finishes the task</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="REFLECTION PROMPT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Reflection Prompt is a system designed to enhance the capabilities of an advanced reasoning agent through self-reflection. It achieves this by diagnosing failures and devising new plans. Additionally, the Reflection Prompt serves as a document that instructs an AI Python assistant to explain why a function implementation is incorrect based on unit test results. Furthermore, it provides a set of instructions for analyzing the trajectories of a solution to a question-answering task, focusing on thoughts, actions, and observations.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="HUMANEVAL FUNCTION IMPLEMENTATION EXAMPLE">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The HumanEval function implementation example is a sample function signature and body implementation for finding the minimum sum of any non-empty sub-array of integers</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="BASE ACTING/REASONING PROMPT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The Base Acting/Reasoning Prompt is a document that provides a comprehensive set of instructions for an AI Python assistant. It guides the assistant in writing a full implementation of a function by leveraging previous implementations, evaluating unit test results, and engaging in self-reflection. This prompt ensures that the AI assistant can effectively implement the function and assess its performance based on the outcomes of the unit tests.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="CORRECTNESS SCORE">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The correctness score is an integer from 1 to 10 that evaluates the correctness of a trajectory in a question-answering task</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="EXAMPLES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">EXAMPLES: A document providing examples of tasks from the ARC challenge, which refer to sample trajectories provided to illustrate correct or failed solutions in a question-answering task.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="CONTEXT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Context refers to the background information or setting in which a question-answering task is performed</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="UNIT TEST RESULTS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">"Unit test results are the outcomes of tests run on a function to verify its correctness and identify any issues. These results are crucial for evaluating the correctness of a function implementation, ensuring that the code behaves as expected and meets the specified requirements."</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="AI PYTHON ASSISTANT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">An AI Python assistant is a system designed to assist with Python programming tasks, including writing and improving code based on feedback and test results</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="FUNCTION IMPLEMENTATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Function implementation is the process of writing the code for a function to perform a specific task</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="TEST CASE GENERATION PROMPT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The Test Case Generation Prompt is a document that instructs the AI coding assistant to write unique, diverse, and intuitive unit tests for functions given the signature and docstring</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="WEBSHOP PROMPTS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">WebShop Prompts are documents that provide instructions for interacting with a webshop, including searching for products and making decisions based on search results</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="ACTING PROMPT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The Acting Prompt is a document that provides instructions for performing actions in a webshop, such as searching for products and selecting items based on criteria</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="WEB SHOP">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">WebShop is an online platform where users can search for and purchase products</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BRIGHT CITRUS DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">Bright Citrus Deodorant by Earth Mama is a natural and safe deodorant specifically designed for sensitive skin, pregnancy, and breastfeeding. It is available in a 3-ounce size and can be purchased through a webshop.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="EARTH MAMA">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Earth Mama is a brand that offers natural and safe products specifically designed for sensitive skin, pregnancy, and breastfeeding. Among their product offerings is the Bright Citrus Deodorant, which exemplifies their commitment to providing gentle and effective solutions for their customers.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="GINGER FRESH DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">Ginger Fresh Deodorant is a product by Earth Mama, described as natural and safe for sensitive skin, and available in a 3-ounce bottle</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BARREL AND OAK">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Barrel and Oak is a brand that produces aluminum-free deodorants for men, including essential oil-based scents</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="CEDAR &amp; PATCHOULI BLEND DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">Cedar &amp; Patchouli Blend Deodorant is a product by Barrel and Oak, described as gentle on sensitive skin and providing 24-hour odor protection</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="MIN SUM">
      <data key="d0">VARIABLE</data>
      <data key="d1">Min sum is a variable used in the code snippet to store the minimum sum found during the iteration</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="CURRENT SUM">
      <data key="d0">VARIABLE</data>
      <data key="d1">Current sum is a variable used in the code snippet to store the sum of the current subarray being evaluated</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="NUMS">
      <data key="d0">VARIABLE</data>
      <data key="d1">Nums is a variable representing the list of numbers being processed in the code snippet</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="ADD FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">The add function is a Python function that takes two integers as input and returns their sum</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="UNIT TEST">
      <data key="d0">DATA</data>
      <data key="d1">Unit test is a type of software testing where individual units or components of a software are tested</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BRIGHT CITRUS">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Bright citrus is a scent attribute of the deodorant products mentioned in the WebShop prompts</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="SENSITIVE SKIN">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Sensitive skin is an attribute describing the type of skin for which the deodorant products are suitable</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="PRICE">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Price is an attribute representing the cost of the deodorant products mentioned in the WebShop prompts</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="3 OUNCE">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">3 ounce is an attribute representing the size of the deodorant products mentioned in the WebShop prompts</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="ENJOY LIFE FOODS">
      <data key="d0">BRAND</data>
      <data key="d1">Enjoy Life Foods is a brand that specializes in producing a wide range of allergen-free food products. Their offerings include soft baked ovals, chewy bars, and lentil chips, all of which are designed to be dairy-free, gluten-free, and vegan. The company is dedicated to providing safe and delicious options for individuals with dietary restrictions, ensuring that their products cater to those who need to avoid common allergens.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS">
      <data key="d0">PRODUCT</data>
      <data key="d1">Dairy Free and Apple Variety Pack of Chips is a product that meets specific dietary requirements, including being dairy-free and available in a variety pack</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="TRAVEL SET (4-PACK)">
      <data key="d0">PRODUCT</data>
      <data key="d1">Travel Set (4-Pack) is a product option for the Bright Citrus Deodorant by Earth Mama, available in a set of four 3-ounce bottles</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="3 OUNCE (PACK OF 1)">
      <data key="d0">PRODUCT</data>
      <data key="d1">3 Ounce (Pack of 1) is a product option for the Bright Citrus Deodorant by Earth Mama, available as a single 3-ounce bottle</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="GINGER FRESH">
      <data key="d0">PRODUCT</data>
      <data key="d1">Ginger Fresh is a scent option for the Bright Citrus Deodorant by Earth Mama</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="CALMING LAVENDER">
      <data key="d0">PRODUCT</data>
      <data key="d1">Calming Lavender is a scent option for the Bright Citrus Deodorant by Earth Mama</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="SIMPLY NON-SCENTS">
      <data key="d0">PRODUCT</data>
      <data key="d1">Simply Non-Scents is a scent option for the Bright Citrus Deodorant by Earth Mama</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE FOODS SOFT BAKED OVALS">
      <data key="d0">PRODUCT</data>
      <data key="d1">Enjoy Life Foods Soft Baked Ovals are breakfast bars that are nut-free, soy-free, dairy-free, non-GMO, gluten-free, and vegan. They are available in a variety pack of 4 boxes, with a total of 20 bars, priced at $100.00.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE SOFT BAKED CHEWY BARS">
      <data key="d0">PRODUCT</data>
      <data key="d1">Enjoy Life Soft Baked Chewy Bars are nut-free, soy-free, dairy-free, gluten-free bars available in a variety pack of 6 boxes, with a total of 30 bars, priced at $21.49.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE LENTIL CHIPS VARIETY PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">The "Enjoy Life Lentil Chips Variety Pack" are dairy-free, soy-free, nut-free, non-GMO, vegan, and gluten-free chips. This variety pack includes 24 bags, each containing 0.8 oz of chips, and is priced at $100.00.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="DILL AND SOUR CREAM">
      <data key="d0">PRODUCT</data>
      <data key="d1">"Dill and Sour Cream is a flavor option for the Enjoy Life Lentil Chips, available as part of the Enjoy Life Lentil Chips Variety Pack."</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="GARLIC &amp; PARMESAN">
      <data key="d0">PRODUCT</data>
      <data key="d1">GARLIC &amp; PARMESAN is a flavor option for the Enjoy Life Lentil Chips, available as part of the Enjoy Life Lentil Chips Variety Pack.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="LIGHT SEA SALT">
      <data key="d0">PRODUCT</data>
      <data key="d1">LIGHT SEA SALT is a flavor option for the Enjoy Life Lentil Chips. It is also available as part of the Enjoy Life Lentil Chips Variety Pack.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="MARGHERITA PIZZA">
      <data key="d0">PRODUCT</data>
      <data key="d1">Margherita Pizza is a flavor option for the Enjoy Life Lentil Chips, specifically available in the Enjoy Life Lentil Chips Variety Pack.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="THAI CHILI LIME">
      <data key="d0">PRODUCT</data>
      <data key="d1">THAI CHILI LIME is a flavor option for the Enjoy Life Lentil Chips, also available in the Enjoy Life Lentil Chips Variety Pack.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="VARIETY PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">The "VARIETY PACK" is an option for the Enjoy Life Lentil Chips that includes multiple flavors in one pack. This allows consumers to enjoy a selection of different tastes within a single purchase, enhancing their snacking experience with a diverse range of flavors.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="0.8 OUNCE (PACK OF 24)">
      <data key="d0">PRODUCT</data>
      <data key="d1">The "0.8 Ounce (Pack of 24)" is a size option for the Enjoy Life Lentil Chips Variety Pack. This option includes 24 individual bags, each containing 0.8 ounces of lentil chips.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="4 OUNCE (PACK OF 12)">
      <data key="d0">PRODUCT</data>
      <data key="d1">4 Ounce (Pack of 12) is a size option for the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ASSORTED SCENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="DAIRY FREE">
      <data key="d0">DIETARY PREFERENCE</data>
      <data key="d1">Dairy free refers to products that do not contain any dairy ingredients</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="APPLE VARIETY PACK OF CHIPS">
      <data key="d0">PRODUCT</data>
      <data key="d1">A variety pack of chips that includes apple-flavored options</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="PRICE LOWER THAN 30.00 DOLLARS">
      <data key="d0">PRICE CONSTRAINT</data>
      <data key="d1">A budget constraint where the price of the desired product should be less than $30.00</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="BUY NOW">
      <data key="d0">ACTION</data>
      <data key="d1">An action to purchase the selected product immediately</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON">
      <data key="d0">PRODUCT</data>
      <data key="d1">A gluten-free, vegetarian product that mimics smoked peppered bacon, available in a 4-ounce pack of 2, with a price constraint of less than $40.00</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SMOKED BACON SEA SALT 3-PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A 3-pack of smoked bacon sea salt flavors including Smoked Bacon Chipotle, Smoked Bacon and Onion, and Smoked Peppered Bacon, all-natural, gluten-free, non-GMO, priced at $29.99</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SPICY HOT PEPPER SEA SALT 3-PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">The "SPICY HOT PEPPER SEA SALT 3-PACK" includes three distinct flavors: Ghost Pepper, Jalapeno, and Habanero. This product is all-natural, gluten-free, kosher, and non-GMO. It is available for purchase at a price of $29.99.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">The "Louisville Vegan Jerky - 5 Flavor Variety Pack" is a product that includes five different flavors of vegan jerky. The flavors in this variety pack are Black Pepper, Buffalo Dill, Pepperoni, Maple Bacon, and Carolina BBQ. Made from non-GMO soy protein and gluten-free, this product is priced at $42.99.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="THINK">
      <data key="d0">ACTION</data>
      <data key="d1">THINK is an action where the user reflects on the suitability of the search results or product options and decides on the next steps. This reflective process involves evaluating the available information to make informed decisions.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="CLICK">
      <data key="d0">ACTION</data>
      <data key="d1">CLICK is an action taken to select a specific product or option, or to navigate to a different page or item.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="PREVIOUS TRIAL INSTRUCTION">
      <data key="d0">ACTION</data>
      <data key="d1">Instructions given for a previous search attempt</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="STATUS: FAIL">
      <data key="d0">OUTCOME</data>
      <data key="d1">"STATUS: FAIL" is an outcome indicating that the user's attempt was unsuccessful.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="NEXT TIME">
      <data key="d0">FUTURE ACTION</data>
      <data key="d1">A plan for future actions to improve the search results</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SEARCH RESULTS">
      <data key="d0">RESULT</data>
      <data key="d1">The list of products returned from a search action</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="PAGE 1">
      <data key="d0">RESULT</data>
      <data key="d1">The first page of search results</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="TOTAL RESULTS: 50">
      <data key="d0">RESULT</data>
      <data key="d1">The total number of search results returned</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="NEXT &gt;">
      <data key="d0">NAVIGATION</data>
      <data key="d1">An option to navigate to the next page of search results</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="PREV">
      <data key="d0">NAVIGATION</data>
      <data key="d1">An option to navigate to the previous page of search results</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="FLAVOR NAME">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">An attribute of the product indicating the available flavors</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="DESCRIPTION">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A section providing details about the product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="FEATURES">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A section highlighting the key features of the product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="REVIEWS">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A section containing customer reviews of the product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="RATING: N.A.">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">An attribute indicating that the product does not have a rating</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SEARCH[DAIRY FREE AND APPLE VARIETY PACK OF CHIPS]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to search for dairy-free and apple variety pack of chips</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SEARCH[GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON 4 OUNCE PACK OF 2]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to search for gluten-free vegetarian smoked peppered bacon in a 4-ounce pack of 2</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SEARCH[&quot;VARIETY PACK OF CHIPS&quot;]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to search for a variety pack of chips</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="THINK[THE FIRST TWO ITEMS ARE NOT WHAT I WANT. THE THIRD ITEM IS THE DAIRY FREE AND APPLE VARIETY PACK OF CHIPS I WANT.]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to reflect on the suitability of the search results, identifying the third item as the desired product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="THINK[THE ITEM HAS OPTIONS &#8216;VARIETY PACK&#8217; AND &#8216;0.8 OUNCE (PACK OF 24)&#8217; AND SEEMS GOOD TO BUY.]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to reflect on the suitability of the product options, deciding that the item seems good to buy</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="THINK[THE FIRST TWO ITEMS ARE NOT WHAT I WANT. THE THIRD ITEM IS NOT WHAT I WANT, BUT IT IS THE CLOSEST ONE.]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to reflect on the suitability of the search results, identifying the third item as the closest match</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="THINK[THE PRICE IS TOO HIGH AND IT IS NOT WHAT I WANT.]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to reflect on the suitability of the product, deciding that the price is too high and it is not what is wanted</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="CLICK[B008D2X8C4]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to select the product with the identifier B008D2X8C4</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="CLICK[B07GJTKYJQ]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to select the product with the identifier B07GJTKYJQ</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="CLICK[&lt;PREV]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to navigate to the previous page of search results</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="CLICK[VARIETY PACK]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to select the variety pack option for a product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="CLICK[0.8 OUNCE (PACK OF 24)]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to select the 0.8 ounce (pack of 24) option for a product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="CLICK[BUY NOW]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to purchase the selected product immediately</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="OBSERVATION[OK.]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to note the results or feedback from a previous action, indicating that the action was acknowledged</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="OBSERVATION[BACK TO SEARCH]">
      <data key="d0">ACTION</data>
      <data key="d1">An action to note the navigation back to the search page</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="OBSERVATION[PAGE 1 (TOTAL RESULTS: 50)]">
      <data key="d0">RESULT</data>
      <data key="d1">An observation indicating that the search results are displayed on page 1 with a total of 50 results</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="OBSERVATION[&lt;PREV] LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK, NON-GMO SOY PROTEIN, GLUTEN-FREE (BLACK PEPPER, BUFFALO DILL, PEPPERONI, MAPLE BACON, AND CAROLINA BBQ, 3 OUNCES) PRICE: $42.99 RATING: N.A. [DESCRIPTION] [FEATURES] [REVIEWS] [BUY NOW]">
      <data key="d0">RESULT</data>
      <data key="d1">An observation noting the details of the Louisville Vegan Jerky 5 Flavor Variety Pack</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="OBSERVATION[&lt;PREV] SMOKED BACON SEA SALT 3-PACK: SMOKED BACON CHIPOTLE, SMOKED BACON AND ONION, SMOKED PEPPERED BACON - ALL-NATURAL SEA SALTS SLOWLY SMOKED OVER ALDERWOOD - NO GLUTEN, NO MSG, NON-GMO (12 TOTAL OZ.) 29.99 [B06Y96N1KG] SPICY HOT PEPPER SEA SALT 3-PACK: GHOST PEPPER, JALAPENO, HABANERO - ALL NATURAL, DELICIOUS BLENDS OF PEPPERS &amp; SEA SALT - GLUTEN-FREE, KOSHER, NO MSG, NON-GMO (12 TOTAL OZ.) 29.99 [B07GJTKYJQ] LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK,">
      <data key="d0">RESULT</data>
      <data key="d1">An observation noting the details of the Smoked Bacon Sea Salt 3-Pack and Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="OBSERVATION[BACK TO SEARCH] PAGE 1 (TOTAL RESULTS: 50) [NEXT &gt;] [B07HRFJWP8] ENJOY LIFE FOODS SOFT BAKED OVALS, BREAKFAST BARS, NUT FREE BARS, SOY FREE, DAIRY FREE, NON GMO, GLUTEN FREE, VEGAN, VARIETY PACK, 4 BOXES(20 BARS TOTAL) $100.0 [B01KMHY5PG] ENJOY LIFE SOFT BAKED CHEWY BARS, VARIETY PACK, NUT FREE BARS, SOY FREE, DAIRY FREE, GLUTEN FREE, 6 BOXES (30 TOTAL BARS) $21.49 [B008D2X8C4] ENJOY LIFE LENTIL CHIPS VARIETY PACK, DAIRY FREE CHIPS, SOY FREE, NUT FREE, NON GMO, VEGAN, GLUTEN FREE, 24 BAGS (0.8 OZ) $100.0">
      <data key="d0">RESULT</data>
      <data key="d1">An observation noting the details of the Enjoy Life Foods Soft Baked Ovals, Enjoy Life Soft Baked Chewy Bars, and Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="OBSERVATION[BACK TO SEARCH] [&lt;PREV] FLAVOR NAME [DILL AND SOUR CREAM][GARLIC &amp; PARMESAN][LIGHT SEA SALT][MARGHERITA PIZZA][THAI CHILI LIME][VARIETY PACK] SIZE [0.8 OUNCE (PACK OF 24)][4 OUNCE (PACK OF 12)] PRICE: $100.0 RATING: N.A. [DESCRIPTION] [FEATURES] [REVIEWS] [BUY NOW]">
      <data key="d0">RESULT</data>
      <data key="d1">An observation noting the details of the Enjoy Life Lentil Chips Variety Pack, including flavor options, size options, price, and rating</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="OBSERVATION[BACK TO SEARCH] PAGE 1 (TOTAL RESULTS: 50) [NEXT &gt;] [B06Y96MXJV] SMOKED BACON SEA SALT 3-PACK: SMOKED BACON CHIPOTLE, SMOKED BACON AND ONION, SMOKED PEPPERED BACON - ALL-NATURAL SEA SALTS SLOWLY SMOKED OVER ALDERWOOD - NO GLUTEN, NO MSG, NON-GMO (12 TOTAL OZ.) $29.99 [B06Y96N1KG] SPICY HOT PEPPER SEA SALT 3-PACK: GHOST PEPPER, JALAPENO, HABANERO - ALL NATURAL, DELICIOUS BLENDS OF PEPPERS &amp; SEA SALT - GLUTEN-FREE, KOSHER, NO MSG, NON-GMO (12 TOTAL OZ.) $29.99 [B07GJTKYJQ] LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK, NON-GMO SOY PROTEIN, GLUTEN-FREE (BLACK PEPPER, BUFFALO DILL, PEPPERONI, MAPLE BACON, AND CAROLINA BBQ, 3 OUNCES) $42.99">
      <data key="d0">RESULT</data>
      <data key="d1">An observation noting the details of the Smoked Bacon Sea Salt 3-Pack, Spicy Hot Pepper Sea Salt 3-Pack, and Louisville Vegan Jerky 5 Flavor Variety Pack</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="OBSERVATION[BACK TO SEARCH] [&lt;PREV] LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK, NON-GMO SOY PROTEIN, GLUTEN-FREE (BLACK PEPPER, BUFFALO DILL, PEPPERONI, MAPLE BACON, AND CAROLINA BBQ, 3 OUNCES) PRICE: $42.99 RATING: N.A. [DESCRIPTION] [FEATURES] [REVIEWS] [BUY NOW]">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="NON-GMO">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Non-GMO refers to products that are not genetically modified</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="GHOST PEPPER">
      <data key="d0">INGREDIENT</data>
      <data key="d1">Ghost Pepper is one of the flavors included in the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="JALAPENO">
      <data key="d0">INGREDIENT</data>
      <data key="d1">Jalapeno is one of the flavors included in the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="HABANERO">
      <data key="d0">INGREDIENT</data>
      <data key="d1">Habanero is one of the flavors included in the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="LOUISVILLE VEGAN JERKY">
      <data key="d0">PRODUCT</data>
      <data key="d1">Louisville Vegan Jerky is a 5-flavor variety pack of vegan jerky that is non-GMO, soy protein-based, and gluten-free. The flavors include Black Pepper, Buffalo Dill, Pepperoni, Maple Bacon, and Carolina BBQ</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="BLACK PEPPER">
      <data key="d0">FLAVOR</data>
      <data key="d1">Black Pepper is one of the flavors included in the Louisville Vegan Jerky variety pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="BUFFALO DILL">
      <data key="d0">FLAVOR</data>
      <data key="d1">Buffalo Dill is one of the flavors included in the Louisville Vegan Jerky variety pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="PEPPERONI">
      <data key="d0">FLAVOR</data>
      <data key="d1">Pepperoni is one of the flavors included in the Louisville Vegan Jerky variety pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="MAPLE BACON">
      <data key="d0">FLAVOR</data>
      <data key="d1">Maple Bacon is one of the flavors included in the Louisville Vegan Jerky variety pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="CAROLINA BBQ">
      <data key="d0">FLAVOR</data>
      <data key="d1">Carolina BBQ is one of the flavors included in the Louisville Vegan Jerky variety pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="REFINE SEARCH">
      <data key="d0">ACTION</data>
      <data key="d1">Refine Search is an action taken to narrow down search results to find more relevant products</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="VEGETARIAN BACON">
      <data key="d0">PRODUCT</data>
      <data key="d1">Vegetarian Bacon is a product that the user intends to search for in the next attempt</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="GLUTEN-FREE">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Gluten-Free refers to products that do not contain gluten</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="4 OUNCE PACK OF 2">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">4 Ounce Pack of 2 refers to the packaging size and quantity constraint for the product the user is searching for</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="B07GJTKYJQ">
      <data key="d0">PRODUCT CODE</data>
      <data key="d1">B07GJTKYJQ is the product code for the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="12 TOTAL OZ.">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">12 total oz. refers to the total weight of the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="29.99">
      <data key="d0">PRICE</data>
      <data key="d1">29.99 is the price of the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="NON-GMO SOY PROTEIN">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Non-GMO Soy Protein is an attribute of the Louisville Vegan Jerky - 5 Flavor Variety Pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="42.99">
      <data key="d0">PRICE</data>
      <data key="d1">42.99 is the price of the Louisville Vegan Jerky - 5 Flavor Variety Pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="3 OUNCES">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">3 ounces refers to the weight of each pack in the Louisville Vegan Jerky - 5 Flavor Variety Pack</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="CLICK[NEXT &gt;]">
      <data key="d0">ACTION</data>
      <data key="d1">Click[Next &gt;] is an action where the user attempts to navigate to the next page of search results</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="CLICK[ &lt;BACK TO SEARCH]">
      <data key="d0">ACTION</data>
      <data key="d1">Click[ &lt;Back to Search] is an action where the user attempts to return to the search page</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="PREVIOUS TRIAL">
      <data key="d0">EVENT</data>
      <data key="d1">Previous trial refers to the user's earlier attempt at searching for products</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="KOSHER">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="NO MSG">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="B06Y96N1KG">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="RESULT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="EVENT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="SHENGRAN HU">
      <data key="d0">PERSON</data>
      <data key="d1">Shengran Hu is a prominent researcher affiliated with the University of British Columbia and the Vector Institute. Hu has made significant contributions to the field of Artificial Intelligence and Machine Learning, particularly through the ADAS project. Hu has ensured that all code, prompts, and experiment results from this project are accessible on GitHub, including detailed implementations of all baselines and discovered agents. Hu is also associated with the GitHub repository where all agents from the experiment can be found.

In 2024, Shengran Hu co-authored several influential papers, including "Intelligent go-explore: Standing on the shoulders of giant foundation models," published on arXiv, and "Thought Cloning: Learning to think while acting by imitating human thinking," published in Advances in Neural Information Processing Systems. Additionally, Hu is the corresponding author of the paper "Automated Design of Agentic Systems." Hu's commitment to open science is evident through the availability of the full framework code on GitHub, facilitating further research and collaboration in the AI and ML communities.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,24d7b89ae9522ae60d2317984951355b,449db721e37968e073e3579b59e023b2,6109537356a2ce2339f77c827aa3668e,97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CONG LU">
      <data key="d0">PERSON</data>
      <data key="d1">Cong Lu is a researcher affiliated with the University of British Columbia and the Vector Institute. Cong Lu has contributed to several significant publications in the field of Artificial Intelligence and Machine Learning. Notably, Cong Lu is one of the authors of the paper titled "Automated Design of Agentic Systems." Additionally, Cong Lu co-authored the paper "Intelligent go-explore: Standing on the shoulders of giant foundation models," which was published on arXiv in 2024. Another notable work by Cong Lu is the paper "Varibad: Variational bayes-adaptive deep RL via meta-learning," published in the Journal of Machine Learning Research in 2021. These contributions highlight Cong Lu's active involvement in advancing research in AI and ML.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The University of British Columbia is an academic institution where some of the authors of the paper "Automated Design of Agentic Systems" are affiliated</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VECTOR INSTITUTE">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The Vector Institute is an organization where some of the authors of the paper "Automated Design of Agentic Systems" are affiliated. Additionally, the Vector Institute is one of the organizations that supported the work on this paper, highlighting its role in advancing research in the field of Artificial Intelligence and Machine Learning.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CANADA CIFAR AI CHAIR">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The Canada CIFAR AI Chair is an organization where one of the authors of the paper "Automated Design of Agentic Systems" is affiliated</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d0">RESEARCH AREA</data>
      <data key="d1">Automated Design of Agentic Systems (ADAS) is a new research area that aims to automatically create powerful agentic system designs, including inventing novel building blocks and/or combining them in new ways</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="FOUNDATION MODELS (FMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundation Models (FMs) are models queried by the meta agent to perform tasks and format prompts. They are used as modules in the control flow of agentic systems to solve tasks by planning, using tools, and carrying out multiple, iterative steps of processing. Foundation Models (FMs) such as GPT and Claude are powerful general-purpose agents employed for agentic tasks that require flexible reasoning and planning.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,4884e8429ca1e567dadf5e22b4b68274,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CLAUDE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Claude is a Foundation Model developed by Anthropic, mentioned as a powerful general-purpose agent in the text</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CHAIN-OF-THOUGHT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Chain-of-Thought (COT) is a manually designed agent technique referenced by Wei et al., 2022, that instructs the agent to output the reasoning before answering to improve complex problem-solving through intermediate steps. It is a state-of-the-art method used for comparison in various studies and serves as a baseline for evaluating other techniques. COT is employed in tasks such as Math, Reading Comprehension, Multi-task, and Science, and is integral to planning and reasoning within agentic systems. The process is handled by the FM_Module, which involves generating a thought process and an answer. Additionally, COT is a strategy used in Meta Agent Search to generate possible answers, refine them, and ensemble the best answers, leveraging step-by-step reasoning to solve tasks effectively.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,4b43decac6833d1515992f8869ecada7,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TOOLFORMER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Toolformer is a module used within agentic systems to enhance their capabilities. It is described in a paper titled "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023. This system exemplifies how language models can autonomously learn to utilize various tools, thereby significantly improving their functionality and performance in complex tasks.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HOG">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">HOG (Histogram of Oriented Gradients) is a hand-designed feature used in computer vision, eventually replaced by learned features from Convolutional Neural Networks</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CONVOLUTIONAL NEURAL NETWORKS (CNNS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Convolutional Neural Networks (CNNs) are a type of neural network used in computer vision, which replaced hand-designed features like HOG</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="NEURAL ARCHITECTURE SEARCH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Neural Architecture Search (NAS) is a process of automating the design of artificial neural networks. It is a research area within AutoML that focuses on creating optimal neural network architectures without human intervention. This method aims to design neural network architectures, such as convolutional neural networks (CNNs), that achieve the best performance. NAS involves observing the emerged architectures to gain deeper insights into neural networks. The concept and methodologies of NAS have been discussed extensively in the literature, including a notable paper authored by Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter, published in the Journal of Machine Learning Research in 2019, and further explored by Shen et al. in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AUTOML">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AutoML (Automated Machine Learning) is a research area focused on automating the end-to-end process of applying machine learning to real-world problems. This includes the design of neural network architectures and learning algorithms. The field aims to simplify and streamline the application of machine learning, making it more accessible and efficient. AutoML methods have been discussed extensively, including by Hutter et al. in 2019, highlighting its significance in advancing the capabilities and reach of machine learning technologies.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AI-Generating Algorithms (AI-GAs) are methods that demonstrate the superiority of learned AI systems compared to hand-designed AI systems</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="MULTI-STEP PEER REVIEW AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Multi-Step Peer Review Agent is an agent discovered by the Meta Agent Search algorithm, specifically within the Reading Comprehension domain (GPQA). It is designed to review and verify answers, exemplifying the capabilities of the Meta Agent Search in identifying effective agents for complex tasks.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="VERIFIED MULTIMODAL AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Verified Multimodal Agent is an agent discovered during the search in the Math domain (MGSM) by Meta Agent Search. It utilizes visual representation, verification, and Chain-of-Thought modules to solve problems. This agent is an example of the capabilities of the Meta Agent Search algorithm, specifically designed to handle tasks involving multiple modalities.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059,ef75d2c866bee783577ed9f65707cf13</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DIVIDE AND CONQUER AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Divide and Conquer Agent is an agent discovered by the Meta Agent Search algorithm, specifically in the Reading Comprehension domain (GPQA). It is designed to divide tasks into sub-problems and solve them efficiently.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ANTHROPIC">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Anthropic is an organization known for its contributions to the development of advanced AI models. They have published blog posts about the next generation of Claude, including Claude 3.5 Sonnet. Additionally, Anthropic is the organization behind the development of the Claude Foundation Model, showcasing their expertise and leadership in the field of artificial intelligence.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="ROCKT&#196;SCHEL">
      <data key="d0">PERSON</data>
      <data key="d1">Rockt&#228;schel is an author mentioned in the text, contributing to the development of agentic systems</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZAHARIA">
      <data key="d0">PERSON</data>
      <data key="d1">Zaharia is an author mentioned in the text, contributing to the development of agentic systems</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HU">
      <data key="d0">PERSON</data>
      <data key="d1">Hu is an author mentioned in the text, contributing significantly to the development of chain-of-thought planning and reasoning methods. Hu's work is particularly noted in the context of research in Neural Architecture Search, with notable contributions referenced in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CLUNE">
      <data key="d0">PERSON</data>
      <data key="d1">Clune is an author mentioned in the text who has made significant contributions to the research areas of AI-Generating Algorithms (AI-GAs), AutoML, and chain-of-thought-based planning and reasoning methods. Notably, Clune discussed the potential of AI-GAs to accelerate the creation of Artificial General Intelligence (AGI) in 2019. Clune's work spans from the development of AI-GAs to advancements in planning and reasoning techniques, highlighting their influence in the field of AI research.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DALAL">
      <data key="d0">PERSON</data>
      <data key="d1">Dalal is an author mentioned in the text, contributing to the development of HOG features in computer vision</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TRIGGS">
      <data key="d0">PERSON</data>
      <data key="d1">Triggs is an author mentioned in the text, contributing to the development of HOG features in computer vision</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KRIZHEVSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Krizhevsky is an influential author in the field of Artificial Intelligence and Machine Learning, particularly known for his significant contributions to the development and popularization of Convolutional Neural Networks (CNNs). His work gained widespread recognition in 2012, marking a pivotal moment in the advancement of CNNs.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HUTTER">
      <data key="d0">PERSON</data>
      <data key="d1">Hutter is an author mentioned in the text who has significantly contributed to the research and development of AutoML methods. Notably, Hutter discussed AutoML methods in 2019, highlighting their expertise and influence in this area of study.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GITHUB">
      <data key="d0">WEBSITE</data>
      <data key="d1">GitHub is the platform where the code for the Automated Design of Agentic Systems (ADAS) can be found. It hosts the full framework code for the project, including all code, prompts, and experiment results related to the ADAS project. Additionally, the repository containing all agents from the experiment is available on GitHub.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,449db721e37968e073e3579b59e023b2,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937</data>
      <data key="d3">WEBSITE</data>
    </node>
    <node id="MEMORY STRUCTURES">
      <data key="d0" />
      <data key="d1">Memory Structures are components used in agentic systems to store and retrieve information</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TOOL USE">
      <data key="d0" />
      <data key="d1">Tool Use is a technique in agentic systems that involves the manipulation and employment of external tools such as search engines, code execution, and database queries to achieve goals and solve complex tasks. It is an important building block for agentic systems, referenced by Nakano et al., 2021; Qu et al., 2024; and Schick et al., 2023. Tool Use encompasses the ability of an AI system to interact with external tools or services via APIs, employing functions or APIs to perform tasks or solve problems. This skill is also covered in the synthetic post-training dataset created by AgentInstruct.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c212c1467564ad33330b1f655a8e27e,427e98b00e49b6a8f8649054122dd45b,b88745a13b69cecbc0ee9c3af41389bf,c3d0436082aada237ee4bee645f16059,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="META AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">META AGENT is an advanced system designed to generate code solutions for the ARC challenge rather than directly outputting answers. It operates by iteratively programming new agents, testing their performance, and adding them to an archive of discovered agents. Utilizing the GPT-4o-2024-05-13 model, META AGENT employs various benchmarks and baselines to discover optimal agents for different tasks. This system follows specific prompts and instructions to generate and improve code, making it a robust tool for enhancing agent performance in diverse experimental settings.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,282313a8340c6792e8c35f53ed157cd0,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AGENT ARCHIVE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Agent Archive is a repository where discovered agents are stored and used to inform the meta agent in subsequent iterations</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CNN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Convolutional Neural Networks (CNNs) are a class of deep neural networks, most commonly applied to analyzing visual imagery. They were popularized by Krizhevsky et al. in 2012</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="AI-GAS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AI-GAs (Artificial Intelligence-Generative Algorithms) is a research area focused on the automated design and optimization of algorithms. AI-GAs, also known as AI-generating algorithms, represent an alternate paradigm for producing general artificial intelligence. This concept was described in a paper authored by Jeff Clune and published on arXiv in 2019. AI-Generating Algorithms (AI-GAs) are designed to generate AI systems, as discussed by Clune in his 2019 publication.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="LLM ALIGNMENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM alignment refers to the process of aligning large language models with desired outcomes, including the use of learned loss functions as discussed by Lu et al. in 2024a</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DPO">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">DPO refers to a hand-designed loss function used in LLM alignment, as discussed by Rafailov et al. in 2024</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="AI SCIENTIST">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The AI Scientist is an automated research pipeline that includes the development of novel machine learning algorithms, as discussed by Lu et al. in 2024b</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="OMNI-EPIC">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">OMNI-EPIC is a method and system that enables Foundation Models (FMs) to create robotics learning environments by programming in code. It is designed to automatically generate these environments, demonstrating both creativity and efficiency. This innovative approach leverages models of human notions of interestingness to foster open-endedness in the generated environments. The concept and implementation of OMNI-EPIC were detailed in a paper authored by Maxence Faldor, Jenny Zhang, Antoine Cully, and Jeff Clune, and published on arXiv in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ADAS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ADAS (Automated Design of Agentic Systems) is a proposed research area in AI-GA (Artificial Intelligence-Generative Algorithms) that focuses on the automated invention of novel building blocks and the design of powerful agentic systems. This innovative field aims to progressively discover agents that outperform state-of-the-art hand-designed baselines by leveraging the innovation and combination of various stepping stones. ADAS showcases the potential to program powerful algorithms without the need for expensive hardware like GPUs. The project encompasses the Meta Agent Search algorithm and related experiments, with all agents from these experiments available in the ADAS GitHub repository. The framework code for ADAS is also provided, facilitating further research and development in this promising area.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,449db721e37968e073e3579b59e023b2,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b,d66dc9ce4a9545b44f7486ea057b5937,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ARC">
      <data key="d0">TASK</data>
      <data key="d1">ARC (Abstraction and Reasoning Corpus) is a multifaceted challenge and dataset designed to evaluate the general intelligence and reasoning capabilities of AI systems. Developed by AllenAI, it serves as a benchmark to measure the performance of various models, including state-of-the-art hand-designed agent baselines like Orca-3. The challenge involves learning transformation rules from input-output grid examples to predict the final answer for a test grid, making it a complex logic puzzle task. It is used in experiments to test the proficiency of agents in in-context learning, search and evaluation algorithms, and the performance of agents discovered by Meta Agent Search. The ARC is also known as the AI2 Reasoning Challenge, which focuses on assessing reasoning, commonsense knowledge, and deep comprehension abilities of language models, as highlighted by Chollet in 2019.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2,4b43decac6833d1515992f8869ecada7,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635,ef75d2c866bee783577ed9f65707cf13</data>
      <data key="d3">TASK</data>
    </node>
    <node id="DROP">
      <data key="d0">TASK</data>
      <data key="d1">DROP (Discrete Reasoning Over Paragraphs) is a Reading Comprehension Benchmark introduced by Dua et al. in 2019. It is designed to assess the ability of models to perform discrete reasoning and comprehend detailed information across multiple paragraphs. DROP evaluates the performance of various models, including Orca-3 and other baselines, by requiring them to generate correct answers for given problems. The benchmark involves resolving references in questions and performing discrete operations such as sorting and counting. It is used in experiments to measure F1 scores and evaluate the reasoning and problem-solving capabilities of discovered agents through one-shot style questions.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,103d98395c393552cc954c89d4e59f50,10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,84317ae35cc75d612287186d93461447,86f77e15d41cbd0cb33f635ccb2cb66b,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">TASK</data>
    </node>
    <node id="MGSM">
      <data key="d0">TASK</data>
      <data key="d1">MGSM (Multilingual Grade School Math Benchmark) is a comprehensive benchmark used to evaluate the mathematical problem-solving abilities of agents across various languages, ensuring broad and effective multilingual performance. It serves as a model to assess the performance of agents in the Math domain, as well as a dataset used to test agents discovered by Meta Agent Search. Introduced by Shi et al. in 2023, MGSM measures accuracy rates in mathematical tasks and is utilized in experiments to evaluate the performance of discovered agents. This benchmark plays a crucial role in understanding and improving the capabilities of agents in multilingual mathematical contexts.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
      <data key="d3">TASK</data>
    </node>
    <node id="GSM8K">
      <data key="d0">TASK</data>
      <data key="d1">GSM8K, or Grade School Math 8K, is a benchmark dataset used to evaluate the performance of AI and language models on math problems. It consists of high-quality, diverse grade school math word problems that require between 2 and 8 steps to solve. This dataset is referenced by Cobbe et al., 2021, and is used to measure the accuracy rates of models in generating correct answers to math-based questions. GSM8K is particularly noted for its role in evaluating the transferability of discovered agents, as seen in experiments involving Meta Agent Search. Notably, the Orca-3 model demonstrated a 54% improvement over the Mistral-7b-Instruct model on this benchmark, highlighting its effectiveness in solving complex math tasks.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,103d98395c393552cc954c89d4e59f50,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">TASK</data>
    </node>
    <node id="GSM-HARD">
      <data key="d0">TASK</data>
      <data key="d1">GSM-Hard is a dataset referenced by Gao et al. in 2023. It is a held-out math task used in experiments to evaluate the transferability of agents discovered by Meta Agent Search. The dataset is specifically designed to test the accuracy rates of these agents within the math domain.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">TASK</data>
    </node>
    <node id="PYTHON">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Python is a programming language that is Turing Complete, enabling the search within a code space for ADAS algorithms, as discussed by Boyer &amp; Moore in 1983 and Ladha in 2024</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="FM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundation Models (FMs) are large-scale models proficient in coding, used as meta agents to create new agents in code for ADAS</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ELSKEN">
      <data key="d0">PERSON</data>
      <data key="d1">Elsken is an author who has made significant contributions to the research area of Neural Architecture Search (NAS). Notably, Elsken discussed Neural Architecture Search in 2019, highlighting their involvement and influence in this specialized field of study.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LU">
      <data key="d0">PERSON</data>
      <data key="d1">Lu is an author who has made significant contributions to the field of Artificial Intelligence and Machine Learning. Lu is associated with the Quality-Diversity state-of-the-art hand-designed agent and has extensively worked on Quality-Diversity techniques. In 2024, Lu discussed various topics including learned loss functions in LLM alignment (2024a), the role of AI Scientists (2024b), and open-endedness algorithms (2024c). Additionally, Lu has contributed to research in Neural Architecture Search and has explored open-endedness algorithms that leverage human notions of interestingness.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RAFAILOV">
      <data key="d0">PERSON</data>
      <data key="d1">Rafailov is an author who has made significant contributions to the field of Artificial Intelligence and Machine Learning in 2024. He has discussed DPO, a hand-designed loss function, and has also worked on FM alignment training. His work reflects a deep understanding of complex AI concepts and showcases his ability to innovate within the community.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHOLLET">
      <data key="d0">PERSON</data>
      <data key="d1">Chollet is an author who discussed the ARC logic puzzle task in 2019</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DUA">
      <data key="d0">PERSON</data>
      <data key="d1">DUA is an author associated with the DROP benchmark for evaluating Reading Comprehension. In 2019, Dua discussed the DROP reading comprehension task, contributing to the understanding and assessment of reading comprehension capabilities in AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="COBBE">
      <data key="d0">PERSON</data>
      <data key="d1">Cobbe is an author referenced in the text, associated with the GSM8K dataset in 2021. Cobbe discussed the GSM8K math task in the same year, highlighting their involvement in the development and analysis of this dataset.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BOYER">
      <data key="d0">PERSON</data>
      <data key="d1">Boyer is an author who discussed the Turing Completeness of Python in 1983</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MOORE">
      <data key="d0">PERSON</data>
      <data key="d1">Moore is an author who discussed the Turing Completeness of Python in 1983</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LADHA">
      <data key="d0">PERSON</data>
      <data key="d1">Ladha is an author who discussed the Turing Completeness of Python in 2024</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FERNANDO">
      <data key="d0">PERSON</data>
      <data key="d1">Fernando is an author mentioned in the text who has made significant contributions to the research area of agentic systems. In 2024, Fernando focused on designing prompts within ADAS methods and worked on a project called PromptBreeder.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OPEN-ENDEDNESS ALGORITHMS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="FOUNDATION MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundation Models (FMs) are large-scale models utilized in various AI-GA (Artificial Intelligence-Generative Algorithms) and AutoML (Automated Machine Learning) projects. They are instrumental in writing code, discovering optimization algorithms, and creating learning environments. Additionally, FMs serve as modules within the control flow of agentic systems, enabling these systems to solve tasks through planning, tool usage, and executing multiple, iterative steps of processing.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="PROMPTBREEDER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">PromptBreeder is a system designed to automate prompt engineering for agents by adopting foundational models (FMs) to enhance the phrasing of instructions, thereby improving reasoning capabilities. It focuses on mutating only the text prompts of an agent, while maintaining other components such as control flow unchanged. This method, known as self-referential self-improvement via prompt evolution, was detailed in a paper authored by Chrisantha Fernando, Dylan Sunil Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt&#228;schel, and published in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="CHRISTOPHER CHASE">
      <data key="d0">PERSON</data>
      <data key="d1">Christopher Chase is an author mentioned in the text who has contributed to the research area of agentic systems</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="NG">
      <data key="d0">PERSON</data>
      <data key="d1">Ng is an author mentioned in the text who has contributed to the research area of agentic systems</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhu is an author mentioned in the text who has contributed to the research area of agentic systems</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="SUTTON">
      <data key="d0">PERSON</data>
      <data key="d1">Sutton is an author mentioned in the text who has contributed to the research area of reinforcement learning.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="BARTO">
      <data key="d0">PERSON</data>
      <data key="d1">Barto is an author mentioned in the text who has contributed to the research area of reinforcement learning.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="AGENTIC SYSTEMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Agentic Systems are powerful, automated systems designed to perform tasks autonomously, as proposed in the ADAS research area. These systems operate primarily over natural language and are interpretable to humans. They involve Foundation Models (FMs) as modules in the control flow to solve tasks by planning, using tools, and carrying out multiple, iterative steps of processing.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="GRAPH STRUCTURES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Graph structures are used as a search space in ADAS to represent agentic systems</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="FEED-FORWARD NETWORKS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Feed-forward networks are used as a search space in ADAS to represent agentic systems</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="SEARCH ENGINE TOOLS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">SEARCH ENGINE TOOLS are building blocks used in agentic systems within the LangChain framework. Additionally, they are mentioned as potential building blocks for Advanced Driver Assistance Systems (ADAS). These tools play a crucial role in enhancing the functionality and efficiency of both LangChain and ADAS by providing essential search capabilities.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="FERNANDO ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Fernando et al. are authors who have contributed to the research area of agentic systems</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="ZHUGE ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuge et al. are authors who have contributed to the research area of agentic systems</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="LIU ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Liu et al. are authors who have made significant contributions to research in the areas of EoH (Evolution of Humanity) and agentic systems. Their work spans across these domains, indicating a broad and impactful engagement with complex systems and the dynamics of human and artificial agents.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="SUTTON &amp; BARTO">
      <data key="d0">PERSON</data>
      <data key="d1">Sutton &amp; Barto are authors who have contributed to the research area of reinforcement learning</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="LANGCHAINAI">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">LangChainAI is the organization behind the LangChain framework, an open-source agent framework designed for building context-aware reasoning applications. Developed and published on GitHub in 2022, LangChain provides tools and resources to facilitate the creation of sophisticated AI-driven solutions.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6109537356a2ce2339f77c827aa3668e,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="SECTION 6">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Section 6 is a part of the document that encourages further studies and opens up new research directions</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="FIGURE 2">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Figure 2 is a part of the document that illustrates the three key components of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="FMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundation Models (FMs) are advanced models whose knowledge is utilized to address complex questions in the Science and Multi-task domains. They serve as meta agents in the Meta Agent Search algorithm, iteratively programming new agents. FMs are also employed to program the loss function for preference learning in FM alignment training. Their application spans various domains, and improvements in these models are anticipated to significantly enhance the performance of agentic systems.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,6bdf681c0bd9e401ac72344a6a0ae479,bc26e68b0b2783ba912b9e5606d9eb0b,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FUNSEARCH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">FUNSEARCH is a method where Foundation Models write code to discover better optimization algorithms. Additionally, FunSearch is a practice referenced in the Meta Agent Search algorithm, where a "forward" function is programmed to define a new agentic system.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="ROMERA-PAREDES">
      <data key="d0">PERSON</data>
      <data key="d1">Romera-Paredes is an author who has contributed to research in FunSearch and has worked on the FunSearch practice mentioned in the Meta Agent Search algorithm.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="PROGRAMMING LANGUAGES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Programming languages are suggested as a search space in ADAS for defining and searching for agents</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="CODE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">CODE is a variable used in the code to store the actual code solution being evaluated. It is also the process of writing the solution as part of the initial candidate solutions. Additionally, CODE is utilized in the Meta Agent Search algorithm to define new agentic systems.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="QUERY APIS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Query APIs are basic functions provided to the meta agent in the Meta Agent Search algorithm</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="VALIDATION DATA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Validation data from the target domain is used to evaluate the performance of generated agents in the Meta Agent Search algorithm</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="PERFORMANCE METRICS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Performance metrics like success rate or F1 score are calculated to evaluate the performance of generated agents in the Meta Agent Search algorithm</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="BOOTSTRAP CONFIDENCE INTERVAL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Bootstrap Confidence Interval is a statistical method utilized to report the test accuracy of agents across multiple domains. Additionally, it serves as a crucial metric for the meta agent to maximize within the Meta Agent Search algorithm. This dual application underscores its importance in both evaluating performance and guiding optimization in complex AI and ML systems.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="ARC LOGIC PUZZLE TASK">
      <data key="d0">TASK</data>
      <data key="d1">ARC logic puzzle task is a challenging task used in experiments to evaluate the performance of discovered agents</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="READING COMPREHENSION">
      <data key="d0">TASK</data>
      <data key="d1">Reading Comprehension is a critical skill involving the ability to understand, process, and interpret written text. It is necessary for learning and encompasses decoding, fluency, and vocabulary knowledge. In the domain of artificial intelligence, reading comprehension is a benchmark used to assess and evaluate the performance of agents in experiments. This domain tests the agents' abilities to process and understand text, making it an essential area for evaluating AI capabilities.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SCIENCE QUESTIONS">
      <data key="d0">TASK</data>
      <data key="d1">Science questions are one of the benchmarks used to assess the agent's abilities in experiments</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="MULTI-TASK PROBLEM SOLVING">
      <data key="d0">TASK</data>
      <data key="d1">Multi-task problem solving is one of the benchmarks used to assess the agent's abilities in experiments</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="TRANSFERABILITY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Transferability is assessed in experiments to evaluate how well discovered agents perform on different tasks and models</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="F1 SCORE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The F1 Score is a performance metric used to evaluate the effectiveness of agents in various domains, including Reading Comprehension and Math. Additionally, it is employed to assess the performance of generated agents within the Meta Agent Search algorithm. This metric is crucial for understanding how well these agents perform in their respective tasks, providing a balanced measure that considers both precision and recall.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ACCURACY RATE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Accuracy Rate is a performance metric used to evaluate the effectiveness of agents in various domains, including Reading Comprehension and Math. Additionally, it is employed to assess the performance of generated agents within the Meta Agent Search algorithm. This metric is crucial for determining how well agents perform their designated tasks, providing insights into their efficiency and reliability across different applications.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="HUMAN-LIKE CRITIC">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Human-like critic is a component used in Meta Agent Search for providing feedback on generated agents</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="FEEDBACK">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">FEEDBACK is a multifaceted variable used in various contexts within the code and AI systems. It serves as a storage mechanism for feedback on code solutions, provided by human-like critics in Meta Agent Search to refine generated agents. Additionally, feedback involves the process of evaluating generated code by running examples and obtaining responses. It also includes the response provided by the Verification Module regarding the accuracy and relevance of visual representations. Furthermore, feedback is an essential component of the Critic module, which plays a crucial role in assessing and improving the performance of generated agents.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,449db721e37968e073e3579b59e023b2,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="EFFICIENCY EXPERT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Efficiency Expert is a type of expert used in the best agent in Meta Agent Search to evaluate efficiency. It serves as a crucial component in Meta Agent Search, providing feedback on the efficiency of generated agents. This role is essential for optimizing the performance and effectiveness of agents within the Meta Agent Search framework.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="READABILITY EXPERT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">READABILITY EXPERT is a type of expert utilized in the best agent in Meta Agent Search to evaluate readability. This component is specifically designed to provide feedback on the readability of generated agents, ensuring that the output is clear and comprehensible.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="SIMPLICITY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Simplicity is a component used in Meta Agent Search for providing feedback on the simplicity of generated agents</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="ARC CHALLENGE">
      <data key="d0">EVENT</data>
      <data key="d1">The ARC CHALLENGE is a challenge where the AI system is asked to learn transformation rules from input-output grid examples and apply these rules to predict the final answer for a test grid. The ARC (Abstraction and Reasoning Corpus) challenge aims to evaluate the general intelligence of AI systems through their ability to efficiently acquire new skills by learning transformation rules of grid patterns from examples and predicting output grid patterns given a test input grid pattern. This event demonstrates the proficiency of agents in in-context learning, which is part of the ADAS research area.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7,7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Self-Consistency with Chain-of-Thought (COT-SC) is a method that ensembles multiple parallel answers from COT to produce a more accurate answer</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="GREENBLATT">
      <data key="d0">PERSON</data>
      <data key="d1">Greenblatt is an author who has worked on the setup for the ARC challenge</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DYNAMIC MEMORY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Dynamic Memory is a system introduced for doing more refinements in the context of Meta Agent Search</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="MULTIPLE CRITICS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Multiple Critics is a feature introduced in the best agent for enhanced refinement in Meta Agent Search</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="CRITIC">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">CRITIC is a component of the best agent in Meta Agent Search that provides feedback for refinement. It is a process handled by the FM_Module, involving the provision of feedback and correctness status.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="SIMPLICITY EXPERT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Simplicity Expert is a type of expert used in the best agent in Meta Agent Search to evaluate simplicity</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="STRUCTURED FEEDBACK AND ENSEMBLE AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Structured Feedback and Ensemble Agent is one of the top agents discovered by Meta Agent Search and has been rigorously tested for transferability. It stands out as the best discovered agent on the Abstraction and Reasoning Corpus (ARC) by Meta Agent Search, utilizing a complex feedback mechanism to refine answers more effectively. This advanced agent leverages structured feedback and ensemble techniques to enhance its problem-solving capabilities, making it a significant contributor to the field of artificial intelligence.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ABSTRACTION AND REASONING CORPUS">
      <data key="d0">EVENT</data>
      <data key="d1">The Abstraction and Reasoning Corpus (ARC) is a challenge that evaluates the general intelligence of AI systems through their ability to efficiently acquire new skills by learning transformation rules of grid patterns from examples and predicting output grid patterns given a test input grid pattern</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="TRANSFORMATION RULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The "TRANSFORMATION RULE" is a rule that AI systems need to learn from input-output grid examples in the ARC (Abstraction and Reasoning Corpus) challenge. This rule is essential for predicting the output grid patterns given a test input grid pattern. The learned rule enables AI to accurately determine the output grid for the test example based on the patterns observed in the provided examples.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="TOOL FUNCTIONS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Tool Functions are provided in the framework to evaluate the generated transformation code in the ARC challenge</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="PUBLIC TRAINING SET (EASY)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Public Training Set (Easy) is a dataset used in the ARC challenge with grid dimensions &#8804;5&#215;5</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="VALIDATION SET">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Validation Set is a dataset used to validate the accuracy of agents in the ARC challenge. It serves as a subset of data specifically designed to assess the performance of solutions in the experiment, ensuring that the agents' results are reliable and accurate.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="TEST SET">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Test Set is a dataset utilized to evaluate the accuracy of agents in the ARC challenge. It serves as a subset of data specifically designed to test the performance of solutions in various experiments.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="STOCHASTIC SAMPLING OF FMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Stochastic Sampling of FMs is a method used to reduce variance in the evaluation of agents in the ARC challenge</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (COT)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Chain-of-Thought (COT) is a method that instructs the agent to output the reasoning before answering, thereby improving complex problem-solving through intermediate steps. Additionally, Chain-of-Thought (COT) serves as a state-of-the-art hand-designed agent baseline for experiments on the Abstraction and Reasoning Corpus (ARC). This dual functionality highlights COT's significance in both enhancing problem-solving capabilities and providing a robust benchmark for experimental evaluations in AI research.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Self-Consistency with Chain-of-Thought (COT-SC) is a method that ensembles multiple parallel answers from Chain-of-Thought (COT) to produce a more accurate answer. It is also recognized as a state-of-the-art hand-designed agent baseline for experiments on the AI2 Reasoning Challenge (ARC).</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="MMLU">
      <data key="d0">BENCHMARK</data>
      <data key="d1">MMLU (Massive Multitask Language Understanding) is a benchmark introduced by Hendrycks et al. in 2021, designed to evaluate the performance of AI models in multi-task problem solving. It assesses a model&#8217;s ability to answer questions across a wide range of subjects and difficulty levels, including STEM, social sciences, humanities, and more. The benchmark encompasses 57 academic subjects with approximately 16,000 multiple-choice questions, making it a comprehensive tool for measuring a model&#8217;s multitask understanding. MMLU is also used to evaluate the performance of models on various mathematical tasks, including abstract algebra and college-level mathematics. Notably, the model Orca-3 demonstrated a 19% improvement over Mistral-7b-Instruct on this benchmark. Additionally, MMLU is one of the datasets included in the MIRAGE Datasets, further highlighting its significance in the AI and ML community.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="GPQA">
      <data key="d0">BENCHMARK</data>
      <data key="d1">GPQA (Graduate-Level Google-Proof Q&amp;A Benchmark) is a comprehensive and challenging benchmark designed to evaluate the capability of solving hard, graduate-level questions in the domains of biology, physics, and chemistry. Created by domain experts to ensure high quality and difficulty, GPQA consists of 448 high-quality multiple-choice questions. It is used to assess the performance of various models, including Orca-3 and other baselines, and plays a significant role in experiments focused on reasoning and problem-solving. The benchmark includes a validation set of 32 questions and a test set of 166 questions. Additionally, GPQA serves as the Reading Comprehension domain where innovative agents like the Multi-Step Peer Review Agent and Divide and Conquer Agent were discovered.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,84317ae35cc75d612287186d93461447,86f77e15d41cbd0cb33f635ccb2cb66b,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="LLM DEBATE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM Debate (Du et al., 2023) is a state-of-the-art, manually designed agent technique referenced in the study by Du et al., 2023. This system enables different Large Language Models (LLMs) to debate with each other, leveraging diverse perspectives to find better answers. LLM Debate performs tasks such as Math, Reading Comprehension, Multi-task, and Science, showcasing its versatility and effectiveness in various domains.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="STEP-BACK ABSTRACTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Step-back Abstraction, referenced by Zheng et al., 2023, is a state-of-the-art, hand-designed agent that serves as a baseline for experiments in Reasoning and Problem-Solving domains. This manually designed agent technique instructs agents to first consider the principles involved in solving tasks to enhance reasoning capabilities. It is implemented for various tasks, including Math, Reading Comprehension, Multi-task, and Science, showcasing its versatility and effectiveness in complex problem-solving scenarios.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ROLE ASSIGNMENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Role Assignment, as referenced by Xu et al. (2023), is a state-of-the-art, hand-designed agent that assigns different roles to functional modules (FMs) to obtain better answers. It serves as a baseline for experiments in the domains of Reasoning and Problem-Solving. This manually designed agent technique is capable of performing tasks such as Math, Reading Comprehension, Multi-tasking, and Science.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="HENDRYCKS">
      <data key="d0">PERSON</data>
      <data key="d1">Hendrycks is an author associated with the MMLU benchmark for evaluating Multi-task Problem Solving</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="REIN">
      <data key="d0">PERSON</data>
      <data key="d1">Rein is an author associated with the GPQA benchmark, which is designed for evaluating the capability of solving hard, graduate-level questions in Science. In the domain of Reading Comprehension, Rein contributed to the discovery of the Multi-Step Peer Review Agent and the Divide and Conquer Agent, both of which are significant advancements in the field.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FEEDBACK MECHANISM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The feedback mechanism is a sophisticated system used to refine answers more effectively by incorporating diverse feedback, evaluating various specific traits, and simulating human-like feedback</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ITERATION 5">
      <data key="d0">EVENT</data>
      <data key="d1">Iteration 5 is a specific stage in the search progress where the idea of incorporating diverse feedback emerged</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ITERATION 11">
      <data key="d0">EVENT</data>
      <data key="d1">Iteration 11 is a specific stage in the search progress where the idea of evaluating for various specific traits such as efficiency and simplicity emerged</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ITERATION 12">
      <data key="d0">EVENT</data>
      <data key="d1">Iteration 12 is a specific stage in the search progress where the idea of simulating human-like feedback emerged</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MECHANISM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The final mechanism is an innovation based on the ideas from iterations 5, 11, and 12, used to refine answers more effectively</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="CROSSOVER">
      <data key="d0">PROCESS</data>
      <data key="d1">Crossover in evolution via LLMs refers to the combination of different stepping stones to achieve better performance</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="REASONING AND PROBLEM-SOLVING DOMAINS">
      <data key="d0">DOMAIN</data>
      <data key="d1">Reasoning and Problem-Solving Domains are areas where experiments are conducted, costing about $300 USD. These domains are the areas of focus for the experiment, including GPQA and DROP, and refer to the areas of math, reading, and reasoning where the algorithm's capabilities are tested.</data>
      <data key="d2">84317ae35cc75d612287186d93461447,bc26e68b0b2783ba912b9e5606d9eb0b,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SETUP">
      <data key="d0">PROCESS</data>
      <data key="d1">Setup refers to the process of investigating the potential of the algorithm to improve the capabilities of agents across various domains</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="BENCHMARKS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Benchmarks are standards or points of reference against which things may be compared or assessed. They are used to measure the performance of models such as Orca-3 and to compare the performance of Meta Agent Search. These benchmarks provide a critical framework for evaluating and understanding the effectiveness and efficiency of various AI and ML models, ensuring that they meet specific performance criteria and facilitating the identification of areas for improvement.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="EXPERIMENT SETTINGS">
      <data key="d0">PROCESS</data>
      <data key="d1">Experiment settings refer to the specific conditions and parameters under which the Meta Agent Search is tested</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="BASELINES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Baselines are the initial seeds and standard solutions used in Meta Agent Search to progressively discover and compare better-performing agents. They serve as the initial standards or reference points in experiments, providing a foundation for evaluating the performance of new agents.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,7c08d98f503d722d7de13be55375c8cb,84317ae35cc75d612287186d93461447,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="RESULTS AND ANALYSIS">
      <data key="d0">PROCESS</data>
      <data key="d1">"Results and Analysis" is the section where the effectiveness of Meta Agent Search is discussed. It refers to the evaluation and interpretation of the performance of Meta Agent Search across multiple domains. This section provides a comprehensive assessment of how well the Meta Agent Search performs, offering insights into its strengths and areas for improvement.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MULTI-TASK DOMAIN">
      <data key="d0">DOMAIN</data>
      <data key="d1">The Multi-task Domain refers to the area where an algorithm's capability to solve multiple tasks is tested. It is one of the areas where Meta Agent Search demonstrates superior performance compared to baseline models, although the performance gap is smaller in this domain compared to others.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="SCIENCE DOMAIN">
      <data key="d0">DOMAIN</data>
      <data key="d1">Science Domain refers to the area where the algorithm's capability to solve hard (graduate-level) questions in Science is tested. It is one of the areas where Meta Agent Search outperforms baselines, although the performance gap is smaller compared to other domains.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MEYERSON">
      <data key="d0">PERSON</data>
      <data key="d1">Meyerson is an author associated with the concept of crossover in evolution via LLMs</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="SEARCH PROGRESS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="READING COMPREHENSION DOMAIN">
      <data key="d0">DOMAIN</data>
      <data key="d1">The Reading Comprehension domain is one of the areas where Meta Agent Search shows significant improvement over baselines</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="MATH DOMAIN">
      <data key="d0">DOMAIN</data>
      <data key="d1">The Math domain is a specific area where agents discovered by Meta Agent Search are tested and evaluated. It is one of the areas where Meta Agent Search shows significant improvement over baselines, highlighting its effectiveness and advancements in this particular field.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="CLAUDE-HAIKU">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Claude-Haiku is a foundation model from Anthropic used to test the transferability of agents discovered by Meta Agent Search</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="CLAUDE-SONNET">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Claude-Sonnet is a foundation model from Anthropic used to test the transferability of agents discovered by Meta Agent Search</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="HIERARCHICAL COMMITTEE REINFORCEMENT AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Hierarchical Committee Reinforcement Agent is one of the top agents discovered by Meta Agent Search and tested for transferability</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DYNAMIC MEMORY AND REFINEMENT AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Dynamic Memory and Refinement Agent is one of the top agents discovered by Meta Agent Search and tested for transferability</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="SVAMP">
      <data key="d0">DATASET</data>
      <data key="d1">SVAMP is a dataset mentioned in the text, referenced by Patel et al., 2021. It is a math domain dataset used to test the transferability of agents discovered by Meta Agent Search.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="ASDIV">
      <data key="d0">DATASET</data>
      <data key="d1">ASDiv is a dataset mentioned in the text, referenced by Miao et al., 2020. It is a math domain dataset used to test the transferability of agents discovered by Meta Agent Search.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Dynamic Role-Playing Architecture is a top agent technique discovered by Meta Agent Search. It excels in performing a variety of tasks, including Math, Reading Comprehension, Multi-tasking, and Science. This architecture stands out for its versatility and effectiveness in handling complex, multi-domain challenges, making it a significant advancement in the field of artificial intelligence.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Structured Multimodal Feedback Loop is a top agent technique discovered by Meta Agent Search. It excels in performing a variety of tasks, including Math, Reading Comprehension, Multi-tasking, and Science. This advanced method leverages structured feedback from multiple modalities to enhance its performance across diverse domains, making it a significant innovation in the field of artificial intelligence and machine learning.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Interactive Multimodal Feedback Loop is a top agent technique discovered by Meta Agent Search. It excels in performing a variety of tasks, including Math, Reading Comprehension, Multi-tasking, and Science. This advanced technique leverages multimodal feedback to enhance its performance across different domains, making it a versatile and powerful tool in the field of artificial intelligence.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain-of-thought-based planning and reasoning methods are important building blocks for agentic systems, referenced by Hu &amp; Clune, 2024; Wei et al., 2022; Yao et al., 2023</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="DEVELOPING NEW SKILLS FOR EMBODIED AGENTS IN CODE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Developing new skills for embodied agents in code is an important building block for agentic systems, referenced by Vemprala et al., 2023; Wang et al., 2023a</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="EXTERNAL MEMORY AND RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">External memory and RAG are important building blocks for agentic systems, referenced by Lewis et al., 2020; Zhang et al., 2024c</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Assigning FM modules in the agentic system with different roles and enabling them to collaborate is an important building block for agentic systems, referenced by Hong et al., 2023; Qian et al., 2023, 2024; Wu et al., 2023; Xu et al., 2023</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="ENABLING THE AGENT TO INSTRUCT ITSELF FOR THE NEXT ACTION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Enabling the agent to instruct itself for the next action is an important building block for agentic systems, referenced by Richards, 2023</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="AI-GENERATING ALGORITHMS">
      <data key="d0">RESEARCH AREA</data>
      <data key="d1">AI-Generating Algorithms (AI-GAs) are a field of research that aims to learn more components in AI systems to replace handcrafted ones. This research area focuses on automating the creation of AI components, thereby reducing the need for manual intervention and potentially accelerating the development of AI technologies. AI-GAs are mentioned in the text as a significant area of study within the broader AI and ML communities.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="MIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Miao is an author referenced in the text, associated with the ASDiv dataset, 2020</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="SCHULHOFF">
      <data key="d0">PERSON</data>
      <data key="d1">Schulhoff is an author referenced in the text, associated with prompting techniques, 2024</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="VEMPRALA">
      <data key="d0">PERSON</data>
      <data key="d1">Vemprala is an author referenced in the text, associated with developing new skills for embodied agents in code, 2023</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="NAKANO">
      <data key="d0">PERSON</data>
      <data key="d1">Nakano is an author referenced in the text, associated with tool use, 2021</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="HONG">
      <data key="d0">PERSON</data>
      <data key="d1">Hong is an author mentioned in the text, referenced in 2023 for their work on assigning FM modules in the agentic system with different roles.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="QIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Qian is an author referenced in the text, associated with assigning FM modules in the agentic system with different roles, 2023, 2024</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="RICHARDS">
      <data key="d0">PERSON</data>
      <data key="d1">Richards is an author referenced in the text, associated with enabling the agent to instruct itself for the next action, 2023</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="PATEL">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="MAML">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">MAML (Model-Agnostic Meta-Learning) is a method that allows "learning to learn" for better sample efficiency, generalizability, and continuous learning of multiple tasks</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="META-RL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Meta-RL (Meta-Reinforcement Learning) is a method that allows "learning to learn" for better sample efficiency, generalizability, and continuous learning of multiple tasks</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="POET">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">POET (Paired Open-Ended Trailblazer) is a method that aims to generate learning environments in an open-ended manner</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="EOH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">EoH is a method where Foundation Models write code to discover better optimization algorithms</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DISCOPOP">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">DiscoPOP is a method where Foundation Models program the loss function for preference learning in FM alignment training</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="EUREKA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">EUREKA is a method and system that enables Foundation Models (FMs) to write reward functions for reinforcement learning in robotics. It facilitates human-level reward design through the coding of large language models. This innovative approach is detailed in a paper published at the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="LANGUAGE-TO-REWARD">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Language-to-Reward is a method that enables Foundation Models (FMs) to write reward functions for reinforcement learning in robotics. This system leverages the capabilities of FMs to generate precise and effective reward functions, which are crucial for guiding the learning process in robotic applications. By utilizing advanced language models, Language-to-Reward aims to enhance the efficiency and performance of reinforcement learning algorithms in the field of robotics.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FINN">
      <data key="d0">PERSON</data>
      <data key="d1">Finn is an author who has contributed to research in MAML</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="NORMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Norman is an author who has contributed to research in Meta-RL</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="ZINTGRAF">
      <data key="d0">PERSON</data>
      <data key="d1">Zintgraf is an author who has contributed to research in Meta-RL</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DHARNA">
      <data key="d0">PERSON</data>
      <data key="d1">Dharna is an author who has contributed to research in POET</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="RAFALIOV">
      <data key="d0">PERSON</data>
      <data key="d1">Rafailov is an author who has contributed to research in FM alignment training</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="MA">
      <data key="d0">PERSON</data>
      <data key="d1">Ma is an author who has contributed to research in Eureka, specifically working on this project in 2023.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="NORMAN &amp; CLUNE">
      <data key="d0">PERSON</data>
      <data key="d1">Norman &amp; Clune are authors who have contributed to research in Meta-RL</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="WANG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang et al. are authors who have contributed to research in POETWang et al. are authors who have contributed to research in Meta-RL and POET</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZINTGRAF ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Zintgraf et al. are authors who have contributed to research in Meta-RL</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DHARNA ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Dharna et al. are authors who have contributed to research in POET</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="FALDOR ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Faldor et al. are authors who have contributed to research in OMNI-EPIC</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="ROMERA-PAREDES ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Romera-Paredes et al. are authors who have contributed to research in FunSearch</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="RAFALIOV ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Rafailov et al. are authors who have contributed to research in FM alignment training</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="MA ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Ma et al. are authors who have contributed to research in Eureka</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="YU ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Yu et al. are authors who have contributed to research in Language-to-Reward</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="NON-MATH DOMAINS">
      <data key="d0">DOMAIN</data>
      <data key="d1">Non-math domains are areas beyond the Math domain where agents discovered by Meta Agent Search are transferred and evaluated</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="PREFERENCE LEARNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Preference Learning is a method used in FM alignment training to program the loss function</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="FM ALIGNMENT TRAINING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">FM Alignment Training is a process where Foundation Models are trained to align with specific preferences using methods like DiscoPOP</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="LEARNING ENVIRONMENTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Learning Environments are generated in an open-ended manner to facilitate the training of AI systems, as seen in methods like POET and OMNI-EPIC</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TRAINING DATA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Training Data is generated to create effective learning environments and improve AI systems, as part of the third pillar of AI-GAs and AutoML</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="META-LEARNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Meta-Learning is a process of learning to learn, which includes meta-learning architectures and learning algorithms, as part of the first and second pillars of AI-GAs and AutoML</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="LEARNING ALGORITHMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Learning Algorithms are meta-learned to improve sample efficiency, generalizability, and continuous learning of multiple tasks, as part of the second pillar of AI-GAs and AutoML</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ARCHITECTURES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Architectures are meta-learned to design neural network structures, as part of the first pillar of AI-GAs and AutoML</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="CONVOLUTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Convolution is a type of neural network architecture that is designed using methods like Neural Architecture Search</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="SAMPLE EFFICIENCY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Sample Efficiency is improved through methods like MAML and Meta-RL, which allow "learning to learn"</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="GENERALIZABILITY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Generalizability is enhanced through meta-learning methods like MAML and Meta-RL, allowing AI systems to perform well across multiple tasks</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="CONTINUOUS LEARNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Continuous Learning is facilitated by meta-learning methods like MAML and Meta-RL, enabling AI systems to learn multiple tasks over time</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="OPTIMIZATION ALGORITHMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Optimization Algorithms are discovered by Foundation Models in methods like FunSearch and EoH</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="LOSS FUNCTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Loss Function is programmed by Foundation Models in methods like DiscoPOP for preference learning in FM alignment training</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="REWARD FUNCTIONS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Reward Functions are written by Foundation Models in methods like Eureka and Language-to-Reward for reinforcement learning in robotics</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="AGENTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Agents are systems designed to perform tasks like Math, Reading Comprehension, Multi-task, and Science, as seen in various manually designed and top agents discovered by Meta Agent Search</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="MULTI-TASK">
      <data key="d0">DOMAIN</data>
      <data key="d1">Multi-task is a domain where agents are tested and evaluated for their performance</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">DOMAIN</data>
    </node>
    <node id="SCIENCE">
      <data key="d0">DOMAIN</data>
      <data key="d1">Science is a domain where agents are tested and evaluated for their performance</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">DOMAIN</data>
    </node>
    <node id="TEST ACCURACY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Test Accuracy is a metric used to evaluate the performance of agents across multiple domains</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DOMAIN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Domain refers to specific areas like Math, Reading Comprehension, Multi-task, and Science where agents are tested and evaluated</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ARCHIVE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ARCHIVE is a crucial component in Meta Agent Search, serving as a repository for initial seeds and facilitating the progressive discovery of better-performing agents. This archive functions as a collection of previous methods and architectures, which are utilized for comparison and improvement within the Meta Agent Search framework.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,7c08d98f503d722d7de13be55375c8cb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="OPRO">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">OPRO is a system that adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="SELF-DISCOVER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Self-Discover is a system that adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="EVOAGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">EvoAgent is a system that optimizes role definition in the prompt, assigning personas or roles to agents</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Yuan is an author who has worked on EvoAgent in 2024</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AGENTVERSE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AgentVerse is a system designed to optimize role definition in prompts by assigning personas or roles to agents. It facilitates multi-agent collaboration and explores emergent behaviors. This innovative system was detailed in a paper published at The Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DYLAN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">DyLAN is a system that starts with a fully connected feed-forward network and uses FMs to score the response quality of nodes in each layer to prune the connections</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DSPY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">DSPy is a system that generates a set of possible nodes and then optimizes across the Cartesian product of these nodes while optimizing the few-shot examples for nodes</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="GPT-SWARM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-Swarm is a system that represents an agentic system in a graph with a predefined set of nodes and uses a Reinforcement Learning algorithm to optimize the possible connections between nodes while optimizing the prompt for each node in a separate stage</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ZHUGE">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuge is an author who has worked on GPT-Swarm in 2024</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AGENTOPTIMIZER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AgentOptimizer is a system that learns the tools used in agents</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="AGENT SYMBOLIC LEARNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Agent Symbolic Learning is a system that learns prompts, tools, and control flow together in agents</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ROKON">
      <data key="d0">PERSON</data>
      <data key="d1">Rokon is an author who has discussed safety concerns when executing untrusted model-generated code in 2020</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YEE">
      <data key="d0">PERSON</data>
      <data key="d1">Yee is an author who has discussed safety concerns when executing untrusted model-generated code in 2010</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BOSTROM">
      <data key="d0">PERSON</data>
      <data key="d1">Bostrom is an author who has been mentioned in the text for his discussions on whether we should pursue Artificial General Intelligence (AGI) and Artificial Intelligence-Generated Art (AI-GA) as early as 2002.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ECOFFET">
      <data key="d0">PERSON</data>
      <data key="d1">Ecoffet is an author mentioned in the text who has discussed whether we should pursue Artificial General Intelligence (AGI) and AI-Generated Algorithms (AI-GA) in 2020.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUDKOWSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Yudkowsky is an author who has been mentioned in the text. In 2008, Yudkowsky discussed the critical topic of whether we should pursue Artificial General Intelligence (AGI) and AI-GA, highlighting his engagement with significant debates in the field of artificial intelligence.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAFE-ADAS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Safe-ADAS refers to algorithms that conduct ADAS safely, avoiding harmful code and creating honest, helpful agents</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CALDWELL">
      <data key="d0">PERSON</data>
      <data key="d1">Caldwell is an author mentioned in the text</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="META">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Meta is an organization mentioned in the text. Meta is also the organization that published the news article titled "Open source AI is the path forward" in July 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="CONSTITUTIONAL AI">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Constitutional AI is an approach that aims to create AI systems that are safe, honest, and helpful</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="BAI">
      <data key="d0">PERSON</data>
      <data key="d1">Bai is an author mentioned in the text</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HIGHER-ORDER ADAS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Higher-order ADAS refers to the concept of improving the meta agent itself through ADAS, allowing for meta-learning of the meta agent and beyond</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="MULTI-OBJECTIVE ADAS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Multi-objective ADAS refers to the concept of optimizing multiple objectives such as cost, latency, and robustness in agentic systems</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="DEB">
      <data key="d0">PERSON</data>
      <data key="d1">Deb is an author mentioned in the text</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NOVELTY SEARCH ALGORITHMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Novelty search algorithms are algorithms designed to explore interesting new designs, potentially incorporating ideas from Quality-Diversity and AI-generating algorithms</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CULLY">
      <data key="d0">PERSON</data>
      <data key="d1">Cully is an author mentioned in the text</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DEMIRIS">
      <data key="d0">PERSON</data>
      <data key="d1">Demiris is an author mentioned in the text</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MOURET">
      <data key="d0">PERSON</data>
      <data key="d1">Mouret is an author mentioned in the text</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MORE INTELLIGENT EVALUATION FUNCTIONS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">More intelligent evaluation functions refer to advanced methods for evaluating agents, including analyzing detailed running logs and addressing subjective answer evaluations</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="MORE COMPLEX DOMAINS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">More complex domains refer to extending the evaluation of Meta Agent Search to real-world applications involving multi-step interaction with complex environments</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="UNDERSTANDING THE EMERGENCE OF COMPLEXITY FROM HUMAN ORGANIZATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Understanding the emergence of complexity from human organizations refers to the scientific study of how complexity arises in human organizations and society, and its connection to agentic systems</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="MULTI-MODAL CAPABILITIES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Multi-modal capabilities refer to the ability to support multiple types of data, such as vision, in agentic systems</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="AS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AS refers to a scientifically intriguing concept that sheds light on the origins of complexity emerging from human organization and society</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="AGENTIC SYSTEM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The agentic system is a machine learning system that operates primarily over natural language, which is interpretable to humans and used by humans in constructing our organization and society</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="HUMAN ORGANIZATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Human organizations refer to the structured groups of people working together, often mentioned in the context of agentic systems and their connection to human society</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="HONG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Hong et al. are authors who have worked on incorporating the organizational structure for human companies in agents</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="PARK ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Park et al. are authors who have worked on simulating a human town with agents</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CANADA CIFAR AI CHAIRS PROGRAM">
      <data key="d0">PROGRAM</data>
      <data key="d1">The Canada CIFAR AI Chairs program is one of the programs that supported the work on Automated Design of Agentic Systems</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PROGRAM</data>
    </node>
    <node id="SCHMIDT FUTURES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Schmidt Futures is one of the organizations that provided grants for the work on Automated Design of Agentic Systems</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="OPEN PHILANTHROPY">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Open Philanthropy is one of the organizations that provided grants for the work on Automated Design of Agentic Systems</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NSERC DISCOVERY GRANT">
      <data key="d0">PROGRAM</data>
      <data key="d1">The NSERC Discovery Grant is one of the grants that supported the work on Automated Design of Agentic Systems</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PROGRAM</data>
    </node>
    <node id="RAFAEL COSMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Rafael Cosman is a person who made a generous donation to support the work on Automated Design of Agentic Systems</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JENNY ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jenny Zhang is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness," published in The Twelfth International Conference on Learning Representations in 2024. She also co-authored the paper "Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code," published on arXiv in 2024. Additionally, Jenny Zhang is acknowledged for her insightful discussions and feedback on the work related to the Automated Design of Agentic Systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7de66b94cf868b37b1df51dc545c415f,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RACH PRADHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Rach Pradhan is one of the individuals thanked for insightful discussions and feedback on the work on Automated Design of Agentic Systems</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RUIYU GOU">
      <data key="d0">PERSON</data>
      <data key="d1">Ruiyu Gou is one of the individuals thanked for insightful discussions and feedback on the work on Automated Design of Agentic Systems</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NICHOLAS IOANNIDIS">
      <data key="d0">PERSON</data>
      <data key="d1">Nicholas Ioannidis is one of the individuals thanked for insightful discussions and feedback on the work on Automated Design of Agentic Systems</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="EUNJEONG HWANG">
      <data key="d0">PERSON</data>
      <data key="d1">Eunjeong Hwang is one of the individuals thanked for insightful discussions and feedback on the work on Automated Design of Agentic Systems</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CLAUDE 3">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Claude 3 is a model introduced by Anthropic in a blog post in March 2024</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="CLAUDE 3.5 SONNET">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Claude 3.5 Sonnet is a model introduced by Anthropic in a blog post in June 2024</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="YUNTAO BAI">
      <data key="d0">PERSON</data>
      <data key="d1">Yuntao Bai is one of the authors of the paper "Constitutional AI: Harmlessness from AI Feedback" published on arXiv in 2022</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAURAV KADAVATH">
      <data key="d0">PERSON</data>
      <data key="d1">Saurav Kadavath is a notable author in the field of Artificial Intelligence and Machine Learning. He has contributed to significant research, including the paper "Constitutional AI: Harmlessness from AI Feedback," published on arXiv in 2022, and the paper "Measuring mathematical problem solving with the math dataset," published on arXiv in 2021. His work spans critical areas such as AI safety and mathematical problem-solving, reflecting his expertise and active involvement in advancing AI research.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SANDIPAN KUNDU">
      <data key="d0">PERSON</data>
      <data key="d1">Sandipan Kundu is one of the authors of the paper "Constitutional AI: Harmlessness from AI Feedback" published on arXiv in 2022</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AMANDA ASKELL">
      <data key="d0">PERSON</data>
      <data key="d1">Amanda Askell is one of the authors of the paper "Constitutional AI: Harmlessness from AI Feedback" published on arXiv in 2022</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JACKSON KERNION">
      <data key="d0">PERSON</data>
      <data key="d1">Jackson Kernion is one of the authors of the paper "Constitutional AI: Harmlessness from AI Feedback" published on arXiv in 2022</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANDY JONES">
      <data key="d0">PERSON</data>
      <data key="d1">Andy Jones is one of the authors of the paper "Constitutional AI: Harmlessness from AI Feedback" published on arXiv in 2022</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANNA CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Anna Chen is one of the authors of the paper "Constitutional AI: Harmlessness from AI Feedback" published on arXiv in 2022</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANNA GOLDIE">
      <data key="d0">PERSON</data>
      <data key="d1">Anna Goldie is one of the authors of the paper "Constitutional AI: Harmlessness from AI Feedback" published on arXiv in 2022</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AZALIA MIRHOSEINI">
      <data key="d0">PERSON</data>
      <data key="d1">Azalia Mirhoseini is one of the authors of the paper "Constitutional AI: Harmlessness from AI Feedback" published on arXiv in 2022</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CAMERON MCKINNON">
      <data key="d0">PERSON</data>
      <data key="d1">Cameron McKinnon is one of the authors of the paper "Constitutional AI: Harmlessness from AI Feedback" published on arXiv in 2022</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GEOFFREY HINTON">
      <data key="d0">PERSON</data>
      <data key="d1">Geoffrey Hinton is one of the authors of the paper "Managing Extreme AI Risks Amid Rapid Progress" published in Science in 2024</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANDREW YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Yao is one of the authors of the paper "Managing Extreme AI Risks Amid Rapid Progress" published in Science in 2024</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAWN SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Dawn Song is a prolific author in the field of Artificial Intelligence and Machine Learning. She has contributed to several significant papers, including "Managing Extreme AI Risks Amid Rapid Progress" published in Science in 2024, "Measuring Massive Multitask Language Understanding" presented at the International Conference on Learning Representations in 2021, and "The False Promise of Imitating Proprietary LLMs" published on arXiv in 2023. Her work spans critical areas such as AI risk management, language understanding, and the limitations of proprietary language models, highlighting her influence and expertise in the AI and ML research community.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TREVOR DARRELL">
      <data key="d0">PERSON</data>
      <data key="d1">Trevor Darrell is one of the authors of the paper "Managing Extreme AI Risks Amid Rapid Progress" published in Science in 2024</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUVAL NOAH HARARI">
      <data key="d0">PERSON</data>
      <data key="d1">Yuval Noah Harari is one of the authors of the paper "Managing Extreme AI Risks Amid Rapid Progress" published in Science in 2024</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YA-QIN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ya-Qin Zhang is one of the authors of the paper "Managing Extreme AI Risks Amid Rapid Progress" published in Science in 2024</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LAN XUE">
      <data key="d0">PERSON</data>
      <data key="d1">Lan Xue is one of the authors of the paper "Managing Extreme AI Risks Amid Rapid Progress" published in Science in 2024</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHAI SHALEV-SHWARTZ">
      <data key="d0">PERSON</data>
      <data key="d1">Shai Shalev-Shwartz is one of the authors of the paper "Managing Extreme AI Risks Amid Rapid Progress" published in Science in 2024</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="N BOSTROM">
      <data key="d0">PERSON</data>
      <data key="d1">N Bostrom is the author of the paper "Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards" published in the Journal of Evolution and Technology in 2002</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ROBERT S BOYER">
      <data key="d0">PERSON</data>
      <data key="d1">Robert S Boyer is one of the authors of the paper "A Mechanical Proof of the Turing Completeness of Pure LISP" published in 1983</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J STROTHER MOORE">
      <data key="d0">PERSON</data>
      <data key="d1">J Strother Moore is one of the authors of the paper "A Mechanical Proof of the Turing Completeness of Pure LISP" published in 1983</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TRACEY CALDWELL">
      <data key="d0">PERSON</data>
      <data key="d1">Tracey Caldwell is the author of the paper "Ethical Hackers: Putting on the White Hat" published in Network Security in 2011</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HARRISON CHASE">
      <data key="d0">PERSON</data>
      <data key="d1">Harrison Chase is the author of the blog post "What is an Agent?" published on the LangChain blog in June 2024</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BANGHAO CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Banghao Chen is one of the authors of the paper "Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review" published on arXiv in 2023</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHAOFENG ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhaofeng Zhang is one of the authors of the paper "Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review" published on arXiv in 2023</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NICOLAS LANGREN&#201;">
      <data key="d0">PERSON</data>
      <data key="d1">Nicolas Langren&#233; is one of the authors of the paper "Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review" published on arXiv in 2023</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHENGXIN ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Shengxin Zhu is one of the authors of the paper "Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review" published on arXiv in 2023</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HENRIQUE PONDE DE OLIVEIRA PINTO">
      <data key="d0">PERSON</data>
      <data key="d1">Henrique Ponde De Oliveira Pinto is one of the authors of the paper "Evaluating Large Language Models Trained on Code" published on arXiv in 2021</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HARRI EDWARDS">
      <data key="d0">PERSON</data>
      <data key="d1">Harri Edwards is one of the authors of the paper "Evaluating Large Language Models Trained on Code" published on arXiv in 2021</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YURI BURDA">
      <data key="d0">PERSON</data>
      <data key="d1">Yuri Burda is one of the authors of the paper "Evaluating Large Language Models Trained on Code" published on arXiv in 2021</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WEIZE CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Weize Chen is one of the authors of the paper "Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors" published in the Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUSHENG SU">
      <data key="d0">PERSON</data>
      <data key="d1">Yusheng Su is one of the authors of the paper titled "Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors," which was published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JINGWEI ZUO">
      <data key="d0">PERSON</data>
      <data key="d1">Jingwei Zuo is one of the authors of the paper titled "Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors," which was published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHENG YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Cheng Yang is one of the authors of the paper titled "Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors," which was published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHENFEI YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Chenfei Yuan is one of the authors of the paper titled "Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors," which was published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHI-MIN CHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Chi-Min Chan is one of the authors of the paper titled "Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors," which was published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HEYANG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Heyang Yu is one of the authors of the paper titled "Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors," which was published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YI-HSIN HUNG">
      <data key="d0">PERSON</data>
      <data key="d1">Yi-Hsin Hung is one of the authors of the paper titled "Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors," which was published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHEN QIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Qian is one of the authors of the paper titled "Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors," which was published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ADVANCED MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Advanced models refer to more recent and sophisticated machine learning models that benefit from simpler feedback mechanisms</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="INSIGHTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">INSIGHTS refer to the thoughts and reasoning behind the design of the next agent, as captured in the "thought" section, as well as the understanding gained from observing the results of experiments and studies. This dual perspective encompasses both the theoretical framework and practical observations, providing a comprehensive view of the development and evaluation processes in AI and ML communities.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="BUILDING BLOCKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Building blocks refer to the fundamental components used in the design of agentic systems</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="ALGORITHM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">An algorithm is a set of rules or processes followed in problem-solving operations, often by a computer</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="DOMAINS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Domains refer to the various fields or areas where the discovered agents are tested and applied</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">EVENT</data>
      <data key="d1">The Twelfth International Conference on Learning Representations is a significant event in the field of artificial intelligence and machine learning. In 2023, the conference featured the publication of the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors." In 2024, it showcased two notable papers: "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" and "OMNI: Open-endedness via models of human notions of interestingness." This conference serves as a platform for presenting cutting-edge research and fostering collaboration among experts in the AI and ML communities.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WEI-LIN CHIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Wei-Lin Chiang is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="LIANMIN ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Lianmin Zheng is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YING SHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Ying Sheng is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ANASTASIOS NIKOLAS ANGELOPOULOS">
      <data key="d0">PERSON</data>
      <data key="d1">Anastasios Nikolas Angelopoulos is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="TIANLE LI">
      <data key="d0">PERSON</data>
      <data key="d1">Tianle Li is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="DACHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Dacheng Li is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="HAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Zhang is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="BANGHUA ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Banghua Zhu is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="MICHAEL JORDAN">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Jordan is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JOSEPH E. GONZALEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Joseph E. Gonzalez is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ION STOICA">
      <data key="d0">PERSON</data>
      <data key="d1">Ion Stoica is one of the authors of the paper titled "Chatbot arena: An open platform for evaluating llms by human preference" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHATBOT ARENA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Chatbot Arena is an open platform for evaluating large language models (LLMs) by human preference, as described in a paper published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="FRAN&#199;OIS CHOLLET">
      <data key="d0">PERSON</data>
      <data key="d1">Fran&#231;ois Chollet is the author of the paper titled "On the measure of intelligence" published on arXiv in 2019</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ON THE MEASURE OF INTELLIGENCE">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "On the measure of intelligence" is authored by Fran&#231;ois Chollet and was published on arXiv in 2019</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="KARL COBBE">
      <data key="d0">PERSON</data>
      <data key="d1">Karl Cobbe is one of the authors of the paper titled "Training verifiers to solve math word problems" published on arXiv in 2021</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="VINEET KOSARAJU">
      <data key="d0">PERSON</data>
      <data key="d1">Vineet Kosaraju is one of the authors of two notable papers published on arXiv in 2021. The first paper, titled "Training verifiers to solve math word problems," explores methodologies for enhancing the capabilities of verifiers in solving mathematical word problems. The second paper, "WebGPT: Browser-assisted question-answering with human feedback," delves into the development of a question-answering system that leverages browser assistance and human feedback to improve its performance.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JACOB HILTON">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Hilton is one of the authors of two significant papers published on arXiv in 2021. The first paper, titled "Training verifiers to solve math word problems," explores innovative methods for training AI verifiers to effectively solve mathematical word problems. The second paper, "WebGPT: Browser-assisted question-answering with human feedback," delves into the development of a browser-assisted question-answering system that leverages human feedback to improve its performance. Both contributions highlight Jacob Hilton's active role in advancing AI and machine learning research, particularly in the areas of problem-solving and human-AI interaction.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="REIICHIRO NAKANO">
      <data key="d0">PERSON</data>
      <data key="d1">Reiichiro Nakano is one of the authors of two notable papers published on arXiv in 2021. The first paper, titled "Training verifiers to solve math word problems," explores methodologies for enhancing the capabilities of verifiers in solving mathematical word problems. The second paper, "WebGPT: Browser-assisted question-answering with human feedback," delves into the development of a question-answering system that leverages browser assistance and human feedback to improve its performance.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Training verifiers to solve math word problems" is authored by Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, and Reiichiro Nakano. It was published on arXiv in 2021.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ANTOINE CULLY">
      <data key="d0">PERSON</data>
      <data key="d1">Antoine Cully is one of the authors of the paper titled "Quality and diversity optimization: A unifying modular framework" published in IEEE Transactions on Evolutionary Computation in 2017</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YIANNIS DEMIRIS">
      <data key="d0">PERSON</data>
      <data key="d1">Yiannis Demiris is one of the authors of the paper titled "Quality and diversity optimization: A unifying modular framework" published in IEEE Transactions on Evolutionary Computation in 2017</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="QUALITY AND DIVERSITY OPTIMIZATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Quality and diversity optimization is a unifying modular framework described in a paper authored by Antoine Cully and Yiannis Demiris, published in IEEE Transactions on Evolutionary Computation in 2017</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="N. DALAL">
      <data key="d0">PERSON</data>
      <data key="d1">N. Dalal is one of the authors of the paper titled "Histograms of oriented gradients for human detection" published in the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="B. TRIGGS">
      <data key="d0">PERSON</data>
      <data key="d1">B. Triggs is one of the authors of the paper titled "Histograms of oriented gradients for human detection" published in the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="HISTOGRAMS OF ORIENTED GRADIENTS FOR HUMAN DETECTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Histograms of oriented gradients for human detection is a method described in a paper authored by N. Dalal and B. Triggs, published in the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="KALYANMOY DEB">
      <data key="d0">PERSON</data>
      <data key="d1">Kalyanmoy Deb is a prominent researcher in the field of evolutionary computation and multi-objective optimization. He is one of the authors of the influential paper titled "A fast and elitist multiobjective genetic algorithm: NSGA-II," published in IEEE Transactions on Evolutionary Computation in 2002. This work has significantly impacted the development of genetic algorithms. Additionally, Deb co-authored the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," which was presented at the Genetic and Evolutionary Computation Conference in 2019, showcasing his contributions to neural architecture search. More recently, in 2023, he co-authored the paper "Revisiting residual networks for adversarial robustness," published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, highlighting his ongoing research in enhancing the robustness of neural networks.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AMRIT PRATAP">
      <data key="d0">PERSON</data>
      <data key="d1">Amrit Pratap is one of the authors of the paper titled "A fast and elitist multiobjective genetic algorithm: NSGA-II" published in IEEE Transactions on Evolutionary Computation in 2002</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SAMEER AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Sameer Agarwal is one of the authors of the paper titled "A fast and elitist multiobjective genetic algorithm: NSGA-II" published in IEEE Transactions on Evolutionary Computation in 2002</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="TAMT MEYARIVAN">
      <data key="d0">PERSON</data>
      <data key="d1">TAMT Meyarivan is one of the authors of the paper titled "A fast and elitist multiobjective genetic algorithm: NSGA-II" published in IEEE Transactions on Evolutionary Computation in 2002</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="NSGA-II">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">NSGA-II is a fast and elitist multiobjective genetic algorithm described in a paper authored by Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan, published in IEEE Transactions on Evolutionary Computation in 2002</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="AARON DHARNA">
      <data key="d0">PERSON</data>
      <data key="d1">Aaron Dharna is one of the authors of the paper titled "Co-generation of game levels and game-playing agents" published in the Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JULIAN TOGELIUS">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Togelius is one of the authors of the paper titled "Co-generation of game levels and game-playing agents" published in the Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="LISA B SOROS">
      <data key="d0">PERSON</data>
      <data key="d1">Lisa B Soros is one of the authors of the paper titled "Co-generation of game levels and game-playing agents" published in the Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CO-GENERATION OF GAME LEVELS AND GAME-PLAYING AGENTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Co-generation of game levels and game-playing agents is a method described in a paper authored by Aaron Dharna, Julian Togelius, and Lisa B Soros, published in the Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SHUANG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Shuang Li is one of the authors of the paper titled "Improving factuality and reasoning in language models through multiagent debate" published on arXiv in 2023</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ANTONIO TORRALBA">
      <data key="d0">PERSON</data>
      <data key="d1">Antonio Torralba is one of the authors of the paper titled "Improving factuality and reasoning in language models through multiagent debate" published on arXiv in 2023</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JOSHUA B TENENBAUM">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua B Tenenbaum is one of the authors of the paper titled "Improving factuality and reasoning in language models through multiagent debate" published on arXiv in 2023</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="IGOR MORDATCH">
      <data key="d0">PERSON</data>
      <data key="d1">Igor Mordatch is one of the authors of the paper titled "Improving factuality and reasoning in language models through multiagent debate" published on arXiv in 2023</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="IMPROVING FACTUALITY AND REASONING IN LANGUAGE MODELS THROUGH MULTIAGENT DEBATE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Improving factuality and reasoning in language models through multiagent debate is a method described in a paper authored by Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch, published on arXiv in 2023</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="DHEERU DUA">
      <data key="d0">PERSON</data>
      <data key="d1">Dheeru Dua is one of the authors of the paper titled "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" published in the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YIZHONG WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yizhong Wang is one of the authors of the paper titled "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" published in the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PRADEEP DASIGI">
      <data key="d0">PERSON</data>
      <data key="d1">Pradeep Dasigi is one of the authors of the paper titled "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" published in the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GABRIEL STANOVSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Gabriel Stanovsky is one of the authors of the paper titled "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" published in the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SAMEER SINGH">
      <data key="d0">PERSON</data>
      <data key="d1">Sameer Singh is one of the authors of the paper titled "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" published in the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MATT GARDNER">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Gardner is one of the authors of the paper titled "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" published in the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHRISTY DORAN">
      <data key="d0">PERSON</data>
      <data key="d1">Christy Doran is one of the editors of the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="THAMAR SOLORIO">
      <data key="d0">PERSON</data>
      <data key="d1">Thamar Solorio is one of the editors of the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YAN DUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Yan Duan is one of the authors of the paper titled "RL^2: Fast reinforcement learning via slow reinforcement learning" published in the International Conference on Learning Representations in 2017</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JOHN SCHULMAN">
      <data key="d0">PERSON</data>
      <data key="d1">John Schulman is one of the authors of the paper titled "RL^2: Fast reinforcement learning via slow reinforcement learning" published in the International Conference on Learning Representations in 2017</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="XI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xi Chen is one of the authors of the paper titled "RL^2: Fast reinforcement learning via slow reinforcement learning" published in the International Conference on Learning Representations in 2017</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="PETER L. BARTLETT">
      <data key="d0">PERSON</data>
      <data key="d1">Peter L. Bartlett is one of the authors of the paper titled "RL^2: Fast reinforcement learning via slow reinforcement learning" published in the International Conference on Learning Representations in 2017</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="RL^2">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">RL^2 is a method for fast reinforcement learning via slow reinforcement learning, as described in a paper authored by Yan Duan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever, and Pieter Abbeel, published in the International Conference on Learning Representations in 2017</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JOEL LEHMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Joel Lehman is a prominent figure in the field of Artificial Intelligence and Machine Learning, known for his contributions to the understanding of open-endedness and novelty in AI. He co-authored the influential book "Why Greatness Cannot Be Planned: The Myth of the Objective," published by Springer in 2015, which challenges traditional goal-oriented approaches. Lehman has also authored several significant papers, including "Abandoning Objectives: Evolution through the Search for Novelty Alone" published in Evolutionary Computation in 2011, which explores the concept of novelty search in evolutionary algorithms. His recent work includes "Language Model Crossover: Variation through Few-Shot Prompting" published on arXiv in 2023, and "OMNI: Open-endedness via Models of Human Notions of Interestingness," presented at The Twelfth International Conference on Learning Representations in 2024. Additionally, he has addressed the balance between control and creativity in AI with his paper "Open Questions in Creating Safe Open-Ended AI: Tensions between Control and Creativity," published in the Conference on Artificial Life in 2020. Lehman also contributed to the development of the POET algorithm with the paper "POET: Open-Ended Coevolution of Environments and Their Optimized Solutions," presented at the Genetic and Evolutionary Computation Conference in 2019. His work continues to influence the AI and ML communities, particularly in the areas of open-endedness, novelty, and the interplay between control and creativity in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="OPEN QUESTIONS IN CREATING SAFE OPEN-ENDED AI">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper "Open questions in creating safe open-ended AI: Tensions between control and creativity" is authored by Adrien Ecoffet, Jeff Clune, and Joel Lehman, and was published in the Conference on Artificial Life in 2020</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="THOMAS ELSKEN">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Elsken is one of the authors of the paper titled "Neural architecture search: A survey" published in the Journal of Machine Learning Research in 2019</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JAN HENDRIK METZEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jan Hendrik Metzen is one of the authors of the paper titled "Neural architecture search: A survey" published in the Journal of Machine Learning Research in 2019</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="FRANK HUTTER">
      <data key="d0">PERSON</data>
      <data key="d1">Frank Hutter is a notable figure in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the book titled "Automated Machine Learning: Methods, Systems, Challenges," published by Springer Nature in 2019. Additionally, he co-authored the paper "Neural Architecture Search: A Survey," which was published in the Journal of Machine Learning Research in 2019. These contributions highlight his expertise and significant role in advancing the understanding and development of automated machine learning and neural architecture search.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MAXENCE FALDOR">
      <data key="d0">PERSON</data>
      <data key="d1">Maxence Faldor is one of the authors of the paper titled "Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code" published on arXiv in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHRISANTHA FERNANDO">
      <data key="d0">PERSON</data>
      <data key="d1">Chrisantha Fernando is one of the authors of the paper titled "Promptbreeder: Self-referential self-improvement via prompt evolution" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="DYLAN SUNIL BANARSE">
      <data key="d0">PERSON</data>
      <data key="d1">Dylan Sunil Banarse is one of the authors of the paper titled "Promptbreeder: Self-referential self-improvement via prompt evolution" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SIMON OSINDERO">
      <data key="d0">PERSON</data>
      <data key="d1">Simon Osindero is one of the authors of the paper titled "Promptbreeder: Self-referential self-improvement via prompt evolution" published in 2024</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="TIM ROCKT&#196;SCHEL">
      <data key="d0">PERSON</data>
      <data key="d1">Tim Rockt&#228;schel is a notable figure in the field of Artificial Intelligence. He is one of the authors of the influential paper titled "Promptbreeder: Self-referential self-improvement via prompt evolution," published in 2024. Additionally, he authored the book "Artificial Intelligence: 10 Things You Should Know," which was published by Seven Dials in September 2024. His contributions to AI literature highlight his expertise and thought leadership in the domain.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MODEL-AGNOSTIC META-LEARNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Model-agnostic meta-learning is a method for fast adaptation of deep networks, as described in a paper authored by Chelsea Finn, Pieter Abbeel, and Sergey Levine, published in the International Conference on Machine Learning in 2017</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="PAL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">PAL, or Program-aided language models, is a method described in a paper authored by Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig, published in the International Conference on Machine Learning in 2023</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="RYAN GREENBLATT">
      <data key="d0">PERSON</data>
      <data key="d1">Ryan Greenblatt is the author of the article titled "Getting 50% SOTA on ARC-AGI with GPT-4," published on Redwood Research Substack in July 2023. Additionally, Ryan Greenblatt authored a technical report with the same title, "Getting 50% SOTA on ARC-AGI with GPT-4," also published on Redwood Research Substack in July 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="GETTING 50% SOTA ON ARC-AGI WITH GPT-4">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The article "Getting 50% SOTA on ARC-AGI with GPT-4" is authored by Ryan Greenblatt and was published on Redwood Research Substack in July 2023</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="INTERNATIONAL CONFERENCE ON MACHINE LEARNING">
      <data key="d0">EVENT</data>
      <data key="d1">The International Conference on Machine Learning is an event where the paper "Pal: Program-aided language models" was published in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="REDWOOD RESEARCH SUBSTACK">
      <data key="d0">PLATFORM</data>
      <data key="d1">Redwood Research Substack is the platform where Ryan Greenblatt published the technical report "Getting 50% sota on arc-agi with gpt-4" in July 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PLATFORM</data>
    </node>
    <node id="DAN HENDRYCKS">
      <data key="d0">PERSON</data>
      <data key="d1">Dan Hendrycks is a notable researcher in the field of Artificial Intelligence and Machine Learning. In 2021, he co-authored two significant papers. The first, titled "Measuring massive multitask language understanding," was published in the International Conference on Learning Representations. The second, "Measuring mathematical problem solving with the math dataset," was published on arXiv. These contributions highlight his involvement in advancing the understanding and evaluation of AI capabilities in both language and mathematical problem-solving domains.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="COLLIN BURNS">
      <data key="d0">PERSON</data>
      <data key="d1">Collin Burns is a notable researcher in the field of Artificial Intelligence and Machine Learning. In 2021, he co-authored two significant papers: "Measuring massive multitask language understanding," which was published in the International Conference on Learning Representations, and "Measuring mathematical problem solving with the math dataset," which was published on arXiv. These contributions highlight his expertise in evaluating complex language models and mathematical problem-solving capabilities within AI systems.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="STEVEN BASART">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Basart is one of the authors of two notable papers published in 2021. The first paper, titled "Measuring massive multitask language understanding," was presented at the International Conference on Learning Representations. The second paper, "Measuring mathematical problem solving with the math dataset," was published on arXiv. Both works contribute to the fields of language understanding and mathematical problem-solving, showcasing Steven Basart's involvement in advancing research in these areas.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANDY ZOU">
      <data key="d0">PERSON</data>
      <data key="d1">Andy Zou is one of the authors of the paper titled "Measuring massive multitask language understanding" published in the International Conference on Learning Representations in 2021</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MANTAS MAZEIKA">
      <data key="d0">PERSON</data>
      <data key="d1">Mantas Mazeika is one of the authors of the paper titled "Measuring massive multitask language understanding" published in the International Conference on Learning Representations in 2021</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JACOB STEINHARDT">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Steinhardt is a notable researcher in the field of Artificial Intelligence and Machine Learning. In 2021, he co-authored two significant papers: "Measuring massive multitask language understanding," which was published in the International Conference on Learning Representations, and "Measuring mathematical problem solving with the math dataset," which was published on arXiv. These contributions highlight his involvement in advancing the understanding of language processing and mathematical problem-solving within the AI and ML communities.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">EVENT</data>
      <data key="d1">The International Conference on Learning Representations is an event where the paper "Measuring massive multitask language understanding" was published in 2021</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="SIRUI HONG">
      <data key="d0">PERSON</data>
      <data key="d1">Sirui Hong is one of the authors of the paper titled "Metagpt: Meta programming for multi-agent collaborative framework" published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIAWU ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiawu Zheng is one of the authors of the paper titled "Metagpt: Meta programming for multi-agent collaborative framework" published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JONATHAN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Chen is one of the authors of the paper titled "Metagpt: Meta programming for multi-agent collaborative framework" published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUHENG CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuheng Cheng is one of the authors of the paper titled "Metagpt: Meta programming for multi-agent collaborative framework" published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JINLIN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jinlin Wang is one of the authors of the paper titled "Metagpt: Meta programming for multi-agent collaborative framework" published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CEYAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ceyao Zhang is one of the authors of the paper titled "Metagpt: Meta programming for multi-agent collaborative framework" published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZILI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zili Wang is one of the authors of the paper titled "Metagpt: Meta programming for multi-agent collaborative framework" published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="STEVEN KA SHING YAU">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Ka Shing Yau is one of the authors of the paper titled "Metagpt: Meta programming for multi-agent collaborative framework" published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZIJUAN LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Zijuan Lin is one of the authors of the paper titled "Metagpt: Meta programming for multi-agent collaborative framework" published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LIYANG ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Liyang Zhou is one of the authors of the paper titled "Metagpt: Meta programming for multi-agent collaborative framework" published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="METAGPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">MetaGPT is a meta programming framework for multi-agent collaboration, as described in a paper published on arXiv in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="RAN CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Ran Cheng is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHENG HE">
      <data key="d0">PERSON</data>
      <data key="d1">Cheng He is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHICHAO LU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhichao Lu is a notable researcher in the field of neural architecture search. He co-authored the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation," which was published in Complex &amp; Intelligent Systems in 2021. Additionally, he contributed to the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," presented at the Proceedings of the Genetic and Evolutionary Computation Conference in 2019. His work focuses on leveraging multi-objective optimization techniques to enhance the efficiency and effectiveness of neural architecture search methodologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JING WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jing Wang is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MIAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Miao Zhang is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="COMPLEX &amp; INTELLIGENT SYSTEMS">
      <data key="d0">JOURNAL</data>
      <data key="d1">Complex &amp; Intelligent Systems is the journal where the paper "Accelerating multi-objective neural architecture search by random-weight evaluation" was published in 2021</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">JOURNAL</data>
    </node>
    <node id="SHIHUA HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shihua Huang is one of the authors of the paper titled "Revisiting residual networks for adversarial robustness" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VISHNU NARESH BODDETI">
      <data key="d0">PERSON</data>
      <data key="d1">Vishnu Naresh Boddeti is one of the authors of the paper titled "Revisiting residual networks for adversarial robustness" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PROCEEDINGS OF THE IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION">
      <data key="d0">EVENT</data>
      <data key="d1">The Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition is an event where the paper "Revisiting residual networks for adversarial robustness" was published in 2023</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="LARS KOTTHOFF">
      <data key="d0">PERSON</data>
      <data key="d1">Lars Kotthoff is one of the authors of the book titled "Automated machine learning: methods, systems, challenges" published by Springer Nature in 2019</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOAQUIN VANSCHOREN">
      <data key="d0">PERSON</data>
      <data key="d1">Joaquin Vanschoren is one of the authors of the book titled "Automated machine learning: methods, systems, challenges" published by Springer Nature in 2019</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SPRINGER NATURE">
      <data key="d0">PUBLISHER</data>
      <data key="d1">Springer Nature is the publisher of the book titled "Automated machine learning: methods, systems, challenges" published in 2019</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PUBLISHER</data>
    </node>
    <node id="OMAR KHATTAB">
      <data key="d0">PERSON</data>
      <data key="d1">Omar Khattab is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ARNAV SINGHVI">
      <data key="d0">PERSON</data>
      <data key="d1">Arnav Singhvi is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PARIDHI MAHESHWARI">
      <data key="d0">PERSON</data>
      <data key="d1">Paridhi Maheshwari is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHIYUAN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Zhang is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KESHAV SANTHANAM">
      <data key="d0">PERSON</data>
      <data key="d1">Keshav Santhanam is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAIFUL HAQ">
      <data key="d0">PERSON</data>
      <data key="d1">Saiful Haq is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ASHUTOSH SHARMA">
      <data key="d0">PERSON</data>
      <data key="d1">Ashutosh Sharma is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="THOMAS T JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas T Joshi is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HANNA MOAZAM">
      <data key="d0">PERSON</data>
      <data key="d1">Hanna Moazam is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HEATHER MILLER">
      <data key="d0">PERSON</data>
      <data key="d1">Heather Miller is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEX KRIZHEVSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Krizhevsky is one of the authors of the paper titled "Imagenet classification with deep convolutional neural networks" published in Advances in Neural Information Processing Systems in 2012</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GEOFFREY E HINTON">
      <data key="d0">PERSON</data>
      <data key="d1">Geoffrey E Hinton is one of the authors of the paper titled "Imagenet classification with deep convolutional neural networks" published in Advances in Neural Information Processing Systems in 2012</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="IMAGENET CLASSIFICATION WITH DEEP CONVOLUTIONAL NEURAL NETWORKS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Imagenet classification with deep convolutional neural networks" was published in Advances in Neural Information Processing Systems in 2012</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="ABRAHIM LADHA">
      <data key="d0">PERSON</data>
      <data key="d1">Abrahim Ladha is the author of the lecture titled "Lecture 11: Turing-completeness" published on the Georgia Tech faculty website in February 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GEORGIA TECH FACULTY WEBSITE">
      <data key="d0">PLATFORM</data>
      <data key="d1">The Georgia Tech faculty website is the platform where Abrahim Ladha published the lecture titled "Lecture 11: Turing-completeness" in February 2024</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PLATFORM</data>
    </node>
    <node id="KENNETH O STANLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Kenneth O. Stanley is a notable figure in the field of Artificial Intelligence and Machine Learning. He co-authored the influential book "Why Greatness Cannot Be Planned: The Myth of the Objective," published by Springer in 2015. Additionally, he contributed to the significant paper "Abandoning Objectives: Evolution Through the Search for Novelty Alone," which was published in the journal Evolutionary Computation in 2011. Stanley's work often challenges conventional approaches, advocating for the exploration of novelty over rigid objectives in evolutionary computation and AI research.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="EVOLUTIONARY COMPUTATION">
      <data key="d0">JOURNAL</data>
      <data key="d1">Evolutionary Computation is the journal where the paper titled "Abandoning objectives: Evolution through the search for novelty alone" was published in 2011</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">JOURNAL</data>
    </node>
    <node id="PATRICK LEWIS">
      <data key="d0">PERSON</data>
      <data key="d1">Patrick Lewis is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ETHAN PEREZ">
      <data key="d0">PERSON</data>
      <data key="d1">Ethan Perez is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEKSANDRA PIKTUS">
      <data key="d0">PERSON</data>
      <data key="d1">Aleksandra Piktus is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FABIO PETRONI">
      <data key="d0">PERSON</data>
      <data key="d1">Fabio Petroni is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VLADIMIR KARPUKHIN">
      <data key="d0">PERSON</data>
      <data key="d1">Vladimir Karpukhin is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="THE AI SCIENTIST">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The AI Scientist is a preprint titled "Towards fully automated open-ended scientific discovery" published on arXiv in 2024</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="IAN WHALEN">
      <data key="d0">PERSON</data>
      <data key="d1">Ian Whalen is one of the authors of the paper titled "Nsga-net: neural architecture search using multi-objective genetic algorithm" published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VISHNU BODDETI">
      <data key="d0">PERSON</data>
      <data key="d1">Vishnu Boddeti is one of the authors of the paper titled "Nsga-net: neural architecture search using multi-objective genetic algorithm" published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YASHESH DHEBAR">
      <data key="d0">PERSON</data>
      <data key="d1">Yashesh Dhebar is one of the authors of the paper titled "Nsga-net: neural architecture search using multi-objective genetic algorithm" published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ERIK GOODMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Erik Goodman is one of the authors of the paper titled "Nsga-net: neural architecture search using multi-objective genetic algorithm" published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WOLFGANG BANZHAF">
      <data key="d0">PERSON</data>
      <data key="d1">Wolfgang Banzhaf is one of the authors of the paper titled "Nsga-net: neural architecture search using multi-objective genetic algorithm" published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NSGA-NET">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Nsga-net is a neural architecture search method using a multi-objective genetic algorithm described in a paper published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="YECHENG JASON MA">
      <data key="d0">PERSON</data>
      <data key="d1">Yecheng Jason Ma is one of the authors of the paper titled "Eureka: Human-level reward design via coding large language models" published in the Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WILLIAM LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">William Liang is one of the authors of the paper titled "Eureka: Human-level reward design via coding large language models" published in the Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OSBERT BASTANI">
      <data key="d0">PERSON</data>
      <data key="d1">Osbert Bastani is one of the authors of the paper titled "Eureka: Human-level reward design via coding large language models" published in the Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DINESH JAYARAMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Dinesh Jayaraman is one of the authors of the paper titled "Eureka: Human-level reward design via coding large language models" published in the Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OPEN SOURCE AI IS THE PATH FORWARD">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Open source AI is the path forward is a news article published by Meta in July 2024</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="ELLIOT MEYERSON">
      <data key="d0">PERSON</data>
      <data key="d1">Elliot Meyerson is one of the authors of the paper titled "Language model crossover: Variation through few-shot prompting" published on arXiv in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MARK J NELSON">
      <data key="d0">PERSON</data>
      <data key="d1">Mark J Nelson is one of the authors of the paper titled "Language model crossover: Variation through few-shot prompting" published on arXiv in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HERBIE BRADLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Herbie Bradley is one of the authors of the paper titled "Language model crossover: Variation through few-shot prompting" published on arXiv in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ADAM GAIER">
      <data key="d0">PERSON</data>
      <data key="d1">Adam Gaier is one of the authors of the paper titled "Language model crossover: Variation through few-shot prompting" published on arXiv in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ARASH MORADI">
      <data key="d0">PERSON</data>
      <data key="d1">Arash Moradi is one of the authors of the paper titled "Language model crossover: Variation through few-shot prompting" published on arXiv in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AMY K HOOVER">
      <data key="d0">PERSON</data>
      <data key="d1">Amy K Hoover is one of the authors of the paper titled "Language model crossover: Variation through few-shot prompting" published on arXiv in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LANGUAGE MODEL CROSSOVER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Language model crossover is a method for variation through few-shot prompting described in a paper published on arXiv in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="SHEN-YUN MIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Shen-yun Miao is one of the authors of the paper titled "A diverse corpus for evaluating and developing English math word problem solvers" published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHAO-CHUN LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chao-Chun Liang is one of the authors of the paper titled "A diverse corpus for evaluating and developing English math word problem solvers" published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KEH-YIH SU">
      <data key="d0">PERSON</data>
      <data key="d1">Keh-Yih Su is one of the authors of the paper titled "A diverse corpus for evaluating and developing English math word problem solvers" published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="A DIVERSE CORPUS FOR EVALUATING AND DEVELOPING ENGLISH MATH WORD PROBLEM SOLVERS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A diverse corpus for evaluating and developing English math word problem solvers is a paper published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="JEAN-BAPTISTE MOURET">
      <data key="d0">PERSON</data>
      <data key="d1">Jean-Baptiste Mouret is one of the authors of the paper titled "Illuminating search spaces by mapping elites" published on arXiv in 2015</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ILLUMINATING SEARCH SPACES BY MAPPING ELITES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Illuminating search spaces by mapping elites is a paper published on arXiv in 2015</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="JEFF WU">
      <data key="d0">PERSON</data>
      <data key="d1">Jeff Wu is one of the authors of the paper titled "WebGPT: Browser-assisted question-answering with human feedback" published on arXiv in 2021</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LONG OUYANG">
      <data key="d0">PERSON</data>
      <data key="d1">Long Ouyang is one of the authors of the paper titled "WebGPT: Browser-assisted question-answering with human feedback" published on arXiv in 2021</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHRISTINA KIM">
      <data key="d0">PERSON</data>
      <data key="d1">Christina Kim is one of the authors of the paper titled "WebGPT: Browser-assisted question-answering with human feedback" published on arXiv in 2021</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHRISTOPHER HESSE">
      <data key="d0">PERSON</data>
      <data key="d1">Christopher Hesse is one of the authors of the paper titled "WebGPT: Browser-assisted question-answering with human feedback" published on arXiv in 2021</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WILLIAM SAUNDERS">
      <data key="d0">PERSON</data>
      <data key="d1">William Saunders is one of the authors of the paper titled "WebGPT: Browser-assisted question-answering with human feedback" published on arXiv in 2021</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WEBGPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">WebGPT is a system for browser-assisted question-answering with human feedback described in a paper published on arXiv in 2021</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ANDREW NG">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Ng is the author of the newsletter issue titled "Issue 253" published on the DeepLearning.AI website in June 2024</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ISSUE 253">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Issue 253 is a newsletter issue authored by Andrew Ng and published on the DeepLearning.AI website in June 2024</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="BEN NORMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ben Norman is one of the authors of the paper titled "First-explore, then exploit: Meta-learning intelligent exploration" published on arXiv in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FIRST-EXPLORE, THEN EXPLOIT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">First-explore, then exploit is a method for meta-learning intelligent exploration described in a paper published on arXiv in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="INTRODUCING CHATGPT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Introducing ChatGPT is a blog post published by OpenAI in November 2022</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="SIMPLE EVALS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Simple evals is a system described by OpenAI and accessible via GitHub as of August 2024</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="JOON SUNG PARK">
      <data key="d0">PERSON</data>
      <data key="d1">Joon Sung Park is one of the authors of the paper titled "Generative agents: Interactive simulacra of human behavior" published in the Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOSEPH O(&quot;ENTITY&quot;">
      <data key="d0">SHRAN HU</data>
      <data key="d1">PERSON</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="JOSEPH O'BRIEN">
      <data key="d0">PERSON</data>
      <data key="d1">Joseph O'Brien is one of the authors of the paper titled "Generative agents: Interactive simulacra of human behavior" published in the Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="CARRIE JUN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Carrie Jun Cai is one of the authors of the paper titled "Generative agents: Interactive simulacra of human behavior" published in the Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="MEREDITH RINGEL MORRIS">
      <data key="d0">PERSON</data>
      <data key="d1">Meredith Ringel Morris is one of the authors of the paper titled "Generative agents: Interactive simulacra of human behavior" published in the Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology in 2023</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="PERCY LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Percy Liang is a prolific researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of several significant papers, including "Alpaca" published on arXiv, "Alpacaeval: An automatic evaluator of instruction-following models" published in 2023, and "Generative agents: Interactive simulacra of human behavior" presented at the 36th Annual ACM Symposium on User Interface Software and Technology in 2023. His work spans various aspects of AI, from developing evaluation tools for instruction-following models to exploring interactive simulacra of human behavior, showcasing his diverse expertise and contributions to the field.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="QIANG WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Qiang Wang is one of the authors of the paper titled "Tool learning with large language models: A survey" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DAWEI YIN">
      <data key="d0">PERSON</data>
      <data key="d1">Dawei Yin is one of the authors of the paper titled "Tool learning with large language models: A survey" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JUN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Jun Xu is one of the authors of the paper titled "Tool learning with large language models: A survey" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JI-RONG WEN">
      <data key="d0">PERSON</data>
      <data key="d1">Ji-Rong Wen is one of the authors of two notable papers published on arXiv in 2024. The first paper is titled "A survey on the memory mechanism of large language model based agents," and the second paper is titled "Tool learning with large language models: A survey." Both papers contribute to the understanding and advancement of large language models, focusing on their memory mechanisms and tool learning capabilities, respectively.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RAFAEL RAFAILOV">
      <data key="d0">PERSON</data>
      <data key="d1">Rafael Rafailov is one of the authors of the paper titled "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARCHIT SHARMA">
      <data key="d0">PERSON</data>
      <data key="d1">Archit Sharma is one of the authors of the paper titled "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ERIC MITCHELL">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Mitchell is one of the authors of the paper titled "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="STEFANO ERMON">
      <data key="d0">PERSON</data>
      <data key="d1">Stefano Ermon is one of the authors of the paper titled "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DAVID REIN">
      <data key="d0">PERSON</data>
      <data key="d1">David Rein is one of the authors of the paper titled "Gpqa: A graduate-level google-proof Q&amp;A benchmark" published in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BETTY LI HOU">
      <data key="d0">PERSON</data>
      <data key="d1">Betty Li Hou is one of the authors of the paper titled "Gpqa: A graduate-level google-proof Q&amp;A benchmark" published in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ASA COOPER STICKLAND">
      <data key="d0">PERSON</data>
      <data key="d1">Asa Cooper Stickland is one of the authors of the paper titled "Gpqa: A graduate-level google-proof Q&amp;A benchmark" published in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JACKSON PETTY">
      <data key="d0">PERSON</data>
      <data key="d1">Jackson Petty is one of the authors of the paper titled "Gpqa: A graduate-level google-proof Q&amp;A benchmark" published in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RICHARD YUANZHE PANG">
      <data key="d0">PERSON</data>
      <data key="d1">Richard Yuanzhe Pang is one of the authors of the paper titled "Gpqa: A graduate-level google-proof Q&amp;A benchmark" published in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JULIEN DIRANI">
      <data key="d0">PERSON</data>
      <data key="d1">Julien Dirani is one of the authors of the paper titled "Gpqa: A graduate-level google-proof Q&amp;A benchmark" published in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JULIAN MICHAEL">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Michael is one of the authors of the paper titled "Gpqa: A graduate-level google-proof Q&amp;A benchmark" published in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SAMUEL R. BOWMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Samuel R. Bowman is one of the authors of the paper titled "Gpqa: A graduate-level google-proof Q&amp;A benchmark" published in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TORAN BRUCE RICHARDS">
      <data key="d0">PERSON</data>
      <data key="d1">Toran Bruce Richards is the author of the project "AutoGPT" available on GitHub in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AUTOGPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AutoGPT is a project available on GitHub, created by Toran Bruce Richards in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE: 10 THINGS YOU SHOULD KNOW">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Artificial Intelligence: 10 Things You Should Know is a book authored by Tim Rockt&#228;schel and published by Seven Dials in September 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MD OMAR FARUK ROKON">
      <data key="d0">PERSON</data>
      <data key="d1">Md Omar Faruk Rokon is one of the authors of the paper titled "SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RISUL ISLAM">
      <data key="d0">PERSON</data>
      <data key="d1">Risul Islam is one of the authors of the paper titled "SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AHMAD DARKI">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmad Darki is one of the authors of the paper titled "SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="EVANGELOS E PAPALEXAKIS">
      <data key="d0">PERSON</data>
      <data key="d1">Evangelos E Papalexakis is one of the authors of the paper titled "SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MICHALIS FALOUTSOS">
      <data key="d0">PERSON</data>
      <data key="d1">Michalis Faloutsos is one of the authors of the paper titled "SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SOURCEFINDER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">SourceFinder is a system designed to find malware source code from publicly available repositories in GitHub, as described in a paper published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BERNARDINO ROMERA-PAREDES">
      <data key="d0">PERSON</data>
      <data key="d1">Bernardino Romera-Paredes is one of the authors of the paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MOHAMMADAMIN BAREKATAIN">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammadamin Barekatain is one of the authors of the paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ALEXANDER NOVIKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Alexander Novikov is one of the authors of the paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATEJ BALOG">
      <data key="d0">PERSON</data>
      <data key="d1">Matej Balog is one of the authors of the paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="M PAWAN KUMAR">
      <data key="d0">PERSON</data>
      <data key="d1">M Pawan Kumar is one of the authors of the paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="EMILIEN DUPONT">
      <data key="d0">PERSON</data>
      <data key="d1">Emilien Dupont is one of the authors of the paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FRANCISCO JR RUIZ">
      <data key="d0">PERSON</data>
      <data key="d1">Francisco JR Ruiz is one of the authors of the paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JORDAN S ELLENBERG">
      <data key="d0">PERSON</data>
      <data key="d1">Jordan S Ellenberg is one of the authors of the paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="PENGMING WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Pengming Wang is one of the authors of the paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="OMAR FAWZI">
      <data key="d0">PERSON</data>
      <data key="d1">Omar Fawzi is one of the authors of the paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATHEMATICAL DISCOVERIES FROM PROGRAM SEARCH WITH LARGE LANGUAGE MODELS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Mathematical discoveries from program search with large language models" was published in Nature in 2024 and authored by Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang, and Omar Fawzi</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ERIC HAMBRO">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Hambro is one of the authors of the paper titled "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SANDER SCHULHOFF">
      <data key="d0">PERSON</data>
      <data key="d1">Sander Schulhoff is one of the authors of the paper titled "The prompt report: A systematic survey of prompting techniques" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MICHAEL ILIE">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Ilie is one of the authors of the paper titled "The prompt report: A systematic survey of prompting techniques" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NISHANT BALEPUR">
      <data key="d0">PERSON</data>
      <data key="d1">Nishant Balepur is one of the authors of the paper titled "The prompt report: A systematic survey of prompting techniques" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="KONSTANTINE KAHADZE">
      <data key="d0">PERSON</data>
      <data key="d1">Konstantine Kahadze is one of the authors of the paper titled "The prompt report: A systematic survey of prompting techniques" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AMANDA LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Amanda Liu is one of the authors of the paper titled "The prompt report: A systematic survey of prompting techniques" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHENGLEI SI">
      <data key="d0">PERSON</data>
      <data key="d1">Chenglei Si is one of the authors of the paper titled "The prompt report: A systematic survey of prompting techniques" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YINHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yinheng Li is one of the authors of the paper titled "The prompt report: A systematic survey of prompting techniques" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AAYUSH GUPTA">
      <data key="d0">PERSON</data>
      <data key="d1">Aayush Gupta is one of the authors of the paper titled "The prompt report: A systematic survey of prompting techniques" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HYOJUNG HAN">
      <data key="d0">PERSON</data>
      <data key="d1">HyoJung Han is one of the authors of the paper titled "The prompt report: A systematic survey of prompting techniques" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SEVIEN SCHULHOFF">
      <data key="d0">PERSON</data>
      <data key="d1">Sevien Schulhoff is one of the authors of the paper titled "The prompt report: A systematic survey of prompting techniques" published on arXiv in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="THE PROMPT REPORT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "The prompt report: A systematic survey of prompting techniques" was published on arXiv in 2024 and authored by Sander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, Aayush Gupta, HyoJung Han, and Sevien Schulhoff</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="XUAN SHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xuan Shen is one of the authors of the paper titled "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YAOHUA WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yaohua Wang is one of the authors of the paper titled "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MING LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Ming Lin is one of the authors of the paper titled "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YILUN HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yilun Huang is one of the authors of the paper titled "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HAO TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Tang is one of the authors of the paper titled "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="XIUYU SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Xiuyu Sun is one of the authors of the paper titled "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YANZHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yanzhi Wang is one of the authors of the paper titled "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DEEPMAD">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Deepmad is a system for mathematical architecture design for deep convolutional neural networks, as described in a paper published in the Proceedings of the IEEE/CVF</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RAID 2020">
      <data key="d0">EVENT</data>
      <data key="d1">The 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020) is an event where the paper "SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub" was published</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d0">EVENT</data>
      <data key="d1">Advances in Neural Information Processing Systems is a conference where the paper "Direct preference optimization: Your language model is secretly a reward model" was published in 2024</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION">
      <data key="d0">EVENT</data>
      <data key="d1">The IEEE/CVF Conference on Computer Vision and Pattern Recognition is an event where the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" was published in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="THE ELEVENTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">EVENT</data>
      <data key="d1">The Eleventh International Conference on Learning Representations is an event where the paper "Language models are multilingual chain-of-thought reasoners" was published in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FREDA SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Freda Shi is one of the authors of the paper titled "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MIRAC SUZGUN">
      <data key="d0">PERSON</data>
      <data key="d1">Mirac Suzgun is a notable researcher in the field of Artificial Intelligence and Machine Learning. He co-authored the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," which was published in 2022. Additionally, he contributed to the paper "Language models are multilingual chain-of-thought reasoners," presented at The Eleventh International Conference on Learning Representations in 2023. These works highlight his involvement in exploring the capabilities and reasoning processes of language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MARKUS FREITAG">
      <data key="d0">PERSON</data>
      <data key="d1">Markus Freitag is one of the authors of the paper titled "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SURAJ SRIVATS">
      <data key="d0">PERSON</data>
      <data key="d1">Suraj Srivats is one of the authors of the paper titled "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SOROUSH VOSOUGHI">
      <data key="d0">PERSON</data>
      <data key="d1">Soroush Vosoughi is one of the authors of the paper titled "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YI TAY">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Tay is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022. Additionally, Yi Tay co-authored the paper "Language models are multilingual chain-of-thought reasoners," which was presented at The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SEBASTIAN RUDER">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Ruder is one of the authors of the paper titled "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DIPANJAN DAS">
      <data key="d0">PERSON</data>
      <data key="d1">Dipanjan Das is one of the authors of the paper titled "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SPRINGER">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Springer is the publisher of the book titled "Why greatness cannot be planned: The myth of the objective" authored by Kenneth O Stanley and Joel Lehman in 2015</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RISTO MIIKKULAINEN">
      <data key="d0">PERSON</data>
      <data key="d1">Risto Miikkulainen is one of the authors of the paper titled "Designing neural networks through neuroevolution" published in Nature Machine Intelligence in 2019</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NATURE MACHINE INTELLIGENCE">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Nature Machine Intelligence is a journal where the paper titled "Designing neural networks through neuroevolution" was published in 2019</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RICHARD S SUTTON">
      <data key="d0">PERSON</data>
      <data key="d1">Richard S Sutton is one of the authors of the book titled "Reinforcement learning: An introduction" published by MIT Press in 2018</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ANDREW G BARTO">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew G Barto is one of the authors of the book titled "Reinforcement learning: An introduction" published by MIT Press in 2018</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MIT PRESS">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">MIT Press is the publisher of the book titled "Reinforcement learning: An introduction" authored by Richard S Sutton and Andrew G Barto in 2018</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SAI VEMPRALA">
      <data key="d0">PERSON</data>
      <data key="d1">Sai Vemprala is one of the authors of the technical report titled "ChatGPT for robotics: Design principles and model abilities" published by Microsoft in February 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROGERIO BONATTI">
      <data key="d0">PERSON</data>
      <data key="d1">Rogerio Bonatti is one of the authors of the technical report titled "ChatGPT for robotics: Design principles and model abilities" published by Microsoft in February 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARTHUR BUCKER">
      <data key="d0">PERSON</data>
      <data key="d1">Arthur Bucker is one of the authors of the technical report titled "ChatGPT for robotics: Design principles and model abilities" published by Microsoft in February 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ASHISH KAPOOR">
      <data key="d0">PERSON</data>
      <data key="d1">Ashish Kapoor is one of the authors of the technical report titled "ChatGPT for robotics: Design principles and model abilities" published by Microsoft in February 2023</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JANE X WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jane X Wang is one of the authors of the paper titled "Learning to reinforcement learn" published on arXiv in 2016</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZEB KURTH-NELSON">
      <data key="d0">PERSON</data>
      <data key="d1">Zeb Kurth-Nelson is one of the authors of the paper titled "Learning to reinforcement learn" published on arXiv in 2016</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DHRUVA TIRUMALA">
      <data key="d0">PERSON</data>
      <data key="d1">Dhruva Tirumala is one of the authors of the paper titled "Learning to reinforcement learn" published on arXiv in 2016</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HUBERT SOYER">
      <data key="d0">PERSON</data>
      <data key="d1">Hubert Soyer is one of the authors of the paper titled "Learning to reinforcement learn" published on arXiv in 2016</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JOEL Z LEIBO">
      <data key="d0">PERSON</data>
      <data key="d1">Joel Z Leibo is one of the authors of the paper titled "Learning to reinforcement learn" published on arXiv in 2016</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="REMI MUNOS">
      <data key="d0">PERSON</data>
      <data key="d1">Remi Munos is one of the authors of the paper titled "Learning to reinforcement learn" published on arXiv in 2016</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHARLES BLUNDELL">
      <data key="d0">PERSON</data>
      <data key="d1">Charles Blundell is one of the authors of the paper titled "Learning to reinforcement learn" published on arXiv in 2016</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DHARSHAN KUMARAN">
      <data key="d0">PERSON</data>
      <data key="d1">Dharshan Kumaran is one of the authors of the paper titled "Learning to reinforcement learn" published on arXiv in 2016</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATT BOTVINICK">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Botvinick is one of the authors of the paper titled "Learning to reinforcement learn" published on arXiv in 2016</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LEI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Lei Wang is one of the authors of the paper titled "A survey on large language model based autonomous agents," which was published in Frontiers of Computer Science in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHEN MA">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Ma is an author of two notable papers published in 2024. One paper, titled "A survey on large language model based autonomous agents," was published in Frontiers of Computer Science. The other paper, titled "A survey on the memory mechanism of large language model based agents," was published on arXiv.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XUEYANG FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xueyang Feng is one of the authors of the paper titled "A survey on large language model based autonomous agents," which was published in Frontiers of Computer Science in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZEYU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zeyu Zhang is an author of two notable papers published in 2024. One paper, titled "A survey on large language model based autonomous agents," was published in Frontiers of Computer Science. The other paper, titled "A survey on the memory mechanism of large language model based agents," was published on arXiv.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="HAO YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Yang is one of the authors of the paper titled "A survey on large language model based autonomous agents," which was published in Frontiers of Computer Science in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JINGSEN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jingsen Zhang is one of the authors of the paper titled "A survey on large language model based autonomous agents," which was published in Frontiers of Computer Science in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZHIYUAN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Chen is one of the authors of the paper titled "A survey on large language model based autonomous agents," which was published in Frontiers of Computer Science in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JIAKAI TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiakai Tang is one of the authors of the paper titled "A survey on large language model based autonomous agents," which was published in Frontiers of Computer Science in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="XU CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xu Chen is one of the authors of the paper titled "A survey on large language model based autonomous agents" published in Frontiers of Computer Science in 2024. Additionally, Xu Chen contributed to the paper "A survey on the memory mechanism of large language model based agents" published on arXiv in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="FRONTIERS OF COMPUTER SCIENCE">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Frontiers of Computer Science is a journal where the paper titled "A survey on large language model based autonomous agents" was published</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SHAN KUMARAN">
      <data key="d0">PERSON</data>
      <data key="d1">Shan Kumaran is one of the authors of the paper titled "Learning to reinforcement learn" published on arXiv in 2016</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RUI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Rui Wang is one of the authors of the paper titled "Poet: open-ended coevolution of environments and their optimized solutions" published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KENNETH O. STANLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Kenneth O. Stanley is one of the authors of the paper titled "Poet: open-ended coevolution of environments and their optimized solutions" published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ADITYA RAWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Aditya Rawal is one of the authors of the paper titled "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions" published in the International Conference on Machine Learning in 2020</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIALE ZHI">
      <data key="d0">PERSON</data>
      <data key="d1">Jiale Zhi is one of the authors of the paper titled "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions" published in the International Conference on Machine Learning in 2020</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YULUN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yulun Li is one of the authors of the paper titled "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions" published in the International Conference on Machine Learning in 2020</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QUOC V LE">
      <data key="d0">PERSON</data>
      <data key="d1">Quoc V Le is a prolific researcher in the field of Artificial Intelligence and Machine Learning, contributing significantly to the advancement of language models. He is one of the authors of several influential papers, including "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022, "Self-consistency improves chain of thought reasoning in language models" presented at The Eleventh International Conference on Learning Representations in 2023, "Take a step back: Evoking reasoning via abstraction in large language models" published on arXiv in 2023, and "Self-discover: Large language models self-compose reasoning structures" published on arXiv in 2024. His work focuses on enhancing the reasoning capabilities of large language models through innovative approaches such as chain-of-thought reasoning and self-composition of reasoning structures.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ED H. CHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ed H. Chi is one of the authors of the paper titled "Self-consistency improves chain of thought reasoning in language models" published in The Eleventh International Conference on Learning Representations in 2023</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QINGYUN WU">
      <data key="d0">PERSON</data>
      <data key="d1">Qingyun Wu is one of the authors of the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework" published on arXiv in 2023. Additionally, Qingyun Wu co-authored another paper titled "Offline training of language model agents with functions as learnable weights," which was presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GAGAN BANSAL">
      <data key="d0">PERSON</data>
      <data key="d1">Gagan Bansal is one of the authors of the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," published on arXiv in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIEYU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jieyu Zhang is an author of multiple significant papers in the field of Artificial Intelligence and Machine Learning. In 2023, Jieyu Zhang co-authored the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," which was published on arXiv. Additionally, Jieyu Zhang contributed to another paper with a similar title, "Autogen: Enabling next-gen llm applications via multi-agent conversation," also published in 2023. Furthermore, Jieyu Zhang co-authored the paper "Offline training of language model agents with functions as learnable weights," which was presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIRAN WU">
      <data key="d0">PERSON</data>
      <data key="d1">Yiran Wu is one of the authors of the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," published on arXiv in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHAOKUN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shaokun Zhang is a notable author in the field of Artificial Intelligence and Machine Learning. Zhang co-authored the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," which was published on arXiv in 2023. Additionally, Zhang contributed to the paper "Offline training of language model agents with functions as learnable weights," presented at the Forty-first International Conference on Machine Learning in 2024. These works highlight Zhang's involvement in advancing language model applications and multi-agent conversation frameworks.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ERKANG ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Erkang Zhu is one of the authors of the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," published on arXiv in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BEIBIN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Beibin Li is one of the authors of the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," published on arXiv in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LI JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Li Jiang is one of the authors of the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," published on arXiv in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIAOYUN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaoyun Zhang is one of the authors of the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework" published on arXiv in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chi Wang is a notable author in the field of Artificial Intelligence and Machine Learning. In 2023, Chi Wang co-authored the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," which was published on arXiv. Additionally, Chi Wang contributed to another significant paper in 2024, titled "Offline training of language model agents with functions as learnable weights," presented at the Forty-first International Conference on Machine Learning. These contributions highlight Chi Wang's active involvement in advancing the development and application of language model agents and multi-agent conversation frameworks.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BENFENG XU">
      <data key="d0">PERSON</data>
      <data key="d1">Benfeng Xu is one of the authors of the paper titled "Expertprompting: Instructing large language models to be distinguished experts" published on arXiv in 2023</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">An Yang is one of the authors of the paper titled "Expertprompting: Instructing large language models to be distinguished experts" published on arXiv in 2023</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JUNYANG LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Junyang Lin is one of the authors of the paper titled "Expertprompting: Instructing large language models to be distinguished experts" published on arXiv in 2023</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QUAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Quan Wang is one of the authors of the paper titled "Expertprompting: Instructing large language models to be distinguished experts" published on arXiv in 2023</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHANG ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Chang Zhou is one of the authors of the paper titled "Expertprompting: Instructing large language models to be distinguished experts" published on arXiv in 2023</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YONGDONG ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yongdong Zhang is one of the authors of the paper titled "Expertprompting: Instructing large language models to be distinguished experts" published on arXiv in 2023</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHENDONG MAO">
      <data key="d0">PERSON</data>
      <data key="d1">Zhendong Mao is one of the authors of the paper titled "Expertprompting: Instructing large language models to be distinguished experts" published on arXiv in 2023</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHENGRUN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chengrun Yang is one of the authors of the paper titled "Large language models as optimizers" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIFENG LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yifeng Lu is one of the authors of the paper titled "Large language models as optimizers" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HANXIAO LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Hanxiao Liu is one of the authors of the paper titled "Large language models as optimizers" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BENNET YEE">
      <data key="d0">PERSON</data>
      <data key="d1">Bennet Yee is one of the authors of the paper titled "Native client: A sandbox for portable, untrusted x86 native code" published in Communications of the ACM in 2010</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAVID SEHR">
      <data key="d0">PERSON</data>
      <data key="d1">David Sehr is one of the authors of the paper titled "Native client: A sandbox for portable, untrusted x86 native code" published in Communications of the ACM in 2010</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GREGORY DARDYK">
      <data key="d0">PERSON</data>
      <data key="d1">Gregory Dardyk is one of the authors of the paper titled "Native client: A sandbox for portable, untrusted x86 native code" published in Communications of the ACM in 2010</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J BRADLEY CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">J Bradley Chen is one of the authors of the paper titled "Native client: A sandbox for portable, untrusted x86 native code" published in Communications of the ACM in 2010</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ROBERT MUTH">
      <data key="d0">PERSON</data>
      <data key="d1">Robert Muth is one of the authors of the paper titled "Native client: A sandbox for portable, untrusted x86 native code" published in Communications of the ACM in 2010</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TAVIS ORMANDY">
      <data key="d0">PERSON</data>
      <data key="d1">Tavis Ormandy is one of the authors of the paper titled "Native client: A sandbox for portable, untrusted x86 native code" published in Communications of the ACM in 2010</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHIKI OKASAKA">
      <data key="d0">PERSON</data>
      <data key="d1">Shiki Okasaka is one of the authors of the paper titled "Native client: A sandbox for portable, untrusted x86 native code" published in Communications of the ACM in 2010</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NEHA NARULA">
      <data key="d0">PERSON</data>
      <data key="d1">Neha Narula is one of the authors of the paper titled "Native client: A sandbox for portable, untrusted x86 native code" published in Communications of the ACM in 2010</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NICHOLAS FULLAGAR">
      <data key="d0">PERSON</data>
      <data key="d1">Nicholas Fullagar is one of the authors of the paper titled "Native client: A sandbox for portable, untrusted x86 native code" published in Communications of the ACM in 2010</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WENHAO YU">
      <data key="d0">PERSON</data>
      <data key="d1">Wenhao Yu is one of the authors of the paper titled "Language to rewards for robotic skill synthesis" published in the Conference on Robot Learning in 2023</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NIMROD GILEADI">
      <data key="d0">PERSON</data>
      <data key="d1">Nimrod Gileadi is one of the authors of the paper titled "Language to rewards for robotic skill synthesis" published in the Conference on Robot Learning in 2023</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SEAN KIRMANI">
      <data key="d0">PERSON</data>
      <data key="d1">Sean Kirmani is one of the authors of the paper</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KENNETH STANLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Kenneth Stanley is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIALE LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Jiale Liu is a notable researcher in the field of Artificial Intelligence and Machine Learning. Liu is one of the authors of the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation," published in 2023. Additionally, Liu contributed to the paper "Offline training of language model agents with functions as learnable weights," which was presented at the Forty-first International Conference on Machine Learning in 2024. These contributions highlight Liu's active involvement in advancing language model technologies and multi-agent systems.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LINXIN SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Linxin Song is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" published in the Forty-first International Conference on Machine Learning in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RANJAY KRISHNA">
      <data key="d0">PERSON</data>
      <data key="d1">Ranjay Krishna is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" published in the Forty-first International Conference on Machine Learning in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FORTY-FIRST INTERNATIONAL CONFERENCE ON MACHINE LEARNING">
      <data key="d0">EVENT</data>
      <data key="d1">The Forty-first International Conference on Machine Learning is an event where the paper "Offline training of language model agents with functions as learnable weights" was published in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="XIAOHE BO">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaohe Bo is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RUI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Rui Li is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QUANYU DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Quanyu Dai is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIEMING ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Jieming Zhu is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHENHUA DONG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhenhua Dong is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HENG-TZE CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Heng-Tze Cheng is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published on arXiv in 2024Heng-Tze Cheng is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models" published on arXiv in 2023</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ED H CHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ed H Chi is a prolific author in the field of Artificial Intelligence and Machine Learning. He has contributed to several significant papers, including "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022, "Take a step back: Evoking reasoning via abstraction in large language models" published on arXiv in 2023, and "Self-discover: Large language models self-compose reasoning structures" published on arXiv in 2024. His work focuses on enhancing the reasoning capabilities of large language models, addressing complex tasks, and exploring innovative methods for AI development.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PEI ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Pei Zhou is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JAY PUJARA">
      <data key="d0">PERSON</data>
      <data key="d1">Jay Pujara is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIANG REN">
      <data key="d0">PERSON</data>
      <data key="d1">Xiang Ren is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WANGCHUNSHU ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Wangchunshu Zhou is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIXIN OU">
      <data key="d0">PERSON</data>
      <data key="d1">Yixin Ou is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHENGWEI DING">
      <data key="d0">PERSON</data>
      <data key="d1">Shengwei Ding is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LONG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Long Li is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIALONG WU">
      <data key="d0">PERSON</data>
      <data key="d1">Jialong Wu is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TIANNAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Tiannan Wang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIAMIN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jiamin Chen is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHUAI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shuai Wang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIAOHUA XU">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaohua Xu is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NINGYU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ningyu Zhang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published on arXiv in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MINGCHEN ZHUGE">
      <data key="d0">PERSON</data>
      <data key="d1">Mingchen Zhuge is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" published in the Forty-first International Conference on Machine Learning in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WENYI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Wenyi Wang is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" published in the Forty-first International Conference on Machine Learning in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LOUIS KIRSCH">
      <data key="d0">PERSON</data>
      <data key="d1">Louis Kirsch is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" published in the Forty-first International Conference on Machine Learning in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FRANCESCO FACCIO">
      <data key="d0">PERSON</data>
      <data key="d1">Francesco Faccio is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" published in the Forty-first International Conference on Machine Learning in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DMITRII KHIZBULLIN">
      <data key="d0">PERSON</data>
      <data key="d1">Dmitrii Khizbullin is one of the authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society" published on arXiv in 2023. He is also one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" published in the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J&#220;RGEN SCHMIDHUBER">
      <data key="d0">PERSON</data>
      <data key="d1">J&#252;rgen Schmidhuber is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" published in the Forty-first International Conference on Machine Learning in 2024</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LUISA ZINTGRAF">
      <data key="d0">PERSON</data>
      <data key="d1">Luisa Zintgraf is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SEBASTIAN SCHULZE">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Schulze is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEO FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Leo Feng is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAXIMILIAN IGL">
      <data key="d0">PERSON</data>
      <data key="d1">Maximilian Igl is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KYRIACOS SHIARLIS">
      <data key="d0">PERSON</data>
      <data key="d1">Kyriacos Shiarlis is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YARIN GAL">
      <data key="d0">PERSON</data>
      <data key="d1">Yarin Gal is a prominent researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024. Additionally, he co-authored the paper "Varibad: Variational bayes-adaptive deep RL via meta-learning," which was published in the Journal of Machine Learning Research in 2021. His work spans critical areas in AI and ML, contributing to the understanding of model training dynamics and adaptive deep reinforcement learning through meta-learning techniques.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KATJA HOFMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Katja Hofmann is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHIMON WHITESON">
      <data key="d0">PERSON</data>
      <data key="d1">Shimon Whiteson is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOURNAL OF MACHINE LEARNING RESEARCH">
      <data key="d0">PUBLICATION</data>
      <data key="d1">The Journal of Machine Learning Research is a publication where the paper "Varibad: Variational bayes-adaptive deep RL via meta-learning" was published in 2021</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="APPENDIX C">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Appendix C is a section in the document that contains additional information relevant to the main text</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="APPENDIX D">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Appendix D is a section in the document that contains additional information relevant to the main text</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="APPENDIX B">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Appendix B is a section in the document that contains the prompts utilized in the evaluations of summarization abilities. It also includes the framework code and specifies the types of tasks or benchmarks, along with the corresponding methods used to extract answers and generate metrics.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="OUTPUT INSTRUCTION AND EXAMPLE">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">The Output Instruction and Example section provides guidelines and examples for the meta agent's output format</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="NAMEDTUPLE INFO OBJECT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The namedtuple Info object is used in the framework to encapsulate and combine different types of information</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FM MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The FM Module is a component within the framework that automatically constructs prompts by concatenating all input Info objects into a structured format. Each Info object is titled by its metadata, ensuring a coherent and organized output.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="FRAMEWORK CODE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The framework code is a simple codebase provided to the meta agent to implement basic functions and facilitate communication between different modules</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FIGURE 3A">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">FIGURE 3A is a figure in the document that shows the results and analysis of Meta Agent Search. It is a visual representation demonstrating the effectiveness of Meta Agent Search.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="TASKINFO">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">TASKINFO is a parameter used in the "forward()" function in the Python code for agent implementation. It is a variable that stores information about the task being performed and serves as input data for various modules, including the Chain-of-Thought module and the FM_Module, to generate initial candidate solutions and aid in problem-solving.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,449db721e37968e073e3579b59e023b2,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="RUNTIME ERROR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A runtime error is an error encountered during the execution of the generated code, prompting self-reflection and debugging</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="DEBUG_THOUGHT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Debug_thought is a section in the prompt where the meta agent provides its thinking for debugging the current code</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="INFO OBJECT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Info object is a namedtuple used to encapsulate and combine different types of information in the framework</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="MAIN TEXT">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">The main text is the primary content of the document, to which the appendices provide additional information</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="TERMINOLOGIES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Terminologies are specific terms used in the main text and matched in the code throughout the appendix</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="PROJECT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The project refers to the entire endeavor of designing and implementing agentic systems as discussed in the document</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPLEMENTATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Implementation refers to the process of coding and executing the agent designs as described in the document</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="OVERALL IDEA">
      <data key="d0">PROCESS</data>
      <data key="d1">Overall Idea refers to the reasoning and concept behind the agent design, as described in the "thought" section</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPROVEMENT">
      <data key="d0">PROCESS</data>
      <data key="d1">Improvement is a metric indicating the percentage of enhancement in performance compared to previous models. It also refers to the suggestions and refinements made to the agent's implementation to enhance performance or effectiveness.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="INTERESTINGNESS">
      <data key="d0">PROCESS</data>
      <data key="d1">Interestingness is the assessment of whether the proposed architecture is innovative compared to existing methods</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPLEMENTATION MISTAKES">
      <data key="d0">PROCESS</data>
      <data key="d1">Implementation Mistakes refer to errors identified in the code during the self-reflection process</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="RESPONSE">
      <data key="d0">PROCESS</data>
      <data key="d1">Response refers to the meta agent's output after performing self-reflection and making improvements</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="ERROR DURING EVALUATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Error during evaluation refers to the runtime errors encountered and the subsequent debugging process</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="APPENDIX E">
      <data key="d0" />
      <data key="d1">APPENDIX E is a section in a document that provides additional details, including more information about the baselines used in the evaluations. This appendix serves as a supplementary resource, offering further insights and elaborations on the baselines mentioned in the main text.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="FORWARD FUNCTION">
      <data key="d0" />
      <data key="d1">The forward function is a method in the AgentSystem class for processing task information and returning either a namedtuple Info or a string as the answer.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="INFO">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">INFO is a versatile named tuple used for holding task information, including attributes such as name, author, content, and iteration index. It serves as a system to encapsulate information about sub-problems and their solutions, providing a structured way to manage and store feedback information within the code. This multifaceted utility makes INFO an essential component for organizing and processing complex datasets and tasks efficiently.</data>
      <data key="d2">84317ae35cc75d612287186d93461447,d66dc9ce4a9545b44f7486ea057b5937,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="FORMAT_INST">
      <data key="d0">FUNCTION</data>
      <data key="d1">FORMAT_INST is a lambda function that formats instructions for FM responses to ensure the JSON format is correct</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="ROLE_DESC">
      <data key="d0">FUNCTION</data>
      <data key="d1">ROLE_DESC is a lambda function that describes the role of the FM Module</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="GET_JSON_RESPONSE_FROM_GPT">
      <data key="d0">FUNCTION</data>
      <data key="d1">get_json_response_from_gpt is a function to get a JSON response from a GPT model, handling rate limit errors using backoff</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="FM_MODULE">
      <data key="d0">CLASS</data>
      <data key="d1">FM_Module is a versatile base class designed for various FM modules, characterized by attributes such as output fields, name, role, model, temperature, and a unique identifier. It serves multiple functions, including generating initial candidate solutions through processes like 'thinking' and 'writing code', as well as providing feedback and evaluation in roles such as human-like feedback, expert advisors, and refinement. Additionally, FM_Module is integral in creating specialized modules like the Decomposition Module, Specialized Expert, Integration Module, Visual Representation Module, Verification Module, and Chain-of-Thought Module, thereby supporting a wide range of processes and applications.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,d66dc9ce4a9545b44f7486ea057b5937,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="AGENT SYSTEM">
      <data key="d0">CLASS</data>
      <data key="d1">AgentSystem is a class with a forward method for processing task information and returning either a namedtuple Info or a string as the answer</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_INITIAL_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">cot_initial_instruction is an instruction for initial reasoning, asking the agent to think step by step to solve the task</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_REFLECT_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">cot_reflect_instruction is an instruction for reflecting on previous attempts and feedback to improve task performance</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="CRITIC_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">CRITIC_INSTRUCTION is an instruction designed for providing feedback and correcting answers. It involves reviewing the given answer, identifying any errors, and offering constructive criticism where necessary. If the answer is correct, the instruction confirms this by outputting 'True' in 'correct'. This process ensures that responses are accurate and reliable, enhancing the overall quality of the information provided.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="CODE 1">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Code 1 is the simple framework used in Meta-Agent Search, including definitions for named tuples, lambda functions, and the FM_Module class</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="CODE 2">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Code 2 is an example of implementing self-reflection using the provided framework</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TASK DESCRIPTIONS">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Task descriptions are pieces of information that describe the tasks to be performed by the system</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="FM RESPONSES">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">FM responses are the results generated by the FM Module in response to the input information and instructions</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TOOL FUNCTION CALLS">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Tool function calls are invocations of specific functions within the system to perform certain tasks</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="BACKOFF">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Backoff is a technique used to handle rate limit errors by retrying the function call with exponential backoff</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="RATE LIMIT ERROR">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Rate Limit Error is an error encountered when the rate limit for API calls is exceeded</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="SYSTEM PROMPT">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The system prompt is part of the generated prompt that provides context and instructions for the FM Module</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="USER PROMPT">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The user prompt is part of the generated prompt that includes the task instructions for the FM Module</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="OUTPUT INFOS">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Output Infos are the results generated by the FM Module in response to the input information and instructions</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="INSTRUCTION">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Instruction is a piece of information that guides the FM Module on how to perform a task</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="NAMED TUPLE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Named tuple is a data structure used to hold task information in a structured format</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="JSON RESPONSE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">JSON response is the output generated by the GPT model in response to a query, formatted as JSON</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="MODEL">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The term "MODEL" is a general reference to various language models evaluated in the text. Specifically, it refers to the particular version of the GPT model used in the FM Module. Additionally, the model is the AI system being assessed for its capability to generate correct answers or emotion scores.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,8ee9617c145e19fa95f1f9349bfbe69b,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TEMPERATURE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Temperature is a parameter that controls the randomness of the GPT model's output</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="UNIQUE IDENTIFIER">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Unique identifier is a string that uniquely identifies an instance of the FM Module</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="OUTPUT FIELDS">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Output fields are the fields expected in the output generated by the FM Module</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="ROLE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Role is a description of the function or position of the FM Module</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TASK INFO">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Task Info is a named tuple containing information about a task, including attributes like name, author, content, and iteration index</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT MODULE">
      <data key="d0">CLASS</data>
      <data key="d1">cot_module is an instance of the FM_Module class used for Chain-of-Thought reasoning</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A module named FM_Module that handles 'thinking' and 'answer' processes, referred to as 'Chain-of-Thought'</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="CRITIC_MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A module named FM_Module that handles 'feedback' and 'correct' processes, referred to as 'Critic'</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="N_MAX">
      <data key="d0">PARAMETER</data>
      <data key="d1">The maximum number of attempts allowed, set to 5</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="COT_INPUTS">
      <data key="d0">DATA</data>
      <data key="d1">The initial inputs for the Chain-of-Thought module, which include task information</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="THINKING">
      <data key="d0">DATA</data>
      <data key="d1">"THINKING" refers to the thought process generated by the Chain-of-Thought module. It is a variable used in the code to store the thought process or reasoning behind a solution. Additionally, thinking is the process of generating thoughts as part of the initial candidate solutions. This concept is integral to understanding how solutions are formulated and refined within the system.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="CORRECT">
      <data key="d0">DATA</data>
      <data key="d1">The correctness status provided by the Critic module, which can be 'True' if the answer is correct</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="GPT-4O-2024-05-13">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4O-2024-05-13 is a version of OpenAI's GPT-4 model utilized by the meta agent in the ARC challenge in 2024. This specific iteration of the GPT-4 model was employed by the meta agent during an experiment, highlighting its role in advanced AI research and applications.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="GPT-3.5-TURBO-0125">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-3.5-TURBO-0125 is a version of OpenAI's GPT-3.5 model specifically used to evaluate discovered agents and baselines in the ARC challenge. Known for its high cost, this model was employed during the evaluation process in 2022 to help reduce compute expenses. It played a crucial role in the experimental assessment of agents and baselines, contributing to the overall efficiency and effectiveness of the evaluation process.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="EXACT MATCH">
      <data key="d0">METRIC</data>
      <data key="d1">The accuracy rate calculated by comparing the reference solution and the predicted answer in the ARC challenge</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="INPUT GRID">
      <data key="d0">DATA</data>
      <data key="d1">A rectangular matrix of integers between 0 and 9 representing colors, used as input in the ARC challenge</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="OUTPUT GRID">
      <data key="d0">DATA</data>
      <data key="d1">A rectangular matrix of integers between 0 and 9 representing colors, used as output in the ARC challenge</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="EXAMPLE 0">
      <data key="d0">EXAMPLE</data>
      <data key="d1">An example task from the ARC challenge with specific input and output grids</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="EXAMPLE INPUT-OUTPUT GRID #1">
      <data key="d0">EXAMPLE</data>
      <data key="d1">An example input-output grid used in the ARC challenge to demonstrate the transformation rules</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="EXAMPLE INPUT-OUTPUT GRID #2">
      <data key="d0">EXAMPLE</data>
      <data key="d1">Another example input-output grid used in the ARC challenge to demonstrate the transformation rules</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="TEST GRID">
      <data key="d0">DATA</data>
      <data key="d1">The grid used in the ARC challenge to test the AI system's ability to apply learned transformation rules to predict the final answer</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="EXPERIMENT DETAILS FOR ARC CHALLENGE">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A document providing detailed information about the experiments conducted for the ARC challenge</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="TASK OVERVIEW">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A document providing an overview of the tasks involved in the ARC challenge</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="INITIAL SOLUTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Initial Solution is the output generated by the FM_Module based on the initial instruction</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="CORRECT EXAMPLES">
      <data key="d0">DATA</data>
      <data key="d1">Correct Examples are the examples that the generated code passed during the feedback process</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="WRONG EXAMPLES">
      <data key="d0">DATA</data>
      <data key="d1">Wrong Examples are the examples that the generated code failed during the feedback process</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="EXAMPLE 2">
      <data key="d0">DATA</data>
      <data key="d1">Example 2 is another test case provided to analyze the transformation rules based on the provided examples</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="TEST PROBLEM">
      <data key="d0">DATA</data>
      <data key="d1">Test Problem is a test case provided to analyze the transformation rules based on the provided examples</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="INITIAL INSTRUCTION">
      <data key="d0">DATA</data>
      <data key="d1">Initial Instruction is the instruction given to the FM_Module to generate initial candidate solutions</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="NUM_CANDIDATES">
      <data key="d0">DATA</data>
      <data key="d1">Num_Candidates is the number of initial candidates generated by the FM_Module</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="THOUGHTS">
      <data key="d0">DATA</data>
      <data key="d1">"THOUGHTS" refers to the intermediate outputs generated by the FM_Module during the initial candidate solution process. In the context of the code, "THOUGHTS" is a variable used to store the thought process or reasoning behind a solution. This dual role highlights its importance in both the generation and documentation of problem-solving strategies within the system.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="CORRECT_COUNT">
      <data key="d0">DATA</data>
      <data key="d1">Correct_Count is the number of correct examples passed by the generated code during the feedback process</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="EXAMPLE 1">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="OUTPUT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="CORRECT_EXAMPLES">
      <data key="d0">DATA</data>
      <data key="d1">Correct_examples is a variable used in the code to store examples where the code solution was correct</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="WRONG_EXAMPLES">
      <data key="d0">DATA</data>
      <data key="d1">Wrong_examples is a variable used in the code to store examples where the code solution was incorrect</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="INITIAL_SOLUTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Initial_solutions is a list used in the code to store initial candidate solutions that passed at least one example</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="HUMAN_LIKE_FEEDBACK_MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Human_like_feedback_module is a module used to simulate human-like feedback for each candidate solution</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="HUMAN_FEEDBACK_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Human_feedback_instruction is an instruction given to the human_like_feedback_module to provide human-like feedback focusing on common mistakes, heuristic corrections, and best practices</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT_ROLES">
      <data key="d0">ROLE</data>
      <data key="d1">Expert_roles are roles assigned to expert advisors to evaluate and provide targeted feedback, including Efficiency Expert, Readability Expert, and Simplicity Expert</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT_ADVISORS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Expert_advisors are modules assigned to expert roles to evaluate and provide targeted feedback for improvement</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Expert_instruction is an instruction given to expert_advisors to evaluate the given code and provide targeted feedback for improvement</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="SOL_FEEDBACK">
      <data key="d0">DATA</data>
      <data key="d1">Sol_feedback is a variable used in the code to store feedback from expert advisors for each solution</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="MAX_REFINEMENT_ITERATIONS">
      <data key="d0">PARAMETER</data>
      <data key="d1">Max_refinement_iterations is a parameter that sets the maximum number of iterations for refining solutions</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINEMENT_MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Refinement_module is a module used to parse and structure feedback to avoid redundancy and iteratively refine solutions</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINEMENT_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Refinement_instruction is an instruction given to the refinement_module to use structured feedback to refine the solution and improve its performance</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINED_SOLUTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Refined_solutions is a list used in the code to store solutions that have been refined and improved</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="SORTED_SOLUTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Sorted_solutions is a list used in the code to store refined solutions sorted by their performance</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="TOP_SOLUTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Top_solutions is a list used in the code to store the top 3 best-performing solutions</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_DECISION_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Final_decision_instruction is an instruction given to the final_decision_module to reason over the top solutions and provide a final answer by writing the code</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_DECISION_MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Final_decision_module is a module used to make a final decision by reasoning over the top solutions and providing the final code</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_INPUTS">
      <data key="d0">DATA</data>
      <data key="d1">Final_inputs is a list used in the code to store inputs for the final_decision_module, including taskInfo, thinking, code, and feedback from top solutions</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_THOUGHTS">
      <data key="d0">DATA</data>
      <data key="d1">Final_thoughts is a variable used in the code to store the final thought process and code from the final_decision_module</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_THINKING">
      <data key="d0">DATA</data>
      <data key="d1">Final_thinking is a variable used in the code to store the final thought process from the final_decision_module</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_CODE">
      <data key="d0">DATA</data>
      <data key="d1">Final_code is a variable used in the code to store the final code solution from the final_decision_module</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="INITIAL_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Initial_instruction is an instruction given at the beginning of the process</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="RUN_EXAMPLES_AND_GET_FEEDBACK">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Run_examples_and_get_feedback is a function used to run examples and obtain feedback on the code solution</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="HUMAN_THINKING">
      <data key="d0">DATA</data>
      <data key="d1">Human_thinking is a variable used in the code to store the thought process or reasoning provided by the human-like feedback module</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="HUMAN_FEEDBACK">
      <data key="d0">DATA</data>
      <data key="d1">Human_feedback is a variable used in the code to store feedback provided by the human-like feedback module</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT_FEEDBACK">
      <data key="d0">DATA</data>
      <data key="d1">Expert_feedback is a variable used in the code to store feedback provided by expert advisors</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="STRUCTURED_FEEDBACK">
      <data key="d0">DATA</data>
      <data key="d1">Structured_feedback is a variable used in the code to store feedback that has been parsed and structured to avoid redundancy</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINEMENT_THINKING">
      <data key="d0">DATA</data>
      <data key="d1">Refinement_thinking is a variable used in the code to store the thought process or reasoning during the refinement process</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINED_CODE">
      <data key="d0">DATA</data>
      <data key="d1">Refined_code is a variable used in the code to store the code solution after refinement</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="GET_TEST_OUTPUT_FROM_CODE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Get_test_output_from_code is a function used to obtain the final answer from the final code solution</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERIMENT DETAILS">
      <data key="d0">DATA</data>
      <data key="d1">Experiment Details is a section in the document that provides information about the experiment setup and evaluation</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="ZERO-SHOT STYLE QUESTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Zero-shot style questions are questions used in the experiment that do not provide any prior examples</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="ONE-SHOT STYLE QUESTIONS">
      <data key="d0">DATA</data>
      <data key="d1">One-shot style questions are questions used in the experiment that provide one prior example</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="DISCOVERED AGENTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Discovered agents are agents identified during the experiment and evaluated using the GPT-3.5-turbo-0125 model</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REASONING AND PROBLEM-SOLVING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PHYSICS EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">Physics Expert is a unique role assigned to a debate module in LLM-Debate</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="CHEMISTRY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">Chemistry Expert is a unique role assigned to a debate module in LLM-Debate</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="PHYSICS CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">Physics Critic is a unique role assigned to a critic module in Self-Refine</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="CHEMISTRY CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">Chemistry Critic is a unique role assigned to a critic module in Self-Refine</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="BIOLOGY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">Biology Expert is a unique role assigned to a debate module in LLM-Debate</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="SCIENCE GENERALIST">
      <data key="d0">ROLE</data>
      <data key="d1">Science Generalist is a unique role assigned to a debate module in LLM-Debate</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="BIOLOGY CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">Biology Critic is a unique role assigned to a critic module in Self-Refine</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="GENERAL CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">General Critic is a unique role assigned to a critic module in Self-Refine</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="FINAL DECISION">
      <data key="d0">ROLE</data>
      <data key="d1">Final Decision is a role assigned to a module in Self-Refine to make the final decision based on all inputs</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="DECOMPOSITION MODULE">
      <data key="d0">ROLE</data>
      <data key="d1">The Decomposition Module is a role assigned to a module in the Divide and Conquer Agent, designed to break down a problem into sub-problems for easier solving. This system facilitates the decomposition of complex issues, enabling more efficient and manageable problem-solving processes.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SPECIALIZED EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">Specialized Expert is a role assigned to a module in the Divide and Conquer Agent, designed to solve sub-problems by leveraging domain-specific expertise. This system assigns each sub-problem to a specialized expert in fields such as Physics, Chemistry, Biology, or General knowledge, ensuring that each aspect of a complex problem is addressed by the most qualified individual.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INTEGRATION MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Integration Module is a system that integrates the solutions of sub-problems to provide a final answer to the original problem</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL REPRESENTATION MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Visual Representation Module is a system that generates visual representations of problems</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VERIFICATION MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Verification Module is a system that verifies the accuracy and relevance of visual representations and provides feedback</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="CHAIN-OF-THOUGHT MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Chain-of-Thought Module is a system that uses verified visual representations to solve problems step by step</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="GPT-4O-MINI">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4o-mini is a newer model that is less expensive and offers better performance compared to GPT-3.5-turbo-0125</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="ADAS ALGORITHMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ADAS (Automated Design of Agentic Systems) algorithms are used for designing and evaluating agentic systems</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB_PROBLEM">
      <data key="d0">DATASET</data>
      <data key="d1">Sub_problem is a part of the original problem that is broken down for easier solving</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB_SOLUTION">
      <data key="d0">DATASET</data>
      <data key="d1">Sub_solution is the solution to a sub-problem</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL_OUTPUT">
      <data key="d0">DATASET</data>
      <data key="d1">Visual_output is the output generated by the Visual Representation Module</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL_REPRESENTATION">
      <data key="d0">DATASET</data>
      <data key="d1">Visual_representation is the visual depiction of a problem generated by the Visual Representation Module</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="COST OF EXPERIMENTS">
      <data key="d0">DATASET</data>
      <data key="d1">Cost of Experiments refers to the financial expense incurred during the search and evaluation processes</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="EVALUATION FUNCTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Evaluation Function is a system used to assess the performance of discovered agents</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="AGENTINSTRUCT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AGENTINSTRUCT is an extensible agentic framework designed to create a collection of instructions aimed at teaching various skills, implemented for 17 different capabilities. It defines three different flows: Content Transformation Flow, Seed Instruction Generation Flow, and Instruction Refinement Flow, to automate the generation process and ensure diversity and complexity in the generated data. This system reduces the need for human expertise in data generation, enabling the creation of high-quality synthetic data at scale. AGENTINSTRUCT synthesizes a large and diverse corpus of data with varying degrees of difficulty, enhancing the proficiency of models like Mistral across various difficulties in math, from elementary to college-level, and improving reading comprehension capabilities. It focuses on creating demonstration and feedback data using raw documents as input, generating high-quality, diverse, and large quantities of data autonomously. Additionally, AGENTINSTRUCT has successfully reduced hallucinations by 31.34% while attaining a quality level comparable to GPT-4, making it a robust approach to Generative Teaching that uses agentic flows for synthetic data generation to improve model post-training.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ARINDAM MITRA">
      <data key="d0">PERSON</data>
      <data key="d1">Arindam Mitra is one of the authors of the Phi-3 technical report. Additionally, he has co-authored the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows" and the paper titled "Orca 2: Teaching small language models how to reason," which was published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LUCIANO DEL CORRO">
      <data key="d0">PERSON</data>
      <data key="d1">Luciano Del Corro is one of the authors of the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows" and also contributed to the paper "Orca 2: Teaching small language models how to reason," which was published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="GUOQING ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Guoqing Zheng is a notable researcher in the field of Artificial Intelligence and Machine Learning. He has contributed to the advancement of AI through his co-authorship of significant papers. One of his works includes the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows." Additionally, in 2023, he co-authored another influential paper, "Orca 2: Teaching small language models how to reason." These contributions highlight his active involvement in developing innovative methodologies for AI and ML, particularly in the areas of generative teaching and reasoning in language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SHWETI MAHAJAN">
      <data key="d0">PERSON</data>
      <data key="d1">Shweti Mahajan is one of the authors of the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows." Additionally, Shweti Mahajan contributed to the paper "Orca 2: Teaching small language models how to reason," which was published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="DANY ROUHANA">
      <data key="d0">PERSON</data>
      <data key="d1">Dany Rouhana is one of the authors of the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows"</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="ANDRES CODAS">
      <data key="d0">PERSON</data>
      <data key="d1">Andres Codas is one of the authors of the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows" and also contributed to the paper "Orca 2: Teaching small language models how to reason," which was published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="YADONG LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yadong Lu is one of the authors of the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows"</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="WEI-GE CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Wei-ge Chen is one of the authors of the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows"</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="OLGA VROUSGOS">
      <data key="d0">PERSON</data>
      <data key="d1">Olga Vrousgos is one of the authors of the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows"</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CORBY ROSSET">
      <data key="d0">PERSON</data>
      <data key="d1">Corby Rosset is a notable author in the field of Artificial Intelligence and Machine Learning. He has contributed to several significant publications, including the Phi-3 technical report, the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows," and the 2023 paper "Orca 2: Teaching small language models how to reason." His work demonstrates a focus on advancing the understanding and capabilities of AI through innovative research and technical documentation.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="FILLIPE SILVA">
      <data key="d0">PERSON</data>
      <data key="d1">Fillipe Silva is one of the authors of the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows"</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="HAMED KHANPOUR">
      <data key="d0">PERSON</data>
      <data key="d1">Hamed Khanpour is one of the authors of the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows." Additionally, he co-authored the paper "Orca 2: Teaching small language models how to reason," which was published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="YASH LARA">
      <data key="d0">PERSON</data>
      <data key="d1">Yash Lara is one of the authors of the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows"</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="AHMED AWADALLAH">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmed Awadallah is a notable author in the field of Artificial Intelligence and Machine Learning. He has contributed to several significant publications, including the Phi-3 technical report, the paper titled "AgentInstruct: Toward Generative Teaching with Agentic Flows," and the 2023 paper "Orca 2: Teaching small language models how to reason." His work spans various aspects of AI and ML, showcasing his expertise and influence in the community.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SYNTHETIC DATA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Synthetic data is artificially generated data used in model training and to accelerate the development of language models, both large and small. While it can significantly speed up the development process, synthetic data often lacks diversity and requires intensive human curation to ensure its quality and representativeness.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GENERATIVE TEACHING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Generative Teaching is a methodology focused on teaching skills to AI models by generating abundant amounts of diverse, challenging, and high-quality synthetic data. This approach leverages powerful models to create data that is specifically designed to teach new skills or behaviors to other models. Techniques such as AgentInstruct are employed within Generative Teaching to produce large volumes of data for effective model post-training.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MISTRAL-7B">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Mistral-7B is a base language model that underwent post-training using a synthetic dataset generated by AgentInstruct. This fine-tuning process resulted in the creation of the Orca-3 model.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="ORCA-3">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Orca-3 is a language model that has been fine-tuned from the Mistral-7B model using the AgentInstruct dataset, which consists of approximately 25.8 million paired instructions. The model's performance is likely to correlate strongly with the distribution of the tuning data. Orca-3 has been evaluated on the Orca-Bench dataset and various other benchmarks, demonstrating notable enhancements in capabilities and significant improvements over other instruction-tuned models using the same base model. The post-training process with data generated by AgentInstruct has contributed to these performance improvements across many benchmarks.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AGIEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">AGIEval is a human-centric benchmark used to evaluate the performance of AI models on various tasks pertinent to human cognition and problem-solving, including reading comprehension, math, and standardized exams like the SAT and LSAT. It assesses the capabilities of different language models, including Orca-3 and other baselines. Notably, Orca-3 demonstrated a 40% improvement in performance compared to Mistral-Instruct-7B on this benchmark.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="BBH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">BBH, or Big Bench Hard, is a benchmark used to evaluate the performance of AI and language models. It consists of a set of 23 tasks from the broader Big-Bench benchmark, which require complex, multi-step reasoning. Notably, the Orca-3 model demonstrated a 38% improvement in performance on BBH compared to the Mistral-Instruct-7B model.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ALPACAEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">AlpacaEval is a benchmark for chat-based language models, designed to assess their abilities in instruction-following tasks. Published in 2023, it consists of 805 instructions and measures win-rates by comparing model outputs to a reference answer, judged by GPT-4-turbo. AlpacaEval has been used to evaluate the performance of various models, including Orca-3, which showed a 45% improvement over Mistral-Instruct-7B.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="GPT-3.5-TURBO">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-3.5-turbo is a language model frequently used as a baseline for performance comparison in various benchmarks and evaluations. It has been evaluated on the Orca-Bench dataset and the MIRAGE Datasets, demonstrating its capabilities in both CoT (Chain of Thought) and RAG (Retrieval-Augmented Generation) tasks. Despite its widespread use for comparison, GPT-3.5-turbo has been outperformed by Orca-3 in several benchmarks. Additionally, its scores for the GSM8K dataset are referenced in the text, highlighting its role in the broader landscape of language model assessments.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="LLMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLMs, or Large Language Models, are advanced language models that have been significantly developed using synthetic data</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SLMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">SLMs, or Small Language Models, are smaller-scale language models that also benefit from synthetic data in their training</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="RLHF">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">RLHF, or Reinforcement Learning from Human Feedback, is a technique used in the training of language models</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SEARCH APIS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">SEARCH APIS are tools that can be used by agents powered by Large Language Models (LLMs) to perform specific tasks. These APIs are integral to agentic workflows, enhancing the capabilities of language models by providing them with the ability to execute specialized functions.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CALCULATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The CALCULATOR is a tool that can be used by agents powered by Large Language Models (LLMs) to perform mathematical calculations. It is also utilized in agentic workflows to enhance the capabilities of language models, providing a crucial function in the processing and analysis of numerical data.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CODE INTERPRETERS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Code interpreters are tools used in agentic workflows to enhance the capabilities of language models</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MULTI-AGENT WORKFLOWS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Multi-agent workflows are agentic workflows that involve multiple agents to generate high-quality data and automate data generation tasks</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MISTRAL-7B-INSTRUCT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Mistral-7B-Instruct is a version of the Mistral-7B language model specifically designed for instruction tuning. It serves as a baseline for comparison in various benchmarks, including those involving the Orca-3-7B model. Despite its utility, Mistral-7B-Instruct was outperformed by Orca-3 in these evaluations.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="LLAMA-8B-INSTRUCT">
      <data key="d0" />
      <data key="d1">LLAMA-8B-Instruct is a model that Orca-3 outperformed on multiple benchmarks.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="SYNTHETIC-DATA-GENERATION-AS-A-SERVICE">
      <data key="d0">SERVICE, CONCEPT</data>
      <data key="d1">Synthetic-Data-Generation-As-A-Service is a concept where agents start with raw materials and generate data for post-training and fine-tuning, enabling continual learning and improvement of any base LLM</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">SERVICE, CONCEPT</data>
    </node>
    <node id="CONTENT TRANSFORMATION AGENTS">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">Content Transformation Agents are used in the AgentInstruct methodology to transform raw seeds into diverse sets of instructions</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">TECHNOLOGY, SYSTEM</data>
    </node>
    <node id="REFINEMENT AGENTS">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">Refinement Agents are used in the AgentInstruct methodology to iteratively refine the complexity and quality of seed instructions</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">TECHNOLOGY, SYSTEM</data>
    </node>
    <node id="RAW SEEDS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Raw seeds are unstructured text documents or source code used as input in the AgentInstruct methodology to generate diverse and high-quality data</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="MISTRAL-INSTRUCT-7B">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-Instruct-7B is a baseline model evaluated on the Orca-Bench dataset. It serves as a standard for performance comparison in various benchmarks. Notably, Mistral-Instruct-7B is used as a comparison benchmark, where the Orca-3 model demonstrated significant improvements over it.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="POST-TRAINING DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The post-training dataset created by AgentInstruct consists of 25 million prompt and response pairs covering a wide array of skills</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="INSTRUCTION CREATION AGENTS">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">Instruction Creation Agents are used in the AgentInstruct methodology to create a diverse set of instructions from raw seeds</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">TECHNOLOGY, SYSTEM</data>
    </node>
    <node id="REFLECTION FLOWS">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">Reflection Flows are used in AgentInstruct to enhance the quality of generated responses by leveraging tools and iterative refinement</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">TECHNOLOGY, SYSTEM</data>
    </node>
    <node id="CREATIVE WRITING">
      <data key="d0">SKILL, CAPABILITY</data>
      <data key="d1">Creative Writing is one of the skills covered in the synthetic post-training dataset created by AgentInstruct. It is a skill involving the creation of original written content, often requiring imagination and storytelling abilities.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">SKILL, CAPABILITY</data>
    </node>
    <node id="DATA GENERATION WORKFLOWS">
      <data key="d0">PROCESS</data>
      <data key="d1">Data generation workflows are processes that can be automated to reduce or eliminate the need for human intervention on some tasks</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="PROMPT SET">
      <data key="d0">DATA</data>
      <data key="d1">A prompt set is an existing collection of prompts used as seeds for generating more instructions in the context of Generative Teaching</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="DEMONSTRATION DATA">
      <data key="d0">DATA</data>
      <data key="d1">Demonstration data is created by AgentInstruct to teach an AI model specific skills or capabilities</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="FEEDBACK DATA">
      <data key="d0">DATA</data>
      <data key="d1">Feedback data is created by AgentInstruct to provide responses and evaluations to improve AI model performance</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="DOMAIN SPECIFIC DATA">
      <data key="d0">DATA</data>
      <data key="d1">Domain specific data refers to specialized data (e.g., gaming, finance) used as seeds to improve an AI model in a certain specialization</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="GENERAL CAPABILITY">
      <data key="d0">SKILL, CAPABILITY</data>
      <data key="d1">General capability refers to broad skills such as Math, Reasoning, and RAG that can be taught to an LLM using AgentInstruct</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="RAW DOCUMENTS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Raw documents are unstructured text documents used as input for AgentInstruct to generate diverse and high-quality data</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="VERIFICATION FLOWS">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">Verification flows are processes used by AgentInstruct to verify and filter generated data</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="DATA FILTERING">
      <data key="d0">PROCESS</data>
      <data key="d1">Data filtering is a process used by AgentInstruct to ensure the quality and relevance of generated data</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="UNSTRUCTURED TEXT DOCUMENTS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Unstructured text documents are raw data sources used as seeds in the AgentInstruct methodology</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="SOURCE CODE">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Source code is a type of raw data used as seeds in the AgentInstruct methodology to generate diverse and high-quality data</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="CONTINUAL LEARNING">
      <data key="d0">PROCESS</data>
      <data key="d1">Continual learning is a process enabled by Synthetic-Data-Generation-As-A-Service, allowing for ongoing improvement of AI models</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="BASE LLM">
      <data key="d0">MODEL</data>
      <data key="d1">Base LLM refers to the initial language model that can be continually improved using data generated by AgentInstruct</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="SUPERVISED FINE-TUNING">
      <data key="d0">PROCESS</data>
      <data key="d1">Supervised fine-tuning is a process of improving AI models using high-quality synthetic datasets</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="INSTRUCTION-TUNING">
      <data key="d0">PROCESS</data>
      <data key="d1">Instruction-tuning is a process of improving AI models using high-quality synthetic datasets to follow instructions better</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="CONTENT TRANSFORMATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">"Content Transformation Flow" is a multifaceted process within the AgentInstruct methodology that converts raw seeds, such as source code snippets or API descriptions, into intermediate representations. This transformation simplifies the creation of instructions tailored to specific objectives. Additionally, it synthesizes a list of APIs and transforms arbitrary articles into well-crafted pieces, facilitating the formulation of diverse reading comprehension question types.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,427e98b00e49b6a8f8649054122dd45b,b88745a13b69cecbc0ee9c3af41389bf,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTION CREATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">The Seed Instruction Creation Flow is a process within the AgentInstruct methodology that generates a diverse set of instructions from raw seeds. This process consumes a list of APIs and employs various agents to create multiple types of tasks. These tasks can involve single or multiple APIs and may include scenarios with missing or superfluous parameters.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="REFINEMENT FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">Refinement Flow is a process in the AgentInstruct methodology that iteratively refines the complexity and quality of seed instructions. This process is aimed at increasing the complexity of tasks by suggesting refinements to increase the number of steps required to solve the task.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="WEB DATA">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Web data is a type of raw material used as seeds for general model training in Synthetic-Data-Generation-As-A-Service</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="TAXONOMY">
      <data key="d0">SYSTEM</data>
      <data key="d1">A taxonomy of over 100 subcategories is used by AgentInstruct to create diverse and high-quality prompts and responses</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="AGENTIC FLOWS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Agentic Flows are automated processes designed to generate data at scale, ensuring high diversity and varying complexity by leveraging raw articles as seeds. These flows are utilized in AgentInstruct to create tailored datasets from unstructured data sources for model post-training.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTION GENERATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">The "SEED INSTRUCTION GENERATION FLOW" is a process that generates diverse instructions from transformed content, adhering to a comprehensive taxonomy. It compiles a collection of reading comprehension question types and defines agents to generate questions based on these predefined types. This systematic approach ensures a wide variety of instructions are produced, enhancing the depth and breadth of reading comprehension exercises.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INSTRUCTION REFINEMENT FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">Instruction Refinement Flow involves suggester-editor agents that refine (passage, question) pairs to create more complex or unanswerable questions. This process iteratively enhances the complexity and quality of instructions generated by the Seed Instruction Generation Flow. By employing a Suggester-Editor pair, the Instruction Refinement Flow aims to increase the sophistication of the generated instructions, ensuring they are more challenging and nuanced.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SUGGESTER-EDITOR AGENTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Suggester-Editor Agents are used in the Instruction Refinement Flow to propose and modify instructions to increase their intricacy and quality</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="QUESTION ANSWERING">
      <data key="d0">SKILL</data>
      <data key="d1">Question answering is a multifaceted task in the field of Artificial Intelligence and Machine Learning. It involves generating responses to questions over a wide range of topics, without being restricted to a specific domain. Additionally, question answering is a critical component of reading comprehension, requiring the system to provide answers based on a given text. This dual nature of question answering highlights its importance in both open-domain and text-specific contexts, making it a versatile and essential area of research and application in AI and ML.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT MODIFICATION">
      <data key="d0">SKILL</data>
      <data key="d1">TEXT MODIFICATION involves changing existing text to improve its quality, modify its tone, or fit a specific context or audience. It encompasses a range of activities including editing written content to correct spelling and grammar, clarify ideas, reorganize content, adjust tone, ensure style consistency, fact-check, remove redundancies, format, develop content, and adapt to specific audiences.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="WEB AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A web agent is a software program that autonomously performs tasks on the web, such as clicking, scrolling, and navigating</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="BRAIN TEASER">
      <data key="d0">ACTIVITY</data>
      <data key="d1">A brain teaser is a problem or puzzle requiring thought to solve, often used for amusement or training logical thinking and problem-solving skills</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ANALYTICAL REASONING">
      <data key="d0">SKILL</data>
      <data key="d1">Analytical reasoning involves the ability to look at information, discern patterns, and draw logical conclusions about relationships within the information</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MULTIPLE CHOICE QUESTIONS">
      <data key="d0">ASSESSMENT</data>
      <data key="d1">Multiple Choice Questions (MCQs) are a form of assessment where respondents select the best possible answer from a list of choices. In an open-ended generation setting, these questions are evaluated with an empty system message, and GPT-4 is utilized to extract the option selected by the model from the model&#8217;s response. This method leverages the advanced capabilities of GPT-4 to accurately determine the chosen answer, enhancing the evaluation process of MCQs.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="DATA TO TEXT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Data-to-text refers to generating human-readable textual summaries from source data, used for reports, explanations, or narratives</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="FERMI PROBLEMS">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Fermi problems are estimation problems that seek quick, rough estimates of quantities, often requiring justified guesses or assumptions. These problems are designed to provide rapid approximations for quantities that can be difficult to measure directly, leveraging logical reasoning and educated assumptions to reach a solution.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CODING">
      <data key="d0">SKILL</data>
      <data key="d1">CODING involves writing code following instructions, understanding code, debugging code, and tracing or writing test cases. It encompasses the entire process of writing, understanding, debugging, and testing code to ensure it functions as intended.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT EXTRACTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">TEXT EXTRACTION is the process of retrieving relevant information from a larger text document. This includes tasks such as named entity recognition, keyword extraction, and extracting specific data fields from unstructured text.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="RAW ARTICLES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Raw articles are used as seeds in agentic flows to foster diversity and ensure broad coverage of generated problems</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INTERMEDIATE REPRESENTATION">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Intermediate representation is the transformed content produced by the Content Transformation Flow, simplifying the creation of instructions tailored to specific objectives</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTIONS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Seed instructions are generated from transformed content in the Seed Instruction Generation Flow, following a comprehensive taxonomy to ensure diversity</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CODE INTERPRETER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Code interpreter is a tool that can be used by agents powered by LLMs to execute and interpret code</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="RETRIEVAL AUGMENTED GENERATION">
      <data key="d0">SKILL</data>
      <data key="d1">Retrieval Augmented Generation (RAG) is a method in natural language processing that combines retrieval-based and generative models to generate responses. This technique involves first retrieving relevant documents and then using these documents to generate a response. RAG is a skill that entails generating content by retrieving and incorporating pertinent information from external sources, thereby enhancing the quality and relevance of the generated output.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="WEB CONTROL">
      <data key="d0">SKILL</data>
      <data key="d1">Web control is a skill involving the use of web agents to autonomously perform tasks on the web</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CASE STUDIES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Case studies are used to explain how the workflows work for generating data for specific skills like Reading Comprehension, Text Modification, and Tool Use</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="DECODING">
      <data key="d0">SKILL</data>
      <data key="d1">Decoding is a sub-skill of reading comprehension involving the ability to interpret written text into meaningful language</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="FLUENCY">
      <data key="d0">SKILL</data>
      <data key="d1">Fluency is a sub-skill of reading comprehension involving the ability to read text smoothly and accurately</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="VOCABULARY KNOWLEDGE">
      <data key="d0">SKILL</data>
      <data key="d1">Vocabulary knowledge is a sub-skill of reading comprehension involving the understanding and use of a wide range of words</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT PASSAGES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Text passages are used in reading comprehension tests to assess the reader&#8217;s understanding</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="QUESTIONS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Questions are used in reading comprehension tests to assess the reader&#8217;s understanding of the text passages</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d0">SKILL</data>
      <data key="d1">Open Domain Question Answering is a method used to generate responses to questions over a wide range of topics, without being restricted to a specific domain. Additionally, it is employed to generate math problems for assessing AI models, showcasing its versatility in both general knowledge and specialized applications.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CONTENT CREATION">
      <data key="d0">SKILL</data>
      <data key="d1">Content creation involves generating original written, visual, or audio content for various purposes</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="EDITING">
      <data key="d0">SKILL</data>
      <data key="d1">Editing involves modifying existing content to improve its quality, tone, or fit for a specific context or audience</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="REPORTS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Reports are human-readable textual summaries generated from source data, often used in data-to-text tasks</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="EXPLANATIONS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Explanations are human-readable textual summaries generated from source data, often used in data-to-text tasks</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="NARRATIVES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Narratives are human-readable textual summaries generated from source data, often used in data-to-text tasks</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ENRICO FERMI">
      <data key="d0">PERSON</data>
      <data key="d1">Enrico Fermi was a physicist renowned for his contributions to the field of estimation problems, commonly referred to as Fermi problems. These problems involve making justified guesses or assumptions to reach quick, rough estimates of quantities.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="NAMED ENTITY RECOGNITION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Named Entity Recognition (NER) is a task in text extraction that involves identifying and classifying named entities in text into predefined categories such as names of persons, organizations, locations, and other significant entities. This process is crucial for structuring unstructured text data, enabling more effective information retrieval and analysis.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="KEYWORD EXTRACTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Keyword extraction is a task in text extraction that involves identifying and extracting important keywords or phrases from a larger text document. This process is essential for summarizing the main topics and themes within the text, enabling more efficient information retrieval and analysis.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="DATA FIELDS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Data fields are specific pieces of information extracted from unstructured text in text extraction tasks</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT CLASSIFICATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Text classification is a machine learning task where text documents are automatically classified into predefined categories, used for spam detection, sentiment analysis, and topic labeling among others</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CREATIVE CONTENT GENERATION">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Creative content generation involves the creation of original content, often involving elements of novelty, value, and surprise, and in AI, it refers to generating text, music, or images that are new, meaningful, and interesting</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FEW SHOT REASONING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Few-shot reasoning refers to the ability of a machine learning model to understand new concepts, patterns, or tasks with minimal examples or guidance, mimicking the human ability to learn quickly from few examples</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CONVERSATION">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Conversation refers to conversational agents or chatbots that interact with humans in a natural, human-like manner</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="AGENTINSTRUCT FLOW">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AgentInstruct Flow is a multifaceted process designed for text modification, enabling the editing and refining of written content to enhance its quality and effectiveness. Additionally, it facilitates models to interact with external tools or services via APIs, broadening its utility. Implemented for various capabilities, including reading comprehension, AgentInstruct Flow processes and understands text for learning and other applications, making it a versatile system in the realm of text processing and AI-driven interactions.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="ARGUMENT PASSAGE GENERATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Argument Passage Generator is a component of the Content Transformation Flow that generates argument passages from seed articles. This agent is adept at creating passages that articulate arguments, although these passages may occasionally contain logical inconsistencies.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="URIC ACID">
      <data key="d0">SUBSTANCE</data>
      <data key="d1">Uric acid is a chemical substance produced naturally by the breakdown of purine, which is found in red meat and seafood. Its levels in the body can be influenced by lifestyle choices, including alcohol consumption and physical inactivity. Excessive amounts of uric acid can lead to health complications such as hyperuricemia.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPERURICEMIA">
      <data key="d0">CONDITION</data>
      <data key="d1">Hyperuricemia is a condition characterized by high levels of uric acid in the blood, which is associated with an increased risk of cardiovascular disease.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPOURICEMIA">
      <data key="d0">CONDITION</data>
      <data key="d1">Hypouricemia is a condition characterized by low levels of uric acid in the blood. It is less common and usually does not present symptoms, but it can indicate underlying kidney or liver issues.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PURINE">
      <data key="d0">SUBSTANCE</data>
      <data key="d1">Purine is a type of dietary protein that, when broken down, produces uric acid</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="LSAT LOGICAL REASONING TEST">
      <data key="d0">TEST</data>
      <data key="d1">The LSAT Logical Reasoning test features specialized question categories, including assumption, strengthening/weakening, flaw, and inference questions</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="WEB CRAWLS">
      <data key="d0">PROCESS</data>
      <data key="d1">Web crawls encompass an extensive collection of human-generated text, which holds potential for generating reading comprehension materials</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="LABORATORY BLOOD AND URINE TESTS">
      <data key="d0">PROCESS</data>
      <data key="d1">Laboratory blood and urine tests are used to diagnose conditions like hyperuricemia and hypouricemia by measuring uric acid levels</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="SPAM DETECTION">
      <data key="d0">PROCESS</data>
      <data key="d1">Spam detection is a type of text classification task where text documents, such as emails, are automatically classified as spam or not spam</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="SENTIMENT ANALYSIS">
      <data key="d0">PROCESS</data>
      <data key="d1">Sentiment analysis is a type of text classification task where text documents are automatically classified based on the sentiment they express, such as positive, negative, or neutral</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="TOPIC LABELING">
      <data key="d0">PROCESS</data>
      <data key="d1">Topic labeling is a type of text classification task where text documents are automatically classified into predefined topics or categories</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="GROUNDED REASONING">
      <data key="d0">PROCESS</data>
      <data key="d1">Grounded reasoning is a task in reading comprehension that involves making inferences and drawing conclusions based on evidence from the text</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="ASSUMPTION QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Assumption questions are a type of question in the LSAT Logical Reasoning test that require identifying assumptions made in an argument</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="STRENGTHENING/WEAKENING QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Strengthening/weakening questions are a type of question in the LSAT Logical Reasoning test that require identifying how an argument can be strengthened or weakened</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FLAW QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Flaw questions are a type of question in the LSAT Logical Reasoning test that require identifying flaws in an argument</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="INFERENCE QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Inference questions are a type of question in the LSAT Logical Reasoning test that require drawing inferences from the given information</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="DEBATES AND CONVERSATIONS">
      <data key="d0">CONTENT TYPE</data>
      <data key="d1">Debates and conversations are types of content generated by the Content Transformation Flow for reading comprehension</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="LONG PASSAGES">
      <data key="d0">CONTENT TYPE</data>
      <data key="d1">Long passages are types of content generated by the Content Transformation Flow for reading comprehension</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="MEETING TRANSCRIPTS">
      <data key="d0">CONTENT TYPE</data>
      <data key="d1">Meeting transcripts are types of content generated by the Content Transformation Flow for reading comprehension</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="POEMS">
      <data key="d0">CONTENT TYPE</data>
      <data key="d1">Poems are types of content generated by the Content Transformation Flow for reading comprehension</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="SATIRICAL CONTENT">
      <data key="d0">CONTENT TYPE</data>
      <data key="d1">Satirical content is a type of content generated by the Content Transformation Flow for reading comprehension</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CARDIOVASCULAR DISEASE">
      <data key="d0">CONDITION</data>
      <data key="d1">Cardiovascular disease is a health condition that may be associated with high levels of uric acid in the blood, although the causal relationship is not conclusively established.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LABORATORY TESTS">
      <data key="d0">PROCEDURE</data>
      <data key="d1">Laboratory blood and urine tests are required to diagnose conditions related to uric acid levels</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Agents are defined to target specific categories of reading comprehension questions and generate questions based on a piece of text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CONTENT TRANSFORMATION AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Content Transformation Agent determines the subset of agents to engage in the orchestration process for generating (passage, question) pairs</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="SUGGESTER AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Suggester Agent provides suggestions to modify passages or questions to add complexity or create difficult distractors</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="EDITOR AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Editor Agent makes modifications to passages or questions based on suggestions to refine the content</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PARAPHRASING AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Paraphrasing Agent is an agent that takes a piece of text and creates paraphrased versions as part of text modification tasks.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="READING COMPREHENSION QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Reading comprehension questions are questions designed to assess understanding of a text, including types like literal, critical, evaluative, reasoning, and identifying assumptions</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPOTHETICAL STUDY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A hypothetical study is a suggested addition to a passage that could potentially strengthen an argument, requiring inference of its impact on relationships within the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="GENETIC PREDISPOSITION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Genetic predisposition refers to the likelihood of developing a condition based on genetic factors, which can add complexity to questions about relationships between conditions</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DISTRACTOR OPTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">A distractor option is a misleading answer choice that seems relevant but does not directly relate to the question, testing the ability to discern relevant from irrelevant information</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="TEXT MODIFICATION TASKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Text modification tasks include activities like paraphrasing, expansion, simplification, redacting, styling, and code switching to alter text attributes</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PASSAGE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A passage is a piece of text used as input for generating questions or for text modification tasks</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="ANSWER CHOICES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Answer choices are the options provided for a question, which can be modified to add complexity or create distractors</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CARDIOVASCULAR EVENTS">
      <data key="d0">CONDITION</data>
      <data key="d1">Cardiovascular events are incidents related to heart disease, which can be influenced by factors like genetic predisposition and uric acid levels</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">CONDITION</data>
    </node>
    <node id="RED MEAT">
      <data key="d0">SUBSTANCE</data>
      <data key="d1">Red meat is a type of food that contains uric acid</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="SEAFOOD">
      <data key="d0">SUBSTANCE</data>
      <data key="d1">Seafood is a type of food that contains uric acid</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="ALCOHOL CONSUMPTION">
      <data key="d0">LIFESTYLE CHOICE</data>
      <data key="d1">Alcohol consumption is a lifestyle choice that can influence uric acid levels</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PHYSICAL INACTIVITY">
      <data key="d0">LIFESTYLE CHOICE</data>
      <data key="d1">Physical inactivity is a lifestyle choice that can influence uric acid levels</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="KIDNEY ISSUES">
      <data key="d0">CONDITION</data>
      <data key="d1">Kidney issues can be indicated by low levels of uric acid</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LIVER ISSUES">
      <data key="d0">CONDITION</data>
      <data key="d1">Liver issues can be indicated by low levels of uric acid</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LITERAL COMPREHENSION QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Literal comprehension questions are a type of reading comprehension question that assesses understanding of explicit information in the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CRITICAL COMPREHENSION QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Critical comprehension questions are a type of reading comprehension question that assesses the ability to evaluate and analyze the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="EVALUATIVE COMPREHENSION QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Evaluative comprehension questions are a type of reading comprehension question that assesses the ability to make judgments about the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="REASONING QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Reasoning questions are a type of reading comprehension question that assesses the ability to draw inferences and conclusions from the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="IDENTIFYING ASSUMPTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Identifying assumptions is a type of reading comprehension question that assesses the ability to recognize underlying assumptions in the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="IDENTIFYING INFORMATION THAT STRENGTHENS/WEAKENS AN ARGUMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Identifying information that strengthens or weakens an argument is a type of reading comprehension question that assesses the ability to evaluate the strength of arguments in the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="ORDERING EVENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Ordering events is a type of reading comprehension question that assesses the ability to sequence events in the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="STRENGTHEN TYPE QUESTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Strengthen type question is a type of question that asks which information, if true, would most strengthen an argument presented in the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="MODIFY THE PASSAGE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Modify the passage is a task in the instruction refinement flow that involves changing the passage to make the question unanswerable or alter the answer</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="MODIFY THE QUESTIONS OR ANSWER CHOICES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Modify the questions or answer choices is a task in the instruction refinement flow that involves changing the questions or answer choices to add complexity</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PARAPHRASING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Paraphrasing involves rewriting text using different words and sentence structures while maintaining the original meaning. It is a text modification task that requires rephrasing the text while retaining its original meaning.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SIMPLIFICATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Simplification is a text modification task that involves making the text easier to understand</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="REDACTING OR REMOVING CONTENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Redacting or removing content is a text modification task that involves deleting parts of the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="STYLING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Styling is a text modification task that involves changing the style of the text</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CODE SWITCHING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Code Switching involves alternating between languages or dialects within a text, often to reflect bilingual speakers&#8217; patterns or for creative writing. It is a text modification task that entails changing the language or dialect used in the text. This practice is commonly observed among bilingual speakers and is utilized to convey nuanced meanings, cultural context, or stylistic elements in written communication.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="FINANCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Finance is a field that deals with the study of investments, money, and revenue management. It encompasses the management of money, including activities such as investing, borrowing, lending, budgeting, and saving. Additionally, finance is one of the domains tested in the FoFo benchmark, highlighting its significance in various analytical and evaluative contexts.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="SOCIAL IMPACT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Social impact refers to the effect of an activity on the social fabric of the community and well-being of individuals and families</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="FINANCIAL DISCOURSES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Financial discourses refer to conversations and discussions about financial topics</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="MARKETS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Markets refer to systems or environments where commercial dealings are conducted</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="ACTORS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Actors in finance refer to individuals or entities that participate in financial markets</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="INSTITUTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Institutions in finance refer to organizations that influence or participate in financial markets</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="NATASCHA VAN DER ZWAN">
      <data key="d0">PERSON</data>
      <data key="d1">Natascha van der Zwan is a researcher who identifies three distinct research streams that have approached financialization</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="FINANCIALIZATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Financialization is a broad concept that encompasses the increasing social impact and interconnection of financial discourses, markets, actors, and institutions</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="UNIVERSITY OF IOWA">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The University of Iowa is the location where an event took place from April 6-8, 2017</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="AMERICAN ANTHROPOLOGICAL ASSOCIATION">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The American Anthropological Association is an organization that manages the registration and abstract submission process for the SEA 2017 Annual Meeting</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SEA 2017 ANNUAL MEETING">
      <data key="d0">EVENT</data>
      <data key="d1">The SEA 2017 Annual Meeting is an event held at the University of Iowa from April 6-8, 2017, with an abstract deadline of December 1, 2016</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTER-EDITOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Suggester-Editor is a duo that increases the complexity of generated instructions by providing suggestions and edits</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="API RETRIEVAL AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The API Retrieval Agent is a system that iteratively searches for similar code to expand an API list</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="VIEW ALL FOOD ITEMS">
      <data key="d0">API</data>
      <data key="d1">View All Food Items is an API that enables clients to obtain a detailed list of food items, complete with nutritional profiles</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SEARCH FOOD ITEMS">
      <data key="d0">API</data>
      <data key="d1">"Search Food Items" is an API that enables clients to search for food items by name and retrieve a list of matching items. It requires a query parameter and optionally accepts a limit parameter to restrict the number of search results returned.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="IOWA CITY">
      <data key="d0">LOCATION</data>
      <data key="d1">Iowa City is the location where the SEA 2017 Annual Meeting was held</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="DECEMBER 1, 2016">
      <data key="d0">DATE</data>
      <data key="d1">December 1, 2016, is the abstract submission deadline for the SEA 2017 Annual Meeting</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="RANDOM SEED">
      <data key="d0">CONCEPT</data>
      <data key="d1">A random seed is a value or set of values used to initialize a random number generator, often used in the context of generating random instructions or tasks</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="API DESCRIPTION">
      <data key="d0">DOCUMENT</data>
      <data key="d1">An API description is a document that provides details about an API, including its name, description, parameters, and usage</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="LIBRARY RECONSTRUCTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Library Reconstruction is a scenario in the Content Transformation Flow where a list of APIs is synthesized from a random seed</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="NUTRITIONAL PROFILES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Nutritional profiles refer to the detailed information about the nutritional content of food items, such as calorie count, protein, and fat</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="GET FOOD ITEM DETAILS">
      <data key="d0">API</data>
      <data key="d1">Get Food Item Details is an API that retrieves detailed information about a specific food item</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="CREATE MEAL PLAN">
      <data key="d0">API</data>
      <data key="d1">Create Meal Plan is an API that allows clients to create a meal plan based on specified parameters such as dietary preferences, caloric goals, and the number of meals per day</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="UPDATE FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">Update Food Item is an API that allows clients to update the details of an existing food item</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="TRACK USER MEAL">
      <data key="d0">API</data>
      <data key="d1">Track User Meal is an API that allows clients to track the meals consumed by a user</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET DIETARY RECOMMENDATIONS">
      <data key="d0">API</data>
      <data key="d1">Get Dietary Recommendations is an API that provides dietary recommendations based on user preferences and nutritional needs</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="ADD NEW FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">Add New Food Item is an API that allows clients to add a new food item to the database</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="DELETE FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">Delete Food Item is an API that allows clients to remove a food item from the database</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET USER NUTRITIONAL STATS">
      <data key="d0">API</data>
      <data key="d1">Get User Nutritional Stats is an API that retrieves the nutritional statistics of a user</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="AGENT-INSTRUCT">
      <data key="d0">SYSTEM</data>
      <data key="d1">Agent-Instruct is a system that creates multi-turn conversations to assist users in achieving their desired outcomes by utilizing a variety of APIs and producing markdown outputs at each step</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="ASSISTANT">
      <data key="d0">SYSTEM</data>
      <data key="d1">The Assistant is an AI system designed to help users achieve their desired outcomes by utilizing various APIs and following a structured process to provide responses and actions</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="CHANA MASALA">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">Chana Masala is a food item that the user wants to update in the database, requiring its unique identifier. Additionally, the user aims to adjust the calorie count of Chana Masala to a lower value.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="BUTTER CHICKEN">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">Butter Chicken is a food item that the user wants to remove from the database, requiring its unique identifier.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="QUINOA SALAD">
      <data key="d0" />
      <data key="d1">QUINOA SALAD is a food item that the user wants to add to the database, requiring nutritional information for its addition.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="VEGETARIAN MEAL PLAN">
      <data key="d0">PLAN</data>
      <data key="d1">A meal plan designed for vegetarians with a caloric goal of 1500 calories per day, consisting of three meals a day</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CALORIC GOAL">
      <data key="d0">METRIC</data>
      <data key="d1">The target number of calories to be consumed per day, set at 1500 calories for the meal plan</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="OATMEAL WITH FRUITS">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A breakfast food item included in the vegetarian meal plan, consisting of oatmeal and fruits</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ALMOND MILK">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A breakfast beverage included in the vegetarian meal plan, made from almonds</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CHICKPEA SALAD">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A lunch food item included in the vegetarian meal plan, consisting of chickpeas and other salad ingredients</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="WHOLE WHEAT BREAD">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A lunch food item included in the vegetarian meal plan, made from whole wheat</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MIXED VEGETABLE STIR FRY">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A dinner food item included in the vegetarian meal plan, consisting of various stir-fried vegetables</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="BROWN RICE">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A dinner food item included in the vegetarian meal plan, made from whole grain rice</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="KNOWLEDGEPILE">
      <data key="d0">DATASET</data>
      <data key="d1">A source of unstructured text and code files used as seeds for instruction data generation in the AgentInstruct system</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="AUTOMATHTEXT">
      <data key="d0">DATASET</data>
      <data key="d1">A source of unstructured text and code files used as seeds for instruction data generation in the AgentInstruct system</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-1">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset consisting of paired instructions used in the training of Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-2">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset consisting of paired instructions used in the training of Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-MATH">
      <data key="d0">DATASET</data>
      <data key="d1">ORCA-MATH is a system designed to unlock the potential of small language models in grade school math, published in 2024. It includes a dataset consisting of paired instructions used in the training of Orca-3. This innovative approach aims to enhance the capabilities of language models in educational settings, particularly focusing on improving mathematical understanding and problem-solving skills among grade school students.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ORCA-2.5">
      <data key="d0">MODEL</data>
      <data key="d1">ORCA-2.5 is a baseline model evaluated on the Orca-Bench dataset. It was trained using approximately 3.8 million paired instructions and is used to compare and evaluate the impact of the 22 million instructions curated through AgentInstruct.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,8ee9617c145e19fa95f1f9349bfbe69b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MISTRAL-7B-V0.1">
      <data key="d0">MODEL</data>
      <data key="d1">The base model finetuned using the AgentInstruct dataset to create Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="NVIDIA A100">
      <data key="d0">HARDWARE</data>
      <data key="d1">The type of GPU used in the training of Orca-3, with 152 GPUs used in total</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ADAMW OPTIMIZER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The optimizer used in the training of Orca-3, with an initial learning rate of 8e-6</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-BENCH">
      <data key="d0">DATASET</data>
      <data key="d1">ORCA-BENCH is a held-out test set used to evaluate the performance of models trained with the AgentInstruct dataset. It consists of 100 samples from each of the 17 skills. Additionally, Orca-Bench serves as a dataset to assess the performance of various baseline models, with scores being measured relative to GPT-4 on a scale from 0 to 10.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="DATABASE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 2">
      <data key="d0">TIME PERIOD</data>
      <data key="d1">The second day in the vegetarian meal plan, consisting of three meals: breakfast, lunch, and dinner</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 3">
      <data key="d0">TIME PERIOD</data>
      <data key="d1">The third day in the vegetarian meal plan, consisting of three meals: breakfast, lunch, and dinner</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 4">
      <data key="d0">TIME PERIOD</data>
      <data key="d1">The fourth day in the vegetarian meal plan, consisting of three meals: breakfast, lunch, and dinner</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 5">
      <data key="d0">TIME PERIOD</data>
      <data key="d1">The fifth day in the vegetarian meal plan, consisting of three meals: breakfast, lunch, and dinner</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 6">
      <data key="d0">TIME PERIOD</data>
      <data key="d1">The sixth day in the vegetarian meal plan, consisting of three meals: breakfast, lunch, and dinner</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 7">
      <data key="d0">TIME PERIOD</data>
      <data key="d1">The seventh day in the vegetarian meal plan, consisting of three meals: breakfast, lunch, and dinner</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="NUTRITIONAL INFORMATION">
      <data key="d0">METRIC</data>
      <data key="d1">The data required to add the Quinoa Salad recipe to the database, including details like calories, protein, fat, etc.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="FOOD_ID">
      <data key="d0">METRIC</data>
      <data key="d1">The unique identifier required to update or remove food items like Chana Masala and Butter Chicken from the database</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="OPENSTAX">
      <data key="d0">DATASET</data>
      <data key="d1">A source of unstructured text used as seeds for instruction data generation in the AgentInstruct system</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="APACHE-2.0 LICENSED SOURCE CODE">
      <data key="d0">DATASET</data>
      <data key="d1">A subset of source code files used as seeds for instruction data generation in the AgentInstruct system</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-2.5-DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset consisting of approximately 3.8 million paired instructions used to train the Orca-2.5 model</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="TOKENIZATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The process applied to each pair in the dataset using the Mistral tokenizer, ensuring a maximum sequence length of 8192 with packing</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="LABEL MASKING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A technique used during training to ensure that the training loss is calculated based only on the response conditioned on the prompt</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="WEIGHT DECAY">
      <data key="d0">METRIC</data>
      <data key="d1">A parameter set at 0.1 during the training of Orca-3 to prevent overfitting</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="BATCH SIZE">
      <data key="d0">METRIC</data>
      <data key="d1">The number of training examples utilized in one iteration, set at 10 for each of the 152 NVIDIA A100 GPUs used in the training of Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="INITIAL LEARNING RATE">
      <data key="d0">METRIC</data>
      <data key="d1">The starting learning rate for the AdamW optimizer, set at 8e-6 during the training of Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="COSINE LEARNING RATE SCHEDULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A learning rate schedule used during the training of Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="LINEAR LEARNING RATE WARM-UP">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A technique used during the initial 500 steps of training Orca-3 to gradually increase the learning rate</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="EPOCH">
      <data key="d0">METRIC</data>
      <data key="d1">A full pass through the training dataset, with Orca-3 being trained for three epochs</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="TRAINING HOURS">
      <data key="d0">METRIC</data>
      <data key="d1">The total time taken to train Orca-3, approximately 200 hours</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="OPEN DOMAIN QUESTION ANSWERING (ODQA)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A category in the Orca-Bench dataset consisting of 100 questions originated from the initial seed instruction phase</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="COMPLEX ODQA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">COMPLEX ODQA is a subset of the ODQA category in the Orca-Bench dataset. It includes more intricate questions that were developed during the refinement phase. This subset is specifically designed to address more complex queries, enhancing the overall depth and challenge of the dataset.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MULTI-TURN INTERACTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A type of interaction in the Orca-Bench dataset involving multiple exchanges</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 1">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CHATGPT">
      <data key="d0">MODEL</data>
      <data key="d1">ChatGPT is a baseline model evaluated on the Orca-Bench dataset</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="LLAMA3-8B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">LLAMA3-8B-Instruct is a baseline language model evaluated on the Orca-Bench dataset. It is used for comparison in various evaluations, highlighting its role in benchmarking and assessing the performance of other models within the AI and ML communities.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="FOFO">
      <data key="d0">BENCHMARK</data>
      <data key="d1">FOFO, also known as Format Following (FoFo), is a benchmark designed to evaluate the performance of models on format-following tasks. It assesses a model's ability to adhere to complex, domain-specific formats across various real-world domains. FOFO uses GPT-4 as a judge to score the format correctness of model responses, with scores ranging between 0 and 1. This benchmark is utilized to evaluate the performance of various models, including Orca-3 and other baselines.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="IFEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">IFEval, or Instruction-Following Evaluation, is a benchmark designed to assess a model's ability to follow natural language instructions. It evaluates the performance of various models, including Orca-3 and other baselines, by checking if the model responses adhere to verifiable instructions provided in the prompts. IFEval utilizes a set of 500 prompts that cover 25 different types of verifiable instructions, making it a comprehensive tool for measuring instruction-following capabilities in AI models.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="INFOBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">INFOBENCH is a benchmark designed to evaluate the instruction-following capability of various models, including Orca-3 and other baselines. It utilizes the Decomposed Requirements Following Ratio (DRFR) metric to assess performance. Evaluated using GPT-4, INFOBENCH determines if model responses adhere to decomposed instructions. This system, published in 2024, provides a comprehensive framework for assessing the instruction-following ability in large language models.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="EQBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">EQBench is an Emotional Intelligence benchmark designed to evaluate the performance of various models, including Orca-3 and other baselines. It serves as a dataset to assess models on their ability to generate emotion scores based on conversations. By testing the capabilities of language models to comprehend intricate emotions and social interactions, EQBench provides a comprehensive measure of emotional intelligence in AI systems.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="METRIC-V2">
      <data key="d0">BENCHMARK</data>
      <data key="d1">METRIC-V2 is a benchmark used to evaluate the performance of various models, including Orca-3 and other baselines. It serves as a performance metric that has demonstrated a 4% improvement over previous metrics, making it a valuable tool for assessing model efficacy in the field of Artificial Intelligence and Machine Learning.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="METRIC-V1">
      <data key="d0">BENCHMARK</data>
      <data key="d1">METRIC-V1 is a benchmark used to evaluate the performance of various models, including Orca-3 and other baselines. It serves as a performance metric that has demonstrated a 28% improvement over previous metrics, making it a significant tool in assessing model efficacy.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="INSTRUCTION PHASE">
      <data key="d0">PHASE</data>
      <data key="d1">The instruction phase is a phase during which questions are developed for the dataset</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="REFINEMENT PHASE">
      <data key="d0">PHASE</data>
      <data key="d1">The refinement phase is a phase during which more intricate questions are developed for the dataset</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="SYSTEM MESSAGE">
      <data key="d0">MESSAGE</data>
      <data key="d1">A system message is part of a multi-turn interaction in the Orca-Bench dataset</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="USER MESSAGE">
      <data key="d0">MESSAGE</data>
      <data key="d1">A user message is part of a multi-turn interaction in the Orca-Bench dataset</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ASSISTANT MESSAGE">
      <data key="d0">MESSAGE</data>
      <data key="d1">An assistant message is part of a multi-turn interaction in the Orca-Bench dataset</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="TEACHER">
      <data key="d0">ROLE</data>
      <data key="d1">The teacher is GPT-4, which crafts each turn in a multi-turn interaction in the Orca-Bench dataset</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="STUDENT">
      <data key="d0">ROLE</data>
      <data key="d1">The student generates responses conditioned on the preceding conversation history as established by the teacher. The student is the individual whose responses are being evaluated and parsed.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ORCA-3 CHECKPOINT">
      <data key="d0">MODEL</data>
      <data key="d1">Orca-3 Checkpoint is a specific version of the Orca-3 model evaluated at different epochs</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ORCA-3 (CHECKPOINT EPOCH 1)">
      <data key="d0">MODEL</data>
      <data key="d1">Orca-3 (checkpoint epoch 1) is a specific version of the Orca-3 model evaluated at the first epoch</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ORCA-3 (CHECKPOINT EPOCH 2)">
      <data key="d0">MODEL</data>
      <data key="d1">Orca-3 (checkpoint epoch 2) is a specific version of the Orca-3 model evaluated at the second epoch</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="LSAT">
      <data key="d0">EXAM</data>
      <data key="d1">The Law School Admission Test (LSAT) is a standardized test used for law school admissions, known for its difficulty. It is particularly challenging in its reading comprehension sections, which are designed to assess a candidate's ability to understand and analyze complex texts. The LSAT plays a crucial role in the admissions process for law schools, serving as a key indicator of a prospective student's readiness for the rigors of legal education.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="ORCA 2.5">
      <data key="d0">MODEL</data>
      <data key="d1">ORCA 2.5 is a model used as a baseline for comparison in reading comprehension capabilities and performance in various benchmarks. It serves as a previous version of the Orca language model, specifically used for comparison with Orca-3-7B.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="ALLENAI">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">AllenAI is the organization that developed the AI2 Reasoning Challenge (ARC) benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="SAT">
      <data key="d0">EXAM</data>
      <data key="d1">The SAT is a standardized test used for college admissions, included in the AGIEval benchmark.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="MATH COMPETITIONS">
      <data key="d0">EXAM</data>
      <data key="d1">Math competitions are included in the AGIEval benchmark to evaluate problem-solving abilities</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="PHILOSOPHY">
      <data key="d0">SUBJECT</data>
      <data key="d1">Philosophy is one of the 57 academic subjects covered in the MMLU benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="MEDICINE">
      <data key="d0">SUBJECT</data>
      <data key="d1">Medicine is one of the 57 academic subjects covered in the MMLU benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="PSYCHOLOGY">
      <data key="d0">SUBJECT</data>
      <data key="d1">Psychology is one of the 57 academic subjects covered in the MMLU benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="COMPUTER-SCIENCE">
      <data key="d0">SUBJECT</data>
      <data key="d1">Computer Science is one of the 57 academic subjects covered in the MMLU benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="LAW">
      <data key="d0">SUBJECT</data>
      <data key="d1">Law is one of the 57 academic subjects covered in the MMLU benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="BIOLOGY">
      <data key="d0">SUBJECT</data>
      <data key="d1">Biology is one of the subjects in the GPQA benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="CHEMISTRY">
      <data key="d0">SUBJECT</data>
      <data key="d1">Chemistry is one of the subjects in the GPQA benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="PHYSICS">
      <data key="d0">SUBJECT</data>
      <data key="d1">Physics is one of the subjects in the GPQA benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="HEALTHCARE">
      <data key="d0">DOMAIN</data>
      <data key="d1">Healthcare is one of the domains tested in the FoFo benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="MARKETING">
      <data key="d0">DOMAIN</data>
      <data key="d1">Marketing is one of the domains tested in the FoFo benchmark</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="DRFR">
      <data key="d0">METRIC</data>
      <data key="d1">Decomposed Requirements Following Ratio (DRFR) is a metric used in the InFoBench benchmark to evaluate instruction-following capability</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="MULTIPLE-CHOICE QUESTIONS FLOWS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Multiple-Choice Questions Flows is a method used to generate math problems for assessing AI models</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ORCA-3-7B">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Orca-3-7B is a language model that has demonstrated significant improvements over its predecessors, Orca 2.5 and Mistral-7B-Instruct, across various benchmarks. It has been evaluated on the FoFo benchmark and the MIRAGE Datasets, showing notable advancements in RAG tasks and overall performance.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DROOP">
      <data key="d0">BENCHMARK</data>
      <data key="d1">DROOP is a benchmark used to evaluate the performance of models on reading comprehension tasks</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="BBH MULTISTEP-ARITHMETIC-TWO">
      <data key="d0">BENCHMARK</data>
      <data key="d1">BBH multistep-arithmetic-two is a benchmark used to evaluate the performance of models on multi-step arithmetic problems</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="FORMAT FOLLOWING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Format Following is a capability of language models to adhere to specific formatting guidelines, essential for real-world applications</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="GEMINI PRO">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GEMINI PRO is a language model whose scores are referenced from the original paper. It is used as a baseline for performance comparison in format-following tasks.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="LSAT-RC">
      <data key="d0">BENCHMARK</data>
      <data key="d1">LSAT-RC is a reading comprehension sub-task of the LSAT used to evaluate model performance</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="SAT-EN">
      <data key="d0">BENCHMARK</data>
      <data key="d1">SAT-EN is an English sub-task of the SAT used to evaluate model performance</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="GAOKAO-ENGLISH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">Gaokao-English is an English sub-task of the Gaokao used to evaluate model performance</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="LSAT-LR">
      <data key="d0">BENCHMARK</data>
      <data key="d1">LSAT-LR is a logical reasoning sub-task of the LSAT used to evaluate model performance</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="SAT-MATH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">SAT-Math is a math sub-task of the SAT used to evaluate model performance</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="ABSTRACT ALGEBRA">
      <data key="d0">BENCHMARK</data>
      <data key="d1">Abstract Algebra is a sub-task of the MMLU used to evaluate model performance in abstract algebra</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="COLLEGE MATHEMATICS">
      <data key="d0">BENCHMARK</data>
      <data key="d1">College Mathematics is a sub-task of the MMLU used to evaluate model performance in college-level mathematics</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="HIGH-SCHOOL MATHEMATICS">
      <data key="d0">BENCHMARK</data>
      <data key="d1">High-School Mathematics is a sub-task of the MMLU used to evaluate model performance in high school-level mathematics</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="GAOKAO">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="FOFO BENCHMARK">
      <data key="d0">BENCHMARK</data>
      <data key="d1">FoFo benchmark is used to evaluate the performance of language models, including Orca-3-7B</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="HALLUCINATIONS">
      <data key="d0">METRIC</data>
      <data key="d1">Hallucinations is a metric used to assess the accuracy of generated summaries by language models</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="QUALITY">
      <data key="d0">METRIC</data>
      <data key="d1">Quality is a metric used to assess the overall quality of generated summaries by language models</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="ACI-BENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">ACI-Bench is a dataset designed for benchmarking automatic report generation from doctor-patient conversations</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="INSTRUSUM">
      <data key="d0">BENCHMARK</data>
      <data key="d1">InstruSum is a dataset for evaluating the generation capabilities of language models for instruction-controllable summarization</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="ORCA-SUM">
      <data key="d0">BENCHMARK</data>
      <data key="d1">Orca-Sum is a newly created benchmark to evaluate language models' ability to follow summarization and grounded data transformation instructions</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MIRAGE">
      <data key="d0">BENCHMARK</data>
      <data key="d1">MIRAGE is a benchmark focusing on answering medical questions by referring to information retrieved from a medical corpus</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MMLU-MED">
      <data key="d0">DATASET</data>
      <data key="d1">MMLU-Med is a dataset used in the MIRAGE benchmark for evaluating medical question answering</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MEDQA-US">
      <data key="d0">DATASET</data>
      <data key="d1">MedQA-US is a dataset used in the MIRAGE benchmark for evaluating medical question answering</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MEDMCQA">
      <data key="d0">DATASET</data>
      <data key="d1">MedMCQA is a dataset used in the MIRAGE benchmark for evaluating medical question answering</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="PUBMEDQA">
      <data key="d0">DATASET</data>
      <data key="d1">PubMedQA is a dataset used in the MIRAGE benchmark for evaluating medical question answering. It is one of the datasets included in the MIRAGE Datasets and is considered an effective testbed for assessing models' ability to perform Retrieval-Augmented Generation (RAG).</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="BIOASQ">
      <data key="d0">DATASET</data>
      <data key="d1">BIOASQ is a dataset used in the MIRAGE benchmark for evaluating medical question answering. It is one of the datasets included in the MIRAGE Datasets, which are designed to assess the performance of AI and ML models in the domain of medical information retrieval and question answering.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="TABLE 6">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Table 6 presents the performance of the Orca-3-7B model and other open and closed-source baselines on the FoFo benchmark</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="TABLE 7">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Table 7 presents hallucination rates and quality scores evaluated by GPT-4 for various models</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="HUGGING FACE">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Hugging Face is a platform from which data was sampled to create the Orca-Sum benchmark</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="TIKTOK VIDEO">
      <data key="d0">DOCUMENT</data>
      <data key="d1">TikTok video is an example of a format that a language model may be asked to generate from a scientific paper</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="SCIENTIFIC PAPER">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Scientific paper is an example of a source document that a language model may be asked to transform into another format</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="LEGAL CONTRACT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Legal contract is an example of a format that a language model may be asked to generate from a Wikipedia page</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="WIKIPEDIA PAGE">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Wikipedia page is an example of a source document that a language model may be asked to transform into another format</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="CO-T">
      <data key="d0">TASK</data>
      <data key="d1">CoT (Chain of Thought) is a method used by GPT-4 for reasoning through complex problems</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="RAG DATA">
      <data key="d0">DATASET</data>
      <data key="d1">RAG data refers to the data used in the Retrieval Augmented Generation skill evaluations</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="NON-MEDICAL DATA">
      <data key="d0">DATASET</data>
      <data key="d1">Non-medical data is a type of data seed used in the AgentInstruct RAG evaluations to test the skill in new domains</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MEDMEDQA">
      <data key="d0">DATASET</data>
      <data key="d1">MedMedQA is one of the datasets included in the MIRAGE Datasets</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="USMEDMCQA">
      <data key="d0">DATASET</data>
      <data key="d1">USMedMCQA is one of the datasets included in the MIRAGE Datasets</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="ORCA-2.5-7B">
      <data key="d0">MODEL</data>
      <data key="d1">Orca-2.5-7B is a model evaluated on the MIRAGE Datasets, showing performance in both CoT and RAG tasks</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MISTRAL-7B-INSTRUCT-V0.1">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-7B-Instruct-v0.1 is a model evaluated on the MIRAGE Datasets, showing performance in both CoT and RAG tasks</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MEDRAG">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">MedRAG is the retrieval mechanism used across all models on the MIRAGE Datasets</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="AZURE">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Azure is a cloud computing service created by Microsoft, which provides various services including transparency notes related to AI technologies. Azure is particularly recommended for reviewing transparency notes related to large language models.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MIRAGE DATASETS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="CONTENT HARMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Content harms refer to the various types of harmful content that large language models can generate, necessitating awareness and preventive actions</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CONTENT MODERATION SERVICES">
      <data key="d0">SERVICE</data>
      <data key="d1">Content moderation services are provided by different companies and institutions to help prevent content harms caused by large language models</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GOVERNMENT">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Government entities are expected to provide better regulations and standards around content harms for AI technologies in the future</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="TECHNOLOGY LEADERS">
      <data key="d0">GROUP</data>
      <data key="d1">Technology leaders are expected to contribute to better regulations and standards around content harms for AI technologies in the future</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RESEARCH COMMUNITY">
      <data key="d0">GROUP</data>
      <data key="d1">The research community plays an important role in addressing content harms and improving AI technologies</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OPEN SOURCE COMMUNITY">
      <data key="d0">GROUP</data>
      <data key="d1">The open source community plays an important role in addressing content harms and improving AI technologies</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HALLUCINATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Hallucination refers to the phenomenon where language models fabricate content, making it unreliable for critical decisions or information</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="25M PAIR DATASET">
      <data key="d0">DATA</data>
      <data key="d1">A 25M pair dataset generated by AgentInstruct was used to post-train the Orca-3 model, resulting in a notable performance gain</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARAH ABDIN">
      <data key="d0">PERSON</data>
      <data key="d1">Marah Abdin is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SAM ADE JACOBS">
      <data key="d0">PERSON</data>
      <data key="d1">Sam Ade Jacobs is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMMAR AHMAD AWAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ammar Ahmad Awan is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JYOTI ANEJA">
      <data key="d0">PERSON</data>
      <data key="d1">Jyoti Aneja is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HANY AWADALLA">
      <data key="d0">PERSON</data>
      <data key="d1">Hany Awadalla is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NGUYEN BACH">
      <data key="d0">PERSON</data>
      <data key="d1">Nguyen Bach is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIT BAHREE">
      <data key="d0">PERSON</data>
      <data key="d1">Amit Bahree is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ARASH BAKHTIARI">
      <data key="d0">PERSON</data>
      <data key="d1">Arash Bakhtiari is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIANMIN BAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jianmin Bao is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HARKIRAT BEHL">
      <data key="d0">PERSON</data>
      <data key="d1">Harkirat Behl is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ALON BENHAIM">
      <data key="d0">PERSON</data>
      <data key="d1">Alon Benhaim is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MISHA BILENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Misha Bilenko is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JOHAN BJORCK">
      <data key="d0">PERSON</data>
      <data key="d1">Johan Bjorck is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="S&#201;BASTIEN BUBECK">
      <data key="d0">PERSON</data>
      <data key="d1">S&#233;bastien Bubeck is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="QIN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Qin Cai is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARTIN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Martin Cai is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CAIO C&#201;SAR TEODORO MENDES">
      <data key="d0">PERSON</data>
      <data key="d1">Caio C&#233;sar Teodoro Mendes is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="VISHRAV CHAUDHARY">
      <data key="d0">PERSON</data>
      <data key="d1">Vishrav Chaudhary is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Dong Chen is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONGDONG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Dongdong Chen is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YEN-CHUN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yen-Chun Chen is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YI-LING CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yi-Ling Chen is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PARUL CHOPRA">
      <data key="d0">PERSON</data>
      <data key="d1">Parul Chopra is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIYANG DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Xiyang Dai is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ALLIE DEL GIORNO">
      <data key="d0">PERSON</data>
      <data key="d1">Allie Del Giorno is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GUSTAVO DE ROSA">
      <data key="d0">PERSON</data>
      <data key="d1">Gustavo de Rosa is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MATTHEW DIXON">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew Dixon is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RONEN ELDAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ronen Eldan is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="VICTOR FRAGOSO">
      <data key="d0">PERSON</data>
      <data key="d1">Victor Fragoso is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DAN ITER">
      <data key="d0">PERSON</data>
      <data key="d1">Dan Iter is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MEI GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Mei Gao is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MIN GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Min Gao is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIANFENG GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jianfeng Gao is a notable figure in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the Phi-3 technical report and has also contributed to the paper titled "Instruction tuning with GPT-4," which was published in 2023. His work demonstrates a significant involvement in advancing AI research, particularly in the areas of technical reporting and instruction tuning with advanced language models like GPT-4.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIT GARG">
      <data key="d0">PERSON</data>
      <data key="d1">Amit Garg is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ABHISHEK GOSWAMI">
      <data key="d0">PERSON</data>
      <data key="d1">Abhishek Goswami is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SURIYA GUNASEKAR">
      <data key="d0">PERSON</data>
      <data key="d1">Suriya Gunasekar is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="EMMAN HAIDER">
      <data key="d0">PERSON</data>
      <data key="d1">Emman Haider is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JUNHENG HAO">
      <data key="d0">PERSON</data>
      <data key="d1">Junheng Hao is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RUSSELL J. HEWETT">
      <data key="d0">PERSON</data>
      <data key="d1">Russell J. Hewett is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JAMIE HUYNH">
      <data key="d0">PERSON</data>
      <data key="d1">Jamie Huynh is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MOJAN JAVAHERIPI">
      <data key="d0">PERSON</data>
      <data key="d1">Mojan Javaheripi is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIN JIN">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Jin is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PIERO KAUFFMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Piero Kauffmann is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NIKOS KARAMPATZIAKIS">
      <data key="d0">PERSON</data>
      <data key="d1">Nikos Karampatziakis is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONGWOO KIM">
      <data key="d0">PERSON</data>
      <data key="d1">Dongwoo Kim is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MAHOUD KHADEMI">
      <data key="d0">PERSON</data>
      <data key="d1">Mahoud Khademi is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LEV KURILENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Lev Kurilenko is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JAMES R. LEE">
      <data key="d0">PERSON</data>
      <data key="d1">James R. Lee is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YIN TAT LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Yin Tat Lee is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YUANZHI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yuanzhi Li is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YUNSHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yunsheng Li is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHEN LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Liang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LARS LIDEN">
      <data key="d0">PERSON</data>
      <data key="d1">Lars Liden is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CE LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Ce Liu is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MENGCHEN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Mengchen Liu is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="WEISHUNG LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Weishung Liu is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ERIC LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Lin is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHONG LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Chong Luo is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PIYUSH MADAN">
      <data key="d0">PERSON</data>
      <data key="d1">Piyush Madan is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MATT MAZZOLA">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Mazzola is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HARDIK MODI">
      <data key="d0">PERSON</data>
      <data key="d1">Hardik Modi is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BRANDON NORICK">
      <data key="d0">PERSON</data>
      <data key="d1">Brandon Norick is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BARUN PATRA">
      <data key="d0">PERSON</data>
      <data key="d1">Barun Patra is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DANIEL PEREZ-BECKER">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Perez-Becker is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="THOMAS PORTET">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Portet is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="REID PRYZANT">
      <data key="d0">PERSON</data>
      <data key="d1">Reid Pryzant is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HEYANG QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Heyang Qin is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARKO RADMILAC">
      <data key="d0">PERSON</data>
      <data key="d1">Marko Radmilac is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SAMBUDHA ROY">
      <data key="d0">PERSON</data>
      <data key="d1">Sambudha Roy is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OLATUNJI RUWASE">
      <data key="d0">PERSON</data>
      <data key="d1">Olatunji Ruwase is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OLLI SAARIKIVI">
      <data key="d0">PERSON</data>
      <data key="d1">Olli Saarikivi is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIN SAIED">
      <data key="d0">PERSON</data>
      <data key="d1">Amin Saied is a notable contributor in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the Phi-3 technical report, showcasing his involvement in significant technical documentation. Additionally, in 2023, Amin Saied co-authored the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," highlighting his active participation in advancing human-centric evaluation methodologies for foundational AI models. His work reflects a commitment to both technical rigor and the development of evaluative benchmarks in AI research.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ADIL SALIM">
      <data key="d0">PERSON</data>
      <data key="d1">Adil Salim is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MICHAEL SANTACROCE">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Santacroce is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SHITAL SHAH">
      <data key="d0">PERSON</data>
      <data key="d1">Shital Shah is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NING SHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ning Shang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HITESHI SHARMA">
      <data key="d0">PERSON</data>
      <data key="d1">Hiteshi Sharma is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SWADHEEN SHUKLA">
      <data key="d0">PERSON</data>
      <data key="d1">Swadheen Shukla is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIA SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Xia Song is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MASAHIRO TANAKA">
      <data key="d0">PERSON</data>
      <data key="d1">Masahiro Tanaka is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ANDREA TUPINI">
      <data key="d0">PERSON</data>
      <data key="d1">Andrea Tupini is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Wang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LIJUAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Lijuan Wang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHUNYU WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chunyu Wang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YU WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Wang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RACHEL WARD">
      <data key="d0">PERSON</data>
      <data key="d1">Rachel Ward is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GUANHUA WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Guanhua Wang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PHILIPP WITTE">
      <data key="d0">PERSON</data>
      <data key="d1">Philipp Witte is one of the authors of the Phi-3 technical report, titled "A highly capable language model locally on your phone," published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HAIPING WU">
      <data key="d0">PERSON</data>
      <data key="d1">Haiping Wu is one of the authors of the Phi-3 technical report, titled "A highly capable language model locally on your phone, 2024."</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MICHAEL WYATT">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Wyatt is one of the authors of the Phi-3 technical report, titled "A highly capable language model locally on your phone, 2024."</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BIN XIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Bin Xiao is one of the authors of the Phi-3 technical report titled "A highly capable language model locally on your phone, 2024."</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CAN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Can Xu is a notable contributor in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the Phi-3 technical report, titled "A highly capable language model locally on your phone," published in 2024. Additionally, Can Xu co-authored the paper "Wizardlm: Empowering large language models to follow complex instructions," which was published in 2023. His work focuses on advancing the capabilities of language models, making significant strides in enabling complex instruction-following and local deployment of AI technologies.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAHANG XU">
      <data key="d0">PERSON</data>
      <data key="d1">Jiahang Xu is one of the authors of the Phi-3 technical report: "A highly capable language model locally on your phone," published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="TRANSPARENCY NOTES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Transparency notes from Azure provide information about the rationale behind specific outputs or decisions made by AI models</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DISINFORMATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Disinformation refers to false information that is spread deliberately to deceive people, which can be generated by large language models without suitable safeguards</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DATA DISTRIBUTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Data distribution refers to the way in which data is spread across different categories or areas, affecting the performance of models like Orca-3</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="UNSTRUCTURED DATA">
      <data key="d0">DATA</data>
      <data key="d1">Unstructured data refers to information that does not have a pre-defined data model, which can be used by AgentInstruct to generate tailored datasets</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PHI-3 TECHNICAL REPORT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The PHI-3 TECHNICAL REPORT is a comprehensive document authored by multiple researchers, detailing the technical aspects of the Phi-3 model. Titled "A highly capable language model locally on your phone," this report was published in 2024. It provides an in-depth analysis of the Phi-3 model, highlighting its capabilities and the innovative technology that allows it to operate efficiently on mobile devices.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AI TECHNOLOGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI technologies refer to the various applications and systems that use artificial intelligence to perform tasks, which can be subject to content harms and hallucinations</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="REGULATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Regulations refer to rules or directives made and maintained by an authority, which are hoped to be improved by government and technology leaders for AI technologies</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="STANDARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Standards refer to a level of quality or attainment, which are hoped to be improved by government and technology leaders for AI technologies</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MITIGATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Mitigations refer to actions taken to reduce the severity, seriousness, or painfulness of something, such as the hallucination issue in AI models</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MEASUREMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Measurement refers to the process of obtaining the magnitude of a quantity, which is important for understanding and mitigating issues like hallucination in AI models</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="POST-TRAINING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Post-training refers to the process of further training a model after its initial training, often using additional data to improve its performance</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PRE-TRAINING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Pre-training refers to the initial phase of training a model on a large dataset before fine-tuning it for specific tasks</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DOMAIN/TASK SPECIALIZATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Domain/task specialization refers to the process of customizing a model to perform well in specific areas or tasks</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CONTINUAL IMPROVEMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Continual improvement refers to the ongoing effort to improve products, services, or processes, such as using agentic flows to generate higher quality data for models</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SEMI-AUTOMATED PIPELINES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Semi-automated pipelines refer to partially automated processes that use synthetic data for model customization and continual improvement</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MODEL CUSTOMIZATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Model customization refers to the process of tailoring a model to meet specific requirements or perform specific tasks</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DOMAIN SPECIFIC CONTENT">
      <data key="d0">DATA</data>
      <data key="d1">Domain specific content refers to information that is relevant to a particular field or area, used as seeds for generating synthetic data in model customization</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA</data>
    </node>
    <node id="CITATIONS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Citations refer to references to other works or documents, such as those listed in the references section of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="ACTIVE RESEARCH TOPIC">
      <data key="d0">CONCEPT</data>
      <data key="d1">Active research topic refers to an area of study that is currently being investigated, such as the measurement, understanding, and mitigations of hallucination in AI models</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="HARMFUL CONTENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Harmful content refers to information that can cause damage or distress, which can be generated by large language models without suitable safeguards</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SAFEGUARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Safeguards refer to measures taken to protect against possible dangers or risks, such as the misuse of large language models to generate disinformation or harmful content</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="TUNING DATA">
      <data key="d0">DATA</data>
      <data key="d1">Tuning data refers to the dataset used to fine-tune a model, which can affect its performance and accuracy</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA</data>
    </node>
    <node id="PERFORMANCE GAIN">
      <data key="d0">CONCEPT</data>
      <data key="d1">Performance gain refers to the improvement in a model's performance, such as the substantial improvement observed in the Orca-3 model post-trained with a 25M pair dataset</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="MULTIPLE BENCHMARKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Multiple benchmarks refer to various standards or points of reference used to measure the performance of models like Orca-3</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="UNSTRUCTURED DATA SOURCES">
      <data key="d0">DATA</data>
      <data key="d1">Unstructured data sources refer to information that does not have a pre-defined data model, which can be used by AgentInstruct to generate tailored datasets</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA</data>
    </node>
    <node id="RESPONSES">
      <data key="d0">DATA</data>
      <data key="d1">Responses refer to the outputs or answers generated by a model in reaction to prompts, used in the datasets generated by AgentInstruct</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA</data>
    </node>
    <node id="UNSTRUCTURED CONTENT">
      <data key="d0">DATA</data>
      <data key="d1">Unstructured content refers to information that does not have a pre-defined data model, which can be used to generate diverse and high-quality instruction data</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA</data>
    </node>
    <node id="INSTRUCTION DATA">
      <data key="d0">DATA</data>
      <data key="d1">Instruction data refers to the information used to teach or train a model, which can be generated from unstructured content using agentic flows</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA</data>
    </node>
    <node id="MODEL TRAINING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Model training refers to the process of teaching a model to perform tasks by feeding it data and adjusting its parameters</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DATA CREATION PROCESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Data creation process refers to the method of generating data for training models, which can involve human curation and intervention</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="HUMAN CURATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Human curation refers to the process of manually selecting and organizing data, which is often required in the data creation process for model training</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="INTERVENTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Intervention refers to the involvement of humans in the data creation process to ensure the quality and relevance of the data</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DIVERSE ANSWERS">
      <data key="d0">DATA</data>
      <data key="d1">Diverse answers refer to a variety of responses generated by a model, which can help explore potential solutions and improve model performance</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA</data>
    </node>
    <node id="POTENTIAL SOLUTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Potential solutions refer to possible answers or methods for solving a problem, which can be explored using diverse answers generated by models</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="BASE MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">Base model refers to the initial version of a model before it undergoes further training or customization</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="HIGHER QUALITY DATA">
      <data key="d0">DATA</data>
      <data key="d1">Higher quality data refers to information that is more accurate, relevant, and useful for training models, which can be generated using agentic flows</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA</data>
    </node>
    <node id="WEIJIAN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Weijian Xu is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SONALI YADAV">
      <data key="d0">PERSON</data>
      <data key="d1">Sonali Yadav is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="FAN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Fan Yang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JIANWEI YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jianwei Yang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZIYI YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ziyi Yang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YIFAN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yifan Yang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DONGHAN YU">
      <data key="d0">PERSON</data>
      <data key="d1">Donghan Yu is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LU YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Lu Yuan is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHENGRUIDONG ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chengruidong Zhang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CYRIL ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Cyril Zhang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JIANWEN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jianwen Zhang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LI LYNA ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Li Lyna Zhang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YI ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Zhang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUE ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yue Zhang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUNAN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yunan Zhang is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XIREN ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Xiren Zhou is one of the authors of the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ISAAC COWHEY">
      <data key="d0">PERSON</data>
      <data key="d1">Isaac Cowhey is one of the authors of the paper titled "Think you have solved question answering? try arc, the ai2 reasoning challenge" published on arXiv in 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OREN ETZIONI">
      <data key="d0">PERSON</data>
      <data key="d1">Oren Etzioni is one of the authors of the paper titled "Think you have solved question answering? try arc, the ai2 reasoning challenge" published on arXiv in 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TUSHAR KHOT">
      <data key="d0">PERSON</data>
      <data key="d1">Tushar Khot is one of the authors of the paper titled "Think you have solved question answering? try arc, the ai2 reasoning challenge" published on arXiv in 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ASHISH SABHARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Ashish Sabharwal is one of the authors of the paper titled "Think you have solved question answering? try arc, the ai2 reasoning challenge" published on arXiv in 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CARISSA SCHOENICK">
      <data key="d0">PERSON</data>
      <data key="d1">Carissa Schoenick is one of the authors of the paper titled "Think you have solved question answering? try arc, the ai2 reasoning challenge" published on arXiv in 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OYVIND TAFJORD">
      <data key="d0">PERSON</data>
      <data key="d1">Oyvind Tafjord is one of the authors of the paper titled "Think you have solved question answering? try arc, the ai2 reasoning challenge" published on arXiv in 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="THINK YOU HAVE SOLVED QUESTION ANSWERING? TRY ARC, THE AI2 REASONING CHALLENGE">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Think you have solved question answering? try arc, the ai2 reasoning challenge" was published on arXiv in 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CODEPARROT">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">CodeParrot is the organization that published the Github-code clean dataset in 2022</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GITHUB-CODE CLEAN DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The Github-code clean dataset is a dataset published by CodeParrot in 2022</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NING DING">
      <data key="d0">PERSON</data>
      <data key="d1">Ning Ding is one of the authors of the paper titled "Enhancing chat language models by scaling high-quality instructional conversations" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YULIN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yulin Chen is one of the authors of the paper titled "Enhancing chat language models by scaling high-quality instructional conversations" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BOKAI XU">
      <data key="d0">PERSON</data>
      <data key="d1">Bokai Xu is one of the authors of the paper titled "Enhancing chat language models by scaling high-quality instructional conversations" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHI ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhi Zheng is one of the authors of the paper titled "Enhancing chat language models by scaling high-quality instructional conversations" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHENGDING HU">
      <data key="d0">PERSON</data>
      <data key="d1">Shengding Hu is one of the authors of the paper titled "Enhancing chat language models by scaling high-quality instructional conversations" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ENHANCING CHAT LANGUAGE MODELS BY SCALING HIGH-QUALITY INSTRUCTIONAL CONVERSATIONS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Enhancing chat language models by scaling high-quality instructional conversations" was published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DROP: A READING COMPREHENSION BENCHMARK REQUIRING DISCRETE REASONING OVER PARAGRAPHS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" was published in the Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHAOYE FEI">
      <data key="d0">PERSON</data>
      <data key="d1">Zhaoye Fei is one of the authors of the paper titled "Query of cc: Unearthing large scale domain-specific knowledge from public corpora" published on arXiv in 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUNFAN SHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yunfan Shao is one of the authors of the paper titled "Query of cc: Unearthing large scale domain-specific knowledge from public corpora" published on arXiv in 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LINYANG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Linyang Li is one of the authors of the paper titled "Query of cc: Unearthing large scale domain-specific knowledge from public corpora" published on arXiv in 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHIYUAN ZENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Zeng is one of the authors of the paper titled "Query of cc: Unearthing large scale domain-specific knowledge from public corpora" published on arXiv in 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANG YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Hang Yan is one of the authors of the paper titled "Query of cc: Unearthing large scale domain-specific knowledge from public corpora" published on arXiv in 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XIPENG QIU">
      <data key="d0">PERSON</data>
      <data key="d1">Xipeng Qiu is one of the authors of the paper titled "Query of cc: Unearthing large scale domain-specific knowledge from public corpora" published on arXiv in 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DAHUA LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Dahua Lin is one of the authors of the paper titled "Query of cc: Unearthing large scale domain-specific knowledge from public corpora" published on arXiv in 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="QUERY OF CC: UNEARTHING LARGE SCALE DOMAIN-SPECIFIC KNOWLEDGE FROM PUBLIC CORPORA">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Query of cc: Unearthing large scale domain-specific knowledge from public corpora" was published on arXiv in 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ARNAV GUDIBANDE">
      <data key="d0">PERSON</data>
      <data key="d1">Arnav Gudibande is one of the authors of the paper titled "The false promise of imitating proprietary llms" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC WALLACE">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Wallace is one of the authors of the paper titled "The false promise of imitating proprietary llms" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHARLIE SNELL">
      <data key="d0">PERSON</data>
      <data key="d1">Charlie Snell is one of the authors of the paper titled "The false promise of imitating proprietary llms" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XINYANG GENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyang Geng is one</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAO LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Liu is one of the authors of the paper titled "The false promise of imitating proprietary llms" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="THE FALSE PROMISE OF IMITATING PROPRIETARY LLMS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "The false promise of imitating proprietary llms" was published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AKUL ARORA">
      <data key="d0">PERSON</data>
      <data key="d1">Akul Arora is one of the authors of the paper titled "Measuring mathematical problem solving with the math dataset" published on arXiv in 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Tang is one of the authors of the paper titled "Measuring mathematical problem solving with the math dataset" published on arXiv in 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MEASURING MATHEMATICAL PROBLEM SOLVING WITH THE MATH DATASET">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Measuring mathematical problem solving with the math dataset" was published on arXiv in 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAMISH IVISON">
      <data key="d0">PERSON</data>
      <data key="d1">Hamish Ivison is one of the authors of the paper titled "Camels in a changing climate: Enhancing lm adaptation with tulu 2" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="VALENTINA PYATKIN">
      <data key="d0">PERSON</data>
      <data key="d1">Valentina Pyatkin is one of the authors of the paper titled "Camels in a changing climate: Enhancing lm adaptation with tulu 2" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NATHAN LAMBERT">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Lambert is one of the authors of the paper titled "Camels in a changing climate: Enhancing lm adaptation with tulu 2" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MATTHEW PETERS">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew Peters is one of the authors of the paper titled "Camels in a changing climate: Enhancing lm adaptation with tulu 2" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JOEL JANG">
      <data key="d0">PERSON</data>
      <data key="d1">Joel Jang is one of the authors of the paper titled "Camels in a changing climate: Enhancing lm adaptation with tulu 2" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DAVID WADDEN">
      <data key="d0">PERSON</data>
      <data key="d1">David Wadden is one of the authors of the paper titled "Camels in a changing climate: Enhancing lm adaptation with tulu 2" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NOAH A. SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Noah A. Smith is one of the authors of the paper titled "Camels in a changing climate: Enhancing lm adaptation with tulu 2" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="IZ BELTAGY">
      <data key="d0">PERSON</data>
      <data key="d1">Iz Beltagy is one of the authors of the paper titled "Camels in a changing climate: Enhancing lm adaptation with tulu 2" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANNANEH HAJISHIRZI">
      <data key="d0">PERSON</data>
      <data key="d1">Hannaneh Hajishirzi is one of the authors of the paper titled "Camels in a changing climate: Enhancing lm adaptation with tulu 2" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CAMELS IN A CHANGING CLIMATE: ENHANCING LM ADAPTATION WITH TULU 2">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Camels in a changing climate: Enhancing lm adaptation with tulu 2" was published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALBERT Q. JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Albert Q. Jiang is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALEXANDRE SABLAYROLLES">
      <data key="d0">PERSON</data>
      <data key="d1">Alexandre Sablayrolles is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ARTHUR MENSCH">
      <data key="d0">PERSON</data>
      <data key="d1">Arthur Mensch is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHRIS BAMFORD">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Bamford is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DEVENDRA SINGH CHAPLOT">
      <data key="d0">PERSON</data>
      <data key="d1">Devendra Singh Chaplot is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DIEGO DE LAS CASAS">
      <data key="d0">PERSON</data>
      <data key="d1">Diego de las Casas is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="FLORIAN BRESSAND">
      <data key="d0">PERSON</data>
      <data key="d1">Florian Bressand is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GIANNA LENGYEL">
      <data key="d0">PERSON</data>
      <data key="d1">Gianna Lengyel is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GUILLAUME LAMPLE">
      <data key="d0">PERSON</data>
      <data key="d1">Guillaume Lample is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LUCILE SAULNIER">
      <data key="d0">PERSON</data>
      <data key="d1">Lucile Saulnier is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="L&#201;LIO RENARD LAVAUD">
      <data key="d0">PERSON</data>
      <data key="d1">L&#233;lio Renard Lavaud is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PIERRE STOCK">
      <data key="d0">PERSON</data>
      <data key="d1">Pierre Stock is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TEVEN LE SCAO">
      <data key="d0">PERSON</data>
      <data key="d1">Teven Le Scao is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="THOMAS WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Wang is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TIMOTH&#201;E LACROIX">
      <data key="d0">PERSON</data>
      <data key="d1">Timoth&#233;e Lacroix is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="WILLIAM EL SAYED">
      <data key="d0">PERSON</data>
      <data key="d1">William El Sayed is one of the authors of the paper titled "Mistral 7b" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MISTRAL 7B">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Mistral 7b" was published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HARRISON LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Harrison Lee is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SAMRAT PHATALE">
      <data key="d0">PERSON</data>
      <data key="d1">Samrat Phatale is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HASSAN MANSOOR">
      <data key="d0">PERSON</data>
      <data key="d1">Hassan Mansoor is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="THOMAS MESNARD">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Mesnard is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JOHAN FERRET">
      <data key="d0">PERSON</data>
      <data key="d1">Johan Ferret is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="KELLIE LU">
      <data key="d0">PERSON</data>
      <data key="d1">Kellie Lu is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="COLTON BISHOP">
      <data key="d0">PERSON</data>
      <data key="d1">Colton Bishop is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ETHAN HALL">
      <data key="d0">PERSON</data>
      <data key="d1">Ethan Hall is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="VICTOR CARBUNE">
      <data key="d0">PERSON</data>
      <data key="d1">Victor Carbune is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ABHINAV RASTOGI">
      <data key="d0">PERSON</data>
      <data key="d1">Abhinav Rastogi is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SUSHANT PRAKASH">
      <data key="d0">PERSON</data>
      <data key="d1">Sushant Prakash is one of the authors of the paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RLAIF: SCALING REINFORCEMENT LEARNING FROM HUMAN FEEDBACK WITH AI FEEDBACK">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Rlaif: Scaling reinforcement learning from human feedback with ai feedback" was published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GUOHAO LI">
      <data key="d0">PERSON</data>
      <data key="d1">Guohao Li is one of the authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HASAN ABED AL KADER HAMMOUD">
      <data key="d0">PERSON</data>
      <data key="d1">Hasan Abed Al Kader Hammoud is one of the authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANI ITANI">
      <data key="d0">PERSON</data>
      <data key="d1">Hani Itani is one of the authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society" published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BERNARD GHANEM">
      <data key="d0">PERSON</data>
      <data key="d1">Bernard Ghanem is one of the authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society," which was published on arXiv in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CAMEL: COMMUNICATIVE AGENTS FOR 'MIND' EXPLORATION OF LARGE LANGUAGE MODEL SOCIETY">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Camel: Communicative agents for 'mind' exploration of large language model society" was published on arXiv in 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XUECHEN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Xuechen Li is a notable researcher in the field of Artificial Intelligence and Machine Learning. He is one of the authors of the paper titled "Alpaca," which was published on arXiv. Additionally, in 2023, he co-authored another significant paper titled "Alpacaeval: An automatic evaluator of instruction-following models." These contributions highlight his active involvement in advancing AI and ML research, particularly in the development and evaluation of instruction-following models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TIANYI ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Tianyi Zhang is one of the authors of the paper titled "Alpaca" published on arXiv. Additionally, Tianyi Zhang is also one of the authors of the paper titled "Alpacaeval: An automatic evaluator of instruction-following models," which was published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YANN DUBOIS">
      <data key="d0">PERSON</data>
      <data key="d1">Yann Dubois is one of the authors of the paper titled "Alpaca" published on arXiv. Additionally, he is also one of the authors of the paper titled "Alpacaeval: An automatic evaluator of instruction-following models," which was published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ROHAN TAORI">
      <data key="d0">PERSON</data>
      <data key="d1">Rohan Taori is one of the authors of the paper titled "Alpaca" published on arXiv. Additionally, he is also one of the authors of the paper titled "Alpacaeval: An automatic evaluator of instruction-following models," which was published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ISHAAN GULRAJANI">
      <data key="d0">PERSON</data>
      <data key="d1">Ishaan Gulrajani is one of the authors of the paper titled "Alpaca" published on arXiv. Additionally, he is also one of the authors of the paper titled "Alpacaeval: An automatic evaluator of instruction-following models," which was published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CARLOS GUESTRIN">
      <data key="d0">PERSON</data>
      <data key="d1">Carlos Guestrin is one of the authors of the paper titled "Alpaca" published on arXiv. Additionally, he is also one of the authors of the paper titled "Alpacaeval: An automatic evaluator of instruction-following models," which was published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TATSUNORI B. HASHIMOTO">
      <data key="d0">PERSON</data>
      <data key="d1">Tatsunori B. Hashimoto is a notable author in the field of Artificial Intelligence and Machine Learning. He has contributed to significant research, including the paper titled "Alpaca" published on arXiv and the paper "Alpacaeval: An automatic evaluator of instruction-following models" published in 2023. His work focuses on advancing the understanding and evaluation of instruction-following models, highlighting his expertise and influence in the AI and ML research community.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALPACA">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The paper titled "Alpaca" was published on arXiv</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RII KHIZBULLIN">
      <data key="d0">PERSON</data>
      <data key="d1">Rii Khizbullin is one of the authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CAMEL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Camel is a system described as Communicative agents for 'mind' exploration of large language model society, published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="YIXIN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Yixin Liu is one of the authors of the paper titled "Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEXANDER R. FABBRI">
      <data key="d0">PERSON</data>
      <data key="d1">Alexander R. Fabbri is one of the authors of the paper titled "Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIAWEN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jiawen Chen is one of the authors of the paper titled "Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YILUN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yilun Zhao is one of the authors of the paper titled "Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SIMENG HAN">
      <data key="d0">PERSON</data>
      <data key="d1">Simeng Han is one of the authors of the paper titled "Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHAFIQ JOTY">
      <data key="d0">PERSON</data>
      <data key="d1">Shafiq Joty is one of the authors of the paper titled "Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DRAGOMIR RADEV">
      <data key="d0">PERSON</data>
      <data key="d1">Dragomir Radev is one of the authors of the paper titled "Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHIEN-SHENG WU">
      <data key="d0">PERSON</data>
      <data key="d1">Chien-Sheng Wu is one of the authors of the paper titled "Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ARMAN COHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Arman Cohan is one of the authors of the paper titled "Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LM-SYS">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">LM-Sys is the organization that published MT-Bench in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="DANIEL VAN STRIEN">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel van Strien is one of the authors of the paper titled "Cosmopedia: how to create large-scale synthetic data for pre-training" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LOUBNA BEN ALLAL">
      <data key="d0">PERSON</data>
      <data key="d1">Loubna Ben Allal is one of the authors of the paper titled "Cosmopedia: how to create large-scale synthetic data for pre-training" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANTON LOZHKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Anton Lozhkov is one of the authors of the paper titled "Cosmopedia: how to create large-scale synthetic data for pre-training" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="COSMOPEDIA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Cosmopedia is a system for creating large-scale synthetic data for pre-training, published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="CLARISSE SIMOES">
      <data key="d0">PERSON</data>
      <data key="d1">Clarisse Simoes is one of the authors of the paper titled "Orca 2: Teaching small language models how to reason" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAHAJ AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Sahaj Agarwal is one of the authors of the paper titled "Orca 2: Teaching small language models how to reason" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XUXI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xuxi Chen is one of the authors of the paper titled "Orca 2: Teaching small language models how to reason" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANASTASIA RAZDAIBIEDINA">
      <data key="d0">PERSON</data>
      <data key="d1">Anastasia Razdaibiedina is one of the authors of the paper titled "Orca 2: Teaching small language models how to reason" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ERIK JONES">
      <data key="d0">PERSON</data>
      <data key="d1">Erik Jones is one of the authors of the paper titled "Orca 2: Teaching small language models how to reason" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KRITI AGGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Kriti Aggarwal is one of the authors of the paper titled "Orca 2: Teaching small language models how to reason" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAMID PALANGI">
      <data key="d0">PERSON</data>
      <data key="d1">Hamid Palangi is one of the authors of the paper titled "Orca 2: Teaching small language models how to reason" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ORCA 2">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Orca 2 is a system for teaching small language models how to reason, published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="SUBHABRATA MUKHERJEE">
      <data key="d0">PERSON</data>
      <data key="d1">Subhabrata Mukherjee is one of the authors of the paper titled "Xtremedistil: Multi-stage distillation for massive multilingual models" published in 2020</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XTREMEDISTIL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Xtremedistil is a multi-stage distillation process for massive multilingual models, published in 2020</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="GANESH JAWAHAR">
      <data key="d0">PERSON</data>
      <data key="d1">Ganesh Jawahar is one of the authors of the paper titled "Orca: Progressive learning from complex explanation traces of GPT-4" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ORCA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Orca is a system for progressive learning from complex explanation traces of GPT-4, published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="SAMUEL J. PAECH">
      <data key="d0">PERSON</data>
      <data key="d1">Samuel J. Paech is the author of the paper titled "EQ-Bench: An emotional intelligence benchmark for large language models" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="EQ-BENCH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">EQ-Bench is an emotional intelligence benchmark for large language models, published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="BAOLIN PENG">
      <data key="d0">PERSON</data>
      <data key="d1">Baolin Peng is one of the authors of the paper titled "Instruction tuning with GPT-4" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHUNYUAN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Chunyuan Li is one of the authors of the paper titled "Instruction tuning with GPT-4" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PENGCHENG HE">
      <data key="d0">PERSON</data>
      <data key="d1">Pengcheng He is one of the authors of the paper titled "Instruction tuning with GPT-4" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MICHEL GALLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Michel Galley is one of the authors of the paper titled "Instruction tuning with GPT-4" published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="INSTRUCTION TUNING WITH GPT-4">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Instruction tuning with GPT-4 is a method described in a paper published in 2023</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="YIWEI QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Yiwei Qin is one of the authors of the paper titled "Infobench: Evaluating instruction following ability in large language models" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KAIQIANG SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Kaiqiang Song is one of the authors of the paper titled "Infobench: Evaluating instruction following ability in large language models" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YEBOWEN HU">
      <data key="d0">PERSON</data>
      <data key="d1">Yebowen Hu is one of the authors of the paper titled "Infobench: Evaluating instruction following ability in large language models" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WENLIN YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Wenlin Yao is one of the authors of the paper titled "Infobench: Evaluating instruction following ability in large language models" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SANGWOO CHO">
      <data key="d0">PERSON</data>
      <data key="d1">Sangwoo Cho is one of the authors of the paper titled "Infobench: Evaluating instruction following ability in large language models" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIAOYANG WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaoyang Wang is one of the authors of the paper titled "Infobench: Evaluating instruction following ability in large language models" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XUANSHENG WU">
      <data key="d0">PERSON</data>
      <data key="d1">Xuansheng Wu is one of the authors of the paper titled "Infobench: Evaluating instruction following ability in large language models" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FEI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Fei Liu is one of the authors of the paper titled "Infobench: Evaluating instruction following ability in large language models" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DONG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Dong Yu is one of the authors of the paper titled "Infobench: Evaluating instruction following ability in large language models" published in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIAHAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiahao Zhang is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," which was published in the Proceedings of the 46th International Conference on Software Engineering, NIER Track (ICSE-NIER &#8217;24) in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LINDSAY RONEY">
      <data key="d0">PERSON</data>
      <data key="d1">Lindsay Roney is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," which was published in the Proceedings of the 46th International Conference on Software Engineering, NIER Track (ICSE-NIER &#8217;24) in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JOANNA C. S.">
      <data key="d0">PERSON</data>
      <data key="d1">Joanna C. S. is one of the authors of a paper mentioned in the text</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ILIA SHUMAILOV">
      <data key="d0">PERSON</data>
      <data key="d1">Ilia Shumailov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZAKHAR SHUMAYLOV">
      <data key="d0">PERSON</data>
      <data key="d1">Zakhar Shumaylov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIREN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiren Zhao is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NICOLAS PAPERNOT">
      <data key="d0">PERSON</data>
      <data key="d1">Nicolas Papernot is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ROSS ANDERSON">
      <data key="d0">PERSON</data>
      <data key="d1">Ross Anderson is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MOHAMMED LATIF SIDDIQ">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammed Latif Siddiq is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks" published in the Proceedings of the 46th International Conference on Software Engineering, NIER Track (ICSE-NIER &#8217;24) in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JOANNA C. S. SANTOS">
      <data key="d0">PERSON</data>
      <data key="d1">Joanna C. S. Santos is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks" published in the Proceedings of the 46th International Conference on Software Engineering, NIER Track (ICSE-NIER &#8217;24) in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NATHANAEL SCH&#196;RLI">
      <data key="d0">PERSON</data>
      <data key="d1">Nathanael Sch&#228;rli is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEN WAI YIM">
      <data key="d0">PERSON</data>
      <data key="d1">Wen wai Yim is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YUJUAN FU">
      <data key="d0">PERSON</data>
      <data key="d1">Yujuan Fu is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ASMA BEN ABACHA">
      <data key="d0">PERSON</data>
      <data key="d1">Asma Ben Abacha is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NEAL SNIDER">
      <data key="d0">PERSON</data>
      <data key="d1">Neal Snider is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="THOMAS LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Lin is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MELIHA YETISGEN">
      <data key="d0">PERSON</data>
      <data key="d1">Meliha Yetisgen is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AHMED HASSAN AWADALLAH">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmed Hassan Awadallah is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RYEN W WHITE">
      <data key="d0">PERSON</data>
      <data key="d1">Ryen W White is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DOUG BURGER">
      <data key="d0">PERSON</data>
      <data key="d1">Doug Burger is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CONGYING XIA">
      <data key="d0">PERSON</data>
      <data key="d1">Congying Xia is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHEN XING">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Xing is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIANGSHU DU">
      <data key="d0">PERSON</data>
      <data key="d1">Jiangshu Du is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XINYI YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyi Yang is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIHAO FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Yihao Feng is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RAN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Ran Xu is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WENPENG YIN">
      <data key="d0">PERSON</data>
      <data key="d1">Wenpeng Yin is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CAIMING XIONG">
      <data key="d0">PERSON</data>
      <data key="d1">Caiming Xiong is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="GUANGZHI XIONG">
      <data key="d0">PERSON</data>
      <data key="d1">Guangzhi Xiong is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QIAO JIN">
      <data key="d0">PERSON</data>
      <data key="d1">Qiao Jin is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHIYONG LU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyong Lu is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AIDONG ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Aidong Zhang is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QINGFENG SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Qingfeng Sun is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="KAI ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Kai Zheng is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIUBO GENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiubo Geng is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="PU ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Pu Zhao is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAZHAN FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiazhan Feng is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHONGYANG TAO">
      <data key="d0">PERSON</data>
      <data key="d1">Chongyang Tao is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DAXIN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Daxin Jiang is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LONGHUI YU">
      <data key="d0">PERSON</data>
      <data key="d1">Longhui Yu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEISEN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Weisen Jiang is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="HAN SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Han Shi is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JINCHENG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Jincheng Yu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHENGYING LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhengying Liu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Zhang is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JAMES T KWOK">
      <data key="d0">PERSON</data>
      <data key="d1">James T Kwok is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHENGUO LI">
      <data key="d0">PERSON</data>
      <data key="d1">Zhenguo Li is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ADRIAN WELLER">
      <data key="d0">PERSON</data>
      <data key="d1">Adrian Weller is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEIYANG LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Weiyang Liu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIFAN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yifan Zhang is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIFAN LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Yifan Luo is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ANDREW CHI-CHIH YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Chi-Chih Yao is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts" published in 2024</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WANJUN ZHONG">
      <data key="d0">PERSON</data>
      <data key="d1">Wanjun Zhong is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RUIXIANG CUI">
      <data key="d0">PERSON</data>
      <data key="d1">Ruixiang Cui is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIDUO GUO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiduo Guo is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YAOBO LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yaobo Liang is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SHUAI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Shuai Lu is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YANLIN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yanlin Wang is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NAN DUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Nan Duan is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JEFFREY ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Jeffrey Zhou is one of the authors of the paper titled "Instruction-following evaluation for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="TIANJIAN LU">
      <data key="d0">PERSON</data>
      <data key="d1">Tianjian Lu is one of the authors of the paper titled "Instruction-following evaluation for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SIDDHARTHA BRAHMA">
      <data key="d0">PERSON</data>
      <data key="d1">Siddhartha Brahma is one of the authors of the paper titled "Instruction-following evaluation for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SUJOY BASU">
      <data key="d0">PERSON</data>
      <data key="d1">Sujoy Basu is one of the authors of the paper titled "Instruction-following evaluation for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YI LUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Luan is one of the authors of the paper titled "Instruction-following evaluation for large language models" published in 2023</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DEBATE PASSAGE GENERATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Debate Passage Generator is an agent that specializes in crafting passages that mimic the structure and content of debate transcripts</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CONVERSATION PASSAGE GENERATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Conversation Passage Generator is an agent that generates passages depicting dialogues</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MEETING TRANSCRIPT GENERATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Meeting Transcript Generator is an agent designed to produce meeting transcripts</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="POEM GENERATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Poem Generator is an agent that generates poems</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SATIRICAL PASSAGE GENERATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Satirical Passage Generator is an agent that creates texts infused with satirical wit</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="INSTRUCTIONAL PASSAGE GENERATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Instructional Passage Generator is an agent that generates passages resembling instructional manuals</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LONG TEXT GENERATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Long Text Generator is an agent that extends the original text by incorporating additional information, thereby increasing its length</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="IDENTITY AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Identity Agent is a straightforward agent that replicates the input text verbatim</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LITERAL COMPREHENSION QUESTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Literal Comprehension Question is a type of question that asks for specific details or facts clearly stated in the text</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NUMERICAL DISCRETE REASONING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Numerical Discrete Reasoning is a type of question that necessitates the reader to employ numerical reasoning across multiple facts presented in the text. These questions challenge the reader to integrate and analyze various numerical data points to arrive at a coherent conclusion.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CRITICAL COMPREHENSION QUESTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">"Critical Comprehension Question is a type of question that involves constructing two statements about the purpose or point of view that the reader must assess as true or false, with one being true and the other false."</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="EVALUATIVE COMPREHENSION QUESTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Evaluative Comprehension Question is a type of question that requires the reader to assess and evaluate the content of the text. These questions are open-ended and prompt an in-depth analysis of the text&#8217;s theme or the effectiveness of an argument.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="VOCABULARY AND LANGUAGE USE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Vocabulary and Language Use questions are fill-in-the-blank questions that test understanding of a particular word or phrase used in the text</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="RELATIONSHIP COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Relationship Comprehension Questions are matching questions where respondents pair items based on a specific criterion</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SEQUENCING EVENTS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Sequencing Events questions involve arranging a series of events from the text in the correct chronological order</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="STRENGTHEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Strengthen questions require identifying information that would make the argument&#8217;s conclusion more likely to be true</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="WEAKEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Weaken questions involve finding evidence or an argument that would make the conclusion less likely to be true</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="ASSUMPTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Assumption questions require determining what must be true for the argument to hold</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="FLAW">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Flaw questions involve pointing out a mistake in the argument&#8217;s reasoning</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="INFERENCE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Inference questions require choosing an option that logically follows from the information provided</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PRINCIPLE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Principle questions involve recognizing the general rule or principle that underlies the argument</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="METHOD OF REASONING">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Method of Reasoning questions involve describing how the argument is constructed logically</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="RESOLVE THE PARADOX">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Resolve the Paradox questions involve offering an explanation that reconciles seemingly contradictory information</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT SIMPLIFICATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Text Simplification involves making text easier to read and understand by using simpler words and sentence structures, often for children or language learners</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT EXPANSION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Text Expansion involves adding more information or detail to make text more comprehensive or to meet a certain word count</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT TRANSLATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Text Translation involves converting text from one language to another while attempting to preserve the original meaning as closely as possible</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT FORMATTING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Text Formatting involves altering the appearance of text to improve readability or for stylistic purposes</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SENTIMENT MODIFICATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Sentiment Modification involves changing the tone of the text to alter its emotional impact, such as making a sentence sound more positive or negative</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT ANNOTATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Text Annotation involves adding notes, comments, or explanations to a text, often for the purpose of analysis or to provide additional context</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="KEYWORD REPLACEMENT">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Keyword Replacement involves substituting specific words or phrases with synonyms or related terms</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT REMOVING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Text Removing involves redacting or removing content from text</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT CAPITALIZATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Text Capitalization involves adjusting the case of letters in text, such as converting to uppercase, lowercase, title case, or sentence case</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT STYLING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Text Styling involves applying styles like bold, italics, underline, etc., to emphasize certain parts of the text or for aesthetic purposes</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="CONTENT REWRITING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Content Rewriting involves extensively modifying a text to produce a new version, which could involve changing the perspective, style, or target audience</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="DATA NORMALIZATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Data Normalization involves standardizing text to ensure consistency, such as converting dates and times to a standard format or unifying the spelling of words</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PLAGIARISM REWORDING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Plagiarism Rewording involves altering text to avoid plagiarism, ensuring that the content is original</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT OBFUSCATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Text Obfuscation involves intentionally making text vague or harder to understand, sometimes for security purposes like masking personal data</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXTUAL ENTAILMENT">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Textual Entailment involves modifying a sentence or phrase to either entail or contradict another sentence, often used in natural language processing tasks</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="REWRITING WITH VOCABULARY LIMITATIONS">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Rewriting with Vocabulary Limitations involves rewriting the entire text or a piece of it while using a limited vocabulary, such as all words starting with a specific letter</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT MODIFICATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">Text Modification Flow is a process that involves various techniques for modifying text to generate seed instructions</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="INSTRUCTION TAXONOMY">
      <data key="d0">PROCESS</data>
      <data key="d1">Instruction Taxonomy is a classification system used for generating seed instructions in the Text Modification Flow</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SEED INSTRUCTION GENERATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Seed Instruction Generation is a process that involves creating initial instructions using various text modification techniques</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="EVALUATION DETAILS">
      <data key="d0">PROCESS</data>
      <data key="d1">Evaluation Details specify the types of tasks and benchmarks used to extract answers and generate metrics</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="EXTRACTION SYSTEM MESSAGE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The Extraction System Message is a system message used by GPT-4 to extract the option selected by the model from the model&#8217;s response in the evaluation of Multiple Choice Questions</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="GPT-4 EXTRACTION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4 Extraction is the process of using GPT-4 to extract the option selected by the model from the model&#8217;s response in the evaluation of Multiple Choice Questions</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="STUDENT RESPONSE">
      <data key="d0">DATA</data>
      <data key="d1">Student Response is the answer or explanation provided by a student in response to a question. It is parsed by GPT-4 to extract the selected option in the evaluation of Multiple Choice Questions. This process helps in understanding the student's choice and reasoning, thereby facilitating a more accurate assessment of their knowledge and comprehension.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="ANSWER OPTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Answer Options are the possible choices provided to the student, from which the selected option is extracted in the evaluation of Multiple Choice Questions</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PARSED STUDENT ANSWER">
      <data key="d0">CONCEPT</data>
      <data key="d1">Parsed Student Answer is the final answer extracted from the student's response, represented by the alphabet(s) corresponding to the option(s) the student chose</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EXACT MATCH/SPAN EXTRACTION PROBLEMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Exact Match/Span Extraction Problems are tasks where the model generates an answer and matches it with a ground-truth answer to determine correctness</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Maths GPT-4 Extraction System Message is a specific system message used to evaluate a student's answer to a math word problem by comparing it with the problem setter's solution</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">General Extraction System Message is a system message used to parse student responses and match them with the correct answer provided in the context</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">EQBench GPT-4 Extraction System Message is a system message used to extract emotion scores from a model's response in the EQBench dataset</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="OPTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Options are the multiple-choice answers provided to the student for selection</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="FINAL ANSWER">
      <data key="d0">CONCEPT</data>
      <data key="d1">The final answer is the student's selected option(s) after considering all possibilities</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="MODEL'S ANSWER">
      <data key="d0">CONCEPT</data>
      <data key="d1">The model's answer is the response generated by the AI model being evaluated</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="GROUND-TRUTH ANSWER">
      <data key="d0">CONCEPT</data>
      <data key="d1">The ground-truth answer is the correct answer provided by the problem setter for comparison with the model's answer</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="FINAL VERDICT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The final verdict is the determination of whether the student's or model's answer is correct or incorrect</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EMOTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Emotion is a feeling or reaction that is scored in the EQBench dataset</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="SCORE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The score is the numeric value assigned to an emotion in the EQBench dataset</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="CRITIQUE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The critique is the step-by-step analysis provided to explain the revised scores in the EQBench dataset</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ALEX">
      <data key="d0">PERSON</data>
      <data key="d1">Alex is a person who is already in a relationship and has been confessed to by Elliot, putting Alex in an awkward position</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="RESIGNED">
      <data key="d0">EMOTION</data>
      <data key="d1">Resigned is an emotion felt by Elliot, scored 7, indicating a strong sense of acceptance of the situation</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ANGRY">
      <data key="d0">EMOTION</data>
      <data key="d1">Angry is an emotion felt by Elliot, scored 3, indicating a mild sense of frustration or self-directed anger</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HOPEFUL">
      <data key="d0">EMOTION</data>
      <data key="d1">Hopeful is an emotion felt by Elliot, scored 5, indicating a moderate sense of optimism that Alex might reciprocate his feelings</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMBARRASSED">
      <data key="d0">EMOTION</data>
      <data key="d1">Embarrassed is an emotion felt by Elliot, scored 8, indicating a strong sense of discomfort for putting Alex in an awkward position</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="OPEN-ENDED GENERATION">
      <data key="d0">TASK</data>
      <data key="d1">Open-Ended Generation is a task where a model is prompted to generate an answer to an open-ended question without a ground-truth to match the answer</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HALLUCINATION JUDGE">
      <data key="d0">TASK</data>
      <data key="d1">Hallucination Judge is a task where a judge decides if there is any hallucination in a generated summary by comparing it to relevant facts from the article</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="QUALITY JUDGE">
      <data key="d0">TASK</data>
      <data key="d1">Quality Judge is a task where a judge evaluates the quality of a response based on instruction adherence, content grounding, and overall quality, scoring from 1 to 10</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="GPT-4-TURBO">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4-turbo is a version of GPT-4 used in the AlpacaEval benchmark to judge model outputs</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="VERSION 0613">
      <data key="d0">VERSION</data>
      <data key="d1">Version 0613 is a specific version of GPT-4 used in the FOFO and AlpacaEval benchmarks</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="VERSION 1106-PREVIEW">
      <data key="d0">VERSION</data>
      <data key="d1">Version 1106-preview is a specific version of GPT-4 used in the InfoBench benchmark</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ELLIOT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMOTIONS">
      <data key="d0">DATA</data>
      <data key="d1">Emotions are the different feelings experienced by Elliot, including Resigned, Angry, Hopeful, and Embarrassed</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="SUMMARY INSTRUCTION">
      <data key="d0">TASK</data>
      <data key="d1">Summary Instruction is a task where a judge evaluates the correctness of a generated summary by comparing it to relevant facts from the article</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="GENERATED SUMMARY">
      <data key="d0">TASK</data>
      <data key="d1">Generated Summary is a task where a summary is generated and then evaluated for correctness and hallucination</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="PROMPT TEMPLATE">
      <data key="d0">TASK</data>
      <data key="d1">Prompt Template is a predefined format used for evaluating tasks such as hallucination detection and summary quality</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="TEXT SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">Text Summarization is a task where a summary of a given text is generated and evaluated for quality and hallucination</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="SUMMARIZATION QUALITY">
      <data key="d0">TASK</data>
      <data key="d1">Summarization Quality is a task where the quality of a generated summary is evaluated based on criteria like instruction adherence, content grounding, and overall quality</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HALLUCINATION EVALUATION">
      <data key="d0">TASK</data>
      <data key="d1">Hallucination Evaluation is a task where a generated summary is checked for hallucinations by comparing it to relevant facts from the article</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="QUALITY EVALUATION">
      <data key="d0">TASK</data>
      <data key="d1">Quality Evaluation is a task where the quality of a generated response is evaluated based on criteria like instruction adherence, content grounding, and overall quality</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="REVISED SCORES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <edge source="DARREN EDGE" target="HA TRINH">
      <data key="d4">8.0</data>
      <data key="d5">Darren Edge and Ha Trinh co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="DARREN EDGE" target="NEWMAN CHENG">
      <data key="d4">8.0</data>
      <data key="d5">Darren Edge and Newman Cheng co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="DARREN EDGE" target="JOSHUA BRADLEY">
      <data key="d4">8.0</data>
      <data key="d5">Darren Edge and Joshua Bradley co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="DARREN EDGE" target="ALEX CHAO">
      <data key="d4">8.0</data>
      <data key="d5">Darren Edge and Alex Chao co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="DARREN EDGE" target="APURVA MODY">
      <data key="d4">8.0</data>
      <data key="d5">Darren Edge and Apurva Mody co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="DARREN EDGE" target="STEVEN TRUITT">
      <data key="d4">8.0</data>
      <data key="d5">Darren Edge and Steven Truitt co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="DARREN EDGE" target="JONATHAN LARSON">
      <data key="d4">8.0</data>
      <data key="d5">Darren Edge and Jonathan Larson co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="DARREN EDGE" target="MICROSOFT RESEARCH">
      <data key="d4">9.0</data>
      <data key="d5">Darren Edge is affiliated with Microsoft Research</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="HA TRINH" target="NEWMAN CHENG">
      <data key="d4">8.0</data>
      <data key="d5">Ha Trinh and Newman Cheng co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="HA TRINH" target="JOSHUA BRADLEY">
      <data key="d4">8.0</data>
      <data key="d5">Ha Trinh and Joshua Bradley co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="HA TRINH" target="ALEX CHAO">
      <data key="d4">8.0</data>
      <data key="d5">Ha Trinh and Alex Chao co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="HA TRINH" target="APURVA MODY">
      <data key="d4">8.0</data>
      <data key="d5">Ha Trinh and Apurva Mody co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="HA TRINH" target="STEVEN TRUITT">
      <data key="d4">8.0</data>
      <data key="d5">Ha Trinh and Steven Truitt co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="HA TRINH" target="JONATHAN LARSON">
      <data key="d4">8.0</data>
      <data key="d5">Ha Trinh and Jonathan Larson co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="HA TRINH" target="MICROSOFT RESEARCH">
      <data key="d4">9.0</data>
      <data key="d5">Ha Trinh is affiliated with Microsoft Research</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="NEWMAN CHENG" target="JOSHUA BRADLEY">
      <data key="d4">8.0</data>
      <data key="d5">Newman Cheng and Joshua Bradley co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="NEWMAN CHENG" target="ALEX CHAO">
      <data key="d4">8.0</data>
      <data key="d5">Newman Cheng and Alex Chao co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="NEWMAN CHENG" target="APURVA MODY">
      <data key="d4">8.0</data>
      <data key="d5">Newman Cheng and Apurva Mody co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="NEWMAN CHENG" target="STEVEN TRUITT">
      <data key="d4">8.0</data>
      <data key="d5">Newman Cheng and Steven Truitt co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="NEWMAN CHENG" target="JONATHAN LARSON">
      <data key="d4">8.0</data>
      <data key="d5">Newman Cheng and Jonathan Larson co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="NEWMAN CHENG" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d4">9.0</data>
      <data key="d5">Newman Cheng is affiliated with Microsoft Strategic Missions and Technologies</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="ALEX CHAO">
      <data key="d4">8.0</data>
      <data key="d5">Joshua Bradley and Alex Chao co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="APURVA MODY">
      <data key="d4">8.0</data>
      <data key="d5">Joshua Bradley and Apurva Mody co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="STEVEN TRUITT">
      <data key="d4">8.0</data>
      <data key="d5">Joshua Bradley and Steven Truitt co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="JONATHAN LARSON">
      <data key="d4">8.0</data>
      <data key="d5">Joshua Bradley and Jonathan Larson co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="JOSHUA BRADLEY" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d4">9.0</data>
      <data key="d5">Joshua Bradley is affiliated with Microsoft Strategic Missions and Technologies</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="ALEX CHAO" target="APURVA MODY">
      <data key="d4">8.0</data>
      <data key="d5">Alex Chao and Apurva Mody co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="ALEX CHAO" target="STEVEN TRUITT">
      <data key="d4">8.0</data>
      <data key="d5">Alex Chao and Steven Truitt co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="ALEX CHAO" target="JONATHAN LARSON">
      <data key="d4">8.0</data>
      <data key="d5">Alex Chao and Jonathan Larson co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="ALEX CHAO" target="MICROSOFT OFFICE OF THE CTO">
      <data key="d4">9.0</data>
      <data key="d5">Alex Chao is affiliated with Microsoft Office of the CTO</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="APURVA MODY" target="STEVEN TRUITT">
      <data key="d4">8.0</data>
      <data key="d5">Apurva Mody and Steven Truitt co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="APURVA MODY" target="JONATHAN LARSON">
      <data key="d4">8.0</data>
      <data key="d5">Apurva Mody and Jonathan Larson co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="APURVA MODY" target="MICROSOFT OFFICE OF THE CTO">
      <data key="d4">9.0</data>
      <data key="d5">Apurva Mody is affiliated with Microsoft Office of the CTO</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="STEVEN TRUITT" target="JONATHAN LARSON">
      <data key="d4">8.0</data>
      <data key="d5">Steven Truitt and Jonathan Larson co-authored the paper titled "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="STEVEN TRUITT" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d4">9.0</data>
      <data key="d5">Steven Truitt is affiliated with Microsoft Strategic Missions and Technologies</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="JONATHAN LARSON" target="MICROSOFT RESEARCH">
      <data key="d4">9.0</data>
      <data key="d5">Jonathan Larson is affiliated with Microsoft Research</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="MICROSOFT">
      <data key="d4">9.0</data>
      <data key="d5">Microsoft Research is a division of Microsoft</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="ARINDAM MITRA">
      <data key="d4">8.0</data>
      <data key="d5">Arindam Mitra is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="LUCIANO DEL CORRO">
      <data key="d4">8.0</data>
      <data key="d5">Luciano Del Corro is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="GUOQING ZHENG">
      <data key="d4">8.0</data>
      <data key="d5">Guoqing Zheng is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="SHWETI MAHAJAN">
      <data key="d4">8.0</data>
      <data key="d5">Shweti Mahajan is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="DANY ROUHANA">
      <data key="d4">8.0</data>
      <data key="d5">Dany Rouhana is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="ANDRES CODAS">
      <data key="d4">8.0</data>
      <data key="d5">Andres Codas is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="YADONG LU">
      <data key="d4">8.0</data>
      <data key="d5">Yadong Lu is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="WEI-GE CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Wei-ge Chen is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="OLGA VROUSGOS">
      <data key="d4">8.0</data>
      <data key="d5">Olga Vrousgos is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="CORBY ROSSET">
      <data key="d4">8.0</data>
      <data key="d5">Corby Rosset is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="FILLIPE SILVA">
      <data key="d4">8.0</data>
      <data key="d5">Fillipe Silva is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="HAMED KHANPOUR">
      <data key="d4">8.0</data>
      <data key="d5">Hamed Khanpour is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="YASH LARA">
      <data key="d4">8.0</data>
      <data key="d5">Yash Lara is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="AHMED AWADALLAH">
      <data key="d4">1.0</data>
      <data key="d5">Ahmed Awadallah is affiliated with Microsoft Research</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES" target="MICROSOFT">
      <data key="d4">9.0</data>
      <data key="d5">Microsoft Strategic Missions and Technologies is a division of Microsoft</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT OFFICE OF THE CTO" target="MICROSOFT">
      <data key="d4">9.0</data>
      <data key="d5">Microsoft Office of the CTO is a division of Microsoft</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is proposed as an improvement over traditional RAG for answering global questions over large text corpora</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG combines the strengths of RAG and QFS to answer global questions over large text corpora</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses large language models (LLMs) to build a graph-based text index</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="LEIDEN">
      <data key="d4">7.0</data>
      <data key="d5">Leiden is used in the Graph RAG approach for community detection</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="MAP-REDUCE">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses a map-reduce approach for query-focused summarization</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="KNOWLEDGE GRAPH">
      <data key="d4">9.0</data>
      <data key="d5">Graph RAG approach is based on the global summarization of an LLM-derived knowledge graph</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG approach uses community detection algorithms to partition graphs into modular communities</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Activity-centered sense-making questions are used to evaluate the Graph RAG approach</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="TEXT SUMMARIZATION (TS)">
      <data key="d4">6.0</data>
      <data key="d5">Both Graph RAG and Text Summarization (TS) are methods used to answer user queries</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="SEMANTIC SEARCH (SS)">
      <data key="d4">6.0</data>
      <data key="d5">Both Graph RAG and Semantic Search (SS) are methods used to answer user queries</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="CONDITION">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is one of the conditions compared in the analysis</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="PUBLIC FIGURES">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG generates comprehensive lists of public figures</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="GRAPH RAG" target="NA&#207;VE RAG">
      <data key="d4">30.0</data>
      <data key="d5">Graph RAG offers scalability advantages and efficiency over Na&#239;ve RAG. Additionally, Graph RAG outperformed Na&#239;ve RAG in comprehensiveness and diversity metrics.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="MODULAR RAG">
      <data key="d4">12.0</data>
      <data key="d5">Graph RAG incorporates multiple concepts related to Modular RAG systems</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="SELF-MEMORY (SELFMEM)">
      <data key="d4">12.0</data>
      <data key="d5">Graph RAG's community summaries are a kind of self-memory (Selfmem) for generation-augmented retrieval</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="GENERATION-AUGMENTED RETRIEVAL (GAR)">
      <data key="d4">12.0</data>
      <data key="d5">Graph RAG's community summaries are related to generation-augmented retrieval (GAR)</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)">
      <data key="d4">12.0</data>
      <data key="d5">Graph RAG's parallel generation of community answers is a kind of iterative retrieval-generation (Iter-RetGen) strategy</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="FEDERATED RETRIEVAL-GENERATION (FEB4RAG)">
      <data key="d4">12.0</data>
      <data key="d5">Graph RAG's parallel generation of community answers is a kind of federated retrieval-generation (FeB4RAG) strategy</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="CAIRE-COVID">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG combines concepts similar to those used in CAiRE-COVID for multi-document summarization</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="ITRG">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG combines concepts similar to those used in ITRG for multi-hop question answering</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="IR-COT">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG combines concepts similar to those used in IR-CoT for multi-hop question answering</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="DSP">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG combines concepts similar to those used in DSP for multi-hop question answering</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="RAPTOR">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG's hierarchical index and summarization are similar to the approach used in RAPTOR</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="TREE OF CLARIFICATIONS">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG's hierarchical index and summarization are similar to the approach used in the tree of clarifications</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="KAPING">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG is related to KAPING where the index is a knowledge graph</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="G-RETRIEVER">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG is related to G-Retriever where subsets of the graph structure are the objects of enquiry</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="GRAPH-TOOLFORMER">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG is related to Graph-ToolFormer where derived graph metrics are the objects of enquiry</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="SURGE">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG is related to SURGE where narrative outputs are grounded in the facts of retrieved subgraphs</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="FABULA">
      <data key="d4">10.0</data>
      <data key="d5">Graph RAG is related to FABULA where retrieved event-plot subgraphs are serialized using narrative templates</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="GRAPH-BASED RAG APPLICATIONS">
      <data key="d4">9.0</data>
      <data key="d5">Graph RAG is an approach within the broader category of graph-based RAG applications</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d4">6.0</data>
      <data key="d5">RAG and QFS are contrasting methods for answering questions over text corpora, with RAG focusing on retrieval and QFS on summarization</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="LEWIS">
      <data key="d4">6.0</data>
      <data key="d5">Lewis is referenced in the context of retrieval-augmented generation (RAG)</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="DANG">
      <data key="d4">6.0</data>
      <data key="d5">Dang is referenced in the context of query-focused summarization (QFS)</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="BAUMEL">
      <data key="d4">6.0</data>
      <data key="d5">Baumel is referenced in the context of query-focused abstractive summarization</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="LASKAR">
      <data key="d4">6.0</data>
      <data key="d5">Laskar is referenced in the context of query-focused abstractive summarization</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="YAO">
      <data key="d4">6.0</data>
      <data key="d5">Yao is referenced in the context of query-focused abstractive summarization</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="GPT">
      <data key="d4">7.0</data>
      <data key="d5">GPT is a large language model referenced in the context of modern LLMs</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="LLAMA">
      <data key="d4">7.0</data>
      <data key="d5">Llama is a large language model referenced in the context of modern LLMs</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="GEMINI">
      <data key="d4">1.0</data>
      <data key="d5">Gemini is a large language model referenced in the context of modern LLMs</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LEIDEN" target="TRAAG ET AL.">
      <data key="d4">6.0</data>
      <data key="d5">Traag et al. are referenced in the context of community detection using the Leiden algorithm</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LEIDEN" target="TRAAG">
      <data key="d4">15.0</data>
      <data key="d5">Traag is one of the authors associated with the development of the Leiden algorithm, which was introduced in 2019.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEIDEN" target="GRAPH COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Leiden is used to detect graph communities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="KLEIN" target="SENSEMAKING">
      <data key="d4">6.0</data>
      <data key="d5">Klein is referenced in the context of sensemaking and understanding connections among people, places, and events</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LEWIS" target="MEMORY STRUCTURES">
      <data key="d4">16.0</data>
      <data key="d5">Lewis contributed to the development of memory structures</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="LEWIS" target="EXTERNAL MEMORY AND RAG">
      <data key="d4">8.0</data>
      <data key="d5">Lewis is an author associated with external memory and RAG, 2020</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="LEWIS" target="RAG">
      <data key="d4">8.0</data>
      <data key="d5">Lewis is an author associated with RAG</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="LASKAR" target="GOODWIN">
      <data key="d4">6.0</data>
      <data key="d5">Goodwin and Laskar are both authors associated with summarization tasks</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LASKAR" target="LIU">
      <data key="d4">6.0</data>
      <data key="d5">Laskar and Liu are both authors associated with summarization tasks</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LASKAR" target="LAPATA">
      <data key="d4">6.0</data>
      <data key="d5">Laskar and Lapata are both authors associated with summarization tasks</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LASKAR" target="HOQUE">
      <data key="d4">8.0</data>
      <data key="d5">Laskar and Hoque co-authored the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" published in Computational Linguistics in 2022</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LASKAR" target="HUANG">
      <data key="d4">8.0</data>
      <data key="d5">Laskar and Huang co-authored the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" published in Computational Linguistics in 2022</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="YAO" target="TRAJANOSKA">
      <data key="d4">14.0</data>
      <data key="d5">Trajanoska and Yao have both worked on using LLMs for knowledge graph creation and completion</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="YAO" target="ZHOU">
      <data key="d4">14.0</data>
      <data key="d5">Zhou and Yao have both worked on improving chain-of-thought (CoT) prompting with search algorithms</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="YAO" target="REACT">
      <data key="d4">33.0</data>
      <data key="d5">Yao has worked on the ReAct method, a prompting technique used in various experiments. This method, known as ReAct, has been a significant focus of Yao's research efforts, highlighting their contribution to the development and application of advanced prompting techniques in the field of Artificial Intelligence and Machine Learning.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="YAO" target="TOT">
      <data key="d4">33.0</data>
      <data key="d5">Yao has worked on the ToT (Tree of Thoughts) method, a prompting technique used in various experiments.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="YAO" target="WEBSHOP">
      <data key="d4">24.0</data>
      <data key="d5">Yao has worked on WebShop, a dataset used to evaluate methods requiring reasoning and acting. Yao is one of the authors who contributed to the development of WebShop.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="YAO" target="GAME OF 24">
      <data key="d4">8.0</data>
      <data key="d5">Yao has worked on Game of 24, a dataset used to evaluate methods requiring reasoning and acting</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="YAO" target="IL">
      <data key="d4">7.0</data>
      <data key="d5">Yao has worked on the IL method</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="YAO" target="RL">
      <data key="d4">7.0</data>
      <data key="d5">Yao has worked on the RL method</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="YAO" target="IL+RL">
      <data key="d4">8.0</data>
      <data key="d5">Yao is one of the authors who contributed to the development of IL+RL</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="YAO" target="CHAIN-OF-THOUGHT">
      <data key="d4">16.0</data>
      <data key="d5">Yao contributed to the development of chain-of-thought planning and reasoning</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="YAO" target="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d4">8.0</data>
      <data key="d5">Yao is an author associated with chain-of-thought-based planning and reasoning methods, 2023</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="GOODWIN" target="TRANSFORMER ARCHITECTURE">
      <data key="d4">6.0</data>
      <data key="d5">Goodwin is referenced in the context of transformer architecture improvements in summarization tasks</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GOODWIN" target="LIU">
      <data key="d4">6.0</data>
      <data key="d5">Goodwin and Liu are both authors associated with summarization tasks</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GOODWIN" target="LAPATA">
      <data key="d4">6.0</data>
      <data key="d5">Goodwin and Lapata are both authors associated with summarization tasks</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LIU" target="TRANSFORMER ARCHITECTURE">
      <data key="d4">6.0</data>
      <data key="d5">Liu is referenced in the context of transformer architecture improvements in summarization tasks</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LIU" target="LAPATA">
      <data key="d4">14.0</data>
      <data key="d5">Liu and Lapata are both authors associated with summarization tasks. They co-authored the paper "Hierarchical transformers for multi-document summarization," which was published on arXiv in 2019. This collaboration highlights their contributions to the field of natural language processing, particularly in the development of advanced techniques for summarizing multiple documents using hierarchical transformer models.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LIU" target="KURATOV">
      <data key="d4">20.0</data>
      <data key="d5">Kuratov and Liu are both authors associated with the issue of information loss in longer contexts. They have also collaborated on research examining the effects of context window size. Their work contributes to understanding how context length impacts information retention and processing in AI and ML systems.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LIU" target="SHRIDHAR">
      <data key="d4">14.0</data>
      <data key="d5">Liu and Shridhar have both worked on text-based environments and acting-based prompting techniques for language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LIU" target="SEARCH ALGORITHMS">
      <data key="d4">2.0</data>
      <data key="d5">Liu has worked on combining search algorithms with language model agents</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LIU" target="SEARCH APPROACHES">
      <data key="d4">6.0</data>
      <data key="d5">Liu has worked on previous search approaches using LMs as world models</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LIU" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Liu has contributed to the research area of agentic systems, which is related to ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LIU" target="DYLAN">
      <data key="d4">16.0</data>
      <data key="d5">Liu has worked on DyLAN, a system that uses FMs to score the response quality of nodes in each layer to prune the connections</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="LIU" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">6.0</data>
      <data key="d5">Liu is mentioned in relation to novelty search algorithms</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="LAPATA" target="TRANSFORMER ARCHITECTURE">
      <data key="d4">6.0</data>
      <data key="d5">Lapata is referenced in the context of transformer architecture improvements in summarization tasks</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LAPATA" target="XU">
      <data key="d4">7.0</data>
      <data key="d5">Xu and Lapata have both worked on methods for extracting latent summarization queries from source texts</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="GPT" target="ACHIAM ET AL.">
      <data key="d4">6.0</data>
      <data key="d5">Achiam et al. are referenced in the context of the GPT large language model</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GPT" target="BROWN ET AL.">
      <data key="d4">6.0</data>
      <data key="d5">Brown et al. are referenced in the context of the GPT large language model</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GPT" target="ACHIAM">
      <data key="d4">7.0</data>
      <data key="d5">Achiam is one of the authors associated with the GPT series</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GPT" target="BROWN">
      <data key="d4">7.0</data>
      <data key="d5">Brown is one of the authors associated with the GPT series</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GPT" target="IN-CONTEXT LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">GPT series of LLMs are capable of using in-context learning to summarize content</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GPT" target="FOUNDATION MODELS (FMS)">
      <data key="d4">18.0</data>
      <data key="d5">GPT is an example of a Foundation Model</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="GPT" target="OPENAI">
      <data key="d4">18.0</data>
      <data key="d5">OpenAI developed the GPT Foundation Model</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="LLAMA" target="TOUVRON ET AL.">
      <data key="d4">6.0</data>
      <data key="d5">Touvron et al. are referenced in the context of the Llama large language model</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LLAMA" target="TOUVRON">
      <data key="d4">7.0</data>
      <data key="d5">Touvron is one of the authors associated with the Llama series</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLAMA" target="IN-CONTEXT LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">Llama series of LLMs are capable of using in-context learning to summarize content</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GEMINI" target="ANIL ET AL.">
      <data key="d4">1.0</data>
      <data key="d5">Anil et al. are referenced in the context of the Gemini large language model</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GEMINI" target="ANIL">
      <data key="d4">7.0</data>
      <data key="d5">Anil is one of the authors associated with the Gemini series</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GEMINI" target="IN-CONTEXT LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">Gemini series of LLMs are capable of using in-context learning to summarize content</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GEMINI" target="GPT-4 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">The GPT-4 technical report and Gemini are both mentioned as significant technologies in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="SENSEMAKING" target="KLEIN ET AL.">
      <data key="d4">6.0</data>
      <data key="d5">Klein et al. are referenced in the context of sensemaking and understanding connections among people, places, and events</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="RANADE" target="JOSHI">
      <data key="d4">21.0</data>
      <data key="d5">Ranade and Joshi are co-authors referenced in the context of intelligence analysis and sensemaking. They have both worked on narrative templates for event-plot subgraphs, contributing to the understanding and structuring of complex data within these fields. Their collaborative efforts highlight their expertise in identifying patterns and relationships within datasets, which is crucial for effective intelligence analysis.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="BROWN ET AL." target="LLM">
      <data key="d4">8.0</data>
      <data key="d5">Brown et al. contributed to the research on in-context learning for LLMs in 2020</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="BROWN ET AL." target="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d4">12.0</data>
      <data key="d5">Brown et al. are referenced in the paper for their work on language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="TOUVRON ET AL." target="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d4">12.0</data>
      <data key="d5">Touvron et al. are referenced in the paper for their work on language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="BROWN" target="LLM">
      <data key="d4">8.0</data>
      <data key="d5">Brown contributed to the research on in-context learning for LLMs in 2020</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="BROWN" target="IN-CONTEXT LEARNING">
      <data key="d4">18.0</data>
      <data key="d5">Brown has worked on in-context learning abilities of language models</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="KURATOV" target="BULATOV">
      <data key="d4">8.0</data>
      <data key="d5">Kuratov and Bulatov co-authored the paper "In search of needles in a 11m haystack: Recurrent memory finds what LLMs miss" published in 2024</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV" target="ANOKHIN">
      <data key="d4">8.0</data>
      <data key="d5">Kuratov and Anokhin co-authored the paper "In search of needles in a 11m haystack: Recurrent memory finds what LLMs miss" published in 2024</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV" target="SOROKIN">
      <data key="d4">8.0</data>
      <data key="d5">Kuratov and Sorokin co-authored the paper "In search of needles in a 11m haystack: Recurrent memory finds what LLMs miss" published in 2024</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV" target="BURTSEV">
      <data key="d4">1.0</data>
      <data key="d5">Kuratov and Burtsev co-authored the paper "In search of needles in a 11m haystack: Recurrent memory finds what("entity"</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="RAG" target="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Query-focused abstractive summarization is a task that RAG methods aim to address</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="RAG" target="PRE-INDEXING">
      <data key="d4">6.0</data>
      <data key="d5">Pre-indexing is mentioned as a potential support for a new RAG approach</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="RAG" target="ADAS">
      <data key="d4">13.0</data>
      <data key="d5">RAG is a building block used in agentic systems within the ADAS framework. It is mentioned as a potential building block for ADAS, highlighting its significance in the development and functionality of these advanced systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="RAG" target="AGENTINSTRUCT">
      <data key="d4">12.0</data>
      <data key="d5">RAG is one of the general capabilities that can be taught to an LLM using AgentInstruct</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="RAG" target="MIRAGE">
      <data key="d4">8.0</data>
      <data key="d5">RAG skill was evaluated using the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="RAG" target="RAG DATA">
      <data key="d4">8.0</data>
      <data key="d5">RAG data is used in the evaluations of the Retrieval Augmented Generation skill</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="RAG" target="MIRAGE DATASETS">
      <data key="d4">9.0</data>
      <data key="d5">RAG is used to enhance model performance on the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="LOUVAIN" target="BLONDEL">
      <data key="d4">7.0</data>
      <data key="d5">Blondel is one of the authors associated with the Louvain algorithm</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="HOTPOTQA" target="YANG">
      <data key="d4">16.0</data>
      <data key="d5">Yang is one of the authors associated with the HotPotQA dataset, a multi-hop question-answering benchmark. Yang has contributed significantly to the development and research of HotPotQA, which is designed to evaluate the ability of AI systems to perform complex reasoning by requiring them to answer questions that necessitate multiple steps of inference.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HOTPOTQA" target="MT-BENCH">
      <data key="d4">7.0</data>
      <data key="d5">HotPotQA and MT-Bench are both benchmark datasets for open-domain question answering</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="HOTPOTQA" target="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d4">14.0</data>
      <data key="d5">HotPotQA is a dataset used in the empirical evaluation of LATS</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="HOTPOTQA" target="LATS">
      <data key="d4">89.0</data>
      <data key="d5">HOTPOTQA is a dataset used to evaluate the performance of the LATS algorithm. LATS achieves the highest accuracy and the lowest average number of nodes/states required for success on HotPotQA. The LATS algorithm is tested and evaluated using the HotPotQA dataset, where it performs well by combining internal reasoning and external retrieval strategies.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HOTPOTQA" target="EXPERIMENTS">
      <data key="d4">8.0</data>
      <data key="d5">Experiments evaluate the applicability of LATS on the HotPotQA dataset</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HOTPOTQA" target="EXACT MATCH (EM)">
      <data key="d4">16.0</data>
      <data key="d5">Exact Match (EM) is a metric used to evaluate the performance of different methods on the HotpotQA dataset. This metric is crucial for assessing how accurately a model's predictions align with the ground truth answers in the HotpotQA dataset, which is designed to test a model's ability to perform multi-hop reasoning and provide comprehensive answers to complex questions.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HOTPOTQA" target="API CALLS">
      <data key="d4">8.0</data>
      <data key="d5">API Calls are used to search and retrieve information in the HotPotQA setup</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HOTPOTQA" target="ORACLE SETUP">
      <data key="d4">8.0</data>
      <data key="d5">Oracle Setup is used in HotPotQA to provide feedback about the answer&#8217;s correctness</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HOTPOTQA" target="FEW-SHOT EXAMPLES">
      <data key="d4">7.0</data>
      <data key="d5">Few-Shot Examples are used in the experiments to evaluate different methods on a subset of 100 questions for HotPotQA</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HOTPOTQA" target="TOT">
      <data key="d4">20.0</data>
      <data key="d5">ToT is evaluated on the HotPotQA dataset and is used as a prompting method in the HotPotQA experiments.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="HOTPOTQA" target="RAP">
      <data key="d4">20.0</data>
      <data key="d5">RAP is evaluated on the HotPotQA dataset and is used as a prompting method in the HotPotQA experiments.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="HOTPOTQA" target="CROWDWORKERS">
      <data key="d4">18.0</data>
      <data key="d5">Crowdworkers crafted the question-answer pairs and provided supporting facts for HotPotQA</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="WIKIPEDIA">
      <data key="d4">18.0</data>
      <data key="d5">HotPotQA uses Wikipedia as a source of information</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="SUPPORTING FACTS">
      <data key="d4">16.0</data>
      <data key="d5">HotPotQA includes supporting facts provided by crowdworkers to justify answers</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="QUESTION-ANSWER PAIRS">
      <data key="d4">16.0</data>
      <data key="d5">HotPotQA consists of question-answer pairs that require reasoning over multiple documents</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="EM">
      <data key="d4">16.0</data>
      <data key="d5">HotPotQA performance is evaluated using the EM (Exact Match) metric</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="TAB. 8">
      <data key="d4">14.0</data>
      <data key="d5">Tab. 8 shows the results of the HotPotQA experiments</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">Prompt is a technique used in HotPotQA</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="HOTPOTQA" target="THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">Thought is an action in HotPotQA</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="HOTPOTQA" target="ACTION">
      <data key="d4">8.0</data>
      <data key="d5">Action is an action in HotPotQA</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="HOTPOTQA" target="OBSERVATION">
      <data key="d4">8.0</data>
      <data key="d5">Observation is an action in HotPotQA</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="HOTPOTQA" target="FINISH">
      <data key="d4">8.0</data>
      <data key="d5">Finish is an action in HotPotQA</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="HOTPOTQA" target="HOTPOTQA PROMPTS">
      <data key="d4">8.0</data>
      <data key="d5">HotPotQA Prompts are techniques used in HotPotQA</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="YANG" target="MULTIHOP-RAG">
      <data key="d4">8.0</data>
      <data key="d5">Yang contributed to the MultiHop-RAG dataset in 2024</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="YANG" target="TANG">
      <data key="d4">7.0</data>
      <data key="d5">Tang and Yang have both worked on the MultiHop-RAG dataset</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="YANG" target="SILVER">
      <data key="d4">7.0</data>
      <data key="d5">Silver and Yang have both worked on model-based reinforcement learning and Monte Carlo Tree Search (MCTS)</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="YANG" target="ADAS">
      <data key="d4">18.0</data>
      <data key="d5">Yang is one of the authors who discussed ADAS methods focusing on designing prompts in 2024</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="YANG" target="OPRO">
      <data key="d4">16.0</data>
      <data key="d5">Yang has worked on OPRO, a system that adopts FMs to automate prompt engineering for agents</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="NEWS ARTICLES">
      <data key="d4">6.0</data>
      <data key="d5">Both podcast transcripts and news articles are real-world datasets used to generate activity-centered sense-making questions</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="KEVIN SCOTT">
      <data key="d4">7.0</data>
      <data key="d5">Kevin Scott is a participant in the podcast conversations compiled in the podcast transcripts dataset</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="BEHIND THE TECH">
      <data key="d4">8.0</data>
      <data key="d5">Behind the Tech is the podcast series compiled into the podcast transcripts dataset</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="MEDIA">
      <data key="d4">7.0</data>
      <data key="d5">Media includes podcast transcripts</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="NEWS ARTICLES" target="MULTIHOP-RAG">
      <data key="d4">8.0</data>
      <data key="d5">MultiHop-RAG is a benchmark dataset of news articles</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NEWS ARTICLES" target="MEDIA">
      <data key="d4">8.0</data>
      <data key="d5">Media includes news articles</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="DIVERSITY">
      <data key="d4">12.0</data>
      <data key="d5">Comprehensiveness and Diversity are metrics used to evaluate the quality of generated answers. These target qualities are particularly significant in the context of evaluating the Graph RAG approach. By focusing on both comprehensiveness and diversity, the evaluation process ensures that the generated answers are not only thorough and complete but also varied and rich in different perspectives.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="EMPOWERMENT">
      <data key="d4">12.0</data>
      <data key="d5">Comprehensiveness and Empowerment are metrics used to evaluate the quality of generated answers. These target qualities are particularly significant in the context of evaluating the Graph RAG approach. By focusing on both comprehensiveness and empowerment, the evaluation process aims to ensure that generated answers are not only thorough and complete but also enable users to feel more informed and capable.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="DIRECTNESS">
      <data key="d4">6.0</data>
      <data key="d5">Both Comprehensiveness and Directness are metrics used to evaluate the quality of generated answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="METRIC">
      <data key="d4">7.0</data>
      <data key="d5">Comprehensiveness is one of the metrics used to evaluate the quality of generated answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="DECISION">
      <data key="d4">7.0</data>
      <data key="d5">Decisions involve assessing comprehensiveness</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="CONTEXT WINDOW SIZE">
      <data key="d4">14.0</data>
      <data key="d5">Context window size affects the comprehensiveness of answers</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIVERSITY" target="EMPOWERMENT">
      <data key="d4">12.0</data>
      <data key="d5">Diversity and Empowerment are metrics used to evaluate the quality of generated answers. These target qualities are particularly significant in the context of assessing the Graph RAG (Retrieval-Augmented Generation) approach. By focusing on Diversity and Empowerment, the evaluation process aims to ensure that the generated responses are not only varied and comprehensive but also empowering and impactful for the end-users.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="DIVERSITY" target="DIRECTNESS">
      <data key="d4">6.0</data>
      <data key="d5">Both Diversity and Directness are metrics used to evaluate the quality of generated answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DIVERSITY" target="METRIC">
      <data key="d4">7.0</data>
      <data key="d5">Diversity is one of the metrics used to evaluate the quality of generated answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DIVERSITY" target="DECISION">
      <data key="d4">7.0</data>
      <data key="d5">Decisions involve assessing diversity</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="DIVERSITY" target="CONTEXT WINDOW SIZE">
      <data key="d4">14.0</data>
      <data key="d5">Context window size affects the diversity of answers</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="EMPOWERMENT" target="DIRECTNESS">
      <data key="d4">6.0</data>
      <data key="d5">Both Empowerment and Directness are metrics used to evaluate the quality of generated answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EMPOWERMENT" target="METRIC">
      <data key="d4">7.0</data>
      <data key="d5">Empowerment is one of the metrics used to evaluate the quality of generated answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EMPOWERMENT" target="DECISION">
      <data key="d4">7.0</data>
      <data key="d5">Decisions involve assessing empowerment</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="EMPOWERMENT" target="CONTEXT WINDOW SIZE">
      <data key="d4">14.0</data>
      <data key="d5">Context window size affects the empowerment of answers</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="TEXT CHUNKS">
      <data key="d4">8.0</data>
      <data key="d5">Text chunks are segments of input texts used in the Graph RAG approach</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ELEMENT INSTANCES">
      <data key="d4">8.0</data>
      <data key="d5">Element instances are extracted from text chunks in the Graph RAG approach</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="TEXT CHUNKS" target="SOURCE DOCUMENTS">
      <data key="d4">8.0</data>
      <data key="d5">Text chunks are segments of input texts extracted from source documents</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="NAMED ENTITIES">
      <data key="d4">7.0</data>
      <data key="d5">Named entities are a type of element instance extracted using LLM prompts</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="LLM PROMPTS">
      <data key="d4">8.0</data>
      <data key="d5">LLM prompts are used to extract element instances from text chunks</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="COVARIATES">
      <data key="d4">1.0</data>
      <data key="d5">Covariates can be associated with extracted node instances in the Graph RAG approach</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="LLM">
      <data key="d4">6.0</data>
      <data key="d5">Element instances are descriptions of entities, relationships, and claims extracted from source texts by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="ELEMENT SUMMARIES">
      <data key="d4">8.0</data>
      <data key="d5">Element summaries are created by further summarizing instance-level summaries</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="NAMED ENTITIES" target="FEW-SHOT EXAMPLES">
      <data key="d4">1.0</data>
      <data key="d5">Few-shot examples are used in LLM prompts to extract named entities</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="NAMED ENTITIES" target="LLM">
      <data key="d4">6.0</data>
      <data key="d5">Named entities are extracted from text by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="DOMAIN-SPECIFIC KNOWLEDGE">
      <data key="d4">7.0</data>
      <data key="d5">Few-shot examples tailored to domain-specific knowledge can improve the extraction process</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="LLM">
      <data key="d4">7.0</data>
      <data key="d5">Few-shot examples are used to train or prompt LLMs in specialized domains</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="IN-CONTEXT LEARNING" target="LATS">
      <data key="d4">16.0</data>
      <data key="d5">In-context learning is leveraged by LATS (Learning Agent Training System) to refine both the agent and the value function. This approach enhances the system's ability to adapt and improve its performance based on the context provided during the learning process.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="IN-CONTEXT LEARNING" target="TREE-BASED SEARCH">
      <data key="d4">14.0</data>
      <data key="d5">In-context learning abilities of language models are leveraged in tree-based search to avoid the cost of training a value function over language descriptions</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="LLM">
      <data key="d4">7.0</data>
      <data key="d5">Community detection algorithms are used by LLMs to partition graphs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="RECALL" target="PRECISION">
      <data key="d4">7.0</data>
      <data key="d5">Recall and precision are quality metrics that need to be balanced in the extraction process</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COVARIATES" target="NODES">
      <data key="d4">9.0</data>
      <data key="d5">Nodes and covariates are elements within a community structure</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COVARIATES" target="EDGES">
      <data key="d4">9.0</data>
      <data key="d5">Edges and covariates are elements within a community structure</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LLM-DEBATE" target="QUALITY-DIVERSITY">
      <data key="d4">5.0</data>
      <data key="d5">Both LLM-Debate and Quality-Diversity are systems designed to leverage diverse perspectives to find better answers</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM-DEBATE" target="META AGENT SEARCH">
      <data key="d4">30.0</data>
      <data key="d5">Meta Agent Search utilizes LLM-DEBATE as both one of its baselines and one of the initial seeds in its archive. This dual role highlights the significance of LLM-DEBATE in the foundational and comparative aspects of Meta Agent Search's methodology.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LLM-DEBATE" target="DU">
      <data key="d4">16.0</data>
      <data key="d5">Du has worked on LLM-Debate</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="LLM-DEBATE" target="ARC">
      <data key="d4">12.0</data>
      <data key="d5">LLM-Debate is a baseline used for experiments on ARC</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="LLM-DEBATE" target="PHYSICS EXPERT">
      <data key="d4">8.0</data>
      <data key="d5">Physics Expert is a unique role assigned to a debate module in LLM-Debate</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LLM-DEBATE" target="CHEMISTRY EXPERT">
      <data key="d4">8.0</data>
      <data key="d5">Chemistry Expert is a unique role assigned to a debate module in LLM-Debate</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LLM-DEBATE" target="BIOLOGY EXPERT">
      <data key="d4">8.0</data>
      <data key="d5">Biology Expert is a unique role assigned to a debate module in LLM-Debate</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LLM-DEBATE" target="SCIENCE GENERALIST">
      <data key="d4">8.0</data>
      <data key="d5">Science Generalist is a unique role assigned to a debate module in LLM-Debate</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="INTELLIGENT GO-EXPLORE">
      <data key="d4">40.0</data>
      <data key="d5">Quality-Diversity is a simplified version of Intelligent Go-Explore</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="META AGENT SEARCH">
      <data key="d4">44.0</data>
      <data key="d5">Meta Agent Search is a sophisticated framework that leverages Quality-Diversity (QD) methodologies to enhance its agent discovery process. Specifically, Meta Agent Search compares its discovered agents against the Quality-Diversity baseline to evaluate performance and effectiveness. Additionally, it utilizes Quality-Diversity as one of the baselines for benchmarking and as one of the initial seeds in its archive, ensuring a diverse and high-quality starting point for further exploration and optimization. This integration of QD principles allows Meta Agent Search to systematically explore a wide range of potential solutions, fostering innovation and robustness in agent development.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="LU">
      <data key="d4">24.0</data>
      <data key="d5">Lu has worked on Quality-Diversity and is an author associated with the state-of-the-art hand-designed agent in this field. Additionally, Lu is linked to the Quality-Diversity technique, as noted in the 2024c publication.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES">
      <data key="d4">7.0</data>
      <data key="d5">Quality-Diversity is a technique related to assigning FM modules in the agentic system with different roles</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="CHAIN-OF-THOUGHT">
      <data key="d4">10.0</data>
      <data key="d5">Both Chain-of-Thought and Quality-Diversity are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="COT-SC">
      <data key="d4">10.0</data>
      <data key="d5">Both COT-SC and Quality-Diversity are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="SELF-REFINE">
      <data key="d4">10.0</data>
      <data key="d5">Both Self-Refine and Quality-Diversity are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="LLM DEBATE">
      <data key="d4">5.0</data>
      <data key="d5">Both LLM Debate and Quality-Diversity are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="STEP-BACK ABSTRACTION">
      <data key="d4">5.0</data>
      <data key="d5">Both Step-back Abstraction and Quality-Diversity are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="ROLE ASSIGNMENT">
      <data key="d4">5.0</data>
      <data key="d5">Both Quality-Diversity and Role Assignment are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="ARC">
      <data key="d4">12.0</data>
      <data key="d5">Quality-Diversity is a baseline used for experiments on ARC</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="INTELLIGENT GO-EXPLORE" target="META AGENT SEARCH">
      <data key="d4">18.0</data>
      <data key="d5">Meta Agent Search uses Intelligent Go-Explore as one of the initial seeds in the archive</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SELFCHECKGPT">
      <data key="d4">6.0</data>
      <data key="d5">SelfCheckGPT is mentioned as a system that could improve the current analysis in the context of Meta Agent Search</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="META AGENT SEARCH" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">18.0</data>
      <data key="d5">Meta Agent Search is an algorithm used within the research area of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-STEP PEER REVIEW AGENT">
      <data key="d4">27.0</data>
      <data key="d5">Meta Agent Search discovered the Multi-Step Peer Review Agent during its exploration in the Reading Comprehension domain, specifically within the Generalized Question-Answering (GPQA) framework. The Multi-Step Peer Review Agent serves as a prime example of an agent identified by the Meta Agent Search algorithm, showcasing the algorithm's capability to uncover sophisticated agents in complex domains.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VERIFIED MULTIMODAL AGENT">
      <data key="d4">27.0</data>
      <data key="d5">META AGENT SEARCH and VERIFIED MULTIMODAL AGENT

Meta Agent Search is an advanced algorithm designed to discover and identify agents within specific domains. During its search in the Math domain (MGSM), it successfully discovered the Verified Multimodal Agent. The Verified Multimodal Agent serves as a prime example of the capabilities of the Meta Agent Search algorithm, showcasing its effectiveness in identifying sophisticated agents across various domains.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DIVIDE AND CONQUER AGENT">
      <data key="d4">27.0</data>
      <data key="d5">The Meta Agent Search algorithm is notable for its ability to discover effective agents within various domains. One such agent, the Divide and Conquer Agent, was identified by the Meta Agent Search during its exploration in the Reading Comprehension domain, specifically within the Generalized Question-Answering (GPQA) framework. The Divide and Conquer Agent exemplifies the potential of the Meta Agent Search algorithm to uncover sophisticated solutions tailored to complex tasks.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ADAS">
      <data key="d4">45.0</data>
      <data key="d5">META AGENT SEARCH is an algorithm used within the research area of Automated Design of Agentic Systems (ADAS). It is a method proposed as part of the ADAS project, showcasing the potential to progressively discover agents that outperform state-of-the-art hand-designed baselines.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,4884e8429ca1e567dadf5e22b4b68274,7de66b94cf868b37b1df51dc545c415f,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FMS">
      <data key="d4">32.0</data>
      <data key="d5">META AGENT SEARCH leverages the knowledge embedded in Foundation Models (FMs) to address questions across various domains, including Science and Multi-task domains. By utilizing FMs as meta agents, META AGENT SEARCH iteratively programs new agents, enhancing its capability to solve challenging questions effectively.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FUNSEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search references the practice of FunSearch for programming a "forward" function to define new agentic systems</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC">
      <data key="d4">34.0</data>
      <data key="d5">META AGENT SEARCH and ARC are intricately connected in the realm of Artificial Intelligence and Machine Learning. ARC, a dataset designed for evaluating performance, serves as the benchmark for Meta Agent Search. Meta Agent Search is a sophisticated tool used to discover the most effective agents by testing their performance on the ARC dataset. This process involves evaluating agents through the ARC logic puzzle task, ensuring that the discovered agents are optimized for solving complex problems presented within the dataset. The synergy between Meta Agent Search and ARC highlights the importance of rigorous evaluation and optimization in advancing AI capabilities.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2,ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DROP">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search is tested on the DROP benchmark for evaluating Reading Comprehension. Meta Agent Search was evaluated using the DROP reading comprehension task.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MGSM">
      <data key="d4">32.0</data>
      <data key="d5">Meta Agent Search is a sophisticated AI system designed to evaluate mathematical capabilities in a multi-lingual context. It has been rigorously tested on the MGSM benchmark, a dataset specifically curated for assessing math proficiency across different languages. The performance of the agents discovered by Meta Agent Search is meticulously evaluated using the MGSM math task, ensuring a comprehensive analysis of their mathematical problem-solving abilities.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM8K">
      <data key="d4">32.0</data>
      <data key="d5">Meta Agent Search is a sophisticated AI model designed to enhance performance on the GSM8K dataset. It significantly improves accuracy on this dataset, which is known for its challenging math tasks. The model's capabilities were rigorously tested by evaluating its performance on the GSM8K held-out math task, demonstrating its effectiveness. Additionally, Meta Agent Search explores the transferability of discovered agents within the GSM8K dataset, showcasing its potential for broader applications in similar domains.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM-HARD">
      <data key="d4">32.0</data>
      <data key="d5">Meta Agent Search is a sophisticated AI technique that has demonstrated significant improvements in accuracy on the GSM-Hard dataset. This method is particularly notable for its ability to test the transferability of discovered agents within the GSM-Hard dataset, showcasing its robustness and adaptability. The efficacy of Meta Agent Search was rigorously evaluated using the GSM-Hard held-out math task, further validating its performance and potential in complex mathematical problem-solving scenarios.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPT-3.5">
      <data key="d4">49.0</data>
      <data key="d5">Meta Agent Search uses GPT-3.5 as a baseline for testing the performance of discovered agents. It evaluates these agents and baselines using GPT-3.5. Notably, Meta Agent Search showed improved performance on ARC tasks after transferring from GPT-3.5 to GPT-4.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPT-4">
      <data key="d4">49.0</data>
      <data key="d5">Meta Agent Search leverages GPT-4 as the language model for its meta agent, demonstrating improved performance on ARC tasks after transitioning from GPT-3.5 to GPT-4. This system tests the transferability of discovered agents on GPT-4, showcasing its capabilities in enhancing the efficiency and effectiveness of the meta agent.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LU">
      <data key="d4">7.0</data>
      <data key="d5">Lu has worked on open-endedness algorithms that leverage human notions of interestingness, which are referenced in Meta Agent Search</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ZHANG">
      <data key="d4">7.0</data>
      <data key="d5">Zhang has worked on open-endedness algorithms that leverage human notions of interestingness, which are referenced in Meta Agent Search</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MADAAN">
      <data key="d4">7.0</data>
      <data key="d5">Madaan has worked on self-reflection iterations in meta agents, which are adopted in Meta Agent Search</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SHINN">
      <data key="d4">1.0</data>
      <data key="d5">Shinn has worked on self-reflection iterations in meta agents, which are adopted in Meta Agent Search</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="PROGRAMMING LANGUAGES">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses programming languages as the search space for defining and searching for agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SEARCH ALGORITHMS">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search contrasts with search algorithms in custom search spaces like graphs</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CODE">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search uses code to define new agentic systems</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="QUERY APIS">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search provides the meta agent with basic functions like query APIs</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="PROMPTS">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search uses prompts for the meta agent to program new agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VALIDATION DATA">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses validation data from the target domain to evaluate the performance of generated agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="PERFORMANCE METRICS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search calculates performance metrics like success rate or F1 score to evaluate generated agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BOOTSTRAP CONFIDENCE INTERVAL">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses bootstrap confidence interval as a metric for the meta agent to maximize</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ITERATIONS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses iterations to refine the novelty and correctness of proposed agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC LOGIC PUZZLE TASK">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search was evaluated using the ARC logic puzzle task</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="READING COMPREHENSION">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search was evaluated using reading comprehension benchmarks</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MATH">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search was evaluated using math benchmarks</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SCIENCE QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search was evaluated using science question benchmarks</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-TASK PROBLEM SOLVING">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search was evaluated using multi-task problem solving benchmarks</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="TRANSFERABILITY">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search assesses the transferability of discovered agents to different tasks and models</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SUCCESS RATE">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses success rate as a performance metric to evaluate generated agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="F1 SCORE">
      <data key="d4">16.0</data>
      <data key="d5">META AGENT SEARCH utilizes the F1 Score as a key performance metric to evaluate its generated agents. This evaluation is specifically applied within the domains of Reading Comprehension and Math, ensuring that the agents' performance is accurately assessed in these areas. The F1 Score, which balances precision and recall, provides a comprehensive measure of the agents' effectiveness, making it an essential tool for META AGENT SEARCH in optimizing and refining its AI capabilities.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ACCURACY RATE">
      <data key="d4">16.0</data>
      <data key="d5">META AGENT SEARCH utilizes the accuracy rate as a key performance metric to evaluate its generated agents. This metric is specifically employed to assess the performance of Meta Agent Search in the domains of Reading Comprehension and Math. By focusing on accuracy rate, Meta Agent Search ensures that its agents are effectively evaluated, providing a reliable measure of their proficiency in these critical areas.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CHAIN-OF-THOUGHT">
      <data key="d4">33.0</data>
      <data key="d5">Meta Agent Search is a sophisticated AI system that leverages the Chain-of-Thought strategy to generate, refine, and ensemble answers. It compares its discovered agents against the Chain-of-Thought baseline, using this strategy as one of its key benchmarks. By integrating the Chain-of-Thought approach, Meta Agent Search enhances its ability to produce accurate and coherent responses, demonstrating its effectiveness in the realm of artificial intelligence and machine learning.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SELF-REFINE">
      <data key="d4">33.0</data>
      <data key="d5">Meta Agent Search is a sophisticated system that leverages the Self-Refine strategy to enhance the refinement of its generated agents. It uses Self-Refine as one of its baselines, comparing its discovered agents against this baseline to ensure improved performance and effectiveness. This approach allows Meta Agent Search to continuously optimize and validate its agents, ensuring they meet high standards of quality and efficiency.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="COT-SC">
      <data key="d4">21.0</data>
      <data key="d5">Meta Agent Search is a system that compares its discovered agents against the COT-SC baseline. Additionally, Meta Agent Search utilizes the COT-SC strategy for generating and refining answers, indicating a reliance on COT-SC methodologies to enhance its performance and accuracy.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HUMAN-LIKE CRITIC">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses human-like critics to provide feedback on generated agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FEEDBACK">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses feedback from human-like critics to refine generated agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EFFICIENCY EXPERT">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses efficiency experts to provide feedback on the efficiency of generated agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="READABILITY EXPERT">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses readability experts to provide feedback on the readability of generated agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SIMPLICITY">
      <data key="d4">1.0</data>
      <data key="d5">Meta Agent Search uses simplicity experts to provide feedback on the simplicity of generated agents</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC CHALLENGE">
      <data key="d4">18.0</data>
      <data key="d5">Meta Agent Search is used to evaluate agents on the ARC challenge</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT">
      <data key="d4">12.0</data>
      <data key="d5">Meta Agent Search uses Self-Consistency with Chain-of-Thought as one of the baselines</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MMLU">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is tested on the MMLU benchmark for evaluating Multi-task Problem Solving</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPQA">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is tested on the GPQA benchmark for evaluating the capability of solving hard (graduate-level) questions in Science</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="REASONING AND PROBLEM-SOLVING DOMAINS">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search is tested in the Reasoning and Problem-Solving Domains</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SETUP">
      <data key="d4">8.0</data>
      <data key="d5">Setup involves investigating the potential of Meta Agent Search to improve the capabilities of agents</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BENCHMARKS">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search is tested on various benchmarks</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXPERIMENT SETTINGS">
      <data key="d4">8.0</data>
      <data key="d5">Experiment settings provide the conditions under which Meta Agent Search is tested</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BASELINES">
      <data key="d4">17.0</data>
      <data key="d5">Meta Agent Search utilizes baselines as initial seeds in the archive to discover better-performing agents. This approach leverages the foundational performance of baseline models to explore and identify superior agents, enhancing the overall efficiency and effectiveness of the search process.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="RESULTS AND ANALYSIS">
      <data key="d4">17.0</data>
      <data key="d5">Results and Analysis demonstrate the performance and effectiveness of Meta Agent Search across multiple domains. The analysis provides insights into how Meta Agent Search operates and its impact on various applications, highlighting its capabilities and potential in the field of Artificial Intelligence and Machine Learning.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-TASK DOMAIN">
      <data key="d4">22.0</data>
      <data key="d5">Meta Agent Search is tested in the Multi-task Domain and outperforms baselines in this domain.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SCIENCE DOMAIN">
      <data key="d4">22.0</data>
      <data key="d5">Meta Agent Search is tested in the Science Domain and outperforms baselines in this field.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="READING COMPREHENSION DOMAIN">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search shows significant improvement over baselines in the Reading Comprehension domain</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MATH DOMAIN">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search shows significant improvement over baselines in the Math domain</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CLAUDE-HAIKU">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search tests the transferability of discovered agents on Claude-Haiku</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CLAUDE-SONNET">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search tests the transferability of discovered agents on Claude-Sonnet</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LLM DEBATE">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search compares its discovered agents against the LLM Debate baseline</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STRUCTURED FEEDBACK AND ENSEMBLE AGENT">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search discovered the Structured Feedback and Ensemble Agent</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HIERARCHICAL COMMITTEE REINFORCEMENT AGENT">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search discovered the Hierarchical Committee Reinforcement Agent</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DYNAMIC MEMORY AND REFINEMENT AGENT">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search discovered the Dynamic Memory and Refinement Agent</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SVAMP">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search tests the transferability of discovered agents on the SVAMP dataset</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ASDIV">
      <data key="d4">2.0</data>
      <data key="d5">Meta Agent Search tests the transferability of discovered agents on the ASDiv dataset</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d4">9.0</data>
      <data key="d5">Dynamic Role-Playing Architecture is a top agent discovered by Meta Agent Search</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d4">9.0</data>
      <data key="d5">Structured Multimodal Feedback Loop is a top agent discovered by Meta Agent Search</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d4">9.0</data>
      <data key="d5">Interactive Multimodal Feedback Loop is a top agent discovered by Meta Agent Search</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CHEN">
      <data key="d4">14.0</data>
      <data key="d5">Chen has discussed safety concerns when executing untrusted model-generated code in Meta Agent Search</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ROKON">
      <data key="d4">14.0</data>
      <data key="d5">Rokon has discussed safety concerns when executing untrusted model-generated code in Meta Agent Search</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="META AGENT SEARCH" target="YEE">
      <data key="d4">14.0</data>
      <data key="d5">Yee has discussed safety concerns when executing untrusted model-generated code in Meta Agent Search</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="META AGENT SEARCH" target="META">
      <data key="d4">12.0</data>
      <data key="d5">Meta is mentioned in relation to the Meta Agent Search algorithm</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HIGHER-ORDER ADAS">
      <data key="d4">14.0</data>
      <data key="d5">Higher-order ADAS is an extension of Meta Agent Search that involves improving the meta agent itself</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">Novelty search algorithms are mentioned as a potential future direction for improving Meta Agent Search</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MORE INTELLIGENT EVALUATION FUNCTIONS">
      <data key="d4">12.0</data>
      <data key="d5">More intelligent evaluation functions are mentioned as a potential future direction for improving Meta Agent Search</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MORE COMPLEX DOMAINS">
      <data key="d4">12.0</data>
      <data key="d5">More complex domains are mentioned as a potential future direction for extending the evaluation of Meta Agent Search</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="UNDERSTANDING THE EMERGENCE OF COMPLEXITY FROM HUMAN ORGANIZATIONS">
      <data key="d4">12.0</data>
      <data key="d5">Understanding the emergence of complexity from human organizations is a scientific aspect of Meta Agent Search</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FIGURE 3A">
      <data key="d4">8.0</data>
      <data key="d5">Figure 3a shows the results and analysis of Meta Agent Search</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARCHIVE">
      <data key="d4">8.0</data>
      <data key="d5">The archive is used for comparison and improvement in Meta Agent Search</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SHENGRAN HU">
      <data key="d4">1.0</data>
      <data key="d5">Shengran Hu is associated with the detailed implementations of all baselines and discovered agents by Meta Agent Search</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPT-3.5-TURBO-0125">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses the GPT-3.5-turbo-0125 model during the evaluation of discovered agents</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPT-4O-MINI">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search could achieve improved results using the GPT-4o-mini model at a lower cost</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ADAS ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is a method used within ADAS algorithms</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EVALUATION FUNCTION">
      <data key="d4">1.0</data>
      <data key="d5">Evaluation Function is used to assess the performance of Meta Agent Search</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses the MIRAGE Datasets to evaluate the performance of various models</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="FALDOR" target="LEHMAN">
      <data key="d4">49.0</data>
      <data key="d5">Faldor and Lehman have both worked on open-endedness and AI-GAs</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,594449768ae2dea9b2efbe677075096b,ab04427ae0415a1c812a35cf8d3ee1a2,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="FALDOR" target="STANLEY">
      <data key="d4">49.0</data>
      <data key="d5">Faldor and Stanley have both worked on open-endedness and AI-GAs</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,594449768ae2dea9b2efbe677075096b,ab04427ae0415a1c812a35cf8d3ee1a2,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="FALDOR" target="WANG">
      <data key="d4">49.0</data>
      <data key="d5">Faldor and Wang have both worked on open-endedness and AI-GAs</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,594449768ae2dea9b2efbe677075096b,ab04427ae0415a1c812a35cf8d3ee1a2,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="FALDOR" target="OMNI-EPIC">
      <data key="d4">34.0</data>
      <data key="d5">Faldor has contributed significantly to the development of OMNI-EPIC, a system designed to enable Functional Managers (FMs) to create robotics learning environments through programming. In 2024, Faldor was one of the authors who discussed the capabilities and applications of OMNI-EPIC, highlighting its potential to revolutionize the way robotics education is approached by allowing for more customizable and interactive learning experiences.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FALDOR" target="ZHANG">
      <data key="d4">14.0</data>
      <data key="d5">Faldor and Zhang have both worked on open-endedness and AI-GAs</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="LEHMAN" target="STANLEY">
      <data key="d4">49.0</data>
      <data key="d5">Lehman and Stanley have both worked on open-endedness and AI-GAs</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,594449768ae2dea9b2efbe677075096b,ab04427ae0415a1c812a35cf8d3ee1a2,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LEHMAN" target="WANG">
      <data key="d4">49.0</data>
      <data key="d5">Lehman and Wang have both worked on open-endedness and AI-GAs</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,594449768ae2dea9b2efbe677075096b,ab04427ae0415a1c812a35cf8d3ee1a2,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LEHMAN" target="ZHANG">
      <data key="d4">14.0</data>
      <data key="d5">Lehman and Zhang have both worked on open-endedness and AI-GAs</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="LEHMAN" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">6.0</data>
      <data key="d5">Lehman is mentioned in relation to novelty search algorithms</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="STANLEY" target="WANG">
      <data key="d4">37.0</data>
      <data key="d5">Stanley and Wang have both worked on open-endedness and AI-GAs</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,594449768ae2dea9b2efbe677075096b,ab04427ae0415a1c812a35cf8d3ee1a2,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="STANLEY" target="ZHANG">
      <data key="d4">14.0</data>
      <data key="d5">Stanley and Zhang have both worked on open-endedness and AI-GAs</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="STANLEY" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">6.0</data>
      <data key="d5">Stanley is mentioned in relation to novelty search algorithms</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="WANG" target="ZHENG">
      <data key="d4">7.0</data>
      <data key="d5">Wang and Zheng have both contributed to research on evaluating natural language generation and RAG systems</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="WANG" target="SHAO">
      <data key="d4">14.0</data>
      <data key="d5">Shao and Wang have both worked on iterative and federated retrieval-generation strategies</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="WANG" target="COBEE">
      <data key="d4">14.0</data>
      <data key="d5">Cobbe and Wang have both worked on reasoning for language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WANG" target="WEI">
      <data key="d4">14.0</data>
      <data key="d5">Wei and Wang have both worked on chain-of-thought (CoT) prompting and its variants for reasoning in language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WANG" target="KOJIMA">
      <data key="d4">14.0</data>
      <data key="d5">Kojima and Wang have both worked on chain-of-thought (CoT) prompting and its variants for reasoning in language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WANG" target="LATS">
      <data key="d4">14.0</data>
      <data key="d5">Wang contributed to the research on self-consistency, which is a component of the value function in LATS</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="WANG" target="COT-SC">
      <data key="d4">29.0</data>
      <data key="d5">Wang is an author associated with the COT-SC state-of-the-art hand-designed agent and has worked on CoT-SC, a variant of CoT used in various experiments. In 2023, Wang contributed to the development and refinement of the COT-SC technique, demonstrating significant expertise in this area.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,bc26e68b0b2783ba912b9e5606d9eb0b,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="WANG" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">16.0</data>
      <data key="d5">Wang contributed to the development of agentic systems in the research area of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="WANG" target="ZHANG">
      <data key="d4">14.0</data>
      <data key="d5">Wang and Zhang have both worked on open-endedness and AI-GAs</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="WANG" target="PHILIPP WITTE">
      <data key="d4">8.0</data>
      <data key="d5">Wang and Philipp Witte co-authored the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="WANG" target="HAIPING WU">
      <data key="d4">8.0</data>
      <data key="d5">Wang and Haiping Wu co-authored the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="WANG" target="MICHAEL WYATT">
      <data key="d4">8.0</data>
      <data key="d5">Wang and Michael Wyatt co-authored the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="WANG" target="BIN XIAO">
      <data key="d4">8.0</data>
      <data key="d5">Wang and Bin Xiao co-authored the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="WANG" target="CAN XU">
      <data key="d4">8.0</data>
      <data key="d5">Wang and Can Xu co-authored the Phi-3 technical report: A highly capable language model locally on your phone, 2024</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="LLM" target="CLAIMS">
      <data key="d4">6.0</data>
      <data key="d5">Claims are extracted by LLMs and linked to detected entities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="LOGIT BIAS">
      <data key="d4">7.0</data>
      <data key="d5">Logit bias is used to force a yes/no decision in LLMs during the entity extraction process</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="EXTRACTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">An extraction prompt is used to extract specific types of information from text using LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="COVARIATE PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">A covariate prompt is used to extract additional variables associated with detected entities by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="GLEANINGS">
      <data key="d4">6.0</data>
      <data key="d5">Gleanings are multiple rounds of extraction used by LLMs to detect any additional entities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="LOGIT BIAS OF 100">
      <data key="d4">7.0</data>
      <data key="d5">A logit bias of 100 is used to force a yes/no decision in LLMs during the entity extraction process</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="YES/NO DECISION">
      <data key="d4">6.0</data>
      <data key="d5">A yes/no decision is used to determine if all entities were extracted by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="CONTINUATION">
      <data key="d4">6.0</data>
      <data key="d5">A continuation is used to encourage LLMs to glean missing entities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="CHUNK SIZES">
      <data key="d4">6.0</data>
      <data key="d5">Chunk sizes refer to the amount of text processed by LLMs in each round of extraction</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="NOISE">
      <data key="d4">5.0</data>
      <data key="d5">Noise can be introduced during the extraction process by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="ABSTRACTIVE SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Abstractive summarization is a method used by LLMs to create meaningful summaries of concepts</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="INSTANCE-LEVEL SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Instance-level summaries are initial summaries created by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="DUPLICATE ENTITY ELEMENTS">
      <data key="d4">6.0</data>
      <data key="d5">Duplicate entity elements can result from inconsistent extraction by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="ENTITY GRAPH">
      <data key="d4">7.0</data>
      <data key="d5">An entity graph is created by LLMs to represent entities and their relationships</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="CLOSELY-RELATED COMMUNITIES">
      <data key="d4">6.0</data>
      <data key="d5">Closely-related communities are detected and summarized by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="GLOBAL, QUERY-FOCUSED SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Global, query-focused summarization is a method used by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="KNOWLEDGE GRAPHS">
      <data key="d4">6.0</data>
      <data key="d5">Knowledge graphs are created and used by LLMs for reasoning tasks</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="HOMOGENEOUS UNDIRECTED WEIGHTED GRAPH">
      <data key="d4">7.0</data>
      <data key="d5">A homogeneous undirected weighted graph is used by LLMs to represent entities and relationships</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="EDGE WEIGHTS">
      <data key="d4">6.0</data>
      <data key="d5">Edge weights are used by LLMs to represent the strength of relationships</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d4">7.0</data>
      <data key="d5">Hierarchical community structure is detected by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="HIERARCHICAL PARTITION">
      <data key="d4">7.0</data>
      <data key="d5">A hierarchical partition is created by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="DIVIDE-AND-CONQUER GLOBAL SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Divide-and-conquer global summarization is a method used by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="REPORT-LIKE SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Report-like summaries are created by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="ROOT COMMUNITIES">
      <data key="d4">6.0</data>
      <data key="d5">Root communities are detected by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="SUB-COMMUNITIES">
      <data key="d4">6.0</data>
      <data key="d5">Sub-communities are detected by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="OPENORD">
      <data key="d4">7.0</data>
      <data key="d5">OpenORD is used by LLMs for visualizing graph communities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="FORCE ATLAS 2">
      <data key="d4">7.0</data>
      <data key="d5">Force Atlas 2 is used by LLMs for visualizing graph communities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="LEAF-LEVEL COMMUNITIES">
      <data key="d4">6.0</data>
      <data key="d5">Leaf-level communities are detected and summarized by LLMs</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="NODE">
      <data key="d4">6.0</data>
      <data key="d5">Nodes are used by LLMs to represent entities in a graph</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="EDGE">
      <data key="d4">6.0</data>
      <data key="d5">Edges are used by LLMs to represent relationships between nodes</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="COVARIATE">
      <data key="d4">1.0</data>
      <data key="d5">Covariates are used by LLMs for more detailed analysis</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="DECISION">
      <data key="d4">7.0</data>
      <data key="d5">LLM is used to generate assessments and decisions</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="LLM" target="SUGGESTER-EDITOR AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Suggester-Editor Agents are powered by LLMs and can use tools like search APIs, code interpreters, or calculators</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="LLM" target="SEARCH APIS">
      <data key="d4">7.0</data>
      <data key="d5">Search APIs are tools that can be used by agents powered by LLMs</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="LLM" target="CODE INTERPRETER">
      <data key="d4">7.0</data>
      <data key="d5">Code interpreter is a tool that can be used by agents powered by LLMs</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="LLM" target="CALCULATOR">
      <data key="d4">7.0</data>
      <data key="d5">Calculator is a tool that can be used by agents powered by LLMs</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="LLM" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Content Transformation Flow uses LLMs to hypothesize other APIs present in the library</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="GRAPH COMMUNITIES">
      <data key="d4">7.0</data>
      <data key="d5">Graph communities are created by grouping element summaries</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="FORTUNATO">
      <data key="d4">6.0</data>
      <data key="d5">Fortunato has conducted surveys on community detection algorithms</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="JIN">
      <data key="d4">6.0</data>
      <data key="d5">Jin has conducted surveys on community detection algorithms</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="MULTIHOP-RAG">
      <data key="d4">7.0</data>
      <data key="d5">MultiHop-RAG is a dataset used for indexing and graph community detection</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="OPENORD">
      <data key="d4">7.0</data>
      <data key="d5">OpenORD is used for visualizing graph communities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="FORCE ATLAS 2">
      <data key="d4">7.0</data>
      <data key="d5">Force Atlas 2 is used for visualizing graph communities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="LEAF-LEVEL COMMUNITIES">
      <data key="d4">7.0</data>
      <data key="d5">Leaf-level communities are the most granular level of graph communities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="NODE">
      <data key="d4">6.0</data>
      <data key="d5">Nodes represent entities in graph communities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="EDGE">
      <data key="d4">6.0</data>
      <data key="d5">Edges represent relationships between nodes in graph communities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="COVARIATE">
      <data key="d4">1.0</data>
      <data key="d5">Covariates are additional variables associated with nodes and edges in graph communities</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="TANG">
      <data key="d4">8.0</data>
      <data key="d5">Tang contributed to the MultiHop-RAG dataset in 2024</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="OPENORD" target="MARTIN">
      <data key="d4">8.0</data>
      <data key="d5">Martin contributed to the development of the OpenORD algorithm in 2011</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="FORCE ATLAS 2" target="JACOMY">
      <data key="d4">8.0</data>
      <data key="d5">Jacomy contributed to the development of the Force Atlas 2 algorithm in 2014</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="HIGHER-LEVEL COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Leaf-level communities and higher-level communities are both part of a hierarchical community structure</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="ROOT-LEVEL COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Root-level communities and leaf-level communities are part of a hierarchical community structure</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NODE" target="TREE SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Node is a state in the tree search</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="GPT-4">
      <data key="d4">9.0</data>
      <data key="d5">GPT-4 was used as an evaluator for abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="HALLUCINATIONS">
      <data key="d4">8.0</data>
      <data key="d5">Hallucinations is a metric used to assess the accuracy of abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="QUALITY">
      <data key="d4">8.0</data>
      <data key="d5">Quality is a metric used to assess the overall quality of abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="ACI-BENCH">
      <data key="d4">7.0</data>
      <data key="d5">ACI-Bench is used for evaluating abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="INSTRUSUM">
      <data key="d4">7.0</data>
      <data key="d5">InstruSum is used for evaluating abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="ORCA-SUM">
      <data key="d4">7.0</data>
      <data key="d5">Orca-Sum is used for evaluating abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="AGENTINSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct approach was used to reduce hallucinations in abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="HIGHER-LEVEL COMMUNITIES" target="ROOT-LEVEL COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Root-level communities and higher-level communities are part of a hierarchical community structure</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are used to generate the global answer in a multi-stage process</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="COMMUNITY ANSWERS">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are used to generate community answers</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="MAP-REDUCE SUMMARIZATION">
      <data key="d4">16.0</data>
      <data key="d5">Community summaries require fewer context tokens compared to map-reduce summarization</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="ROOT-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">16.0</data>
      <data key="d5">Root-level community summaries are a type of community summaries</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d4">16.0</data>
      <data key="d5">Intermediate-level summaries are a type of community summaries</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">9.0</data>
      <data key="d5">Low-level community summaries are a type of community summaries</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="COMMUNITY ANSWERS">
      <data key="d4">9.0</data>
      <data key="d5">Community answers are used to generate the global answer</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="KEVIN SCOTT" target="SCOTT">
      <data key="d4">9.0</data>
      <data key="d5">Scott and Kevin Scott are the same person, who compiled the podcast transcripts dataset</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="MT-BENCH" target="ORCA-3">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3 is evaluated on the MT-Bench benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MT-BENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">MT-Bench is a benchmark used in the Open-Ended Generation task</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="MT-BENCH" target="GPT-4">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 is used as a judge in the MT-Bench benchmark</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="KOESTEN" target="DATA SENSEMAKING">
      <data key="d4">1.0</data>
      <data key="d5">Koesten has worked on the process of data sensemaking</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="KOESTEN" target="GREGORY">
      <data key="d4">8.0</data>
      <data key="d5">Koesten and Gregory co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours" published in the International Journal of Human-Computer Studies in 2021</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KOESTEN" target="GROTH">
      <data key="d4">8.0</data>
      <data key="d5">Koesten and Groth co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours" published in the International Journal of Human-Computer Studies in 2021</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KOESTEN" target="SIMPERL">
      <data key="d4">8.0</data>
      <data key="d5">Koesten and Simperl co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours" published in the International Journal of Human-Computer Studies in 2021</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="XU" target="SU">
      <data key="d4">8.0</data>
      <data key="d5">Su and Xu co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="XU" target="YU">
      <data key="d4">8.0</data>
      <data key="d5">Xu and Yu co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="XU" target="SIDDIQUE">
      <data key="d4">8.0</data>
      <data key="d5">Xu and Siddique co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="XU" target="BAREZI">
      <data key="d4">8.0</data>
      <data key="d5">Xu and Barezi co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="XU" target="FUNG">
      <data key="d4">8.0</data>
      <data key="d5">Xu and Fung co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="XU" target="ROLE ASSIGNMENT">
      <data key="d4">24.0</data>
      <data key="d5">Xu is an author associated with the Role Assignment state-of-the-art hand-designed agent. In 2023, Xu contributed to the development of the Role Assignment technique, which serves as a baseline in the field.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="XU" target="AGENTVERSE">
      <data key="d4">14.0</data>
      <data key="d5">Xu has shown that assigning personas or roles to agents is beneficial, which is a concept used in AgentVerse</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="DATA SENSEMAKING" target="SENSEMAKING QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Sensemaking questions are part of the data sensemaking process</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NODES" target="EDGES">
      <data key="d4">9.0</data>
      <data key="d5">Nodes and edges are elements within a community structure</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NODES" target="LATS">
      <data key="d4">8.0</data>
      <data key="d5">Nodes are used in LATS to store and retrieve external feedback</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="USER" target="TECH JOURNALIST">
      <data key="d4">7.0</data>
      <data key="d5">A tech journalist is a type of user</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="USER" target="EDUCATOR">
      <data key="d4">7.0</data>
      <data key="d5">An educator is a type of user</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="USER" target="DATASET">
      <data key="d4">8.0</data>
      <data key="d5">Users interact with datasets to perform tasks or gain information</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="USER" target="TASK">
      <data key="d4">8.0</data>
      <data key="d5">Users perform tasks that often involve interaction with datasets or systems</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="USER" target="ASSISTANT">
      <data key="d4">1.0</data>
      <data key="d5">The User interacts with the Assistant to achieve specific goals such as creating a meal plan, tracking meals, getting food recommendations, and updating food item details</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="QUINOA SALAD">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to add Quinoa Salad to the database</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="CHANA MASALA">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to update the calorie count for Chana Masala to a lower value</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="BUTTER CHICKEN">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to remove Butter Chicken from the database</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="SENSEMAKING QUESTIONS" target="RAG SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Sensemaking questions are used to evaluate the effectiveness of RAG systems</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="PRIVACY LAWS" target="INNOVATION">
      <data key="d4">7.0</data>
      <data key="d5">Privacy laws and innovation are concepts discussed in relation to each other in the podcast transcripts</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="INNOVATION" target="ETHICAL CONSIDERATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Innovation and ethical considerations are concepts discussed in relation to each other in the podcast transcripts</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="POLICIES" target="COLLABORATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Policies and collaborations are concepts discussed in relation to each other in the podcast transcripts</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="HEALTH EDUCATION" target="PREVENTIVE MEDICINE">
      <data key="d4">7.0</data>
      <data key="d5">Health education and preventive medicine are concepts discussed in relation to each other in news articles</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="HEALTH EDUCATION" target="PUBLIC HEALTH">
      <data key="d4">7.0</data>
      <data key="d5">Public health and health education are concepts discussed in relation to each other in news articles</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="HEALTH EDUCATION" target="HEALTH LITERACY">
      <data key="d4">1.0</data>
      <data key="d5">Health literacy and health education are concepts discussed in relation to each other in news articles</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="DATASET" target="ACTIVITY-CENTERED APPROACH">
      <data key="d4">8.0</data>
      <data key="d5">The activity-centered approach is used to automate the generation of questions based on a short description of a dataset</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DATASET" target="TABLE 1">
      <data key="d4">6.0</data>
      <data key="d5">Table 1 shows example questions for each of the two evaluation datasets</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DATASET" target="ACI-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">ACI-Bench is a dataset used for evaluating summarization abilities</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="DATASET" target="INSTRUSUM">
      <data key="d4">8.0</data>
      <data key="d5">InstruSum is a dataset used for evaluating summarization abilities</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="DATASET" target="ORCA-SUM">
      <data key="d4">8.0</data>
      <data key="d5">Orca-Sum is a dataset used for evaluating summarization abilities</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="DATASET" target="MIRAGE">
      <data key="d4">8.0</data>
      <data key="d5">MIRAGE is a dataset used for evaluating RAG capabilities</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="DATASET" target="MMLU-MED">
      <data key="d4">7.0</data>
      <data key="d5">MMLU-Med is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="DATASET" target="MEDQA-US">
      <data key="d4">7.0</data>
      <data key="d5">MedQA-US is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="DATASET" target="MEDMCQA">
      <data key="d4">7.0</data>
      <data key="d5">MedMCQA is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="DATASET" target="PUBMEDQA">
      <data key="d4">7.0</data>
      <data key="d5">PubMedQA is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="DATASET" target="BIOASQ">
      <data key="d4">7.0</data>
      <data key="d5">BioASQ is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="TASK" target="QUESTION">
      <data key="d4">7.0</data>
      <data key="d5">Tasks often involve generating questions to evaluate understanding of a dataset</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TASK" target="PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">Prompts are used to instruct language models to generate responses</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="QUESTION" target="N">
      <data key="d4">7.0</data>
      <data key="d5">N represents the number of questions generated per (user, task) combination</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="QUESTION" target="ANSWER">
      <data key="d4">8.0</data>
      <data key="d5">Questions are inquiries made to gain information, and answers are responses generated to address those questions</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="QUESTION" target="TRAJECTORIES">
      <data key="d4">8.0</data>
      <data key="d5">Trajectories are analyzed to determine the correctness of the solution to a question</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="QUESTION" target="PASSAGE">
      <data key="d4">9.0</data>
      <data key="d5">A passage is used as input for generating questions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="QUESTION" target="ANSWER CHOICES">
      <data key="d4">9.0</data>
      <data key="d5">Questions have answer choices that can be modified to add complexity</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="QUESTION" target="STUDENT RESPONSE">
      <data key="d4">16.0</data>
      <data key="d5">The Question and Student Response are used together to extract the selected option. The student response is given in reply to the question.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50,5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="QUESTION" target="ANSWER OPTIONS">
      <data key="d4">1.0</data>
      <data key="d5">The Answer Options are provided along with the Question to the student</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT SUMMARIZATION (TS)" target="SEMANTIC SEARCH (SS)">
      <data key="d4">6.0</data>
      <data key="d5">Both Text Summarization (TS) and Semantic Search (SS) are methods used to answer user queries</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TEXT SUMMARIZATION (TS)" target="CONDITION">
      <data key="d4">7.0</data>
      <data key="d5">Text Summarization (TS) is one of the conditions compared in the analysis</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TEXT SUMMARIZATION (TS)" target="SUBSECTION 2.6">
      <data key="d4">7.0</data>
      <data key="d5">Subsection 2.6 describes the method used for text summarization</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="SEMANTIC SEARCH (SS)" target="CONDITION">
      <data key="d4">7.0</data>
      <data key="d5">Semantic Search (SS) is one of the conditions compared in the analysis</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="CONTEXT INFORMATION">
      <data key="d4">7.0</data>
      <data key="d5">Context information is used in the context window for answer generation</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="CONTEXT WINDOW SIZE">
      <data key="d4">7.0</data>
      <data key="d5">Context window size is the number of tokens used in the context window</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PODCAST DATASET" target="NEWS DATASET">
      <data key="d4">17.0</data>
      <data key="d5">The Podcast dataset and the News dataset are both utilized for analysis and evaluation in the study. These datasets play a crucial role in the research, providing the necessary data to support the study's objectives and findings.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIRECTNESS" target="METRIC">
      <data key="d4">7.0</data>
      <data key="d5">Directness is one of the metrics used to evaluate the quality of generated answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DIRECTNESS" target="DECISION">
      <data key="d4">1.0</data>
      <data key="d5">Decisions involve assessing directness</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="LLM EVALUATOR" target="RAGAS">
      <data key="d4">7.0</data>
      <data key="d5">Both LLM Evaluator and RAGAS are systems used to assess the quality of generated answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="LLM EVALUATOR" target="HEAD-TO-HEAD COMPARISON">
      <data key="d4">7.0</data>
      <data key="d5">Head-to-head comparison is an approach where an LLM evaluator assesses pairs of answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="LLM EVALUATOR" target="TABLE 2">
      <data key="d4">6.0</data>
      <data key="d5">Table 2 shows an example of LLM-generated assessment</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="ZHENG" target="STEP-BACK ABSTRACTION">
      <data key="d4">30.0</data>
      <data key="d5">Zheng is an author associated with the Step-back Abstraction state-of-the-art hand-designed agent. In 2023, Zheng contributed to the development and documentation of the Step-back Abstraction technique, which serves as a baseline in the field. This technique represents a significant advancement in the design and implementation of AI agents, showcasing Zheng's expertise and influence in the AI and ML communities.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="PUBLIC FIGURE" target="ENTERTAINMENT INDUSTRY">
      <data key="d4">1.0</data>
      <data key="d5">Public figures are individuals who are well-known in the entertainment industry due to their significant contributions and influence</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="PROMINENT PUBLIC FIGURES">
      <data key="d4">8.0</data>
      <data key="d5">Prominent public figures are key individuals in the entertainment industry</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="N" target="LATS">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses N as a parameter to represent the visit counter for states</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="TABLE 1" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">Table 1 provides a full list of the 17 different skills implemented in the workflows defined by AgentInstruct</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONDITION" target="C0">
      <data key="d4">7.0</data>
      <data key="d5">C0 is a condition that uses root-level community summaries to answer user queries</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONDITION" target="C1">
      <data key="d4">7.0</data>
      <data key="d5">C1 is a condition that uses high-level community summaries to answer user queries</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONDITION" target="C2">
      <data key="d4">7.0</data>
      <data key="d5">C2 is a condition that uses intermediate-level community summaries to answer user queries</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONDITION" target="C3">
      <data key="d4">7.0</data>
      <data key="d5">C3 is a condition that uses low-level community summaries to answer user queries</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONDITION" target="GRAPH INDEX">
      <data key="d4">7.0</data>
      <data key="d5">The graph index supports conditions C0-C3</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="C0" target="C1">
      <data key="d4">6.0</data>
      <data key="d5">C0 and C1 are both conditions used in the study</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C0" target="C2">
      <data key="d4">6.0</data>
      <data key="d5">C0 and C2 are both conditions used in the study</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C0" target="C3">
      <data key="d4">6.0</data>
      <data key="d5">C0 and C3 are both conditions used in the study</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C1" target="C2">
      <data key="d4">6.0</data>
      <data key="d5">C1 and C2 are both conditions used in the study</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C1" target="C3">
      <data key="d4">6.0</data>
      <data key="d5">C1 and C3 are both conditions used in the study</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C2" target="C3">
      <data key="d4">1.0</data>
      <data key="d5">C2 and C3 are both conditions used in the study</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH INDEX" target="GLEANING">
      <data key="d4">7.0</data>
      <data key="d5">Gleaning is a process used in the graph indexing method</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="ANSWER" target="COT_MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The Chain-of-Thought module generates the answer</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ANSWER" target="FINAL_CODE">
      <data key="d4">8.0</data>
      <data key="d5">Answer is derived from Final_code</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="ANSWER" target="INTEGRATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">Answer is generated by the Integration Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="PROMINENT PUBLIC FIGURES" target="ACTORS AND DIRECTORS">
      <data key="d4">8.0</data>
      <data key="d5">Actors and directors are types of prominent public figures</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PROMINENT PUBLIC FIGURES" target="MUSICIANS AND EXECUTIVES">
      <data key="d4">8.0</data>
      <data key="d5">Musicians and executives are types of prominent public figures</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PROMINENT PUBLIC FIGURES" target="ATHLETES AND COACHES">
      <data key="d4">8.0</data>
      <data key="d5">Athletes and coaches are types of prominent public figures</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PROMINENT PUBLIC FIGURES" target="INFLUENCERS AND ENTREPRENEURS">
      <data key="d4">1.0</data>
      <data key="d5">Influencers and entrepreneurs are types of prominent public figures</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="MEDIA COVERAGE">
      <data key="d4">9.0</data>
      <data key="d5">Public figures are often the subject of media coverage</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="PUBLIC INTEREST">
      <data key="d4">9.0</data>
      <data key="d5">Public figures attract public interest</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="CULTURAL NARRATIVES">
      <data key="d4">8.0</data>
      <data key="d5">Public figures help shape cultural narratives</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="SOCIAL DISCUSSIONS">
      <data key="d4">8.0</data>
      <data key="d5">Public figures often become central figures in social discussions</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="PUBLIC DISCOURSE">
      <data key="d4">8.0</data>
      <data key="d5">Public figures influence public discourse</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="DIGITAL MEDIA">
      <data key="d4">7.0</data>
      <data key="d5">Public figures use digital media to reach their audience</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ENTERTAINMENT">
      <data key="d4">9.0</data>
      <data key="d5">Public figures play significant roles in various aspects of entertainment</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ECONOMIC IMPACTS">
      <data key="d4">8.0</data>
      <data key="d5">Public figures have significant economic impacts</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="NA&#207;VE RAG">
      <data key="d4">7.0</data>
      <data key="d5">Na&#239;ve RAG generates lists of public figures</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="TAYLOR SWIFT" target="PROFESSIONAL ACHIEVEMENTS">
      <data key="d4">9.0</data>
      <data key="d5">Taylor Swift is known for her professional achievements in music</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="TAYLOR SWIFT" target="PERSONAL LIVES">
      <data key="d4">9.0</data>
      <data key="d5">Taylor Swift's personal life is frequently covered in media</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="TRAVIS KELCE" target="ENTERTAINMENT ARTICLES">
      <data key="d4">9.0</data>
      <data key="d5">Travis Kelce is frequently mentioned in entertainment articles</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="TRAVIS KELCE" target="PROFESSIONAL ACHIEVEMENTS">
      <data key="d4">9.0</data>
      <data key="d5">Travis Kelce is known for his professional achievements in sports</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="TRAVIS KELCE" target="PERSONAL LIVES">
      <data key="d4">9.0</data>
      <data key="d5">Travis Kelce's personal life is frequently covered in media</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="ENTERTAINMENT ARTICLES">
      <data key="d4">9.0</data>
      <data key="d5">Britney Spears is frequently mentioned in entertainment articles</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="PROFESSIONAL ACHIEVEMENTS">
      <data key="d4">9.0</data>
      <data key="d5">Britney Spears is known for her professional achievements in music</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="PERSONAL LIVES">
      <data key="d4">9.0</data>
      <data key="d5">Britney Spears's personal life is frequently covered in media</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="ENTERTAINMENT ARTICLES">
      <data key="d4">9.0</data>
      <data key="d5">Justin Timberlake is frequently mentioned in entertainment articles</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="PROFESSIONAL ACHIEVEMENTS">
      <data key="d4">9.0</data>
      <data key="d5">Justin Timberlake is known for his professional achievements in music</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="PERSONAL LIVES">
      <data key="d4">9.0</data>
      <data key="d5">Justin Timberlake's personal life is frequently covered in media</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="MEDIA COVERAGE">
      <data key="d4">8.0</data>
      <data key="d5">Entertainment articles are a form of media coverage</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="ENTERTAINMENT ARTICLES" target="MEDIA">
      <data key="d4">8.0</data>
      <data key="d5">Media includes entertainment articles</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="MEDIA COVERAGE" target="PUBLIC INTEREST">
      <data key="d4">8.0</data>
      <data key="d5">Media coverage influences public interest</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="MEDIA COVERAGE" target="DIGITAL MEDIA">
      <data key="d4">7.0</data>
      <data key="d5">Digital media is a platform for media coverage</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="CULTURAL NARRATIVES" target="ENTERTAINMENT">
      <data key="d4">8.0</data>
      <data key="d5">Entertainment helps shape cultural narratives</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="SOCIAL DISCUSSIONS" target="PUBLIC DISCOURSE">
      <data key="d4">1.0</data>
      <data key="d5">Social discussions contribute to public discourse</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="ENTERTAINMENT" target="TREND">
      <data key="d4">8.0</data>
      <data key="d5">Entertainment drives trends in society</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="ENTERTAINMENT" target="CULTURAL LANDSCAPE">
      <data key="d4">8.0</data>
      <data key="d5">Entertainment influences the broader cultural landscape</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="MEDIA" target="DATA SOURCES">
      <data key="d4">8.0</data>
      <data key="d5">Data sources provide information for media coverage</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="SS" target="TS">
      <data key="d4">6.0</data>
      <data key="d5">SS and TS are both baseline conditions used in the study</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LANGCHAIN" target="LLAMAINDEX">
      <data key="d4">14.0</data>
      <data key="d5">Both LangChain and LlamaIndex support a variety of graph databases</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="LANGCHAIN" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">LangChain is an open-source agent framework that can be used within the search space of ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LANGCHAIN" target="LANGCHAINAI">
      <data key="d4">17.0</data>
      <data key="d5">LangChain is an open-source agent framework developed by LangChainAI.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NEO4J" target="NALLM">
      <data key="d4">24.0</data>
      <data key="d5">NaLLM utilizes the Neo4J format for constructing knowledge graphs, while Neo4J supports the NaLLM system in both creating and reasoning over these knowledge graphs. This symbiotic relationship highlights the integration of Neo4J's robust graph database capabilities with NaLLM's advanced knowledge graph functionalities.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="NEO4J" target="GRAPH-BASED RAG APPLICATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Neo4J is a format used in graph-based RAG applications</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="NEBULA-GRAPH" target="GRAPHRAG">
      <data key="d4">16.0</data>
      <data key="d5">Nebula-Graph supports the GraphRAG system for creating and reasoning over knowledge graphs</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPHRAG" target="NEBULAGRAPH">
      <data key="d4">8.0</data>
      <data key="d5">GraphRAG uses the NebulaGraph format for knowledge graphs</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RAM" target="GAO">
      <data key="d4">14.0</data>
      <data key="d5">Ram and Gao have both worked on RAG approaches and systems</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GAO" target="GSM-HARD">
      <data key="d4">26.0</data>
      <data key="d5">Gao is an author associated with the GSM-Hard dataset, 2023. Gao is one of the authors who discussed the GSM-Hard math task in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="CHENG" target="MAO">
      <data key="d4">14.0</data>
      <data key="d5">Cheng and Mao have both worked on generation-augmented retrieval</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="SU" target="FENG">
      <data key="d4">14.0</data>
      <data key="d5">Su and Feng have both worked on multi-document summarization and multi-hop question answering</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="SU" target="YU">
      <data key="d4">8.0</data>
      <data key="d5">Su and Yu co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="SU" target="SIDDIQUE">
      <data key="d4">8.0</data>
      <data key="d5">Su and Siddique co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="SU" target="BAREZI">
      <data key="d4">8.0</data>
      <data key="d5">Su and Barezi co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="SU" target="FUNG">
      <data key="d4">8.0</data>
      <data key="d5">Su and Fung co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="TRIVEDI" target="KHATTAB">
      <data key="d4">14.0</data>
      <data key="d5">Trivedi and Khattab have both worked on multi-hop question answering</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KHATTAB" target="DSPY">
      <data key="d4">16.0</data>
      <data key="d5">Khattab has worked on DSPy, a system that generates a set of possible nodes and then optimizes across the Cartesian product of these nodes</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SARTHI" target="KIM">
      <data key="d4">14.0</data>
      <data key="d5">Sarthi and Kim have both worked on hierarchical approaches for text summarization and question answering</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="BAEK" target="HE">
      <data key="d4">14.0</data>
      <data key="d5">Baek and He have both worked on advanced RAG systems</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="ZHANG" target="KANG">
      <data key="d4">14.0</data>
      <data key="d5">Zhang and Kang have both worked on graph-based RAG systems</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="ZHANG" target="BAN">
      <data key="d4">2.0</data>
      <data key="d5">Ban and Zhang have both worked on the extraction of causal graphs from source texts</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="ZHANG" target="MEMORY STRUCTURES">
      <data key="d4">16.0</data>
      <data key="d5">Zhang contributed to the development of memory structures</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="ZHANG" target="OPEN-ENDEDNESS ALGORITHMS">
      <data key="d4">2.0</data>
      <data key="d5">Zhang is one of the authors who discussed open-endedness algorithms in 2024a</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="ZHANG" target="EXTERNAL MEMORY AND RAG">
      <data key="d4">8.0</data>
      <data key="d5">Zhang is an author associated with external memory and RAG, 2024c</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="ZHANG" target="AGENTOPTIMIZER">
      <data key="d4">16.0</data>
      <data key="d5">Zhang has worked on AgentOptimizer, a system that learns the tools used in agents</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ZHANG" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">6.0</data>
      <data key="d5">Zhang is mentioned in relation to novelty search algorithms</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NEBULAGRAPH" target="GRAPH-BASED RAG APPLICATIONS">
      <data key="d4">7.0</data>
      <data key="d5">NebulaGraph is a format used in graph-based RAG applications</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="TABLE 3" target="ORCA-3">
      <data key="d4">8.0</data>
      <data key="d5">Table 3 shows the performance of Orca-3 on various benchmarks</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="TABLE 3" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">Table 3 shows the performance of Mistral-7b-Instruct on various benchmarks</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GRAPH-BASED RAG APPLICATIONS" target="FAST UNFOLDING OF COMMUNITIES IN LARGE NETWORKS">
      <data key="d4">1.0</data>
      <data key="d5">Fast unfolding of communities in large networks is a method that could be used in graph-based RAG applications</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="AMBER HOAK">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Amber Hoak both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Andr&#233;s Morales Esquivel both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="BEN CUTLER">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Ben Cutler both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="BILLIE RINALDI">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Billie Rinaldi both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="CHRIS SANCHEZ">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Chris Sanchez both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="CHRIS TREVINO">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Chris Trevino both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="CHRISTINE CAGGIANO">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Christine Caggiano both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="DAVID TITTSWORTH">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and David Tittsworth both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="DAYENNE DE SOUZA">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Dayenne de Souza both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="DOUGLAS ORBAKER">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Douglas Orbaker both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="ED CLARK">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Ed Clark both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="GABRIEL NIEVES-PONCE">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Gabriel Nieves-Ponce both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="GAUDY BLANCO MENESES">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Gaudy Blanco Meneses both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="KATE LYTVYNETS">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Kate Lytvynets both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="KATY SMITH">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Katy Smith both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="M&#211;NICA CARVAJAL">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and M&#243;nica Carvajal both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="NATHAN EVANS">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Nathan Evans both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="RICHARD ORTEGA">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Richard Ortega both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="RODRIGO RACANICCI">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Rodrigo Racanicci both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="SARAH SMITH">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Sarah Smith both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ALONSO GUEVARA FERN&#193;NDEZ" target="SHANE SOLOMON">
      <data key="d4">7.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez and Shane Solomon both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Andr&#233;s Morales Esquivel both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="BEN CUTLER">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Ben Cutler both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="BILLIE RINALDI">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Billie Rinaldi both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="CHRIS SANCHEZ">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Chris Sanchez both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="CHRIS TREVINO">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Chris Trevino both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="CHRISTINE CAGGIANO">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Christine Caggiano both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="DAVID TITTSWORTH">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and David Tittsworth both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="DAYENNE DE SOUZA">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Dayenne de Souza both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="DOUGLAS ORBAKER">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Douglas Orbaker both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="ED CLARK">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Ed Clark both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="GABRIEL NIEVES-PONCE">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Gabriel Nieves-Ponce both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="GAUDY BLANCO MENESES">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Gaudy Blanco Meneses both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="KATE LYTVYNETS">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Kate Lytvynets both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="KATY SMITH">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Katy Smith both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="M&#211;NICA CARVAJAL">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and M&#243;nica Carvajal both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="NATHAN EVANS">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Nathan Evans both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="RICHARD ORTEGA">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Richard Ortega both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="RODRIGO RACANICCI">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Rodrigo Racanicci both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="SARAH SMITH">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Sarah Smith both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="AMBER HOAK" target="SHANE SOLOMON">
      <data key="d4">7.0</data>
      <data key="d5">Amber Hoak and Shane Solomon both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="BEN CUTLER">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and Ben Cutler both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="BILLIE RINALDI">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and Billie Rinaldi both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="CHRIS SANCHEZ">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and Chris Sanchez both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="CHRIS TREVINO">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and Chris Trevino both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="CHRISTINE CAGGIANO">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and Christine Caggiano both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="DAVID TITTSWORTH">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and David Tittsworth both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="DAYENNE DE SOUZA">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and Dayenne de Souza both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="DOUGLAS ORBAKER">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and Douglas Orbaker both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="ED CLARK">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and Ed Clark both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="GABRIEL NIEVES-PONCE">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and Gabriel Nieves-Ponce both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="GAUDY BLANCO MENESES">
      <data key="d4">7.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and Gaudy Blanco Meneses both contributed to the work mentioned in the text</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ANDR&#201;S MORALES ESQUIVEL" target="KATE LYTVYNETS">
      <data key="d4">1.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel and("entity"</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="SAMUEL ADLER" target="JOSH ACHIAM">
      <data key="d4">7.0</data>
      <data key="d5">Josh Achiam and Samuel Adler co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="SHIVANI AGARWAL" target="JOSH ACHIAM">
      <data key="d4">7.0</data>
      <data key="d5">Josh Achiam and Shivani Agarwal co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="LAILA AHMAD" target="JOSH ACHIAM">
      <data key="d4">7.0</data>
      <data key="d5">Josh Achiam and Laila Ahmad co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="ILYA AKKAYA" target="JOSH ACHIAM">
      <data key="d4">7.0</data>
      <data key="d5">Josh Achiam and Ilya Akkaya co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="FERNANDO L. ALEMAN" target="JOSH ACHIAM">
      <data key="d4">7.0</data>
      <data key="d5">Josh Achiam and Fernando L. Aleman co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="DANIEL ALMEIDA" target="JOSH ACHIAM">
      <data key="d4">7.0</data>
      <data key="d5">Josh Achiam and Daniel Almeida co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="JULIA ALTENSCHMIDT" target="JOSH ACHIAM">
      <data key="d4">7.0</data>
      <data key="d5">Josh Achiam and Julia Altenschmidt co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="SAM ALTMAN" target="JOSH ACHIAM">
      <data key="d4">7.0</data>
      <data key="d5">Josh Achiam and Sam Altman co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="SAMEER ANADKAT" target="JOSH ACHIAM">
      <data key="d4">7.0</data>
      <data key="d5">Josh Achiam and Sameer Anadkat co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RISHI ANIL" target="SEBASTIAN BORGEAUD">
      <data key="d4">7.0</data>
      <data key="d5">Rishi Anil and Sebastian Borgeaud co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RISHI ANIL" target="YONGJUN WU">
      <data key="d4">7.0</data>
      <data key="d5">Rishi Anil and Yongjun Wu co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RISHI ANIL" target="JEAN-BAPTISTE ALAYRAC">
      <data key="d4">7.0</data>
      <data key="d5">Rishi Anil and Jean-Baptiste Alayrac co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RISHI ANIL" target="JUNYU YU">
      <data key="d4">7.0</data>
      <data key="d5">Rishi Anil and Junyu Yu co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RISHI ANIL" target="RADU SORICUT">
      <data key="d4">7.0</data>
      <data key="d5">Rishi Anil and Radu Soricut co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RISHI ANIL" target="JOHAN SCHALKWYK">
      <data key="d4">7.0</data>
      <data key="d5">Rishi Anil and Johan Schalkwyk co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RISHI ANIL" target="ANDREW M. DAI">
      <data key="d4">7.0</data>
      <data key="d5">Rishi Anil and Andrew M. Dai co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RISHI ANIL" target="ANDREAS HAUTH">
      <data key="d4">7.0</data>
      <data key="d5">Rishi Anil and Andreas Hauth co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="JUNSU BAEK" target="ALFIAN F. AJI">
      <data key="d4">7.0</data>
      <data key="d5">Junsu Baek and Alfian F. Aji co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="JUNSU BAEK" target="ALI SAFFARI">
      <data key="d4">7.0</data>
      <data key="d5">Junsu Baek and Ali Saffari co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="TAKASHI BAN" target="LI CHEN">
      <data key="d4">7.0</data>
      <data key="d5">Takashi Ban and Li Chen co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="TAKASHI BAN" target="XIAOWEI WANG">
      <data key="d4">7.0</data>
      <data key="d5">Takashi Ban and Xiaowei Wang co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="TAKASHI BAN" target="HONG CHEN">
      <data key="d4">7.0</data>
      <data key="d5">Takashi Ban and Hong Chen co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="TAL BAUMEL" target="MICHAL EYAL">
      <data key="d4">7.0</data>
      <data key="d5">Tal Baumel and Michal Eyal co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="TAL BAUMEL" target="MICHAEL ELHADAD">
      <data key="d4">7.0</data>
      <data key="d5">Tal Baumel and Michael Elhadad co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="VINCENT D. BLONDEL" target="JEAN-LOUP GUILLAUME">
      <data key="d4">7.0</data>
      <data key="d5">Vincent D. Blondel and Jean-Loup Guillaume co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="VINCENT D. BLONDEL" target="R&#201;MY LAMBIOTTE">
      <data key="d4">7.0</data>
      <data key="d5">Vincent D. Blondel and R&#233;my Lambiotte co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="VINCENT D. BLONDEL" target="ETIENNE LEFEBVRE">
      <data key="d4">7.0</data>
      <data key="d5">Vincent D. Blondel and Etienne Lefebvre co-authored a referenced paper</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING" target="QUERY FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d4">6.0</data>
      <data key="d5">Both Knowledge-augmented language model prompting and Query focused abstractive summarization are techniques related to language models</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="BLONDEL, V. D." target="GUILLAUME, J.-L.">
      <data key="d4">8.0</data>
      <data key="d5">Blondel, V. D. and Guillaume, J.-L. co-authored the paper "Fast unfolding of communities in large networks" published in the Journal of Statistical Mechanics: Theory and Experiment in 2008</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BLONDEL, V. D." target="LAMIOTTE, R.">
      <data key="d4">8.0</data>
      <data key="d5">Blondel, V. D. and Lambiotte, R. co-authored the paper "Fast unfolding of communities in large networks" published in the Journal of Statistical Mechanics: Theory and Experiment in 2008</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BLONDEL, V. D." target="LEFEBVRE, E.">
      <data key="d4">8.0</data>
      <data key="d5">Blondel, V. D. and Lefebvre, E. co-authored the paper "Fast unfolding of communities in large networks" published in the Journal of Statistical Mechanics: Theory and Experiment in 2008</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GUILLAUME, J.-L." target="LAMIOTTE, R.">
      <data key="d4">8.0</data>
      <data key="d5">Guillaume, J.-L. and Lambiotte, R. co-authored the paper "Fast unfolding of communities in large networks" published in the Journal of Statistical Mechanics: Theory and Experiment in 2008</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GUILLAUME, J.-L." target="LEFEBVRE, E.">
      <data key="d4">8.0</data>
      <data key="d5">Guillaume, J.-L. and Lefebvre, E. co-authored the paper "Fast unfolding of communities in large networks" published in the Journal of Statistical Mechanics: Theory and Experiment in 2008</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LAMIOTTE, R." target="LEFEBVRE, E.">
      <data key="d4">8.0</data>
      <data key="d5">Lambiotte, R. and Lefebvre, E. co-authored the paper "Fast unfolding of communities in large networks" published in the Journal of Statistical Mechanics: Theory and Experiment in 2008</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="MANN, B.">
      <data key="d4">8.0</data>
      <data key="d5">Brown, T. and Mann, B. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="RYDER, N.">
      <data key="d4">8.0</data>
      <data key="d5">Brown, T. and Ryder, N. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="SUBBIAH, M.">
      <data key="d4">8.0</data>
      <data key="d5">Brown, T. and Subbiah, M. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="KAPLAN, J. D.">
      <data key="d4">8.0</data>
      <data key="d5">Brown, T. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="DHARIWAL, P.">
      <data key="d4">8.0</data>
      <data key="d5">Brown, T. and Dhariwal, P. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="NEELAKANTAN, A.">
      <data key="d4">8.0</data>
      <data key="d5">Brown, T. and Neelakantan, A. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="SHYAM, P.">
      <data key="d4">8.0</data>
      <data key="d5">Brown, T. and Shyam, P. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="SASTRY, G.">
      <data key="d4">8.0</data>
      <data key="d5">Brown, T. and Sastry, G. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="ASKELL, A.">
      <data key="d4">8.0</data>
      <data key="d5">Brown, T. and Askell, A. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="MANN, B." target="RYDER, N.">
      <data key="d4">8.0</data>
      <data key="d5">Mann, B. and Ryder, N. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="MANN, B." target="SUBBIAH, M.">
      <data key="d4">8.0</data>
      <data key="d5">Mann, B. and Subbiah, M. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="MANN, B." target="KAPLAN, J. D.">
      <data key="d4">8.0</data>
      <data key="d5">Mann, B. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="MANN, B." target="DHARIWAL, P.">
      <data key="d4">8.0</data>
      <data key="d5">Mann, B. and Dhariwal, P. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="MANN, B." target="NEELAKANTAN, A.">
      <data key="d4">8.0</data>
      <data key="d5">Mann, B. and Neelakantan, A. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="MANN, B." target="SHYAM, P.">
      <data key="d4">8.0</data>
      <data key="d5">Mann, B. and Shyam, P. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="MANN, B." target="SASTRY, G.">
      <data key="d4">8.0</data>
      <data key="d5">Mann, B. and Sastry, G. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="MANN, B." target="ASKELL, A.">
      <data key="d4">8.0</data>
      <data key="d5">Mann, B. and Askell, A. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RYDER, N." target="SUBBIAH, M.">
      <data key="d4">8.0</data>
      <data key="d5">Ryder, N. and Subbiah, M. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RYDER, N." target="KAPLAN, J. D.">
      <data key="d4">8.0</data>
      <data key="d5">Ryder, N. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RYDER, N." target="DHARIWAL, P.">
      <data key="d4">8.0</data>
      <data key="d5">Ryder, N. and Dhariwal, P. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RYDER, N." target="NEELAKANTAN, A.">
      <data key="d4">8.0</data>
      <data key="d5">Ryder, N. and Neelakantan, A. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RYDER, N." target="SHYAM, P.">
      <data key="d4">8.0</data>
      <data key="d5">Ryder, N. and Shyam, P. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RYDER, N." target="SASTRY, G.">
      <data key="d4">8.0</data>
      <data key="d5">Ryder, N. and Sastry, G. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RYDER, N." target="ASKELL, A.">
      <data key="d4">8.0</data>
      <data key="d5">Ryder, N. and Askell, A. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SUBBIAH, M." target="KAPLAN, J. D.">
      <data key="d4">8.0</data>
      <data key="d5">Subbiah, M. and Kaplan, J. D. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SUBBIAH, M." target="DHARIWAL, P.">
      <data key="d4">8.0</data>
      <data key="d5">Subbiah, M. and Dhariwal, P. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SUBBIAH, M." target="NEELAKANTAN, A.">
      <data key="d4">8.0</data>
      <data key="d5">Subbiah, M. and Neelakantan, A. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SUBBIAH, M." target="SHYAM, P.">
      <data key="d4">8.0</data>
      <data key="d5">Subbiah, M. and Shyam, P. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SUBBIAH, M." target="SASTRY, G.">
      <data key="d4">8.0</data>
      <data key="d5">Subbiah, M. and Sastry, G. co-authored the paper "Language models are few-shot learners" published in Advances in Neural Information Processing Systems in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GREGORY" target="GROTH">
      <data key="d4">8.0</data>
      <data key="d5">Gregory and Groth co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours" published in the International Journal of Human-Computer Studies in 2021</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="GREGORY" target="SIMPERL">
      <data key="d4">8.0</data>
      <data key="d5">Gregory and Simperl co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours" published in the International Journal of Human-Computer Studies in 2021</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="GROTH" target="SIMPERL">
      <data key="d4">8.0</data>
      <data key="d5">Groth and Simperl co-authored the paper "Talking datasets&#8211;understanding data sensemaking behaviours" published in the International Journal of Human-Computer Studies in 2021</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="HOQUE" target="HUANG">
      <data key="d4">8.0</data>
      <data key="d5">Hoque and Huang co-authored the paper "Domain adaptation with pre-trained transformers for query-focused abstractive text summarization" published in Computational Linguistics in 2022</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="HUANG" target="AHN">
      <data key="d4">14.0</data>
      <data key="d5">Ahn and Huang have both worked on adapting language models as high-level controllers in robotics</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HUANG" target="DRIESS">
      <data key="d4">14.0</data>
      <data key="d5">Huang and Driess have both worked on adapting language models as high-level controllers in robotics</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HUANG" target="EXTERNAL TOOLS">
      <data key="d4">14.0</data>
      <data key="d5">Huang suggested that language models cannot self-correct their internal reasoning, making it critical to use external feedback, such as external tools</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="HUANG" target="LATS">
      <data key="d4">14.0</data>
      <data key="d5">Huang contributed to the research on improving value assignment in language models, which is a component of LATS</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="HUANG" target="MULTI-OBJECTIVE ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Huang is mentioned in relation to the concept of Multi-objective ADAS</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="SHEN" target="NEURAL ARCHITECTURE SEARCH">
      <data key="d4">18.0</data>
      <data key="d5">Shen is one of the authors who discussed Neural Architecture Search (NAS) in 2023</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="CHEN" target="GUO">
      <data key="d4">14.0</data>
      <data key="d5">Guo and Chen have both worked on addressing error propagation in chain-of-thought (CoT) prompting for language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHEN" target="YA0">
      <data key="d4">7.0</data>
      <data key="d5">Yao and Chen have both worked on the WebShop dataset and ReAct prompting technique</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHEN" target="LATS">
      <data key="d4">14.0</data>
      <data key="d5">Chen contributed to the research on programming domains, which is one of the domains evaluated by LATS</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="CHEN" target="AUSTIN">
      <data key="d4">6.0</data>
      <data key="d5">Chen and Austin have worked on programming-related tasks evaluated in the experiments</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="CHEN" target="PROGRAMMING">
      <data key="d4">7.0</data>
      <data key="d5">Chen has worked on synthetic test suite generation for programming tasks</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="CHEN" target="HUMANEVAL DATASET">
      <data key="d4">7.0</data>
      <data key="d5">Chen has worked on the HumanEval dataset</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="CHEN" target="HUMANEVAL">
      <data key="d4">6.0</data>
      <data key="d5">Chen has worked on the HumanEval dataset for programming tasks</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHEN" target="PROMPTING TECHNIQUES">
      <data key="d4">8.0</data>
      <data key="d5">Chen is an author associated with prompting techniques, 2023a</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="CHEN" target="AGENTVERSE">
      <data key="d4">16.0</data>
      <data key="d5">Chen has worked on AgentVerse, a system that optimizes role definition in the prompt</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="CHEN" target="YUSHENG SU">
      <data key="d4">8.0</data>
      <data key="d5">Chen and Yusheng Su co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="CHEN" target="JINGWEI ZUO">
      <data key="d4">8.0</data>
      <data key="d5">Chen and Jingwei Zuo co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="CHEN" target="CHENG YANG">
      <data key="d4">8.0</data>
      <data key="d5">Chen and Cheng Yang co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="CHEN" target="CHENFEI YUAN">
      <data key="d4">8.0</data>
      <data key="d5">Chen and Chenfei Yuan co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="CHEN" target="CHI-MIN CHAN">
      <data key="d4">8.0</data>
      <data key="d5">Chen and Chi-Min Chan co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="CHEN" target="HEYANG YU">
      <data key="d4">8.0</data>
      <data key="d5">Chen and Heyang Yu co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="CHEN" target="YAXI LU">
      <data key="d4">8.0</data>
      <data key="d5">Chen and Yaxi Lu co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="CHEN" target="YI-HSIN HUNG">
      <data key="d4">8.0</data>
      <data key="d5">Chen and Yi-Hsin Hung co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="CHEN" target="CHEN QIAN">
      <data key="d4">8.0</data>
      <data key="d5">Chen and Chen Qian co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YU" target="SIDDIQUE">
      <data key="d4">8.0</data>
      <data key="d5">Yu and Siddique co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="YU" target="BAREZI">
      <data key="d4">8.0</data>
      <data key="d5">Yu and Barezi co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="YU" target="FUNG">
      <data key="d4">8.0</data>
      <data key="d5">Yu and Fung co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="YU" target="LANGUAGE-TO-REWARD">
      <data key="d4">16.0</data>
      <data key="d5">Yu has worked on language-to-reward, a system that enables FMs to write reward functions for reinforcement learning in robotics</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SIDDIQUE" target="BAREZI">
      <data key="d4">8.0</data>
      <data key="d5">Siddique and Barezi co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="SIDDIQUE" target="FUNG">
      <data key="d4">8.0</data>
      <data key="d5">Siddique and Fung co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="BAREZI" target="FUNG">
      <data key="d4">1.0</data>
      <data key="d5">Barezi and Fung co-authored the paper "Caire-covid: A question answering and query-focused multi-document summarization" published in 2020</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="SHI" target="MGSM">
      <data key="d4">39.0</data>
      <data key="d5">Shi is an author associated with the MGSM benchmark, which is designed for evaluating mathematical capabilities under a multi-lingual setting. In 2023, Shi contributed to discussions on the MGSM math task, highlighting their involvement in the Math domain.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="QU" target="TOOL USE">
      <data key="d4">24.0</data>
      <data key="d5">Qu has significantly contributed to the development of tool use in agentic systems. As an author associated with tool use in 2024, Qu's work has been instrumental in advancing the understanding and application of tools within AI and ML communities.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="ZHOU" target="SELF-DISCOVER">
      <data key="d4">16.0</data>
      <data key="d5">Zhou has worked on Self-Discover, a system that adopts FMs to automate prompt engineering for agents</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ZHOU" target="AGENT SYMBOLIC LEARNING">
      <data key="d4">16.0</data>
      <data key="d5">Zhou has worked on Agent Symbolic Learning, a system that learns prompts, tools, and control flow together in agents</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ZHOU" target="MORE INTELLIGENT EVALUATION FUNCTIONS">
      <data key="d4">6.0</data>
      <data key="d5">Zhou is mentioned in relation to more intelligent evaluation functions</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="BENGIO" target="ADAS">
      <data key="d4">14.0</data>
      <data key="d5">Bengio has discussed whether we should pursue AGI and AI-GA, which includes ADAS</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="CHIANG" target="MORE INTELLIGENT EVALUATION FUNCTIONS">
      <data key="d4">6.0</data>
      <data key="d5">Chiang is mentioned in relation to more intelligent evaluation functions</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ZHUANG" target="A*">
      <data key="d4">14.0</data>
      <data key="d5">Zhuang is associated with the A* search algorithm and is one of the authors who contributed to the work on A*.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="ZHUANG" target="DFS">
      <data key="d4">1.0</data>
      <data key="d5">Zhuang is associated with the DFS search algorithm</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="WU" target="REINFORCEMENT LEARNING">
      <data key="d4">18.0</data>
      <data key="d5">Wu has worked on reinforcement learning algorithms</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="WU" target="ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES">
      <data key="d4">8.0</data>
      <data key="d5">Wu is an author associated with assigning FM modules in the agentic system with different roles, 2023</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MONTE CARLO TREE SEARCH (MCTS)">
      <data key="d4">18.0</data>
      <data key="d5">LATS integrates Monte Carlo Tree Search (MCTS) to enable language models as agents for proficient exploration and enhanced decision-making</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GPT-4">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses GPT-4 in its experimental evaluation, achieving state-of-the-art pass@1 accuracy (92.7%) for programming on HumanEval</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GPT-3.5">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses GPT-3.5 in its experimental evaluation, demonstrating gradient-free performance comparable to gradient-based fine-tuning for web navigation on WebShop</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="HUMANEVAL">
      <data key="d4">14.0</data>
      <data key="d5">HumanEval is a dataset used to evaluate the programming performance of LATS with GPT-4</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="WEBSHOP">
      <data key="d4">14.0</data>
      <data key="d5">WebShop is a dataset used to evaluate the web navigation performance of LATS with GPT-3.5</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="REACT">
      <data key="d4">16.0</data>
      <data key="d5">LATS expands upon ReAct to improve reasoning and decision-making</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="INTERNATIONAL CONFERENCE ON MACHINE LEARNING (ICML)">
      <data key="d4">18.0</data>
      <data key="d5">The paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models" was presented at the International Conference on Machine Learning (ICML)</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PMLR">
      <data key="d4">16.0</data>
      <data key="d5">PMLR published the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="CHOWDHERY ET AL.">
      <data key="d4">12.0</data>
      <data key="d5">Chowdhery et al. are referenced in the paper for their work on language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="OPENAI">
      <data key="d4">12.0</data>
      <data key="d5">OpenAI is referenced in the paper for their work on language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="NALLAPATI ET AL.">
      <data key="d4">12.0</data>
      <data key="d5">Nallapati et al. are referenced in the paper for their work on summarization using language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="BOWMAN ET AL.">
      <data key="d4">12.0</data>
      <data key="d5">Bowman et al. are referenced in the paper for their work on language inference using language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="COBBE ET AL.">
      <data key="d4">12.0</data>
      <data key="d5">Cobbe et al. are referenced in the paper for their work on tasks requiring advanced common-sense reasoning or quantitative skills using language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SAPAROV AND HE">
      <data key="d4">12.0</data>
      <data key="d5">Saparov and He are referenced in the paper for their work on tasks requiring advanced common-sense reasoning or quantitative skills using language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="YAO ET AL.">
      <data key="d4">12.0</data>
      <data key="d5">Yao et al. are referenced in the paper for their work on web navigation using language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="DENG ET AL.">
      <data key="d4">12.0</data>
      <data key="d5">Deng et al. are referenced in the paper for their work on web navigation using language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SCHICK ET AL.">
      <data key="d4">12.0</data>
      <data key="d5">Schick et al. are referenced in the paper for their work on tool-use using language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="FAN ET AL.">
      <data key="d4">12.0</data>
      <data key="d5">Fan et al. are referenced in the paper for their work on open-ended games using language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GAO ET AL.">
      <data key="d4">12.0</data>
      <data key="d5">Gao et al. are referenced in the paper for their work on prompting techniques that augment language models with feedback or observations from an external environment</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SHINN ET AL.">
      <data key="d4">12.0</data>
      <data key="d5">Shinn et al. are referenced in the paper for their work on prompting techniques that augment language models with feedback or observations from an external environment</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SLOMAN">
      <data key="d4">12.0</data>
      <data key="d5">Sloman is referenced in the paper for their work on deliberate and thoughtful decision-making characteristics in humans</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="EVANS">
      <data key="d4">6.0</data>
      <data key="d5">Evans is referenced in the paper for their work on deliberate and thoughtful decision-making characteristics in humans</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="XIE ET AL.">
      <data key="d4">6.0</data>
      <data key="d5">Xie et al. are referenced in the paper for their work on search-guided language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="HAO ET AL.">
      <data key="d4">6.0</data>
      <data key="d5">Hao et al. are referenced in the paper for their work on search-guided language models</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="WOOLDRIDGE AND JENNINGS">
      <data key="d4">1.0</data>
      <data key="d5">Wooldridge and Jennings are referenced in the paper for their work on general autonomous agents capable of reasoning and decision-making</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="ANDY ZHOU" target="KAI YAN">
      <data key="d4">16.0</data>
      <data key="d5">Andy Zhou and Kai Yan co-authored the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="ANDY ZHOU" target="MICHAL SHLAPENTOKH-ROTHMAN">
      <data key="d4">16.0</data>
      <data key="d5">Andy Zhou and Michal Shlapentokh-Rothman co-authored the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="ANDY ZHOU" target="HAOHAN WANG">
      <data key="d4">16.0</data>
      <data key="d5">Andy Zhou and Haohan Wang co-authored the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="ANDY ZHOU" target="YU-XIONG WANG">
      <data key="d4">16.0</data>
      <data key="d5">Andy Zhou and Yu-Xiong Wang co-authored the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="ANDY ZHOU" target="UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN">
      <data key="d4">18.0</data>
      <data key="d5">Andy Zhou is affiliated with the University of Illinois Urbana-Champaign</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="ANDY ZHOU" target="LAPIS LABS">
      <data key="d4">16.0</data>
      <data key="d5">Andy Zhou is affiliated with Lapis Labs</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="KAI YAN" target="MICHAL SHLAPENTOKH-ROTHMAN">
      <data key="d4">16.0</data>
      <data key="d5">Kai Yan and Michal Shlapentokh-Rothman co-authored the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="KAI YAN" target="HAOHAN WANG">
      <data key="d4">16.0</data>
      <data key="d5">Kai Yan and Haohan Wang co-authored the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="KAI YAN" target="YU-XIONG WANG">
      <data key="d4">16.0</data>
      <data key="d5">Kai Yan and Yu-Xiong Wang co-authored the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="KAI YAN" target="UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN">
      <data key="d4">18.0</data>
      <data key="d5">Kai Yan is affiliated with the University of Illinois Urbana-Champaign</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="MICHAL SHLAPENTOKH-ROTHMAN" target="HAOHAN WANG">
      <data key="d4">16.0</data>
      <data key="d5">Michal Shlapentokh-Rothman and Haohan Wang co-authored the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="MICHAL SHLAPENTOKH-ROTHMAN" target="YU-XIONG WANG">
      <data key="d4">16.0</data>
      <data key="d5">Michal Shlapentokh-Rothman and Yu-Xiong Wang co-authored the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="MICHAL SHLAPENTOKH-ROTHMAN" target="UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN">
      <data key="d4">18.0</data>
      <data key="d5">Michal Shlapentokh-Rothman is affiliated with the University of Illinois Urbana-Champaign</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="HAOHAN WANG" target="YU-XIONG WANG">
      <data key="d4">16.0</data>
      <data key="d5">Haohan Wang and Yu-Xiong Wang co-authored the paper titled "Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models"</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="HAOHAN WANG" target="UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN">
      <data key="d4">18.0</data>
      <data key="d5">Haohan Wang is affiliated with the University of Illinois Urbana-Champaign</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="YU-XIONG WANG" target="UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN">
      <data key="d4">18.0</data>
      <data key="d5">Yu-Xiong Wang is affiliated with the University of Illinois Urbana-Champaign</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="LATS">
      <data key="d4">9.0</data>
      <data key="d5">LATS is based on Monte Carlo Tree Search (MCTS) to construct the best trajectory from sampled actions</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="MODEL-BASED REINFORCEMENT LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">Model-based reinforcement learning inspired the use of Monte Carlo Tree Search (MCTS) in LATS</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="REASONING VIA PLANNING (RAP)">
      <data key="d4">8.0</data>
      <data key="d5">Reasoning via planning (RAP) uses Monte Carlo Tree Search (MCTS)</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="TREE-OF-THOUGHT (TOT) PROMPTING">
      <data key="d4">7.0</data>
      <data key="d5">Tree-of-thought (ToT) prompting uses search algorithms like those in Monte Carlo Tree Search (MCTS) to explore reasoning paths</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="RAP">
      <data key="d4">6.0</data>
      <data key="d5">RAP also adopts Monte Carlo Tree Search (MCTS) for planning strategies</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="KOCSIS AND SZEPESV&#193;RI, 2006">
      <data key="d4">9.0</data>
      <data key="d5">Kocsis and Szepesv&#225;ri, 2006 introduced the UCT value used in Monte Carlo Tree Search (MCTS)</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="YE ET AL., 2021">
      <data key="d4">8.0</data>
      <data key="d5">Ye et al., 2021 applied Monte Carlo Tree Search (MCTS) to decision-making environments like Atari</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="SILVER ET AL., 2016">
      <data key="d4">1.0</data>
      <data key="d5">Silver et al., 2016 applied Monte Carlo Tree Search (MCTS) to decision-making environments like Go</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)">
      <data key="d4">9.0</data>
      <data key="d5">Monte Carlo Tree Search (MCTS) uses UCT to select the best child node for expansion</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="EXPANSION">
      <data key="d4">9.0</data>
      <data key="d5">Expansion is a step in Monte Carlo Tree Search (MCTS) where multiple children states are explored</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="SELECTION">
      <data key="d4">9.0</data>
      <data key="d5">Selection is a step in Monte Carlo Tree Search (MCTS) where the child with the highest UCT value is selected for expansion</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="BACKPROPAGATION">
      <data key="d4">9.0</data>
      <data key="d5">Backpropagation is a step in Monte Carlo Tree Search (MCTS) where the return is used to update the value function of nodes</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="GPT-4" target="LATS">
      <data key="d4">26.0</data>
      <data key="d5">LATS, when used with GPT-4, has demonstrated exceptional performance in various experiments. Notably, this combination has set the state of the art for HumanEval, achieving a remarkable 92.7 Pass@1 rate. This high level of performance underscores the effectiveness of LATS in enhancing the capabilities of GPT-4 in evaluation tasks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-4" target="REACT">
      <data key="d4">8.0</data>
      <data key="d5">ReAct is used with GPT-4 in various experiments, achieving high performance</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-4" target="REFLEXION">
      <data key="d4">8.0</data>
      <data key="d5">Reflexion is used with GPT-4 in various experiments, achieving high performance</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-4" target="HUMANEVAL">
      <data key="d4">18.0</data>
      <data key="d5">GPT-4 is used to evaluate performance on the HumanEval dataset</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-4" target="OPENAI">
      <data key="d4">27.0</data>
      <data key="d5">OpenAI developed GPT-4, a sophisticated language model that has been utilized in the ARC challenge. This model represents a significant advancement in artificial intelligence, showcasing OpenAI's commitment to pushing the boundaries of machine learning and natural language processing.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="GPT-4" target="GPT-4O-2024-05-13">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4o-2024-05-13 is a specific version of the GPT-4 model</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="GPT-4" target="SYNTHETIC DATA">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 is used to generate responses to prompts for creating synthetic data</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="GPT-4" target="AGENTINSTRUCT">
      <data key="d4">16.0</data>
      <data key="d5">AgentInstruct uses GPT-4 to generate high-quality data</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="GPT-4" target="ORCA-BENCH">
      <data key="d4">19.0</data>
      <data key="d5">GPT-4 is utilized as a baseline for scoring the performance of models evaluated with the Orca-Bench dataset. It serves as a benchmark model, achieving a score of 10 in the Orca-Bench dataset. This highlights GPT-4's role in setting a standard for comparison within the context of the Orca-Bench evaluations.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GPT-4" target="ORCA-3">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3's performance in reading comprehension is elevated to match that of GPT-4</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPT-4" target="ORCA-3-7B">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3-7B has been compared to GPT-4 in various benchmarks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="AGIEVAL">
      <data key="d4">14.0</data>
      <data key="d5">AGIEval is used to evaluate the performance of GPT-4 on various tasks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="DROOP">
      <data key="d4">14.0</data>
      <data key="d5">DROOP is used to evaluate the performance of GPT-4 on reading comprehension tasks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="BBH MULTISTEP-ARITHMETIC-TWO">
      <data key="d4">14.0</data>
      <data key="d5">BBH multistep-arithmetic-two is used to evaluate the performance of GPT-4 on multi-step arithmetic problems</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="MMLU">
      <data key="d4">14.0</data>
      <data key="d5">MMLU is used to evaluate the performance of GPT-4 on various mathematical tasks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="GSM8K">
      <data key="d4">14.0</data>
      <data key="d5">GSM8K is used to evaluate the performance of GPT-4 on math problems</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="TABLE 7">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 evaluated hallucination rates and quality scores presented in Table 7</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="APPENDIX B">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 used prompts found in Appendix B for evaluations</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="APPENDIX E">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4's evaluations reference baselines detailed in Appendix E</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="EVALUATION">
      <data key="d4">9.0</data>
      <data key="d5">GPT-4 was used as an evaluator in various tasks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 used specific prompts for generating responses</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="CO-T">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 uses Chain of Thought (CoT) for reasoning through complex problems</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 is evaluated on the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="AZURE">
      <data key="d4">7.0</data>
      <data key="d5">Azure is recommended for reviewing transparency notes related to GPT-4</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="COT">
      <data key="d4">8.0</data>
      <data key="d5">CoT shows the performance of GPT-4 when answering directly without using RAG</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="MULTIPLE CHOICE QUESTIONS">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4 is used for extracting the option selected by the model in the evaluation of Multiple Choice Questions</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="GPT-4" target="EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The Extraction System Message is used by GPT-4 to extract the option selected by the model</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="GPT-4" target="STUDENT RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 parses the Student Response to extract the selected option</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="GPT-4" target="FOFO">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 is used as a judge in the FOFO benchmark</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="IFEVAL">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 is used as a judge in the IFEval benchmark</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="INFOBENCH">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 is used as a judge in the InfoBench benchmark</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="HALLUCINATION JUDGE">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 is used as a judge in the Hallucination Judge task</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="QUALITY JUDGE">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 is used as a judge in the Quality Judge task</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="HALLUCINATION EVALUATION">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 is used as a judge in Hallucination Evaluation</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="QUALITY EVALUATION">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4 is used as a judge in Quality Evaluation</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-3.5" target="LATS">
      <data key="d4">40.0</data>
      <data key="d5">LATS achieves the highest performance on MBPP when evaluated with the GPT-3.5 language model. LATS is consistently used with GPT-3.5 in various experiments, demonstrating significant performance improvements. The combination of LATS and GPT-3.5 has proven to be highly effective, achieving notable success in multiple evaluations.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-3.5" target="REACT">
      <data key="d4">24.0</data>
      <data key="d5">GPT-3.5, a state-of-the-art language model, is utilized in conjunction with the ReAct prompting method in various experiments. This combination has demonstrated high performance, showcasing the effectiveness of ReAct when paired with GPT-3.5. The synergy between GPT-3.5 and ReAct highlights the potential for advanced prompting techniques to enhance the capabilities of sophisticated AI models in experimental settings.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-3.5" target="REFLEXION">
      <data key="d4">24.0</data>
      <data key="d5">GPT-3.5, a state-of-the-art language model, is utilized in conjunction with the Reflexion prompting method in various experiments. This combination has demonstrated high performance, showcasing the effectiveness of Reflexion when applied to GPT-3.5. The synergy between GPT-3.5 and Reflexion highlights the potential for advanced prompting techniques to enhance the capabilities of sophisticated AI models.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-3.5" target="TOT">
      <data key="d4">7.0</data>
      <data key="d5">ToT is used with GPT-3.5 in various experiments, achieving high performance</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-3.5" target="RAP">
      <data key="d4">7.0</data>
      <data key="d5">RAP is used with GPT-3.5 in various experiments, achieving high performance</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-3.5" target="COT">
      <data key="d4">7.0</data>
      <data key="d5">CoT is used with GPT-3.5 in various experiments, achieving high performance</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-3.5" target="HUMANEVAL">
      <data key="d4">18.0</data>
      <data key="d5">GPT-3.5 is used to evaluate performance on the HumanEval dataset</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-3.5" target="GAME OF 24">
      <data key="d4">8.0</data>
      <data key="d5">GPT-3.5 is a language model used in the Game of 24</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="GPT-3.5" target="OPENAI">
      <data key="d4">27.0</data>
      <data key="d5">OpenAI developed GPT-3.5, a sophisticated language model that has been utilized in various applications, including the ARC challenge. This model represents a significant advancement in artificial intelligence, showcasing OpenAI's commitment to pushing the boundaries of machine learning and natural language processing.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="GPT-3.5" target="GPT-3.5-TURBO-0125">
      <data key="d4">8.0</data>
      <data key="d5">GPT-3.5-turbo-0125 is a specific version of the GPT-3.5 model</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="GPT-3.5" target="ORCA-3">
      <data key="d4">16.0</data>
      <data key="d5">Orca-3 outperformed GPT-3.5 on multiple benchmarks</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="HUMANEVAL" target="LATS">
      <data key="d4">39.0</data>
      <data key="d5">LATS achieves the highest performance on the HumanEval dataset. The LATS algorithm is evaluated using the HumanEval dataset, demonstrating its effectiveness in programming tasks. Through its evaluation on HumanEval, LATS has proven to be a top performer, showcasing its advanced capabilities in handling complex programming challenges.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HUMANEVAL" target="PASS@1">
      <data key="d4">8.0</data>
      <data key="d5">Pass@1 is a metric used to evaluate the performance of different methods on HumanEval</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HUMANEVAL" target="PROGRAMMING">
      <data key="d4">8.0</data>
      <data key="d5">Programming is evaluated using the HumanEval dataset</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="CHEN ET AL.">
      <data key="d4">7.0</data>
      <data key="d5">Chen et al. introduced the HumanEval dataset in 2021</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEBSHOP" target="LATS">
      <data key="d4">48.0</data>
      <data key="d5">LATS achieves high performance on the WebShop dataset. The LATS algorithm is evaluated using the WebShop tasks, demonstrating its effectiveness in reasoning and acting tasks within the WebShop environment. Through its evaluation on the WebShop dataset, LATS has shown significant improvements in performance, underscoring its capability in handling complex tasks associated with the WebShop environment.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="WEBSHOP" target="EXPERIMENTS">
      <data key="d4">7.0</data>
      <data key="d5">Experiments evaluate the applicability of LATS on the WebShop dataset</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="WEBSHOP" target="REACT">
      <data key="d4">7.0</data>
      <data key="d5">ReAct is evaluated on the WebShop dataset</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="WEBSHOP" target="REFLEXION">
      <data key="d4">7.0</data>
      <data key="d5">Reflexion is evaluated on the WebShop dataset</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="WEBSHOP" target="YA0">
      <data key="d4">6.0</data>
      <data key="d5">Yao has worked on methods like WebShop</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="WEBSHOP" target="AMAZON">
      <data key="d4">18.0</data>
      <data key="d5">WebShop uses over 1 million real-world products scraped from Amazon</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEBSHOP" target="TASK SCORE">
      <data key="d4">16.0</data>
      <data key="d5">Task Score is an evaluation metric used in WebShop</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEBSHOP" target="SUCCESS RATE (SR)">
      <data key="d4">9.0</data>
      <data key="d5">Success Rate (SR) is an evaluation metric used in WebShop</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEBSHOP" target="YA0 ET AL.">
      <data key="d4">1.0</data>
      <data key="d5">Yao et al. introduced the WebShop environment in 2022</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEBSHOP" target="QUERY">
      <data key="d4">8.0</data>
      <data key="d5">Query is an action in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEBSHOP" target="RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">Results is a state in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEBSHOP" target="PRODUCT TITLE">
      <data key="d4">7.0</data>
      <data key="d5">Product title is an attribute in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEBSHOP" target="OPTION">
      <data key="d4">7.0</data>
      <data key="d5">Option is an attribute in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEBSHOP" target="DESC/OVERVIEW">
      <data key="d4">7.0</data>
      <data key="d5">Desc/Overview is an attribute in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEBSHOP" target="ITEM">
      <data key="d4">8.0</data>
      <data key="d5">Item is a state in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEBSHOP" target="ITEM-DETAIL">
      <data key="d4">8.0</data>
      <data key="d5">Item-Detail is a state in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEBSHOP" target="EPISODE END">
      <data key="d4">8.0</data>
      <data key="d5">Episode End is a state in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEBSHOP" target="REWARD">
      <data key="d4">8.0</data>
      <data key="d5">Reward is a metric used in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEBSHOP" target="SUCCESS RATE">
      <data key="d4">8.0</data>
      <data key="d5">Success Rate is a metric used in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEBSHOP" target="VALUE FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">Value function is a component used in the WebShop system</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="REACT" target="LATS">
      <data key="d4">58.0</data>
      <data key="d5">LATS is compared to ReAct in terms of computational cost and efficiency. In various experiments, including those on the HotPotQA dataset, LATS outperforms ReAct in both performance and efficiency. LATS leverages ReAct as a prompting method, utilizing ReAct-based prompts to achieve high performance on tasks such as HotPotQA and programming.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="REACT" target="COT">
      <data key="d4">12.0</data>
      <data key="d5">ReAct is similar to CoT in that both are prompting techniques aimed at improving reasoning in language models</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="CHAIN-OF-THOUGHT (COT) PROMPTING">
      <data key="d4">7.0</data>
      <data key="d5">ReAct builds on Chain-of-thought (CoT) prompting by adding interactions with an external environment</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="TREE-OF-THOUGHT (TOT) PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">Both Tree-of-thought (ToT) prompting and ReAct are techniques that extend the capabilities of language models</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="LANGUAGE MODELS (LMS)">
      <data key="d4">9.0</data>
      <data key="d5">ReAct is a technique used to improve the reasoning and acting capabilities of language models</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="YAO ET AL., 2023B">
      <data key="d4">9.0</data>
      <data key="d5">Yao et al., 2023b introduced ReAct</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="ENVIRONMENTAL FEEDBACK">
      <data key="d4">9.0</data>
      <data key="d5">ReAct uses observations from the environment to improve reasoning and acting</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="LM AGENT">
      <data key="d4">7.0</data>
      <data key="d5">LM Agent follows the ReAct instantiation for its action space</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="REACT" target="PROMPT METHOD">
      <data key="d4">8.0</data>
      <data key="d5">ReAct is one of the prompt methods used in the experiments</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="REACT" target="EXTERNAL RETRIEVAL">
      <data key="d4">7.0</data>
      <data key="d5">External Retrieval strategies are evaluated using ReAct</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="REACT" target="WEI">
      <data key="d4">7.0</data>
      <data key="d5">Wei has worked on the ReAct prompting method</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="INTERNATIONAL CONFERENCE ON MACHINE LEARNING (ICML)" target="VIENNA, AUSTRIA">
      <data key="d4">14.0</data>
      <data key="d5">The 41st International Conference on Machine Learning (ICML) was held in Vienna, Austria</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="OPENAI" target="GET_JSON_RESPONSE_FROM_GPT">
      <data key="d4">1.0</data>
      <data key="d5">The get_json_response_from_gpt function uses a GPT model associated with OpenAI</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="OPENAI" target="GPT-4O-2024-05-13">
      <data key="d4">27.0</data>
      <data key="d5">OpenAI developed the GPT-4o-2024-05-13 model</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="OPENAI" target="GPT-3.5-TURBO-0125">
      <data key="d4">12.0</data>
      <data key="d5">OpenAI developed and provides the GPT-3.5-turbo-0125 model, which is utilized in various experiments. This model represents a significant advancement in the field of artificial intelligence, showcasing OpenAI's commitment to pushing the boundaries of machine learning and natural language processing.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="OPENAI" target="GPT-4O-MINI">
      <data key="d4">9.0</data>
      <data key="d5">OpenAI provides the GPT-4o-mini model, which is less expensive and offers better performance</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="OPENAI" target="COST OF EXPERIMENTS">
      <data key="d4">9.0</data>
      <data key="d5">Cost of Experiments is incurred due to querying OpenAI's models</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="EVANS" target="LM AGENT">
      <data key="d4">1.0</data>
      <data key="d5">Evans contributed to the understanding of complex decision-making tasks, which is relevant to the LM Agent</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SELF-REFINEMENT">
      <data key="d4">7.0</data>
      <data key="d5">LATS incorporates self-refinement as a heuristic to guide the search process</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SELF-CONSISTENCY">
      <data key="d4">15.0</data>
      <data key="d5">LATS incorporates self-consistency as a heuristic to guide the search process. Self-consistency is a heuristic used in LATS to improve value assignment. This approach ensures that the search process is more efficient and reliable by maintaining consistent value assignments throughout the process.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SEARCH ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">Search algorithms are adapted in LATS for language agents</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="PROMPTS">
      <data key="d4">8.0</data>
      <data key="d5">Prompts are used in LATS to store and retrieve external feedback</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="VALUE ASSIGNMENT">
      <data key="d4">8.0</data>
      <data key="d5">Value assignment is incorporated in LATS</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="INTERNAL REASONING PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">LATS aims to surpass internal reasoning performance</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="LM-POWERED VALUE FUNCTIONS">
      <data key="d4">8.0</data>
      <data key="d5">LM-powered value functions are used in LATS for cleverer exploration</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SELF-REFLECTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflections are used in LATS</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="PLANNING">
      <data key="d4">8.0</data>
      <data key="d5">Planning is a key component of LATS</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="REASONING">
      <data key="d4">8.0</data>
      <data key="d5">Reasoning is enhanced by LATS</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="ACTING">
      <data key="d4">8.0</data>
      <data key="d5">Acting is a component of LATS</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="DECISION-MAKING">
      <data key="d4">8.0</data>
      <data key="d5">Decision-making is enhanced by LATS</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="PROGRAMMING">
      <data key="d4">39.0</data>
      <data key="d5">LATS is an algorithm evaluated using programming tasks, specifically utilizing datasets such as HumanEval and MBPP. Programming is one of the primary domains where LATS is tested, demonstrating its capabilities and performance in this area.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="INTERACTIVE QUESTION-ANSWERING (QA)">
      <data key="d4">8.0</data>
      <data key="d5">Interactive question-answering (QA) is one of the domains where LATS is tested</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="WEB NAVIGATION">
      <data key="d4">9.0</data>
      <data key="d5">Web navigation is an environment where LATS determines the success of a trajectory. It is one of the domains where LATS is tested, highlighting its application in evaluating and optimizing navigation paths within web environments.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="MATH">
      <data key="d4">8.0</data>
      <data key="d5">Math is one of the domains where LATS is tested</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="EXTERNAL FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">External feedback is incorporated in LATS</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SELF-IMPROVEMENT">
      <data key="d4">8.0</data>
      <data key="d5">Self-improvement techniques are used in LATS</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENTAL CONDITIONS">
      <data key="d4">8.0</data>
      <data key="d5">LATS can handle environmental conditions without additional training</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="TRAJECTORIES">
      <data key="d4">24.0</data>
      <data key="d5">LATS utilizes trajectories as a parameter to determine the number of trajectories sampled. These trajectories are constructed by LATS from sampled actions, indicating a systematic approach to data sampling and analysis within the framework.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="HEURISTICS">
      <data key="d4">8.0</data>
      <data key="d5">Heuristics are incorporated in LATS for value assignment and search processes</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="TREE-BASED SEARCH">
      <data key="d4">16.0</data>
      <data key="d5">LATS operates on the tree-based framework to unify reasoning, acting, and planning in language models</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="MCTS">
      <data key="d4">45.0</data>
      <data key="d5">LATS adapts MCTS (Monte Carlo Tree Search) to language agents to unify reasoning, acting, and planning in language models. By leveraging MCTS as a search algorithm, LATS achieves significant performance gains. The use of the MCTS algorithm in LATS ensures a principled and efficient search process, enhancing the overall capabilities of language models in complex tasks.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LM AGENT">
      <data key="d4">8.0</data>
      <data key="d5">LM Agent is a component within LATS that supports sequential reasoning or decision-making tasks</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="P&#920;">
      <data key="d4">22.0</data>
      <data key="d5">LATS utilizes P&#952; as a parameter to represent the action generator. Additionally, P&#952; is repurposed as an agent, state evaluator, and feedback generator within the LATS framework. This multifaceted role of P&#952; highlights its versatility and central importance in the LATS system.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="RAP">
      <data key="d4">56.0</data>
      <data key="d5">LATS and RAP use similar search algorithms to perform well on reasoning tasks. LATS is frequently compared to RAP in terms of sample complexity, performance, and reliance on internal dynamics models. In various experiments, LATS has been shown to achieve high performance, often outperforming RAP in both performance and efficiency. Additionally, LATS utilizes the RAP method for reasoning and planning, further highlighting the close relationship between the two entities in their approach to solving complex tasks.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,c234cb83764b899335af0950677ad024,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="SEARCH ALGORITHM">
      <data key="d4">8.0</data>
      <data key="d5">Search algorithm is the main component of LATS</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="TREE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Tree search is used in LATS to frame decision-making</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LONG-TERM MEMORY STRUCTURE">
      <data key="d4">7.0</data>
      <data key="d5">Long-term memory structure is used to store the tree in LATS</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="VALUE FUNCTION">
      <data key="d4">1.0</data>
      <data key="d5">Value function is proposed for LATS based on a self-generated LM score</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="TOT">
      <data key="d4">49.0</data>
      <data key="d5">LATS and ToT both use search methods to sample and explore more outputs for better performance on reasoning tasks. LATS is compared to ToT in terms of sample complexity and performance, and in various experiments, LATS achieves high performance. Notably, LATS outperforms ToT in terms of performance and efficiency. Additionally, the value function in LATS is inspired by the ToT method.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="CAMPBELL">
      <data key="d4">12.0</data>
      <data key="d5">Campbell's research on programmed heuristics is referenced in the context of LATS</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="SILVER">
      <data key="d4">12.0</data>
      <data key="d5">Silver's research on learned heuristics is referenced in the context of LATS</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="COT">
      <data key="d4">30.0</data>
      <data key="d5">LATS is compared with CoT in various experiments, achieving high performance. LATS leverages CoT-based prompts to enhance its performance on reasoning tasks, utilizing the CoT method for reasoning-based prompting. This integration of CoT techniques allows LATS to excel in tasks that require complex reasoning, demonstrating its effectiveness in various experimental settings.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="SHINN">
      <data key="d4">14.0</data>
      <data key="d5">Shinn contributed to the research on self-reflection, which is a component of LATS</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="MADAAN">
      <data key="d4">14.0</data>
      <data key="d5">Madaan contributed to the research on self-reflection, which is a component of LATS</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="AUSTIN">
      <data key="d4">8.0</data>
      <data key="d5">Austin contributed to the research on programming domains, which is one of the domains evaluated by LATS</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="UCT FORMULA">
      <data key="d4">8.0</data>
      <data key="d5">The UCT formula is used in LATS to guide the selection of the next node</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENTAL FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">Environmental feedback is used in LATS to improve value assignment and scaling to more challenging environments</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="SELF-REFLECTION">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection is used in LATS to refine the decision-making process</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="REINFORCEMENT LEARNING">
      <data key="d4">7.0</data>
      <data key="d5">LATS aims to avoid the cost of expensive optimization such as reinforcement learning</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="GAME OF 24">
      <data key="d4">15.0</data>
      <data key="d5">LATS is a method utilized in the Game of 24. It has been evaluated on the Game of 24, achieving high performance in both reasoning and acting tasks.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="REFLEXION">
      <data key="d4">40.0</data>
      <data key="d5">LATS is compared to Reflexion in terms of computational cost and efficiency. In various experiments, including those conducted on HumanEval, LATS consistently outperforms Reflexion, particularly on reasoning tasks. This high performance across multiple evaluations highlights LATS's superior capabilities in comparison to Reflexion.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="EXPERIMENTS">
      <data key="d4">8.0</data>
      <data key="d5">Experiments are conducted to demonstrate the general applicability of LATS across various domains</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="PROMPT METHOD">
      <data key="d4">30.0</data>
      <data key="d5">LATS is one of the prompt methods used in the experiments, specifically designed to evaluate performance on HotPotQA. The PROMPT METHOD refers to the different configurations and techniques employed within LATS to achieve this evaluation.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="EXTERNAL RETRIEVAL">
      <data key="d4">8.0</data>
      <data key="d5">External Retrieval strategies are evaluated using LATS</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="INTERNAL AND EXTERNAL REASONING">
      <data key="d4">8.0</data>
      <data key="d5">Internal and External Reasoning is a combined approach used in LATS</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="MODERN LMS">
      <data key="d4">1.0</data>
      <data key="d5">Modern LMs are used in LATS experiments, leveraging their large-scale training corpus</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="MBPP">
      <data key="d4">9.0</data>
      <data key="d5">LATS achieves the highest performance on the MBPP dataset</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="CHAIN OF THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">LATS uses Chain of Thought (CoT) prompts to enhance performance on reasoning tasks</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="SEARCH METHODS">
      <data key="d4">8.0</data>
      <data key="d5">LATS uses search methods like ToT and RAP to sample and explore more outputs for better performance on reasoning tasks</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="HUMANEVAL DATASET">
      <data key="d4">9.0</data>
      <data key="d5">LATS achieves the highest performance on the HumanEval dataset</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="MBPP DATASET">
      <data key="d4">9.0</data>
      <data key="d5">LATS achieves the highest performance on the MBPP dataset</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="GPT-3.5 MODEL">
      <data key="d4">8.0</data>
      <data key="d5">LATS achieves the highest performance on MBPP when evaluated with GPT-3.5</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="GPT-4 MODEL">
      <data key="d4">9.0</data>
      <data key="d5">LATS sets the state of the art for HumanEval when used with GPT-4</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="WEBSHOP DATASET">
      <data key="d4">8.0</data>
      <data key="d5">LATS achieves high performance on the WebShop dataset</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="COT-SC">
      <data key="d4">12.0</data>
      <data key="d5">LATS is compared to CoT-SC in terms of efficiency</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="MINECRAFT">
      <data key="d4">5.0</data>
      <data key="d5">LATS is suggested for future work in the Minecraft environment</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="LM VALUE FUNCTION">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses the LM value function to score states based on expected future reward</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="EXPLORATION WEIGHT">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses exploration weight as a parameter to affect the effectiveness of the search</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="DEPTH">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses depth as a parameter to limit the number of steps in the search process</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SAMPLING SIZE">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses sampling size as a parameter to determine the number of actions generated</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="VALUE FUNCTION WEIGHT">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses value function weight to balance the LM score and self-consistency score</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="STATE SPACE">
      <data key="d4">14.0</data>
      <data key="d5">LATS performance depends on the complexity of the state space</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SEARCH [ENTITY]">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses the search [entity] action to retrieve information from Wikipedia</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="LOOKUP [STRING]">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses the lookup [string] action to retrieve information from Wikipedia</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="REFLECTION">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses the reflection action to generate reflections from the context</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="EVALUATION">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses the evaluation action to score states based on the value function</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="BACKPROPAGATION">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses the backpropagation action to update the value function based on rewards</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="EXPANSION &amp; SIMULATION">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses the expansion &amp; simulation action to generate and evaluate actions</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SELECTION">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses the selection action to choose the best action based on the value function and exploration weight</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="TERMINAL STATE">
      <data key="d4">14.0</data>
      <data key="d5">LATS identifies terminal states where no further actions can be taken</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="INITIAL STATE">
      <data key="d4">14.0</data>
      <data key="d5">LATS starts from an initial state</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SUCCESS">
      <data key="d4">14.0</data>
      <data key="d5">LATS aims for success, often determined by environment rewards</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENT REWARDS">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses environment rewards to guide the search process</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="WIKIPEDIA WEB API">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses the Wikipedia web API to support interactive information retrieval</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="A">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses A as a parameter to represent the action space</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="O">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses O as a parameter to represent the observation space</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="S">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses S as a parameter to represent the state space</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="PV">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses PV as a parameter to represent the value function</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="PREF">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses PREF as a parameter to represent the reflection generator</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="K">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses K as a parameter to represent the number of roll-outs</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="L">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses L as a parameter to represent the depth limit</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="C">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses C as a parameter to represent the context</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="R">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses R as a parameter to represent the reward</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="T">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses T as a parameter to represent the actual number of steps</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ST">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses ST as a parameter to represent the state at time t</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="AT">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses AT as a parameter to represent the action at time t</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="OT">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses OT as a parameter to represent the observation at time t</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="CT">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses CT as a parameter to represent the context at time t</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SC">
      <data key="d4">2.0</data>
      <data key="d5">LATS uses SC as a parameter to represent the self-consistency score</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="SELF-CONSISTENCY" target="MAJORITY VOTING">
      <data key="d4">8.0</data>
      <data key="d5">Majority voting is used in self-consistency to mitigate error propagation</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SELF-CONSISTENCY" target="SAMPLED CHAINS">
      <data key="d4">8.0</data>
      <data key="d5">Sampled chains are used in self-consistency for majority voting</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="COBEE" target="WEI">
      <data key="d4">14.0</data>
      <data key="d5">Cobbe and Wei have both worked on reasoning for language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="COBEE" target="KOJIMA">
      <data key="d4">14.0</data>
      <data key="d5">Cobbe and Kojima have both worked on reasoning for language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WEI" target="KOJIMA">
      <data key="d4">14.0</data>
      <data key="d5">Wei and Kojima have both worked on chain-of-thought (CoT) prompting and its variants for reasoning in language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WEI" target="COT">
      <data key="d4">41.0</data>
      <data key="d5">Wei has worked extensively on Chain-of-thought (CoT) prompting, a method used in various experiments. As one of the authors who contributed to the development and application of CoT, Wei has played a significant role in advancing this prompting technique.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="WEI" target="CHAIN-OF-THOUGHT">
      <data key="d4">54.0</data>
      <data key="d5">Wei has significantly contributed to the development of Chain-of-Thought planning and reasoning. In 2022, Wei was an author associated with the state-of-the-art hand-designed Chain-of-Thought agent, showcasing expertise in this advanced technique.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HAO" target="BESTA">
      <data key="d4">14.0</data>
      <data key="d5">Hao and Besta have both worked on improving chain-of-thought (CoT) prompting with search algorithms</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HAO" target="RAP">
      <data key="d4">46.0</data>
      <data key="d5">Hao is an author who has significantly contributed to the development and application of RAP, a prompting method used in various experiments. Hao's work on RAP includes exploring its techniques and search methods, highlighting his expertise in this area.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HAO" target="SEARCH APPROACHES">
      <data key="d4">6.0</data>
      <data key="d5">Hao has worked on previous search approaches</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="AHN" target="DRIESS">
      <data key="d4">14.0</data>
      <data key="d5">Ahn and Driess have both worked on adapting language models as high-level controllers in robotics</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="BAKER" target="GUSS">
      <data key="d4">14.0</data>
      <data key="d5">Baker and Guss have both worked on adapting language model agents to complex multimodal games such as Minecraft</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="BAKER" target="FAN">
      <data key="d4">14.0</data>
      <data key="d5">Baker and Fan have both worked on adapting language model agents to complex multimodal games such as Minecraft</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="GUSS" target="FAN">
      <data key="d4">21.0</data>
      <data key="d5">Fan and Guss have both worked on the Minecraft gameGuss and Fan have both worked on adapting language model agents to complex multimodal games such as Minecraft</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="FAN" target="MINECRAFT">
      <data key="d4">6.0</data>
      <data key="d5">Fan has worked on using planning-based prompting methods in environments like Minecraft</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="SHRIDHAR" target="ALFWORLD">
      <data key="d4">6.0</data>
      <data key="d5">Shridhar has worked on text-based manipulation tasks like Alfworld</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="MADAAN" target="SHINN">
      <data key="d4">7.0</data>
      <data key="d5">Madaan and Shinn have both worked on self-improvement techniques for language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MADAAN" target="SELF-REFINE">
      <data key="d4">56.0</data>
      <data key="d5">Madaan is an author associated with the Self-Refine technique, a state-of-the-art hand-designed agent. Madaan has worked extensively on the Self-Refine method, contributing to its development and refinement. The Self-Refine technique, which is set to make significant strides in 2024, showcases Madaan's expertise and innovative contributions to the field.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,bc26e68b0b2783ba912b9e5606d9eb0b,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="MADAAN" target="SELF-REFLECTION">
      <data key="d4">23.0</data>
      <data key="d5">Madaan contributed significantly to the concept of self-reflection in 2024, particularly in the development of self-reflection within agentic systems.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHINN" target="REFLEXION">
      <data key="d4">49.0</data>
      <data key="d5">Shinn is one of the authors who contributed to the development of Reflexion, a prompting method utilized in various experiments. Shinn's work on the Reflexion method has been instrumental in advancing the understanding and application of this technique within the field.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="SHINN" target="SELF-REFLECTION">
      <data key="d4">23.0</data>
      <data key="d5">Shinn made significant contributions to the concept of self-reflection in 2023, particularly in the development of self-reflection within agentic systems.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHINN" target="SELF-REFINE">
      <data key="d4">16.0</data>
      <data key="d5">Shinn has worked on Self-Refine</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="SHINN" target="REFLECTION">
      <data key="d4">8.0</data>
      <data key="d5">Shinn is an author associated with reflection, 2023</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="YA0" target="TOT">
      <data key="d4">6.0</data>
      <data key="d5">Yao has worked on methods like ToT</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="SEARCH ALGORITHMS" target="TREE-OF-THOUGHT (TOT) PROMPTING">
      <data key="d4">8.0</data>
      <data key="d5">Tree-of-thought (ToT) prompting uses search algorithms</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SEARCH ALGORITHMS" target="TOT">
      <data key="d4">7.0</data>
      <data key="d5">Search Algorithms are integrated with ToT in the experiments</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="SEARCH ALGORITHMS" target="RAP">
      <data key="d4">7.0</data>
      <data key="d5">Search Algorithms are integrated with RAP in the experiments</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="PLANNING" target="LANGUAGE AGENT TREE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Language Agent Tree Search unifies planning in language models</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="REASONING" target="CHAIN-OF-THOUGHT (COT) PROMPTING">
      <data key="d4">8.0</data>
      <data key="d5">Chain-of-thought (CoT) prompting is a method for reasoning in language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="REASONING" target="LANGUAGE AGENT TREE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Language Agent Tree Search unifies reasoning in language models</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="REASONING" target="AGENTINSTRUCT">
      <data key="d4">12.0</data>
      <data key="d5">Reasoning is one of the skills covered in the synthetic post-training dataset created by AgentInstruct</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ACTING" target="POLICY MODEL">
      <data key="d4">8.0</data>
      <data key="d5">A policy model is used in acting tasks for language models</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="ACTING" target="TEXT-BASED ENVIRONMENTS">
      <data key="d4">8.0</data>
      <data key="d5">Text-based environments are used for acting-based prompting techniques</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="ACTING" target="LANGUAGE AGENT TREE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Language Agent Tree Search unifies acting in language models</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="PROGRAMMING" target="EXPERIMENTS">
      <data key="d4">7.0</data>
      <data key="d5">Experiments evaluate the applicability of LATS in the domain of programming</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="PROGRAMMING" target="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d4">8.0</data>
      <data key="d5">Programming is evaluated using the Mostly Basic Programming Problems (MBPP) benchmark</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="MATH" target="AGENTINSTRUCT">
      <data key="d4">12.0</data>
      <data key="d5">Math is one of the skills covered in the synthetic post-training dataset created by AgentInstruct</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="ERROR PROPAGATION">
      <data key="d4">8.0</data>
      <data key="d5">Error propagation can occur in chain-of-thought (CoT) prompting as the number of steps increases</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="TREE-OF-THOUGHT (TOT) PROMPTING">
      <data key="d4">8.0</data>
      <data key="d5">Tree-of-thought (ToT) prompting extends Chain-of-thought (CoT) prompting by exploring multiple reasoning paths</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="LANGUAGE MODELS (LMS)">
      <data key="d4">9.0</data>
      <data key="d5">Chain-of-thought (CoT) prompting is a technique used to improve the reasoning capabilities of language models</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="WEI ET AL., 2022">
      <data key="d4">9.0</data>
      <data key="d5">Wei et al., 2022 introduced Chain-of-thought (CoT) prompting</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="THOUGHTS Z">
      <data key="d4">9.0</data>
      <data key="d5">Chain-of-thought (CoT) prompting involves creating intermediate thoughts z to act as stepping stones between the input and the output</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MULTI-STEP DECOMPOSITION" target="LEAST-TO-MOST PROMPTING">
      <data key="d4">8.0</data>
      <data key="d5">Multi-step decomposition is used in least-to-most prompting</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="DFS">
      <data key="d4">8.0</data>
      <data key="d5">DFS is used in tree-of-thought (ToT) prompting</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="BFS">
      <data key="d4">8.0</data>
      <data key="d5">BFS is used in tree-of-thought (ToT) prompting</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="LM-GENERATED HEURISTIC">
      <data key="d4">1.0</data>
      <data key="d5">An LM-generated heuristic is used in tree-of-thought (ToT) prompting</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="LANGUAGE MODELS (LMS)">
      <data key="d4">9.0</data>
      <data key="d5">Tree-of-thought (ToT) prompting is a technique used to improve the reasoning capabilities of language models</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="YAO ET AL., 2023A">
      <data key="d4">9.0</data>
      <data key="d5">Yao et al., 2023a introduced Tree-of-thought (ToT) prompting</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REASONING VIA PLANNING (RAP)" target="ROLLOUTS">
      <data key="d4">8.0</data>
      <data key="d5">Rollouts are used in reasoning via planning (RAP) with Monte Carlo Tree Search (MCTS)</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="DFS" target="TOT">
      <data key="d4">7.0</data>
      <data key="d5">DFS is a base search algorithm used in the ToT method for HotPotQA</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="DFS" target="MCTS">
      <data key="d4">18.0</data>
      <data key="d5">MCTS (Monte Carlo Tree Search) is compared to DFS (Depth-First Search) as a more principled search algorithm. Both MCTS and DFS are search algorithms, but MCTS is often highlighted for its structured and methodical approach in contrast to the more straightforward, exhaustive nature of DFS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="ROBOTICS" target="CONTROL POLICIES">
      <data key="d4">8.0</data>
      <data key="d5">Control policies are used in robotics</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MULTIMODAL GAMES" target="MINECRAFT">
      <data key="d4">8.0</data>
      <data key="d5">Minecraft is a complex multimodal game</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="REFLEXION" target="SELF-IMPROVEMENT">
      <data key="d4">8.0</data>
      <data key="d5">Reflexion is a self-improvement technique</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="REFLEXION" target="SELF-REFINE">
      <data key="d4">16.0</data>
      <data key="d5">Both Self-Refine and Reflexion use self-improvement to enhance reasoning and decision-making in language models</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REFLEXION" target="ADAPLANNER">
      <data key="d4">12.0</data>
      <data key="d5">AdaPlanner and Reflexion are methods aimed at enhancing reasoning and decision-making in language models</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REFLEXION" target="LANGUAGE MODELS (LMS)">
      <data key="d4">8.0</data>
      <data key="d5">Reflexion is a technique used to improve the decision-making capabilities of language models</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REFLEXION" target="SHINN ET AL., 2023">
      <data key="d4">9.0</data>
      <data key="d5">Shinn et al., 2023 introduced Reflexion</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REFLEXION" target="PROMPT METHOD">
      <data key="d4">8.0</data>
      <data key="d5">Reflexion is one of the prompt methods used in the experiments</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="REFLEXION" target="EXTERNAL RETRIEVAL">
      <data key="d4">7.0</data>
      <data key="d5">External Retrieval strategies are evaluated using Reflexion</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="TRAJECTORIES" target="VALUE FUNCTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The Value Function Prompt provides instructions for analyzing the trajectories of a solution to a question-answering task</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="TRAJECTORIES" target="REFLECTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The Reflection Prompt provides instructions for analyzing the trajectories of a solution to a question-answering task</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="TRAJECTORIES" target="THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">Trajectories include thoughts that reason about the current situation</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="TRAJECTORIES" target="ACTION">
      <data key="d4">8.0</data>
      <data key="d5">Trajectories include actions that can be of three types: Search[entity], Lookup[keyword], or Finish[answer]</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="TRAJECTORIES" target="OBSERVATION">
      <data key="d4">8.0</data>
      <data key="d5">Trajectories include observations about the situation</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="COT" target="LM AGENT">
      <data key="d4">7.0</data>
      <data key="d5">CoT is used as the base prompting framework in environments without feedback for LM Agent</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="COT" target="COT-SC">
      <data key="d4">13.0</data>
      <data key="d5">COT and COT-SC are methods used to prompt the FM to think step by step before answering a question. COT-SC is a variant of the Chain of Thought (CoT) prompting method.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="COT" target="INTERNAL REASONING">
      <data key="d4">7.0</data>
      <data key="d5">Internal Reasoning strategies are evaluated using CoT and its variants</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="COT" target="GAME OF 24">
      <data key="d4">14.0</data>
      <data key="d5">CoT is used as the base prompting design in the Game of 24 experiments</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="COT" target="GPT-3.5-TURBO">
      <data key="d4">8.0</data>
      <data key="d5">CoT shows the performance of GPT-3.5-turbo when answering directly without using RAG</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="COT" target="ORCA-2.5-7B">
      <data key="d4">8.0</data>
      <data key="d5">CoT shows the performance of Orca-2.5-7B when answering directly without using RAG</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="COT" target="MISTRAL-7B-INSTRUCT-V0.1">
      <data key="d4">8.0</data>
      <data key="d5">CoT shows the performance of Mistral-7B-Instruct-v0.1 when answering directly without using RAG</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="COT" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">CoT shows the performance of Orca-3-7B when answering directly without using RAG</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="SELF-REFINE" target="ADAPLANNER">
      <data key="d4">12.0</data>
      <data key="d5">AdaPlanner and Self-Refine are methods aimed at enhancing reasoning and decision-making in language models</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="SELF-REFINE" target="REFLECTION">
      <data key="d4">7.0</data>
      <data key="d5">Self-Refine is a technique related to reflection</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="SELF-REFINE" target="CHAIN-OF-THOUGHT">
      <data key="d4">10.0</data>
      <data key="d5">Both Chain-of-Thought and Self-Refine are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="SELF-REFINE" target="COT-SC">
      <data key="d4">10.0</data>
      <data key="d5">Both COT-SC and Self-Refine are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="SELF-REFINE" target="LLM DEBATE">
      <data key="d4">10.0</data>
      <data key="d5">Both Self-Refine and LLM Debate are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="SELF-REFINE" target="STEP-BACK ABSTRACTION">
      <data key="d4">10.0</data>
      <data key="d5">Both Self-Refine and Step-back Abstraction are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="SELF-REFINE" target="ROLE ASSIGNMENT">
      <data key="d4">10.0</data>
      <data key="d5">Both Self-Refine and Role Assignment are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="SELF-REFINE" target="ARC">
      <data key="d4">12.0</data>
      <data key="d5">Self-Refine is a baseline used for experiments on ARC</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="SELF-REFINE" target="PHYSICS CRITIC">
      <data key="d4">8.0</data>
      <data key="d5">Physics Critic is a unique role assigned to a critic module in Self-Refine</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="SELF-REFINE" target="CHEMISTRY CRITIC">
      <data key="d4">8.0</data>
      <data key="d5">Chemistry Critic is a unique role assigned to a critic module in Self-Refine</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="SELF-REFINE" target="BIOLOGY CRITIC">
      <data key="d4">8.0</data>
      <data key="d5">Biology Critic is a unique role assigned to a critic module in Self-Refine</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="SELF-REFINE" target="GENERAL CRITIC">
      <data key="d4">8.0</data>
      <data key="d5">General Critic is a unique role assigned to a critic module in Self-Refine</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="SELF-REFINE" target="FINAL DECISION">
      <data key="d4">8.0</data>
      <data key="d5">Final Decision is a role assigned to a module in Self-Refine to make the final decision based on all inputs</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="EXTERNAL TOOLS" target="LM AGENT">
      <data key="d4">7.0</data>
      <data key="d5">External tools are used in reasoning tasks as part of the action space</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="TREE-BASED SEARCH" target="MCTS">
      <data key="d4">16.0</data>
      <data key="d5">MCTS is a tree-based search algorithm used to fully unlock the potential of language models</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="TREE-BASED SEARCH" target="SWIECHOWSKI">
      <data key="d4">18.0</data>
      <data key="d5">Swiechowski has worked on tree-based search algorithms</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="MCTS" target="LM TASKS">
      <data key="d4">7.0</data>
      <data key="d5">LM tasks can conveniently reset to any step, which mitigates the major shortcoming of MCTS</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="EXPLORATION WEIGHT">
      <data key="d4">7.0</data>
      <data key="d5">Exploration weight is a parameter used in the MCTS algorithm</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="PARENT NODE">
      <data key="d4">7.0</data>
      <data key="d5">Parent node is a component of the MCTS tree</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="VALUE FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">Value function is used in MCTS to evaluate the desirability of a state</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="ENVIRONMENT MODEL">
      <data key="d4">8.0</data>
      <data key="d5">Environment model is required by MCTS to undo previous steps and form a searching tree</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="A*">
      <data key="d4">18.0</data>
      <data key="d5">MCTS is compared to A* as a more principled search algorithm. Both MCTS (Monte Carlo Tree Search) and A* are search algorithms, but MCTS is often highlighted for its principled approach in various applications.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="XIE" target="BEAM SEARCH">
      <data key="d4">18.0</data>
      <data key="d5">Xie has worked on Beam Search techniques</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LAVALLE" target="PLANNING ALGORITHMS">
      <data key="d4">18.0</data>
      <data key="d5">LaValle has worked on planning algorithms</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="HAFNER" target="REINFORCEMENT LEARNING">
      <data key="d4">18.0</data>
      <data key="d5">Hafner has worked on reinforcement learning algorithms</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="DU" target="REINFORCEMENT LEARNING">
      <data key="d4">18.0</data>
      <data key="d5">Du has worked on reinforcement learning algorithms</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="DU" target="LLM DEBATE">
      <data key="d4">22.0</data>
      <data key="d5">Du is an author associated with the LLM Debate, a state-of-the-art hand-designed agent technique developed in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="VODOPIVEC" target="ENVIRONMENT MODELS">
      <data key="d4">18.0</data>
      <data key="d5">Vodopivec has worked on environment models for tree-based search</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="TOT" target="PROMPT METHOD">
      <data key="d4">8.0</data>
      <data key="d5">ToT is one of the prompt methods used in the experiments</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="RAP" target="LANGUAGE MODELS (LMS)">
      <data key="d4">8.0</data>
      <data key="d5">RAP is a technique used to improve the reasoning capabilities of language models</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="HAO ET AL., 2023">
      <data key="d4">9.0</data>
      <data key="d5">Hao et al., 2023 introduced RAP</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="PROMPT METHOD">
      <data key="d4">8.0</data>
      <data key="d5">RAP is one of the prompt methods used in the experiments</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">ADAS involves search algorithms that can include reinforcement learning</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SCHICK" target="TOOL USE">
      <data key="d4">24.0</data>
      <data key="d5">Schick is an author who has significantly contributed to the development of tool use in agentic systems, as noted in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="INPUT X" target="PROMPT">
      <data key="d4">9.0</data>
      <data key="d5">A prompt is provided along with the input x to improve reasoning in language models</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="INPUT X" target="OUTPUT Y">
      <data key="d4">9.0</data>
      <data key="d5">Input x is transformed into output y by the language model</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)" target="VALUE FUNCTION V(S)">
      <data key="d4">9.0</data>
      <data key="d5">UCT uses the value function V(s) to select the best child node for expansion</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)" target="EXPLORATION WEIGHT W">
      <data key="d4">9.0</data>
      <data key="d5">UCT uses the exploration weight w to balance exploration and exploitation</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="EXPANSION" target="PARENT NODE P">
      <data key="d4">9.0</data>
      <data key="d5">Expansion explores multiple children states from the parent node p</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="EXPANSION" target="CHILD NODE S">
      <data key="d4">9.0</data>
      <data key="d5">Expansion explores child node s from the parent node</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="EXPANSION" target="SELECTION">
      <data key="d4">7.0</data>
      <data key="d5">Selection is followed by Expansion in the LATS process</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="EXPANSION" target="EVALUATION">
      <data key="d4">7.0</data>
      <data key="d5">Expansion is followed by Evaluation in the LATS process</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="EXPANSION" target="AGENTINSTRUCT FLOW">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct Flow includes expansion as a text modification task</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SELECTION" target="CHILD NODE S">
      <data key="d4">1.0</data>
      <data key="d5">Selection chooses the child node s with the highest UCT value for expansion</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="SELECTION" target="UCT ALGORITHM">
      <data key="d4">8.0</data>
      <data key="d5">The UCT algorithm is used in the Selection operation of LATS to balance exploration and exploitation</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="BACKPROPAGATION" target="RETURN R">
      <data key="d4">9.0</data>
      <data key="d5">Return r is used in the backpropagation step of Monte Carlo Tree Search (MCTS) to update the value function of nodes</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="BACKPROPAGATION" target="SIMULATION">
      <data key="d4">7.0</data>
      <data key="d5">Simulation is followed by Backpropagation in the LATS process</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="BACKPROPAGATION" target="REFLECTION">
      <data key="d4">7.0</data>
      <data key="d5">Backpropagation is followed by Reflection in the LATS process</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="BACKPROPAGATION" target="RETURN">
      <data key="d4">8.0</data>
      <data key="d5">Return is used in the backpropagation process to update the value function</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="RETURN R" target="VALUE FUNCTION V(S)">
      <data key="d4">9.0</data>
      <data key="d5">Value function V(s) is updated using the return r in the backpropagation step of Monte Carlo Tree Search (MCTS)</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="PROMPT" target="THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">Thought is an action used in the Prompt technique in HotPotQA</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PROMPT" target="ACTION">
      <data key="d4">8.0</data>
      <data key="d5">Action is an action used in the Prompt technique in HotPotQA</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PROMPT" target="OBSERVATION">
      <data key="d4">8.0</data>
      <data key="d5">Observation is an action used in the Prompt technique in HotPotQA</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PROMPT" target="FINISH">
      <data key="d4">8.0</data>
      <data key="d5">Finish is an action used in the Prompt technique in HotPotQA</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PROMPT" target="META AGENT">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent uses the prompt to guide its output and improve the quality of the generated code</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="PROMPT" target="FM MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module constructs the prompt by concatenating all input Info objects</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="PROMPT" target="APPENDIX">
      <data key="d4">6.0</data>
      <data key="d5">The appendix contains details about how the prompt is constructed</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="PROMPT" target="SYSTEM PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The system prompt is part of the generated prompt</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="PROMPT" target="USER PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The user prompt is part of the generated prompt</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="PROMPT" target="TIKTOK VIDEO">
      <data key="d4">7.0</data>
      <data key="d5">A prompt may ask the model to generate a TikTok video from a scientific paper</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PROMPT" target="SCIENTIFIC PAPER">
      <data key="d4">7.0</data>
      <data key="d5">A prompt may ask the model to generate a TikTok video from a scientific paper</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PROMPT" target="LEGAL CONTRACT">
      <data key="d4">7.0</data>
      <data key="d5">A prompt may ask the model to generate a legal contract from a Wikipedia page</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PROMPT" target="WIKIPEDIA PAGE">
      <data key="d4">7.0</data>
      <data key="d5">A prompt may ask the model to generate a legal contract from a Wikipedia page</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="LM TASKS" target="HISTORICAL TEXT INPUT">
      <data key="d4">7.0</data>
      <data key="d5">Historical text input is used in LM tasks to reset to any step</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="BASE PROMPTING FRAMEWORK">
      <data key="d4">7.0</data>
      <data key="d5">Base prompting framework is the initial design framework for LM Agent</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="OBSERVATION">
      <data key="d4">7.0</data>
      <data key="d5">Observation is the input received by an agent from the environment</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="ACTION">
      <data key="d4">7.0</data>
      <data key="d5">Action is the output taken by an agent following a policy</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="POLICY">
      <data key="d4">7.0</data>
      <data key="d5">Policy is a strategy used by an agent to determine actions</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="LANGUAGE REPRESENTATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Language representations are leveraged by LM Agent for decision-making</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="ACTION SPACE">
      <data key="d4">7.0</data>
      <data key="d5">Action space is the set of all possible actions an agent can take</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="REASONING TRACES">
      <data key="d4">7.0</data>
      <data key="d5">Reasoning traces are used to formalize decisions by organizing information</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="TRAJECTORY">
      <data key="d4">7.0</data>
      <data key="d5">Trajectory is a sequence of actions or reasoning paths sampled by an agent</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="EVALUATION" target="SIMULATION">
      <data key="d4">7.0</data>
      <data key="d5">Evaluation is followed by Simulation in the LATS process</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="EVALUATION" target="SCALAR VALUE">
      <data key="d4">7.0</data>
      <data key="d5">Scalar value is assigned to each new child node during evaluation</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="EVALUATION" target="HEURISTIC">
      <data key="d4">7.0</data>
      <data key="d5">Heuristic is used to steer the search algorithm during evaluation</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="EVALUATION" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B was evaluated on various benchmarks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="EVALUATION" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">Mistral-7B-Instruct was evaluated on various benchmarks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="EVALUATION" target="GEMINI PRO">
      <data key="d4">7.0</data>
      <data key="d5">Gemini Pro was evaluated on various benchmarks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="EVALUATION" target="GPT-3.5-TURBO">
      <data key="d4">8.0</data>
      <data key="d5">GPT-3.5-turbo was used for comparison in various evaluations</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="EVALUATION" target="LLAMA3-8B-INSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">LLAMA3-8B-instruct was evaluated on various benchmarks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="EVALUATION" target="ORCA-2.5">
      <data key="d4">8.0</data>
      <data key="d5">Orca 2.5 was evaluated on various benchmarks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="REFLECTION" target="STATUS: FAIL">
      <data key="d4">8.0</data>
      <data key="d5">The user reflects on the unsuccessful attempt</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="REFLECTION" target="ACTION">
      <data key="d4">7.0</data>
      <data key="d5">Reflection is an action taken by the user during the search process</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="REFLECTION" target="SELF-REFLECTION">
      <data key="d4">8.0</data>
      <data key="d5">Reflection is part of the self-reflection process</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="VALUE FUNCTION" target="REWARD">
      <data key="d4">8.0</data>
      <data key="d5">Value function is a component that influences the Reward metric in WebShop</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="VALUE FUNCTION" target="SELF-CONSISTENCY TERM">
      <data key="d4">8.0</data>
      <data key="d5">Self-consistency term is an attribute that validates the design of the Value function in the Game of 24</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="OBSERVATION" target="SMOKED BACON SEA SALT 3-PACK">
      <data key="d4">6.0</data>
      <data key="d5">The observation action notes the details of the Smoked Bacon Sea Salt 3-Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="OBSERVATION" target="SPICY HOT PEPPER SEA SALT 3-PACK">
      <data key="d4">1.0</data>
      <data key="d5">The observation action notes the details of the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="OBSERVATION" target="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK">
      <data key="d4">6.0</data>
      <data key="d5">The observation action notes the details of the Louisville Vegan Jerky 5 Flavor Variety Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="OBSERVATION" target="SEARCH RESULTS">
      <data key="d4">6.0</data>
      <data key="d5">The observation action notes the search results</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="OBSERVATION" target="ACTION">
      <data key="d4">7.0</data>
      <data key="d5">Observation is an action taken by the user during the search process</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="ACTION" target="THINK">
      <data key="d4">7.0</data>
      <data key="d5">Think is an action taken by the user during the search process</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="ACTION" target="CLICK[NEXT &gt;]">
      <data key="d4">7.0</data>
      <data key="d5">Click[Next &gt;] is an action taken by the user during the search process</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="ACTION" target="CLICK[ &lt;BACK TO SEARCH]">
      <data key="d4">7.0</data>
      <data key="d5">Click[ &lt;Back to Search] is an action taken by the user during the search process</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="TRAJECTORY" target="EVENT">
      <data key="d4">1.0</data>
      <data key="d5">Trajectory is an event in the user's search process</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="TREE SEARCH" target="STATE">
      <data key="d4">7.0</data>
      <data key="d5">State is a representation of the current situation in the tree search</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AUSTIN" target="MBPP DATASET">
      <data key="d4">7.0</data>
      <data key="d5">Austin has worked on the MBPP dataset</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="SELF-REFLECTION" target="AI PYTHON ASSISTANT">
      <data key="d4">8.0</data>
      <data key="d5">The AI Python assistant engages in self-reflection to identify issues and improvements in its previous implementations</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="SELF-REFLECTION" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">16.0</data>
      <data key="d5">Self-Reflection is a building block used within agentic systems in the research area of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SELF-REFLECTION" target="META AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent performs self-reflection to review and improve its generated code</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="INTERESTINGNESS">
      <data key="d4">8.0</data>
      <data key="d5">Interestingness is assessed during the self-reflection process</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPLEMENTATION MISTAKES">
      <data key="d4">8.0</data>
      <data key="d5">Implementation Mistakes are identified during the self-reflection process</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="CHAIN-OF-THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">Self-Reflection implementation example uses the Chain-of-Thought technique</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-REFLECTION" target="COT_INITIAL_INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">Self-Reflection implementation example includes the cot_initial_instruction for initial reasoning</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-REFLECTION" target="COT_REFLECT_INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">Self-Reflection implementation example includes the cot_reflect_instruction for reflecting on previous attempts and feedback</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-REFLECTION" target="CRITIC_INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">Self-Reflection implementation example includes the critic_instruction for providing feedback and correcting the answer</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-REFLECTION" target="CODE 2">
      <data key="d4">9.0</data>
      <data key="d5">Code 2 is an example of implementing self-reflection using the provided framework</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GAME OF 24" target="EXPERIMENTS">
      <data key="d4">7.0</data>
      <data key="d5">Experiments evaluate the applicability of LATS on the Game of 24 dataset</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GAME OF 24" target="SUCCESS RATE">
      <data key="d4">8.0</data>
      <data key="d5">Success Rate is a metric used in the Game of 24</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="GAME OF 24" target="PROMPT METHOD">
      <data key="d4">8.0</data>
      <data key="d5">Prompt Method is a technique used in the Game of 24</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="GAME OF 24" target="ITERATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Iterations are attributes used in the Game of 24</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="COT-SC" target="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d4">7.0</data>
      <data key="d5">COT-SC is a technique related to chain-of-thought-based planning and reasoning methods</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="COT-SC" target="CHAIN-OF-THOUGHT">
      <data key="d4">10.0</data>
      <data key="d5">Both Chain-of-Thought and COT-SC are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="COT-SC" target="LLM DEBATE">
      <data key="d4">10.0</data>
      <data key="d5">Both COT-SC and LLM Debate are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="COT-SC" target="STEP-BACK ABSTRACTION">
      <data key="d4">10.0</data>
      <data key="d5">Both COT-SC and Step-back Abstraction are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="COT-SC" target="ROLE ASSIGNMENT">
      <data key="d4">10.0</data>
      <data key="d5">Both COT-SC and Role Assignment are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="IL" target="RL">
      <data key="d4">7.0</data>
      <data key="d5">IL and RL are used in combination for training language models</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="IL" target="FURUTA">
      <data key="d4">6.0</data>
      <data key="d5">Furuta has worked on fine-tuning methods that involve IL</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="RL" target="FURUTA">
      <data key="d4">6.0</data>
      <data key="d5">Furuta has worked on fine-tuning methods that involve RL</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="FURUTA" target="FINE-TUNING">
      <data key="d4">24.0</data>
      <data key="d5">Furuta has made significant contributions to the field of fine-tuning methods for language models. As one of the authors involved in this area of research, Furuta's work has been instrumental in advancing the understanding and application of fine-tuning techniques, which are crucial for optimizing the performance of language models.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="EXPERT" target="WEBSHOP DATASET">
      <data key="d4">8.0</data>
      <data key="d5">Expert performance is used as a benchmark in the WebShop dataset</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH" target="VALUE FUNCTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">Language Agent Tree Search uses the Value Function Prompt to evaluate the correctness of purchasing trajectories</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH" target="REFLECTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">Language Agent Tree Search uses the Reflection Prompt to improve its reasoning and planning capabilities</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="PERFORMANCE" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B's performance was assessed on various benchmarks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PERFORMANCE" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">Mistral-7B-Instruct's performance was assessed on various benchmarks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PERFORMANCE" target="GEMINI PRO">
      <data key="d4">7.0</data>
      <data key="d5">Gemini Pro's performance was assessed on various benchmarks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PERFORMANCE" target="LLAMA3-8B-INSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">LLAMA3-8B-instruct's performance was assessed on various benchmarks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PERFORMANCE" target="ORCA-2.5">
      <data key="d4">8.0</data>
      <data key="d5">Orca 2.5's performance was assessed on various benchmarks</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PROMPTING TECHNIQUES" target="STEP-BACK ABSTRACTION">
      <data key="d4">7.0</data>
      <data key="d5">Step-back Abstraction is a technique related to prompting techniques</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="PROMPTING TECHNIQUES" target="SCHULHOFF">
      <data key="d4">8.0</data>
      <data key="d5">Schulhoff is an author associated with prompting techniques, 2024</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="SUCCESS RATE" target="REWARD">
      <data key="d4">8.0</data>
      <data key="d5">Success Rate is a metric that depends on the Reward metric in WebShop</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="FAILED TRAJECTORIES" target="VALUE FUNCTION PROMPT">
      <data key="d4">6.0</data>
      <data key="d5">The Value Function Prompt includes failed trajectories as examples</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="FAILED TRAJECTORIES" target="REFLECTION PROMPT">
      <data key="d4">6.0</data>
      <data key="d5">The Reflection Prompt includes failed trajectories as examples</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="QUOC LE" target="OLIVIER BOUSQUET">
      <data key="d4">16.0</data>
      <data key="d5">Olivier Bousquet and Quoc Le co-authored the paper "Least-to-most prompting enables complex reasoning in large language models" published in ICLR 2022</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="QUOC LE" target="ED CHI">
      <data key="d4">16.0</data>
      <data key="d5">Quoc Le and Ed Chi co-authored the paper "Least-to-most prompting enables complex reasoning in large language models" published in ICLR 2022</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="JEFF CLUNE" target="SHENGRAN HU">
      <data key="d4">16.0</data>
      <data key="d5">Shengran Hu and Jeff Clune co-authored the paper "Automated Design of Agentic Systems"</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="CONG LU">
      <data key="d4">16.0</data>
      <data key="d5">Cong Lu and Jeff Clune co-authored the paper "Automated Design of Agentic Systems"</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d4">18.0</data>
      <data key="d5">Jeff Clune is affiliated with the University of British Columbia</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="VECTOR INSTITUTE">
      <data key="d4">18.0</data>
      <data key="d5">Jeff Clune is affiliated with the Vector Institute</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="CANADA CIFAR AI CHAIR">
      <data key="d4">18.0</data>
      <data key="d5">Jeff Clune is affiliated with the Canada CIFAR AI Chair</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="JENNY ZHANG">
      <data key="d4">16.0</data>
      <data key="d5">Jenny Zhang and Jeff Clune co-authored the paper "OMNI: Open-endedness via models of human notions of interestingness" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JEFF CLUNE" target="JOEL LEHMAN">
      <data key="d4">16.0</data>
      <data key="d5">Joel Lehman and Jeff Clune co-authored the paper "OMNI: Open-endedness via models of human notions of interestingness" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JEFF CLUNE" target="KENNETH STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Kenneth Stanley and Jeff Clune co-authored the paper "OMNI: Open-endedness via models of human notions of interestingness" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ARXIV" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">18.0</data>
      <data key="d5">The paper "Automated Design of Agentic Systems" is published on arXiv</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AAKANKSHA CHOWDHERY" target="MIRAC SUZGUN">
      <data key="d4">8.0</data>
      <data key="d5">Mirac Suzgun and Aakanksha Chowdhery co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AAKANKSHA CHOWDHERY" target="NATHAN SCALES">
      <data key="d4">8.0</data>
      <data key="d5">Nathan Scales and Aakanksha Chowdhery co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="HYUNG WON CHUNG" target="MIRAC SUZGUN">
      <data key="d4">8.0</data>
      <data key="d5">Mirac Suzgun and Hyung Won Chung co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="HYUNG WON CHUNG" target="NATHAN SCALES">
      <data key="d4">8.0</data>
      <data key="d5">Nathan Scales and Hyung Won Chung co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="SEBASTIAN GEHRMANN" target="MIRAC SUZGUN">
      <data key="d4">8.0</data>
      <data key="d5">Mirac Suzgun and Sebastian Gehrmann co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="SEBASTIAN GEHRMANN" target="NATHAN SCALES">
      <data key="d4">8.0</data>
      <data key="d5">Nathan Scales and Sebastian Gehrmann co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="LUYU GAO" target="AMAN MADAAN">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Luyu Gao co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="NIKET TANDON">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Niket Tandon co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="PRAKHAR GUPTA">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Prakhar Gupta co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="SKYLER HALLINAN">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Skyler Hallinan co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="SARAH WIEGREFFE">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Sarah Wiegreffe co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="URI ALON">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Uri Alon co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="NOUHA DZIRI">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Nouha Dziri co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="SHRIMAI PRABHUMOYE">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Shrimai Prabhumoye co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="YIMING YANG">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Yiming Yang co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="SHASHANK GUPTA">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Shashank Gupta co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="BODHISATTWA PRASAD MAJUMDER">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Bodhisattwa Prasad Majumder co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="KATHERINE HERMANN">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Katherine Hermann co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="SEAN WELLECK">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Sean Welleck co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="AMAN MADAAN" target="AMIR YAZDANBAKHSH">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Amir Yazdanbakhsh co-authored the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS 2023</data>
      <data key="d6">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </edge>
    <edge source="YAXI LU" target="YUSHENG SU">
      <data key="d4">8.0</data>
      <data key="d5">Yusheng Su and Yaxi Lu co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YAXI LU" target="JINGWEI ZUO">
      <data key="d4">8.0</data>
      <data key="d5">Jingwei Zuo and Yaxi Lu co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="XIANG CHEN">
      <data key="d4">16.0</data>
      <data key="d5">Yuchen Zhuang and Xiang Chen co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="TONG YU">
      <data key="d4">16.0</data>
      <data key="d5">Yuchen Zhuang and Tong Yu co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="SAAYAN MITRA">
      <data key="d4">16.0</data>
      <data key="d5">Yuchen Zhuang and Saayan Mitra co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="VICTOR BURSZTYN">
      <data key="d4">16.0</data>
      <data key="d5">Yuchen Zhuang and Victor Bursztyn co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="RYAN A. ROSSI">
      <data key="d4">16.0</data>
      <data key="d5">Yuchen Zhuang and Ryan A. Rossi co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="SOMDEB SARKHEL">
      <data key="d4">16.0</data>
      <data key="d5">Yuchen Zhuang and Somdeb Sarkhel co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="CHAO ZHANG">
      <data key="d4">16.0</data>
      <data key="d5">Yuchen Zhuang and Chao Zhang co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHAO ZHANG" target="XIANG CHEN">
      <data key="d4">16.0</data>
      <data key="d5">Xiang Chen and Chao Zhang co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHAO ZHANG" target="TONG YU">
      <data key="d4">16.0</data>
      <data key="d5">Tong Yu and Chao Zhang co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHAO ZHANG" target="SAAYAN MITRA">
      <data key="d4">16.0</data>
      <data key="d5">Saayan Mitra and Chao Zhang co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHAO ZHANG" target="VICTOR BURSZTYN">
      <data key="d4">16.0</data>
      <data key="d5">Victor Bursztyn and Chao Zhang co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHAO ZHANG" target="RYAN A. ROSSI">
      <data key="d4">16.0</data>
      <data key="d5">Ryan A. Rossi and Chao Zhang co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHAO ZHANG" target="SOMDEB SARKHEL">
      <data key="d4">16.0</data>
      <data key="d5">Somdeb Sarkhel and Chao Zhang co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="JASON WEI" target="MIRAC SUZGUN">
      <data key="d4">8.0</data>
      <data key="d5">Mirac Suzgun and Jason Wei co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ED CHI" target="OLIVIER BOUSQUET">
      <data key="d4">16.0</data>
      <data key="d5">Olivier Bousquet and Ed Chi co-authored the paper "Least-to-most prompting enables complex reasoning in large language models" published in ICLR 2022</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="DENNY ZHOU" target="MIRAC SUZGUN">
      <data key="d4">8.0</data>
      <data key="d5">Mirac Suzgun and Denny Zhou co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="NATHAN SCALES" target="MIRAC SUZGUN">
      <data key="d4">8.0</data>
      <data key="d5">Mirac Suzgun and Nathan Scales co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="NATHAN SCALES" target="NATHANAEL SCH&#196;RLI">
      <data key="d4">8.0</data>
      <data key="d5">Nathan Scales and Nathanael Sch&#228;rli co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="NATHAN SCALES" target="YI TAY">
      <data key="d4">8.0</data>
      <data key="d5">Nathan Scales and Yi Tay co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="NATHAN SCALES" target="QUOC V LE">
      <data key="d4">8.0</data>
      <data key="d5">Nathan Scales and Quoc V Le co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="XIANG CHEN" target="TONG YU">
      <data key="d4">16.0</data>
      <data key="d5">Xiang Chen and Tong Yu co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="XIANG CHEN" target="SAAYAN MITRA">
      <data key="d4">16.0</data>
      <data key="d5">Xiang Chen and Saayan Mitra co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="XIANG CHEN" target="VICTOR BURSZTYN">
      <data key="d4">16.0</data>
      <data key="d5">Xiang Chen and Victor Bursztyn co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="XIANG CHEN" target="RYAN A. ROSSI">
      <data key="d4">16.0</data>
      <data key="d5">Xiang Chen and Ryan A. Rossi co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="XIANG CHEN" target="SOMDEB SARKHEL">
      <data key="d4">16.0</data>
      <data key="d5">Xiang Chen and Somdeb Sarkhel co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TONG YU" target="SAAYAN MITRA">
      <data key="d4">16.0</data>
      <data key="d5">Tong Yu and Saayan Mitra co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TONG YU" target="VICTOR BURSZTYN">
      <data key="d4">16.0</data>
      <data key="d5">Tong Yu and Victor Bursztyn co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TONG YU" target="RYAN A. ROSSI">
      <data key="d4">16.0</data>
      <data key="d5">Tong Yu and Ryan A. Rossi co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TONG YU" target="SOMDEB SARKHEL">
      <data key="d4">16.0</data>
      <data key="d5">Tong Yu and Somdeb Sarkhel co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="SAAYAN MITRA" target="VICTOR BURSZTYN">
      <data key="d4">16.0</data>
      <data key="d5">Saayan Mitra and Victor Bursztyn co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="SAAYAN MITRA" target="RYAN A. ROSSI">
      <data key="d4">16.0</data>
      <data key="d5">Saayan Mitra and Ryan A. Rossi co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="SAAYAN MITRA" target="SOMDEB SARKHEL">
      <data key="d4">16.0</data>
      <data key="d5">Saayan Mitra and Somdeb Sarkhel co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="VICTOR BURSZTYN" target="RYAN A. ROSSI">
      <data key="d4">16.0</data>
      <data key="d5">Victor Bursztyn and Ryan A. Rossi co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="VICTOR BURSZTYN" target="SOMDEB SARKHEL">
      <data key="d4">16.0</data>
      <data key="d5">Victor Bursztyn and Somdeb Sarkhel co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="RYAN A. ROSSI" target="SOMDEB SARKHEL">
      <data key="d4">16.0</data>
      <data key="d5">Ryan A. Rossi and Somdeb Sarkhel co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search" published in ICLR 2023</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="QIN" target="TOOLBENCH">
      <data key="d4">1.0</data>
      <data key="d5">Qin has worked on LM-based environments like ToolBench</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="SEARCH" target="RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">Search is an action that leads to the Results state in WebShop</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="SEARCH" target="DAIRY FREE">
      <data key="d4">6.0</data>
      <data key="d5">The search action includes a criterion for dairy-free products</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH" target="APPLE VARIETY PACK OF CHIPS">
      <data key="d4">6.0</data>
      <data key="d5">The search action includes a criterion for an apple variety pack of chips</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH" target="PRICE LOWER THAN 30.00 DOLLARS">
      <data key="d4">6.0</data>
      <data key="d5">The search action includes a budget constraint of less than $30.00</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH" target="NEXT TIME">
      <data key="d4">7.0</data>
      <data key="d5">The user plans to refine their search criteria next time</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH" target="PREVIOUS TRIAL INSTRUCTION">
      <data key="d4">6.0</data>
      <data key="d5">The previous trial instruction includes a search action</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH" target="CLICK">
      <data key="d4">7.0</data>
      <data key="d5">Click is an action that can be taken after a search to select or navigate to a different page or item</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SEARCH" target="REFINE SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Refine Search is an action taken to narrow down search results to find more relevant products</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SEARCH" target="READING COMPREHENSION">
      <data key="d4">9.0</data>
      <data key="d5">Search is a task in reading comprehension</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LOOKUP" target="INTERACTIVE INFORMATION RETRIEVAL">
      <data key="d4">16.0</data>
      <data key="d5">Lookup is an action within the Interactive Information Retrieval system</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="FINISH" target="INTERACTIVE INFORMATION RETRIEVAL">
      <data key="d4">16.0</data>
      <data key="d5">Finish is an action within the Interactive Information Retrieval system</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)" target="AUSTIN ET AL.">
      <data key="d4">7.0</data>
      <data key="d5">Austin et al. introduced the Mostly Basic Programming Problems (MBPP) benchmark in 2022</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="RESULTS" target="PRODUCT TITLE">
      <data key="d4">7.0</data>
      <data key="d5">Product title is an attribute displayed in the Results state in WebShop</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="RESULTS" target="ITEM">
      <data key="d4">8.0</data>
      <data key="d5">Item is a state that follows the Results state in WebShop</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="OPTION" target="ITEM">
      <data key="d4">7.0</data>
      <data key="d5">Option is an attribute associated with the Item state in WebShop</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="DESC/OVERVIEW" target="ITEM">
      <data key="d4">7.0</data>
      <data key="d5">Desc/Overview is an attribute associated with the Item state in WebShop</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ITEM" target="ITEM-DETAIL">
      <data key="d4">8.0</data>
      <data key="d5">Item-Detail is a state that provides detailed information about the Item state in WebShop</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ITEM-DETAIL" target="EPISODE END">
      <data key="d4">8.0</data>
      <data key="d5">Episode End is a state that follows the Item-Detail state in WebShop</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="THOUGHT" target="INSIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Insights are captured in the "thought" section of the meta agent's output</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="THOUGHT" target="OVERALL IDEA">
      <data key="d4">8.0</data>
      <data key="d5">Overall Idea is described in the "thought" section of the meta agent's output</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="FIRST FOR WOMEN">
      <data key="d4">6.0</data>
      <data key="d5">Both Arthur's Magazine and First for Women are entities mentioned in a HotPotQA example</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="TIMOTHY SHAY ARTHUR">
      <data key="d4">16.0</data>
      <data key="d5">Timothy Shay Arthur is the editor of Arthur's Magazine.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="EDGAR A. POE">
      <data key="d4">7.0</data>
      <data key="d5">Edgar A. Poe is an author whose work was featured in Arthur's Magazine</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="J.H. INGRAHAM">
      <data key="d4">7.0</data>
      <data key="d5">J.H. Ingraham is an author whose work was featured in Arthur's Magazine</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="SARAH JOSEPHA HALE">
      <data key="d4">7.0</data>
      <data key="d5">Sarah Josepha Hale is an author whose work was featured in Arthur's Magazine</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="THOMAS G. SPEAR">
      <data key="d4">7.0</data>
      <data key="d5">Thomas G. Spear is an author whose work was featured in Arthur's Magazine</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="GODEY'S LADY'S BOOK">
      <data key="d4">16.0</data>
      <data key="d5">Arthur's Magazine was merged into Godey's Lady's Book in May 1846</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="FIRST FOR WOMEN" target="BAUER MEDIA GROUP">
      <data key="d4">8.0</data>
      <data key="d5">Bauer Media Group is the publisher of First for Women</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="FIRST FOR WOMEN" target="ENGLEWOOD CLIFFS">
      <data key="d4">7.0</data>
      <data key="d5">Englewood Cliffs is the location where First for Women is based</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="FIRST FOR WOMEN" target="CIRCULATION">
      <data key="d4">7.0</data>
      <data key="d5">Circulation is an attribute associated with First for Women</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="COLORADO OROGENY" target="HIGH PLAINS">
      <data key="d4">8.0</data>
      <data key="d5">Both Colorado orogeny and High Plains are entities mentioned in a HotPotQA exampleHigh Plains is a region affected by the Colorado orogeny</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="HIGH PLAINS" target="ELEVATION">
      <data key="d4">1.0</data>
      <data key="d5">Elevation is an attribute associated with the High Plains</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="BACK TO SEARCH" target="SEARCH RESULTS">
      <data key="d4">5.0</data>
      <data key="d5">The Back to Search option allows navigation back to the search page</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="INSTRUCTIONS" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Instructions are iteratively refined in the Instruction Refinement Flow</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="HOTPOTQA PROMPTS" target="BASE ACTING PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">Base Acting Prompt is a technique used in HotPotQA Prompts</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="HOTPOTQA PROMPTS" target="BASE REASONING PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">Base Reasoning Prompt is a technique used in HotPotQA Prompts</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="HOTPOTQA PROMPTS" target="VALUE FUNCTION PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">Value Function Prompt is a technique used in HotPotQA Prompts</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="SEARCH[ENTITY]">
      <data key="d4">7.0</data>
      <data key="d5">The Value Function Prompt includes the action Search[entity] as one of the types of actions</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="LOOKUP[KEYWORD]">
      <data key="d4">7.0</data>
      <data key="d5">The Value Function Prompt includes the action Lookup[keyword] as one of the types of actions</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="FINISH[ANSWER]">
      <data key="d4">7.0</data>
      <data key="d5">The Value Function Prompt includes the action Finish[answer] as one of the types of actions</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="CORRECTNESS SCORE">
      <data key="d4">7.0</data>
      <data key="d5">The Value Function Prompt instructs to conclude with a correctness score from 1 to 10</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="EXAMPLES">
      <data key="d4">6.0</data>
      <data key="d5">The Value Function Prompt includes examples to illustrate correct or failed solutions</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="CONTEXT">
      <data key="d4">6.0</data>
      <data key="d5">The Value Function Prompt provides context for the question-answering task</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="SEARCH[ENTITY]" target="REFLECTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The Reflection Prompt includes the action Search[entity] as one of the types of actions</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="LOOKUP[KEYWORD]" target="REFLECTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The Reflection Prompt includes the action Lookup[keyword] as one of the types of actions</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="FINISH[ANSWER]" target="REFLECTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The Reflection Prompt includes the action Finish[answer] as one of the types of actions</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="REFLECTION PROMPT" target="CORRECTNESS SCORE">
      <data key="d4">7.0</data>
      <data key="d5">The Reflection Prompt instructs to conclude with a correctness score from 1 to 10</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="REFLECTION PROMPT" target="EXAMPLES">
      <data key="d4">6.0</data>
      <data key="d5">The Reflection Prompt includes examples to illustrate correct or failed solutions</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="REFLECTION PROMPT" target="CONTEXT">
      <data key="d4">6.0</data>
      <data key="d5">The Reflection Prompt provides context for the question-answering task</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="REFLECTION PROMPT" target="AI PYTHON ASSISTANT">
      <data key="d4">9.0</data>
      <data key="d5">The Reflection Prompt instructs the AI Python assistant to explain why a function implementation is wrong based on unit test results</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="HUMANEVAL FUNCTION IMPLEMENTATION EXAMPLE" target="BASE ACTING/REASONING PROMPT">
      <data key="d4">1.0</data>
      <data key="d5">The HumanEval function implementation example is part of the Base Acting/Reasoning Prompt</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="BASE ACTING/REASONING PROMPT" target="UNIT TEST RESULTS">
      <data key="d4">1.0</data>
      <data key="d5">The Base Acting/Reasoning Prompt includes unit test results to evaluate the correctness of a function implementation</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="BASE ACTING/REASONING PROMPT" target="AI PYTHON ASSISTANT">
      <data key="d4">9.0</data>
      <data key="d5">The Base Acting/Reasoning Prompt provides instructions for the AI Python assistant to write a full implementation of a function</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="EXAMPLES" target="ARC CHALLENGE">
      <data key="d4">1.0</data>
      <data key="d5">The Examples document provides examples of tasks from the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="UNIT TEST RESULTS" target="AI PYTHON ASSISTANT">
      <data key="d4">8.0</data>
      <data key="d5">The AI Python assistant uses unit test results to verify the correctness of its function implementations</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="UNIT TEST RESULTS" target="UNIT TEST">
      <data key="d4">9.0</data>
      <data key="d5">Unit test results are the outcomes of running unit tests on the add function</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="AI PYTHON ASSISTANT" target="FUNCTION IMPLEMENTATION">
      <data key="d4">9.0</data>
      <data key="d5">The AI Python assistant is responsible for writing function implementations</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="AI PYTHON ASSISTANT" target="TEST CASE GENERATION PROMPT">
      <data key="d4">9.0</data>
      <data key="d5">The Test Case Generation Prompt instructs the AI Python assistant to write unique, diverse, and intuitive unit tests for functions</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="WEBSHOP PROMPTS" target="WEB SHOP">
      <data key="d4">8.0</data>
      <data key="d5">WebShop Prompts provide instructions for interacting with the WebShop platform</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ACTING PROMPT" target="WEB SHOP">
      <data key="d4">8.0</data>
      <data key="d5">The Acting Prompt provides instructions for performing actions in the WebShop</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="EARTH MAMA">
      <data key="d4">18.0</data>
      <data key="d5">Bright Citrus Deodorant is a product by Earth Mama. Earth Mama is the brand that produces the Bright Citrus Deodorant.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="BRIGHT CITRUS">
      <data key="d4">9.0</data>
      <data key="d5">Bright citrus is the scent attribute of the Bright Citrus Deodorant</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="SENSITIVE SKIN">
      <data key="d4">9.0</data>
      <data key="d5">Bright Citrus Deodorant is suitable for sensitive skin</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="PRICE">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant has a price attribute</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="3 OUNCE">
      <data key="d4">9.0</data>
      <data key="d5">Bright Citrus Deodorant is available in a 3-ounce size</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="ASSORTED SCENTS">
      <data key="d4">8.0</data>
      <data key="d5">Assorted Scents is a product option for the Bright Citrus Deodorant by Earth Mama</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="TRAVEL SET (4-PACK)">
      <data key="d4">8.0</data>
      <data key="d5">Travel Set (4-Pack) is a product option for the Bright Citrus Deodorant by Earth Mama</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="3 OUNCE (PACK OF 1)">
      <data key="d4">8.0</data>
      <data key="d5">3 Ounce (Pack of 1) is a product option for the Bright Citrus Deodorant by Earth Mama</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="GINGER FRESH">
      <data key="d4">8.0</data>
      <data key="d5">Ginger Fresh is a scent option for the Bright Citrus Deodorant by Earth Mama</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="CALMING LAVENDER">
      <data key="d4">8.0</data>
      <data key="d5">Calming Lavender is a scent option for the Bright Citrus Deodorant by Earth Mama</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="SIMPLY NON-SCENTS">
      <data key="d4">8.0</data>
      <data key="d5">Simply Non-Scents is a scent option for the Bright Citrus Deodorant by Earth Mama</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="EARTH MAMA" target="GINGER FRESH DEODORANT">
      <data key="d4">9.0</data>
      <data key="d5">Ginger Fresh Deodorant is a product by Earth Mama</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="GINGER FRESH DEODORANT" target="SENSITIVE SKIN">
      <data key="d4">9.0</data>
      <data key="d5">Ginger Fresh Deodorant is suitable for sensitive skin</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="GINGER FRESH DEODORANT" target="PRICE">
      <data key="d4">8.0</data>
      <data key="d5">Ginger Fresh Deodorant has a price attribute</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="GINGER FRESH DEODORANT" target="3 OUNCE">
      <data key="d4">9.0</data>
      <data key="d5">Ginger Fresh Deodorant is available in a 3-ounce size</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BARREL AND OAK" target="CEDAR &amp; PATCHOULI BLEND DEODORANT">
      <data key="d4">1.0</data>
      <data key="d5">Cedar &amp; Patchouli Blend Deodorant is a product by Barrel and Oak</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="CEDAR &amp; PATCHOULI BLEND DEODORANT" target="SENSITIVE SKIN">
      <data key="d4">9.0</data>
      <data key="d5">Cedar &amp; Patchouli Blend Deodorant is gentle on sensitive skin</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="CEDAR &amp; PATCHOULI BLEND DEODORANT" target="PRICE">
      <data key="d4">8.0</data>
      <data key="d5">Cedar &amp; Patchouli Blend Deodorant has a price attribute</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="CEDAR &amp; PATCHOULI BLEND DEODORANT" target="3 OUNCE">
      <data key="d4">1.0</data>
      <data key="d5">Cedar &amp; Patchouli Blend Deodorant is available in a 3-ounce size</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="MIN SUM" target="CURRENT SUM">
      <data key="d4">7.0</data>
      <data key="d5">Min sum is updated based on the value of current sum during the iteration in the code snippet</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="CURRENT SUM" target="NUMS">
      <data key="d4">8.0</data>
      <data key="d5">Current sum is calculated by adding elements from the nums list</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="UNIT TEST">
      <data key="d4">9.0</data>
      <data key="d5">The add function is tested using unit tests to verify its correctness</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ENJOY LIFE FOODS" target="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS">
      <data key="d4">1.0</data>
      <data key="d5">Enjoy Life Foods produces the Dairy Free and Apple Variety Pack of Chips</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE FOODS" target="ENJOY LIFE FOODS SOFT BAKED OVALS">
      <data key="d4">18.0</data>
      <data key="d5">Enjoy Life Foods is the company that produces the Enjoy Life Foods Soft Baked Ovals. Enjoy Life Foods Soft Baked Ovals is a product offered by Enjoy Life Foods.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE FOODS" target="ENJOY LIFE SOFT BAKED CHEWY BARS">
      <data key="d4">18.0</data>
      <data key="d5">Enjoy Life Foods is the company that produces the Enjoy Life Soft Baked Chewy Bars. Enjoy Life Soft Baked Chewy Bars is a product offered by Enjoy Life Foods.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE FOODS" target="ENJOY LIFE LENTIL CHIPS VARIETY PACK">
      <data key="d4">18.0</data>
      <data key="d5">Enjoy Life Foods is the company that produces the Enjoy Life Lentil Chips Variety Pack. The Enjoy Life Lentil Chips Variety Pack is a product offered by Enjoy Life Foods.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE FOODS SOFT BAKED OVALS" target="DAIRY FREE">
      <data key="d4">8.0</data>
      <data key="d5">The Enjoy Life Foods Soft Baked Ovals are dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE FOODS SOFT BAKED OVALS" target="THINK">
      <data key="d4">5.0</data>
      <data key="d5">The user reflects that the Enjoy Life Foods Soft Baked Ovals are not what they want</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE SOFT BAKED CHEWY BARS" target="DAIRY FREE">
      <data key="d4">8.0</data>
      <data key="d5">The Enjoy Life Soft Baked Chewy Bars are dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE SOFT BAKED CHEWY BARS" target="PRICE LOWER THAN 30.00 DOLLARS">
      <data key="d4">9.0</data>
      <data key="d5">The Enjoy Life Soft Baked Chewy Bars are priced at $21.49, which is within the budget constraint</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE SOFT BAKED CHEWY BARS" target="THINK">
      <data key="d4">5.0</data>
      <data key="d5">The user reflects that the Enjoy Life Soft Baked Chewy Bars are not what they want</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="DILL AND SOUR CREAM">
      <data key="d4">8.0</data>
      <data key="d5">Dill and Sour Cream is a flavor option for the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="GARLIC &amp; PARMESAN">
      <data key="d4">8.0</data>
      <data key="d5">Garlic &amp; Parmesan is a flavor option for the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="LIGHT SEA SALT">
      <data key="d4">8.0</data>
      <data key="d5">Light Sea Salt is a flavor option for the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="MARGHERITA PIZZA">
      <data key="d4">8.0</data>
      <data key="d5">Margherita Pizza is a flavor option for the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="THAI CHILI LIME">
      <data key="d4">8.0</data>
      <data key="d5">Thai Chili Lime is a flavor option for the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="VARIETY PACK">
      <data key="d4">8.0</data>
      <data key="d5">Variety Pack is a flavor option for the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="0.8 OUNCE (PACK OF 24)">
      <data key="d4">8.0</data>
      <data key="d5">0.8 Ounce (Pack of 24) is a size option for the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="4 OUNCE (PACK OF 12)">
      <data key="d4">1.0</data>
      <data key="d5">4 Ounce (Pack of 12) is a size option for the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="DAIRY FREE">
      <data key="d4">8.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack is dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="APPLE VARIETY PACK OF CHIPS">
      <data key="d4">7.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack includes apple-flavored chips</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="THINK">
      <data key="d4">7.0</data>
      <data key="d5">The user reflects that the Enjoy Life Lentil Chips Variety Pack is what they want</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="CLICK">
      <data key="d4">8.0</data>
      <data key="d5">The user clicks on the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="FLAVOR NAME">
      <data key="d4">7.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has multiple flavor options</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="DESCRIPTION">
      <data key="d4">6.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has a description section</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="FEATURES">
      <data key="d4">6.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has a features section</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="REVIEWS">
      <data key="d4">6.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has a reviews section</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="RATING: N.A.">
      <data key="d4">5.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack does not have a rating</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="THINK[THE FIRST TWO ITEMS ARE NOT WHAT I WANT. THE THIRD ITEM IS THE DAIRY FREE AND APPLE VARIETY PACK OF CHIPS I WANT.]">
      <data key="d4">8.0</data>
      <data key="d5">The user reflects that the Enjoy Life Lentil Chips Variety Pack is the desired product</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="THINK[THE ITEM HAS OPTIONS &#8216;VARIETY PACK&#8217; AND &#8216;0.8 OUNCE (PACK OF 24)&#8217; AND SEEMS GOOD TO BUY.]">
      <data key="d4">8.0</data>
      <data key="d5">The user reflects that the Enjoy Life Lentil Chips Variety Pack seems good to buy</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="CLICK[B008D2X8C4]">
      <data key="d4">8.0</data>
      <data key="d5">The user clicks on the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="VARIETY PACK" target="CLICK">
      <data key="d4">7.0</data>
      <data key="d5">The user clicks on the variety pack option for the Enjoy Life Lentil Chips</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="VARIETY PACK" target="CLICK[VARIETY PACK]">
      <data key="d4">7.0</data>
      <data key="d5">The user clicks on the variety pack option for the Enjoy Life Lentil Chips</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="0.8 OUNCE (PACK OF 24)" target="CLICK">
      <data key="d4">7.0</data>
      <data key="d5">The user clicks on the 0.8 ounce (pack of 24) option for the Enjoy Life Lentil Chips</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="0.8 OUNCE (PACK OF 24)" target="CLICK[0.8 OUNCE (PACK OF 24)]">
      <data key="d4">7.0</data>
      <data key="d5">The user clicks on the 0.8 ounce (pack of 24) option for the Enjoy Life Lentil Chips</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="BUY NOW" target="CLICK">
      <data key="d4">9.0</data>
      <data key="d5">The user clicks on the Buy Now option to purchase the product</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="BUY NOW" target="CLICK[BUY NOW]">
      <data key="d4">9.0</data>
      <data key="d5">The user clicks on the Buy Now option to purchase the product</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="SMOKED BACON SEA SALT 3-PACK">
      <data key="d4">6.0</data>
      <data key="d5">The Smoked Bacon Sea Salt 3-Pack is a potential alternative to the gluten-free vegetarian smoked peppered bacon</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="SPICY HOT PEPPER SEA SALT 3-PACK">
      <data key="d4">6.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is a potential alternative to the gluten-free vegetarian smoked peppered bacon</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK">
      <data key="d4">6.0</data>
      <data key="d5">The Louisville Vegan Jerky 5 Flavor Variety Pack is a potential alternative to the gluten-free vegetarian smoked peppered bacon</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SMOKED BACON SEA SALT 3-PACK" target="THINK">
      <data key="d4">5.0</data>
      <data key="d5">The user reflects that the Smoked Bacon Sea Salt 3-Pack is not what they want</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="THINK">
      <data key="d4">5.0</data>
      <data key="d5">The user reflects that the Spicy Hot Pepper Sea Salt 3-Pack is not what they want</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="NON-GMO">
      <data key="d4">8.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as Non-GMO</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="GHOST PEPPER">
      <data key="d4">8.0</data>
      <data key="d5">Ghost Pepper is one of the flavors included in the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="JALAPENO">
      <data key="d4">8.0</data>
      <data key="d5">Jalapeno is one of the flavors included in the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="HABANERO">
      <data key="d4">8.0</data>
      <data key="d5">Habanero is one of the flavors included in the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="GLUTEN-FREE">
      <data key="d4">8.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as Gluten-Free</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="KOSHER">
      <data key="d4">8.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as Kosher</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="NO MSG">
      <data key="d4">8.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as No MSG</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="B07GJTKYJQ">
      <data key="d4">8.0</data>
      <data key="d5">The product with code B07GJTKYJQ is the Spicy Hot Pepper Sea Salt 3-Pack</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="12 TOTAL OZ.">
      <data key="d4">8.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack weighs 12 total ounces</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="29.99">
      <data key="d4">8.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is priced at 29.99</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="THINK">
      <data key="d4">5.0</data>
      <data key="d5">The user reflects that the Louisville Vegan Jerky 5 Flavor Variety Pack is not what they want</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="CLICK">
      <data key="d4">6.0</data>
      <data key="d5">The user clicks on the Louisville Vegan Jerky 5 Flavor Variety Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="THINK[THE FIRST TWO ITEMS ARE NOT WHAT I WANT. THE THIRD ITEM IS NOT WHAT I WANT, BUT IT IS THE CLOSEST ONE.]">
      <data key="d4">7.0</data>
      <data key="d5">The user reflects that the Louisville Vegan Jerky 5 Flavor Variety Pack is the closest match</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="THINK[THE PRICE IS TOO HIGH AND IT IS NOT WHAT I WANT.]">
      <data key="d4">7.0</data>
      <data key="d5">The user reflects that the price of the Louisville Vegan Jerky 5 Flavor Variety Pack is too high and it is not what is wanted</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="CLICK[B07GJTKYJQ]">
      <data key="d4">7.0</data>
      <data key="d5">The user clicks on the Louisville Vegan Jerky 5 Flavor Variety Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="OBSERVATION[&lt;PREV] LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK, NON-GMO SOY PROTEIN, GLUTEN-FREE (BLACK PEPPER, BUFFALO DILL, PEPPERONI, MAPLE BACON, AND CAROLINA BBQ, 3 OUNCES) PRICE: $42.99 RATING: N.A. [DESCRIPTION] [FEATURES] [REVIEWS] [BUY NOW]">
      <data key="d4">6.0</data>
      <data key="d5">The observation action notes the details of the Louisville Vegan Jerky 5 Flavor Variety Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="NON-GMO">
      <data key="d4">8.0</data>
      <data key="d5">The Louisville Vegan Jerky - 5 Flavor Variety Pack is labeled as Non-GMO</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="GLUTEN-FREE">
      <data key="d4">8.0</data>
      <data key="d5">The Louisville Vegan Jerky - 5 Flavor Variety Pack is labeled as Gluten-Free</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="42.99">
      <data key="d4">8.0</data>
      <data key="d5">The Louisville Vegan Jerky - 5 Flavor Variety Pack is priced at 42.99</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="3 OUNCES">
      <data key="d4">8.0</data>
      <data key="d5">Each pack in the Louisville Vegan Jerky - 5 Flavor Variety Pack weighs 3 ounces</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK" target="NON-GMO SOY PROTEIN">
      <data key="d4">8.0</data>
      <data key="d5">The Louisville Vegan Jerky - 5 Flavor Variety Pack is made with Non-GMO Soy Protein</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="CLICK" target="PREV">
      <data key="d4">5.0</data>
      <data key="d5">The user clicks on the Prev option to navigate back to the previous page of search results</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="STATUS: FAIL" target="RESULT">
      <data key="d4">7.0</data>
      <data key="d5">Status: Fail is the result of the user's search attempt</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="NEXT TIME" target="SEARCH[&quot;VARIETY PACK OF CHIPS&quot;]">
      <data key="d4">7.0</data>
      <data key="d5">The user plans to refine their search criteria next time by searching for "variety pack of chips"</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH RESULTS" target="PAGE 1">
      <data key="d4">5.0</data>
      <data key="d5">The search results are displayed on page 1</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH RESULTS" target="TOTAL RESULTS: 50">
      <data key="d4">5.0</data>
      <data key="d5">The search results include a total of 50 results</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH RESULTS" target="NEXT &gt;">
      <data key="d4">5.0</data>
      <data key="d5">The Next option allows navigation to the next page of search results</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH RESULTS" target="PREV">
      <data key="d4">5.0</data>
      <data key="d5">The Prev option allows navigation to the previous page of search results</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH RESULTS" target="OBSERVATION[BACK TO SEARCH]">
      <data key="d4">5.0</data>
      <data key="d5">The observation action notes the navigation back to the search page</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH RESULTS" target="OBSERVATION[PAGE 1 (TOTAL RESULTS: 50)]">
      <data key="d4">5.0</data>
      <data key="d5">The observation action notes that the search results are displayed on page 1 with a total of 50 results</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH[DAIRY FREE AND APPLE VARIETY PACK OF CHIPS]" target="OBSERVATION[BACK TO SEARCH] PAGE 1 (TOTAL RESULTS: 50) [NEXT &gt;] [B07HRFJWP8] ENJOY LIFE FOODS SOFT BAKED OVALS, BREAKFAST BARS, NUT FREE BARS, SOY FREE, DAIRY FREE, NON GMO, GLUTEN FREE, VEGAN, VARIETY PACK, 4 BOXES(20 BARS TOTAL) $100.0 [B01KMHY5PG] ENJOY LIFE SOFT BAKED CHEWY BARS, VARIETY PACK, NUT FREE BARS, SOY FREE, DAIRY FREE, GLUTEN FREE, 6 BOXES (30 TOTAL BARS) $21.49 [B008D2X8C4] ENJOY LIFE LENTIL CHIPS VARIETY PACK, DAIRY FREE CHIPS, SOY FREE, NUT FREE, NON GMO, VEGAN, GLUTEN FREE, 24 BAGS (0.8 OZ) $100.0">
      <data key="d4">8.0</data>
      <data key="d5">The search action for dairy-free and apple variety pack of chips resulted in a list of products including Enjoy Life Foods Soft Baked Ovals, Enjoy Life Soft Baked Chewy Bars, and Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SEARCH[GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON 4 OUNCE PACK OF 2]" target="OBSERVATION[BACK TO SEARCH] PAGE 1 (TOTAL RESULTS: 50) [NEXT &gt;] [B06Y96MXJV] SMOKED BACON SEA SALT 3-PACK: SMOKED BACON CHIPOTLE, SMOKED BACON AND ONION, SMOKED PEPPERED BACON - ALL-NATURAL SEA SALTS SLOWLY SMOKED OVER ALDERWOOD - NO GLUTEN, NO MSG, NON-GMO (12 TOTAL OZ.) $29.99 [B06Y96N1KG] SPICY HOT PEPPER SEA SALT 3-PACK: GHOST PEPPER, JALAPENO, HABANERO - ALL NATURAL, DELICIOUS BLENDS OF PEPPERS &amp; SEA SALT - GLUTEN-FREE, KOSHER, NO MSG, NON-GMO (12 TOTAL OZ.) $29.99 [B07GJTKYJQ] LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK, NON-GMO SOY PROTEIN, GLUTEN-FREE (BLACK PEPPER, BUFFALO DILL, PEPPERONI, MAPLE BACON, AND CAROLINA BBQ, 3 OUNCES) $42.99">
      <data key="d4">8.0</data>
      <data key="d5">The search action for gluten-free vegetarian smoked peppered bacon resulted in a list of products including Smoked Bacon Sea Salt 3-Pack, Spicy Hot Pepper Sea Salt 3-Pack, and Louisville Vegan Jerky 5 Flavor Variety Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="THINK[THE FIRST TWO ITEMS ARE NOT WHAT I WANT. THE THIRD ITEM IS THE DAIRY FREE AND APPLE VARIETY PACK OF CHIPS I WANT.]" target="OBSERVATION[OK.]">
      <data key="d4">6.0</data>
      <data key="d5">The observation action notes the user's reflection on the suitability of the search results</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="THINK[THE ITEM HAS OPTIONS &#8216;VARIETY PACK&#8217; AND &#8216;0.8 OUNCE (PACK OF 24)&#8217; AND SEEMS GOOD TO BUY.]" target="OBSERVATION[OK.]">
      <data key="d4">6.0</data>
      <data key="d5">The observation action notes the user's reflection on the suitability of the product options</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="THINK[THE FIRST TWO ITEMS ARE NOT WHAT I WANT. THE THIRD ITEM IS NOT WHAT I WANT, BUT IT IS THE CLOSEST ONE.]" target="OBSERVATION[OK.]">
      <data key="d4">6.0</data>
      <data key="d5">The observation action notes the user's reflection on the suitability of the search results</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="THINK[THE PRICE IS TOO HIGH AND IT IS NOT WHAT I WANT.]" target="OBSERVATION[OK.]">
      <data key="d4">6.0</data>
      <data key="d5">The observation action notes the user's reflection on the suitability of the product</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="CLICK[&lt;PREV]" target="OBSERVATION[BACK TO SEARCH] [&lt;PREV] LOUISVILLE VEGAN JERKY - 5 FLAVOR VARIETY PACK, NON-GMO SOY PROTEIN, GLUTEN-FREE (BLACK PEPPER, BUFFALO DILL, PEPPERONI, MAPLE BACON, AND CAROLINA BBQ, 3 OUNCES) PRICE: $42.99 RATING: N.A. [DESCRIPTION] [FEATURES] [REVIEWS] [BUY NOW]">
      <data key="d4">6.0</data>
      <data key="d5">The user clicks on the Prev option to navigate back to the previous page of search results</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="NON-GMO" target="B06Y96N1KG">
      <data key="d4">8.0</data>
      <data key="d5">The product with code B06Y96N1KG is labeled as Non-GMO</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="BLACK PEPPER">
      <data key="d4">8.0</data>
      <data key="d5">Black Pepper is one of the flavors included in the Louisville Vegan Jerky variety pack</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="BUFFALO DILL">
      <data key="d4">8.0</data>
      <data key="d5">Buffalo Dill is one of the flavors included in the Louisville Vegan Jerky variety pack</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="PEPPERONI">
      <data key="d4">8.0</data>
      <data key="d5">Pepperoni is one of the flavors included in the Louisville Vegan Jerky variety pack</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="MAPLE BACON">
      <data key="d4">8.0</data>
      <data key="d5">Maple Bacon is one of the flavors included in the Louisville Vegan Jerky variety pack</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="CAROLINA BBQ">
      <data key="d4">8.0</data>
      <data key="d5">Carolina BBQ is one of the flavors included in the Louisville Vegan Jerky variety pack</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="VEGETARIAN BACON" target="GLUTEN-FREE">
      <data key="d4">6.0</data>
      <data key="d5">Vegetarian Bacon is a product that the user intends to search for, and it must fulfill the gluten-free constraint</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="VEGETARIAN BACON" target="4 OUNCE PACK OF 2">
      <data key="d4">1.0</data>
      <data key="d5">Vegetarian Bacon is a product that the user intends to search for, and it must fulfill the 4 ounce pack of 2 constraint</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="PREVIOUS TRIAL" target="EVENT">
      <data key="d4">7.0</data>
      <data key="d5">Previous trial is an event in the user's search process</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SHENGRAN HU" target="CONG LU">
      <data key="d4">16.0</data>
      <data key="d5">Shengran Hu and Cong Lu co-authored the paper "Automated Design of Agentic Systems"</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d4">18.0</data>
      <data key="d5">Shengran Hu is affiliated with the University of British Columbia</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="VECTOR INSTITUTE">
      <data key="d4">18.0</data>
      <data key="d5">Shengran Hu is affiliated with the Vector Institute</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="GITHUB">
      <data key="d4">33.0</data>
      <data key="d5">Shengran Hu is associated with the GitHub platform, where they have made significant contributions to the field of Automated Design of Agentic Systems (ADAS). Shengran Hu has a GitHub repository dedicated to ADAS, and they have made the full framework code available on this platform, facilitating access and collaboration within the AI and ML communities.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SHENGRAN HU" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">Shengran Hu is associated with the ADAS project and has made all related resources available on GitHub</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="CONG LU" target="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d4">18.0</data>
      <data key="d5">Cong Lu is affiliated with the University of British Columbia</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONG LU" target="VECTOR INSTITUTE">
      <data key="d4">18.0</data>
      <data key="d5">Cong Lu is affiliated with the Vector Institute</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="VECTOR INSTITUTE" target="ADAS">
      <data key="d4">16.0</data>
      <data key="d5">The Vector Institute supported the work on ADAS</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="FOUNDATION MODELS (FMS)">
      <data key="d4">16.0</data>
      <data key="d5">Foundation Models (FMs) are used as modules within agentic systems in the research area of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="CHAIN-OF-THOUGHT">
      <data key="d4">16.0</data>
      <data key="d5">Chain-of-Thought is a building block used within agentic systems in the research area of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="TOOLFORMER">
      <data key="d4">16.0</data>
      <data key="d5">Toolformer is a module used within agentic systems in the research area of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="AUTOML">
      <data key="d4">16.0</data>
      <data key="d5">AutoML methods are related to the research area of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">16.0</data>
      <data key="d5">AI-Generating Algorithms (AI-GAs) are related to the research area of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="GITHUB">
      <data key="d4">18.0</data>
      <data key="d5">The code for the Automated Design of Agentic Systems (ADAS) can be found on GitHub</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="ROCKT&#196;SCHEL">
      <data key="d4">16.0</data>
      <data key="d5">Rockt&#228;schel contributed to the development of agentic systems in the research area of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="ZAHARIA">
      <data key="d4">16.0</data>
      <data key="d5">Zaharia contributed to the development of agentic systems in the research area of Automated Design of Agentic Systems (ADAS)</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="CLAUDE">
      <data key="d4">18.0</data>
      <data key="d5">Claude is an example of a Foundation Model</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="AGENTIC SYSTEMS">
      <data key="d4">1.0</data>
      <data key="d5">Foundation Models (FMs) are used as modules in the control flow of agentic systems</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="META AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent queries Foundation Models (FMs) to perform tasks and format prompts</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="CLAUDE" target="ANTHROPIC">
      <data key="d4">18.0</data>
      <data key="d5">Anthropic developed the Claude Foundation Model</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="HU">
      <data key="d4">16.0</data>
      <data key="d5">Hu contributed to the development of chain-of-thought planning and reasoning</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="CLUNE">
      <data key="d4">16.0</data>
      <data key="d5">Clune contributed to the development of chain-of-thought planning and reasoning</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought is a technique related to chain-of-thought-based planning and reasoning methods</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="LLM DEBATE">
      <data key="d4">10.0</data>
      <data key="d5">Both Chain-of-Thought and LLM Debate are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="STEP-BACK ABSTRACTION">
      <data key="d4">10.0</data>
      <data key="d5">Both Chain-of-Thought and Step-back Abstraction are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="ROLE ASSIGNMENT">
      <data key="d4">10.0</data>
      <data key="d5">Both Chain-of-Thought and Role Assignment are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="FM_MODULE">
      <data key="d4">17.0</data>
      <data key="d5">CHAIN-OF-THOUGHT is a process handled by the FM_MODULE. The FM_MODULE uses the Chain-of-Thought technique for step-by-step reasoning. This technique is integral to the FM_MODULE's functionality, enabling it to break down complex problems into manageable steps, thereby enhancing its reasoning capabilities.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7,d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="COT MODULE">
      <data key="d4">1.0</data>
      <data key="d5">cot_module is an instance of the FM_Module class used for Chain-of-Thought reasoning</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="HOG" target="CONVOLUTIONAL NEURAL NETWORKS (CNNS)">
      <data key="d4">18.0</data>
      <data key="d5">HOG features were eventually replaced by learned features from Convolutional Neural Networks</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HOG" target="DALAL">
      <data key="d4">16.0</data>
      <data key="d5">Dalal contributed to the development of HOG features in computer vision</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HOG" target="TRIGGS">
      <data key="d4">16.0</data>
      <data key="d5">Triggs contributed to the development of HOG features in computer vision</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONVOLUTIONAL NEURAL NETWORKS (CNNS)" target="NEURAL ARCHITECTURE SEARCH">
      <data key="d4">18.0</data>
      <data key="d5">Neural Architecture Search is a method that led to the best-performing Convolutional Neural Networks</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONVOLUTIONAL NEURAL NETWORKS (CNNS)" target="KRIZHEVSKY">
      <data key="d4">16.0</data>
      <data key="d5">Krizhevsky contributed to the development of Convolutional Neural Networks</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ELSKEN">
      <data key="d4">18.0</data>
      <data key="d5">Elsken is one of the authors who discussed Neural Architecture Search (NAS) in 2019</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">ADAS is related to the research area of Neural Architecture Search</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="AI-GENERATING ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">Neural Architecture Search is a method under the first pillar of AI-Generating Algorithms</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="AUTOML">
      <data key="d4">12.0</data>
      <data key="d5">Neural Architecture Search is a method under the first pillar of AutoML</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AUTOML" target="HUTTER">
      <data key="d4">34.0</data>
      <data key="d5">Hutter is a significant contributor to the development of AutoML methods. In 2019, Hutter was one of the authors who discussed these methods, highlighting his role in advancing the field of automated machine learning.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOML" target="ADAS">
      <data key="d4">21.0</data>
      <data key="d5">ADAS aims to invent novel building blocks and design powerful agentic systems in an automated manner, which aligns with the goals of AutoML. ADAS is related to the research area of AutoML, indicating a strong connection between the two entities in their pursuit of advancing automated machine learning techniques.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AUTOML" target="AI-GENERATING ALGORITHMS">
      <data key="d4">16.0</data>
      <data key="d5">Both AI-Generating Algorithms and AutoML aim to automate the design and learning processes in AI systems</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AUTOML" target="MAML">
      <data key="d4">12.0</data>
      <data key="d5">MAML is a method under the second pillar of AutoML</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AUTOML" target="META-RL">
      <data key="d4">12.0</data>
      <data key="d5">Meta-RL is a method under the second pillar of AutoML</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AUTOML" target="POET">
      <data key="d4">12.0</data>
      <data key="d5">POET is a method under the third pillar of AutoML</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AUTOML" target="OMNI-EPIC">
      <data key="d4">12.0</data>
      <data key="d5">OMNI-EPIC is a method under the third pillar of AutoML</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="CLUNE">
      <data key="d4">2.0</data>
      <data key="d5">Clune contributed to the development of AI-Generating Algorithms</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="GPQA">
      <data key="d4">8.0</data>
      <data key="d5">The Multi-Step Peer Review Agent was discovered during the search in the Reading Comprehension domain (GPQA)</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="MGSM">
      <data key="d4">8.0</data>
      <data key="d5">The Verified Multimodal Agent was discovered during the search in the Math domain (MGSM)</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="VISUAL REPRESENTATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Verified Multimodal Agent uses the Visual Representation Module to generate visual representations of problems</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="VERIFICATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Verified Multimodal Agent uses the Verification Module to verify visual representations</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="CHAIN-OF-THOUGHT MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Verified Multimodal Agent uses the Chain-of-Thought Module to solve problems using verified visual representations</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="GPQA">
      <data key="d4">8.0</data>
      <data key="d5">The Divide and Conquer Agent was discovered during the search in the Reading Comprehension domain (GPQA)</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="DECOMPOSITION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">Decomposition Module is a role assigned to a module in the Divide and Conquer Agent to decompose the problem into sub-problems</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="SPECIALIZED EXPERT">
      <data key="d4">1.0</data>
      <data key="d5">Specialized Expert is a role assigned to a module in the Divide and Conquer Agent to solve sub-problems</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="HU" target="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d4">8.0</data>
      <data key="d5">Hu is an author associated with chain-of-thought-based planning and reasoning methods, 2024</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="HU" target="MULTI-OBJECTIVE ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Hu is mentioned in relation to the concept of Multi-objective ADAS</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="CLUNE" target="AI-GAS">
      <data key="d4">18.0</data>
      <data key="d5">Clune is one of the authors who discussed AI-Generating Algorithms (AI-GAs) in 2019</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="CLUNE" target="ADAS">
      <data key="d4">27.0</data>
      <data key="d5">Clune has made significant contributions to the research area of AI-Generative Algorithms (AI-GAs), which is closely related to Advanced Driver Assistance Systems (ADAS). Clune has discussed the potential of ADAS to accelerate the development of Artificial General Intelligence (AGI), highlighting its importance in the broader AI research community. Clune's work and insights are frequently mentioned in relation to ADAS, underscoring his influence and the interconnectedness of these advanced technologies.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="CLUNE" target="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d4">8.0</data>
      <data key="d5">Clune is an author associated with chain-of-thought-based planning and reasoning methods, 2024</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="KRIZHEVSKY" target="CNN">
      <data key="d4">18.0</data>
      <data key="d5">Krizhevsky is one of the authors who popularized Convolutional Neural Networks (CNNs) in 2012</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="HUTTER" target="ADAS">
      <data key="d4">5.0</data>
      <data key="d5">Hutter has contributed to the research area of AutoML, which is related to ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="GITHUB" target="ADAS">
      <data key="d4">26.0</data>
      <data key="d5">ADAS is the repository hosted on GitHub. All code, prompts, and experiment results related to the ADAS project are available on GitHub. The full framework code for ADAS is also accessible on GitHub.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,449db721e37968e073e3579b59e023b2,d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="TOOL USE" target="LLM DEBATE">
      <data key="d4">7.0</data>
      <data key="d5">LLM Debate is a technique related to tool use</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="TOOL USE" target="NAKANO">
      <data key="d4">8.0</data>
      <data key="d5">Nakano is an author associated with tool use, 2021</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="TOOL USE" target="AGENTINSTRUCT">
      <data key="d4">2.0</data>
      <data key="d5">Tool Use is one of the skills covered in the synthetic post-training dataset created by AgentInstruct</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="TOOL USE" target="TEXT MODIFICATION">
      <data key="d4">6.0</data>
      <data key="d5">Both Text Modification and Tool Use are skills related to altering or employing text and tools to perform tasks</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TOOL USE" target="WEB AGENT">
      <data key="d4">7.0</data>
      <data key="d5">A web agent is a type of tool used in Tool Use to perform tasks on the web</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TOOL USE" target="CODING">
      <data key="d4">1.0</data>
      <data key="d5">Coding is a skill that often involves the use of tools or APIs to perform tasks</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TOOL USE" target="AGENTINSTRUCT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Tool use is a task in the AgentInstruct Flow that involves enabling models to interact with external tools or services via APIs</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="META AGENT" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent is part of the automated design of agentic systems</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="RUNTIME ERROR">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent performs self-reflection and debugging when a runtime error is encountered</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="PROJECT">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent is part of the project of designing and implementing agentic systems</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="IMPLEMENTATION">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent is responsible for the implementation of agent designs</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="IMPROVEMENT">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent suggests improvements to the agent's implementation</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">The response is the meta agent's output after performing self-reflection and making improvements</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="ERROR DURING EVALUATION">
      <data key="d4">1.0</data>
      <data key="d5">The meta agent performs self-reflection and debugging when an error is encountered during evaluation</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="ARC CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent is designed to generate code solutions for the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="META AGENT" target="GPT-4O-2024-05-13">
      <data key="d4">30.0</data>
      <data key="d5">META AGENT utilizes the GPT-4O-2024-05-13 model.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="META AGENT" target="GPQA">
      <data key="d4">16.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the GPQA benchmark</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="MGSM">
      <data key="d4">16.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the MGSM benchmark</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="MMLU">
      <data key="d4">16.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the MMLU benchmark</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="GPT-3.5-TURBO-0125">
      <data key="d4">14.0</data>
      <data key="d5">The meta agent uses the GPT-3.5-turbo-0125 model to evaluate discovered agents and baselines</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="AI-GAS" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">ADAS is related to the research area of AI-GAs</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LLM ALIGNMENT" target="LU">
      <data key="d4">18.0</data>
      <data key="d5">Lu is one of the authors who discussed learned loss functions in LLM alignment in 2024a</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AI SCIENTIST" target="LU">
      <data key="d4">18.0</data>
      <data key="d5">Lu is one of the authors who discussed the AI Scientist in 2024b</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="OMNI-EPIC" target="AI-GENERATING ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">OMNI-EPIC is a method under the third pillar of AI-Generating Algorithms</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="FERNANDO">
      <data key="d4">24.0</data>
      <data key="d5">Fernando has made significant contributions to the research area of agentic systems, which is related to Advanced Driver Assistance Systems (ADAS). In 2024, Fernando was one of the authors who discussed ADAS methods, particularly focusing on designing prompts. His work in these areas highlights his expertise and influence in the field of AI and ML, particularly in the context of enhancing the functionality and safety of ADAS through innovative prompt design.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="ADAS" target="FOUNDATION MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models are used as modules in the control flow of agentic systems within the research area of ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="PROMPTBREEDER">
      <data key="d4">7.0</data>
      <data key="d5">PromptBreeder is an example of a system that mutates text prompts within the search space of ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="ELSKEN">
      <data key="d4">5.0</data>
      <data key="d5">Elsken has contributed to the research area of Neural Architecture Search, which is related to ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="ZHU">
      <data key="d4">6.0</data>
      <data key="d5">Zhu has contributed to the research area of agentic systems, which is related to ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="AGENTIC SYSTEMS">
      <data key="d4">17.0</data>
      <data key="d5">ADAS, which stands for Automated Design of Agentic Systems, involves the automated design of agentic systems. It is a type of agentic system itself, indicating its dual role in both the creation and functioning within the realm of agentic systems. This highlights ADAS's significance in the field of AI and ML, where it contributes to the development and optimization of intelligent agents.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="GRAPH STRUCTURES">
      <data key="d4">6.0</data>
      <data key="d5">Graph structures are used as a search space in ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="FEED-FORWARD NETWORKS">
      <data key="d4">6.0</data>
      <data key="d5">Feed-forward networks are used as a search space in ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="SEARCH ENGINE TOOLS">
      <data key="d4">13.0</data>
      <data key="d5">ADAS (Advanced Driver Assistance Systems) and search engine tools are closely related in the context of agentic systems. Search engine tools are considered essential building blocks within the ADAS framework, playing a crucial role in enhancing the functionality and efficiency of these systems. They are mentioned as potential components that can significantly contribute to the development and optimization of ADAS, highlighting their importance in the integration and performance of advanced driver assistance technologies.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="FERNANDO ET AL.">
      <data key="d4">6.0</data>
      <data key="d5">Fernando et al. have contributed to the research area of agentic systems, which is related to ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="ZHUGE ET AL.">
      <data key="d4">6.0</data>
      <data key="d5">Zhuge et al. have contributed to the research area of agentic systems, which is related to ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="LIU ET AL.">
      <data key="d4">6.0</data>
      <data key="d5">Liu et al. have contributed to the research area of agentic systems, which is related to ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="SUTTON &amp; BARTO">
      <data key="d4">6.0</data>
      <data key="d5">Sutton &amp; Barto have contributed to the research area of reinforcement learning, which is related to ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="SECTION 6">
      <data key="d4">7.0</data>
      <data key="d5">Section 6 of the document encourages further studies and opens up new research directions in ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="FIGURE 2">
      <data key="d4">7.0</data>
      <data key="d5">Figure 2 of the document illustrates the three key components of ADAS</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="AI-GENERATING ALGORITHMS">
      <data key="d4">15.0</data>
      <data key="d5">ADAS (Automated Design of Agentic Systems) is a proposed research area that aims to invent novel building blocks and design powerful agentic systems in an automated manner. This objective aligns closely with the goals of AI-Generating Algorithms, which focus on creating advanced AI systems through automated processes. ADAS builds on the lessons learned from AI-Generating Algorithms, leveraging their methodologies to further enhance the development of sophisticated, autonomous agents.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="BOSTROM">
      <data key="d4">20.0</data>
      <data key="d5">Bostrom has discussed whether we should pursue Artificial General Intelligence (AGI) and Artificial Intelligence-Generated Art (AI-GA), which includes Advanced Driver Assistance Systems (ADAS). Additionally, Bostrom is mentioned in relation to ADAS, highlighting his involvement in the discourse surrounding the development and ethical considerations of these advanced AI technologies.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="ECOFFET">
      <data key="d4">20.0</data>
      <data key="d5">Ecoffet has discussed whether we should pursue AGI and AI-GA, which includes ADAS. Additionally, Ecoffet is mentioned in relation to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="YUDKOWSKY">
      <data key="d4">8.0</data>
      <data key="d5">Yudkowsky has discussed whether we should pursue AGI (Artificial General Intelligence) and AI-GA (Artificial Intelligence-Generated Algorithms), which includes ADAS. Yudkowsky is also mentioned in relation to ADAS, indicating his involvement or interest in the development and ethical considerations of these advanced AI systems.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="SAFE-ADAS">
      <data key="d4">16.0</data>
      <data key="d5">Safe-ADAS is a subset of ADAS focused on conducting ADAS safely and creating honest, helpful agents</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="HIGHER-ORDER ADAS">
      <data key="d4">14.0</data>
      <data key="d5">Higher-order ADAS is a concept within the broader ADAS framework</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="MULTI-OBJECTIVE ADAS">
      <data key="d4">14.0</data>
      <data key="d5">Multi-objective ADAS is a concept within the broader ADAS framework</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="UNDERSTANDING THE EMERGENCE OF COMPLEXITY FROM HUMAN ORGANIZATIONS">
      <data key="d4">14.0</data>
      <data key="d5">Understanding the emergence of complexity from human organizations is a scientific aspect of ADAS</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="FMS">
      <data key="d4">8.0</data>
      <data key="d5">FMs are used to program ADAS algorithms without expensive hardware like GPUs</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="MULTI-MODAL CAPABILITIES">
      <data key="d4">7.0</data>
      <data key="d5">Multi-modal capabilities are mentioned as potential features for ADAS</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="CANADA CIFAR AI CHAIRS PROGRAM">
      <data key="d4">16.0</data>
      <data key="d5">The Canada CIFAR AI Chairs program supported the work on ADAS</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="SCHMIDT FUTURES">
      <data key="d4">16.0</data>
      <data key="d5">Schmidt Futures provided grants for the work on ADAS</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="OPEN PHILANTHROPY">
      <data key="d4">16.0</data>
      <data key="d5">Open Philanthropy provided grants for the work on ADAS</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="NSERC DISCOVERY GRANT">
      <data key="d4">16.0</data>
      <data key="d5">The NSERC Discovery Grant supported the work on ADAS</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="RAFAEL COSMAN">
      <data key="d4">9.0</data>
      <data key="d5">Rafael Cosman made a generous donation("entity"Rafael Cosman made a generous donation to support the work on ADAS</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="JENNY ZHANG">
      <data key="d4">7.0</data>
      <data key="d5">Jenny Zhang provided insightful discussions and feedback on the work on ADAS</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="RACH PRADHAN">
      <data key="d4">7.0</data>
      <data key="d5">Rach Pradhan provided insightful discussions and feedback on the work on ADAS</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ARC" target="CHOLLET">
      <data key="d4">18.0</data>
      <data key="d5">Chollet is one of the authors who discussed the ARC logic puzzle task in 2019</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="ARC" target="ARC CHALLENGE">
      <data key="d4">9.0</data>
      <data key="d5">ARC is the full name of the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">12.0</data>
      <data key="d5">Chain-of-Thought (COT) is a baseline used for experiments on ARC</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ARC" target="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)">
      <data key="d4">12.0</data>
      <data key="d5">Self-Consistency with Chain-of-Thought (COT-SC) is a baseline used for experiments on ARC</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ARC" target="ORCA-3">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3 is evaluated on the ARC benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ARC" target="ALLENAI">
      <data key="d4">9.0</data>
      <data key="d5">AllenAI developed the AI2 Reasoning Challenge (ARC) benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="DROP" target="DUA">
      <data key="d4">32.0</data>
      <data key="d5">Dua is an author associated with the DROP benchmark for evaluating Reading Comprehension. In 2019, Dua was one of the authors who discussed the DROP reading comprehension task, contributing to the development and analysis of this important benchmark in the field of Natural Language Processing.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="DROP" target="GPT-3.5-TURBO-0125">
      <data key="d4">1.0</data>
      <data key="d5">DROP domain uses GPT-3.5-turbo-0125 for evaluation</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="DROP" target="ONE-SHOT STYLE QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">One-shot style questions are used in the DROP domain</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="DROP" target="ORCA-3">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3 is evaluated on the DROP benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="DROP" target="EXACT MATCH/SPAN EXTRACTION PROBLEMS">
      <data key="d4">8.0</data>
      <data key="d5">DROP is a dataset used for Exact Match/Span Extraction Problems where a ground-truth answer is provided</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="DROP" target="MODEL">
      <data key="d4">8.0</data>
      <data key="d5">The model is evaluated on its ability to generate correct answers in the DROP dataset</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="GSM8K" target="COBBE">
      <data key="d4">26.0</data>
      <data key="d5">GSM8K is a dataset that was discussed in 2021, particularly in the context of math tasks. Cobbe is an author associated with the GSM8K dataset and contributed to the discussions surrounding the GSM8K math task in the same year.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="GSM8K" target="ORCA-3">
      <data key="d4">41.0</data>
      <data key="d5">Orca-3 is evaluated on the GSM8K benchmark, where it demonstrated a 54% improvement compared to Mistral-Instruct-7B. This significant performance enhancement highlights Orca-3's capabilities in comparison to other models on the GSM8K benchmark.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GSM8K" target="GPT-3.5-TURBO">
      <data key="d4">5.0</data>
      <data key="d5">GPT-3.5-turbo's scores for GSM8K are referenced</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GSM8K" target="ORCA-3-7B">
      <data key="d4">14.0</data>
      <data key="d5">GSM8K is used to evaluate the performance of Orca-3-7B on math problems</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GSM8K" target="EXACT MATCH/SPAN EXTRACTION PROBLEMS">
      <data key="d4">8.0</data>
      <data key="d5">GSM8K is a dataset used for Exact Match/Span Extraction Problems involving math-based questions</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="GSM8K" target="MODEL">
      <data key="d4">8.0</data>
      <data key="d5">The model is evaluated on its ability to generate correct answers in the GSM8K dataset</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="PYTHON" target="BOYER">
      <data key="d4">18.0</data>
      <data key="d5">Boyer is one of the authors who discussed the Turing Completeness of Python in 1983</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="PYTHON" target="MOORE">
      <data key="d4">18.0</data>
      <data key="d5">Moore is one of the authors who discussed the Turing Completeness of Python in 1983</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="PYTHON" target="LADHA">
      <data key="d4">18.0</data>
      <data key="d5">Ladha is one of the authors who discussed the Turing Completeness of Python in 2024</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="LU" target="OPEN-ENDEDNESS ALGORITHMS">
      <data key="d4">18.0</data>
      <data key="d5">Lu is one of the authors who discussed open-endedness algorithms in 2024c</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="LU" target="HIGHER-ORDER ADAS">
      <data key="d4">1.0</data>
      <data key="d5">Lu is mentioned in relation to the concept of Higher-order ADAS</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="RAFAILOV" target="FMS">
      <data key="d4">16.0</data>
      <data key="d5">Rafailov has worked on programming the loss function for preference learning in FM alignment training</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FERNANDO" target="PROMPTBREEDER">
      <data key="d4">16.0</data>
      <data key="d5">Fernando has worked on PromptBreeder, a system that adopts FMs to automate prompt engineering for agents</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="CHRISTOPHER CHASE" target="NG">
      <data key="d4">6.0</data>
      <data key="d5">Christopher Chase and Ng have both contributed to the research area of agentic systems</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SUTTON" target="BARTO">
      <data key="d4">1.0</data>
      <data key="d5">Sutton and Barto have both contributed to the research area of reinforcement learning</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SUTTON" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">6.0</data>
      <data key="d5">Sutton is mentioned in relation to novelty search algorithms</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="BARTO" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">6.0</data>
      <data key="d5">Barto is mentioned in relation to novelty search algorithms</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="FUNSEARCH" target="ROMERA-PAREDES">
      <data key="d4">7.0</data>
      <data key="d5">Romera-Paredes has worked on the FunSearch practice mentioned in the Meta Agent Search algorithm</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="CODE" target="FM_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">Code is part of the process generated by the FM_Module</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="CODE" target="THINKING">
      <data key="d4">7.0</data>
      <data key="d5">Thinking and Code are used together as inputs for various modules in the code</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="CODE" target="FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">Code and Feedback are used together to evaluate the performance of solutions</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="CODE" target="THOUGHTS">
      <data key="d4">7.0</data>
      <data key="d5">Thoughts and Code are used together as inputs for various modules in the code</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="READING COMPREHENSION" target="QUESTION ANSWERING">
      <data key="d4">15.0</data>
      <data key="d5">Reading Comprehension and Question Answering are skills related to understanding and processing text. Question Answering is a specific task within the broader domain of Reading Comprehension, highlighting its role in extracting and providing precise information from given texts.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="MULTIPLE CHOICE QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Multiple Choice Questions are often used to assess Reading Comprehension skills</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="DECODING">
      <data key="d4">8.0</data>
      <data key="d5">Decoding is a sub-skill of reading comprehension</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="FLUENCY">
      <data key="d4">8.0</data>
      <data key="d5">Fluency is a sub-skill of reading comprehension</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="VOCABULARY KNOWLEDGE">
      <data key="d4">8.0</data>
      <data key="d5">Vocabulary knowledge is a sub-skill of reading comprehension</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="TEXT PASSAGES">
      <data key="d4">7.0</data>
      <data key="d5">Text passages are used in reading comprehension tests</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Questions are used in reading comprehension tests</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="GROUNDED REASONING">
      <data key="d4">9.0</data>
      <data key="d5">Grounded reasoning is a task in reading comprehension</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="FEEDBACK" target="CRITIC_MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The Critic module provides feedback</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="FEEDBACK" target="FM_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">Feedback is part of the process generated by the FM_Module</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="CORRECT EXAMPLES">
      <data key="d4">7.0</data>
      <data key="d5">Correct Examples are evaluated during the feedback process</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="WRONG EXAMPLES">
      <data key="d4">1.0</data>
      <data key="d5">Wrong Examples are evaluated during the feedback process</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="CORRECT_COUNT">
      <data key="d4">1.0</data>
      <data key="d5">Correct_Count is the number of correct examples passed by the generated code during the feedback process</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="CORRECT_EXAMPLES">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is used to determine Correct_examples</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="WRONG_EXAMPLES">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is used to determine Wrong_examples</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="RUN_EXAMPLES_AND_GET_FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">Run_examples_and_get_feedback is used to obtain Feedback on the code solution</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="VERIFICATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is provided by the Verification Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ARC CHALLENGE" target="GPT-3.5-TURBO-0125">
      <data key="d4">7.0</data>
      <data key="d5">The GPT-3.5-turbo-0125 model is used to evaluate discovered agents and baselines in the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXACT MATCH">
      <data key="d4">7.0</data>
      <data key="d5">Exact Match is the metric used to calculate the accuracy rate in the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="INPUT GRID">
      <data key="d4">9.0</data>
      <data key="d5">Input grids are used as part of the tasks in the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="OUTPUT GRID">
      <data key="d4">9.0</data>
      <data key="d5">Output grids are used as part of the tasks in the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="TRANSFORMATION RULE">
      <data key="d4">9.0</data>
      <data key="d5">The transformation rule is learned from input-output grid examples to predict the output grid for the test example in the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXAMPLE 0">
      <data key="d4">1.0</data>
      <data key="d5">Example 0 is a specific task from the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXAMPLE INPUT-OUTPUT GRID #1">
      <data key="d4">7.0</data>
      <data key="d5">Example Input-Output Grid #1 is used in the ARC challenge to demonstrate transformation rules</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXAMPLE INPUT-OUTPUT GRID #2">
      <data key="d4">7.0</data>
      <data key="d5">Example Input-Output Grid #2 is used in the ARC challenge to demonstrate transformation rules</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="TEST GRID">
      <data key="d4">9.0</data>
      <data key="d5">The Test Grid is used in the ARC challenge to test the AI system's ability to apply learned transformation rules</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXPERIMENT DETAILS FOR ARC CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">The Experiment Details for ARC Challenge document provides detailed information about the experiments conducted for the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="TASK OVERVIEW">
      <data key="d4">8.0</data>
      <data key="d5">The Task Overview document provides an overview of the tasks involved in the ARC challenge</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="CRITIC" target="FM_MODULE">
      <data key="d4">9.0</data>
      <data key="d5">Critic is a process handled by the FM_Module</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="VALIDATION SET" target="GPQA">
      <data key="d4">7.0</data>
      <data key="d5">Validation set is used to validate the performance of solutions in the GPQA domain</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TEST SET" target="GPQA">
      <data key="d4">7.0</data>
      <data key="d5">Test set is used to test the performance of solutions in the GPQA domain</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="MMLU" target="HENDRYCKS">
      <data key="d4">14.0</data>
      <data key="d5">Hendrycks is an author associated with the MMLU benchmark for evaluating Multi-task Problem Solving</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="MMLU" target="ORCA-3">
      <data key="d4">35.0</data>
      <data key="d5">Orca-3 is evaluated on the MMLU benchmark and demonstrated a significant performance improvement. Specifically, Orca-3 showed a 19% improvement on the MMLU benchmark compared to Mistral-Instruct-7B, also referred to as Mistral-7b-Instruct.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MMLU" target="EQBENCH">
      <data key="d4">7.0</data>
      <data key="d5">EQBench has a strong correlation (r=0.97) with comprehensive multi-domain benchmarks like MMLU</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="PHILOSOPHY">
      <data key="d4">6.0</data>
      <data key="d5">Philosophy is one of the 57 academic subjects covered in the MMLU benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="MEDICINE">
      <data key="d4">6.0</data>
      <data key="d5">Medicine is one of the 57 academic subjects covered in the MMLU benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="PSYCHOLOGY">
      <data key="d4">6.0</data>
      <data key="d5">Psychology is one of the 57 academic subjects covered in the MMLU benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="COMPUTER-SCIENCE">
      <data key="d4">6.0</data>
      <data key="d5">Computer Science is one of the 57 academic subjects covered in the MMLU benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="LAW">
      <data key="d4">6.0</data>
      <data key="d5">Law is one of the 57 academic subjects covered in the MMLU benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="ORCA-3-7B">
      <data key="d4">14.0</data>
      <data key="d5">MMLU is used to evaluate the performance of Orca-3-7B on various mathematical tasks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MMLU" target="ABSTRACT ALGEBRA">
      <data key="d4">8.0</data>
      <data key="d5">Abstract Algebra is a sub-task of the MMLU</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MMLU" target="COLLEGE MATHEMATICS">
      <data key="d4">8.0</data>
      <data key="d5">College Mathematics is a sub-task of the MMLU</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MMLU" target="HIGH-SCHOOL MATHEMATICS">
      <data key="d4">1.0</data>
      <data key="d5">High-School Mathematics is a sub-task of the MMLU</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MMLU" target="MIRAGE DATASETS">
      <data key="d4">9.0</data>
      <data key="d5">MMLU is part of the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPQA" target="REIN">
      <data key="d4">15.0</data>
      <data key="d5">Rein is an author associated with the GPQA benchmark, which is designed for evaluating the capability of solving hard, graduate-level questions in Science. Additionally, Rein is involved in the Reading Comprehension domain within the GPQA framework.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPQA" target="GPT-4O-2024-05-13">
      <data key="d4">7.0</data>
      <data key="d5">GPQA domain uses GPT-4o-2024-05-13 for evaluation</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPQA" target="ZERO-SHOT STYLE QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Zero-shot style questions are used in the GPQA domain</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPQA" target="ORCA-3">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3 is evaluated on the GPQA benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GPQA" target="BIOLOGY">
      <data key="d4">6.0</data>
      <data key="d5">Biology is one of the subjects in the GPQA benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPQA" target="CHEMISTRY">
      <data key="d4">6.0</data>
      <data key="d5">Chemistry is one of the subjects in the GPQA benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPQA" target="PHYSICS">
      <data key="d4">6.0</data>
      <data key="d5">Physics is one of the subjects in the GPQA benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="LLM DEBATE" target="STEP-BACK ABSTRACTION">
      <data key="d4">10.0</data>
      <data key="d5">Both LLM Debate and Step-back Abstraction are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LLM DEBATE" target="ROLE ASSIGNMENT">
      <data key="d4">5.0</data>
      <data key="d5">Both LLM Debate and Role Assignment are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="STEP-BACK ABSTRACTION" target="ROLE ASSIGNMENT">
      <data key="d4">5.0</data>
      <data key="d5">Both Step-back Abstraction and Role Assignment are manually designed agents that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="STEP-BACK ABSTRACTION" target="REASONING AND PROBLEM-SOLVING">
      <data key="d4">12.0</data>
      <data key="d5">Step-back Abstraction is a baseline used for experiments on Reasoning and Problem-Solving domains</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES">
      <data key="d4">7.0</data>
      <data key="d5">Role Assignment is a technique related to assigning FM modules in the agentic system with different roles</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="REASONING AND PROBLEM-SOLVING">
      <data key="d4">12.0</data>
      <data key="d5">Role Assignment is a baseline used for experiments on Reasoning and Problem-Solving domains</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="FEEDBACK MECHANISM" target="SEARCH PROGRESS">
      <data key="d4">8.0</data>
      <data key="d5">The search progress reveals the development of the feedback mechanism through various iterations</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="FEEDBACK MECHANISM" target="ITERATION 5">
      <data key="d4">7.0</data>
      <data key="d5">The idea of incorporating diverse feedback emerged in iteration 5</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="FEEDBACK MECHANISM" target="ITERATION 11">
      <data key="d4">7.0</data>
      <data key="d5">The idea of evaluating for various specific traits such as efficiency and simplicity emerged in iteration 11</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="FEEDBACK MECHANISM" target="ITERATION 12">
      <data key="d4">7.0</data>
      <data key="d5">The idea of simulating human-like feedback emerged in iteration 12</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="ITERATION 5" target="MECHANISM">
      <data key="d4">8.0</data>
      <data key="d5">The final mechanism is based on the idea from iteration 5</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="ITERATION 11" target="MECHANISM">
      <data key="d4">8.0</data>
      <data key="d5">The final mechanism is based on the idea from iteration 11</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="ITERATION 12" target="MECHANISM">
      <data key="d4">8.0</data>
      <data key="d5">The final mechanism is based on the idea from iteration 12</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="MECHANISM" target="CROSSOVER">
      <data key="d4">7.0</data>
      <data key="d5">The final mechanism resembles crossover in evolution via LLMs</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="CROSSOVER" target="MEYERSON">
      <data key="d4">7.0</data>
      <data key="d5">Meyerson is an author associated with the concept of crossover in evolution via LLMs</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="REASONING AND PROBLEM-SOLVING DOMAINS" target="EXPERIMENT DETAILS">
      <data key="d4">7.0</data>
      <data key="d5">Experiment Details provide information about the Reasoning and Problem-Solving Domains</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REASONING AND PROBLEM-SOLVING DOMAINS" target="COST OF EXPERIMENTS">
      <data key="d4">7.0</data>
      <data key="d5">Reasoning and Problem-Solving Domains incur a cost of about $300 USD</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="BASELINES" target="GPT-3.5-TURBO-0125">
      <data key="d4">8.0</data>
      <data key="d5">Baselines are evaluated using the GPT-3.5-turbo-0125 model</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="RESULTS AND ANALYSIS" target="FIGURE 3A">
      <data key="d4">7.0</data>
      <data key="d5">Figure 3a is part of the Results and Analysis section</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="SVAMP" target="PATEL">
      <data key="d4">8.0</data>
      <data key="d5">Patel is an author associated with the SVAMP dataset, 2021</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="ASDIV" target="MIAO">
      <data key="d4">8.0</data>
      <data key="d5">Miao is an author associated with the ASDiv dataset, 2020</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="DYNAMIC ROLE-PLAYING ARCHITECTURE" target="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d4">5.0</data>
      <data key="d5">Both Dynamic Role-Playing Architecture and Structured Multimodal Feedback Loop are top agents discovered by Meta Agent Search that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="DYNAMIC ROLE-PLAYING ARCHITECTURE" target="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d4">5.0</data>
      <data key="d5">Both Dynamic Role-Playing Architecture and Interactive Multimodal Feedback Loop are top agents discovered by Meta Agent Search that perform tasks like Math, Reading Comprehension, Multi-task, and Science</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="DEVELOPING NEW SKILLS FOR EMBODIED AGENTS IN CODE" target="VEMPRALA">
      <data key="d4">8.0</data>
      <data key="d5">Vemprala is an author associated with developing new skills for embodied agents in code, 2023</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES" target="HONG">
      <data key="d4">8.0</data>
      <data key="d5">Hong is an author associated with assigning FM modules in the agentic system with different roles, 2023</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES" target="QIAN">
      <data key="d4">8.0</data>
      <data key="d5">Qian is an author associated with assigning FM modules in the agentic system with different roles, 2023, 2024</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="ENABLING THE AGENT TO INSTRUCT ITSELF FOR THE NEXT ACTION" target="RICHARDS">
      <data key="d4">1.0</data>
      <data key="d5">Richards is an author associated with enabling the agent to instruct itself for the next action, 2023</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="MAML">
      <data key="d4">12.0</data>
      <data key="d5">MAML is a method under the second pillar of AI-Generating Algorithms</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="META-RL">
      <data key="d4">12.0</data>
      <data key="d5">Meta-RL is a method under the second pillar of AI-Generating Algorithms</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="POET">
      <data key="d4">12.0</data>
      <data key="d5">POET is a method under the third pillar of AI-Generating Algorithms</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="EUREKA" target="MA">
      <data key="d4">16.0</data>
      <data key="d5">Ma has worked on Eureka, a system that enables FMs to write reward functions for reinforcement learning in robotics</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="EVOAGENT" target="YUAN">
      <data key="d4">16.0</data>
      <data key="d5">Yuan has worked on EvoAgent, a system that optimizes role definition in the prompt</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="GPT-SWARM" target="ZHUGE">
      <data key="d4">16.0</data>
      <data key="d5">Zhuge has worked on GPT-Swarm, a system that represents an agentic system in a graph with a predefined set of nodes and uses a Reinforcement Learning algorithm to optimize the connections</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SAFE-ADAS" target="CALDWELL">
      <data key="d4">6.0</data>
      <data key="d5">Caldwell is mentioned in relation to the concept of Safe-ADAS</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="CONSTITUTIONAL AI" target="BAI">
      <data key="d4">8.0</data>
      <data key="d5">Bai is an author associated with Constitutional AI</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="MULTI-OBJECTIVE ADAS" target="DEB">
      <data key="d4">6.0</data>
      <data key="d5">Deb is mentioned in relation to the concept of Multi-objective ADAS</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NOVELTY SEARCH ALGORITHMS" target="CULLY">
      <data key="d4">6.0</data>
      <data key="d5">Cully is mentioned in relation to novelty search algorithms</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NOVELTY SEARCH ALGORITHMS" target="DEMIRIS">
      <data key="d4">6.0</data>
      <data key="d5">Demiris is mentioned in relation to novelty search algorithms</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NOVELTY SEARCH ALGORITHMS" target="MOURET">
      <data key="d4">6.0</data>
      <data key="d5">Mouret is mentioned in relation to novelty search algorithms</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="HUMAN ORGANIZATIONS">
      <data key="d4">16.0</data>
      <data key="d5">The agentic system operates over natural language, which is used by humans in constructing human organizations and society</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="HUMAN ORGANIZATIONS" target="HONG ET AL.">
      <data key="d4">14.0</data>
      <data key="d5">Hong et al. worked on incorporating the organizational structure for human companies in agents</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="HUMAN ORGANIZATIONS" target="PARK ET AL.">
      <data key="d4">14.0</data>
      <data key="d5">Park et al. worked on simulating a human town with agents</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="JENNY ZHANG" target="JOEL LEHMAN">
      <data key="d4">16.0</data>
      <data key="d5">Jenny Zhang and Joel Lehman co-authored the paper "OMNI: Open-endedness via models of human notions of interestingness" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JENNY ZHANG" target="KENNETH STANLEY">
      <data key="d4">16.0</data>
      <data key="d5">Jenny Zhang and Kenneth Stanley co-authored the paper "OMNI: Open-endedness via models of human notions of interestingness" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="YUSHENG SU" target="JINGWEI ZUO">
      <data key="d4">8.0</data>
      <data key="d5">Yusheng Su and Jingwei Zuo co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YUSHENG SU" target="CHENG YANG">
      <data key="d4">8.0</data>
      <data key="d5">Yusheng Su and Cheng Yang co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YUSHENG SU" target="CHENFEI YUAN">
      <data key="d4">8.0</data>
      <data key="d5">Yusheng Su and Chenfei Yuan co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YUSHENG SU" target="CHI-MIN CHAN">
      <data key="d4">8.0</data>
      <data key="d5">Yusheng Su and Chi-Min Chan co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YUSHENG SU" target="HEYANG YU">
      <data key="d4">8.0</data>
      <data key="d5">Yusheng Su and Heyang Yu co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YUSHENG SU" target="YI-HSIN HUNG">
      <data key="d4">8.0</data>
      <data key="d5">Yusheng Su and Yi-Hsin Hung co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YUSHENG SU" target="CHEN QIAN">
      <data key="d4">8.0</data>
      <data key="d5">Yusheng Su and Chen Qian co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="JINGWEI ZUO" target="CHENG YANG">
      <data key="d4">8.0</data>
      <data key="d5">Jingwei Zuo and Cheng Yang co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="JINGWEI ZUO" target="CHENFEI YUAN">
      <data key="d4">8.0</data>
      <data key="d5">Jingwei Zuo and Chenfei Yuan co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="JINGWEI ZUO" target="CHI-MIN CHAN">
      <data key="d4">8.0</data>
      <data key="d5">Jingwei Zuo and Chi-Min Chan co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="JINGWEI ZUO" target="HEYANG YU">
      <data key="d4">8.0</data>
      <data key="d5">Jingwei Zuo and Heyang Yu co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="JINGWEI ZUO" target="YI-HSIN HUNG">
      <data key="d4">8.0</data>
      <data key="d5">Jingwei Zuo and Yi-Hsin Hung co-authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" published in The Twelfth International Conference on Learning Representations in 2023</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="JOEL LEHMAN" target="KENNETH STANLEY">
      <data key="d4">16.0</data>
      <data key="d5">Joel Lehman and Kenneth Stanley co-authored the paper "OMNI: Open-endedness via models of human notions of interestingness" published in The Twelfth International Conference on Learning Representations in 2024</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="QIANG WANG" target="DAWEI YIN">
      <data key="d4">8.0</data>
      <data key="d5">Qiang Wang and Dawei Yin co-authored the paper "Tool learning with large language models: A survey" published on arXiv in 2024</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="QIANG WANG" target="JUN XU">
      <data key="d4">8.0</data>
      <data key="d5">Qiang Wang and Jun Xu co-authored the paper "Tool learning with large language models: A survey" published on arXiv in 2024</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="QIANG WANG" target="JI-RONG WEN">
      <data key="d4">8.0</data>
      <data key="d5">Qiang Wang and Ji-Rong Wen co-authored the paper "Tool learning with large language models: A survey" published on arXiv in 2024</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="DAWEI YIN" target="JUN XU">
      <data key="d4">8.0</data>
      <data key="d5">Dawei Yin and Jun Xu co-authored the paper "Tool learning with large language models: A survey" published on arXiv in 2024</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="DAWEI YIN" target="JI-RONG WEN">
      <data key="d4">8.0</data>
      <data key="d5">Dawei Yin and Ji-Rong Wen co-authored the paper "Tool learning with large language models: A survey" published on arXiv in 2024</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="JUN XU" target="JI-RONG WEN">
      <data key="d4">8.0</data>
      <data key="d5">Jun Xu and Ji-Rong Wen co-authored the paper "Tool learning with large language models: A survey" published on arXiv in 2024</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="RAFAEL RAFAILOV" target="ARCHIT SHARMA">
      <data key="d4">8.0</data>
      <data key="d5">Rafael Rafailov and Archit Sharma co-authored the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="RAFAEL RAFAILOV" target="ERIC MITCHELL">
      <data key="d4">8.0</data>
      <data key="d5">Rafael Rafailov and Eric Mitchell co-authored the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="MIRAC SUZGUN" target="NATHANAEL SCH&#196;RLI">
      <data key="d4">8.0</data>
      <data key="d5">Mirac Suzgun and Nathanael Sch&#228;rli co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="MIRAC SUZGUN" target="YI TAY">
      <data key="d4">8.0</data>
      <data key="d5">Mirac Suzgun and Yi Tay co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="MIRAC SUZGUN" target="QUOC V LE">
      <data key="d4">8.0</data>
      <data key="d5">Mirac Suzgun and Quoc V Le co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="MIRAC SUZGUN" target="ED H CHI">
      <data key="d4">8.0</data>
      <data key="d5">Mirac Suzgun and Ed H Chi co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them" published in 2022</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="JIEYU ZHANG" target="SHAOKUN ZHANG">
      <data key="d4">8.0</data>
      <data key="d5">Shaokun Zhang and Jieyu Zhang co-authored the paper "Offline training of language model agents with functions as learnable weights" published in the Forty-first International Conference on Machine Learning in 2024</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="SHAOKUN ZHANG" target="JIALE LIU">
      <data key="d4">8.0</data>
      <data key="d5">Shaokun Zhang and Jiale Liu co-authored the paper "Offline training of language model agents with functions as learnable weights" published in the Forty-first International Conference on Machine Learning in 2024</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="SHAOKUN ZHANG" target="LINXIN SONG">
      <data key="d4">8.0</data>
      <data key="d5">Shaokun Zhang and Linxin Song co-authored the paper "Offline training of language model agents with functions as learnable weights" published in the Forty-first International Conference on Machine Learning in 2024</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="YARIN GAL" target="ILIA SHUMAILOV">
      <data key="d4">8.0</data>
      <data key="d5">Ilia Shumailov and Yarin Gal co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="YARIN GAL" target="ZAKHAR SHUMAYLOV">
      <data key="d4">8.0</data>
      <data key="d5">Zakhar Shumaylov and Yarin Gal co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="YARIN GAL" target="YIREN ZHAO">
      <data key="d4">8.0</data>
      <data key="d5">Yiren Zhao and Yarin Gal co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="YARIN GAL" target="NICOLAS PAPERNOT">
      <data key="d4">8.0</data>
      <data key="d5">Yarin Gal and Nicolas Papernot co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="YARIN GAL" target="ROSS ANDERSON">
      <data key="d4">8.0</data>
      <data key="d5">Yarin Gal and Ross Anderson co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="APPENDIX C" target="APPENDIX D">
      <data key="d4">5.0</data>
      <data key="d5">Both Appendix C and Appendix D are sections in the document that contain additional information</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="APPENDIX C" target="APPENDIX E">
      <data key="d4">5.0</data>
      <data key="d5">Both Appendix E and Appendix C are sections in the document that contain additional information</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="APPENDIX C" target="MAIN TEXT">
      <data key="d4">8.0</data>
      <data key="d5">Appendix C provides additional information relevant to the main text</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="APPENDIX D" target="APPENDIX E">
      <data key="d4">5.0</data>
      <data key="d5">Both Appendix E and Appendix D are sections in the document that contain additional information</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="APPENDIX D" target="MAIN TEXT">
      <data key="d4">8.0</data>
      <data key="d5">Appendix D provides additional information relevant to the main text</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="APPENDIX B" target="FRAMEWORK CODE">
      <data key="d4">9.0</data>
      <data key="d5">Appendix B contains the framework code</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="APPENDIX B" target="APPENDIX E">
      <data key="d4">5.0</data>
      <data key="d5">Both Appendix E and Appendix B are sections in the document that contain additional information</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="APPENDIX B" target="MAIN TEXT">
      <data key="d4">8.0</data>
      <data key="d5">Appendix B provides additional information relevant to the main text</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="APPENDIX B" target="ORCA-3">
      <data key="d4">7.0</data>
      <data key="d5">Appendix B specifies the types of tasks/benchmarks and the corresponding method used to extract answers and generate metrics for Orca-3</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="NAMEDTUPLE INFO OBJECT" target="FRAMEWORK CODE">
      <data key="d4">8.0</data>
      <data key="d5">The namedtuple Info object is used in the framework code to encapsulate and combine different types of information</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FM MODULE" target="FRAMEWORK CODE">
      <data key="d4">1.0</data>
      <data key="d5">The FM module is part of the framework code that constructs prompts by concatenating input Info objects</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FM MODULE" target="INFO">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module constructs prompts by concatenating all input Info objects</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="TASK DESCRIPTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module facilitates communication between different modules by using task descriptions</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="FM RESPONSES">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module generates FM responses based on the input information and instructions</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="TOOL FUNCTION CALLS">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module uses tool function calls to perform specific tasks</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="OUTPUT INFOS">
      <data key="d4">8.0</data>
      <data key="d5">Output Infos are the results generated by the FM Module</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Instruction guides the FM Module on how to perform a task</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="MODEL">
      <data key="d4">8.0</data>
      <data key="d5">Model refers to the specific version of the GPT model used in the FM Module</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="TEMPERATURE">
      <data key="d4">7.0</data>
      <data key="d5">Temperature is a parameter that controls the randomness of the GPT model's output in the FM Module</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="UNIQUE IDENTIFIER">
      <data key="d4">7.0</data>
      <data key="d5">Unique identifier is a string that uniquely identifies an instance of the FM Module</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="OUTPUT FIELDS">
      <data key="d4">7.0</data>
      <data key="d5">Output fields are the fields expected in the output generated by the FM Module</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="ROLE">
      <data key="d4">7.0</data>
      <data key="d5">Role is a description of the function or position of the FM Module</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FRAMEWORK CODE" target="INFO OBJECT">
      <data key="d4">8.0</data>
      <data key="d5">Info object is used in the framework code to encapsulate and combine different types of information</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="TASKINFO" target="FORWARD FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">TaskInfo is a parameter used in the "forward()" function in the Python code for agent implementation</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="TASKINFO" target="COT_INPUTS">
      <data key="d4">7.0</data>
      <data key="d5">Task information is part of the initial inputs for the Chain-of-Thought module</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="TASKINFO" target="FM_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">TaskInfo is the input data provided to the FM_Module</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="TASKINFO" target="THINKING">
      <data key="d4">7.0</data>
      <data key="d5">TaskInfo and Thinking are used together as inputs for various modules in the code</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TASKINFO" target="INITIAL_INSTRUCTION">
      <data key="d4">6.0</data>
      <data key="d5">Initial_instruction is given to TaskInfo at the beginning of the process</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TASKINFO" target="DECOMPOSITION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">TaskInfo is used as input data in the Decomposition Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="TASKINFO" target="VISUAL REPRESENTATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">TaskInfo is used as input data in the Visual Representation Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="TASKINFO" target="VERIFICATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">TaskInfo is used as input data in the Verification Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="TASKINFO" target="CHAIN-OF-THOUGHT MODULE">
      <data key="d4">8.0</data>
      <data key="d5">TaskInfo is used as input data in the Chain-of-Thought Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="RUNTIME ERROR" target="DEBUG_THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">Debug_thought is used to provide the meta agent's thinking for debugging the current code after a runtime error</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="MAIN TEXT" target="TERMINOLOGIES">
      <data key="d4">8.0</data>
      <data key="d5">Terminologies used in the main text are matched in the code throughout the appendix</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="IMPROVEMENT" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B showed improvements over Orca 2.5 and Mistral-7B-Instruct</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="IMPROVEMENT" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">Mistral-7B-Instruct's performance was used as a baseline for improvement</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="IMPROVEMENT" target="ORCA-2.5">
      <data key="d4">7.0</data>
      <data key="d5">Orca 2.5's performance was used as a baseline for improvement</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="APPENDIX E" target="ORCA-3">
      <data key="d4">7.0</data>
      <data key="d5">Appendix E contains more details about the baselines used in the evaluations of Orca-3</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="FORWARD FUNCTION" target="AGENT SYSTEM">
      <data key="d4">9.0</data>
      <data key="d5">The forward function is a method in the AgentSystem class</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="INFO" target="NAMED TUPLE">
      <data key="d4">9.0</data>
      <data key="d5">Info is a named tuple used for holding task information</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="INFO" target="TASK INFO">
      <data key="d4">9.0</data>
      <data key="d5">Task Info is a named tuple containing information about a task</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="INFO" target="STRUCTURED_FEEDBACK">
      <data key="d4">7.0</data>
      <data key="d5">Info is used to store Structured_feedback information</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INFO" target="SUB_PROBLEM">
      <data key="d4">7.0</data>
      <data key="d5">Info encapsulates information about sub-problems</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="INFO" target="SUB_SOLUTION">
      <data key="d4">7.0</data>
      <data key="d5">Info encapsulates information about sub-problem solutions</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FORMAT_INST" target="FM_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The FM_Module uses the FORMAT_INST lambda function to format instructions for FM responses</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="ROLE_DESC" target="FM_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The FM_Module uses the ROLE_DESC lambda function to describe its role</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GET_JSON_RESPONSE_FROM_GPT" target="FM_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The FM_Module can use the get_json_response_from_gpt function to get JSON responses from a GPT model</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GET_JSON_RESPONSE_FROM_GPT" target="JSON RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">The get_json_response_from_gpt function generates a JSON response</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM_MODULE" target="CODE 1">
      <data key="d4">9.0</data>
      <data key="d5">Code 1 includes the definition of the FM_Module class</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM_MODULE" target="INITIAL SOLUTION">
      <data key="d4">8.0</data>
      <data key="d5">FM_Module generates the Initial Solution based on the initial instruction</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM_MODULE" target="THINKING">
      <data key="d4">7.0</data>
      <data key="d5">Thinking is part of the process generated by the FM_Module</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM_MODULE" target="INITIAL INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Initial Instruction is given to the FM_Module to generate initial candidate solutions</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM_MODULE" target="NUM_CANDIDATES">
      <data key="d4">7.0</data>
      <data key="d5">Num_Candidates is the number of initial candidates generated by the FM_Module</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM_MODULE" target="THOUGHTS">
      <data key="d4">7.0</data>
      <data key="d5">Thoughts are generated by the FM_Module during the initial candidate solution process</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM_MODULE" target="HUMAN_LIKE_FEEDBACK_MODULE">
      <data key="d4">9.0</data>
      <data key="d5">Human_like_feedback_module is an instance of FM_Module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FM_MODULE" target="EXPERT_ADVISORS">
      <data key="d4">9.0</data>
      <data key="d5">Expert_advisors are instances of FM_Module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FM_MODULE" target="REFINEMENT_MODULE">
      <data key="d4">9.0</data>
      <data key="d5">Refinement_module is an instance of FM_Module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FM_MODULE" target="FINAL_DECISION_MODULE">
      <data key="d4">9.0</data>
      <data key="d5">Final_decision_module is an instance of FM_Module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FM_MODULE" target="DECOMPOSITION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">FM_Module is used to create the Decomposition Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="SPECIALIZED EXPERT">
      <data key="d4">9.0</data>
      <data key="d5">FM_Module is used to create the Specialized Expert</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="INTEGRATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">FM_Module is used to create the Integration Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="VISUAL REPRESENTATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">FM_Module is used to create the Visual Representation Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="VERIFICATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">FM_Module is used to create the Verification Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="CHAIN-OF-THOUGHT MODULE">
      <data key="d4">9.0</data>
      <data key="d5">FM_Module is used to create the Chain-of-Thought Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="CRITIC_INSTRUCTION" target="CRITIC_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Critic module uses the critic instruction to provide feedback and correctness status</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="BACKOFF" target="RATE LIMIT ERROR">
      <data key="d4">8.0</data>
      <data key="d5">Backoff is used to handle Rate Limit Errors by retrying the function call</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="MODEL" target="EXACT MATCH/SPAN EXTRACTION PROBLEMS">
      <data key="d4">8.0</data>
      <data key="d5">The model is evaluated on its ability to generate correct answers in Exact Match/Span Extraction Problems</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MODEL" target="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The model's answers to math problems are evaluated using the Maths GPT-4 Extraction System Message</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MODEL" target="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d4">1.0</data>
      <data key="d5">The model's answers to non-math problems are evaluated using the General Extraction System Message</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MODEL" target="EQBENCH">
      <data key="d4">8.0</data>
      <data key="d5">The model is evaluated on its ability to generate emotion scores in the EQBench dataset</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MODEL" target="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The model's emotion scores are extracted using the EQBench GPT-4 Extraction System Message</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MODEL" target="MODEL'S ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">The model generates the model's answer</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="COT_MODULE" target="THINKING">
      <data key="d4">9.0</data>
      <data key="d5">The Chain-of-Thought module generates the thought process</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="CRITIC_MODULE" target="CORRECT">
      <data key="d4">9.0</data>
      <data key="d5">The Critic module provides the correctness status</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="THINKING" target="THOUGHTS">
      <data key="d4">7.0</data>
      <data key="d5">Thoughts and Thinking are used together as inputs for various modules in the code</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPT-3.5-TURBO-0125" target="DISCOVERED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Discovered agents are evaluated using the GPT-3.5-turbo-0125 model</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPT-3.5-TURBO-0125" target="COST OF EXPERIMENTS">
      <data key="d4">8.0</data>
      <data key="d5">Cost of Experiments is high due to the use of GPT-3.5-turbo-0125</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="EXAMPLE 2" target="OUTPUT">
      <data key="d4">7.0</data>
      <data key="d5">Example 2 is used to generate a specific output based on the transformation rules</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="TEST PROBLEM" target="OUTPUT">
      <data key="d4">7.0</data>
      <data key="d5">Test Problem is used to generate a specific output based on the transformation rules</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="EXAMPLE 1" target="OUTPUT">
      <data key="d4">7.0</data>
      <data key="d5">Example 1 is used to generate a specific output based on the transformation rules</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="HUMAN_LIKE_FEEDBACK_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">Initial_solutions are evaluated using the Human_like_feedback_module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="HUMAN_LIKE_FEEDBACK_MODULE" target="HUMAN_FEEDBACK_INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Human_feedback_instruction is given to the Human_like_feedback_module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERT_ROLES" target="EXPERT_ADVISORS">
      <data key="d4">8.0</data>
      <data key="d5">Expert_roles are assigned to Expert_advisors</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERT_ADVISORS" target="EXPERT_INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Expert_instruction is given to Expert_advisors</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERT_ADVISORS" target="SOL_FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">Sol_feedback is generated by Expert_advisors</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERT_ADVISORS" target="EXPERT_FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">Expert_feedback is provided by Expert_advisors</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="MAX_REFINEMENT_ITERATIONS" target="REFINEMENT_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">Max_refinement_iterations is a parameter for the Refinement_module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINEMENT_MODULE" target="REFINEMENT_INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Refinement_instruction is given to the Refinement_module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINEMENT_MODULE" target="REFINED_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Refined_solutions are generated by the Refinement_module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINED_SOLUTIONS" target="SORTED_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Sorted_solutions are derived from Refined_solutions</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="SORTED_SOLUTIONS" target="TOP_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Top_solutions are selected from Sorted_solutions</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FINAL_DECISION_INSTRUCTION" target="FINAL_DECISION_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">Final_decision_instruction is given to the Final_decision_module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FINAL_DECISION_MODULE" target="FINAL_INPUTS">
      <data key="d4">8.0</data>
      <data key="d5">Final_inputs are used by the Final_decision_module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FINAL_DECISION_MODULE" target="FINAL_THOUGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Final_thoughts are generated by the Final_decision_module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FINAL_THOUGHTS" target="FINAL_THINKING">
      <data key="d4">8.0</data>
      <data key="d5">Final_thinking is part of Final_thoughts</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FINAL_THOUGHTS" target="FINAL_CODE">
      <data key="d4">8.0</data>
      <data key="d5">Final_code is part of Final_thoughts</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FINAL_CODE" target="GET_TEST_OUTPUT_FROM_CODE">
      <data key="d4">8.0</data>
      <data key="d5">Get_test_output_from_code is used to obtain the final answer from the Final_code solution</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="HUMAN_THINKING" target="HUMAN_FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">Human_thinking and Human_feedback are provided by the human-like feedback module</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINEMENT_THINKING" target="REFINED_CODE">
      <data key="d4">8.0</data>
      <data key="d5">Refinement_thinking and Refined_code are generated during the refinement process</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="DECOMPOSITION MODULE" target="SPECIALIZED EXPERT">
      <data key="d4">8.0</data>
      <data key="d5">The Decomposition Module assigns each sub-problem to a Specialized Expert</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERT" target="INTEGRATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">Specialized Experts solve sub-problems, and the Integration Module integrates these solutions</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VERIFICATION MODULE" target="VISUAL_REPRESENTATION">
      <data key="d4">8.0</data>
      <data key="d5">Visual_representation is verified by the Verification Module</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="GPT-4O-MINI" target="COST OF EXPERIMENTS">
      <data key="d4">8.0</data>
      <data key="d5">Cost of Experiments could be reduced by using GPT-4o-mini</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VISUAL_OUTPUT" target="VISUAL_REPRESENTATION">
      <data key="d4">7.0</data>
      <data key="d5">Visual_output contains the visual representation of a problem</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="GENERATIVE TEACHING">
      <data key="d4">27.0</data>
      <data key="d5">AgentInstruct is an agentic solution designed specifically for the Generative Teaching methodology. It is utilized to create synthetic data, which plays a crucial role in the implementation and effectiveness of Generative Teaching. This innovative tool aids in the generation of high-quality, diverse datasets that are essential for training and improving machine learning models within the Generative Teaching framework.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-7B">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct was used to generate data for post-training Mistral-7b</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SYNTHETIC-DATA-GENERATION-AS-A-SERVICE">
      <data key="d4">16.0</data>
      <data key="d5">AgentInstruct can enable Synthetic-Data-Generation-As-A-Service by generating data for post-training and fine-tuning</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTENT TRANSFORMATION AGENTS">
      <data key="d4">14.0</data>
      <data key="d5">Content Transformation Agents are used in the AgentInstruct methodology</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="REFINEMENT AGENTS">
      <data key="d4">14.0</data>
      <data key="d5">Refinement Agents are used in the AgentInstruct methodology</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="RAW SEEDS">
      <data key="d4">16.0</data>
      <data key="d5">Raw seeds are used as input in the AgentInstruct methodology</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="POST-TRAINING DATASET">
      <data key="d4">18.0</data>
      <data key="d5">The post-training dataset was created by AgentInstruct</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="INSTRUCTION CREATION AGENTS">
      <data key="d4">14.0</data>
      <data key="d5">Instruction Creation Agents are used in the AgentInstruct methodology</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="REFLECTION FLOWS">
      <data key="d4">14.0</data>
      <data key="d5">Reflection Flows are used in AgentInstruct to enhance the quality of generated responses</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CREATIVE WRITING">
      <data key="d4">19.0</data>
      <data key="d5">AgentInstruct has incorporated Creative Writing as one of the 17 different skills in its synthetic post-training dataset. This skill is also implemented in the workflows defined by AgentInstruct, showcasing its commitment to enhancing diverse capabilities within its AI training processes.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Flow is one of the three flows defined by AgentInstruct</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SEED INSTRUCTION GENERATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow is one of the three flows defined by AgentInstruct</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow is one of the three flows defined by AgentInstruct</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="RETRIEVAL AUGMENTED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">Retrieval augmented generation is one of the 17 different skills implemented in the workflows defined by AgentInstruct</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="WEB CONTROL">
      <data key="d4">7.0</data>
      <data key="d5">Web control is one of the 17 different skills implemented in the workflows defined by AgentInstruct</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CASE STUDIES">
      <data key="d4">7.0</data>
      <data key="d5">Case studies are used to explain how the workflows defined by AgentInstruct work for generating data for specific skills</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3">
      <data key="d4">32.0</data>
      <data key="d5">AgentInstruct data has led to a performance augmentation of 33.94% over the Orca 2.5 baseline and an enhancement of 14.92% over Mistral-Instruct-7B. AgentInstruct is used to improve Orca-3's reading comprehension capabilities. Orca-3 was trained using the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="KNOWLEDGEPILE">
      <data key="d4">8.0</data>
      <data key="d5">KnowledgePile is a source of unstructured text and code files used in the AgentInstruct system</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="AUTOMATHTEXT">
      <data key="d4">8.0</data>
      <data key="d5">AutoMathText is a source of unstructured text and code files used in the AgentInstruct system</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="OPENSTAX">
      <data key="d4">8.0</data>
      <data key="d5">Openstax is a source of unstructured text used in the AgentInstruct system</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="APACHE-2.0 LICENSED SOURCE CODE">
      <data key="d4">8.0</data>
      <data key="d5">Apache-2.0 licensed source code is a subset of source code files used in the AgentInstruct system</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct is used to improve Mistral-7b-Instruct's reading comprehension capabilities</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="LSAT">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct helps models perform well on the reading comprehension sections of the LSAT</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-INSTRUCT-7B">
      <data key="d4">16.0</data>
      <data key="d5">AgentInstruct has enhanced Mistral's proficiency across various difficulties in math</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d4">12.0</data>
      <data key="d5">AgentInstruct uses math problems generated by Open Domain Question Answering</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MULTIPLE-CHOICE QUESTIONS FLOWS">
      <data key="d4">12.0</data>
      <data key="d5">AgentInstruct uses math problems generated by Multiple-Choice Questions Flows</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="NON-MEDICAL DATA">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct RAG data used non-medical data seeds for evaluations</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is fine-tuned with the AgentInstruct data</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="LLMS">
      <data key="d4">9.0</data>
      <data key="d5">Synthetic data has been used to significantly accelerate the development of Large Language Models (LLMs)</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="SLMS">
      <data key="d4">9.0</data>
      <data key="d5">Synthetic data has been used to significantly accelerate the development of Small Language Models (SLMs)</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="RLHF">
      <data key="d4">8.0</data>
      <data key="d5">Synthetic data has been used in the training of language models through Reinforcement Learning from Human Feedback (RLHF)</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MISTRAL-7B" target="ORCA-3">
      <data key="d4">27.0</data>
      <data key="d5">MISTRAL-7B is a foundational model that has been further refined to create Orca-3. Orca-3 is the fine-tuned version of the Mistral-7B model, resulting from post-training Mistral-7B with data generated by AgentInstruct. This process enhances the capabilities of the original Mistral-7B model, leveraging the additional data to improve performance and accuracy in various applications.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="AGIEVAL">
      <data key="d4">35.0</data>
      <data key="d5">Orca-3 is evaluated on the AGIEval benchmark, where it demonstrated a significant performance improvement. Specifically, Orca-3 showed a 40% improvement on the AGIEval benchmark compared to Mistral-Instruct-7B. This notable enhancement underscores Orca-3's advanced capabilities in the context of the AGIEval evaluation.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="BBH">
      <data key="d4">35.0</data>
      <data key="d5">Orca-3 is evaluated on the BBH benchmark and demonstrated a significant performance improvement. Specifically, Orca-3 showed a 38% improvement on the BBH benchmark compared to Mistral-Instruct-7B. This highlights Orca-3's superior capabilities in the context of the BBH benchmark, showcasing its advancements over Mistral-7B-Instruct.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="ALPACAEVAL">
      <data key="d4">35.0</data>
      <data key="d5">Orca-3 is evaluated on the AlpacaEval benchmark, where it demonstrated a significant performance improvement. Specifically, Orca-3 showed a 45% improvement on the AlpacaEval benchmark compared to Mistral-Instruct-7B, also referred to as Mistral-7b-Instruct. This highlights Orca-3's superior capabilities in the context of this particular evaluation.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="LLAMA-8B-INSTRUCT">
      <data key="d4">24.0</data>
      <data key="d5">ORCA-3 consistently outperformed LLAMA-8B-Instruct in various benchmarks. This superior performance was observed across multiple evaluations, highlighting ORCA-3's advanced capabilities in comparison to LLAMA-8B-Instruct.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="GPT-3.5-TURBO">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 consistently outperformed GPT-3.5-turbo in various benchmarks</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">9.0</data>
      <data key="d5">ORCA-3 demonstrated significant performance improvements over MISTRAL-7B-INSTRUCT across various benchmarks. This indicates that ORCA-3 has made notable advancements in its capabilities, outperforming MISTRAL-7B-INSTRUCT in multiple evaluation metrics.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-INSTRUCT-7B">
      <data key="d4">16.0</data>
      <data key="d5">Orca-3 showed significant improvements over Mistral-Instruct-7B</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-1">
      <data key="d4">8.0</data>
      <data key="d5">Orca-1 is one of the datasets used in the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-2">
      <data key="d4">8.0</data>
      <data key="d5">Orca-2 is one of the datasets used in the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-MATH">
      <data key="d4">8.0</data>
      <data key="d5">Orca-Math is one of the datasets used in the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-2.5">
      <data key="d4">7.0</data>
      <data key="d5">Orca-2.5 is a model used to compare and evaluate the impact of the 22 million instructions curated through AgentInstruct on Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-V0.1">
      <data key="d4">9.0</data>
      <data key="d5">Mistral-7b-v0.1 is the base model finetuned to create Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="NVIDIA A100">
      <data key="d4">8.0</data>
      <data key="d5">NVIDIA A100 GPUs were used in the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ADAMW OPTIMIZER">
      <data key="d4">8.0</data>
      <data key="d5">AdamW optimizer was used in the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-BENCH">
      <data key="d4">25.0</data>
      <data key="d5">ORCA-3 is a model that has been evaluated on the ORCA-BENCH dataset, demonstrating notable enhancement in capabilities during post-training. ORCA-BENCH serves as the dataset specifically designed to assess the performance of ORCA-3, providing a comprehensive framework for evaluating its improvements and effectiveness.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="TOKENIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Tokenization is applied to each pair in the dataset using the Mistral tokenizer during the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="LABEL MASKING">
      <data key="d4">8.0</data>
      <data key="d5">Label masking is used during the training of Orca-3 to ensure that the training loss is calculated based only on the response conditioned on the prompt</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="WEIGHT DECAY">
      <data key="d4">8.0</data>
      <data key="d5">Weight decay was set at 0.1 during the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="BATCH SIZE">
      <data key="d4">8.0</data>
      <data key="d5">A batch size of 10 was used for each of the 152 NVIDIA A100 GPUs during the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="INITIAL LEARNING RATE">
      <data key="d4">8.0</data>
      <data key="d5">The initial learning rate for the AdamW optimizer was set at 8e-6 during the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="COSINE LEARNING RATE SCHEDULE">
      <data key="d4">8.0</data>
      <data key="d5">A cosine learning rate schedule was used during the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="LINEAR LEARNING RATE WARM-UP">
      <data key="d4">8.0</data>
      <data key="d5">A linear learning rate warm-up was used during the initial 500 steps of training Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="EPOCH">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 was trained for three epochs</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="TRAINING HOURS">
      <data key="d4">8.0</data>
      <data key="d5">The training of Orca-3 took approximately 200 hours</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="FOFO">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3 is evaluated on the FOFO benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="IFEVAL">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3 is evaluated on the IFEval benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="INFOBENCH">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3 is evaluated on the InfoBench benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="EQBENCH">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3 is evaluated on the EQBench benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="METRIC-V2">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3 is evaluated on the Metric-v2 benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="METRIC-V1">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 is evaluated on the Metric-v1 benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="ORCA 2.5">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 shows an 18% improvement over Orca 2.5 in reading comprehension capabilities</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="ORCA-3" target="TABLE 6">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3's performance is presented in Table 6</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="AGIEVAL" target="SAT">
      <data key="d4">7.0</data>
      <data key="d5">AGIEval includes the SAT as part of its human-centric benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGIEVAL" target="LSAT">
      <data key="d4">7.0</data>
      <data key="d5">AGIEval includes the LSAT as part of its human-centric benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGIEVAL" target="MATH COMPETITIONS">
      <data key="d4">7.0</data>
      <data key="d5">AGIEval includes math competitions as part of its human-centric benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGIEVAL" target="ORCA-3-7B">
      <data key="d4">14.0</data>
      <data key="d5">AGIEval is used to evaluate the performance of Orca-3-7B on various tasks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ALPACAEVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">AlpacaEval is a benchmark used in the Open-Ended Generation task</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ALPACAEVAL" target="GPT-4-TURBO">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4-turbo is used as a judge in the AlpacaEval benchmark</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ALPACAEVAL" target="VERSION 0613">
      <data key="d4">7.0</data>
      <data key="d5">Version 0613 of GPT-4-turbo is used in the AlpacaEval benchmark</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="ORCA-BENCH">
      <data key="d4">14.0</data>
      <data key="d5">GPT-3.5-turbo is a baseline model evaluated on the Orca-Bench dataset</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="TABLE 7">
      <data key="d4">8.0</data>
      <data key="d5">GPT-3.5-turbo's performance is presented in Table 7</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">GPT-3.5-turbo is evaluated on the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="AZURE">
      <data key="d4">1.0</data>
      <data key="d5">Azure is recommended for reviewing transparency notes related to GPT-3.5-turbo</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="SEARCH APIS" target="MULTI-AGENT WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Search APIs are tools used in multi-agent workflows to enhance the capabilities of language models</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="CALCULATOR" target="MULTI-AGENT WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Calculator is a tool used in multi-agent workflows to enhance the capabilities of language models</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="CODE INTERPRETERS" target="MULTI-AGENT WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Code interpreters are tools used in multi-agent workflows to enhance the capabilities of language models</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT" target="ORCA-3-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3-7B shows improvements over Mistral-7B-Instruct</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT" target="TABLE 6">
      <data key="d4">8.0</data>
      <data key="d5">Mistral-7B-Instruct's performance is presented in Table 6</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT" target="TABLE 7">
      <data key="d4">8.0</data>
      <data key="d5">Mistral-7B-Instruct's hallucination rates and quality scores are presented in Table 7</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MISTRAL-INSTRUCT-7B" target="ORCA-BENCH">
      <data key="d4">14.0</data>
      <data key="d5">Mistral-Instruct-7B is a baseline model evaluated on the Orca-Bench dataset</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MISTRAL-INSTRUCT-7B" target="ORCA-3-7B">
      <data key="d4">18.0</data>
      <data key="d5">Orca-3-7B has shown significant improvements over Mistral-Instruct-7B in various benchmarks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MISTRAL-INSTRUCT-7B" target="FORMAT FOLLOWING">
      <data key="d4">16.0</data>
      <data key="d5">Format Following has significantly improved Mistral's ability to follow formats</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="AGENTIC FLOWS">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Flow is one of the agentic flows used to convert raw seeds into intermediate representations</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="SEED INSTRUCTION GENERATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow takes transformed content from the Content Transformation Flow to generate diverse instructions</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="RAW ARTICLES">
      <data key="d4">7.0</data>
      <data key="d5">Raw articles are used as seeds in the Content Transformation Flow</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="ARGUMENT PASSAGE GENERATOR">
      <data key="d4">8.0</data>
      <data key="d5">Argument Passage Generator is a component of the Content Transformation Flow</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="WEB CRAWLS">
      <data key="d4">7.0</data>
      <data key="d5">Content Transformation Flow uses web crawls to generate reading comprehension materials</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="DEBATES AND CONVERSATIONS">
      <data key="d4">8.0</data>
      <data key="d5">Debates and conversations are types of content generated by the Content Transformation Flow</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="LONG PASSAGES">
      <data key="d4">8.0</data>
      <data key="d5">Long passages are types of content generated by the Content Transformation Flow</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="MEETING TRANSCRIPTS">
      <data key="d4">8.0</data>
      <data key="d5">Meeting transcripts are types of content generated by the Content Transformation Flow</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="POEMS">
      <data key="d4">8.0</data>
      <data key="d5">Poems are types of content generated by the Content Transformation Flow</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="SATIRICAL CONTENT">
      <data key="d4">8.0</data>
      <data key="d5">Satirical content is a type of content generated by the Content Transformation Flow</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="AGENTINSTRUCT FLOW">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct Flow involves enabling models to interact with external tools or services, which is part of the Content Transformation Flow</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="API RETRIEVAL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Content Transformation Flow uses the API Retrieval Agent to iteratively search for similar code to expand the API list</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="API DESCRIPTION">
      <data key="d4">7.0</data>
      <data key="d5">An API description can be used as a random seed in the Content Transformation Flow to synthesize a list of APIs</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="LIBRARY RECONSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Library Reconstruction is a scenario in the Content Transformation Flow where a list of APIs is synthesized from a random seed</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEED INSTRUCTION CREATION FLOW" target="REFINEMENT FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow generates initial tasks, and the Refinement Flow increases the complexity of these tasks</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="SEED INSTRUCTION GENERATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow is one of the agentic flows used to generate diverse instructions from transformed content</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow is one of the agentic flows used to iteratively enhance the complexity and quality of instructions</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow takes instructions from the Seed Instruction Generation Flow to enhance their complexity and quality</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="INTERMEDIATE REPRESENTATION">
      <data key="d4">7.0</data>
      <data key="d5">Intermediate representation is the input for the Seed Instruction Generation Flow</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="AGENT">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow defines agents to generate reading comprehension questions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="LITERAL COMPREHENSION QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Seed Instruction Generation Flow includes literal comprehension questions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="CRITICAL COMPREHENSION QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Seed Instruction Generation Flow includes critical comprehension questions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="EVALUATIVE COMPREHENSION QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Seed Instruction Generation Flow includes evaluative comprehension questions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="REASONING QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Seed Instruction Generation Flow includes reasoning questions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="IDENTIFYING ASSUMPTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Seed Instruction Generation Flow includes identifying assumptions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="IDENTIFYING INFORMATION THAT STRENGTHENS/WEAKENS AN ARGUMENT">
      <data key="d4">7.0</data>
      <data key="d5">Seed Instruction Generation Flow includes identifying information that strengthens or weakens an argument</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="ORDERING EVENTS">
      <data key="d4">7.0</data>
      <data key="d5">Seed Instruction Generation Flow includes ordering events</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR AGENTS">
      <data key="d4">9.0</data>
      <data key="d5">Suggester-Editor Agents are used in the Instruction Refinement Flow to propose and modify instructions</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SEED INSTRUCTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Seed instructions are the input for the Instruction Refinement Flow</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER AGENT">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow involves suggester agents to provide suggestions for refining questions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="EDITOR AGENT">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow involves editor agents to make modifications based on suggestions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="MODIFY THE PASSAGE">
      <data key="d4">7.0</data>
      <data key="d5">Instruction Refinement Flow includes tasks to modify the passage</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="MODIFY THE QUESTIONS OR ANSWER CHOICES">
      <data key="d4">7.0</data>
      <data key="d5">Instruction Refinement Flow includes tasks to modify the questions or answer choices</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR">
      <data key="d4">8.0</data>
      <data key="d5">The Instruction Refinement Flow involves a Suggester-Editor pair to increase the complexity of generated instructions</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Open domain question answering is a type of question answering</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="CONTENT CREATION">
      <data key="d4">7.0</data>
      <data key="d5">Content creation is related to text modification as both involve generating or altering text</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="EDITING">
      <data key="d4">7.0</data>
      <data key="d5">Editing is related to text modification as both involve altering text to improve its quality or fit a specific context</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="AGENTINSTRUCT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct Flow is a process for text modification</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="BRAIN TEASER" target="ANALYTICAL REASONING">
      <data key="d4">6.0</data>
      <data key="d5">Both Brain Teasers and Analytical Reasoning involve problem-solving and logical thinking skills</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="ANALYTICAL REASONING" target="FERMI PROBLEMS">
      <data key="d4">7.0</data>
      <data key="d5">Fermi Problems require Analytical Reasoning to make justified guesses or assumptions</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="EVALUATION DETAILS">
      <data key="d4">8.0</data>
      <data key="d5">Evaluation Details specify the method used to extract answers and generate metrics for Multiple Choice Questions</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="GPT-4 EXTRACTION">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 Extraction is used to extract the option selected by the model in the evaluation of Multiple Choice Questions</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="DATA TO TEXT" target="TEXT EXTRACTION">
      <data key="d4">6.0</data>
      <data key="d5">Both Data to Text and Text Extraction involve processing and summarizing information from text</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="DATA TO TEXT" target="REPORTS">
      <data key="d4">7.0</data>
      <data key="d5">Reports are a type of document generated in data-to-text tasks</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="DATA TO TEXT" target="EXPLANATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Explanations are a type of document generated in data-to-text tasks</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="DATA TO TEXT" target="NARRATIVES">
      <data key="d4">7.0</data>
      <data key="d5">Narratives are a type of document generated in data-to-text tasks</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="FERMI PROBLEMS" target="ENRICO FERMI">
      <data key="d4">17.0</data>
      <data key="d5">Fermi problems are named after physicist Enrico Fermi</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="NAMED ENTITY RECOGNITION">
      <data key="d4">16.0</data>
      <data key="d5">Named entity recognition is a task in text extraction</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="KEYWORD EXTRACTION">
      <data key="d4">16.0</data>
      <data key="d5">Keyword extraction is a task in text extraction</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="DATA FIELDS">
      <data key="d4">1.0</data>
      <data key="d5">Data fields are specific pieces of information extracted in text extraction tasks</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="SPAM DETECTION">
      <data key="d4">9.0</data>
      <data key="d5">Spam detection is a type of text classification task</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="SENTIMENT ANALYSIS">
      <data key="d4">9.0</data>
      <data key="d5">Sentiment analysis is a type of text classification task</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="TOPIC LABELING">
      <data key="d4">9.0</data>
      <data key="d5">Topic labeling is a type of text classification task</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="AGENTINSTRUCT FLOW" target="PARAPHRASING">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct Flow includes paraphrasing as a text modification task</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="AGENTINSTRUCT FLOW" target="SIMPLIFICATION">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct Flow includes simplification as a text modification task</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="AGENTINSTRUCT FLOW" target="REDACTING OR REMOVING CONTENT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct Flow includes redacting or removing content as a text modification task</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="AGENTINSTRUCT FLOW" target="STYLING">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct Flow includes styling as a text modification task</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="AGENTINSTRUCT FLOW" target="CODE SWITCHING">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct Flow includes code switching as a text modification task</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="HYPERURICEMIA">
      <data key="d4">18.0</data>
      <data key="d5">Hyperuricemia is a condition characterized by high levels of uric acid in the blood. High levels of uric acid in the blood lead to hyperuricemia.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="HYPOURICEMIA">
      <data key="d4">18.0</data>
      <data key="d5">Hypouricemia is a condition characterized by low levels of uric acid in the blood. This medical condition, known as hypouricemia, occurs when the concentration of uric acid falls below the normal range, leading to various potential health implications. Uric acid, a waste product formed from the breakdown of purines, is typically excreted through the kidneys. When its levels are abnormally low, it can indicate underlying health issues or the influence of certain medications or dietary factors.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="PURINE">
      <data key="d4">9.0</data>
      <data key="d5">Uric acid is produced by the breakdown of purine</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="URIC ACID" target="RED MEAT">
      <data key="d4">8.0</data>
      <data key="d5">Uric acid is found in red meat</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="SEAFOOD">
      <data key="d4">8.0</data>
      <data key="d5">Uric acid is found in seafood</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="ALCOHOL CONSUMPTION">
      <data key="d4">8.0</data>
      <data key="d5">Uric acid levels can be influenced by alcohol consumption</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="PHYSICAL INACTIVITY">
      <data key="d4">8.0</data>
      <data key="d5">Uric acid levels can be influenced by physical inactivity</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPERURICEMIA" target="LABORATORY BLOOD AND URINE TESTS">
      <data key="d4">8.0</data>
      <data key="d5">Laboratory blood and urine tests are used to diagnose hyperuricemia</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPERURICEMIA" target="CARDIOVASCULAR DISEASE">
      <data key="d4">9.0</data>
      <data key="d5">Hyperuricemia is associated with an increased risk of cardiovascular disease. This condition, characterized by elevated levels of uric acid in the blood, may contribute to the development and progression of cardiovascular disease, highlighting the importance of monitoring and managing uric acid levels to potentially reduce cardiovascular risk.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPERURICEMIA" target="LABORATORY TESTS">
      <data key="d4">7.0</data>
      <data key="d5">Laboratory blood and urine tests are required to diagnose hyperuricemia</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY BLOOD AND URINE TESTS">
      <data key="d4">1.0</data>
      <data key="d5">Laboratory blood and urine tests are used to diagnose hypouricemia</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY TESTS">
      <data key="d4">7.0</data>
      <data key="d5">Laboratory blood and urine tests are required to diagnose hypouricemia</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="KIDNEY ISSUES">
      <data key="d4">7.0</data>
      <data key="d5">Hypouricemia can indicate underlying kidney issues</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LIVER ISSUES">
      <data key="d4">7.0</data>
      <data key="d5">Hypouricemia can indicate underlying liver issues</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="ASSUMPTION QUESTIONS">
      <data key="d4">9.0</data>
      <data key="d5">Assumption questions are a type of question in the LSAT Logical Reasoning test</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="STRENGTHENING/WEAKENING QUESTIONS">
      <data key="d4">9.0</data>
      <data key="d5">Strengthening/weakening questions are a type of question in the LSAT Logical Reasoning test</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="FLAW QUESTIONS">
      <data key="d4">9.0</data>
      <data key="d5">Flaw questions are a type of question in the LSAT Logical Reasoning test</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="INFERENCE QUESTIONS">
      <data key="d4">9.0</data>
      <data key="d5">Inference questions are a type of question in the LSAT Logical Reasoning test</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="AGENT" target="READING COMPREHENSION QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Agents generate reading comprehension questions based on predefined types</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="AGENT" target="CONTENT TRANSFORMATION AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Content Transformation Agent determines the subset of agents to engage in the orchestration process</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER AGENT" target="HYPOTHETICAL STUDY">
      <data key="d4">7.0</data>
      <data key="d5">Suggester Agent may introduce a hypothetical study to strengthen an argument</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER AGENT" target="GENETIC PREDISPOSITION">
      <data key="d4">7.0</data>
      <data key="d5">Suggester Agent may suggest genetic predisposition to add complexity to questions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER AGENT" target="DISTRACTOR OPTION">
      <data key="d4">7.0</data>
      <data key="d5">Suggester Agent may include a distractor option to test the ability to discern relevant from irrelevant information</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="PARAPHRASING AGENT" target="TEXT MODIFICATION TASKS">
      <data key="d4">7.0</data>
      <data key="d5">Paraphrasing Agent creates paraphrased versions of text as part of text modification tasks</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="PARAPHRASING AGENT" target="RANDOM SEED">
      <data key="d4">7.0</data>
      <data key="d5">The Paraphrasing Agent uses a random seed to create text modification tasks</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="GENETIC PREDISPOSITION" target="CARDIOVASCULAR EVENTS">
      <data key="d4">1.0</data>
      <data key="d5">Cardiovascular events can be influenced by genetic predisposition</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="PARAPHRASING" target="TEXT SIMPLIFICATION">
      <data key="d4">7.0</data>
      <data key="d5">Both are text modification techniques used to alter the text while maintaining its original meaning</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="CODE SWITCHING" target="TEXT OBFUSCATION">
      <data key="d4">6.0</data>
      <data key="d5">Both are text modification techniques used to alternate languages or make text harder to understand</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="FINANCE" target="SOCIAL IMPACT">
      <data key="d4">6.0</data>
      <data key="d5">Finance has an increasing social impact</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="FINANCE" target="FINANCIAL DISCOURSES">
      <data key="d4">6.0</data>
      <data key="d5">Finance involves financial discourses</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="FINANCE" target="MARKETS">
      <data key="d4">6.0</data>
      <data key="d5">Finance involves markets</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="FINANCE" target="ACTORS">
      <data key="d4">6.0</data>
      <data key="d5">Finance involves actors</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="FINANCE" target="INSTITUTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Finance involves institutions</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="FINANCE" target="FINANCIALIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Finance is a broader concept that encompasses financialization, which includes the increasing social impact and interconnection of financial discourses, markets, actors, and institutions</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="FINANCE" target="FOFO">
      <data key="d4">6.0</data>
      <data key="d5">Finance is one of the domains tested in the FoFo benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="NATASCHA VAN DER ZWAN" target="FINANCIALIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Natascha van der Zwan identifies three distinct research streams that have approached financialization</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="UNIVERSITY OF IOWA" target="SEA 2017 ANNUAL MEETING">
      <data key="d4">9.0</data>
      <data key="d5">The SEA 2017 Annual Meeting was held at the University of Iowa from April 6-8, 2017</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="AMERICAN ANTHROPOLOGICAL ASSOCIATION" target="SEA 2017 ANNUAL MEETING">
      <data key="d4">8.0</data>
      <data key="d5">The American Anthropological Association manages the registration and abstract submission process for the SEA 2017 Annual Meeting</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEA 2017 ANNUAL MEETING" target="IOWA CITY">
      <data key="d4">9.0</data>
      <data key="d5">Iowa City is the location where the SEA 2017 Annual Meeting was held</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEA 2017 ANNUAL MEETING" target="DECEMBER 1, 2016">
      <data key="d4">9.0</data>
      <data key="d5">December 1, 2016, is the abstract submission deadline for the SEA 2017 Annual Meeting</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="SEARCH FOOD ITEMS">
      <data key="d4">1.0</data>
      <data key="d5">View All Food Items and Search Food Items are related APIs in the same library</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="NUTRITIONAL PROFILES">
      <data key="d4">1.0</data>
      <data key="d5">View All Food Items API provides a detailed list of food items, complete with nutritional profiles</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEARCH FOOD ITEMS" target="GET FOOD ITEM DETAILS">
      <data key="d4">7.0</data>
      <data key="d5">Search Food Items can be used to find food items, and Get Food Item Details can then be used to retrieve detailed information about those items</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="CREATE MEAL PLAN" target="TRACK USER MEAL">
      <data key="d4">8.0</data>
      <data key="d5">Create Meal Plan can be used to create a meal plan, and Track User Meal can be used to track the meals consumed according to that plan</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="CREATE MEAL PLAN" target="GET DIETARY RECOMMENDATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Create Meal Plan can be used to create a meal plan, and Get Dietary Recommendations can provide additional dietary suggestions</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="CREATE MEAL PLAN" target="ASSISTANT">
      <data key="d4">9.0</data>
      <data key="d5">The Assistant uses the Create Meal Plan API to create a meal plan for the User</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="UPDATE FOOD ITEM" target="ADD NEW FOOD ITEM">
      <data key="d4">7.0</data>
      <data key="d5">Add New Food Item can be used to add new food items to the database, and Update Food Item can be used to modify the details of these items</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="UPDATE FOOD ITEM" target="DELETE FOOD ITEM">
      <data key="d4">6.0</data>
      <data key="d5">Delete Food Item can be used to remove food items from the database, and Update Food Item can be used to modify the details of existing items</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="UPDATE FOOD ITEM" target="ASSISTANT">
      <data key="d4">9.0</data>
      <data key="d5">The Assistant uses the Update Food Item API to update the nutritional information for Chana Masala</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="TRACK USER MEAL" target="GET USER NUTRITIONAL STATS">
      <data key="d4">8.0</data>
      <data key="d5">Get User Nutritional Stats can be used to retrieve nutritional statistics, which can be informed by the data collected through Track User Meal</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="TRACK USER MEAL" target="ASSISTANT">
      <data key="d4">9.0</data>
      <data key="d5">The Assistant uses the Track User Meal API to help the User track their daily meals</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="GET DIETARY RECOMMENDATIONS" target="ASSISTANT">
      <data key="d4">9.0</data>
      <data key="d5">The Assistant uses the Get Dietary Recommendations API to offer new food recommendations to the User</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="ADD NEW FOOD ITEM" target="ASSISTANT">
      <data key="d4">9.0</data>
      <data key="d5">The Assistant uses the Add New Food Item API to add the Quinoa Salad recipe to the database</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="DELETE FOOD ITEM" target="ASSISTANT">
      <data key="d4">1.0</data>
      <data key="d5">The Assistant uses the Delete Food Item API to remove Butter Chicken from the database</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="GET USER NUTRITIONAL STATS" target="ASSISTANT">
      <data key="d4">9.0</data>
      <data key="d5">The Assistant uses the Get User Nutritional Stats API to generate a nutritional summary for the User at the end of the week</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="AGENT-INSTRUCT" target="ASSISTANT">
      <data key="d4">8.0</data>
      <data key="d5">Agent-Instruct is a system that helps the Assistant create multi-turn conversations to assist users</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="CHANA MASALA" target="DATABASE">
      <data key="d4">7.0</data>
      <data key="d5">The user wants to update the Chana Masala recipe in the database</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="CHANA MASALA" target="FOOD_ID">
      <data key="d4">8.0</data>
      <data key="d5">The unique identifier (food_id) is required to update the Chana Masala recipe in the database</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BUTTER CHICKEN" target="DATABASE">
      <data key="d4">7.0</data>
      <data key="d5">The user wants to remove the Butter Chicken recipe from the database</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BUTTER CHICKEN" target="FOOD_ID">
      <data key="d4">8.0</data>
      <data key="d5">The unique identifier (food_id) is required to remove the Butter Chicken recipe from the database</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="QUINOA SALAD" target="DATABASE">
      <data key="d4">7.0</data>
      <data key="d5">The user wants to add the Quinoa Salad recipe to the database</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="QUINOA SALAD" target="NUTRITIONAL INFORMATION">
      <data key="d4">8.0</data>
      <data key="d5">Nutritional information is required to add the Quinoa Salad recipe to the database</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="CALORIC GOAL">
      <data key="d4">9.0</data>
      <data key="d5">The vegetarian meal plan is designed to meet a caloric goal of 1500 calories per day</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="OATMEAL WITH FRUITS">
      <data key="d4">8.0</data>
      <data key="d5">Oatmeal with fruits is included in the vegetarian meal plan for breakfast</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="ALMOND MILK">
      <data key="d4">8.0</data>
      <data key="d5">Almond milk is included in the vegetarian meal plan for breakfast</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="CHICKPEA SALAD">
      <data key="d4">8.0</data>
      <data key="d5">Chickpea salad is included in the vegetarian meal plan for lunch</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="WHOLE WHEAT BREAD">
      <data key="d4">8.0</data>
      <data key="d5">Whole wheat bread is included in the vegetarian meal plan for lunch</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="MIXED VEGETABLE STIR FRY">
      <data key="d4">8.0</data>
      <data key="d5">Mixed vegetable stir fry is included in the vegetarian meal plan for dinner</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="BROWN RICE">
      <data key="d4">8.0</data>
      <data key="d5">Brown rice is included in the vegetarian meal plan for dinner</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="DAY 1">
      <data key="d4">9.0</data>
      <data key="d5">Day 1 is the first day in the vegetarian meal plan</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="DAY 2">
      <data key="d4">9.0</data>
      <data key="d5">Day 2 is the second day in the vegetarian meal plan</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="DAY 3">
      <data key="d4">9.0</data>
      <data key="d5">Day 3 is the third day in the vegetarian meal plan</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="DAY 4">
      <data key="d4">9.0</data>
      <data key="d5">Day 4 is the fourth day in the vegetarian meal plan</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="DAY 5">
      <data key="d4">9.0</data>
      <data key="d5">Day 5 is the fifth day in the vegetarian meal plan</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="DAY 6">
      <data key="d4">9.0</data>
      <data key="d5">Day 6 is the sixth day in the vegetarian meal plan</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="DAY 7">
      <data key="d4">9.0</data>
      <data key="d5">Day 7 is the seventh day in the vegetarian meal plan</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-2.5-DATASET">
      <data key="d4">8.0</data>
      <data key="d5">Orca-2.5-dataset is used to train the Orca-2.5 model</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-BENCH">
      <data key="d4">14.0</data>
      <data key="d5">Orca-2.5 is a baseline model evaluated on the Orca-Bench dataset</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-2.5" target="TABLE 6">
      <data key="d4">8.0</data>
      <data key="d5">Orca 2.5's performance is presented in Table 6</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-2.5" target="TABLE 7">
      <data key="d4">8.0</data>
      <data key="d5">Orca 2.5's hallucination rates and quality scores are presented in Table 7</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-BENCH" target="OPEN DOMAIN QUESTION ANSWERING (ODQA)">
      <data key="d4">8.0</data>
      <data key="d5">ODQA is a category in the Orca-Bench dataset</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-BENCH" target="COMPLEX ODQA">
      <data key="d4">22.0</data>
      <data key="d5">ORCA-BENCH is a dataset that includes a subset of questions categorized under Complex ODQA. Complex ODQA, which stands for Open-Domain Question Answering, is a specific subset within the broader ODQA category in the ORCA-BENCH dataset. This subset focuses on more intricate and challenging questions, providing a valuable resource for evaluating and advancing AI and ML models in the field of open-domain question answering.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="MULTI-TURN INTERACTION">
      <data key="d4">1.0</data>
      <data key="d5">Multi-turn interaction is a type of interaction in the Orca-Bench dataset</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-BENCH" target="CHATGPT">
      <data key="d4">14.0</data>
      <data key="d5">ChatGPT is a baseline model evaluated on the Orca-Bench dataset</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="LLAMA3-8B-INSTRUCT">
      <data key="d4">14.0</data>
      <data key="d5">LLAMA3-8B-Instruct is a baseline model evaluated on the Orca-Bench dataset</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="LLAMA3-8B-INSTRUCT" target="TABLE 7">
      <data key="d4">8.0</data>
      <data key="d5">LLAMA3-8B-instruct's performance is presented in Table 7</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="FOFO" target="HEALTHCARE">
      <data key="d4">6.0</data>
      <data key="d5">Healthcare is one of the domains tested in the FoFo benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="FOFO" target="MARKETING">
      <data key="d4">6.0</data>
      <data key="d5">Marketing is one of the domains tested in the FoFo benchmark</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="FOFO" target="ORCA-3-7B">
      <data key="d4">14.0</data>
      <data key="d5">FoFo is used to evaluate the performance of Orca-3-7B on format-following tasks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="FOFO" target="GEMINI PRO">
      <data key="d4">8.0</data>
      <data key="d5">FoFo is used to evaluate the performance of Gemini Pro on format-following tasks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="FOFO" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">FOFO is a benchmark used in the Open-Ended Generation task</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="FOFO" target="VERSION 0613">
      <data key="d4">7.0</data>
      <data key="d5">Version 0613 of GPT-4 is used in the FOFO benchmark</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="IFEVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">IFEval is a benchmark used in the Open-Ended Generation task</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="INFOBENCH" target="DRFR">
      <data key="d4">1.0</data>
      <data key="d5">InFoBench uses the Decomposed Requirements Following Ratio (DRFR) metric to evaluate instruction-following capability</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="INFOBENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">InfoBench is a benchmark used in the Open-Ended Generation task</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="INFOBENCH" target="VERSION 1106-PREVIEW">
      <data key="d4">1.0</data>
      <data key="d5">Version 1106-preview of GPT-4 is used in the InfoBench benchmark</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EQBENCH" target="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">1.0</data>
      <data key="d5">EQBench GPT-4 Extraction System Message is used to extract emotion scores from responses in the EQBench dataset</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="INSTRUCTION PHASE" target="REFINEMENT PHASE">
      <data key="d4">6.0</data>
      <data key="d5">The instruction phase precedes the refinement phase in the development of questions for the dataset</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="SYSTEM MESSAGE" target="USER MESSAGE">
      <data key="d4">7.0</data>
      <data key="d5">System messages and user messages are part of a multi-turn interaction in the Orca-Bench dataset</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="USER MESSAGE" target="ASSISTANT MESSAGE">
      <data key="d4">7.0</data>
      <data key="d5">User messages and assistant messages are part of a multi-turn interaction in the Orca-Bench dataset</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="TEACHER" target="STUDENT">
      <data key="d4">8.0</data>
      <data key="d5">The teacher (GPT-4) crafts each turn in a multi-turn interaction, and the student generates responses conditioned on the preceding conversation history</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="STUDENT" target="STUDENT RESPONSE">
      <data key="d4">9.0</data>
      <data key="d5">The student provides the student response to the question</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="LSAT" target="LSAT-RC">
      <data key="d4">8.0</data>
      <data key="d5">LSAT-RC is a reading comprehension sub-task of the LSAT</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="LSAT" target="LSAT-LR">
      <data key="d4">8.0</data>
      <data key="d5">LSAT-LR is a logical reasoning sub-task of the LSAT</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA 2.5" target="ORCA-3-7B">
      <data key="d4">25.0</data>
      <data key="d5">ORCA-3-7B has demonstrated significant improvements over ORCA 2.5 in various benchmarks, showcasing advancements in performance and capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="SAT" target="SAT-EN">
      <data key="d4">8.0</data>
      <data key="d5">SAT-EN is an English sub-task of the SAT</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="SAT" target="SAT-MATH">
      <data key="d4">8.0</data>
      <data key="d5">SAT-Math is a math sub-task of the SAT</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3-7B" target="DROOP">
      <data key="d4">14.0</data>
      <data key="d5">DROOP is used to evaluate the performance of Orca-3-7B on reading comprehension tasks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3-7B" target="BBH MULTISTEP-ARITHMETIC-TWO">
      <data key="d4">14.0</data>
      <data key="d5">BBH multistep-arithmetic-two is used to evaluate the performance of Orca-3-7B on multi-step arithmetic problems</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3-7B" target="FOFO BENCHMARK">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B was evaluated on the FoFo benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="TABLE 6">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B's performance is presented in Table 6</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="TABLE 7">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B's hallucination rates and quality scores are presented in Table 7</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated on the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="FORMAT FOLLOWING" target="GEMINI PRO">
      <data key="d4">14.0</data>
      <data key="d5">Format Following has surpassed the capabilities of Gemini Pro</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GEMINI PRO" target="FOFO BENCHMARK">
      <data key="d4">6.0</data>
      <data key="d5">Scores for Gemini Pro on the FoFo benchmark are taken from the original paper</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GEMINI PRO" target="TABLE 6">
      <data key="d4">7.0</data>
      <data key="d5">Gemini Pro's scores are referenced in Table 6</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GAOKAO-ENGLISH" target="GAOKAO">
      <data key="d4">8.0</data>
      <data key="d5">Gaokao-English is an English sub-task of the Gaokao</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-SUM" target="HUGGING FACE">
      <data key="d4">8.0</data>
      <data key="d5">Data for the Orca-Sum benchmark was sampled from Hugging Face</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="MMLU-MED">
      <data key="d4">7.0</data>
      <data key="d5">MMLU-Med is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="MEDQA-US">
      <data key="d4">7.0</data>
      <data key="d5">MedQA-US is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="MEDMCQA">
      <data key="d4">7.0</data>
      <data key="d5">MedMCQA is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="PUBMEDQA">
      <data key="d4">7.0</data>
      <data key="d5">PubMedQA is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="BIOASQ">
      <data key="d4">1.0</data>
      <data key="d5">BioASQ is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PUBMEDQA" target="MIRAGE DATASETS">
      <data key="d4">9.0</data>
      <data key="d5">PubMedQA is part of the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="BIOASQ" target="MIRAGE DATASETS">
      <data key="d4">9.0</data>
      <data key="d5">BioASQ is part of the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MEDMEDQA" target="MIRAGE DATASETS">
      <data key="d4">9.0</data>
      <data key="d5">MedMedQA is part of the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="USMEDMCQA" target="MIRAGE DATASETS">
      <data key="d4">9.0</data>
      <data key="d5">USMedMCQA is part of the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-2.5-7B" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">Orca-2.5-7B is evaluated on the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT-V0.1" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">Mistral-7B-Instruct-v0.1 is evaluated on the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MEDRAG" target="MIRAGE DATASETS">
      <data key="d4">9.0</data>
      <data key="d5">MedRAG is the retrieval mechanism used across all models on the MIRAGE Datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="JIAHAO ZHANG" target="MOHAMMED LATIF SIDDIQ">
      <data key="d4">8.0</data>
      <data key="d5">Mohammed Latif Siddiq and Jiahao Zhang co-authored the paper "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks" published in the Proceedings of the 46th International Conference on Software Engineering, NIER Track (ICSE-NIER &#8217;24) in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="JIAHAO ZHANG" target="LINDSAY RONEY">
      <data key="d4">8.0</data>
      <data key="d5">Jiahao Zhang and Lindsay Roney co-authored the paper "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks" published in the Proceedings of the 46th International Conference on Software Engineering, NIER Track (ICSE-NIER &#8217;24) in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="JIAHAO ZHANG" target="JOANNA C. S. SANTOS">
      <data key="d4">8.0</data>
      <data key="d5">Jiahao Zhang and Joanna C. S. Santos co-authored the paper "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks" published in the Proceedings of the 46th International Conference on Software Engineering, NIER Track (ICSE-NIER &#8217;24) in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="LINDSAY RONEY" target="MOHAMMED LATIF SIDDIQ">
      <data key="d4">8.0</data>
      <data key="d5">Mohammed Latif Siddiq and Lindsay Roney co-authored the paper "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks" published in the Proceedings of the 46th International Conference on Software Engineering, NIER Track (ICSE-NIER &#8217;24) in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="LINDSAY RONEY" target="JOANNA C. S. SANTOS">
      <data key="d4">8.0</data>
      <data key="d5">Lindsay Roney and Joanna C. S. Santos co-authored the paper "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks" published in the Proceedings of the 46th International Conference on Software Engineering, NIER Track (ICSE-NIER &#8217;24) in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ILIA SHUMAILOV" target="ZAKHAR SHUMAYLOV">
      <data key="d4">8.0</data>
      <data key="d5">Ilia Shumailov and Zakhar Shumaylov co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ILIA SHUMAILOV" target="YIREN ZHAO">
      <data key="d4">8.0</data>
      <data key="d5">Ilia Shumailov and Yiren Zhao co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ILIA SHUMAILOV" target="NICOLAS PAPERNOT">
      <data key="d4">8.0</data>
      <data key="d5">Ilia Shumailov and Nicolas Papernot co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ILIA SHUMAILOV" target="ROSS ANDERSON">
      <data key="d4">8.0</data>
      <data key="d5">Ilia Shumailov and Ross Anderson co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ZAKHAR SHUMAYLOV" target="YIREN ZHAO">
      <data key="d4">8.0</data>
      <data key="d5">Zakhar Shumaylov and Yiren Zhao co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ZAKHAR SHUMAYLOV" target="NICOLAS PAPERNOT">
      <data key="d4">8.0</data>
      <data key="d5">Zakhar Shumaylov and Nicolas Papernot co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ZAKHAR SHUMAYLOV" target="ROSS ANDERSON">
      <data key="d4">8.0</data>
      <data key="d5">Zakhar Shumaylov and Ross Anderson co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="YIREN ZHAO" target="NICOLAS PAPERNOT">
      <data key="d4">8.0</data>
      <data key="d5">Yiren Zhao and Nicolas Papernot co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="YIREN ZHAO" target="ROSS ANDERSON">
      <data key="d4">8.0</data>
      <data key="d5">Yiren Zhao and Ross Anderson co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="NICOLAS PAPERNOT" target="ROSS ANDERSON">
      <data key="d4">8.0</data>
      <data key="d5">Nicolas Papernot and Ross Anderson co-authored the paper "The curse of recursion: Training on generated data makes models forget" published in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="MOHAMMED LATIF SIDDIQ" target="JOANNA C. S. SANTOS">
      <data key="d4">8.0</data>
      <data key="d5">Mohammed Latif Siddiq and Joanna C. S. Santos co-authored the paper "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks" published in the Proceedings of the 46th International Conference on Software Engineering, NIER Track (ICSE-NIER &#8217;24) in 2024</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="NUMERICAL DISCRETE REASONING" target="CRITICAL COMPREHENSION QUESTION">
      <data key="d4">5.0</data>
      <data key="d5">Both are types of questions used to assess comprehension and reasoning skills</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="EVALUATIVE COMPREHENSION QUESTION" target="VOCABULARY AND LANGUAGE USE">
      <data key="d4">5.0</data>
      <data key="d5">Both are types of questions used to assess different aspects of text comprehension</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="RELATIONSHIP COMPREHENSION QUESTION" target="SEQUENCING EVENTS">
      <data key="d4">5.0</data>
      <data key="d5">Both are types of questions used to assess understanding of relationships and sequences in the text</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="STRENGTHEN" target="WEAKEN">
      <data key="d4">6.0</data>
      <data key="d5">Both are types of questions used to assess the strength of an argument</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="ASSUMPTION" target="FLAW">
      <data key="d4">6.0</data>
      <data key="d5">Both are types of questions used to assess the logical structure of an argument</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="INFERENCE" target="PRINCIPLE">
      <data key="d4">6.0</data>
      <data key="d5">Both are types of questions used to assess the underlying logic and principles in the text</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="METHOD OF REASONING" target="RESOLVE THE PARADOX">
      <data key="d4">6.0</data>
      <data key="d5">Both are types of questions used to assess the logical construction and resolution of contradictions in the text</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT EXPANSION" target="TEXT TRANSLATION">
      <data key="d4">6.0</data>
      <data key="d5">Both are text modification techniques used to add information or convert text while preserving its meaning</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT FORMATTING" target="SENTIMENT MODIFICATION">
      <data key="d4">6.0</data>
      <data key="d5">Both are text modification techniques used to alter the appearance or tone of the text</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT ANNOTATION" target="KEYWORD REPLACEMENT">
      <data key="d4">6.0</data>
      <data key="d5">Both are text modification techniques used to add context or substitute specific words</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT REMOVING" target="TEXT CAPITALIZATION">
      <data key="d4">6.0</data>
      <data key="d5">Both are text modification techniques used to alter the content or case of the text</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT STYLING" target="CONTENT REWRITING">
      <data key="d4">6.0</data>
      <data key="d5">Both are text modification techniques used to emphasize or extensively modify the text</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="DATA NORMALIZATION" target="PLAGIARISM REWORDING">
      <data key="d4">6.0</data>
      <data key="d5">Both are text modification techniques used to ensure consistency or originality</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXTUAL ENTAILMENT" target="REWRITING WITH VOCABULARY LIMITATIONS">
      <data key="d4">6.0</data>
      <data key="d5">Both are text modification techniques used to modify text with specific constraints</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION FLOW" target="INSTRUCTION TAXONOMY">
      <data key="d4">7.0</data>
      <data key="d5">Instruction Taxonomy is part of the Text Modification Flow process</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="INSTRUCTION TAXONOMY" target="SEED INSTRUCTION GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">Instruction Taxonomy is used in the Seed Instruction Generation process</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="ANSWER OPTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Answer Options and Student Response are used together to extract the selected option</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="FINAL ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">The final answer is extracted from the student response</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EXACT MATCH/SPAN EXTRACTION PROBLEMS" target="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">9.0</data>
      <data key="d5">Maths GPT-4 Extraction System Message is used for evaluating math-based Exact Match/Span Extraction Problems</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EXACT MATCH/SPAN EXTRACTION PROBLEMS" target="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d4">9.0</data>
      <data key="d5">General Extraction System Message is used for evaluating non-math Exact Match/Span Extraction Problems</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="OPTIONS" target="FINAL ANSWER">
      <data key="d4">8.0</data>
      <data key="d5">The final answer is selected from the provided options</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MODEL'S ANSWER" target="GROUND-TRUTH ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">The model's answer is compared with the ground-truth answer to determine correctness</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="GROUND-TRUTH ANSWER" target="FINAL VERDICT">
      <data key="d4">9.0</data>
      <data key="d5">The final verdict is based on the comparison between the model's answer and the ground-truth answer</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EMOTION" target="SCORE">
      <data key="d4">9.0</data>
      <data key="d5">Each emotion is assigned a score in the EQBench dataset</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="SCORE" target="CRITIQUE">
      <data key="d4">8.0</data>
      <data key="d5">The critique provides an explanation for the revised scores</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="RESIGNED" target="ELLIOT">
      <data key="d4">8.0</data>
      <data key="d5">Elliot feels resigned about the situation, scored 7</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="RESIGNED" target="EMOTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Emotions include the feeling of being Resigned</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ANGRY" target="ELLIOT">
      <data key="d4">6.0</data>
      <data key="d5">Elliot feels angry at himself for putting himself in this situation, scored 3</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ANGRY" target="REVISED SCORES">
      <data key="d4">8.0</data>
      <data key="d5">Revised scores include a score of 3 for the emotion Angry</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ANGRY" target="EMOTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Emotions include the feeling of being Angry</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HOPEFUL" target="ELLIOT">
      <data key="d4">7.0</data>
      <data key="d5">Elliot feels hopeful that Alex might reciprocate his feelings, scored 5</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HOPEFUL" target="REVISED SCORES">
      <data key="d4">8.0</data>
      <data key="d5">Revised scores include a score of 5 for the emotion Hopeful</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HOPEFUL" target="EMOTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Emotions include the feeling of being Hopeful</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMBARRASSED" target="ELLIOT">
      <data key="d4">9.0</data>
      <data key="d5">Elliot feels embarrassed for putting Alex in an awkward position, scored 8</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMBARRASSED" target="REVISED SCORES">
      <data key="d4">8.0</data>
      <data key="d5">Revised scores include a score of 8 for the emotion Embarrassed</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMBARRASSED" target="EMOTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Emotions include the feeling of being Embarrassed</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="SUMMARY INSTRUCTION" target="GENERATED SUMMARY">
      <data key="d4">8.0</data>
      <data key="d5">Summary Instruction involves evaluating a Generated Summary for correctness</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="SUMMARY INSTRUCTION" target="HALLUCINATION EVALUATION">
      <data key="d4">8.0</data>
      <data key="d5">Summary Instruction involves evaluating a Generated Summary for hallucinations</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GENERATED SUMMARY" target="HALLUCINATION EVALUATION">
      <data key="d4">8.0</data>
      <data key="d5">Generated Summary is evaluated for hallucinations</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GENERATED SUMMARY" target="QUALITY EVALUATION">
      <data key="d4">8.0</data>
      <data key="d5">Generated Summary is evaluated for quality</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="PROMPT TEMPLATE" target="HALLUCINATION EVALUATION">
      <data key="d4">7.0</data>
      <data key="d5">Prompt Template is used for evaluating hallucinations in a Generated Summary</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="PROMPT TEMPLATE" target="QUALITY EVALUATION">
      <data key="d4">7.0</data>
      <data key="d5">Prompt Template is used for evaluating the quality of a Generated Summary</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="TEXT SUMMARIZATION" target="HALLUCINATION EVALUATION">
      <data key="d4">8.0</data>
      <data key="d5">Text Summarization involves evaluating the generated summary for hallucinations</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="TEXT SUMMARIZATION" target="QUALITY EVALUATION">
      <data key="d4">8.0</data>
      <data key="d5">Text Summarization involves evaluating the generated summary for quality</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="SUMMARIZATION QUALITY" target="QUALITY EVALUATION">
      <data key="d4">8.0</data>
      <data key="d5">Summarization Quality involves evaluating the quality of a generated summary</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
  </graph>
</graphml>