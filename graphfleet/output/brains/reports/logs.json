{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 47 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 47 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 47 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 47 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 47 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 47 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 42 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 42 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 42 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 42 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 41 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 41 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 37 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 37 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 16 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 16 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1305, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1509, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Samsung-SSD-T7/Qredence/GraphFleet/GraphFleet1/gfleetenv/lib/python3.11/site-packages/openai/_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}\n", "source": "Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-05-15 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
