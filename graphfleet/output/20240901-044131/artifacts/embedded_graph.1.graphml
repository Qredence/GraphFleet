<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d6" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d5" for="edge" attr.name="description" attr.type="string" />
  <key id="d4" for="edge" attr.name="weight" attr.type="double" />
  <key id="d3" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d2" for="node" attr.name="source_id" attr.type="string" />
  <key id="d1" for="node" attr.name="description" attr.type="string" />
  <key id="d0" for="node" attr.name="type" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="GRAPH RAG APPROACH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Graph RAG approach is a sophisticated method designed for automating the generation of questions based on dataset descriptions, employing a structured pipeline for effective processing and analysis. This approach integrates several advanced techniques, including knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS), to enhance human sensemaking across extensive text corpora. By focusing on global summarization, the Graph RAG approach utilizes knowledge graphs derived from large language model (LLM) outputs, facilitating a more comprehensive understanding of the data. Additionally, it emphasizes query-focused summarization by combining RAG with a graph-based text index, which significantly improves the diversity and comprehensiveness of the generated answers, making it a valuable tool for processing text data.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Query-focused summarization (QFS) is a task that aims to generate summaries based on specific user queries, rather than simply retrieving text excerpts.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Large language models (LLMs) are advanced AI models designed to understand and generate human-like text, often used for tasks like summarization and question answering.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="SOURCE DOCUMENTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The entity "SOURCE DOCUMENTS" refers to the original texts utilized in the Graph RAG approach. These documents serve as the foundational materials from which information is extracted for processing. Specifically, they provide the input texts necessary for the effective functioning of the Graph RAG methodology, ensuring that the data utilized is both authentic and relevant.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="COMMUNITY SUMMARIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">**COMMUNITY SUMMARIES** are aggregated descriptions that encapsulate elements within a community, serving to generate answers to user queries. They provide high-level overviews of information derived from groups within a knowledge graph, offering condensed representations of closely-related entities. These summaries are crafted to enhance response quality, particularly in the Graph RAG approach, by distilling insights from original texts. Overall, COMMUNITY SUMMARIES play a crucial role in improving the efficiency and effectiveness of information retrieval within professional networks.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,4930fce6da868f894757a9da465807ba,ac21ebe9a9d70d691c717f961d3f10c8,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="MICROSOFT RESEARCH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Research is a division of Microsoft focused on advancing the state of the art in computing through research and innovation.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Strategic Missions and Technologies is a division within Microsoft that focuses on strategic initiatives and technological advancements.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="MICROSOFT OFFICE OF THE CTO">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Office of the CTO is a division that oversees technological strategy and innovation within Microsoft.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="DARREN EDGE">
      <data key="d0">PERSON</data>
      <data key="d1">Darren Edge is a researcher affiliated with Microsoft Research, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="HA TRINH">
      <data key="d0">PERSON</data>
      <data key="d1">Ha Trinh is a researcher affiliated with Microsoft Research, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="NEWMAN CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Newman Cheng is a researcher affiliated with Microsoft Strategic Missions and Technologies, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="JOSHUA BRADLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Bradley is a researcher affiliated with Microsoft Strategic Missions and Technologies, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="ALEX CHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Chao is a researcher affiliated with Microsoft Office of the CTO, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="APURVA MODY">
      <data key="d0">PERSON</data>
      <data key="d1">Apurva Mody is a researcher affiliated with Microsoft Office of the CTO, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="STEVEN TRUITT">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Truitt is a researcher affiliated with Microsoft Strategic Missions and Technologies, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="JONATHAN LARSON">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Larson is a researcher affiliated with Microsoft Research, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Retrieval-augmented generation (RAG) is an approach that combines retrieval of relevant information from external sources with generative models to answer user queries.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="GLOBAL SENSEMAKING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Global sensemaking refers to the process of understanding and interpreting large datasets to derive insights that go beyond the explicit information contained within the texts.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="COMMUNITY DETECTION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Community detection is a method employed to identify groups of closely-related entities within a dataset, enhancing the efficiency of summarization and analysis. This process involves recognizing groups of nodes in a network that exhibit a higher density of connections among themselves compared to their connections with the broader network. By facilitating the identification of these interconnected groups, community detection plays a crucial role in understanding the structure and dynamics of complex networks.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LEIDEN ALGORITHM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Leiden algorithm is a sophisticated community detection method recognized for its ability to efficiently recover hierarchical structures within large-scale graphs. It is specifically designed for identifying clusters in networks, showcasing both efficiency and accuracy in its performance. This makes the Leiden algorithm a valuable tool for analyzing complex networks and understanding the underlying community structures.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TOKEN RANGE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Token range refers to the number of tokens (words or characters) in a dataset, which can impact the performance of summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Query-focused abstractive summarization is a task that aims to summarize content based on specific queries, often requiring handling large volumes of text.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LLM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM, or Large Language Model, refers to advanced artificial intelligence models that are specifically designed to understand and generate human-like text. These models utilize input data or prompts to produce coherent and contextually relevant text, making them applicable in various fields, including summarization and other natural language processing tasks. Their capabilities enable them to engage in complex language tasks, thereby enhancing communication and interaction in numerous applications.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TEXT CHUNKS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The entity "TEXT CHUNKS" refers to segments of input texts that are extracted from source documents. These text chunks are specifically processed for further analysis, allowing for a more manageable and focused examination of the information contained within the original documents.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="KURATOV ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Kuratov et al. (2024) is a reference to a study that explores the limitations of large language models (LLMs) in processing longer text chunks. The study highlights the performance challenges associated with these models when handling extended text, emphasizing the need for improved algorithms to enhance their efficacy in text chunk processing. Overall, Kuratov et al. (2024) provides valuable insights into the performance of language models in relation to longer text segments, contributing to the ongoing discourse on optimizing algorithmic capabilities in natural language processing.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LIU ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Liu et al. (2023) is a comprehensive study that explores various aspects of agentic systems, particularly focusing on the design of search spaces and the limitations of large language models (LLMs) in processing longer text chunks. The research delves into the challenges posed by LLM context windows, highlighting their constraints when handling extensive information. Additionally, Liu et al. (2023) investigates the integration of search algorithms with language model agents, aiming to enhance their functionality and efficiency in navigating complex data environments. This multifaceted approach provides valuable insights into the interplay between search methodologies and language processing technologies.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,64476a39d7d8b87b399e3bd3cead79c7,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="HOTPOTQA">
      <data key="d0">DATASET</data>
      <data key="d1">HotPotQA is a comprehensive dataset designed for evaluating question-answering systems, particularly focusing on multi-hop reasoning tasks. It assesses the ability of models to reason and retrieve information from multiple sources, specifically requiring retrieval over various Wikipedia passages to answer complex questions. The dataset contains 113,000 diverse, multi-hop, and explainable question-answer pairs, which have been meticulously crafted by crowdworkers. HotPotQA not only emphasizes entity reference detection but also evaluates the reasoning capabilities of language models, including their performance in answering questions based on multiple supporting documents. Overall, it serves as a benchmark for measuring the effectiveness of question-answering systems in handling intricate reasoning challenges.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,64476a39d7d8b87b399e3bd3cead79c7,8180bf20b7577f3eee40df5991e2886d,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="COMMUNITY DETECTION ALGORITHMS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Community detection algorithms are specialized methods designed to identify and partition graphs into modular communities comprised of closely-related nodes. These algorithms focus on uncovering groups of interconnected nodes within a graph, facilitating the understanding of the underlying structure and relationships within complex networks. By effectively identifying these communities, the algorithms enhance the analysis of network dynamics and interactions, making them essential tools in various fields, including social network analysis, biology, and information retrieval.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="MODULARITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Modularity is a property of a graph that measures the strength of division of a network into modules or communities.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LLAMA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Llama is a series of large language models designed for efficient text processing and generation, capable of handling various natural language tasks.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="GEMINI">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Gemini is a series of advanced language models that utilize in-context learning to summarize and process text effectively.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="ACHIAM ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Achiam et al. (2023) is a reference to a study discussing the capabilities of the GPT series in summarization tasks.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="BROWN ET AL. (2020)">
      <data key="d0">PERSON</data>
      <data key="d1">Brown et al. (2020) is a significant study that explores the capabilities of language models, particularly highlighting their function as few-shot learners. The research delves into the foundational aspects of large language models, detailing their training methodologies and various applications. This comprehensive examination underscores the advancements in natural language processing and the potential of these models to perform tasks with minimal examples, thereby enhancing their utility in diverse contexts.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,93cb0d0456e0822b5fe30a3e627405f8,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TOUVRON ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Touvron et al. (2023) is a reference to a study that explores significant advancements in language models, specifically focusing on the Llama series. The study examines the performance of these models across various tasks, highlighting their capabilities and contributions to the field of Natural Language Processing. Through this analysis, Touvron et al. (2023) provides valuable insights into the evolution and effectiveness of contemporary language models, underscoring their relevance in ongoing research and application within the domain.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="ANIL ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Anil et al. (2023) is a reference to a study that discusses the Gemini series of models and their capabilities in text processing.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="GPT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="NAMED ENTITIES">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Named entities are specific categories of information such as people, places, and organizations that are extracted from text.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="FEW-SHOT EXAMPLES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Few-shot examples are specific instances provided to the LLM to improve its performance in specialized domains by offering context and guidance.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="COVARIATES">
      <data key="d0">DATA TYPE</data>
      <data key="d1">COVARIATES refer to additional variables or attributes that are associated with extracted entities, specifically highlighting claims linked to those entities. These covariates play a crucial role in enhancing the understanding and analysis of the relationships and characteristics within a given dataset.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="EXTRACTION PROMPT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">An extraction prompt is a specific instruction given to the LLM to guide it in identifying and extracting relevant information from text.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="GLEANINGS">
      <data key="d0">PROCESS</data>
      <data key="d1">Gleanings refer to multiple rounds of extraction attempts aimed at identifying any missed entities in the text.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Abstractive summarization is a method where the LLM generates concise summaries that capture the essence of the original text, including implied relationships.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ENTITY GRAPH">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">An entity graph is a representation of entities and their relationships, structured as nodes and edges to illustrate connections.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="MULTIHOP-RAG DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The MultiHop-RAG dataset is a collection of data used for testing and evaluating the performance of the Graph RAG approach.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HIERARCHICAL CLUSTERING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Hierarchical clustering is a method of organizing data into a hierarchy of clusters based on similarity.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="GLOBAL SUMMARIZATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Global summarization refers to the process of creating comprehensive summaries that capture the overall structure and semantics of a dataset.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="NODE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">A node is an individual entity within a graph, representing a specific item or concept connected to other nodes through relationships.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="EDGE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">An edge is a connection between two nodes in a graph, representing the relationship or interaction between those entities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="CLAIMS">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Claims are assertions or statements linked to entities, providing additional context or information about them.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="GRAPH INDEX">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LEAF-LEVEL COMMUNITIES">
      <data key="d0">COMMUNITY STRUCTURE</data>
      <data key="d1">Leaf-level communities are the lowest hierarchical level in a community structure, where element summaries are prioritized and added to the LLM context window for processing.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="HIGHER-LEVEL COMMUNITIES">
      <data key="d0">COMMUNITY STRUCTURE</data>
      <data key="d1">Higher-level communities are the upper hierarchical levels in a community structure, which summarize element summaries and manage sub-communities based on token limits.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="LLM CONTEXT WINDOW">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The LLM context window is a limit on the amount of information that can be processed at one time, affecting how summaries and answers are generated.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="GLOBAL ANSWER">
      <data key="d0">OUTPUT</data>
      <data key="d1">The global answer is the final response generated for a user query, synthesized from community summaries and evaluated for helpfulness.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="USER QUERY">
      <data key="d0">REQUEST</data>
      <data key="d1">A user query is a question posed by a user seeking information or insights from the community summaries.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="DATASET EXAMPLES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Dataset examples are specific instances of data used to illustrate potential user tasks and questions in the context of information retrieval.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="PODCAST TRANSCRIPTS">
      <data key="d0">DATASET</data>
      <data key="d1">Podcast transcripts are written records of conversations between technology leaders, used as a dataset for analysis and question generation.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="NEWS ARTICLES">
      <data key="d0">DATASET</data>
      <data key="d1">News articles are written reports on current events, used as a dataset for analysis and question generation in various categories.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="EVALUATION">
      <data key="d0">PROCESS</data>
      <data key="d1">The entity "EVALUATION" refers to the systematic process of assessing the effectiveness and performance of various systems and models, particularly in the context of RAG (Retrieval-Augmented Generation) systems. This evaluation focuses on determining how well these systems generate high-level understanding questions from datasets. Additionally, it encompasses a broader scope of assessing the performance or effectiveness of models and techniques across specific tasks or domains. Through this comprehensive evaluation process, stakeholders can gain insights into the capabilities and limitations of these systems, facilitating improvements and advancements in the field.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="NODES">
      <data key="d0">DATA ELEMENT</data>
      <data key="d1">Nodes are the individual elements or entities within a community structure that represent distinct points of interest or data.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="EDGES">
      <data key="d0">DATA ELEMENT</data>
      <data key="d1">Edges are the connections between nodes in a community structure, indicating relationships or interactions between the entities.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="SUB-COMMUNITIES">
      <data key="d0">COMMUNITY STRUCTURE</data>
      <data key="d1">Sub-communities are smaller groups within higher-level communities that can be summarized and substituted to fit within the LLM context window.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="DATASET">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The entity "DATASET" refers to a collection of related data utilized for analysis and training purposes in the fields of machine learning and artificial intelligence (AI). It serves as a foundational component for generating insights or formulating questions, thereby playing a crucial role in data analysis. Datasets are essential for enabling algorithms to learn from data, facilitating the development of models that can make predictions or identify patterns.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="USER">
      <data key="d0">PERSON</data>
      <data key="d1">The entity "USER" refers to an individual or entity that engages with a dataset and a large language model (LLM) to generate questions or perform tasks related to data analysis. Specifically, this user is seeking assistance in creating a vegetarian diet plan and tracking their meals. They are actively involved in providing feedback on the success of the meal plan, indicating a commitment to optimizing their dietary choices. This interaction highlights the user's role not only as a consumer of information but also as a participant in the iterative process of meal planning and evaluation.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a,26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="TASK">
      <data key="d0">ACTIVITY</data>
      <data key="d1">The entity "TASK" refers to a specific activity or job that a user aims to accomplish utilizing a dataset and a large language model (LLM). This often involves processes such as question generation or data interpretation, highlighting the practical applications of LLMs in various tasks. However, no additional context or descriptions were provided to further elaborate on the nature or scope of the tasks associated with this entity.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="QUESTION">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The entity "QUESTION" refers to an inquiry that serves as a prompt or problem presented to a student, necessitating a response based on available options. This inquiry is generated by a Large Language Model (LLM) and demands a thorough understanding of the dataset and its contents to formulate a comprehensive answer. In essence, a question encapsulates both the need for engagement from the student and the requirement for the LLM to interpret and analyze the underlying data effectively.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="EVALUATION METRICS">
      <data key="d0">CRITERIA</data>
      <data key="d1">The entity "EVALUATION METRICS" refers to quantitative measures employed to evaluate the performance of models and systems across various tasks, particularly in the domains of summarization and generation. These metrics include standards such as success rate and F1 score, which are utilized to assess the effectiveness and quality of generated agents. Additionally, evaluation metrics serve as criteria for determining the quality of generated answers or questions, thereby playing a crucial role in ensuring the reliability and performance of artificial intelligence systems.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,26b2dad01a219bc034ac7d6a32d07582,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COMPREHENSIVENESS">
      <data key="d0">CRITERIA</data>
      <data key="d1">Comprehensiveness is a critical metric that assesses the thoroughness of an answer in relation to a question. It evaluates the quality of responses by indicating how well they encompass all necessary information and cover all aspects of the inquiry. This metric serves as a valuable tool for determining the effectiveness and completeness of answers, ensuring that they meet the informational needs of the audience.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DIVERSITY">
      <data key="d0">CRITERIA</data>
      <data key="d1">Diversity is a multifaceted metric that assesses the variety and richness of perspectives in responses generated by an entity. It serves as a crucial indicator of the quality of these responses, reflecting the range of answers produced from identical inputs. Furthermore, diversity encompasses the variety and scope of generated problems or instructions, which is a fundamental objective within agentic flows. This comprehensive understanding of diversity highlights its importance in fostering a rich and varied dialogue, ultimately enhancing the effectiveness of communication and collaboration within professional networks.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="EMPOWERMENT">
      <data key="d0">CRITERIA</data>
      <data key="d1">Empowerment is a metric that evaluates the effectiveness of responses in enhancing user understanding and facilitating informed decision-making regarding a topic. It serves as a measure of quality, indicating how well answers enable users to comprehend information and take appropriate actions based on that understanding.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DIRECTNESS">
      <data key="d0">CRITERIA</data>
      <data key="d1">Directness is a metric that assesses the clarity and specificity of responses in relation to the questions posed. It serves as a tool for evaluating the quality of answers, highlighting how straightforward and clear they are. By measuring directness, one can determine the effectiveness of communication, ensuring that responses are not only relevant but also easily understood.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C0">
      <data key="d0">GRAPH COMMUNITY</data>
      <data key="d1">C0 serves as the root-level community summary within the Graph RAG approach, designed to address user queries. It represents the highest level of abstraction, encapsulating the foundational elements of the community's structure and relationships.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C1">
      <data key="d0">GRAPH COMMUNITY</data>
      <data key="d1">C1 is a multifaceted entity that plays a significant role in the Graph RAG approach, specifically utilized to evaluate performance metrics across various datasets and comparisons. Additionally, C1 serves as a high-level community summary, offering answers to queries and functioning as sub-communities of C0 when such sub-communities are available. This dual functionality highlights C1's importance in both performance assessment and community organization within its broader network.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C2">
      <data key="d0">GRAPH COMMUNITY</data>
      <data key="d1">C2 is a multifaceted entity within the context of community analysis and development, particularly in the Graph RAG approach. It serves a dual purpose: first, as a condition utilized to evaluate performance metrics across various datasets and comparisons, thereby playing a critical role in assessing the effectiveness of different methodologies. Second, C2 functions as an intermediate-level community summary that addresses specific queries, acting as sub-communities of C1 when such subdivisions are available. This dual functionality highlights C2's importance in both performance evaluation and community structuring within its broader network.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C3">
      <data key="d0">GRAPH COMMUNITY</data>
      <data key="d1">C3 is a multifaceted entity within the context of community analysis, particularly in the Graph RAG approach. It serves as a condition for evaluating performance metrics across various datasets and comparisons, highlighting its role in assessing the effectiveness of different methodologies. Additionally, C3 functions as a low-level community summary, designed to provide the maximum number of answers to queries. This characteristic positions C3 as a sub-community of C2, whenever applicable, thereby enhancing the overall structure and connectivity within the network. Through these functions, C3 plays a crucial role in facilitating collaboration and communication within its professional domain.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="TS">
      <data key="d0">METHOD</data>
      <data key="d1">TS refers to a text summarization method that employs a map-reduce approach directly on source texts to generate concise summaries. Additionally, TS is recognized as the global text summarization condition utilized for comparative analysis against the Graph RAG conditions. This dual role highlights TS's significance in both the practical application of summarization techniques and its function as a benchmark for evaluating other summarization methodologies.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="SS">
      <data key="d0">METHOD</data>
      <data key="d1">SS is a na &#239;ve semantic search RAG approach that retrieves text chunks and adds them to the context window until a specified token limit is reached.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PODCAST DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The "PODCAST DATASET" is a specialized collection of transcripts designed for assessing the effectiveness of the Graph RAG approach, particularly focusing on summarization and response quality. This dataset is notable for its distinctive content and structure, which contribute to its utility in evaluating the performance of the Graph RAG methodology.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="NEWS DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The "NEWS DATASET" is a specialized collection of articles designed for assessing the effectiveness of the Graph RAG approach, particularly focusing on summarization and response quality. This dataset is notable for its unique content and structure, which contribute to its role in evaluating the performance of the Graph RAG methodology. Through its targeted design, the News dataset serves as a critical resource for understanding and enhancing the capabilities of summarization techniques within the context of artificial intelligence and natural language processing.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="GRAPH COMMUNITIES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="SOURCE TEXTS">
      <data key="d0" />
      <data key="d1">The entity "SOURCE TEXTS" refers to the original documents or data utilized in the Graph RAG approach for information extraction and processing. These source texts serve as the foundational materials from which insights and knowledge are derived, playing a crucial role in the overall methodology.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="TAYLOR SWIFT">
      <data key="d0">PERSON</data>
      <data key="d1">Taylor Swift is a prominent musician known for her significant contributions to the music industry and her influence on popular culture.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TRAVIS KELCE">
      <data key="d0">PERSON</data>
      <data key="d1">Travis Kelce is a well-known athlete, recognized for his achievements in sports and his impact on popular culture.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="BRITNEY SPEARS">
      <data key="d0">PERSON</data>
      <data key="d1">Britney Spears is a famous musician and public figure, noted for her influence in the music industry and her personal life controversies.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="JUSTIN TIMBERLAKE">
      <data key="d0">PERSON</data>
      <data key="d1">Justin Timberlake is a renowned musician and entertainer, recognized for his contributions to music and his public persona.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PUBLIC FIGURES">
      <data key="d0">CATEGORY</data>
      <data key="d1">Public figures are individuals who have gained significant attention and influence in various sectors, including entertainment, sports, and media.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTERTAINMENT ARTICLES">
      <data key="d0">MEDIA FORMAT</data>
      <data key="d1">Entertainment articles are written pieces that cover various aspects of the entertainment industry, including news about public figures and cultural trends.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="COACHES">
      <data key="d0">CATEGORY</data>
      <data key="d1">Coaches are individuals who train and guide athletes, playing a significant role in sports and team dynamics.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="INFLUENCERS">
      <data key="d0">CATEGORY</data>
      <data key="d1">Influencers are individuals who have the power to affect the purchasing decisions of others due to their authority, knowledge, position, or relationship with their audience.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTREPRENEURS">
      <data key="d0">CATEGORY</data>
      <data key="d1">Entrepreneurs are individuals who create and manage businesses, often influencing trends and economic landscapes.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="CULTURAL NARRATIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Cultural narratives are the stories and themes that shape societal values and beliefs, often influenced by public figures in entertainment.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="SOCIAL DISCUSSIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Social discussions are conversations and debates that occur in public discourse, often involving topics related to public figures and their influence.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ATHLETES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="GRAPH RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Graph RAG is a method designed for processing and summarizing text data through a graph-based approach. This innovative technique aims to enhance the comprehensiveness and diversity of responses, making it particularly effective in generating varied outputs. Additionally, Graph RAG emphasizes efficiency and scalability, positioning itself as a superior alternative to traditional text summarization methods. By leveraging graph structures, it not only improves the quality of summaries but also addresses the challenges of handling large volumes of data, thereby facilitating more effective information retrieval and communication.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="CONTEXT WINDOW SIZE">
      <data key="d0">PARAMETER</data>
      <data key="d1">Context window size refers to the number of tokens that can be processed at once by the model, affecting the performance of the Graph RAG approach.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="WIN RATE">
      <data key="d0">METRIC</data>
      <data key="d1">Win rate is a performance metric indicating the percentage of successful outcomes in comparisons between different conditions.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="TOKEN COUNT">
      <data key="d0">METRIC</data>
      <data key="d1">Token count refers to the number of tokens processed or generated in the context of the Graph RAG approach.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="COMMUNITY SUMMARY LEVEL">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Community summary levels refer to the hierarchical structure of summaries generated from the original texts in the Graph RAG approach.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="SOURCE TEXT SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Source text summarization refers to the process of condensing original texts into shorter summaries while retaining essential information.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="PODCAST INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Podcast intermediate-level summaries are summaries derived from podcast content, aimed at providing a balanced overview of the material.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="NEWS LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">News low-level community summaries are concise summaries of news articles, focusing on community-related content.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="EMPOWERMENT COMPARISONS">
      <data key="d0">ANALYSIS</data>
      <data key="d1">Empowerment comparisons analyze the effectiveness of different summarization approaches in helping users achieve informed understanding.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="AD-HOC LLM USE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Ad-hoc LLM use involves employing large language models for specific tasks, such as analyzing reasoning and providing examples or citations.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SELF-MEMORY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Self-memory is a mechanism utilized in retrieval-augmented generation that enables models to retain and leverage past information to produce relevant responses. This concept also encompasses the idea that generated summaries act as memory aids, facilitating future retrieval and generation tasks. By integrating these functions, self-memory enhances the efficiency and effectiveness of information processing within artificial intelligence systems, particularly in the context of natural language processing.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GENERATING HIERARCHICAL INDEX">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Generating a hierarchical index involves organizing text chunks into a structured format to facilitate efficient retrieval and summarization.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="KNOWLEDGE GRAPH">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The "KNOWLEDGE GRAPH" is a structured representation of information that captures the relationships between various entities. It plays a crucial role in enhancing the understanding of artificial intelligence (AI) systems. Knowledge graphs are particularly valuable as they can be further enriched through the application of large language models, which improve their ability to represent and process complex information. This dual functionality underscores the significance of knowledge graphs in the fields of AI and natural language processing, facilitating better communication and collaboration within professional networks.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GRAPH DATABASES">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Graph databases are specialized databases designed to store and manage graph structures, enabling efficient querying and analysis of relationships.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="LANGCHAIN">
      <data key="d0">SOFTWARE</data>
      <data key="d1">LangChain is an open-source framework designed for building applications that leverage language models, including functionalities that are graph-based. It enables developers to create context-aware reasoning applications, allowing for effective understanding and utilization of context. The framework provides a variety of tools and components that support the development of applications utilizing large language models and graph databases, making it particularly useful in advanced driver-assistance systems (ADAS). Additionally, LangChain facilitates the creation of agentic systems by offering existing building blocks for development, thereby enhancing the capabilities of applications built within this ecosystem.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6109537356a2ce2339f77c827aa3668e,6bdf681c0bd9e401ac72344a6a0ae479,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="LLAMAINDEX">
      <data key="d0">SOFTWARE</data>
      <data key="d1">LlamaIndex is a software library that facilitates the integration of large language models with graph-based data structures.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="NA&#207;VE RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Na&#239;ve RAG refers to basic retrieval-augmented generation methods that convert documents to text and split them into chunks for embedding in a vector space.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="PRE-RETRIEVAL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Pre-retrieval is a strategy in advanced RAG systems that involves preparing data before the retrieval process to improve efficiency and accuracy.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="RETRIEVAL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Retrieval is the process of fetching relevant information from a dataset or external source to assist in generating responses.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="POST-RETRIEVAL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Post-retrieval refers to strategies applied after the retrieval process to refine or enhance the generated output.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="MODULAR RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Modular RAG systems incorporate patterns for iterative and dynamic cycles of retrieval and generation, improving the overall process of information synthesis.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="MULTI-DOCUMENT SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-document summarization involves condensing information from multiple sources into a coherent summary, often using advanced techniques like RAG.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-hop Question Answering is a specialized task within the field of Artificial Intelligence that focuses on the capability to answer questions necessitating reasoning across multiple pieces of information. This process involves synthesizing data from various sources or steps, enabling a system to provide comprehensive and accurate responses. By integrating information from diverse origins, Multi-hop Question Answering enhances the depth and reliability of answers, making it a critical component in the development of advanced AI systems and Natural Language Processing applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="HIERARCHICAL INDEX">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">A hierarchical index organizes data in a tree-like structure, facilitating efficient retrieval and summarization of information.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TEXT EMBEDDINGS">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Text embeddings are numerical representations of text data that capture semantic meaning, often used in machine learning and natural language processing.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="VECTOR SPACE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Vector space is a mathematical representation where text data is transformed into vectors for similarity comparisons and retrieval tasks.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="KAPING">
      <data key="d0">PERSON</data>
      <data key="d1">KAPING refers to a study or work that discusses advanced RAG systems and their applications in knowledge graph contexts.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TRAJANOSKA ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Trajanoska et al. (2023) is a reference to a study that explores the use of LLMs for knowledge graph creation and completion.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="YAO ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Yao et al. (2023) is a comprehensive study that explores multiple facets of language models and their applications. It proposes the use of the Wikipedia web API, particularly in the context of Language and Text Systems (LATS). The study also delves into the ReAct technique, highlighting its significance in enhancing the capabilities of language models. Furthermore, it addresses the extraction of causal graphs from source texts utilizing large language models (LLMs), showcasing innovative methodologies in this area. Additionally, Yao et al. (2023) examines various prompting methods and evaluates their performance within language models, contributing valuable insights to the field of Natural Language Processing.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,c95e02c0dca4a4a36b701cbc7dd14da6,edab4014b8f55e5b25bd7f396314be1f,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="BAN ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Ban et al. (2023) is a reference to a study that focuses on the extraction of causal graphs from textual data.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="ZHANG ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang et al. (2024) refers to a comprehensive study that explores two significant advancements in the field of artificial intelligence. Firstly, it examines AgentOptimizer, a system designed to learn and optimize the tools utilized by agents, enhancing their operational efficiency. Secondly, the study delves into the extraction of causal graphs from source texts, contributing to the understanding of relationships and dependencies within data. Together, these insights reflect Zhang et al.'s contributions to improving agent functionality and advancing causal inference methodologies in AI.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="G-RETRIEVER">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">G-Retriever is a system that focuses on retrieving subsets of graph structures for enhanced information retrieval tasks.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GRAPH-TOOLFORMER">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Graph-ToolFormer is a sophisticated method that leverages derived graph metrics to enhance various analytical tasks within the framework of Retrieval-Augmented Generation (RAG). This innovative system is specifically designed to empower large language models by integrating graph reasoning capabilities, utilizing prompts that are augmented by ChatGPT. Through this dual approach, Graph-ToolFormer aims to improve the efficiency and effectiveness of language models in processing and understanding complex graph-based data.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SURGE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">SURGE is a system that emphasizes narrative outputs grounded in the facts of retrieved subgraphs for enhanced storytelling.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="FABULA">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">FABULA is a method that serializes event-plot sub-graphs using narrative templates to create coherent stories.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="WANG ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Wang et al. (2023) is a reference to a study that explores two significant areas in the field of Artificial Intelligence and Natural Language Processing. Firstly, it discusses systems that support the creation and traversal of text-relationship graphs specifically designed for multi-hop question answering. This aspect emphasizes the importance of understanding complex relationships within text to enhance the accuracy and efficiency of answering intricate queries. Secondly, the study addresses the adaptation of language models in interactive environments, highlighting the need for these models to be flexible and responsive in real-time applications. Together, these contributions underscore the advancements in leveraging language models and graph-based systems to improve user interaction and information retrieval in AI-driven contexts.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="KNOWLEDGE GRAPHS">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Knowledge graphs are structured representations of information that allow for reasoning and querying over interconnected data points.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="NATURAL MODULARITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Natural modularity refers to the inherent structure within graphs that allows for effective partitioning of data for summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SENSEMAKING QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Sensemaking questions are inquiries designed to extract meaningful insights from data, guiding the analysis process.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GRAPH-FREE APPROACH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The graph-free approach is a method of summarizing source texts without utilizing graph structures, often employing map-reduce techniques.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="OPEN-SOURCE IMPLEMENTATION">
      <data key="d0">SOFTWARE</data>
      <data key="d1">An open-source implementation refers to publicly available software that allows users to access and modify the Graph RAG approaches.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Alonso Guevara Fern&#225;ndez is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="AMBER HOAK">
      <data key="d0">PERSON</data>
      <data key="d1">Amber Hoak is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d0">PERSON</data>
      <data key="d1">Andr&#233;s Morales Esquivel is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BEN CUTLER">
      <data key="d0">PERSON</data>
      <data key="d1">Ben Cutler is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BILLIE RINALDI">
      <data key="d0">PERSON</data>
      <data key="d1">Billie Rinaldi is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRIS SANCHEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Sanchez is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRIS TREVI&#209;O">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Trevi&#241;o is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRISTINE CAGGIANO">
      <data key="d0">PERSON</data>
      <data key="d1">Christine Caggiano is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DAVID TITTSWORTH">
      <data key="d0">PERSON</data>
      <data key="d1">David Tittsworth is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DAYENNE DE SOUZA">
      <data key="d0">PERSON</data>
      <data key="d1">Dayenne de Souza is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DOUGLAS ORBAKER">
      <data key="d0">PERSON</data>
      <data key="d1">Douglas Orbaker is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ED CLARK">
      <data key="d0">PERSON</data>
      <data key="d1">Ed Clark is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GABRIEL NIEVES-PONCE">
      <data key="d0">PERSON</data>
      <data key="d1">Gabriel Nieves-Ponce is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GAUDY BLANCO MENES">
      <data key="d0">PERSON</data>
      <data key="d1">Gaudy Blanco Meneses is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATE LYTVYNETS">
      <data key="d0">PERSON</data>
      <data key="d1">Kate Lytvynets is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATY SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Katy Smith is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="M&#211;NICA CARVAJAL">
      <data key="d0">PERSON</data>
      <data key="d1">M&#243;nica Carvajal is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="NATHAN EVANS">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Evans is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RICHARD ORTEGA">
      <data key="d0">PERSON</data>
      <data key="d1">Richard Ortega is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RODRIGO RACANICCI">
      <data key="d0">PERSON</data>
      <data key="d1">Rodrigo Racanicci is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SARAH SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Smith is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SHANE SOLOMON">
      <data key="d0">PERSON</data>
      <data key="d1">Shane Solomon is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="FABRICATION RATES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Fabrication rates refer to the frequency of inaccuracies or false information generated by language models, which is crucial for assessing their performance.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Query-focused summarization is a method that tailors summaries based on specific queries, enhancing the relevance of the information presented.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="HYBRID RAG SCHEMES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Hybrid RAG schemes combine different retrieval-augmented generation techniques to improve the efficiency and effectiveness of information retrieval.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="EMBEDDING-BASED MATCHING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Embedding-based matching is a technique that uses vector representations of data to find relevant information based on user queries.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="MAP-REDUCE SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Map-reduce summarization is a computational approach that processes large datasets by dividing them into smaller chunks for efficient summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Hierarchical community structure refers to the organization of data into nested groups, facilitating better analysis and understanding of relationships within the data.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="TOKEN COST">
      <data key="d0">CONCEPT</data>
      <data key="d1">Token cost refers to the computational expense associated with processing text data in language models, impacting the efficiency of various approaches.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHENG ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Cheng et al. (2024) is a reference to a study on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DANG H. T. (2006)">
      <data key="d0">PERSON</data>
      <data key="d1">Dang H. T. (2006) is a reference to a study evaluating question-focused summarization systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ES ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Es et al. (2023) is a reference to a study on automated evaluation of retrieval-augmented generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FENG ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Feng et al. (2023) is a reference to a study on retrieval-generation synergy augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FORTUNATO S. (2010)">
      <data key="d0">PERSON</data>
      <data key="d1">Fortunato S. (2010) is a reference to a study on community detection in graphs.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GAO ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Gao et al. (2023) is a comprehensive study that explores prompting techniques for language models, as well as serving as a survey on retrieval-augmented generation for large language models. This dual focus highlights the significance of effective prompting strategies in enhancing the performance of language models, while also examining the integration of retrieval mechanisms to improve the generation capabilities of these models. The work contributes valuable insights into the evolving landscape of artificial intelligence and natural language processing, emphasizing the importance of both prompting and retrieval-augmented approaches in optimizing language model functionality.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GOODWIN ET AL. (2020)">
      <data key="d0">PERSON</data>
      <data key="d1">Goodwin et al. (2020) is a reference to a study comparing transformers on multi-document abstractive summarization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HE ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">He et al. (2024) is a reference to a study on retrieval-augmented generation for textual graph understanding.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JACOMY ET AL. (2014)">
      <data key="d0">PERSON</data>
      <data key="d1">Jacomy et al. (2014) is a reference to a study on a graph layout algorithm for network visualization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIN ET AL. (2021)">
      <data key="d0">PERSON</data>
      <data key="d1">Jin et al. (2021) is a reference to a survey of community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KANG ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Kang et al. (2023) is a reference to a study on knowledge graph-augmented language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KHATTAB ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Khattab et al. (2022) is a reference to a study on composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KIM ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Kim et al. (2023) is a reference to a study on answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KLEIN ET AL. (2006)">
      <data key="d0">PERSON</data>
      <data key="d1">Klein et al. (2006) is a reference to a study on sensemaking perspectives.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KOESTEN ET AL. (2021)">
      <data key="d0">PERSON</data>
      <data key="d1">Koesten et al. (2021) is a reference to a study on understanding data sensemaking behaviors.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1">Language models are sophisticated algorithms specifically designed to comprehend and generate human language. They are typically trained on extensive datasets, enabling them to learn the intricacies of language patterns. These models function as statistical tools that predict the next word in a sequence, which is essential for various natural language processing (NLP) tasks. Their ability to analyze and generate text makes them a pivotal component in advancing technologies related to human-computer interaction and communication.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED TEXT GENERATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="QUESTION-FOCUSED SUMMARIZATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="AUTOMATED EVALUATION">
      <data key="d0" />
      <data key="d1">Automated evaluation refers to the use of algorithms and metrics to assess the quality of generated text without human intervention.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="RETRIEVAL-GENERATION SYNERGY">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SURVEY ON RETRIEVAL-AUGMENTED GENERATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TRANSFORMERS">
      <data key="d0" />
      <data key="d1">Transformers are a type of neural network architecture that has become the foundation for many state-of-the-art models in natural language processing.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TEXTUAL GRAPH UNDERSTANDING">
      <data key="d0" />
      <data key="d1">Textual graph understanding involves interpreting and analyzing information represented in graph structures derived from text.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TASK</data>
    </node>
    <node id="GRAPH LAYOUT ALGORITHM">
      <data key="d0" />
      <data key="d1">Graph layout algorithms are methods used to visualize graph structures in a way that highlights relationships and patterns among nodes.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="COMMUNITY DETECTION APPROACHES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KNOWLEDGE-GROUNDED DIALOGUE">
      <data key="d0" />
      <data key="d1">Knowledge-grounded dialogue refers to conversational systems that utilize external knowledge sources to provide contextually relevant responses.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TASK</data>
    </node>
    <node id="RETRIEVAL AND LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1">The integration of retrieval and language models involves combining information retrieval techniques with language generation capabilities for improved performance.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AMBIGUOUS QUESTIONS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SENSEMAKING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DATA SENSEMAKING">
      <data key="d0" />
      <data key="d1">Data sensemaking refers to the process of interpreting and understanding data to derive insights and inform decision-making.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SEQ2SEQ MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Sequence-to-sequence (seq2seq) models are a type of neural network architecture used for tasks such as translation and summarization, where input sequences are transformed into output sequences.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FAST UNFOLDING OF COMMUNITIES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Fast unfolding of communities is a method for detecting community structures in large networks, as discussed by Blondel et al. (2008).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Retrieval-augmented generation is a sophisticated technique that integrates the retrieval of relevant information with generative models to improve performance on knowledge-intensive natural language processing (NLP) tasks. This approach, highlighted in a 2020 paper by Patrick Lewis and colleagues, aims to enhance the quality of generated text outputs by leveraging external information sources. By combining these two methodologies, retrieval-augmented generation effectively addresses the challenges associated with generating accurate and contextually relevant content in various applications within the field of NLP.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MULTI-DOCUMENT ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">Multi-document abstractive summarization is the task of generating concise summaries from multiple documents, capturing the main ideas and information.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="EVALUATION OF QUESTION-FOCUSED SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">Evaluation of question-focused summarization involves assessing the effectiveness of summarization systems that target specific questions.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d0">CONFERENCE</data>
      <data key="d1">Neural Information Processing Systems (NeurIPS) is a prominent conference focused on machine learning and computational neuroscience.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COLING">
      <data key="d0">CONFERENCE</data>
      <data key="d1">COLING is the International Conference on Computational Linguistics, which focuses on research in natural language processing and computational linguistics.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING">
      <data key="d0">JOURNAL</data>
      <data key="d1">IEEE Transactions on Knowledge and Data Engineering is a scholarly journal that publishes research on knowledge and data engineering topics.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JOURNAL OF STATISTICAL MECHANICS">
      <data key="d0">JOURNAL</data>
      <data key="d1">Journal of Statistical Mechanics is a scientific journal that publishes research in statistical mechanics and related fields.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PLOS ONE">
      <data key="d0">JOURNAL</data>
      <data key="d1">PLoS ONE is a multidisciplinary open-access journal that publishes research across all areas of science and medicine.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d0">JOURNAL</data>
      <data key="d1">"Advances in Neural Information Processing Systems" is a prominent conference proceedings publication that showcases cutting-edge research in the fields of machine learning and artificial intelligence. It serves as a significant platform for disseminating innovative findings related to neural information processing. The publication includes contributions from various researchers, including notable work by Aman Madaan, among others, highlighting its role in advancing knowledge and collaboration within the AI community.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d0">JOURNAL</data>
      <data key="d1">International Journal of Human-Computer Studies is a journal that publishes research on the interaction between humans and computers.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NIH PUBLIC ACCESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">NIH Public Access refers to the policy that ensures public access to research funded by the National Institutes of Health.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ARXIV">
      <data key="d0">REPOSITORY</data>
      <data key="d1">arXiv is a free distribution service and an open-access archive for scholarly articles in various fields, including physics, mathematics, and computer science.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TASK-FOCUSED SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">Task-focused summarization is the process of generating summaries that are specifically tailored to answer particular questions or fulfill specific tasks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZERO-SHOT LEARNING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Zero-shot learning is a machine learning paradigm where a model is able to recognize objects or perform tasks it has not been explicitly trained on.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FEW-SHOT LEARNING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Few-shot learning is a machine learning approach that enables models to learn from a small number of training examples.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LARGE LANGUAGE MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Large language models are advanced AI systems that utilize extensive training on vast amounts of text data to understand and generate human-like text. These models are designed to perform a variety of language tasks, making them relevant to numerous discussed papers in the field. By leveraging sophisticated neural network architectures, large language models demonstrate a remarkable ability to process and produce language, thereby enhancing communication and facilitating collaboration across various applications in artificial intelligence and natural language processing.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,68e5573b596d253a03047b1e41988598,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GRAPH RETRIEVER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Graph retrievers are systems designed to extract relevant information from graph structures to support various applications, including question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TEXT GENERATION">
      <data key="d0">TASK</data>
      <data key="d1">Text generation is the process of creating coherent and contextually relevant text based on input data or prompts.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NEURAL NETWORK ARCHITECTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Neural network architecture refers to the design and structure of neural networks, which determine how they process information.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CROSS-DOMAIN LEARNING">
      <data key="d0">CONCEPT</data>
      <data key="d1">CROSS-DOMAIN LEARNING refers to the process of applying knowledge or models from one domain to enhance performance in another domain. This approach involves transferring knowledge between different domains, which significantly improves the performance of models when faced with new, unseen domains. It is particularly relevant to various research efforts in the field of machine learning, where leveraging insights from established domains can lead to advancements in understanding and addressing challenges in less familiar areas.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MULTIMODAL LEARNING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Multimodal learning refers to the integration of multiple types of data (e.g., text, images) to enhance learning and understanding.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DATA VISUALIZATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Data visualization is a crucial technique that involves the graphical representation of information and data, aimed at making complex datasets more accessible and understandable. It employs various visual elements, such as charts, graphs, and maps, to effectively communicate information in a clear and concise manner. By transforming intricate data into visual formats, data visualization enhances comprehension and facilitates better decision-making, making it an essential tool in various fields, including Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NLP">
      <data key="d0">FIELD</data>
      <data key="d1">Natural Language Processing (NLP) is a specialized area within the broader field of artificial intelligence (AI) that concentrates on the interaction between computers and human language. This discipline aims to enable machines to understand, interpret, and respond to human language in a meaningful way, facilitating seamless communication between humans and computers. Through various techniques and algorithms, NLP seeks to bridge the gap between human linguistic capabilities and computational processing, making it a crucial component in the development of intelligent systems.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEEP LEARNING">
      <data key="d0">FIELD</data>
      <data key="d1">Deep learning is a specialized subset of machine learning that employs neural networks characterized by multiple layers to analyze diverse forms of data. This approach is particularly relevant to numerous academic papers and is widely utilized in applications such as image and speech recognition. By leveraging its capacity to process complex datasets, deep learning has become a pivotal technology in various fields, enhancing the capabilities of artificial intelligence systems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MACHINE LEARNING">
      <data key="d0">FIELD</data>
      <data key="d1">Machine learning is a field within artificial intelligence (AI) that emphasizes the creation of algorithms enabling computers to learn from data and make predictions. It is specifically recognized as a subset of AI, dedicated to the advancement of these predictive algorithms. Through its focus on data-driven learning, machine learning plays a crucial role in enhancing the capabilities of AI systems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COMPUTATIONAL LINGUISTICS">
      <data key="d0">FIELD</data>
      <data key="d1">Computational linguistics is an interdisciplinary field that merges linguistics and computer science, focusing on the processing and analysis of human language through computational methods. This area of study is significant in various academic discussions and research papers, highlighting its relevance and application in understanding and manipulating language using technological approaches.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="STATISTICAL MODELING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Statistical modeling involves using statistical methods to represent and analyze data, often to make predictions or infer relationships.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEEP LEARNING MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Deep learning models are advanced algorithms that use multiple layers of processing to learn representations of data for various tasks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL SYSTEMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Retrieval systems are technologies designed to search and retrieve relevant information from large datasets or databases.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KNOWLEDGE BASES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Knowledge bases are organized collections of information that can be used to support reasoning and decision-making in various applications.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="INFORMATION RETRIEVAL">
      <data key="d0">CONCEPT</data>
      <data key="d1">Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DATA ANALYSIS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Data analysis is a comprehensive process that encompasses inspecting, cleaning, transforming, and modeling data to uncover valuable insights. This practice is essential for informing conclusions and supporting decision-making within various contexts. By meticulously examining data, analysts can identify patterns and trends that facilitate informed choices, ultimately enhancing organizational effectiveness and strategic planning.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="EXPERIMENTAL STUDIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Experimental studies are research designs that involve manipulating one or more variables to determine their effect on a dependent variable.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RESEARCH PAPERS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research papers are scholarly articles that present original findings or reviews of existing research in a specific field.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TECHNICAL REPORTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Technical reports are documents that describe the process, progress, or results of technical or scientific research.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SURVEYS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Surveys are research methods used to collect data from a predefined group of respondents to gain insights into specific topics.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WORKSHOPS">
      <data key="d0">EVENT</data>
      <data key="d1">Workshops are interactive training sessions focused on specific topics, often involving hands-on activities and discussions.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CONFERENCES">
      <data key="d0">EVENT</data>
      <data key="d1">Conferences are formal meetings where researchers and professionals gather to discuss and share findings in a specific field.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SYMPOSIA">
      <data key="d0">EVENT</data>
      <data key="d1">Symposia are formal gatherings of experts to discuss a particular topic, often resulting in published proceedings.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PRESENTATIONS">
      <data key="d0">EVENT</data>
      <data key="d1">Presentations are formal displays of information or research findings, often delivered at conferences or workshops.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="POSTERS">
      <data key="d0">EVENT</data>
      <data key="d1">Posters are visual presentations of research findings, typically displayed at conferences for attendees to review and discuss.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEMONSTRATIONS">
      <data key="d0">EVENT</data>
      <data key="d1">Demonstrations are practical displays of a product or process, often used to showcase new technologies or methods.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TUTORIALS">
      <data key="d0">EVENT</data>
      <data key="d1">Tutorials are instructional sessions designed to teach specific skills or knowledge, often in a hands-on format.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COLLABORATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Collaborations involve partnerships between researchers or organizations to work together on projects or studies.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NETWORKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Networks refer to interconnected systems or structures, often used to represent relationships among entities in various fields.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SYSTEMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Systems refer to organized collections of components that work together to achieve a specific goal or function.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="APPLICATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Applications refer to practical uses of theories, models, or technologies in real-world scenarios.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PLATFORMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Platforms refer to foundational technologies or services that support the development and deployment of applications.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TOOLS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Tools refer to software or hardware resources used to perform specific tasks or functions in various fields.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TECHNOLOGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Technologies refer to the application of scientific knowledge for practical purposes, often resulting in new tools or methods.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="METHODS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Methods refer to systematic approaches or techniques used to conduct research or analysis in various fields.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PROCESSES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Processes refer to series of actions or steps taken to achieve a particular end in various contexts.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FRAMEWORKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Frameworks refer to structured approaches or systems that provide guidance for developing or analyzing specific topics.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MODELS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Models refer to simplified representations of complex systems or phenomena used for analysis or prediction.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="STRATEGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Strategies refer to plans of action designed to achieve specific goals or objectives in various contexts.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="APPROACHES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Approaches refer to methods or ways of dealing with a particular situation or problem.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PRACTICES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Practices refer to established methods or techniques used in a particular field or profession.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="STANDARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Standards refer to established norms or criteria used to measure quality or performance in various fields.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GUIDELINES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Guidelines refer to recommended practices or procedures designed to assist in decision-making or actions.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="POLICIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Policies refer to formal rules or guidelines that govern actions and decisions within organizations or systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="REGULATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Regulations refer to rules or directives made and maintained by an authority to regulate conduct within a specific area.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LAWS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Laws refer to system of rules that are created and enforced through social or governmental institutions to regulate behavior.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ETHICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Ethics refer to moral principles that govern a person's behavior or the conducting of an activity.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="STUDIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Studies refer to systematic investigations or analyses conducted to discover or interpret facts or principles.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RESEARCH">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research refers to the systematic investigation into and study of materials and sources to establish facts and reach new conclusions.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FINDINGS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Findings refer to the results or conclusions drawn from research or analysis.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CONCLUSIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Conclusions refer to judgments or decisions reached after consideration of the relevant facts and evidence.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IMPLICATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Implications refer to the possible effects or outcomes that may result from a particular action or decision.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RECOMMENDATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Recommendations refer to suggestions or proposals for actions based on findings or conclusions.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FUTURE WORK">
      <data key="d0">CONCEPT</data>
      <data key="d1">Future work refers to proposed directions for further research or development based on current findings.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIMITATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The term "LIMITATIONS" encompasses various constraints and challenges that can impact the validity and applicability of research findings across different contexts. Specifically, limitations refer to the restrictions that may affect the outcomes of research, highlighting the importance of acknowledging these factors in scholarly work. In the realm of language models, limitations are particularly pronounced in the context of synthetic data generation, where challenges can hinder the effectiveness and reliability of the models. Additionally, the LATS algorithm faces its own set of limitations, especially in decision-making tasks, which can affect its performance and the quality of its outputs. Overall, understanding these limitations is crucial for researchers and practitioners in navigating the complexities of their respective fields.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,aa79049289e6532592eec17b9e76adfb,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="CONTRIBUTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Contributions refer to the input or additions made to a field or area of study through research or practice.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PERSPECTIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Perspectives refer to particular attitudes or ways of considering a situation or topic.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="INSIGHTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The entity "INSIGHTS" refers to valuable understandings or discoveries that emerge from research or analysis. These insights are crucial as they often lead to advancements in technology or methodology. Additionally, insights encompass deep understandings or perceptions that are derived from both analysis and experience. Collectively, these descriptions highlight the significance of insights in fostering innovation and enhancing comprehension within various fields, particularly in the context of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="EXAMPLES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Examples refer to specific instances or cases that illustrate a concept or principle.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CASE STUDIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Case studies refer to in-depth examinations of specific instances or examples within a real-world context.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FUTURE DIRECTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Future directions refer to potential paths for research or development based on current trends and findings.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RESEARCH AGENDA">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research agenda refers to a plan or outline of topics and questions to be explored in future research.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RESEARCH QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research questions refer to specific queries that guide the focus and direction of a research study.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HYPOTHESES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Hypotheses refer to proposed explanations or predictions that can be tested through research.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="VARIABLES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Variables refer to elements or factors that can change and affect the outcome of a study or experiment.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DATA COLLECTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Data collection refers to the systematic gathering of information for analysis and interpretation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ANALYSIS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Analysis refers to the process of examining data to draw conclusions or insights.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RESULTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Results refer to the outcomes or findings derived from research or analysis.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="VALIDATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Validation refers to the process of confirming that a method or model is accurate and reliable.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="REPRODUCIBILITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Reproducibility refers to the ability to achieve consistent results using the same methods or procedures in research.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TRANSPARENCY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Transparency refers to the openness and clarity with which research processes and findings are communicated.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ACCOUNTABILITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Accountability refers to the obligation to explain, justify, and take responsibility for actions and decisions in research.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COLLABORATIVE RESEARCH">
      <data key="d0">CONCEPT</data>
      <data key="d1">Collaborative research involves joint efforts by multiple researchers or institutions working together towards a common goal. This collaborative approach often leads to the production of co-authored publications, highlighting the synergy and shared expertise among the participating parties. By pooling resources and knowledge, collaborative research enhances the depth and breadth of studies conducted, fostering innovation and advancing understanding in various fields.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KOESTEN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">L. Koesten is a researcher who co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GREGORY, K.">
      <data key="d0">PERSON</data>
      <data key="d1">K. Gregory is a researcher who co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GROTH, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Groth is a researcher who co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SIMPURL, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Simperl is a researcher who co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KURATOV, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Kuratov is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BULATOV, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Bulatov is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ANOKHIN, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Anokhin is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SOROKIN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Sorokin is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SOROKIN, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Sorokin is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BURTSEV, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Burtsev is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LASKAR, M. T. R.">
      <data key="d0">PERSON</data>
      <data key="d1">M. T. R. Laskar is a researcher who co-authored studies on query-focused abstractive summarization.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HOQUE, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Hoque is a researcher who co-authored studies on query-focused abstractive summarization.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HUANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Huang is a researcher who co-authored studies on query-focused abstractive summarization.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEWIS, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Lewis is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PEREZ, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Perez is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PIKTUS, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Piktus is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PETRONI, F.">
      <data key="d0">PERSON</data>
      <data key="d1">F. Petroni is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KARPUKHIN, V.">
      <data key="d0">PERSON</data>
      <data key="d1">V. Karpukhin is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GOYAL, N.">
      <data key="d0">PERSON</data>
      <data key="d1">N. Goyal is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="K&#220;TTLER, H.">
      <data key="d0">PERSON</data>
      <data key="d1">H. K&#252;ttler is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MARTIN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Martin is a researcher who co-authored a study on graph layout tools.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MICROSOFT">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft is a technology company that conducts research on the impact of large language models on scientific discovery.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NEBULAGRAPH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">NebulaGraph is a company that launched a graph-based retrieval-augmented generation system.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NEO4J">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Neo4J is a graph database company that is involved in projects related to language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NEWMAN, M. E.">
      <data key="d0">PERSON</data>
      <data key="d1">M. E. Newman is a researcher known for his work on modularity and community structure in networks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RAM, O.">
      <data key="d0">PERSON</data>
      <data key="d1">O. Ram is a researcher who co-authored a study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RANADE, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Ranade is a researcher who co-authored a study on intelligence report generation using retrieval-augmented narrative construction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SARTHI, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Sarthi is a researcher who co-authored a study on recursive abstractive processing for retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHAO, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Z. Shao is a researcher who co-authored a study on enhancing retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SU, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Su is a researcher recognized for co-authoring significant studies in the fields of question answering and multi-document summarization. Notably, Su contributed to the development of Caire-covid, a specialized system designed for question answering and query-focused multi-document summarization specifically addressing the challenges posed by COVID-19. This work highlights Su's involvement in advancing methodologies that enhance information retrieval and synthesis in critical contexts.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DUAN, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Duan, N. is a researcher who co-authored a paper on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="CHEN, W.">
      <data key="d0">PERSON</data>
      <data key="d1">Chen, W. is a researcher who co-authored a paper on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="XU, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Xu, Y. is a researcher who co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Yang, Y. is a researcher who co-authored a paper on MultiHop-RAG, benchmarking retrieval-augmented generation for multi-hop queries.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Tang, Y. is a researcher who co-authored a paper on MultiHop-RAG, benchmarking retrieval-augmented generation for multi-hop queries.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TOUVRON, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Touvron, H. is a researcher who co-authored a paper on Llama 2, which includes open foundation and fine-tuned chat models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MARTIN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Martin, L. is a researcher who co-authored a paper on Llama 2, which includes open foundation and fine-tuned chat models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRAJANOSKA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Trajanoska, M. is a researcher who co-authored a paper on enhancing knowledge graph construction using large language models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRIVEDI, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Trivedi, H. is a researcher who co-authored a paper on interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, J. is a researcher who co-authored a preliminary study on whether ChatGPT is a good NLG evaluator.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, S. is a researcher who co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YAO, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Yao, L. is a researcher who co-authored a paper exploring large language models for knowledge graph completion.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, J. is a researcher who co-authored a paper on Graph-toolformer, empowering LLMs with graph reasoning ability via prompts augmented by ChatGPT.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, Y. is a researcher who co-authored a paper on causal graph discovery with retrieval-augmented generation based large language models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHENG, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Zheng, L. is a researcher who co-authored a paper judging LLMs as judges with MT-bench and Chatbot Arena.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="CAIRE-COVID">
      <data key="d0">SYSTEM</data>
      <data key="d1">Caire-covid is a question answering and query-focused multi-document summarization system designed for managing COVID-19 scholarly information.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MULTIHOP-RAG">
      <data key="d0">SYSTEM</data>
      <data key="d1">MultiHop-RAG is a benchmarking system for retrieval-augmented generation focused on multi-hop queries.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LLAMA 2">
      <data key="d0">SYSTEM</data>
      <data key="d1">LLAMA 2 is a sophisticated system that encompasses both open foundation and fine-tuned chat models, designed for a wide range of applications in the field of artificial intelligence. This innovative model serves as a versatile tool, facilitating various AI-driven tasks through its advanced capabilities.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="CHATGPT">
      <data key="d0" />
      <data key="d1">ChatGPT is a conversational AI model developed by OpenAI, specifically designed to generate human-like text responses. It is also evaluated in the Orca-Bench dataset, which assesses its performance and capabilities in various conversational contexts.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,bd4eb9459bc29b4c2da4658914fd4635,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SIDDIQUE, F. B.">
      <data key="d0">PERSON</data>
      <data key="d1">Siddique, F. B. is a researcher who co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="FUNG, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Fung, P. is a researcher who co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BENGIO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Bengio, Y. is a researcher who co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SALAKHUTDINOV, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Salakhutdinov, R. is a researcher who co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MANNING, C. D.">
      <data key="d0">PERSON</data>
      <data key="d1">Manning, C. D. is a researcher who co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="XIAO, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Xiao, J. is a researcher who co-authored a paper on recent advances in document summarization.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LI, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Li, Z. is a researcher who co-authored a paper on knowledge graph prompting for multi-document question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="DERR, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Derr, T. is a researcher who co-authored a paper on knowledge graph prompting for multi-document question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, R. is a researcher who co-authored a paper on knowledge graph prompting for multi-document question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="KRAMTSOVA, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Khramtsova, E. is a researcher who co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHUANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuang, S. is a researcher who co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZUCCON, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Zuccon, G. is a researcher who co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BAREZI, E. J.">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="HOTSPOTQA">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="DOCUMENT SUMMARIZATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Language Agent Tree Search (LATS) is a comprehensive framework aimed at unifying reasoning, acting, and planning within language models to improve problem-solving capabilities. By addressing the limitations of previous prompting techniques, LATS incorporates advanced search algorithms and external feedback mechanisms. This integration enhances the decision-making processes of language models, facilitating more effective and efficient outcomes in various applications.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="LANGUAGE MODELS (LMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Language models (LMs) are advanced AI systems specifically engineered to comprehend and produce human language. They excel in generating human-like text based on input prompts and are capable of performing a variety of tasks, including reasoning, decision-making, text generation, and question answering. These models play a crucial role in enhancing communication and facilitating interactions in various applications, showcasing their versatility and importance in the field of artificial intelligence.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MONTE CARLO TREE SEARCH (MCTS)">
      <data key="d0">ALGORITHM</data>
      <data key="d1">Monte Carlo Tree Search (MCTS) is a heuristic search algorithm utilized in decision-making processes, particularly within the realms of artificial intelligence and reinforcement learning. It operates by constructing a decision tree that iteratively explores various states and actions, allowing for the evaluation of potential actions and their outcomes. MCTS is especially prominent in game-playing scenarios and other decision-making tasks, where it aids in determining optimal strategies by assessing the consequences of different choices.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="EXTERNAL ENVIRONMENT">
      <data key="d0">CONTEXT</data>
      <data key="d1">The external environment provides feedback to language models, enhancing their problem-solving capabilities and decision-making processes.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="PROGRAMMING">
      <data key="d0">DOMAIN</data>
      <data key="d1">Programming is a domain that encompasses the design and development of executable computer software aimed at accomplishing specific tasks or solving problems. It involves writing code and creating software solutions, making it a critical area where language models can be effectively applied. These models assist in various programming-related activities, including writing code, debugging, and tackling coding challenges. Additionally, programming serves as a benchmark for evaluating the capabilities of language models, highlighting its significance in the field of artificial intelligence and natural language processing.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,7de66b94cf868b37b1df51dc545c415f,93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="INTERACTIVE QUESTION-ANSWERING (QA)">
      <data key="d0">DOMAIN</data>
      <data key="d1">Interactive Question-Answering (QA) is a specialized domain that leverages language models to provide real-time responses to user inquiries. This field emphasizes the importance of reasoning and context understanding, enabling the models to engage in dialogue effectively. By facilitating interactive exchanges, these language models not only answer questions but also adapt to the flow of conversation, enhancing user experience and satisfaction.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WEB NAVIGATION">
      <data key="d0">DOMAIN</data>
      <data key="d1">Web navigation refers to the process of utilizing language models to aid users in locating information and effectively navigating online resources. This encompasses the use of advanced algorithms and artificial intelligence techniques to enhance the user experience by streamlining the search for information on the internet. Through these language models, web navigation not only facilitates access to data but also improves the overall efficiency of online interactions.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MATH">
      <data key="d0">DOMAIN</data>
      <data key="d1">MATH is a domain that encompasses tasks involving numerical reasoning and problem-solving. In this context, language models play a significant role by assisting in solving mathematical problems and providing explanations. These models enhance the understanding and application of mathematical concepts, making them valuable tools for individuals seeking to navigate complex mathematical challenges.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="HUMAN EVAL">
      <data key="d0">EVALUATION SET</data>
      <data key="d1">HumanEval is a benchmark used to evaluate the performance of programming models, particularly in coding tasks.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="GPT-4">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4 is a state-of-the-art language model developed by OpenAI, recognized for its advanced capabilities in natural language processing, reasoning, and programming tasks. As an enhanced version of the Generative Pre-trained Transformer model, GPT-4 demonstrates superior performance compared to its predecessor, GPT-3.5, and is noted for its cost-effectiveness. It serves as a benchmark for evaluating the performance of other models, particularly in the Orca-Bench dataset, and is utilized in various methodologies, including the AgentInstruct approach for generating high-quality data and responses in synthetic data generation processes. Additionally, GPT-4 is employed in the Meta Agent Search for assessing the transferability of discovered agents and is known for its effectiveness in reading comprehension and problem-solving tasks, as well as its low hallucination rates in summarization performance evaluations. Overall, GPT-4 stands out as a powerful tool in the field of artificial intelligence, enhancing the capabilities of applications that rely on advanced language understanding.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,1b1399c76420a477c0c97893d258ae69,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,2d4672dfb7bd4283f0b5f23ab4f26653,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635,ef75d2c866bee783577ed9f65707cf13,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="GPT-3.5">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-3.5 is a sophisticated language model developed by OpenAI, recognized for its advanced capabilities in natural language processing (NLP). It is employed across a variety of tasks, including programming, reasoning, decision-making, and web navigation. The model serves as a benchmark for evaluating performance in various contexts, such as the HotPotQA task and the Game of 24, where it analyzes performance and success rates.

Additionally, GPT-3.5 plays a crucial role in the evaluation of instruction-tuned models and is utilized in the Meta Agent Search process to assess baselines and facilitate the transfer of knowledge to newer models. Its architecture requires a complex feedback mechanism for refining answers, distinguishing it from other advanced models. Furthermore, GPT-3.5 serves as the foundational model for LATS, providing essential reasoning capabilities and acting as a reference point for performance evaluation in the study of discovered agents and baselines. Overall, GPT-3.5 exemplifies the cutting-edge advancements in the field of artificial intelligence and natural language processing.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,594449768ae2dea9b2efbe677075096b,7de66b94cf868b37b1df51dc545c415f,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b88745a13b69cecbc0ee9c3af41389bf,b8dd0300033963bb4a3e1bad37f8e7b9,bc26e68b0b2783ba912b9e5606d9eb0b,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="REACT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">ReAct is a sophisticated prompting method designed to enhance the performance of language models, particularly in decision-making tasks. It operates by integrating reasoning and acting strategies, allowing for improved interactions and outcomes in various applications. ReAct adapts based on the success of previous attempts and is often used in conjunction with LATS to further boost performance. This technique serves as a baseline for comparison with LATS and is characterized by its ability to incorporate feedback from external environments, thereby enriching the decision-making process.

While ReAct is recognized for its effectiveness in enhancing language models, it is also noted for its simplicity, which can limit its adaptability to varying environmental conditions. Despite this limitation, ReAct has demonstrated success in improving interactive tasks by synergizing reasoning and acting, making it a valuable tool in the field of artificial intelligence and natural language processing.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,8180bf20b7577f3eee40df5991e2886d,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="WOOLDRIDGE AND JENNINGS (1995)">
      <data key="d0">PERSON</data>
      <data key="d1">Wooldridge and Jennings (1995) is a reference to foundational work in the field of artificial intelligence regarding autonomous agents.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="CHOWDHERY ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Chowdhery et al. (2023) is a reference to a study that discusses advancements in language models.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="OPENAI (2023)">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">OpenAI is an artificial intelligence research organization known for developing advanced language models like GPT-4.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="NALLAPATI ET AL. (2016)">
      <data key="d0">PERSON</data>
      <data key="d1">Nallapati et al. (2016) is a reference to a study that discusses summarization tasks in natural language processing.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="BOWMAN ET AL. (2015)">
      <data key="d0">PERSON</data>
      <data key="d1">Bowman et al. (2015) is a reference to a study that discusses language inference tasks in natural language processing.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="COBBE ET AL. (2021)">
      <data key="d0">PERSON</data>
      <data key="d1">Cobbe et al. (2021) is a reference to a study that explores the reasoning abilities of language models, focusing on how these models can decompose complex inputs. The study highlights the capabilities of language models in reasoning, providing insights into their performance and potential applications in understanding and processing language. Through this research, Cobbe et al. (2021) contributes to the ongoing discourse on the effectiveness and limitations of language models in handling intricate linguistic tasks.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SAPAROV AND HE (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Saparov and He (2023) is a reference to a study that discusses the capabilities of language models in reasoning.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="YAO ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Yao et al. (2022) is a comprehensive study that investigates the role of language models in web navigation, specifically within the WebShop domain. The research evaluates how these models function in the WebShop environment, highlighting their applications in enhancing decision-making processes. Through this exploration, Yao et al. (2022) contributes valuable insights into the effectiveness of language models in facilitating user interactions and improving overall web navigation experiences.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,93cb0d0456e0822b5fe30a3e627405f8,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="DENG ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Deng et al. (2023) is a reference to a study that discusses language models in web navigation.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="SCHICK ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Schick et al. (2023) is a reference to a study that discusses tool-use capabilities of language models.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="FAN ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Fan et al. (2022) is a reference to a study that explores the application of language models in the context of open-ended games, as well as their use in complex multimodal games. The research highlights the capabilities of language models to enhance gameplay experiences by integrating linguistic understanding with various modalities, thereby contributing to the development of more interactive and engaging gaming environments.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="XIE ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Xie et al. (2023) is a reference to a study that discusses search-guided language models.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="YAO ET AL. (2023A)">
      <data key="d0">PERSON</data>
      <data key="d1">Yao et al. (2023A) is a comprehensive study that explores various aspects of search-guided language models. It delves into the sample complexity of the LATS method, comparing it with other approaches to highlight its efficiency. Additionally, the study discusses advancements in search algorithms specifically tailored for language models, aiming to enhance their performance. Furthermore, it examines the Game of 24 and its implications for the development and understanding of language models, providing a multifaceted view of the interplay between game theory and language processing.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="YAO ET AL. (2023B)">
      <data key="d0">PERSON</data>
      <data key="d1">Yao et al. (2023B) refers to a study that explores the ReAct technique, focusing on its efficiency. The research highlights the effectiveness of the ReAct method, providing insights into its application and potential benefits within the relevant field.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="SHINN ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Shinn et al. (2023) is a comprehensive study that explores various aspects of language models and their performance in decision-making tasks. The research focuses on prompting techniques for language models, examining how these techniques can enhance the models' effectiveness. Additionally, the study evaluates the performance of agents that utilize semantic feedback, highlighting its impact on decision-making processes. Furthermore, Shinn et al. (2023) assesses the performance of language models through the Reflexion method, providing insights into their capabilities and limitations. Overall, this study contributes valuable knowledge to the field of Artificial Intelligence and Natural Language Processing by investigating the interplay between prompting techniques, semantic feedback, and model evaluation methods.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,93cb0d0456e0822b5fe30a3e627405f8,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SLOMAN (1996)">
      <data key="d0">PERSON</data>
      <data key="d1">Sloman (1996) is a reference to a study that discusses human-like decision-making characteristics.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="EVANS (2010)">
      <data key="d0">PERSON</data>
      <data key="d1">Evans (2010) is a reference to a study that discusses human-like decision-making characteristics.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="AUTONOMOUS AGENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Autonomous agents are systems capable of performing tasks without human intervention, often utilizing reasoning and decision-making capabilities.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="REINFORCEMENT LEARNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Reinforcement Learning is a specialized area within machine learning that focuses on how agents make decisions through a system of rewards and penalties. This technique enables agents to learn optimal behaviors by evaluating the consequences of their actions. It is particularly relevant in the context of agentic systems, where the decision-making process is crucial. Additionally, reinforcement learning has been highlighted in various academic papers, underscoring its significance and application across multiple domains. Overall, reinforcement learning serves as a foundational approach for developing intelligent systems capable of adapting and improving their performance over time.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="COMBINATORIAL SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Combinatorial space refers to the set of all possible combinations of actions or decisions that can be made in a given context.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="HEURISTICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Heuristics are strategies or methods employed to facilitate decision-making and problem-solving, primarily grounded in experience or established rules of thumb. These approaches simplify complex decision-making processes, enabling individuals to make quick judgments effectively. By leveraging heuristics, individuals can navigate challenges more efficiently, drawing on practical insights rather than exhaustive analysis.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="EXPLORATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Exploration refers to the process of investigating or trying out different options or paths in decision-making.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="PROBLEM-SOLVING">
      <data key="d0">PROCESS</data>
      <data key="d1">Problem-solving is the process of finding solutions to complex issues or challenges, often requiring reasoning and decision-making.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="STATE-OF-THE-ART">
      <data key="d0">CONCEPT</data>
      <data key="d1">State-of-the-art refers to the highest level of development or performance achieved in a particular field or technology.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="GRADIENT-BASED FINE-TUNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Gradient-based fine-tuning is a method used to improve the performance of models by adjusting their parameters based on gradient descent techniques.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="GRADIENT-FREE PERFORMANCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Gradient-free performance refers to the ability of a model to perform tasks without relying on gradient-based optimization methods.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="EFFECTIVENESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Effectiveness refers to the degree to which a model or technique achieves its intended outcomes or goals.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="ADAPTIVE MECHANISM">
      <data key="d0">CONCEPT</data>
      <data key="d1">An adaptive mechanism is a system or process that adjusts its behavior based on feedback or changes in the environment.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="IN-CONTEXT LEARNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">In-context learning is a method where models learn from examples provided in the context of a task, enhancing their performance on similar tasks.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="FEEDBACK">
      <data key="d0">PROCESS</data>
      <data key="d1">The entity "FEEDBACK" encompasses a multifaceted concept integral to the evaluation and enhancement of models and agents in various applications. Feedback serves as a critical mechanism for providing information about performance, which is essential for improving future actions and decisions. It includes evaluations of generated solutions, highlighting their correctness and identifying areas for improvement. Additionally, feedback is supplied by experts during the refinement process, offering insights that enhance agent performance. The Critic Module plays a significant role in this context, delivering assessments regarding the accuracy of answers and suggesting improvements. Overall, feedback is vital for assessing the quality of code solutions, encompassing corrections and recommendations that contribute to ongoing development and optimization.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,449db721e37968e073e3579b59e023b2,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,93cb0d0456e0822b5fe30a3e627405f8,97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="PROFICIENT EXPLORATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Proficient exploration refers to the ability of a model or agent to effectively investigate and evaluate different options in decision-making.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="LATS">
      <data key="d0">FRAMEWORK</data>
      <data key="d1">LATS (Language Agent Tree Search) is a sophisticated search algorithm and framework designed to enhance the performance of language models (LMs) by integrating reasoning, acting, and planning. It adapts Monte Carlo Tree Search (MCTS) techniques to create a structured approach for decision-making in complex environments. LATS focuses on autonomous decision-making and interpretability, allowing language models to interact effectively with various environments.

The framework employs advanced prompting strategies and self-reflection techniques to improve decision-making performance across diverse tasks, including question answering and programming challenges. Additionally, LATS combines internal reasoning with external retrieval strategies, which has proven beneficial in specific applications such as HotPotQA and the Game of 24, where it evaluates success rates based on different parameter configurations. Overall, LATS represents a novel advancement in the field of artificial intelligence, particularly in enhancing the capabilities of language models through a comprehensive integration of reasoning, acting, and planning.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,4ae237a491bc8a84cc720e40c59a7464,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SELF-REFINEMENT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Self-refinement is a method used to improve the performance of models by allowing them to learn from their own outputs and experiences.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SELF-CONSISTENCY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Self-consistency is a method designed to enhance chain of thought reasoning in language models. This technique employs majority voting over multiple outputs, thereby improving the reliability of model predictions. By integrating these approaches, self-consistency aims to refine the decision-making process within language models, ensuring more accurate and dependable results.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (COT)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain-of-Thought (COT) is a hand-designed agent baseline specifically developed for reasoning tasks. It serves as a method that instructs agents to output reasoning steps prior to arriving at a final answer, thereby enhancing their ability to tackle complex problem-solving scenarios. COT prompting is particularly effective as it aids language models in reasoning through intricate tasks by offering structured prompts. This approach encourages these models to generate answers by systematically breaking down complex problems into sequential steps, facilitating a clearer and more logical thought process.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SILVER ET AL. (2017)">
      <data key="d0">PERSON</data>
      <data key="d1">Silver et al. (2017) is a reference to a study that discusses the success of Monte Carlo Tree Search in model-based reinforcement learning.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WEI ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Wei et al. (2022) is a reference to a study that discusses chain-of-thought prompting and its variants in language models.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="GUO ET AL. (2018)">
      <data key="d0">PERSON</data>
      <data key="d1">Guo et al. (2018) is a reference to a study that addresses error propagation in reasoning tasks with language models.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CHEN ET AL. (2021)">
      <data key="d0">PERSON</data>
      <data key="d1">Chen et al. (2021) is a reference to a study that explores the HumanEval dataset, which is utilized for evaluating programming tasks. The study also delves into the application of language models in these programming tasks, highlighting their effectiveness and potential in enhancing programming capabilities. Through this research, Chen et al. (2021) contributes valuable insights into the intersection of artificial intelligence and programming, particularly in the context of natural language processing.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="HAO ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Hao et al. (2023) is a comprehensive study that examines multiple facets of artificial intelligence methodologies, particularly focusing on the performance of LATS in comparison to other techniques. The research delves into reasoning via planning, utilizing Monte Carlo Tree Search as a pivotal approach. Additionally, it evaluates various prompting methods within decision-making tasks, highlighting their effectiveness. Furthermore, the study explores the integration of planning and search algorithms in language models, contributing valuable insights into the optimization of AI systems. Overall, Hao et al. (2023) presents a multifaceted analysis that enhances the understanding of advanced AI methodologies and their applications.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="BESTA ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Besta et al. (2023) is a reference to a study that discusses advancements in search algorithms for language models.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="AHN ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Ahn et al. (2022) is a reference to a study that discusses the application of language models in robotics as high-level controllers.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="HUANG ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Huang et al. (2022) is a reference to a study that discusses the use of language models in robotics.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="DRIESS ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Driess et al. (2023) is a reference to a study that discusses the application of language models in robotics.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="BAKER ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Baker et al. (2022) is a reference to a study that discusses the adaptation of language models to complex multimodal games.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="GUSS ET AL. (2019)">
      <data key="d0">PERSON</data>
      <data key="d1">Guss et al. (2019) is a reference to a study that discusses the application of language models in games like Minecraft.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LIU ET AL. (2018)">
      <data key="d0">PERSON</data>
      <data key="d1">Liu et al. (2018) is a reference to a study that discusses the application of language models in text-based environments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SHRIDHAR ET AL. (2020)">
      <data key="d0">PERSON</data>
      <data key="d1">Shridhar et al. (2020) is a reference to a study that discusses the use of language models in interactive environments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LIU ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Liu et al. (2024) is a reference to a study that discusses the application of language models in text-based environments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="YANG ET AL. (2018)">
      <data key="d0" />
      <data key="d1">Yang et al. (2018) is a reference to a study that discusses the HotPotQA benchmark, which is a significant contribution in the field of Artificial Intelligence and Natural Language Processing. The study provides insights into the development and evaluation of this benchmark, which is designed to assess the performance of models in answering complex questions that require multi-hop reasoning across multiple documents.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SELF-REFINE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Self-Refine is a sophisticated baseline technique designed to enhance the performance of agents in reasoning and problem-solving tasks through iterative feedback and adjustments. This method involves a manually designed agent that demonstrates notable performance metrics in various applications, including reading comprehension and scientific reasoning. By allowing agents to reflect on and correct mistakes from previous attempts, Self-Refine facilitates a process of continuous improvement. It enables language models to iteratively refine their outputs based on feedback, thereby enhancing their overall effectiveness. This technique is particularly relevant in agentic systems, where it serves as an extension of prompting techniques, leveraging self-improvement to bolster reasoning and decision-making capabilities. The concept has been discussed in academic literature, notably in a paper by Aman Madaan and colleagues, highlighting its significance in advancing model performance through self-feedback mechanisms.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,1b1399c76420a477c0c97893d258ae69,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="REFLEXION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Reflexion is a prompting method designed to enhance the reasoning capabilities of language models through self-reflection and self-improvement. It is utilized in conjunction with LATS for decision-making, where it is compared against LATS in terms of performance on tasks such as HotPotQA. Reflexion addresses the limitations of simpler methods by providing semantic feedback to agents, thereby improving their decision-making capabilities. While it is considered a simpler technique compared to LATS, Reflexion effectively focuses on enhancing reasoning and decision-making processes within language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="ADAPLANNER">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">AdaPlanner is a method that incorporates both positive and negative feedback to improve decision-making in language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="EXTERNAL TOOLS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">External tools include APIs, search engines, calculators, and other models that enhance the reasoning and practical abilities of language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="MCTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">MCTS, or Monte Carlo Tree Search, is a heuristic search algorithm designed for decision-making in complex environments. It provides principled performance gains by effectively balancing exploration and exploitation strategies. MCTS serves as a foundational algorithm that enhances performance across various decision-making tasks by exploring multiple branches of potential outcomes. Additionally, it is utilized in LATS (likely referring to a specific application or system) to identify and select high-value options while also considering promising alternatives. Overall, MCTS is recognized for its ability to improve decision-making processes in environments that require strategic exploration.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TREE-BASED SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Tree-based search is a method used in planning algorithms and reinforcement learning that explores multiple branches of outcomes for effective decision-making.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="PROBLEM SETTING AND PROMPTING">
      <data key="d0">CONCEPT</data>
      <data key="d1">This section outlines the problem setting for using language models in reasoning and decision-making, including the role of prompts.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="KURATOV ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Kuratov et al. (2023) is a reference to a study discussing the effectiveness of various prompting techniques in language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="DECISION-MAKING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Decision-making encompasses the processes through which language model agents, including those utilizing the LATS algorithm, select actions based on reasoning and the information at their disposal. This involves generating outputs in response to input prompts, where reasoning and planning play crucial roles. The decision-making process is integral to the functionality of language models, as it enables them to evaluate various options and determine the most appropriate actions based on their analytical capabilities.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="REASONING">
      <data key="d0">CONCEPT</data>
      <data key="d1">The entity "REASONING" refers to the cognitive process utilized by language models to draw conclusions or make decisions based on provided inputs. This process is essential for the effective functioning of artificial intelligence systems, particularly in the context of natural language processing, where understanding and interpreting language is crucial for generating accurate and relevant responses.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="PLANNING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Planning involves the use of algorithms to determine a sequence of actions or decisions that a language model should take to achieve a specific goal.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="TOOL USE">
      <data key="d0" />
      <data key="d1">Tool Use refers to the ability of agents in agentic systems to utilize external tools to accomplish tasks effectively. This capability encompasses employing functions or APIs, as well as utilizing resources such as search engines and code execution, to solve complex problems. In the context of artificial intelligence, tool use involves the manipulation of these external tools to achieve specific goals, highlighting its significance in enhancing the problem-solving capabilities of AI systems.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c212c1467564ad33330b1f655a8e27e,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CHAIN-OF-THOUGHT PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain-of-thought (CoT) prompting is a method that enhances reasoning by creating intermediate thoughts that connect input queries to outputs, particularly in complex scenarios like mathematical problems.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="TREE-OF-THOUGHT PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Tree-of-thought (ToT) prompting extends CoT prompting by exploring multiple reasoning paths in a tree structure, where each node represents a partial solution state.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="DECISION-MAKING TASKS">
      <data key="d0">TASK TYPE</data>
      <data key="d1">Decision-making tasks involve scenarios where choices must be made based on reasoning, often requiring complex problem-solving strategies.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="ERROR PROPAGATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Error propagation refers to the phenomenon where errors in reasoning or decision-making can lead to further inaccuracies in subsequent steps or outputs.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="OUTPUT">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Output refers to the result generated by a language model in response to a given input prompt, often representing the final answer or solution.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="LANGUAGE MODEL (LM)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A language model (LM) is an AI system designed to understand and generate human-like text based on input data and prompts.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="THOUGHTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The entity "THOUGHTS" encompasses the concept of intermediate language sequences produced during the reasoning process, which act as essential steps between the input and output in prompting techniques. Additionally, "Thoughts" are defined as the outputs generated by the FM_Module, incorporating both the agent's reasoning and the corresponding code necessary for task execution. This dual perspective highlights the role of thoughts not only as a bridge in the reasoning framework but also as integral components of the output generated by advanced language models.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="SEARCH ALGORITHMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Search algorithms are methods used to explore possible solutions or paths in decision-making processes, such as depth-first search (DFS) and breadth-first search (BFS).</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="DECISION TREE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">A decision tree is a model used to represent decisions and their possible consequences, structured as a tree with nodes representing states and edges representing actions.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="INPUT PROMPT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="LM AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The LM Agent is a decision-making entity that utilizes language models to perform reasoning and action-taking tasks based on observations from its environment.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="POLICY &#928;">
      <data key="d0">CONCEPT</data>
      <data key="d1">The policy &#960; defines the strategy that the LM Agent follows to take actions based on its observations and previous actions.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="ENVIRONMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The environment serves as the foundational context in which the LM Agent operates, offering essential observations and feedback that inform the agent's actions. Additionally, it encompasses the setting for the LATS algorithm, defining the state space and the dynamics of the tasks being executed. This dual role highlights the environment's critical importance in shaping the interactions and performance of both the LM Agent and the LATS algorithm, ensuring that they function effectively within their respective operational frameworks.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="UCT ALGORITHM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Upper Confidence Bound for Trees (UCT) algorithm is used in MCTS to balance exploration and exploitation during the selection of nodes in the search tree.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="REFLECTION">
      <data key="d0">PROCESS</data>
      <data key="d1">Reflection is a multifaceted process utilized in various contexts, particularly within Learning and Adaptive Systems (LATS) and agentic systems. In LATS, Reflection involves analyzing feedback from unsuccessful trajectories to enhance future decision-making and overall performance. This process is crucial for continuous improvement, as it allows for the integration of lessons learned from past experiences. Similarly, in agentic systems, Reflection serves as a technique that empowers agents to assess their actions critically, facilitating the enhancement of their future performance. Additionally, Reflection encompasses the user's introspection regarding their prior actions and outcomes, which leads to modifications in future search strategies. Collectively, these aspects underscore the importance of Reflection in fostering adaptive learning and effective decision-making across various domains.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,5d356b8ff719763a38cecff22c4e17b7,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="VALUE FUNCTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">The "VALUE FUNCTION" is a critical component of the LATS (Learning and Task Strategy) algorithm, serving to quantify the agent's progress in task completion. It integrates a self-generated language model (LM) score and a self-consistency score to inform decision-making processes. Additionally, the value function scores states based on anticipated future rewards, effectively guiding the search process within the algorithm. Mathematically, it represents the expected return of various states in the search tree, directing the search algorithm towards more promising areas, thereby enhancing the overall efficiency and effectiveness of the task execution.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="OBSERVATION">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The entity "OBSERVATION" refers to the information received by the LM Agent from the environment following an action taken. This information plays a crucial role in influencing subsequent decisions made by the agent. Additionally, observation encompasses the data collected during the execution of an action, which serves to inform future thoughts and actions. Thus, observations are integral to the decision-making process, as they provide essential feedback that shapes the agent's ongoing interactions with its environment.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="ACTIONS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Actions are the decisions made by the LM Agent based on its policy, which directly affect the environment and lead to new observations.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SEARCH ALGORITHM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The "SEARCH ALGORITHM" is a systematic method employed to explore possible actions and states, ultimately aimed at identifying optimal solutions or trajectories in decision-making tasks. In the context of LATS, the search algorithm plays a crucial role in navigating the decision tree, leveraging heuristics and feedback to select the most promising paths for task completion. Additionally, within ADAS, the search algorithm is utilized to explore the search space, with the goal of discovering high-performance agentic systems. This multifaceted approach highlights the algorithm's importance in enhancing decision-making processes across various applications.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,4884e8429ca1e567dadf5e22b4b68274,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="BACKPROPAGATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SELF-CONSISTENCY SCORE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The "SELF-CONSISTENCY SCORE" is a crucial metric employed to assess the reliability of results generated by the LATS (Learning and Adaptive Techniques for Sampling) method, particularly in the context of the Game of 24. This score serves as a heuristic that enhances value assignment by evaluating the accuracy of actions sampled multiple times at the same state. By focusing on self-consistency, the score ensures that the outcomes produced by the LATS method are dependable, thereby improving the overall effectiveness of the decision-making process within the game.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HYPERPARAMETER">
      <data key="d0">CONCEPT</data>
      <data key="d1">A hyperparameter in LATS, denoted as &#955;, is used to balance the contributions of the LM score and self-consistency score in the overall value function.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="ENVIRONMENTAL FEEDBACK">
      <data key="d0">CONCEPT</data>
      <data key="d1">Environmental feedback in LATS provides objective assessments of the correctness of trajectories, influencing the agent's learning and decision-making.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="SELF-REFLECTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Self-reflection is a critical process within LATS (Learning Agent Technology Systems) that enables agents to analyze unsuccessful outcomes and propose better alternatives, thereby enhancing their learning from errors. This technique involves a meta agent that reviews its previous outputs to identify mistakes and suggest improvements, facilitating an iterative refinement of both novelty and correctness in generated agents. By evaluating their own performance, agents can continuously improve over time, making self-reflection an essential component of agentic systems.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="TRIAL AND ERROR">
      <data key="d0">CONCEPT</data>
      <data key="d1">Trial and error is a learning process in LATS where the agent learns from past experiences without the need for expensive optimization methods like reinforcement learning.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="SCALAR VALUE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A scalar value in LATS is assigned to each new child node to quantify the agent's progress in task completion, serving as a heuristic for guiding the search algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="TERMINAL STATE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A terminal state in LATS is the endpoint of a trajectory where the outcome of the task is evaluated, providing feedback for the agent's learning process.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="TRAJECTORY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A trajectory in LATS refers to the path taken by the agent through the decision tree, from the initial state to a terminal state, which is evaluated for success or failure.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="REWARD">
      <data key="d0">CONCEPT</data>
      <data key="d1">The entity "REWARD" encompasses multiple interpretations across different contexts. In the context of LATS (likely a learning or algorithmic framework), a reward is defined as a feedback signal received by an agent upon reaching a terminal state, which plays a crucial role in influencing the value updates of nodes within the search tree. Additionally, in the realm of e-commerce, specifically within a Web Shop system, reward serves as a metric for evaluating performance, calculated based on the number of attributes satisfied by the selected item. Furthermore, in broader algorithmic applications, reward refers to the feedback received from the environment based on the actions taken, which is instrumental in assessing the success of trajectories within various algorithms. Collectively, these descriptions highlight the multifaceted nature of "REWARD" as a critical component in both reinforcement learning and performance evaluation across different systems.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="UCT FORMULA">
      <data key="d0">CONCEPT</data>
      <data key="d1">The Upper Confidence Bound for Trees (UCT) formula is used in LATS to guide the selection of the next node based on updated values and exploration strategies.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="PROGRAMMED HEURISTICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Programmed heuristics are predefined strategies used in decision-making processes, which LATS aims to improve upon with its flexible and adaptive approach.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="LEARNED HEURISTICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Learned heuristics are strategies developed through training, which LATS seeks to outperform in terms of efficiency and adaptability in various scenarios.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="AGENT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="TO">
      <data key="d0">METHOD</data>
      <data key="d1">ToT is a prompting method that adapts search algorithms for decision-making in language models.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="RAP">
      <data key="d0">METHOD</data>
      <data key="d1">RAP (Retrieval-Augmented Prompting) is a sophisticated prompting method designed to enhance the reasoning capabilities of language models by incorporating external retrieval strategies. This innovative approach not only combines reasoning and action but also serves as a benchmark for comparing performance and efficiency with other methods, such as LATS. By integrating these strategies, RAP aims to significantly improve the overall performance of language models, making it a valuable tool in the fields of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="API CALLS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">API calls are used in the context of language models to search and retrieve information, enhancing the model's ability to answer questions.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="CO">
      <data key="d0">METHOD</data>
      <data key="d1">CoT is a prompting method that focuses on reasoning based on the existing knowledge of language models.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="AUSTIN ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Austin et al. (2022) is a reference to a study that evaluates language models in various domains.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="EXTERNAL FEEDBACK">
      <data key="d0">CONCEPT</data>
      <data key="d1">External feedback refers to information provided to the language model agent about the correctness of its answers, which can enhance its reasoning capabilities.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="INTERNAL REASONING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Internal reasoning involves the language model's ability to generate answers based solely on its existing knowledge without external input.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="OBSERVATION SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The observation space consists of the outputs from API calls and self-generated reflections that inform the language model's decision-making process.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SAMPLE TRAJECTORIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Sample trajectories are paths or sequences of actions taken by the language model agent during its decision-making process, used for evaluation.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="FEEDBACK CORRECTNESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Feedback correctness refers to the accuracy of the information provided to the language model agent regarding the correctness of its answers.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="PROMPTING DESIGNS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Prompting designs are structured formats or strategies used to guide the language model in generating responses or performing tasks.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="LANGUAGE MODEL AGENT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="COT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">COT, or Chain of Thought, is a prompting technique designed to enhance the reasoning capabilities of language models. It encourages the model to engage in a step-by-step thought process before arriving at an answer. This method not only promotes clearer reasoning but also slightly improves performance on various reasoning tasks, making it a valuable tool in the field of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="TOT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">ToT (Tree of Thought) is a search method that samples and explores outputs to improve performance in reasoning tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="HUMANEVAL">
      <data key="d0">DATASET</data>
      <data key="d1">HumanEval is a specialized dataset designed for evaluating programming tasks within language models. It serves as a tool to assess the correctness of Python programs that are synthesized from natural language descriptions. This dual purpose highlights HumanEval's role in both the evaluation of programming capabilities and the effectiveness of language models in translating human language into functional code.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="MBPP">
      <data key="d0">DATASET</data>
      <data key="d1">MBPP (Multi-Choice Programming Problems) is a dataset that measures the performance of models in generating correct Python code from natural language prompts.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="IL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">IL, or Imitation Learning, is a method utilized in the field of Artificial Intelligence that focuses on training models to replicate expert behavior across a range of tasks. This includes both reasoning and acting, making it a versatile approach in developing intelligent systems.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="IL+RL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">IL+RL (Imitation Learning with Reinforcement Learning) combines imitation learning with reinforcement learning to improve model performance in complex tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="EXTERNAL OBSERVATIONS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">External observations refer to additional context or feedback used to enhance the reasoning capabilities of models during tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="SYNTHETIC TEST SUITE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A synthetic test suite consists of generated test cases used to evaluate the correctness of programming solutions.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="WEB SHOP">
      <data key="d0">ENVIRONMENT</data>
      <data key="d1">The Web Shop is an online platform designed for users to search for and purchase a wide range of products, including items like deodorants, by utilizing specific criteria such as size and price. It features a structured interface that enables users to view search results and make purchases efficiently. Additionally, the Web Shop encompasses a diverse array of real-world products and incorporates human instructions, allowing agents to navigate the platform effectively to meet user specifications. This comprehensive shopping environment enhances the online shopping experience by facilitating user interaction and product discovery.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,785ad59c6a37896a4676ec5c1689735f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="COACHING OF THOUGHT (COT)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">CoT is a prompting method that guides agents in reasoning tasks, helping them to arrive at solutions through structured thinking.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="GAME OF 24">
      <data key="d0">TASK</data>
      <data key="d1">The "Game of 24" is a mathematical reasoning challenge that engages players in using basic arithmetic operations to derive the number 24 from a set of four given numbers. This task requires participants to apply their mathematical skills creatively, as they must manipulate the numbers through addition, subtraction, multiplication, and division to achieve the target number. The game serves as both a cognitive exercise and a fun activity, promoting critical thinking and problem-solving abilities among its players.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="DFS">
      <data key="d0">ALGORITHM</data>
      <data key="d1">DFS, or Depth-First Search, is a search algorithm that systematically explores as far as possible along each branch of a decision tree before backtracking. This method is particularly useful in decision-making tasks, allowing for thorough exploration of potential solutions. Additionally, DFS is often compared with Monte Carlo Tree Search (MCTS), highlighting its role in various algorithmic strategies within fields such as Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="RL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">RL (Reinforcement Learning) is a type of machine learning where agents learn to make decisions by receiving rewards or penalties based on their actions.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="FURUTA ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Furuta et al. (2024) is a reference to a study that discusses fine-tuning methods in machine learning.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="TOOL OF THOUGHT (TOT)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">ToT is a prompting method that aids agents in reasoning tasks by providing structured guidance.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="HOT-POTQA">
      <data key="d0">DATASET</data>
      <data key="d1">HotPotQA is a dataset used for evaluating the performance of various methods in question answering tasks, particularly in the context of tree-based search methods.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TOKEN CONSUMPTION">
      <data key="d0">METRIC</data>
      <data key="d1">Token consumption refers to the number of tokens used during the execution of a method, which is a critical factor in evaluating the efficiency of search algorithms.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SAMPLE COMPLEXITY">
      <data key="d0">METRIC</data>
      <data key="d1">Sample complexity is a critical metric that quantifies the number of samples or tokens necessary for the LATS algorithm to attain a specified level of performance. It serves as an essential measure for evaluating the efficiency of algorithms, highlighting the relationship between the amount of data utilized and the effectiveness of the method employed. Understanding sample complexity is vital for optimizing algorithm performance and ensuring that sufficient data is available to achieve desired outcomes.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="NODES EXPANDED">
      <data key="d0">METRIC</data>
      <data key="d1">Nodes expanded refers to the number of nodes processed during the search, which is a critical factor in evaluating the efficiency of search algorithms.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The entity "TRAJECTORIES" refers to sequences of actions or decisions made by an algorithm throughout its search process. These trajectories are essential for evaluating the performance and efficiency of the algorithm, providing insights into its operational dynamics. However, no additional context or descriptions were provided to further enrich this summary.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="GROUND-TRUTH FEEDBACK">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Ground-truth feedback is the actual correct information used to guide the learning process of the algorithm, enhancing its performance.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="COMPUTATIONAL COST">
      <data key="d0">METRIC</data>
      <data key="d1">The term "Computational Cost" encompasses the resources necessary to execute a method, which is a critical factor when assessing the LATS (Language and Textual Analysis System) algorithm in comparison to simpler methodologies. Specifically, the computational cost associated with running the LATS algorithm can be notably higher than that of these simpler methods. This highlights the importance of considering computational efficiency and resource allocation when choosing between different analytical approaches in the field of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="LATS PERFORMANCE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SYSTEM-2 LM APPROACHES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">System-2 LM approaches refer to advanced methods in language modeling that emphasize reasoning and decision-making over simple autoregressive generation.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DECISION-MAKING COMMUNITY">
      <data key="d0">COMMUNITY</data>
      <data key="d1">The decision-making community encompasses researchers and practitioners focused on improving decision-making processes using language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DANIEL CAMPOS">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Campos is an individual acknowledged for providing useful feedback on earlier versions of the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NSF GRANT 2106825">
      <data key="d0">FUNDING</data>
      <data key="d1">NSF Grant 2106825 is a financial support awarded for research related to language models and their applications.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NIFA AWARD 2020-67021-32799">
      <data key="d0">FUNDING</data>
      <data key="d1">NIFA Award 2020-67021-32799 is a financial support awarded for research related to language models and their applications.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="IBM-ILLINOIS DISCOVERY ACCELERATOR INSTITUTE">
      <data key="d0">INSTITUTION</data>
      <data key="d1">The IBM-Illinois Discovery Accelerator Institute is an institution that supports research and development in advanced computing and AI technologies.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NVIDIA GPUS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">NVIDIA GPUs are high-performance graphics processing units used for computational tasks, including those in language model research.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ACCESS PROGRAM">
      <data key="d0">PROGRAM</data>
      <data key="d1">The ACCESS program provides allocations for computational resources to support research initiatives, including those involving language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="MICHAEL AHN">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Ahn is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ANTHONY BROHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Anthony Brohan is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NOAH BROWN">
      <data key="d0">PERSON</data>
      <data key="d1">Noah Brown is a researcher specializing in embodied reasoning through planning with language models. He has contributed to the field by co-authoring a paper that focuses on grounding language in robotic affordances, highlighting his involvement in the intersection of language processing and robotics. His work emphasizes the integration of linguistic understanding with practical applications in robotics, showcasing his expertise in both artificial intelligence and natural language processing.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YEVGEN CHEBOTAR">
      <data key="d0">PERSON</data>
      <data key="d1">Yevgen Chebotar is a prominent researcher specializing in embodied reasoning through planning with language models. He is actively involved in the development of PaLM-E, an advanced embodied multimodal language model that integrates various forms of data and reasoning. Additionally, Chebotar has co-authored a significant paper focused on grounding language in robotic affordances, highlighting his contributions to the intersection of language processing and robotics. His work emphasizes the importance of understanding and utilizing language in practical, embodied contexts, making him a key figure in the fields of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="OMAR CORTES">
      <data key="d0">PERSON</data>
      <data key="d1">Omar Cortes is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="BYRON DAVID">
      <data key="d0">PERSON</data>
      <data key="d1">Byron David is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CHELSEA FINN">
      <data key="d0">PERSON</data>
      <data key="d1">Chelsea Finn is a prominent researcher recognized for her significant contributions to the fields of Artificial Intelligence and Natural Language Processing. She is particularly known for her work on model-agnostic meta-learning, which emphasizes the development of algorithms that can adapt to new tasks with minimal data. Additionally, Finn has co-authored influential papers on direct preference optimization, a method that enhances decision-making processes in AI systems, and on grounding language in robotic affordances, which explores how robots can understand and interact with their environments through language. Her research plays a crucial role in advancing the understanding and capabilities of AI systems, particularly in their ability to learn and adapt in dynamic settings.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,34d0bb2211fc795fe1096442e086a2b3,4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CHUYUAN FU">
      <data key="d0">PERSON</data>
      <data key="d1">Chuyuan Fu is a researcher actively contributing to advancements in language models, particularly in the context of their application in robotics. He co-authored a paper focused on grounding language in robotic affordances, highlighting his involvement in bridging the gap between natural language processing and practical robotic applications. Through his work, Chuyuan Fu plays a significant role in enhancing the understanding and functionality of language models within the field of artificial intelligence.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="KEERTHANA GOPALAKRISHNAN">
      <data key="d0">PERSON</data>
      <data key="d1">Keerthana Gopalakrishnan is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="KAROL HAUSMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Karol Hausman is a prominent researcher specializing in embodied reasoning through planning with language models. He is actively involved in the development of PaLM-E, an advanced embodied multimodal language model that integrates various forms of data and reasoning. Additionally, Hausman has co-authored a significant paper focused on grounding language in robotic affordances, highlighting his contributions to the intersection of language processing and robotics. His work emphasizes the importance of understanding and utilizing language in the context of physical interactions and capabilities of robots.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEX HERZOG">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Herzog is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DANIEL HO">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Ho is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JASMINE HSU">
      <data key="d0">PERSON</data>
      <data key="d1">Jasmine Hsu is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JULIAN IBARZ">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Ibarz is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="BRIAN ICHTER">
      <data key="d0">PERSON</data>
      <data key="d1">Brian Ichter is a researcher actively contributing to the field of embodied reasoning, particularly through the integration of planning with language models. He is notably involved in the development of PaLM-E, an advanced embodied multimodal language model that enhances the interaction between language and physical actions. Additionally, Ichter has co-authored a paper focused on grounding language in robotic affordances, further emphasizing his commitment to bridging the gap between linguistic understanding and robotic capabilities. His work reflects a significant intersection of artificial intelligence and natural language processing, highlighting his role in advancing these technologies.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEX IRPAN">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Irpan is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ERIC JANG">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Jang is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ROSARIO JAUREGUI RUANO">
      <data key="d0">PERSON</data>
      <data key="d1">Rosario Jauregui Ruano is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="KYLE JEFFREY">
      <data key="d0">PERSON</data>
      <data key="d1">Kyle Jeffrey is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="SALLY JESMONTH">
      <data key="d0">PERSON</data>
      <data key="d1">Sally Jesmonth is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NIKHIL J JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Nikhil J Joshi is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="RYAN JULIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ryan Julian is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DMITRY KALASHNIKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Dmitry Kalashnikov is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="YUHENG KUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuheng Kuang is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="KUANG-HUEI LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Kuang-Huei Lee is a prominent researcher recognized for his significant contributions to the field of language models and multimodal web navigation. He specializes in the development of instruction-finetuned foundation models that enhance user interaction with web content. Additionally, Lee has co-authored a paper focused on grounding language in robotic affordances, further demonstrating his expertise in integrating language processing with robotics. His work reflects a commitment to advancing the capabilities of artificial intelligence in understanding and navigating complex environments.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SERGEY LEVINE">
      <data key="d0">PERSON</data>
      <data key="d1">Sergey Levine is a prominent researcher in the fields of Artificial Intelligence and Natural Language Processing, with a focus on embodied reasoning and planning through the use of language models. He is actively involved in model-agnostic meta-learning, which enhances the adaptability of machine learning models across various tasks. Levine has made significant contributions to the development of PaLM-E, an advanced embodied multimodal language model that integrates various forms of data. Additionally, he co-authored a paper that explores the grounding of language in robotic affordances, emphasizing the practical applications of language in robotics. Furthermore, Levine has engaged in discussions regarding the imitation of proprietary language models, contributing to the broader discourse on the ethical and practical implications of such technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YAO LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yao Lu is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="LINDA LUU">
      <data key="d0">PERSON</data>
      <data key="d1">Linda Luu is a researcher specializing in embodied reasoning through planning with language models. She has contributed to the field by co-authoring a paper that focuses on grounding language in robotic affordances, highlighting her involvement in the intersection of language processing and robotics. Her work emphasizes the integration of language models with practical applications in robotics, showcasing her expertise in both artificial intelligence and natural language processing.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CAROLINA PARADA">
      <data key="d0">PERSON</data>
      <data key="d1">Carolina Parada is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="PETER PASTOR">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Pastor is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JORNELL QUIAMBAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jornell Quiambao is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="KANISHKA RAO">
      <data key="d0">PERSON</data>
      <data key="d1">Kanishka Rao is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JAREK RETTINGHOUSE">
      <data key="d0">PERSON</data>
      <data key="d1">Jarek Rettinghouse is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DIEGO REYES">
      <data key="d0">PERSON</data>
      <data key="d1">Diego Reyes is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="PIERRE SERMANET">
      <data key="d0">PERSON</data>
      <data key="d1">Pierre Sermanet is a prominent researcher in the field of artificial intelligence, specifically focusing on embodied reasoning and the integration of language models with planning. He has made significant contributions to the development of PaLM-E, an advanced embodied multimodal language model that enhances the interaction between language and physical actions. Additionally, Sermanet has co-authored a paper that explores the grounding of language in robotic affordances, further emphasizing his commitment to bridging the gap between linguistic understanding and robotic capabilities. Through his work, Sermanet is actively advancing the understanding and application of language models in real-world scenarios, particularly in robotics.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NICOLAS SIEVERS">
      <data key="d0">PERSON</data>
      <data key="d1">Nicolas Sievers is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CLAYTON TAN">
      <data key="d0">PERSON</data>
      <data key="d1">Clayton Tan is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ALEXANDER TOSHEV">
      <data key="d0">PERSON</data>
      <data key="d1">Alexander Toshev is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="VINCENT VANHOUCKE">
      <data key="d0">PERSON</data>
      <data key="d1">Vincent Vanhoucke is a prominent researcher recognized for his contributions to the field of artificial intelligence, particularly in the development of advanced language models. He is notably involved in the creation of PaLM-E, an embodied multimodal language model that integrates various forms of data to enhance understanding and interaction. Additionally, Vanhoucke has co-authored a significant paper focused on grounding language in robotic affordances, which explores how language can be effectively linked to the capabilities and actions of robots. His work exemplifies the intersection of language processing and robotics, highlighting his role in advancing the understanding of how machines can interpret and respond to human language in practical contexts.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FEI XIA">
      <data key="d0">PERSON</data>
      <data key="d1">Fei Xia is a prominent researcher actively contributing to advancements in language models and their diverse applications. Notably, Xia is involved in the development of PaLM-E, an innovative embodied multimodal language model that integrates various forms of data. Additionally, Xia has co-authored a significant paper focused on grounding language in robotic affordances, highlighting the intersection of language processing and robotics. Through these contributions, Fei Xia plays a crucial role in enhancing the understanding and capabilities of language models within the fields of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="TED XIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Ted Xiao is a researcher actively engaged in the field of embodied reasoning, particularly focusing on the integration of planning with language models. His work emphasizes the importance of grounding language in practical applications, as evidenced by his co-authorship of a paper that explores the relationship between language and robotic affordances. Through these contributions, Ted Xiao is advancing the understanding of how language can be effectively utilized in robotic systems, enhancing their ability to interact with and interpret their environments.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PENG XU">
      <data key="d0">PERSON</data>
      <data key="d1">Peng Xu is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="SICHUN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Sichun Xu is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="MENGYUAN YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Mengyuan Yan is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ANDY ZENG">
      <data key="d0">PERSON</data>
      <data key="d1">Andy Zeng is a prominent researcher specializing in embodied reasoning, particularly through the integration of planning with language models. He has made significant contributions to the development of PaLM-E, an advanced embodied multimodal language model that enhances the interaction between language and physical actions. Additionally, Zeng has co-authored a paper focused on grounding language in robotic affordances, further demonstrating his expertise in the intersection of language processing and robotics. His work is pivotal in advancing the understanding and application of language models in embodied contexts.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JORNELL QUIAMBAO&lt;|(&quot;ENTITY&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="PROGRAM SYNTHESIS">
      <data key="d0" />
      <data key="d1">Program synthesis is a process that involves the automatic generation of code from high-level specifications or natural language descriptions. This technique aims to bridge the gap between human intentions and machine-executable code, facilitating the development of software by allowing users to specify what they want in a more intuitive manner. By leveraging natural language inputs, program synthesis can enhance productivity and reduce the complexity associated with traditional coding practices.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="VIDEO PRETRAINING (VPT)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Video pretraining (VPT) is a technique that involves training models to learn to act by observing unlabeled online videos, enhancing their performance in action-related tasks.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="GRAPH OF THOUGHTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Graph of Thoughts is a method for solving complex problems using large language models, focusing on structured reasoning and decision-making.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NATURAL LANGUAGE INFERENCE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Natural language inference is a task in natural language processing that involves determining the logical relationship between sentences, often used for training language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DEEP BLUE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Deep Blue is a chess-playing computer developed by IBM, known for its ability to compete against and defeat human chess champions.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CODET">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">CodeT is a technique for code generation that includes generating tests to ensure the correctness of the generated code.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="AMODEI">
      <data key="d0">PERSON</data>
      <data key="d1">Dario Amodei is a researcher known for his work on language models and their capabilities as few-shot learners.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MURRAY CAMPBELL">
      <data key="d0">PERSON</data>
      <data key="d1">Murray Campbell is a researcher associated with the development of the Deep Blue chess program.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSEPH HOANE JR">
      <data key="d0">PERSON</data>
      <data key="d1">Joseph Hoane Jr is a researcher involved in the development of the Deep Blue chess program.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FENG-HSIUNG HSU">
      <data key="d0">PERSON</data>
      <data key="d1">Feng-hsiung Hsu is a researcher associated with the Deep Blue chess program.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BEI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Bei Chen is a researcher who co-authored a paper on CodeT, a code generation model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FENGJI ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Fengji Zhang is a researcher who co-authored a paper on CodeT, a code generation model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANH NGUYEN">
      <data key="d0">PERSON</data>
      <data key="d1">Anh Nguyen is a researcher actively engaged in the advancement of artificial intelligence technologies. He has made significant contributions to the Phi-3 technical report, showcasing his expertise in the field. Additionally, Anh Nguyen co-authored a paper on CodeT, a model designed for code generation, further highlighting his involvement in innovative AI research and development. Through these efforts, he plays a vital role in the ongoing evolution of AI applications.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DAOGUANG ZAN">
      <data key="d0">PERSON</data>
      <data key="d1">Daoguang Zan is a researcher who co-authored a paper on CodeT, a code generation model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ZEQI LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Zeqi Lin is a researcher actively engaged in the advancement of artificial intelligence technologies. He has made significant contributions to the Phi-3 technical report, showcasing his expertise in the field. Additionally, Zeqi Lin co-authored a paper on CodeT, a model designed for code generation, further highlighting his involvement in innovative AI applications. Through these efforts, he plays a vital role in the ongoing development and research within the AI community.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIAN-GUANG LOU">
      <data key="d0">PERSON</data>
      <data key="d1">Jian-Guang Lou is a researcher who co-authored a paper on CodeT, a code generation model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WEIZHU CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Weizhu Chen is a prominent researcher in the field of Artificial Intelligence, actively contributing to the advancement of AI technologies. He has played a significant role in the development of the Phi-3 technical report, showcasing his expertise in the domain. Additionally, Weizhu Chen co-authored a paper on CodeT, a model designed for code generation, further highlighting his involvement in innovative AI applications. In 2023, he also co-authored a paper focused on a human-centric benchmark for evaluating foundation models, emphasizing his commitment to enhancing the evaluation standards within the AI community. Through these contributions, Weizhu Chen is establishing himself as a key figure in the ongoing development and assessment of AI technologies.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MARK CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Mark Chen is a researcher specializing in the evaluation and training of large language models, particularly in the context of code. He has a significant focus on developing verifiers designed to solve math word problems. His work encompasses both the training of these verifiers and the evaluation of their effectiveness, contributing to advancements in the field of Natural Language Processing and Artificial Intelligence.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JERRY TWOREK">
      <data key="d0">PERSON</data>
      <data key="d1">Jerry Tworek is a researcher actively engaged in the training of verifiers specifically designed to solve math word problems. In addition to this focus, he is also involved in evaluating large language models that have been trained on code. His work contributes significantly to the development and assessment of methodologies that enhance the capabilities of artificial intelligence in understanding and processing mathematical language and coding tasks.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HEEWOO JUN">
      <data key="d0">PERSON</data>
      <data key="d1">Heewoo Jun is a researcher actively engaged in the training of verifiers for math word problems. In addition to this focus, Heewoo Jun also contributes to the evaluation of large language models that are specifically trained on code. This dual involvement highlights Heewoo Jun's commitment to advancing methodologies in both mathematical problem-solving and programming language processing within the field of Artificial Intelligence.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QIMING YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Qiming Yuan is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HENRIQUE PONDE">
      <data key="d0">PERSON</data>
      <data key="d1">Henrique Ponde is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JARED KAPLAN">
      <data key="d0">PERSON</data>
      <data key="d1">Jared Kaplan is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HARRISON EDWARDS">
      <data key="d0">PERSON</data>
      <data key="d1">Harrison Edwards is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YURA BURDA">
      <data key="d0">PERSON</data>
      <data key="d1">Yura Burda is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NICHOLAS JOSEPH">
      <data key="d0">PERSON</data>
      <data key="d1">Nicholas Joseph is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GREG BROCKMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Greg Brockman is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEX RAY">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Ray is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="RAUL PURI">
      <data key="d0">PERSON</data>
      <data key="d1">Raul Puri is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GRETCHEN KRUEGER">
      <data key="d0">PERSON</data>
      <data key="d1">Gretchen Krueger is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MICHAEL PETROV">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Petrov is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HEIDY KHLAAF">
      <data key="d0">PERSON</data>
      <data key="d1">Heidy Khlaaf is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GIRISH SASTRY">
      <data key="d0">PERSON</data>
      <data key="d1">Girish Sastry is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PAMELA MISHKIN">
      <data key="d0">PERSON</data>
      <data key="d1">Pamela Mishkin is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BROOKE CHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Brooke Chan is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SCOTT GRAY">
      <data key="d0">PERSON</data>
      <data key="d1">Scott Gray is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NICK RYDER">
      <data key="d0">PERSON</data>
      <data key="d1">Nick Ryder is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MIKHAIL PAVLOV">
      <data key="d0">PERSON</data>
      <data key="d1">Mikhail Pavlov is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALETHEA POWER">
      <data key="d0">PERSON</data>
      <data key="d1">Alethea Power is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="LUKASZ KAISER">
      <data key="d0">PERSON</data>
      <data key="d1">Lukasz Kaiser is a researcher with a focus on the development and training of verifiers specifically designed to solve math word problems. In addition to this, he is also engaged in the evaluation of large language models that are trained on code. His work encompasses both the training of these verifiers and the assessment of their effectiveness in addressing complex mathematical challenges, highlighting his dual expertise in natural language processing and mathematical problem-solving.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MOHAMMAD BAVARIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammad Bavarian is a dedicated researcher specializing in the training of verifiers for math word problems. His work encompasses evaluating large language models that are specifically trained on code, highlighting his involvement in both the mathematical and computational aspects of artificial intelligence. Through his research, Bavarian aims to enhance the capabilities of verifiers, contributing significantly to the field of Natural Language Processing and its applications in solving complex mathematical challenges.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CLEMENS WINTER">
      <data key="d0">PERSON</data>
      <data key="d1">Clemens Winter is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PHILIPPE TILLET">
      <data key="d0">PERSON</data>
      <data key="d1">Philippe Tillet is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FELIPE PETROSKI SUCH">
      <data key="d0">PERSON</data>
      <data key="d1">Felipe Petroski Such is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DAVID W. CUMMINGS">
      <data key="d0">PERSON</data>
      <data key="d1">David W. Cummings is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MATTHIAS PLAPPERT">
      <data key="d0">PERSON</data>
      <data key="d1">Matthias Plappert is a researcher actively engaged in the training and evaluation of verifiers for math word problems. His work focuses on developing methodologies to enhance the accuracy and effectiveness of these verifiers. Additionally, he is involved in evaluating large language models that are specifically trained on code, indicating a broad expertise in both mathematical problem-solving and programming language processing. Through his contributions, Plappert plays a significant role in advancing the capabilities of artificial intelligence in understanding and solving complex tasks.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FOTIOS CHANTZIS">
      <data key="d0">PERSON</data>
      <data key="d1">Fotios Chantzis is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ELIZABETH BARNES">
      <data key="d0">PERSON</data>
      <data key="d1">Elizabeth Barnes is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ARIEL HERBERT-VOSS">
      <data key="d0">PERSON</data>
      <data key="d1">Ariel Herbert-Voss is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WILLIAM H. GUSS">
      <data key="d0">PERSON</data>
      <data key="d1">William H. Guss is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEX NICOL">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Nicol is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="IGOR BABUSHKIN">
      <data key="d0">PERSON</data>
      <data key="d1">Igor Babushkin is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SUCHIR BALAJI">
      <data key="d0">PERSON</data>
      <data key="d1">Suchir Balaji is a researcher actively engaged in the evaluation of large language models specifically trained on code. In addition to this work, he has co-authored a paper focused on browser-assisted question-answering, contributing to advancements in the field of Natural Language Processing. His research efforts reflect a commitment to enhancing the capabilities and applications of AI technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SHANTANU JAIN">
      <data key="d0">PERSON</data>
      <data key="d1">Shantanu Jain is a researcher actively engaged in the evaluation of large language models specifically trained on code. In addition to this work, he has co-authored a paper focused on browser-assisted question-answering, contributing to advancements in the field of Natural Language Processing. His research efforts reflect a commitment to enhancing the capabilities and applications of AI technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANDREW CARR">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Carr is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JAN LEIKE">
      <data key="d0">PERSON</data>
      <data key="d1">Jan Leike is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA ACHIAM">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Achiam is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="VEDANT MISRA">
      <data key="d0">PERSON</data>
      <data key="d1">Vedant Misra is a researcher involved in evaluating large language models trained on code.Vedant Misra is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="EVAN MORIKAWA">
      <data key="d0">PERSON</data>
      <data key="d1">Evan Morikawa is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEC RADFORD">
      <data key="d0">PERSON</data>
      <data key="d1">Alec Radford is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MATTHEW M. KNIGHT">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew M. Knight is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MILES BRUNDAGE">
      <data key="d0">PERSON</data>
      <data key="d1">Miles Brundage is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MIRA MURATI">
      <data key="d0">PERSON</data>
      <data key="d1">Mira Murati is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KATIE MAYER">
      <data key="d0">PERSON</data>
      <data key="d1">Katie Mayer is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PETER WELINDER">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Welinder is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BOB MCGREW">
      <data key="d0">PERSON</data>
      <data key="d1">Bob McGrew is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DARIO AMODEI">
      <data key="d0">PERSON</data>
      <data key="d1">Dario Amodei is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SAM MCCANDLISH">
      <data key="d0">PERSON</data>
      <data key="d1">Sam McCandlish is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ILYA SUTSKEVER">
      <data key="d0">PERSON</data>
      <data key="d1">Ilya Sutskever is a prominent researcher in the field of reinforcement learning, known for his significant contributions to the development and evaluation of large language models, particularly those trained on code. He has co-authored influential papers that explore the intersection of reinforcement learning and game mastery through the application of deep neural networks. His work has positioned him as a key figure in advancing the understanding and capabilities of artificial intelligence, particularly in the realms of machine learning and natural language processing.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,2d4672dfb7bd4283f0b5f23ab4f26653,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WOJCIECH ZAREMBA">
      <data key="d0">PERSON</data>
      <data key="d1">Wojciech Zaremba is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WENHU CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Wenhu Chen is a researcher who co-authored a paper on program of thoughts prompting for numerical reasoning tasks.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XUEGUANG MA">
      <data key="d0">PERSON</data>
      <data key="d1">Xueguang Ma is a researcher who co-authored a paper on program of thoughts prompting for numerical reasoning tasks.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WILLIAM W. COHEN">
      <data key="d0">PERSON</data>
      <data key="d1">William W. Cohen is a researcher who co-authored a paper on program of thoughts prompting for numerical reasoning tasks.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="AAKANKSHA CHOWDHERY">
      <data key="d0">PERSON</data>
      <data key="d1">Aakanksha Chowdhery is a prominent researcher specializing in language model applications. She has played a significant role in the development of advanced language models, including PaLM and PaLM-E, the latter being an embodied multimodal language model. In addition to her contributions to model development, Aakanksha co-authored a paper in 2022 that addressed challenging big-bench tasks, further showcasing her expertise and involvement in the evolving landscape of artificial intelligence and natural language processing.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHARAN NARANG">
      <data key="d0">PERSON</data>
      <data key="d1">Sharan Narang is a researcher actively contributing to advancements in language models, with a specific focus on the development of PaLM, a notable language model. Through his work, Narang plays a significant role in enhancing the capabilities and applications of language processing technologies.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JACOB DEVLIN">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Devlin is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MAARTEN BOSMA">
      <data key="d0">PERSON</data>
      <data key="d1">Maarten Bosma is a researcher specializing in prompting techniques for large language models. He is actively involved in the development of PaLM, a prominent language model. Through his work, Bosma contributes to advancing the capabilities and applications of artificial intelligence in natural language processing, focusing on enhancing the interaction between users and language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GAURAV MISHRA">
      <data key="d0">PERSON</data>
      <data key="d1">Gaurav Mishra is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ADAM ROBERTS">
      <data key="d0">PERSON</data>
      <data key="d1">Adam Roberts is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PAUL BARHAM">
      <data key="d0">PERSON</data>
      <data key="d1">Paul Barham is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HYUNG WON CHUNG">
      <data key="d0">PERSON</data>
      <data key="d1">Hyung Won Chung is a prominent researcher in the field of Artificial Intelligence, particularly known for his contributions to the development of the PaLM language model. In 2022, he co-authored a paper addressing challenging big-bench tasks, showcasing his expertise in evaluating and enhancing language models. Additionally, he has collaborated on research focused on multilingual chain-of-thought reasoning, further demonstrating his commitment to advancing the capabilities of natural language processing. Through these endeavors, Hyung Won Chung has established himself as a key figure in the AI research community.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHARLES SUTTON">
      <data key="d0">PERSON</data>
      <data key="d1">Charles Sutton is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SEBASTIAN GEHRMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Gehrmann is a prominent researcher in the field of artificial intelligence, specifically recognized for his contributions to the development of PaLM, a sophisticated language model. In addition to his work on PaLM, he co-authored a significant paper in 2022 that addressed challenging big-bench tasks, showcasing his active engagement in advancing the capabilities and understanding of language models within the research community.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="PARKER SCHUH">
      <data key="d0">PERSON</data>
      <data key="d1">Parker Schuh is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KENSEN SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Kensen Shi is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SASHA TSVYASHCHENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Sasha Tsvyashchenko is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA MAYNEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Maynez is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ABHISHEK RAO">
      <data key="d0">PERSON</data>
      <data key="d1">Abhishek Rao is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YI TAY">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Tay is a prominent researcher in the field of Artificial Intelligence, particularly recognized for contributions to the development of the PaLM language model. In 2022, Yi Tay co-authored a significant paper addressing challenging big-bench tasks, showcasing expertise in evaluating and enhancing the performance of language models. Additionally, Yi Tay has collaborated on research focused on multilingual chain-of-thought reasoning, further emphasizing a commitment to advancing understanding and capabilities in natural language processing across diverse languages. Through these contributions, Yi Tay plays a vital role in the ongoing evolution of AI and NLP technologies.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NOAM SHAZEER">
      <data key="d0">PERSON</data>
      <data key="d1">Noam Shazeer is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="VINODKUMAR PRABHAKARAN">
      <data key="d0">PERSON</data>
      <data key="d1">Vinodkumar Prabhakaran is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="EMILY REIF">
      <data key="d0">PERSON</data>
      <data key="d1">Emily Reif is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NAN DU">
      <data key="d0">PERSON</data>
      <data key="d1">Nan Du is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BEN HUTCHINSON">
      <data key="d0">PERSON</data>
      <data key="d1">Ben Hutchinson is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="REINER POPE">
      <data key="d0">PERSON</data>
      <data key="d1">Reiner Pope is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JAMES BRADBURY">
      <data key="d0">PERSON</data>
      <data key="d1">James Bradbury is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JACOB AUSTIN">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Austin is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MICHAEL ISARD">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Isard is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GUY GUR-ARI">
      <data key="d0">PERSON</data>
      <data key="d1">Guy Gur-Ari is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PENGCHENG YIN">
      <data key="d0">PERSON</data>
      <data key="d1">Pengcheng Yin is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="TOJU DUKE">
      <data key="d0">PERSON</data>
      <data key="d1">Toju Duke is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANSELM LEVSKAYA">
      <data key="d0">PERSON</data>
      <data key="d1">Anselm Levskaya is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SANJAY GHEMAWAT">
      <data key="d0">PERSON</data>
      <data key="d1">Sanjay Ghemawat is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SUNIPA DEV">
      <data key="d0">PERSON</data>
      <data key="d1">Sunipa Dev is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HENRYK MICHALIWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Henryk Michalewski is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XAVIER GARCIA">
      <data key="d0">PERSON</data>
      <data key="d1">Xavier Garcia is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KEVIN ROBINSON">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin Robinson is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="LIAM FEDUS">
      <data key="d0">PERSON</data>
      <data key="d1">Liam Fedus is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DENNY ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Denny Zhou is a prominent researcher specializing in large language models and their reasoning capabilities. He has made significant contributions to the development of advanced AI technologies, including the PaLM language model. Zhou is recognized for his work on various aspects of language models, particularly in reasoning techniques. His research includes co-authoring several influential papers, such as those addressing challenging big-bench tasks in 2022, instruction-following evaluation for large language models in 2023, multilingual chain-of-thought reasoning, reasoning via abstraction in large language models, and self-discovery in large language models. Through these efforts, Denny Zhou has established himself as a key figure in the field of artificial intelligence and natural language processing.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DAPHNE IPPOLITO">
      <data key="d0">PERSON</data>
      <data key="d1">Daphne Ippolito is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DAVID LUAN">
      <data key="d0">PERSON</data>
      <data key="d1">David Luan is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HYEONTAEK LIM">
      <data key="d0">PERSON</data>
      <data key="d1">Hyeontaek Lim is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BARRET ZOPH">
      <data key="d0">PERSON</data>
      <data key="d1">Barret Zoph is a researcher involved("entity"</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="VINEET KOSARAJU">
      <data key="d0">PERSON</data>
      <data key="d1">Vineet Kosaraju is a researcher actively engaged in the field of Artificial Intelligence, specifically focusing on the training of verifiers for solving math word problems. He has made significant contributions to this area, emphasizing the development of methodologies that enhance the accuracy and efficiency of problem-solving in mathematical contexts. Additionally, Kosaraju co-authored a paper on browser-assisted question-answering, further showcasing his involvement in advancing natural language processing techniques. His work reflects a commitment to improving educational tools and resources through innovative research in AI.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JACOB HILTON">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Hilton is a researcher who specializes in the training of verifiers for math word problems. His work involves developing methodologies to enhance the accuracy and effectiveness of these verifiers in solving such problems. Additionally, Jacob Hilton has co-authored a paper on browser-assisted question-answering, indicating his involvement in broader research areas that intersect with artificial intelligence and natural language processing. Through his contributions, he plays a significant role in advancing the understanding and capabilities of automated systems in educational contexts.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="REIICHIRO NAKANO">
      <data key="d0">PERSON</data>
      <data key="d1">Reiichiro Nakano is a researcher actively engaged in the training of verifiers for solving math word problems. He has contributed significantly to this field, focusing on enhancing the capabilities of systems designed to tackle such problems. Additionally, Nakano co-authored a paper on browser-assisted question-answering, showcasing his involvement in advancing methodologies that facilitate effective information retrieval and problem-solving. His work reflects a commitment to improving the intersection of artificial intelligence and education, particularly in the context of mathematical reasoning.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHRISTOPHER HESSE">
      <data key="d0">PERSON</data>
      <data key="d1">Christopher Hesse is a researcher actively engaged in the field of Artificial Intelligence, specifically focusing on training verifiers to effectively solve math word problems. In addition to this work, he has co-authored a paper on browser-assisted question-answering, contributing to advancements in how technology can assist users in finding answers to their queries. His research efforts highlight his commitment to enhancing problem-solving capabilities through innovative approaches in AI and Natural Language Processing.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOHN SCHULMAN">
      <data key="d0">PERSON</data>
      <data key="d1">John Schulman is a researcher recognized for his contributions to the field of artificial intelligence, particularly in the development of fast reinforcement learning methods. Additionally, he is involved in training verifiers to effectively solve math word problems, showcasing his diverse expertise in both reinforcement learning and natural language processing applications. His work reflects a commitment to advancing methodologies that enhance problem-solving capabilities within AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XIANG DENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiang Deng is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YU GU">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Gu is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BOYUAN ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Boyuan Zheng is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SHIJIE CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Shijie Chen is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SAMUEL STEVENS">
      <data key="d0">PERSON</data>
      <data key="d1">Samuel Stevens is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BOSHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Boshi Wang is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HUAN SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Huan Sun is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YU SU">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Su is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DANNY DRIES">
      <data key="d0">PERSON</data>
      <data key="d1">Danny Driess is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MEHDI S. M. SAJJADI">
      <data key="d0">PERSON</data>
      <data key="d1">Mehdi S. M. Sajjadi is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="COREY LYNCH">
      <data key="d0">PERSON</data>
      <data key="d1">Corey Lynch is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="AYZAAN WAHID">
      <data key="d0">PERSON</data>
      <data key="d1">Ayzaan Wahid is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JONATHAN TOMPHSON">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Tompson is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="QUAN VUONG">
      <data key="d0">PERSON</data>
      <data key="d1">Quan Vuong is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="TIANHE YU">
      <data key="d0">PERSON</data>
      <data key="d1">Tianhe Yu is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WENLONG HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Wenlong Huang is a researcher actively contributing to the field of embodied reasoning, particularly through the integration of planning with language models. He is also involved in the development of PaLM-E, an advanced embodied multimodal language model. His work focuses on enhancing the capabilities of language models to understand and interact with the physical world, bridging the gap between language processing and embodied cognition.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DANIEL DUCKWORTH">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Duckworth is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MARC TOUSSAINT">
      <data key="d0">PERSON</data>
      <data key="d1">Marc Toussaint is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KLAUS GREFF">
      <data key="d0">PERSON</data>
      <data key="d1">Klaus Greff is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="IGOR MORDATCH">
      <data key="d0">PERSON</data>
      <data key="d1">Igor Mordatch is a prominent researcher specializing in the field of embodied reasoning, particularly through the integration of planning with language models. His work emphasizes enhancing the factuality and reasoning capabilities of these models, contributing significantly to advancements in artificial intelligence. Additionally, he is involved in the development of PaLM-E, an innovative embodied multimodal language model, which showcases his commitment to pushing the boundaries of how language models can interact with and understand the world around them. Through these efforts, Igor Mordatch plays a crucial role in advancing the capabilities and applications of language models in various contexts.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PETE FLORENCE">
      <data key="d0">PERSON</data>
      <data key="d1">Pete Florence is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YILUN DU">
      <data key="d0">PERSON</data>
      <data key="d1">Yilun Du is a multifaceted researcher actively engaged in several innovative areas within the fields of Artificial Intelligence and Natural Language Processing. He focuses on enhancing the factuality and reasoning capabilities of language models through the implementation of multi-agent debate systems. Additionally, Yilun is involved in the development of universal policies for text-guided video generation, showcasing his commitment to advancing the intersection of language and visual content. Furthermore, he contributes to the creation of an embodied multi-modal language model, which signifies his role in pushing the boundaries of AI and machine learning technologies. Through these diverse research endeavors, Yilun Du plays a significant role in shaping the future of AI applications.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MENGJIAO YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Mengjiao Yang is a researcher specializing in the development of universal policies through text-guided video generation. Additionally, Yang has co-authored a paper on embodied multi-modal language models, which emphasizes the integration of various modalities within the field of artificial intelligence. This work highlights Yang's commitment to advancing the understanding and application of multi-modal interactions in AI systems.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BO DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Bo Dai is a prominent researcher in the field of multi-modal language models, with a specific focus on embodied agents. His work encompasses the development of universal policies through text-guided video generation, showcasing his expertise in integrating language and visual data. Additionally, Bo Dai has co-authored the AdaPlanner paper, which highlights his contributions to advancements in adaptive planning techniques. Through these efforts, he plays a significant role in enhancing the capabilities of artificial intelligence systems, particularly in the realms of language processing and interactive agent design.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HANJUN DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Hanjun Dai is a researcher specializing in the development of multi-modal language models, with a particular emphasis on their applications in artificial intelligence (AI). Additionally, Dai is engaged in innovative research aimed at learning universal policies through text-guided video generation. This dual focus on both language models and video generation highlights Dai's commitment to advancing the intersection of natural language processing and visual content creation within the AI field.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="OFIR NACHUM">
      <data key="d0">PERSON</data>
      <data key="d1">Ofir Nachum is a researcher specializing in the development of universal policies through text-guided video generation. He has made significant contributions to the field of multi-modal language models, exploring their applications within artificial intelligence. His work integrates various modalities, enhancing the understanding and generation of content that combines text and video, thereby advancing the capabilities of AI systems in processing and generating multi-faceted information.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA B. TENENBAUM">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua B. Tenenbaum is a prominent researcher in the field of Artificial Intelligence, recognized for his significant contributions to cognitive models and multi-modal learning. His work encompasses the development of universal policies through text-guided video generation, showcasing his innovative approach to integrating language and visual information in AI systems. Tenenbaum's research not only advances theoretical understanding but also has practical implications for enhancing machine learning capabilities across various applications.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DALE SCHUURMANS">
      <data key="d0">PERSON</data>
      <data key="d1">Dale Schuurmans is a prominent researcher in the field of Artificial Intelligence, with a particular focus on multi-modal language models and language model reasoning. His contributions extend to the development of advanced language models and the innovative learning of universal policies through text-guided video generation. Through his work, Schuurmans plays a significant role in advancing the capabilities and applications of language models, enhancing their effectiveness in various contexts.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PIETER ABBEEL">
      <data key="d0">PERSON</data>
      <data key="d1">Pieter Abbeel is a prominent researcher in the field of Artificial Intelligence, with a particular focus on various advanced technologies and methodologies. His work encompasses AI technologies and language models, as well as meta-learning and reinforcement learning techniques. Abbeel is actively engaged in discussions regarding the limitations of imitating proprietary language models, highlighting the challenges and ethical considerations in the field. Additionally, he is involved in innovative research aimed at learning universal policies through text-guided video generation. Known for his significant contributions to AI and robotics, Pieter Abbeel has played a crucial role in the development of multi-modal language models, further advancing the capabilities and applications of AI technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JONATHAN ST BT EVANS">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan St BT Evans is a researcher known for his work on intuition and reasoning from a dual-process perspective.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PSYCHOLOGICAL INQUIRY">
      <data key="d0">PUBLICATION</data>
      <data key="d1">Psychological Inquiry is a journal that publishes research on psychological topics, including intuition and reasoning.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MINE DOJO">
      <data key="d0">PROJECT</data>
      <data key="d1">MineDojo is a project focused on building open-ended embodied agents using internet-scale knowledge, contributing to advancements in AI.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="INSTRUCTION-FINETUNED FOUNDATION MODELS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Instruction-finetuned foundation models are AI models that have been fine-tuned to follow specific instructions, enhancing their performance in various tasks.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PAL">
      <data key="d0">PROJECT</data>
      <data key="d1">PAL (Program-aided language models) is a project aimed at improving language models through programmatic assistance, enhancing their capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MINE RL">
      <data key="d0">PROJECT</data>
      <data key="d1">MineRL is a large-scale dataset of Minecraft demonstrations, used for training AI agents in complex environments.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AGENTBENCH">
      <data key="d0">PROJECT</data>
      <data key="d1">AgentBench is a framework for evaluating large language models (LLMs) as agents, assessing their performance in various tasks.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DUAL-PROCESS PERSPECTIVE">
      <data key="d0">THEORY</data>
      <data key="d1">The dual-process perspective is a psychological theory that explains reasoning and intuition as two distinct cognitive processes.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LINXI FAN">
      <data key="d0">PERSON</data>
      <data key="d1">Linxi Fan is a prominent researcher specializing in the development of open-ended embodied agents, particularly through their work on MineDojo. In addition to this, Fan has co-authored significant research papers, including one on Voyager, another open-ended embodied agent, and a study focused on human-level reward design utilizing large language models. Through these contributions, Linxi Fan is actively advancing the field of Artificial Intelligence and Natural Language Processing, particularly in the context of creating agents that can operate in complex, dynamic environments.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="GUANZHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Guanzhi Wang is a prominent researcher actively contributing to the MineDojo project, which emphasizes the development of embodied agents equipped with internet-scale knowledge. In addition to this work, Wang has co-authored a paper on Voyager, an innovative open-ended embodied agent, showcasing his involvement in cutting-edge research within the field. Furthermore, he has collaborated on a paper that explores human-level reward design utilizing large language models, highlighting his expertise in integrating advanced AI methodologies into practical applications. Through these contributions, Guanzhi Wang plays a significant role in advancing the understanding and capabilities of embodied agents in artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUNFAN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yunfan Jiang is a researcher actively engaged in the MineDojo project, where he contributes to the development of embodied agents. Additionally, he has co-authored a paper on Voyager, which is recognized as an open-ended embodied agent. Through his work, Jiang plays a significant role in advancing the field of artificial intelligence, particularly in the context of creating agents that can interact with and learn from their environments.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AJAY MANDLEKAR">
      <data key="d0">PERSON</data>
      <data key="d1">Ajay Mandlekar is a researcher actively involved in the MineDojo project, where he focuses on the development of embodied agents. In addition to his work on MineDojo, he has co-authored a paper on Voyager, which is an open-ended embodied agent. His contributions to these projects highlight his expertise in the field of artificial intelligence, particularly in the area of creating agents that can interact with and learn from their environments.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUNCONG YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuncong Yang is a researcher involved in the MineDojo project, contributing to the development of embodied agents.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAOYI ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Haoyi Zhu is a researcher contributing to the MineDojo project, focusing on building embodied agents.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ANDREW TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Tang is a researcher involved in the MineDojo project, contributing to the development of embodied agents.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DE-AN HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">De-An Huang is a researcher actively involved in the MineDojo project, where he focuses on the development of embodied agents. In addition to his work on this project, he has co-authored a paper that explores human-level reward design utilizing large language models. His contributions reflect a commitment to advancing the field of artificial intelligence, particularly in the context of creating intelligent agents that can interact with and learn from their environments.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUKE ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Yuke Zhu is a prominent researcher actively engaged in the MineDojo project, where he contributes to the advancement of embodied agents. His expertise extends to co-authoring significant papers, including one focused on Voyager, an open-ended embodied agent, and another addressing human-level reward design utilizing large language models. Through these contributions, Yuke Zhu plays a vital role in the intersection of artificial intelligence and natural language processing, enhancing the understanding and development of intelligent systems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ANIMA ANANDKUMAR">
      <data key="d0">PERSON</data>
      <data key="d1">Anima Anandkumar is a prominent researcher actively involved in the MineDojo project, which aims to develop embodied agents. She has co-authored significant papers, including one on Voyager, an open-ended embodied agent, and another focusing on human-level reward design utilizing large language models. Through her contributions, Anandkumar is advancing the field of artificial intelligence, particularly in the development and understanding of intelligent agents and their interactions with complex environments.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HIROKI FURUTA">
      <data key="d0">PERSON</data>
      <data key="d1">Hiroki Furuta is a researcher involved in multimodal web navigation with instruction-finetuned foundation models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUTAKA MATSUNO">
      <data key="d0">PERSON</data>
      <data key="d1">Yutaka Matsuno is a researcher involved in multimodal web navigation with instruction-finetuned foundation models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHIXIANG SHANE GU">
      <data key="d0">PERSON</data>
      <data key="d1">Shixiang Shane Gu is a researcher contributing to multimodal web navigation with instruction-finetuned foundation models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="IZZEDDIN GUR">
      <data key="d0">PERSON</data>
      <data key="d1">Izzeddin Gur is a researcher involved in multimodal web navigation with instruction-finetuned foundation models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LUYU GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Luyu Gao is a researcher actively contributing to the field of program-aided language models (PAL). His work includes a focus on the development of these models, emphasizing innovative techniques such as iterative refinement. Luyu has co-authored significant papers in this area, including one on iterative refinement with self-feedback and another titled "Self-refine," which explores iterative refinement techniques in depth. Through these contributions, Luyu Gao plays a vital role in advancing the capabilities and applications of language models in artificial intelligence.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AMAN MAADAAN">
      <data key="d0">PERSON</data>
      <data key="d1">Aman Madaan is a researcher actively engaged in the advancement of program-aided language models (PAL) and has made significant contributions to the field of Natural Language Processing. He is particularly noted for his work on the Self-refine method, which facilitates iterative refinement through self-feedback mechanisms. Additionally, Aman Madaan has co-authored a paper that explores the intricacies of iterative refinement with self-feedback, further underscoring his expertise and commitment to enhancing language model development.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHUYAN ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Shuyan Zhou is a researcher actively contributing to the development of program-aided language models (PAL). Their work is centered on enhancing the capabilities and applications of these models, which play a significant role in the field of Artificial Intelligence and Natural Language Processing. Through their research, Shuyan Zhou is involved in advancing the understanding and implementation of program-aided language models, thereby influencing the broader landscape of AI technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="URI ALON">
      <data key="d0">PERSON</data>
      <data key="d1">Uri Alon is a prominent researcher in the field of Artificial Intelligence, specifically focusing on program-aided language models (PAL). He has made significant contributions to the development of these models, emphasizing their potential in enhancing language processing capabilities. Additionally, Uri Alon co-authored a paper on iterative refinement with self-feedback, further showcasing his expertise in improving language models through innovative methodologies. His work on the Self-refine paper highlights his commitment to advancing the understanding and functionality of language models, particularly through iterative refinement techniques.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PENGFEI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Pengfei Liu is a dedicated researcher actively contributing to the advancement of program-aided language models (PAL). His work encompasses a focus on enhancing the capabilities of these models, particularly in the context of benchmarking their generation and evaluation features. Liu has co-authored a significant paper that addresses the performance metrics of large language models, further solidifying his role in the field of Artificial Intelligence and Natural Language Processing. Through his research, he aims to improve the effectiveness and reliability of language models, thereby influencing the broader landscape of AI development.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,3d1f6634f93f8a4c296dc8df7e59859e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YIMING YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yiming Yang is a prominent researcher specializing in program-aided language models (PAL). His work focuses on the development and refinement of these models, contributing significantly to the field of Natural Language Processing. Yang co-authored a notable paper on iterative refinement techniques, which emphasizes the use of self-feedback to enhance model performance. Additionally, he played a key role in co-authoring a paper on program-aided language models that was presented at the International Conference on Machine Learning in 2023. Through these contributions, Yiming Yang is recognized for his advancements in iterative refinement and his commitment to improving language model capabilities.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JAMIE CALLAN">
      <data key="d0">PERSON</data>
      <data key="d1">Jamie Callan is a prominent researcher in the field of Artificial Intelligence, specifically focusing on program-aided language models (PAL). He has made significant contributions to the development of these models, enhancing their capabilities and applications. In 2023, he co-authored a paper on program-aided language models, which was presented at the prestigious International Conference on Machine Learning, further establishing his expertise and influence in the domain.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="GRAHAM NEUBIG">
      <data key="d0">PERSON</data>
      <data key="d1">Graham Neubig is a prominent researcher specializing in program-aided language models. He is actively involved in the development of PAL, which emphasizes the integration of programming techniques with language modeling. In 2023, he co-authored a paper on program-aided language models that was presented at the International Conference on Machine Learning, further contributing to the advancement of this innovative field.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DANIJAR HAFNER">
      <data key="d0">PERSON</data>
      <data key="d1">Danijar Hafner is a researcher who plays a significant role in advancing the fields of artificial intelligence (AI) and language models. His work focuses on learning latent dynamics, which involves developing methods for planning directly from pixel data. This dual emphasis on AI and the intricacies of language models highlights his contributions to enhancing the understanding and capabilities of machine learning systems. Through his research, Hafner is helping to push the boundaries of how AI can interpret and interact with complex visual information, thereby facilitating more sophisticated planning and decision-making processes.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TIMOTHY LILLICRAP">
      <data key="d0">PERSON</data>
      <data key="d1">Timothy Lillicrap is a researcher contributing to learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="IAN FISCHER">
      <data key="d0">PERSON</data>
      <data key="d1">Ian Fischer is a researcher involved in learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="RUBEN VILLEGAS">
      <data key="d0">PERSON</data>
      <data key="d1">Ruben Villegas is a researcher contributing to learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DAVID HA">
      <data key="d0">PERSON</data>
      <data key="d1">David Ha is a researcher involved in learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HONGLAK LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Honglak Lee is a researcher contributing to learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JAMES DAVIDSON">
      <data key="d0">PERSON</data>
      <data key="d1">James Davidson is a researcher involved in learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHIBO HAO">
      <data key="d0">PERSON</data>
      <data key="d1">Shibo Hao is a researcher contributing to reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YI GU">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Gu is a researcher involved in reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAODI MA">
      <data key="d0">PERSON</data>
      <data key="d1">Haodi Ma is a researcher contributing to reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JOSHUA JIAHUA HONG">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Jiahua Hong is a researcher involved in reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHEN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhen Wang is a researcher contributing to reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DAISY ZHE WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Daisy Zhe Wang is a researcher involved in reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHITING HU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiting Hu is a researcher contributing to reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JIE HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jie Huang is a researcher involved in large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XINYUN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyun Chen is a researcher actively engaged in the exploration of large language models, particularly focusing on their reasoning capabilities. Chen has co-authored significant papers that delve into critical aspects of these models, including self-discovery and reasoning via abstraction. Through this work, Xinyun Chen contributes valuable insights to the understanding and development of advanced artificial intelligence systems.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SWAROOP MISHRA">
      <data key="d0">PERSON</data>
      <data key="d1">Swaroop Mishra is a researcher specializing in large language models, particularly focusing on their reasoning capabilities. In 2023, he co-authored a paper that evaluates instruction-following in these models, contributing to the understanding of how they interpret and execute tasks based on given instructions. Additionally, he has co-authored another paper that explores reasoning through abstraction in large language models, further enhancing the discourse on their cognitive functionalities. Through these contributions, Swaroop Mishra plays a significant role in advancing research in the field of artificial intelligence and natural language processing.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="HUAIXIU STEVEN ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Huaixiu Steven Zheng is a researcher actively engaged in the exploration of large language models, particularly focusing on their reasoning capabilities. He has co-authored a paper that delves into the concept of reasoning via abstraction within these models, contributing valuable insights to the field of Artificial Intelligence and Natural Language Processing. His work emphasizes the importance of understanding how large language models can effectively reason and abstract information, thereby enhancing their applicability and performance in various tasks.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ADAMS WEI YU">
      <data key="d0">PERSON</data>
      <data key="d1">Adams Wei Yu is a researcher involved in large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XINYING SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinying Song is a researcher contributing to the study of large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="F. XIA">
      <data key="d0">PERSON</data>
      <data key="d1">F. Xia is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HARRIS CHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Harris Chan is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JACKY LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jacky Liang is a researcher contributing to embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PETER R. FLORENCE">
      <data key="d0">PERSON</data>
      <data key="d1">Peter R. Florence is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JONATHAN TOMPSON">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Tompson is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TOMAS JACKSON">
      <data key="d0">PERSON</data>
      <data key="d1">Tomas Jackson is a researcher contributing to embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LEVANTE KOCSIS">
      <data key="d0">PERSON</data>
      <data key="d1">Levente Kocsis is a researcher known for his work on bandit-based Monte Carlo planning.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CSABA SZEPESV&#193;RI">
      <data key="d0">PERSON</data>
      <data key="d1">Csaba Szepesv&#225;ri is a researcher contributing to bandit-based Monte Carlo planning.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TAKESHI KOJIMA">
      <data key="d0">PERSON</data>
      <data key="d1">Takeshi Kojima is a researcher involved in large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MACHEL REID">
      <data key="d0">PERSON</data>
      <data key="d1">Machel Reid is a researcher contributing to large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUSUKE IWASAWA">
      <data key="d0">PERSON</data>
      <data key="d1">Yusuke Iwasawa is a researcher involved in large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHIHAN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhihan Liu is a researcher contributing to the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAO HU">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Hu is a researcher involved in the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHENAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shenao Zhang is a researcher contributing to the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HONGYI GUO">
      <data key="d0">PERSON</data>
      <data key="d1">Hongyi Guo is a researcher involved in the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHUQI KE">
      <data key="d0">PERSON</data>
      <data key="d1">Shuqi Ke is a researcher contributing to the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="BOYI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Boyi Liu is a researcher involved in the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHAORAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhaoran Wang is a researcher contributing to the study of autonomous LLM agents with provable sample efficiency.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="NIKET TANDON">
      <data key="d0">PERSON</data>
      <data key="d1">Niket Tandon is a researcher recognized for his contributions to the field of Artificial Intelligence, particularly in the area of iterative refinement techniques. He co-authored a significant paper on this topic, known as the "Self-refine" paper, which explores the concept of iterative refinement with self-feedback. His work is instrumental in advancing methodologies that enhance the effectiveness of AI systems through self-improvement processes.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PRAKHAR GUPTA">
      <data key="d0">PERSON</data>
      <data key="d1">Prakhar Gupta is a researcher recognized for his contributions to the field of Artificial Intelligence, particularly in the area of self-feedback mechanisms. He co-authored a paper on iterative refinement with self-feedback, as well as the Self-refine paper, which emphasizes the importance of self-feedback in enhancing the refinement process. His work reflects a commitment to advancing understanding and methodologies within the domain of Natural Language Processing.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SKYLER HALLINAN">
      <data key="d0">PERSON</data>
      <data key="d1">Skyler Hallinan is a researcher recognized for his contributions to the field of natural language processing. He co-authored a paper on iterative refinement with self-feedback, as well as the Self-refine paper, showcasing his expertise and involvement in advancing methodologies within this domain. His work emphasizes innovative approaches to enhancing the effectiveness of natural language processing techniques.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SARAH WIEGREFFE">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Wiegreffe is a researcher recognized for her contributions to the field of Artificial Intelligence, particularly in the area of self-feedback methods. She co-authored a paper on iterative refinement with self-feedback, showcasing her expertise in enhancing these techniques. Additionally, she played a significant role in the development of the Self-refine paper, further advancing the understanding and application of self-feedback methodologies. Through her work, Wiegreffe has made notable strides in improving the effectiveness of AI systems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NOUHA DZIRI">
      <data key="d0">PERSON</data>
      <data key="d1">Nouha Dziri is a researcher recognized for her contributions to the field of natural language processing. She co-authored a paper on iterative refinement with self-feedback, demonstrating her expertise in enhancing machine learning techniques. Additionally, she played a significant role in the development of the Self-refine paper, further solidifying her impact within the research community focused on advancing natural language processing methodologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SHRIMAI PRABHUMOYE">
      <data key="d0">PERSON</data>
      <data key="d1">Shrimai Prabhumoye is a researcher recognized for her contributions to the field of Artificial Intelligence, particularly in the area of self-feedback mechanisms. She co-authored a paper on iterative refinement that emphasizes the importance of self-feedback in enhancing model performance. Additionally, she collaborated on the Self-refine paper, which further explores these self-feedback mechanisms, showcasing her commitment to advancing research in this domain. Through her work, Prabhumoye plays a significant role in the ongoing development of innovative approaches within the AI research community.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SHASHANK GUPTA">
      <data key="d0">PERSON</data>
      <data key="d1">Shashank Gupta is a researcher who co-authored the Self-refine paper, focusing on self-feedback methods.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BODHISATTVA PRASAD MAJUMDER">
      <data key="d0">PERSON</data>
      <data key="d1">Bodhisattwa Prasad Majumder is a researcher who co-authored the Self-refine paper, contributing to the field of natural language processing.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KATHERINE HERMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Katherine Hermann is a researcher who co-authored the Self-refine paper, focusing on iterative refinement techniques.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SEAN WELLECK">
      <data key="d0">PERSON</data>
      <data key="d1">Sean Welleck is a researcher who co-authored the Self-refine paper, contributing to advancements in self-feedback methods.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="AMIR YAZDANBAKHSH">
      <data key="d0">PERSON</data>
      <data key="d1">Amir Yazdanbakhsh is a researcher who co-authored the Self-refine paper, focusing on iterative refinement in language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PETER CLARK">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Clark is a prominent researcher recognized for his significant contributions to the fields of question answering and natural language processing. He is notably associated with the AI2 Reasoning Challenge, which showcases advancements in artificial intelligence. Additionally, Clark co-authored the Self-refine paper, further enhancing the understanding and development of techniques within natural language processing. His work reflects a deep commitment to advancing AI methodologies and improving the capabilities of machine understanding.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RAMESH NALLAPATI">
      <data key="d0">PERSON</data>
      <data key="d1">Ramesh Nallapati is a researcher who co-authored a paper on abstractive text summarization using sequence-to-sequence RNNs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BOWEN ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Bowen Zhou is a researcher recognized for his contributions to the field of Natural Language Processing (NLP). He co-authored a paper on abstractive text summarization, specifically concentrating on sequence-to-sequence models, which are pivotal in generating concise summaries from larger texts. Additionally, Zhou has played a significant role in enhancing chat language models, further advancing the capabilities of conversational AI. His work reflects a commitment to improving the efficiency and effectiveness of language processing technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CICERO DOS SANTOS">
      <data key="d0">PERSON</data>
      <data key="d1">Cicero dos Santos is a researcher who co-authored a paper on abstractive text summarization, contributing to advancements in RNNs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CAGLAR GULCEHRE">
      <data key="d0">PERSON</data>
      <data key="d1">Caglar Gulcehre is a researcher who co-authored a paper on abstractive text summarization, focusing on sequence-to-sequence techniques.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BING XIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Bing Xiang is a researcher who co-authored a paper on abstractive text summarization, contributing to the field of natural language processing.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="OPENAI">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">OpenAI is an artificial intelligence research organization recognized for its significant contributions to the field of AI, particularly through the development of advanced models such as ChatGPT and GPT-4. The organization is dedicated to pushing the boundaries of artificial intelligence technology, fostering innovation, and enhancing the capabilities of AI systems. Through its research and development efforts, OpenAI plays a pivotal role in advancing the understanding and application of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUJIA QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Yujia Qin is a researcher dedicated to advancing chat language models. She has co-authored the ToolLLM paper, which emphasizes the importance of enabling large language models to effectively interact with and master real-world APIs. Through her work, Yujia Qin contributes significantly to the development of more sophisticated and practical applications of artificial intelligence in natural language processing.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHIHAO LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shihao Liang is a researcher who co-authored the ToolLLM paper, contributing to advancements in API integration with language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YINING YE">
      <data key="d0">PERSON</data>
      <data key="d1">Yining Ye is a researcher who co-authored the ToolLLM paper, focusing on enhancing language models' capabilities.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KUNLUN ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Kunlun Zhu is a researcher who co-authored the ToolLLM paper, contributing to the integration of language models with APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="LAN YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Lan Yan is a researcher who co-authored the ToolLLM paper, focusing on facilitating language models' interactions with APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YAXI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yaxi Lu is a researcher actively engaged in the exploration of emergent behaviors in artificial intelligence systems. In addition to this focus, Yaxi Lu has made significant contributions to the field of natural language processing as a co-author of the ToolLLM paper, which has advanced the capabilities of language models. Through these efforts, Yaxi Lu plays a vital role in enhancing the understanding and functionality of AI technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YANKAI LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Yankai Lin is a researcher actively contributing to the field of large language model-based autonomous agents. He is notably recognized for co-authoring the ToolLLM paper, which emphasizes the enhancement of language models' interactions with APIs. Through his work, Lin plays a significant role in advancing the capabilities and applications of language models in various contexts.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XIN CONG">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Cong is a researcher who co-authored the ToolLLM paper, contributing to the integration of language models with real-world APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XIANGRU TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiangru Tang is a researcher who co-authored the ToolLLM paper, focusing on facilitating language models' capabilities.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BILL QIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Bill Qian is a researcher who co-authored the ToolLLM paper, contributing to advancements in language model integration.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SIHAN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Sihan Zhao is a researcher who co-authored the ToolLLM paper, focusing on enhancing language models' API interactions.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="RUNCHU TIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Runchu Tian is a researcher who co-authored the ToolLLM paper, contributing to the integration of language models with APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="RUOBING XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Ruobing Xie is a researcher who co-authored the ToolLLM paper, focusing on facilitating language models' capabilities.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JIE ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Jie Zhou is a researcher who co-authored the ToolLLM paper, contributing to advancements in language model integration.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARK GERSTEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Mark Gerstein is a researcher who co-authored the ToolLLM paper, focusing on enhancing language models' API interactions.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DAHAI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Dahai Li is a researcher who co-authored the ToolLLM paper, contributing to the integration of language models with real-world APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ZHUYUAN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Liu is a researcher who co-authored the ToolLLM paper, focusing on facilitating language models' capabilities.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MAOSONG SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Maosong Sun is a prominent researcher focused on the enhancement of chat language models. He has made significant contributions to the field, notably through his co-authorship of the ToolLLM paper, which addresses advancements in the integration of language models. His work is pivotal in advancing the capabilities and applications of artificial intelligence in natural language processing.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ABULHAIR SAPAROV">
      <data key="d0">PERSON</data>
      <data key="d1">Abulhair Saparov is a researcher who co-authored a paper analyzing the reasoning capabilities of language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HE HE">
      <data key="d0">PERSON</data>
      <data key="d1">He He is a researcher who co-authored a paper analyzing the reasoning capabilities of language models, focusing on chain-of-thought reasoning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="TIMO SCHICK">
      <data key="d0">PERSON</data>
      <data key="d1">Timo Schick is a researcher recognized for his contributions to the field of Artificial Intelligence, particularly in the area of Natural Language Processing. He co-authored a significant paper on Toolformer, which explores the innovative concept of language models that are capable of teaching themselves to utilize various tools. This work highlights Schick's involvement in advancing the understanding of how language models can enhance their functionality through self-directed learning and tool integration.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JANE DWIVEDI-YU">
      <data key="d0">PERSON</data>
      <data key="d1">Jane Dwivedi-Yu is a researcher recognized for her contributions to the field of Artificial Intelligence, particularly in Natural Language Processing. She co-authored a significant paper on Toolformer, which focuses on enhancing language model capabilities. Through her work, she has played a vital role in advancing the understanding and functionality of language models, showcasing her expertise and commitment to innovation in this domain.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROBERTO DESSI">
      <data key="d0">PERSON</data>
      <data key="d1">Roberto Dessi is a researcher recognized for his contributions to the field of Artificial Intelligence, particularly in the area of Natural Language Processing. He co-authored a significant paper on Toolformer, which explores the self-teaching capabilities of language models. Through his work, Dessi has contributed to advancing the understanding of how language models can enhance their performance autonomously.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROBERTA RAILEANU">
      <data key="d0">PERSON</data>
      <data key="d1">Roberta Raileanu is a researcher recognized for her contributions to the field of Artificial Intelligence, particularly in Natural Language Processing. She co-authored a significant paper on Toolformer, which focuses on advancements in the integration of language models. Her work in this area highlights her role in enhancing the capabilities and applications of AI technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MARIA LOMELI">
      <data key="d0">PERSON</data>
      <data key="d1">Maria Lomeli is a researcher recognized for her contributions to the field of Artificial Intelligence, particularly in Natural Language Processing. She co-authored a significant paper on Toolformer, which emphasizes the enhancement of language models' capabilities. Through her work, Lomeli plays a vital role in advancing the understanding and functionality of AI-driven language technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LUKE ZETTLEMOYER">
      <data key="d0">PERSON</data>
      <data key="d1">Luke Zettlemoyer is a prominent researcher known for his contributions to the field of Artificial Intelligence, particularly in Natural Language Processing. He co-authored a significant paper on Toolformer, which focuses on advancements in the integration of language models. His work in this area highlights his expertise and commitment to enhancing the capabilities of AI technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NICOLA CANCEDDA">
      <data key="d0">PERSON</data>
      <data key="d1">Nicola Cancedda is a researcher recognized for his contributions to the field of Artificial Intelligence, particularly in the area of Natural Language Processing. He co-authored a significant paper on Toolformer, which explores the self-teaching capabilities of language models. Through this work, Cancedda has contributed to advancing the understanding of how language models can enhance their own learning processes, thereby influencing future developments in AI technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="THOMAS SCIALOM">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Scialom is a researcher actively contributing to the field of language models, particularly through his co-authorship of the paper on Toolformer. His work focuses on advancing the capabilities of language models, highlighting his significant role in the ongoing development and enhancement of this technology.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YONATAN BISK">
      <data key="d0">PERSON</data>
      <data key="d1">Yonatan Bisk is a researcher who co-authored the ALFWorld paper, focusing on aligning text and embodied environments for interactive learning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ADAM TRISCHLER">
      <data key="d0">PERSON</data>
      <data key="d1">Adam Trischler is a researcher who co-authored the ALFWorld paper, contributing to advancements in interactive learning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MATTHEW HAUSKNECHT">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew Hausknecht is a researcher who co-authored the ALFWorld paper, focusing on aligning text and environments for learning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DAVID SILVER">
      <data key="d0">PERSON</data>
      <data key="d1">David Silver is a researcher known for his work on reinforcement learning and has co-authored papers on game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="AJA HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Aja Huang is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CHRIS J. MADDISON">
      <data key="d0">PERSON</data>
      <data key="d1">Chris J. Maddison is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ARTHUR GUEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Arthur Guez is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="L. SIFRE">
      <data key="d0">PERSON</data>
      <data key="d1">L. Sifre is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="GEORGE VAN DEN DRIESSCHE">
      <data key="d0">PERSON</data>
      <data key="d1">George van den Driessche is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JULIAN SCHRITTWIESER">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Schrittwieser is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="IOANNIS ANTONOGLOU">
      <data key="d0">PERSON</data>
      <data key="d1">Ioannis Antonoglou is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="VEDAVYAS PANNEERSHELVAM">
      <data key="d0">PERSON</data>
      <data key="d1">Vedavyas Panneershelvam is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARC LANCTOT">
      <data key="d0">PERSON</data>
      <data key="d1">Marc Lanctot is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SANDER DIELEMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Sander Dieleman is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DOMINIK GREWE">
      <data key="d0">PERSON</data>
      <data key="d1">Dominik Grewe is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JOHN NHAM">
      <data key="d0">PERSON</data>
      <data key="d1">John Nham is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NAL KALCHBRENNER">
      <data key="d0">PERSON</data>
      <data key="d1">Nal Kalchbrenner is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="TIMOTHY P. LILLICRAP">
      <data key="d0">PERSON</data>
      <data key="d1">Timothy P. Lillicrap is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MADELEINE LEACH">
      <data key="d0">PERSON</data>
      <data key="d1">Madeleine Leach is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KORAY KAVUKCUOGLU">
      <data key="d0">PERSON</data>
      <data key="d1">Koray Kavukcuoglu is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="THORE GRAEPEL">
      <data key="d0">PERSON</data>
      <data key="d1">Thore Graepel is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DEMIS HASABIS">
      <data key="d0">PERSON</data>
      <data key="d1">Demis Hassabis is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HAOTIAN SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Haotian Sun is a researcher who co-authored the AdaPlanner paper, focusing on adaptive planning with language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUCHEN ZHUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuchen Zhuang is a researcher recognized for significant contributions in the field of artificial intelligence, particularly in the context of large language models and adaptive planning. He co-authored a paper focused on efficient action space navigation, which addresses challenges in optimizing decision-making processes within these models. Additionally, Zhuang played a key role in the development of the AdaPlanner paper, further advancing the methodologies related to adaptive planning. His work reflects a commitment to enhancing the capabilities and efficiency of AI systems, positioning him as a notable figure in the ongoing evolution of natural language processing technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="LINGKAI KONG">
      <data key="d0">PERSON</data>
      <data key="d1">Lingkai Kong is a researcher who co-authored the AdaPlanner paper, focusing on feedback mechanisms in planning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CHAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chao Zhang is a prominent researcher in the fields of Artificial Intelligence and Natural Language Processing. He has made significant contributions to the advancement of adaptive planning through his co-authorship of the AdaPlanner paper, which emphasizes the integration of language models in planning processes. Additionally, he co-authored the ToolChain* paper, which focuses on innovations in action space navigation. Through these works, Chao Zhang has played a vital role in enhancing the understanding and capabilities of adaptive systems within the AI community.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="DIDAC SURIS">
      <data key="d0">PERSON</data>
      <data key="d1">D&#237;dac Sur&#237;s is a researcher who co-authored the ViperGPT paper, focusing on visual inference via Python execution.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SACHIT MENON">
      <data key="d0">PERSON</data>
      <data key="d1">Sachit Menon is a researcher who co-authored the ViperGPT paper, contributing to advancements in visual inference.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CARL VONDRICK">
      <data key="d0">PERSON</data>
      <data key="d1">Carl Vondrick is a researcher who co-authored the ViperGPT paper, focusing on reasoning through visual inference.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MACIEJ SWIECHOWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Maciej Swiechowski is a researcher who co-authored a review on Monte Carlo tree search and its applications.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KONRAD GODLEWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Konrad Godlewski is a researcher who co-authored a review on Monte Carlo tree search, focusing on recent modifications.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BARTOSZ SAWICKI">
      <data key="d0">PERSON</data>
      <data key="d1">Bartosz Sawicki is a researcher who co-authored a review on Monte Carlo tree search and its applications.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JACEK MA&#8217;NDZIUK">
      <data key="d0">PERSON</data>
      <data key="d1">Jacek Ma&#8217;ndziuk is a researcher who co-authored a review on Monte Carlo tree search, focusing on its applications in AI.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HUGO TOUVRON">
      <data key="d0">PERSON</data>
      <data key="d1">Hugo Touvron is a researcher actively engaged in the development of language models and associated technologies. He has contributed to the field of artificial intelligence through his co-authorship of a paper focused on visual inference and its applications within AI. His work reflects a commitment to advancing the understanding and capabilities of AI systems, particularly in the intersection of language and visual processing.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LOUIS MARTIN">
      <data key="d0">PERSON</data>
      <data key="d1">Louis Martin is a researcher actively contributing to advancements in language models and artificial intelligence technologies. He has co-authored a paper focusing on visual inference and its applications within the field of AI, showcasing his involvement in cutting-edge research that bridges language processing and visual understanding. Through his work, Martin plays a significant role in enhancing the capabilities and applications of AI systems.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KEVIN R. STONE">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin R. Stone is a researcher specializing in language models and their diverse applications within the field of Artificial Intelligence. He has contributed to the academic community by co-authoring a paper that explores visual inference and its implications in AI, highlighting his engagement with both language processing and visual data analysis. Through his work, Stone is actively involved in advancing the understanding and capabilities of AI technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PETER ALBERT">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Albert is a researcher actively engaged in the fields of Artificial Intelligence and Natural Language Processing. He has co-authored a paper focusing on visual inference and its applications within AI, showcasing his contributions to understanding how visual data can be interpreted and utilized in intelligent systems. Additionally, he is involved in the development of language models and AI methodologies, indicating a broad expertise that spans both visual and linguistic aspects of artificial intelligence. This dual focus highlights Peter Albert's significant role in advancing research and applications in AI.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AMJAD ALMAHAIRI">
      <data key="d0">PERSON</data>
      <data key="d1">Amjad Almahairi is a researcher actively contributing to the fields of language models and artificial intelligence (AI). He has co-authored a paper focusing on visual inference and its applications within AI, showcasing his involvement in advancing the understanding and capabilities of AI technologies. Through his work, Almahairi plays a significant role in the ongoing development and exploration of innovative AI methodologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YASMINE BABAIEI">
      <data key="d0">("ENTITY"</data>
      <data key="d1">YASMINE BABAIEI</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NIKOLAY BASHLYKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Nikolay Bashlykov is a researcher actively contributing to advancements in language models and has co-authored a paper focused on visual inference and its applications in artificial intelligence. His work reflects a commitment to enhancing the understanding and capabilities of AI technologies, particularly in the intersection of language processing and visual data interpretation.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SOUMYA BATRA">
      <data key="d0">PERSON</data>
      <data key="d1">Soumya Batra is a researcher specializing in language models and artificial intelligence technologies. She has contributed to the field through her co-authorship of a paper that explores visual inference and its applications within AI. Her work reflects a commitment to advancing understanding and innovation in AI, particularly in the intersection of language processing and visual data interpretation.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PRAJJWAL BHARGAVA">
      <data key="d0">PERSON</data>
      <data key="d1">Prajjwal Bhargava is a researcher actively engaged in the fields of Artificial Intelligence and Natural Language Processing. He has co-authored a paper focusing on visual inference and its applications within AI, showcasing his contributions to understanding how visual data can be interpreted and utilized in intelligent systems. Additionally, he is involved in research related to language models, exploring their various applications. This dual focus on both visual inference and language models highlights his versatility and commitment to advancing the capabilities of AI technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SHRUTI BHOSALE">
      <data key="d0">PERSON</data>
      <data key="d1">Shruti Bhosale is a researcher actively contributing to the field of language models and has co-authored a paper focused on visual inference and its applications in artificial intelligence. Her work encompasses both the development of advanced language models and the exploration of how visual inference can enhance AI capabilities, indicating a multidisciplinary approach to her research endeavors.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DANIEL M. BIKEL">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel M. Bikel is a prominent researcher engaged in the development of language models, contributing significantly to advancements in the field of Artificial Intelligence. He has co-authored a paper focusing on visual inference and its applications within AI, showcasing his expertise in integrating language processing with visual data interpretation. Through his work, Bikel plays a vital role in enhancing the understanding and capabilities of AI systems, particularly in the intersection of language and visual information.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LUKAS BLECHER">
      <data key="d0">PERSON</data>
      <data key="d1">Lukas Blecher is a researcher dedicated to the advancements in language models, contributing significantly to the field of Artificial Intelligence. He has co-authored a paper that explores visual inference and its applications within AI, showcasing his involvement in interdisciplinary research that bridges language processing and visual understanding. Through his work, Blecher is actively enhancing the understanding and capabilities of AI technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CRISTIAN CANT&#211;N FERRER">
      <data key="d0">PERSON</data>
      <data key="d1">Cristian Cant&#243;n Ferrer is a researcher actively contributing to advancements in language model technologies. He has co-authored a paper focused on visual inference and its applications within the field of artificial intelligence. His work reflects a commitment to exploring the intersections of language processing and visual understanding, highlighting his role in the ongoing development of innovative AI solutions.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MOYA CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Moya Chen is a researcher actively engaged in the development of language models, contributing to advancements in the field of Artificial Intelligence. In addition to her work on language models, she has co-authored a paper that explores visual inference and its applications within AI, highlighting her multifaceted expertise and involvement in cutting-edge research.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="GUILLEM CUCURULL">
      <data key="d0">PERSON</data>
      <data key="d1">Guillem Cucurull is a researcher specializing in language models and artificial intelligence (AI). He has contributed to the field through co-authoring a paper that explores visual inference and its applications within AI. His work reflects a commitment to advancing understanding and innovation in these interconnected areas of research.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YASMINE BABAIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yasmine Babaie is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DAVID ESIOSU">
      <data key="d0">PERSON</data>
      <data key="d1">David Esiosu is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JUDE FERNANDES">
      <data key="d0">PERSON</data>
      <data key="d1">Jude Fernandes is a researcher working on language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEREMY FU">
      <data key="d0">PERSON</data>
      <data key="d1">Jeremy Fu is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WENYIN FU">
      <data key="d0">PERSON</data>
      <data key="d1">Wenyin Fu is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BRIAN FULLER">
      <data key="d0">PERSON</data>
      <data key="d1">Brian Fuller is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CYNTHIA GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Cynthia Gao is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VEDANUJ GOSWAMI">
      <data key="d0">PERSON</data>
      <data key="d1">Vedanuj Goswami is a researcher focused on language models and AI technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NAMAN GOYAL">
      <data key="d0">PERSON</data>
      <data key="d1">Naman Goyal is a researcher actively contributing to advancements in language models, particularly in the field of Natural Language Processing (NLP). He co-authored a significant paper in 2020 that focuses on retrieval-augmented generation for knowledge-intensive NLP tasks, highlighting his involvement in innovative approaches to enhance the capabilities of language models. Through his work, Goyal plays a vital role in the ongoing development and refinement of techniques that improve the efficiency and effectiveness of NLP applications.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANTHONY S. HARTSHORN">
      <data key="d0">PERSON</data>
      <data key="d1">Anthony S. Hartshorn is a researcher working on language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SAGHAR HOSSEINI">
      <data key="d0">PERSON</data>
      <data key="d1">Saghar Hosseini is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RUI HOU">
      <data key="d0">PERSON</data>
      <data key="d1">Rui Hou is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="HAKAN INAN">
      <data key="d0">PERSON</data>
      <data key="d1">Hakan Inan is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MARCIN KARDAS">
      <data key="d0">PERSON</data>
      <data key="d1">Marcin Kardas is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VIKTOR KERKEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Viktor Kerkez is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MADIAN KHABSA">
      <data key="d0">PERSON</data>
      <data key="d1">Madian Khabsa is a researcher contributing to language model technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ISABEL M. KLOUMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Isabel M. Kloumann is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="A. V. KORENEV">
      <data key="d0">PERSON</data>
      <data key="d1">A. V. Korenev is a researcher focused on language models and AI.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUNIT SINGH KOURA">
      <data key="d0">PERSON</data>
      <data key="d1">Punit Singh Koura is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MARIE-ANNE LACHAUX">
      <data key="d0">PERSON</data>
      <data key="d1">Marie-Anne Lachaux is a researcher actively involved in the development of language models and their applications. She has made significant contributions to the Mistral 7b project, showcasing her expertise in the field of Artificial Intelligence and Natural Language Processing. Through her work, Lachaux plays a vital role in advancing the understanding and functionality of language models, thereby enhancing their practical applications in various domains.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="THIBAUT LAVRIL">
      <data key="d0">PERSON</data>
      <data key="d1">Thibaut Lavril is a researcher actively engaged in the Mistral 7b project, which focuses on the development of advanced language models. His work contributes to the broader field of Natural Language Processing, where he plays a significant role in enhancing the capabilities and applications of these models. Through his involvement in both the Mistral 7b project and the development of language models, Lavril is positioned at the forefront of research that aims to innovate and improve the understanding and generation of human language by machines.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JENYA LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Jenya Lee is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DIANA LISKOVICH">
      <data key="d0">PERSON</data>
      <data key="d1">Diana Liskovich is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YINGHAI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yinghai Lu is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUNING MAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yuning Mao is a researcher focused on language models and AI technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XAVIER MARTINET">
      <data key="d0">PERSON</data>
      <data key="d1">Xavier Martinet is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TODOR MIHAYLOV">
      <data key="d0">PERSON</data>
      <data key="d1">Todor Mihaylov is a researcher working on language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUSHKAR MISHRA">
      <data key="d0">PERSON</data>
      <data key="d1">Pushkar Mishra is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="IGOR MOLYBOG">
      <data key="d0">PERSON</data>
      <data key="d1">Igor Molybog is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YIXIN NIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yixin Nie is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANDREW POULTON">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Poulton is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEREMY REIZENSTEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Jeremy Reizenstein is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RASHI RUNGTA">
      <data key="d0">PERSON</data>
      <data key="d1">Rashi Rungta is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KALYAN SALADI">
      <data key="d0">PERSON</data>
      <data key="d1">Kalyan Saladi is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ALAN SCHELTON">
      <data key="d0">PERSON</data>
      <data key="d1">Alan Schelton is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RUAN SILVA">
      <data key="d0">PERSON</data>
      <data key="d1">Ruan Silva is a researcher contributing to language model technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ERIC MICHAEL SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Michael Smith is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="R. SUBRAMANIAN">
      <data key="d0">PERSON</data>
      <data key="d1">R. Subramanian is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XIA TAN">
      <data key="d0">PERSON</data>
      <data key="d1">Xia Tan is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BINH TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Binh Tang is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROSS TAYLOR">
      <data key="d0">PERSON</data>
      <data key="d1">Ross Taylor is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ADINA WILLIAMS">
      <data key="d0">PERSON</data>
      <data key="d1">Adina Williams is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JIAN XIANG KUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Jian Xiang Kuan is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUXIN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Puxin Xu is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ZHENGXU YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Zhengxu Yan is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ILIYAN ZAROV">
      <data key="d0">PERSON</data>
      <data key="d1">Iliyan Zarov is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANGELA FAN">
      <data key="d0">PERSON</data>
      <data key="d1">Angela Fan is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MELANIE KAMBADUR">
      <data key="d0">PERSON</data>
      <data key="d1">Melanie Kambadur is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AURELIEN RODRIGUEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Aurelien Rodriguez is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROBERT STOJNIC">
      <data key="d0">PERSON</data>
      <data key="d1">Robert Stojnic is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SERGEY EDUNOV">
      <data key="d0">PERSON</data>
      <data key="d1">Sergey Edunov is a researcher involved in the development of language models.Sergey Edunov is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LANGUAGE AGENT TREE SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The "Language Agent Tree Search" is a method that integrates reasoning, acting, and planning within language models. This innovative approach enhances decision-making processes across a variety of tasks, providing a cohesive framework for utilizing language models effectively. By unifying these critical components, the Language Agent Tree Search facilitates improved performance and adaptability in complex scenarios, making it a valuable tool in the fields of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="VOYAGER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Voyager is an open-ended embodied agent that utilizes large language models for various tasks.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHAIN OF THOUGHT PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain of thought prompting is a technique that elicits reasoning in large language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="INTELLIGENT AGENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Intelligent agents are systems that can reason, act, and plan, often discussed in the context of AI.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DAYDREAMER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Daydreamer is a model for physical robot learning that utilizes world models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DECOMPOSITION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Decomposition is a method that enhances reasoning through self-evaluation guided decoding.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WEBSHOP">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">WebShop is a multifaceted entity that serves as both a dataset and a system designed for evaluating language models and agents in the context of web search and e-commerce tasks. It is specifically utilized for assessing language models in web search scenarios, providing a robust framework for understanding how these models perform in real-world applications. Additionally, WebShop functions as an interactive web-based environment that focuses on grounded language understanding and decision-making, particularly in e-commerce settings. This dual role enhances its utility in facilitating scalable real-world web interactions with grounded language agents, making it a significant resource for researchers and developers in the fields of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="TREE OF THOUGHTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Tree of thoughts is a method for deliberate problem solving using large language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MASTERING ATARI GAMES">
      <data key="d0">RESEARCH</data>
      <data key="d1">Mastering Atari games with limited data is a research area focused on AI learning in gaming environments.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LEAST-TO-MOST PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Least-to-most prompting is a method that enables complex reasoning in large language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TOOLCHAIN*">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ToolChain* is a system designed to enhance the efficiency of action space navigation within large language models by utilizing A* search algorithms. This innovative approach aims to optimize the decision-making processes in artificial intelligence applications, particularly in the realm of natural language processing.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="HOWARD CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Howard Chen is a researcher contributing to the development of language models and AI systems.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JOHN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">John Yang is a researcher focused on advancements in language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KARTHIK R NARASIMHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Karthik R Narasimhan is a researcher involved in the development of language models and AI technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KEN GOLDBERG">
      <data key="d0">PERSON</data>
      <data key="d1">Ken Goldberg is a researcher involved in the development of AI systems and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XUEZHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xuezhi Wang is a prominent researcher in the field of Artificial Intelligence, particularly known for his contributions to advancements in language models and AI technologies. He has co-authored a significant paper on multilingual chain-of-thought reasoning, showcasing his expertise in enhancing reasoning capabilities within language models. Through his work, Xuezhi Wang has played a vital role in pushing the boundaries of how AI systems understand and process language, thereby contributing to the broader development of intelligent technologies.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JASON WEI">
      <data key="d0">PERSON</data>
      <data key="d1">Jason Wei is a prominent researcher specializing in language models and their diverse applications. He is particularly involved in developing prompting techniques for large language models, which enhance their performance and usability. In 2022, he co-authored a significant paper addressing challenging big-bench tasks, contributing to the advancement of benchmarks in the field. Additionally, Jason Wei co-authored a paper focused on multilingual chain-of-thought reasoning, further demonstrating his commitment to exploring the complexities of language processing across different languages. His work is instrumental in pushing the boundaries of research in artificial intelligence and natural language processing.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QUOC LE">
      <data key="d0">PERSON</data>
      <data key="d1">Quoc Le is a prominent researcher recognized for his significant contributions to advancements in language models and artificial intelligence technologies. He has played a crucial role in the development of prompting techniques specifically designed for large language models, enhancing their functionality and effectiveness in various applications. Through his work, Quoc Le has helped to push the boundaries of what is possible in the field of AI, particularly in the realm of natural language processing.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ED CHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ed Chi is a prominent researcher specializing in artificial intelligence systems and language models. His work particularly emphasizes the study of reasoning within large language models, with a specific focus on methodologies such as least-to-most prompting. Through his research, Ed Chi contributes to the understanding and development of advanced AI technologies, enhancing the capabilities of language models in reasoning tasks.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUXI XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yuxi Xie is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KENJI KAWAGUCHI">
      <data key="d0">PERSON</data>
      <data key="d1">Kenji Kawaguchi is a researcher focused on language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YIRAN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiran Zhao is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XU ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Xu Zhao is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MIN-YEN KAN">
      <data key="d0">PERSON</data>
      <data key="d1">Min-Yen Kan is a researcher focused on language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JUNXIAN HE">
      <data key="d0">PERSON</data>
      <data key="d1">Junxian He is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="QIZHE XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Qizhe Xie is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PHILIPP WU">
      <data key="d0">PERSON</data>
      <data key="d1">Philipp Wu is a researcher focused on AI technologies and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MONTE CARLO TREE SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Monte Carlo Tree Search (MCTS) is a heuristic search algorithm that plays a crucial role in decision-making tasks, particularly within the realm of artificial intelligence (AI) applications. It is widely utilized in reinforcement learning and various decision-making processes, enabling systems to evaluate potential outcomes and make informed choices. MCTS combines the principles of random sampling with tree search, allowing it to effectively navigate complex decision spaces and optimize performance in AI-driven environments.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="A* SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A* Search is a widely recognized algorithm utilized for pathfinding and graph traversal, primarily in the field of Artificial Intelligence (AI). It is particularly effective in navigating action spaces within language models, showcasing its versatility and application in various AI contexts. This algorithm is essential for efficiently determining optimal paths, making it a critical tool in both theoretical and practical implementations of AI systems.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MONTY CARLO TREE SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Monte Carlo Tree Search is a heuristic search algorithm for decision processes.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHAIN OF THOUGHT REASONING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain of Thought Reasoning is a method that enhances reasoning capabilities in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PROBLEM SOLVING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Problem Solving is a cognitive process aimed at finding solutions to complex issues, often discussed in AI contexts.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SCALABLE WEB INTERACTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Scalable Web Interaction refers to systems designed for efficient interaction with web services using AI.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="EXPLAINABLE AI">
      <data key="d0">CONCEPT</data>
      <data key="d1">Explainable AI refers to methods and techniques that make the decision-making processes of AI systems understandable to humans.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="EMNLP">
      <data key="d0">CONFERENCE</data>
      <data key="d1">EMNLP is a conference focused on natural language processing and computational linguistics.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ICLR">
      <data key="d0">CONFERENCE</data>
      <data key="d1">ICLR is a conference that focuses on learning representations and deep learning.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NEURIPS">
      <data key="d0">CONFERENCE</data>
      <data key="d1">NeurIPS is a conference that covers advancements in neural information processing systems and machine learning.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CORL">
      <data key="d0">CONFERENCE</data>
      <data key="d1">CoRL is a conference focused on robot learning and reinforcement learning.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AI RESEARCH">
      <data key="d0">FIELD</data>
      <data key="d1">AI Research refers to a broad field that includes various studies and advancements in artificial intelligence technologies. It involves both the exploration and development of methodologies aimed at enhancing the capabilities and applications of artificial intelligence. This field is characterized by its focus on innovative techniques and the continuous evolution of AI systems, contributing significantly to the overall progress in technology and its integration into various sectors.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROBOTICS">
      <data key="d0">FIELD</data>
      <data key="d1">Robotics is a multidisciplinary field that encompasses engineering and artificial intelligence, dedicated to the design, construction, operation, and application of robots. This domain not only focuses on the physical aspects of robot creation but also integrates advanced technologies such as AI and machine learning techniques to enhance robot functionality and autonomy. As a branch of technology, robotics plays a crucial role in various industries, driving innovation and efficiency through the deployment of intelligent machines.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AGENT-BASED SYSTEMS">
      <data key="d0">FIELD</data>
      <data key="d1">Agent-based systems are computational systems that use autonomous agents to perform tasks and solve problems.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AI ETHICS">
      <data key="d0">FIELD</data>
      <data key="d1">AI Ethics is a field that critically examines the moral implications and societal impacts of artificial intelligence technologies. This area of study focuses on understanding how AI systems affect individuals and communities, addressing ethical concerns related to their development and deployment. By exploring these implications, AI Ethics aims to guide the responsible use of AI, ensuring that technological advancements align with societal values and ethical standards.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AI SYSTEMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Systems are defined as computational systems that leverage artificial intelligence technologies to perform tasks and make decisions. These integrated systems are designed to solve problems by utilizing various AI methodologies, enabling them to operate autonomously or assist users in decision-making processes.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI TECHNOLOGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Technologies refer to a diverse array of tools and methods utilized in the development and application of artificial intelligence. This includes a broad spectrum of techniques aimed at creating intelligent systems, such as machine learning, natural language processing, and robotics. These technologies play a crucial role in advancing the capabilities of AI, enabling more sophisticated and efficient solutions across various domains.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI APPLICATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Applications encompass the practical uses of artificial intelligence technologies across a diverse range of fields and industries. These applications are particularly prominent in sectors such as healthcare, finance, and education, where they enhance efficiency, improve decision-making, and drive innovation. By leveraging AI, organizations can optimize processes, analyze vast amounts of data, and deliver tailored solutions to meet specific needs within these critical areas.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI MODELS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Models are sophisticated mathematical representations and algorithms designed to simulate and predict behaviors within artificial intelligence systems. They emulate human-like intelligence to execute specific tasks, making them integral to various applications discussed in numerous academic papers. These models serve as foundational elements in the development of AI technologies, enabling systems to learn from data and make informed decisions.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI TOOLS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Tools are software and applications specifically designed to assist in the development and implementation of artificial intelligence technologies. These tools utilize AI to perform various tasks, significantly enhancing productivity and efficiency across multiple fields. By integrating advanced algorithms and machine learning capabilities, AI Tools facilitate a wide range of applications, making them essential resources for professionals seeking to leverage AI in their work.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI FRAMEWORKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Frameworks are structured environments and methodologies designed to facilitate the development and deployment of artificial intelligence applications and systems. They provide a systematic approach that aids developers in creating, implementing, and managing AI technologies effectively. By offering a cohesive structure, AI Frameworks enhance the efficiency and effectiveness of AI development processes, ensuring that applications are built on solid foundations and can be deployed seamlessly.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI PLATFORMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Platforms are comprehensive software environments that offer a range of tools and services designed for the development and deployment of AI applications. These platforms facilitate the entire lifecycle of AI projects, enabling users to efficiently build, test, and implement AI solutions. By providing an integrated set of resources, AI Platforms support developers and organizations in harnessing the power of artificial intelligence to address various challenges and innovate within their respective fields.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI SOLUTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Solutions encompass specific implementations and applications of artificial intelligence technologies aimed at addressing particular problems or needs. These solutions are designed to leverage AI capabilities to create systems that effectively tackle distinct challenges, thereby enhancing efficiency and problem-solving in various contexts.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI STRATEGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Strategies refer to the comprehensive plans and approaches designed for the effective utilization and implementation of artificial intelligence technologies across diverse contexts. These strategies encompass a range of methodologies aimed at optimizing the application of AI, ensuring that organizations can leverage its capabilities to achieve their goals efficiently.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI INNOVATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Innovations encompass new and creative advancements as well as improved methods, technologies, and applications within the field of artificial intelligence. This term signifies the ongoing evolution and enhancement of AI, highlighting the importance of innovation in developing cutting-edge solutions that address various challenges and opportunities in the industry.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI TRENDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Trends encompass the emerging patterns and directions in the development and application of artificial intelligence. They represent the current trajectories and advancements within the field, significantly influencing both research and practical applications. This concept highlights the dynamic nature of AI, reflecting how ongoing innovations and shifts in technology shape the landscape of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI CHALLENGES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Challenges encompass the various obstacles and issues encountered in the development and implementation of artificial intelligence technologies. These challenges are critical to address as they can significantly impact the effectiveness and efficiency of AI systems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI OPPORTUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Opportunities are potential areas for growth and advancement in the field of artificial intelligence.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI RESEARCH DIRECTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Research Directions refer to the future paths and areas of focus in artificial intelligence research.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI COLLABORATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Collaborations are partnerships and joint efforts in the field of artificial intelligence research and development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Communities are groups of individuals and organizations focused on advancing artificial intelligence technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI EDUCATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Education encompasses the teaching and learning of artificial intelligence concepts and technologies. It is often integrated into academic curricula, providing students with a comprehensive understanding of AI principles and applications. This educational approach aims to equip learners with the necessary skills to navigate and contribute to the rapidly evolving field of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI TRAINING">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Training involves the process of teaching AI models to perform specific tasks using data.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI EVALUATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Evaluation refers to the assessment of AI models and systems to determine their effectiveness and performance.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI DEPLOYMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Deployment is the process of implementing AI models and systems in real-world applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI MAINTENANCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Maintenance involves the ongoing support and updates of AI systems to ensure their functionality and relevance.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI REGULATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Regulations encompass the legal and ethical guidelines that govern the use of artificial intelligence technologies. These regulations are designed to ensure the ethical and responsible application of AI, establishing a framework of laws and guidelines that promote accountability and transparency in the deployment of AI systems. By addressing potential risks and ethical considerations, AI Regulations aim to foster trust and safety in the utilization of these advanced technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI STANDARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Standards refer to the established criteria and benchmarks that guide the development, application, and evaluation of artificial intelligence technologies. These standards are crucial for ensuring consistency, reliability, and safety in AI systems, facilitating their integration into various sectors while promoting best practices in the field.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI POLICIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Policies are guidelines and rules governing the use and development of artificial intelligence technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI BEST PRACTICES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Best Practices are recommended methods and techniques for effectively utilizing artificial intelligence.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI METHODOLOGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Methodologies are systematic approaches to conducting research and development in artificial intelligence.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="OLIVIER BOUSQUET">
      <data key="d0">PERSON</data>
      <data key="d1">Olivier Bousquet is a researcher known for his work on prompting methods in large language models, particularly in the context of complex reasoning.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="XIANG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xiang Chen is a researcher who contributed to the development of the ToolChain* method for action space navigation in large language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="TONG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Tong Yu is a researcher involved in the ToolChain* project, focusing on navigation in large language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SAAYAN MITRA">
      <data key="d0">PERSON</data>
      <data key="d1">Saayan Mitra is a researcher who co-authored the ToolChain* paper, contributing to action space navigation in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="VICTOR BURSZTYN">
      <data key="d0">PERSON</data>
      <data key="d1">Victor Bursztyn is a researcher associated with the ToolChain* project, focusing on efficient navigation in large language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="RYAN A. ROSSI">
      <data key="d0">PERSON</data>
      <data key="d1">Ryan A. Rossi is a researcher who contributed to the ToolChain* project, which enhances action space navigation in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SOMDEB SARKHEL">
      <data key="d0">PERSON</data>
      <data key="d1">Somdeb Sarkhel is a researcher involved in the ToolChain* project, focusing on large language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="TOOLBENCH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ToolBench is a framework for evaluating language models with tool use capabilities.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ALFWORLD">
      <data key="d0">DATASET</data>
      <data key="d1">Alfworld is a dataset used for evaluating text-based manipulation tasks in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="WANG ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Wang et al. (2022) is a reference to a study discussing the CoT-SC method in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="EXPERIMENTAL RESULTS">
      <data key="d0">DATA</data>
      <data key="d1">Experimental results refer to the data and findings obtained from testing the LATS algorithm across various tasks and environments.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ENVIRONMENT DETAILS">
      <data key="d0">DATA</data>
      <data key="d1">Environment details provide information about the settings and conditions under which experiments with the LATS algorithm were conducted.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="PROMPTS">
      <data key="d0">DATA</data>
      <data key="d1">The entity "PROMPTS" refers to specific instructions or queries utilized to elicit responses from language models, particularly during the training process. These prompts play a crucial role in guiding the language model's responses across various environments, especially within the context of the LATS algorithm. By providing structured queries or instructions, prompts help optimize the interaction between users and language models, ensuring that the generated responses are relevant and contextually appropriate.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="TRIALS">
      <data key="d0">DATA</data>
      <data key="d1">Trials refer to the repeated tests conducted to evaluate the performance and efficiency of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="RESOURCE CONSTRAINTS">
      <data key="d0">DATA</data>
      <data key="d1">Resource constraints refer to the limitations in computational resources that may affect the implementation of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="REAL-WORLD ENVIRONMENTS">
      <data key="d0">DATA</data>
      <data key="d1">Real-world environments are practical applications where the LATS algorithm can be utilized, such as programming and web search tasks.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="INTERACTIVE ENVIRONMENTS">
      <data key="d0">DATA</data>
      <data key="d1">Interactive environments are settings where the LATS algorithm can engage with users or systems to perform tasks.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ACTION SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The term "ACTION SPACE" encompasses two distinct contexts: the LATS algorithm and the Web Shop platform. In the context of the LATS algorithm, the action space refers to the defined set of possible actions that can be executed, which includes searching for entities and utilizing the Wikipedia API for string lookups. Conversely, within the Web Shop environment, the action space pertains to the range of actions available to users, such as searching for products, selecting items, and viewing detailed information about those items. Together, these descriptions illustrate the concept of action space as a framework for understanding user interactions and algorithmic capabilities across different platforms.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="WIKIPEDIA">
      <data key="d0">RESOURCE</data>
      <data key="d1">Wikipedia is a free online encyclopedia that provides a wealth of information, which is utilized by the LATS algorithm for interactive information retrieval.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="SAMPLING SIZE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Sampling size refers to the number of trajectories or samples taken during the evaluation of an algorithm, impacting the performance and results observed.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="EXPLORATION WEIGHT">
      <data key="d0">PARAMETER</data>
      <data key="d1">Exploration weight is a parameter in the selection formula that influences the effectiveness of the search process in algorithms like LATS, affecting performance outcomes.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="DEPTH">
      <data key="d0">PARAMETER</data>
      <data key="d1">Depth is a parameter that limits the maximum number of steps an algorithm can take in a decision-making process, impacting the performance and efficiency of the search.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="PERFORMANCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Performance refers to the effectiveness of an algorithm in completing tasks, often measured through metrics like accuracy or efficiency in answering questions.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="INTERACTIVE INFORMATION RETRIEVAL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Interactive information retrieval is a method that allows users to search for entities and retrieve relevant information from a database or knowledge base, such as Wikipedia.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="ENTITY WIKI PAGE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">An entity wiki page is a dedicated page on Wikipedia that contains information about a specific entity, including its attributes and related topics.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="SEARCH">
      <data key="d0">FUNCTION</data>
      <data key="d1">Search is a function that retrieves the first five sentences from an entity's wiki page or suggests similar entities if the page does not exist.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="LOOKUP">
      <data key="d0">FUNCTION</data>
      <data key="d1">Lookup is a function that returns the next sentence in a page based on a given string.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="FINISH">
      <data key="d0">FUNCTION</data>
      <data key="d1">Finish is a function that completes the current task with a specified answer.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="HUMANEVAL DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The HumanEval dataset is a collection of programming problems used to evaluate the functional correctness of models that synthesize programs from natural language descriptions.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d0">DATASET</data>
      <data key="d1">The Mostly Basic Programming Problems (MBPP) benchmark is a dataset of short Python functions designed to assess program synthesis techniques.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="AGENTS">
      <data key="d0">AGENT</data>
      <data key="d1">The term "AGENTS" refers to automated systems designed to perform a variety of tasks across different contexts. In educational settings, agents generate questions or modify text based on predefined criteria, enhancing the learning experience. In the realm of e-commerce, specifically within the WebShop environment, agents facilitate interactions by searching for products and executing purchases, streamlining the shopping process for users. Additionally, these agents are powered by large language models (LLMs) and play specific roles within workflows, contributing to the generation and refinement of instructions. Overall, agents serve as versatile tools that enhance both educational and commercial activities through automation and intelligent interaction.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="PRODUCTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Products are items available for purchase in the WebShop environment, containing various attributes and options for customization.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="E-COMMERCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">E-commerce refers to the buying and selling of goods and services over the internet, which is simulated in the WebShop environment.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="FUNCTION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="EXACT MATCH (EM)">
      <data key="d0">METRIC</data>
      <data key="d1">Exact Match (EM) is a metric used to evaluate the performance of models by checking if the generated answer exactly matches the ground truth.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="PASS@K">
      <data key="d0">METRIC</data>
      <data key="d1">Pass@k is a metric that evaluates the success rate of a model by determining if any of the k generated samples pass all tests for a given problem.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d0">PARAMETER</data>
      <data key="d1">The "VALUE FUNCTION HYPERPARAMETERS" refer to specific settings utilized to enhance the performance of language models and decision-making algorithms across various applications. These hyperparameters, such as &#955; values for scoring, play a crucial role in optimizing the effectiveness of these models in tasks related to natural language processing and other domains. In the context of a Web Shop, these hyperparameters are particularly important for refining the algorithms that drive decision-making processes, ensuring that the system operates efficiently and effectively. Overall, value function hyperparameters are essential for improving the performance and accuracy of both language models and decision-making frameworks.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="SUCCESS RATE (SR)">
      <data key="d0">METRIC</data>
      <data key="d1">Success Rate (SR) is a metric that measures the portion of instructions successfully executed by the system, defined as r=1.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HOTPOTQA PROMPTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">HotPotQA prompts are structured instructions designed to guide question-answering tasks using reasoning and observation steps.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Thought refers to the reasoning process that occurs during a question-answering task, guiding the actions taken to find an answer.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ACTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Action represents the steps taken in response to a Thought during a question-answering task, such as searching for information or finishing an answer.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITEM-DETAIL">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Item-Detail provides comprehensive information about a specific item, including its description, attributes, and purchasing options.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EPISODE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Episode refers to a distinct instance or session of interaction within the Web Shop, where users can perform actions and receive rewards.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ENVIRONMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Environments refer to the different settings or scenarios in which experiments are conducted to evaluate the performance of the Web Shop system.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITEM">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PLAINS">
      <data key="d0">GEOGRAPHICAL FEATURE</data>
      <data key="d1">Plains are flat or gently rolling areas of land that rise in elevation, typically characterized by their expansive and open landscapes.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="ELEVATION">
      <data key="d0">MEASUREMENT</data>
      <data key="d1">Elevation refers to the height of a geographical feature above a reference point, usually sea level, measured in feet or meters.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="ARTHUR&#8217;S MAGAZINE">
      <data key="d0">PUBLICATION</data>
      <data key="d1">Arthur&#8217;s Magazine was an American literary periodical published in Philadelphia in the 19th century, known for featuring works by notable authors.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="FIRST FOR WOMEN">
      <data key="d0">PUBLICATION</data>
      <data key="d1">First for Women is a magazine that focuses on topics relevant to women, including health, lifestyle, and personal stories.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="EDGAR A. POE">
      <data key="d0">PERSON</data>
      <data key="d1">Edgar A. Poe was a notable author whose work was featured in Arthur&#8217;s Magazine, known for his contributions to American literature.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="J.H. INGRAHAM">
      <data key="d0">PERSON</data>
      <data key="d1">J.H. Ingraham was an author whose works were published in Arthur&#8217;s Magazine, contributing to its literary significance.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="SARAH JOSEPHA HALE">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Josepha Hale was a prominent writer featured in Arthur&#8217;s Magazine, recognized for her contributions to literature and women&#8217;s rights.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="THOMAS G. SPEAR">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas G. Spear was an author whose works appeared in Arthur&#8217;s Magazine, adding to its diverse literary offerings.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="TIMOTHY SHAY ARTHUR">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="ADD FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">The add function is a Python function designed to take two integers as input and return their total value. However, the initial implementation incorrectly subtracts the second integer from the first instead of adding them together.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="UNIT TEST RESULTS">
      <data key="d0">TESTING</data>
      <data key="d1">Unit test results provide feedback on the performance of the add function, indicating which tests passed and which failed, thus guiding improvements in the implementation.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="REFLECTION ON IMPLEMENTATION">
      <data key="d0">ANALYSIS</data>
      <data key="d1">The reflection on the implementation discusses the errors in the add function, specifically the incorrect use of the subtraction operator instead of the addition operator, and suggests a fix.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="IMPROVED IMPLEMENTATION">
      <data key="d0">FUNCTION</data>
      <data key="d1">The improved implementation of the add function corrects the previous error by changing the operator from subtraction to addition, ensuring the function returns the correct output for the given input.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BRIGHT CITRUS DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">Bright Citrus Deodorant by Earth Mama is a natural deodorant specifically formulated for sensitive skin, making it suitable for use during pregnancy and breastfeeding. This product features organic calendula as a key ingredient and is packaged in a convenient 3-ounce bottle. Additionally, it is priced under $50.00, emphasizing its accessibility for consumers seeking gentle and effective personal care options.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="TEST CASE">
      <data key="d0">TESTING</data>
      <data key="d1">A test case is a set of conditions or variables under which a tester will determine whether a function or system is working correctly.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="SEARCH ACTION">
      <data key="d0">ACTION</data>
      <data key="d1">The entity "SEARCH ACTION" encompasses the user's initiative to locate specific products online, reflecting their preferences and constraints. It is characterized as a command executed within an online shopping context, specifically in a Web Shop, to identify items based on user-defined criteria, which may include factors such as product type and price. This process highlights the importance of user input in shaping the search experience and optimizing product discovery in e-commerce environments.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7,6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="CLICK ACTION">
      <data key="d0">ACTION</data>
      <data key="d1">The click action is a command executed in the Web Shop to select a specific product from the search results for more details.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="UNIT TEST">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="VALUE FUNCTION PROMPT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Value Function Prompt is a method used to analyze purchasing trajectories and evaluate their correctness based on specified criteria.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS">
      <data key="d0">PRODUCT</data>
      <data key="d1">The "Dairy Free and Apple Variety Pack of Chips" is a specialized snack product designed to cater to individuals with dietary restrictions, particularly those avoiding dairy. This variety pack not only emphasizes its dairy-free composition but also features an appealing apple flavor, making it a sought-after choice for consumers who prioritize both health and taste. The combination of dietary compliance and a unique flavor profile positions this snack as an attractive option for those looking for enjoyable yet suitable snack alternatives.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE FOODS">
      <data key="d0">BRAND</data>
      <data key="d1">Enjoy Life Foods is a brand dedicated to providing a diverse range of allergen-free snacks, specifically designed to meet various dietary needs. Their product offerings include soft baked ovals, chewy bars, and a variety of chips, ensuring that individuals with food allergies or sensitivities can enjoy tasty and safe snack options. By focusing on allergen-free ingredients, Enjoy Life Foods aims to cater to consumers seeking healthier alternatives without compromising on flavor or enjoyment.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="CORRECTNESS SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">The Correctness Score is a numerical evaluation of how well a purchasing action meets the specified requirements, ranging from 1 to 10.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="CALMING LAVENDER DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">Calming Lavender Deodorant by Earth Mama is a natural deodorant designed for sensitive skin, pregnancy, and breastfeeding, containing organic ingredients and available in a 3-ounce size.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="TRAVEL SET (4-PACK)">
      <data key="d0">PRODUCT</data>
      <data key="d1">The Travel Set (4-Pack) is a collection of various deodorant scents offered by Earth Mama, designed for convenience and portability.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="3 OUNCE (PACK OF 1)">
      <data key="d0">PRODUCT</data>
      <data key="d1">The 3 Ounce (Pack of 1) refers to a single unit of deodorant, suitable for individual use, particularly for sensitive skin.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="3-OUNCE (2-PACK)">
      <data key="d0">PRODUCT</data>
      <data key="d1">The 3-Ounce (2-Pack) is a collection of two units of deodorant, designed for users who prefer to have a backup or share with others.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="NATURAL AND SAFE FOR SENSITIVE SKIN">
      <data key="d0">FEATURE</data>
      <data key="d1">Natural and safe for sensitive skin indicates that the product is formulated without harsh chemicals, making it suitable for individuals with skin sensitivities.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ORGANIC CALENDULA">
      <data key="d0">INGREDIENT</data>
      <data key="d1">Organic Calendula is a natural ingredient used in the formulation of the deodorant, known for its soothing properties.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="GINGER FRESH DEODORANT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="SOFT BAKED OVALS">
      <data key="d0">PRODUCT</data>
      <data key="d1">Soft Baked Ovals are a type of breakfast bar produced by Enjoy Life Foods, designed to be nut-free, soy-free, dairy-free, and gluten-free.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SOFT BAKED CHEWY BARS">
      <data key="d0">PRODUCT</data>
      <data key="d1">Soft Baked Chewy Bars are another product from Enjoy Life Foods, available in a variety pack and meeting dietary restrictions.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="LENTIL CHIPS VARIETY PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">Lentil Chips Variety Pack is a snack option from Enjoy Life Foods that is dairy-free, soy-free, nut-free, and gluten-free.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON">
      <data key="d0">PRODUCT</data>
      <data key="d1">A specific type of vegetarian bacon that is gluten-free and sought after for its flavor and dietary compliance.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="LOUISVILLE VEGAN JERKY">
      <data key="d0">BRAND</data>
      <data key="d1">Louisville Vegan Jerky is a brand specializing in a diverse range of vegan jerky products, crafted from non-GMO soy protein. The brand offers a variety pack that includes multiple flavors, catering to different taste preferences. Additionally, all products are gluten-free, making them suitable for individuals with gluten sensitivities. This commitment to plant-based snacking positions Louisville Vegan Jerky as a versatile and health-conscious option for consumers seeking flavorful, meat-free alternatives.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="SMOKED BACON SEA SALT 3-PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A product that includes three flavors of smoked bacon sea salt, marketed as gluten-free and non-GMO.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SPICY HOT PEPPER SEA SALT 3-PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A product that includes three flavors of spicy hot pepper sea salt, also marketed as gluten-free and non-GMO.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="0.8 OUNCE (PACK OF 24)">
      <data key="d0">PRODUCT</data>
      <data key="d1">A specific packaging size for snacks, indicating that the product contains 24 bags, each weighing 0.8 ounces.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="PRICE">
      <data key="d0">VALUE</data>
      <data key="d1">The cost associated with a product, which is a critical factor in consumer purchasing decisions, often compared against budget constraints.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="BUDGET">
      <data key="d0">VALUE</data>
      <data key="d1">The maximum amount of money a consumer is willing to spend on a product, influencing their purchasing choices.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="VARIETY PACK">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="NON-GMO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Non-GMO indicates that the product does not contain genetically modified organisms, ensuring it meets certain dietary preferences.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="SPICY HOT PEPPER SEA SALT">
      <data key="d0">PRODUCT</data>
      <data key="d1">Spicy Hot Pepper Sea Salt is a seasoning product that includes blends of various peppers and sea salt, marketed as all-natural and gluten-free.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="GLUTEN-FREE">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Gluten-free indicates that the product does not contain gluten, catering to individuals with gluten sensitivities or celiac disease.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="PEPPER FLAVORS">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Pepper flavors refer to the various types of peppers used in products, such as Ghost Pepper, Jalapeno, and Habanero, contributing to the taste profile.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="JALAPENO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Jalapeno is a medium-heat chili pepper commonly used in cooking, known for its distinct flavor and versatility in various dishes.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="HABANERO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Habanero is a very hot chili pepper that adds significant heat and flavor to food products.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="BLACK PEPPER">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Black Pepper is a common spice made from the dried fruit of the pepper plant, used to enhance the flavor of various dishes.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="BUFFALO DILL">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Buffalo Dill is a flavor variant of Louisville Vegan Jerky, combining the taste of buffalo sauce with dill seasoning.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="PEPPERONI">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Pepperoni is a type of spicy Italian-American sausage, often used as a flavor in various food products.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="MAPLE BACON">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Maple Bacon is a flavor variant that combines the sweetness of maple with the savory taste of bacon, used in Louisville Vegan Jerky.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="CAROLINA BBQ">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Carolina BBQ is a flavor variant that reflects the barbecue style from the Carolinas, known for its tangy and smoky taste.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="4 OUNCE PACK">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A 4 ounce pack refers to the size of the product packaging, indicating the quantity of the product contained within.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="GHOST PEPPER">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="SHENGRAN HU">
      <data key="d0">PERSON</data>
      <data key="d1">Shengran Hu is a researcher affiliated with the University of British Columbia and the Vector Institute, where he contributes to the field of automated design of agentic systems. In 2024, he co-authored a paper on Thought Cloning, which emphasizes the concept of learning to think while acting by imitating human thinking. Additionally, he has co-authored a paper focused on intelligent exploration utilizing foundation models, further showcasing his involvement in advancing research in artificial intelligence and natural language processing.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CONG LU">
      <data key="d0">PERSON</data>
      <data key="d1">Cong Lu is a researcher affiliated with the University of British Columbia and the Vector Institute, where he contributes significantly to the field of automated design of agentic systems. His expertise is further demonstrated through his co-authorship of a paper focused on intelligent exploration utilizing foundation models, as well as another paper on variational Bayes-adaptive deep reinforcement learning. Through these contributions, Cong Lu plays a vital role in advancing research in artificial intelligence and natural language processing.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JEFF CLUNE">
      <data key="d0">PERSON</data>
      <data key="d1">Jeff Clune is a prominent researcher affiliated with the University of British Columbia and the Vector Institute, where he holds a Canada CIFAR AI Chair. His work primarily focuses on agentic systems and the development of AI-generating algorithms, particularly addressing the challenges of creating safe, open-ended artificial intelligence. Clune is recognized for his significant contributions to evolutionary computation and reinforcement learning, and he has been involved in multiple studies related to AI and intelligent exploration.

In 2024, he co-authored a paper on Thought Cloning, which explores the concept of learning to think while acting by imitating human thought processes. Additionally, he has contributed to research on designing neural networks through neuroevolution and has co-authored a paper discussing open-endedness in models of human notions of interestingness. Through his diverse research endeavors, Jeff Clune continues to advance the understanding and development of AI technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d0">RESEARCH AREA</data>
      <data key="d1">The "AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" is an emerging research area dedicated to the automatic creation and design of advanced agentic systems. This field emphasizes the development of innovative building blocks and their combinations, aiming to enhance the capabilities of these systems. ADAS specifically focuses on leveraging Foundation Models (FMs) to facilitate task-solving through effective planning and iterative processing. Overall, ADAS represents a significant advancement in the automated invention and design of powerful agentic systems, positioning itself as a pivotal area of study within the broader landscape of artificial intelligence and system design.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="FOUNDATION MODELS (FMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundation Models (FMs) are advanced AI systems characterized by their large-scale architecture, exemplified by models such as GPT and Claude. These models function as powerful general-purpose agents capable of executing a wide range of tasks, including programming and reinforcement learning in robotics. Additionally, Foundation Models serve as integral modules within the control flow of agentic systems, empowering them to undertake complex tasks that require flexible reasoning and planning. Their versatility and advanced capabilities position them as essential tools in the development of sophisticated AI applications.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,c3d0436082aada237ee4bee645f16059,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="META AGENT SEARCH">
      <data key="d0">ALGORITHM</data>
      <data key="d1">**META AGENT SEARCH** is a comprehensive method and algorithm designed for discovering and optimizing high-performance agents tailored to specific tasks across various domains. It showcases its effectiveness in enhancing performance metrics, particularly in areas such as mathematics, reading, and reasoning. The initiative employs iterative evaluation and refinement based on prior discoveries, particularly within the context of the ARC challenge, to identify generalizable design patterns and systems.

In the realm of Automated Design and Analysis Systems (ADAS), Meta Agent Search facilitates the programming of new agents by leveraging existing algorithms and frameworks. This approach allows for the definition and discovery of agentic systems through a systematic search process. By utilizing foundational models (FMs) as meta agents, the algorithm iteratively creates new agents based on an archive of previous discoveries, thereby outperforming traditional hand-designed agents.

Overall, Meta Agent Search represents a significant advancement in the field of agent design, enabling the automatic programming of agents and enhancing their capabilities through a structured, iterative methodology.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CHAIN-OF-THOUGHT PLANNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain-of-thought planning is a technique used in agentic systems to enhance reasoning and decision-making processes.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AGENT ARCHIVE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The agent archive is a collection of previously discovered agents that informs the meta agent during the programming of new agents.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="MULTI-STEP PEER REVIEW AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">The Multi-Step Peer Review Agent is a specialized agent developed to enhance the quality of answers through a systematic review and refinement process. It exemplifies an innovative approach to task evaluation, having been identified through the Meta Agent Search algorithm. This agent is specifically tailored for reviewing tasks, ensuring that responses are thoroughly vetted and improved upon, thereby contributing to more accurate and reliable outcomes in various applications.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VERIFIED MULTIMODAL AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">The Verified Multimodal Agent is a notable entity identified within the Math domain, emphasizing its capabilities in multimodal problem-solving. This agent was discovered through the Meta Agent Search algorithm and is specifically designed to manage visual tasks effectively. Its dual focus on both mathematical and visual problem-solving highlights its versatility and potential applications in various fields, particularly in enhancing the efficiency of tasks that require the integration of multiple modalities.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="DIVIDE AND CONQUER AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">The "Divide and Conquer Agent" is a specialized agent designed to enhance processing efficiency by breaking down complex tasks into smaller, manageable subproblems. This approach allows for the decomposition of larger problems into more focused components, facilitating the development of specialized solutions tailored to each subproblem. By employing this method, the Divide and Conquer Agent exemplifies a strategic framework for problem-solving that optimizes resource allocation and improves overall effectiveness in addressing intricate challenges.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ZAHARIA ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Zaharia et al. (2024) is a reference to a study that emphasizes the importance of compound agentic systems in solving complex tasks.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HOG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">HOG (Histogram of Oriented Gradients) is a hand-designed feature used in computer vision, which has been replaced by learned features over time.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="DALAL &amp; TRIGGS (2005)">
      <data key="d0">PERSON</data>
      <data key="d1">Dalal &amp; Triggs (2005) is a reference to a study that introduced the HOG feature in computer vision.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CNNS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Convolutional Neural Networks (CNNs) are a specialized class of deep learning algorithms that excel in image processing and recognition tasks. They represent a significant advancement in the field of artificial intelligence, particularly in their ability to outperform traditional hand-designed features in various image processing applications. CNNs leverage hierarchical feature learning, enabling them to automatically detect and learn patterns from visual data, which enhances their effectiveness in tasks such as object detection and classification.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HUTTER ET AL. (2019)">
      <data key="d0">PERSON</data>
      <data key="d1">Hutter et al. (2019) refers to a study that explores AutoML methods, highlighting the advantages and effectiveness of learned AI systems. The research emphasizes the advancements in automated machine learning, showcasing how these methods can outperform traditional approaches in various applications.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AI-Generating Algorithms are methods that create AI systems automatically, showing better performance than hand-designed systems.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="NEURAL ARCHITECTURE SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Neural Architecture Search (NAS) is a sophisticated method aimed at the automatic design of neural network architectures, enabling the discovery of models that often outperform those crafted manually. This approach not only optimizes performance but also explores various architectural configurations to gain insights into their effectiveness. NAS frequently employs multi-objective optimization strategies, as highlighted in the work of Shengran Hu in 2021, further enhancing its capability to identify optimal architectures. Overall, Neural Architecture Search represents a significant advancement in the field of artificial intelligence, streamlining the design process and improving the efficiency of neural networks.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ROCKT&#196;SCHEL (2024)">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="EXAMPLE AGENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Example agents refer to the specific implementations or instances of agents discussed in the context of automated design and AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AUTOML METHODS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AutoML methods are automated machine learning techniques that optimize the process of applying machine learning to real-world problems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AI-GENERATING ALGORITHMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AI-Generating Algorithms (AI-GAs) are advanced algorithms specifically designed to automate the creation of AI systems, showcasing superior performance when compared to traditional development methods. These algorithms focus on learning and optimizing components within AI systems, effectively replacing manually crafted elements. This enhancement in automation significantly streamlines the AI development process, making it more efficient and capable of producing high-quality outcomes.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LLM ALIGNMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">LLM alignment refers to the process of ensuring that large language models (LLMs) behave in accordance with human intentions and values.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LEARNED LOSS FUNCTIONS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Learned loss functions are loss functions that are optimized through learning processes, often outperforming traditional hand-designed loss functions.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="DPO">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">DPO (Differentiable Programming Optimization) is a hand-designed loss function used in training AI models.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AI SCIENTIST">
      <data key="d0">CONCEPT</data>
      <data key="d1">The "AI Scientist" is a concept centered on the idea of fully automated, open-ended scientific discovery, as outlined in a preprint document. This entity represents an automated research pipeline designed to develop novel machine learning algorithms and conduct experiments. By integrating these capabilities, the AI Scientist aims to revolutionize the scientific research process, enabling more efficient and innovative exploration within the field of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="OMNI-EPIC">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">OMNI-EPIC is a versatile framework designed to automatically generate diverse robotics learning environments, emphasizing both creativity and efficiency. It facilitates the development of these environments by enabling Foundation Models to engage in automated programming. Additionally, OMNI-EPIC aims to achieve open-endedness in artificial intelligence by incorporating human notions of interestingness, thereby enhancing the adaptability and richness of the learning experiences it creates.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="F1 SCORES">
      <data key="d0">METRIC</data>
      <data key="d1">F1 scores are a measure of a model's accuracy, balancing precision and recall, particularly in classification tasks.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="DROP">
      <data key="d0">DATASET</data>
      <data key="d1">DROP (Discrete Reasoning over Paragraphs) is a comprehensive benchmark designed to evaluate reading comprehension capabilities, particularly focusing on discrete reasoning and the ability to comprehend detailed information across multiple paragraphs. It employs one-shot style questions to assess reading comprehension skills and is referenced in the context of Meta Agent Search. The dataset is specifically utilized for evaluating reading comprehension tasks, including logic puzzles, and serves as a critical tool for assessing the performance of various agents. DROP requires models to effectively resolve references and perform operations on text, making it a vital resource in the field of artificial intelligence and natural language processing.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,84317ae35cc75d612287186d93461447,86f77e15d41cbd0cb33f635ccb2cb66b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MGSM">
      <data key="d0">DATASET</data>
      <data key="d1">MGSM, which stands for Math Generalization and Search Model, is a comprehensive benchmark designed to evaluate the performance of agents in math-related tasks. It is also referred to as the Multilingual Grade School Math Benchmark, highlighting its capability to assess mathematical problem-solving abilities across various languages. This dataset serves as a critical tool for evaluating the math capabilities of AI systems, particularly in the context of Meta Agent Search. By providing a standardized framework, MGSM facilitates the assessment of agents' performance in mathematical problem-solving, making it an essential resource for researchers and developers in the field of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="GSM8K">
      <data key="d0">DATASET</data>
      <data key="d1">GSM8K, also known as Grade School Math 8K, is a benchmark dataset specifically designed to evaluate the performance of artificial intelligence models in mathematical problem-solving. It focuses on assessing the mathematical reasoning capabilities of language models, particularly in the context of multi-step arithmetic tasks. The dataset comprises a diverse array of grade school math word problems that require multiple steps to arrive at a solution. GSM8K serves as a critical tool for measuring the accuracy and effectiveness of AI systems in tackling challenging math problems, thereby providing a comprehensive benchmark for evaluating the performance of mathematical problem-solving agents.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="GSM-HARD">
      <data key="d0">DATASET</data>
      <data key="d1">GSM-HARD is a challenging benchmark dataset specifically designed for evaluating the performance of mathematical problem-solving agents. It presents a series of difficult math problems that serve as a rigorous test for AI systems, allowing researchers and developers to assess the accuracy and effectiveness of their agents in tackling complex mathematical tasks. By providing a standardized set of challenging problems, GSM-HARD plays a crucial role in advancing the field of artificial intelligence, particularly in the context of enhancing the capabilities of mathematical problem-solving agents.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="CLUNE (2019)">
      <data key="d0">PERSON</data>
      <data key="d1">Clune (2019) is a reference to a study that highlights the advantages of AI-Generating Algorithms over traditional AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="ELSEN ET AL. (2019)">
      <data key="d0">PERSON</data>
      <data key="d1">Elsken et al. (2019) is a reference to a study that discusses the application of Neural Architecture Search in developing CNN models.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="SHEN ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Shen et al. (2023) is a reference to a study that contributes to the understanding of Neural Architecture Search in CNNs.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LU ET AL. (2024A)">
      <data key="d0">PERSON</data>
      <data key="d1">Lu et al. (2024a) is a reference to a study that compares learned loss functions with traditional loss functions in LLM alignment.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="RAFALIOV ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Rafailov et al. (2024) is a reference to a study that discusses the DPO loss function in AI training.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LU ET AL. (2024B)">
      <data key="d0">PERSON</data>
      <data key="d1">Lu et al. (2024b) is a reference to a study that presents the AI Scientist and its automated research capabilities.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="FALDOR ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Faldor et al. (2024) refers to a study that explores the OMNI-EPIC framework, which facilitates the creation of robotics learning environments through the utilization of Foundation Models. This research highlights the innovative capabilities of OMNI-EPIC in generating effective and adaptive learning settings for robotics, thereby contributing to advancements in the field of artificial intelligence and robotics education.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FERNANDO ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Fernando et al. (2024) refers to a comprehensive study centered on PromptBreeder, which aims to enhance the field of prompt engineering. The study not only delves into the methodologies associated with prompt design but also examines existing approaches within Advanced Driver Assistance Systems (ADAS) that are specifically focused on the creation and optimization of prompts. This dual focus highlights the significance of effective prompt engineering in both artificial intelligence applications and the broader context of ADAS, showcasing the potential for improved interaction and functionality in these domains.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="YANG ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Yang et al. (2024) is a reference to a study that explores the automation of prompt engineering for agents through a system known as OPRO. This study not only highlights the innovative aspects of OPRO but also critically examines the limitations present in current Advanced Driver Assistance Systems (ADAS) methods, particularly concerning prompt design. By addressing these limitations, Yang et al. (2024) contributes valuable insights into enhancing the effectiveness and efficiency of prompt engineering in the context of artificial intelligence applications.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="BOYER &amp; MOORE (1983)">
      <data key="d0">PERSON</data>
      <data key="d1">Boyer &amp; Moore (1983) is a reference to a study discussing the Turing completeness of programming languages.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LADHA (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Ladha (2024) is a reference to a study that discusses the implications of Turing completeness in programming languages.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="SEARCH SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The search space defines the range of agentic systems that can be represented and discovered in ADAS, including various structures and components.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="EVALUATION FUNCTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">The evaluation function is a criterion used to assess the performance of candidate agents based on specific objectives such as accuracy or cost.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="PROMPTBREEDER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">PromptBreeder is a sophisticated technique that leverages Foundation Models to enhance prompt engineering specifically for agents. This innovative tool is designed to mutate text prompts while preserving other critical components, such as control flow, ensuring that the overall functionality of the agents remains intact. By focusing on the optimization of prompts, PromptBreeder aims to improve the performance and effectiveness of agents in various applications.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ZHUKE ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuge et al. (2024) is a reference to a study discussing search algorithms and their application in exploring search spaces for agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="CHASE (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Chase (2024) is a reference to a work that contributes to the understanding of agentic systems and their definitions.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="NG (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Ng (2024) is a reference to a work that contributes to the understanding of agentic systems and their definitions.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="OPTIMIZATION PROCESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">An optimization process is a systematic approach to finding the best solution or outcome among various alternatives, often used in algorithm design.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="ITERATIVE PROCESSING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Iterative processing involves repeatedly applying a set of operations or algorithms to refine results or improve performance over time.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="EXPLORATION-EXPLOITATION TRADE-OFF">
      <data key="d0">CONCEPT</data>
      <data key="d1">The exploration-exploitation trade-off is a dilemma in decision-making where one must balance between exploring new options and exploiting known ones for optimal outcomes.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="ACCURACY">
      <data key="d0">METRIC</data>
      <data key="d1">The entity "ACCURACY" refers to a crucial metric utilized in evaluating the performance of models or agents, particularly in the fields of Artificial Intelligence and Natural Language Processing. It signifies the proportion of correct predictions made by these models, serving as a key indicator of their effectiveness. Furthermore, accuracy is specifically employed to assess the correctness of agents' responses across various tasks, including reading comprehension and mathematical problem-solving. This dual role underscores the importance of accuracy in ensuring reliable and effective performance in diverse applications.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="COST">
      <data key="d0">METRIC</data>
      <data key="d1">Cost refers to the resources required to implement or operate a system, often considered in the evaluation of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="LATENCY">
      <data key="d0">METRIC</data>
      <data key="d1">Latency is the time delay between the initiation of a process and its completion, an important factor in assessing the performance of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="SAFETY">
      <data key="d0">METRIC</data>
      <data key="d1">Safety refers to the measures taken to ensure that systems operate without causing harm, a critical consideration in the design of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="AGENTIC SYSTEMS">
      <data key="d0" />
      <data key="d1">Agentic Systems are defined as computational systems designed to perform tasks autonomously, capable of making decisions based on their environment. These systems can be programmed by a meta agent within the Meta Agent Search framework. The concept of agentic systems has been explored in various research papers, including those focusing on MetaGPT and dynamic LLM-agent networks. Their relevance extends to broader discussions on artificial intelligence and automation, highlighting their potential to operate independently in complex environments.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1b1399c76420a477c0c97893d258ae69,24d7b89ae9522ae60d2317984951355b,4884e8429ca1e567dadf5e22b4b68274,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FOUNDATIONAL MODELS (FMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundational models (FMs) are large-scale machine learning models that serve as the basis for creating new agents in the Meta Agent Search algorithm.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="ARCHIVE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The archive is a collection of previously discovered agents and their evaluation metrics, used to inform the meta agent's future proposals.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="PROMPTING TECHNIQUES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">**PROMPTING TECHNIQUES** are specialized methods employed to guide the behavior of agents within agentic systems, significantly enhancing their problem-solving capabilities. These techniques also serve to instruct the meta agent on generating new agents by leveraging information derived from both archival resources and academic literature. Through these dual functions, prompting techniques play a crucial role in optimizing agent performance and fostering innovation in the development of new agents.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="ARC LOGIC PUZZLE TASK">
      <data key="d0">TASK</data>
      <data key="d1">The ARC logic puzzle task is a benchmark used to evaluate the performance of agents in logical reasoning and problem-solving.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="ITERATIONS">
      <data key="d0">PROCESS</data>
      <data key="d1">The term "Iterations" pertains to the repeated cycles integral to the Meta Agent Search process. During these iterations, the meta agent refines its proposals by leveraging insights gained from prior evaluations. This cyclical process emphasizes continuous evaluation and improvement, allowing agents to enhance their performance and outcomes throughout the Meta Agent Search.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="VALIDATION DATA">
      <data key="d0">DATA</data>
      <data key="d1">Validation data is the dataset used to evaluate the performance of newly generated agents in the target domain.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="FUNSEARCH">
      <data key="d0" />
      <data key="d1">FunSearch is a method that leverages Foundation Models to enhance the discovery of superior optimization algorithms through automated coding. This innovative approach aims to streamline the process of identifying effective algorithms, thereby improving efficiency and outcomes in various applications.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="ARC CHALLENGE">
      <data key="d0">EVENT</data>
      <data key="d1">The ARC Challenge is a competition designed to evaluate the general intelligence of AI systems by testing their ability to learn transformation rules from visual input-output grid patterns.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="SELF-CONSISTENCY WITH COT (COT-SC)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Self-Consistency with Chain-of-Thought (COT-SC) is a hand-designed agent baseline that enhances the Chain-of-Thought (COT) technique. This method involves ensembling multiple answers generated through COT, aiming to improve the overall accuracy of responses. By leveraging the strengths of the COT approach, COT-SC seeks to provide more reliable and consistent outputs in various applications.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="LLM DEBATE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">LLM Debate is a sophisticated baseline technique that employs debate-style interactions among agents to improve reasoning and answer quality. This method involves multiple language models engaging in a structured debate format, which enhances their decision-making capabilities by leveraging diverse perspectives. LLM Debate is not only a theoretical construct but also a practical approach, as it encompasses manually designed agents that perform across various tasks, including math and reading comprehension. It is particularly relevant in agentic systems for problem-solving, highlighting its utility in enhancing the effectiveness of language models in complex scenarios.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="QUALITY-DIVERSITY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Quality-Diversity is a sophisticated baseline technique within the realm of evolutionary algorithms, designed to enhance both the diversity and quality of solutions generated by agents. It emphasizes the generation of a varied set of high-quality solutions, thereby improving the overall performance of language models. This method operates through multiple iterations, collecting diverse answers based on previous responses, which allows for a more effective exploration of potential solutions. Quality-Diversity is also characterized as a manually designed agent that showcases performance metrics across various tasks. Additionally, it serves as a simplified version of Intelligent Go-Explore, functioning as a hand-designed agent baseline. Overall, Quality-Diversity plays a crucial role in agentic systems for problem-solving, facilitating the generation of diverse and high-quality solutions.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="EXPERTS">
      <data key="d0">ROLE</data>
      <data key="d1">Experts are evaluators that assess the performance of agents based on specific traits such as efficiency, readability, and simplicity.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="HUMAN-LIKE CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">Human-like critics are evaluators that simulate human feedback to assess the quality of answers produced by agents.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="EFFICIENCY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">Efficiency experts evaluate agents based on their ability to produce answers quickly and effectively.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="READABILITY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">Readability experts assess the clarity and comprehensibility of the answers generated by agents.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="SIMPLICITY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">Simplicity experts evaluate the straightforwardness and ease of understanding of the answers produced by agents.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="TOP-3 ANSWERS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Top-3 answers refer to the best three responses generated by agents, selected for further evaluation and potential ensemble.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="FINAL ANSWER">
      <data key="d0">OUTPUT</data>
      <data key="d1">The "FINAL ANSWER" refers to the definitive response generated after a thorough evaluation and refinement of the leading answers through an ensemble process. This process ensures that the final answer is well-informed and reliable. Additionally, it represents the specific choice made by a student from a set of provided options, which may consist of a single letter or a combination of letters. Thus, the final answer serves both as a culmination of analytical processes and as a personal selection in an educational context.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="REFINEMENT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="ADAS">
      <data key="d0">CONCEPT</data>
      <data key="d1">ADAS, which stands for Automated Design of Agentic Systems, encompasses a research area dedicated to the development of algorithms aimed at creating intelligent agents capable of operating autonomously. This field emphasizes the invention of novel building blocks and the design of powerful agentic systems through automated processes. The focus of ADAS is on automating the design and optimization of these systems, leveraging advanced foundational models (FMs) to enhance their capabilities. Additionally, ADAS is also associated with Advanced Driver Assistance Systems, which are technologies specifically designed to improve vehicle safety and facilitate driving. Thus, ADAS represents a multifaceted domain that bridges both theoretical research in AI and practical applications in automotive safety technologies.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,bc26e68b0b2783ba912b9e5606d9eb0b,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FEEDBACK MECHANISM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The "FEEDBACK MECHANISM" is a critical process that utilizes the outcomes of previous actions to inform and adjust future actions, playing a vital role in enhancing the performance of Artificial Intelligence (AI) models. This mechanism is characterized as a sophisticated system that integrates various forms of feedback, allowing for iterative refinement of responses and overall performance improvement. By continuously incorporating diverse feedback, the feedback mechanism ensures that AI models evolve and adapt, ultimately leading to more accurate and effective outcomes.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="STEP-BACK ABSTRACTION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Step-back Abstraction is a baseline technique designed to enhance the reasoning capabilities of agents by instructing them to consider the underlying principles involved in task-solving. It serves as a hand-designed agent baseline specifically tailored for reasoning and problem-solving domains. This method is utilized in various learning tasks, providing performance metrics that help evaluate the effectiveness of agents. Additionally, Step-back Abstraction is referenced in the context of agentic systems, where it plays a crucial role in experiments focused on reasoning and problem-solving, highlighting its significance in the development of manually designed agents.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ROLE ASSIGNMENT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Role Assignment is a foundational technique utilized in various domains, particularly in reasoning and problem-solving contexts. It involves the strategic assignment of different roles to function models (FMs) and debate modules, enhancing the quality of answers and facilitating collaboration within agentic systems. This hand-designed agent baseline demonstrates notable performance metrics in multi-task learning scenarios, showcasing its effectiveness in improving outcomes. By assigning specific roles to modules, Role Assignment fosters better interaction and cooperation among agents, thereby optimizing their problem-solving capabilities.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MMLU">
      <data key="d0">BENCHMARK</data>
      <data key="d1">MMLU, or Massive Multitask Language Understanding, is a comprehensive benchmark designed to evaluate the performance of AI models in answering questions across a diverse array of subjects and difficulty levels. It specifically assesses the capabilities of language models in various academic disciplines, including abstract algebra and college mathematics. MMLU measures multi-task problem-solving abilities in agents, and is referenced in contexts such as Meta Agent Search. The benchmark employs multiple-choice questions to gauge a model's multitask understanding, making it a critical tool for evaluating the effectiveness of language models in handling a wide range of tasks.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="GPQA">
      <data key="d0">BENCHMARK</data>
      <data key="d1">GPQA, which stands for Generalized Problem Solving Questions and Answers, is a comprehensive dataset and benchmark designed to evaluate reasoning and problem-solving capabilities across various domains, particularly in the sciences. It includes challenging multiple-choice questions specifically crafted by domain experts in biology, physics, and chemistry. The GPQA serves as a graduate-level benchmark aimed at assessing the effectiveness of question-and-answer systems, ensuring their robustness against conventional search engines like Google. This dataset is referenced in the context of Meta Agent Search, highlighting its significance in evaluating the capabilities of language models in tackling complex, graduate-level scientific inquiries. Overall, GPQA is a critical tool for advancing the development and assessment of AI-driven question-and-answer systems.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e,84317ae35cc75d612287186d93461447,86f77e15d41cbd0cb33f635ccb2cb66b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MEYERSON ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Meyerson et al. (2023) is a reference to a study that discusses the evolution of feedback mechanisms in the context of agent performance.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="F1 SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">F1 Score is a performance metric used to evaluate the accuracy of agents in tasks, particularly in reading comprehension and math.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="CHAIN-OF-THOUGHT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The entity "CHAIN-OF-THOUGHT" refers to a baseline technique that significantly enhances reasoning capabilities in agentic systems. This method encourages agents to articulate their thought processes while solving tasks, thereby improving their problem-solving abilities. It is particularly noted for its application in manually designed agents, where it serves as a foundational approach to bolster reasoning and decision-making.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="COT-SC">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">COT-SC (Chain-of-Thought with Self-Consistency) is a sophisticated technique designed to enhance the performance of language models by generating multiple reasoning paths and selecting the most effective one. It serves as a baseline method that builds upon the foundational principles of Chain-of-Thought, thereby improving reasoning capabilities and overall performance across various tasks. COT-SC is particularly notable for its application in agentic systems, where it functions as a manually designed agent that demonstrates specific performance metrics in multi-task learning scenarios. This technique involves sampling multiple answers and employing ensemble methods for final decision-making, making it a valuable tool for problem-solving in complex environments.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="AGENT NAME">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Agent Name refers to the identifier assigned to each agent evaluated in the performance comparison across various tasks.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="HOLD-OUT TEST SETS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Hold-out test sets are subsets of data reserved for evaluating the performance of agents after training, ensuring unbiased assessment.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="FOUNDATION MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundation Models are large-scale machine learning models that serve as a foundational base for a variety of artificial intelligence applications. They are particularly notable for their ability to generate code and optimize algorithms. These models are trained on diverse datasets, allowing them to be fine-tuned for various downstream tasks. Their versatility is highlighted in contexts such as Meta Agent Search and intelligent exploration and exploitation strategies, where they can be adapted to meet specific application needs. Overall, Foundation Models play a crucial role in advancing AI capabilities across multiple domains.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2901d5e2711fa4f32d39cd8eea36cd71,6109537356a2ce2339f77c827aa3668e,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="CLAUDE-HAIKU">
      <data key="d0">MODEL</data>
      <data key="d1">Claude-Haiku is a language model developed by Anthropic, used to evaluate the performance of agents discovered through Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="CLAUDE-SONNET">
      <data key="d0">MODEL</data>
      <data key="d1">Claude-Sonnet is another language model from Anthropic, noted for its high performance in evaluations of agents discovered through Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ARC">
      <data key="d0">EVALUATION METRIC</data>
      <data key="d1">ARC, which stands for AI Reading Comprehension, is a benchmark developed by AllenAI to evaluate the performance of AI agents in reading comprehension and reasoning tasks. It serves as a specific evaluation framework designed to assess the accuracy and capabilities of these agents through various tasks, including multiple-choice questions. The AI2 Reasoning Challenge (ARC) focuses on measuring the reasoning and comprehension abilities of language models, making it a critical tool for understanding how well AI can interpret and respond to complex information. Overall, ARC encompasses both the AI Reading Comprehension and AI Research Challenge aspects, providing a comprehensive assessment of AI agents' performance in reading and reasoning tasks.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2,86f77e15d41cbd0cb33f635ccb2cb66b,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SVAMP">
      <data key="d0">DATASET</data>
      <data key="d1">SVAMP is a dataset specifically designed for assessing the performance of agents in solving mathematical problems. It serves as a benchmark for evaluating the effectiveness of various agents in mathematical problem-solving tasks, with a particular focus on measuring accuracy improvements. This dataset plays a crucial role in the development and evaluation of algorithms in the fields of Artificial Intelligence and Natural Language Processing, providing a structured framework for researchers and practitioners to gauge advancements in agent performance.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ASDIV">
      <data key="d0">DATASET</data>
      <data key="d1">ASDIV is a dataset specifically designed for evaluating the performance of agents in diverse mathematical tasks. It serves as a benchmark for assessing the effectiveness of agents in mathematical problem-solving scenarios, with a particular emphasis on improvements in accuracy. This dataset plays a crucial role in the development and evaluation of algorithms within the field of artificial intelligence, particularly in enhancing the capabilities of agents to tackle a variety of mathematical challenges.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d0">AGENT</data>
      <data key="d1">Dynamic Role-Playing Architecture is a highly effective agent identified through Meta Agent Search, demonstrating exceptional performance across a range of mathematical domains. Additionally, this architecture showcases its versatility by maintaining strong performance metrics when applied to non-mathematical domains, indicating its adaptability and potential for broader applications beyond its initial evaluation context.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d0">AGENT</data>
      <data key="d1">The "Structured Multimodal Feedback Loop" is a top-performing agent identified by Meta Agent Search, demonstrating exceptional capabilities across a range of mathematical domains. This agent exhibits notable performance metrics when evaluated across various tasks, highlighting its versatility and effectiveness in handling diverse challenges.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d0">AGENT</data>
      <data key="d1">The "Interactive Multimodal Feedback Loop" is recognized as a top-performing agent identified by Meta Agent Search, showcasing its capabilities across various mathematical domains. This agent not only excels in performance but also offers comprehensive performance metrics across multiple domains, highlighting its versatility and effectiveness in diverse applications.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="MANUALLY DESIGNED AGENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="EXTERNAL MEMORY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">External Memory is a technique used in agentic systems to store and retrieve information, enhancing the agents' capabilities.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="FM MODULES">
      <data key="d0">CONCEPT</data>
      <data key="d1">FM Modules are functional modules within agentic systems that can be assigned different roles to collaborate effectively.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="AUTOML">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">AutoML refers to automated machine learning techniques that streamline the process of applying machine learning to real-world problems.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="META-LEARNING ARCHITECTURES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Meta-learning architectures are frameworks that enable systems to learn how to learn, improving efficiency and adaptability in AI models.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="META-LEARNING ALGORITHMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Meta-learning algorithms are techniques that allow models to improve their learning processes over time, enhancing their performance on various tasks.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="LEARNING ENVIRONMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Learning environments are settings or frameworks designed to facilitate the training and development of AI models.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="MAML">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">MAML (Model-Agnostic Meta-Learning) is a meta-learning algorithm that enables models to adapt quickly to new tasks with minimal data.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="META-RL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Meta-RL (Meta-Reinforcement Learning) is a framework that focuses on improving the learning efficiency of reinforcement learning agents.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="POET">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">POET (Population-Based Open-Ended Learning) is a method for generating learning environments in an open-ended manner.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DISCOPOP">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">DiscoPOP is a framework where Foundation Models program loss functions for preference learning in alignment training.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="EUREKA">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">EUREKA is a method and project that leverages Foundation Models to create reward functions specifically for reinforcement learning applications. This innovative approach is particularly relevant in the field of robotics, where effective reward design is crucial for training intelligent systems. The initiative emphasizes human-level reward design through the coding capabilities of large language models, as detailed in a paper authored by Yecheng Jason Ma and colleagues. By integrating these advanced models, EUREKA aims to enhance the efficiency and effectiveness of reinforcement learning strategies across various applications.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="LANGUAGE-TO-REWARD">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The entity "LANGUAGE-TO-REWARD" refers to a technique that empowers Foundation Models to generate reward functions specifically for reinforcement learning applications. This technique is particularly relevant in the context of robotics, where it facilitates the development of effective reward systems that guide learning processes. By leveraging the capabilities of Foundation Models, LANGUAGE-TO-REWARD enhances the ability to design and implement reinforcement learning strategies, thereby contributing to advancements in both artificial intelligence and robotics.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="OPRO">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">OPRO is a method that utilizes Foundation Models to automate prompt engineering for agents, focusing on enhancing reasoning capabilities.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="SELF-DISCOVER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Self-Discover is a method that uses Foundation Models to automate the creation of effective prompts for agents.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="EVOAGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">EvoAgent is a framework that optimizes role definitions in prompts to enhance agent performance.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENTVERSE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AgentVerse is a comprehensive system and framework that optimizes agent roles and definitions to enhance performance in agentic systems. It is specifically designed to facilitate multi-agent collaboration, allowing for the exploration of emergent behaviors within artificial intelligence systems. By focusing on the dynamics of agent interactions, AgentVerse aims to improve the efficiency and effectiveness of collaborative AI efforts.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DYLAN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">DyLAN is a method that uses Foundation Models to score response quality in agent networks and prune connections.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DSPY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">DSPy is a framework that generates and optimizes nodes in agentic systems using Foundation Models.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="GPT-SWARM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-Swarm is a system that represents agentic systems in a graph format and optimizes connections using reinforcement learning.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENTOPTIMIZER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AgentOptimizer is a method that learns the tools used in agentic systems to enhance their functionality.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENT SYMBOLIC LEARNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Agent Symbolic Learning is a framework that learns prompts, tools, and control flow in agentic systems.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="SAFETY CONSIDERATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Safety considerations refer to the precautions and awareness needed when executing untrusted model-generated code in AI research.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ARTIFICIAL GENERAL INTELLIGENCE (AGI)">
      <data key="d0">CONCEPT</data>
      <data key="d1">Artificial General Intelligence (AGI) is a theoretical form of AI that possesses the ability to understand, learn, and apply intelligence across a wide range of tasks.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="YU ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Yu et al. (2023) is a reference to a study that discusses language-to-reward techniques for Foundation Models.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ZHOU ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Zhou et al. (2024) is a reference to a study discussing Self-Discover, which automates prompt creation for agents.Zhou et al. (2024) is a reference to a study on Agent Symbolic Learning, which learns prompts, tools, and control flow.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XU ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Xu et al. (2023) is a reference to a study that highlights the benefits of assigning personas or roles to agents.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="KHATTAB ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Khattab et al. (2024) is a reference to a study discussing DSPy and its optimization of nodes in agentic systems.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ZHUGE ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuge et al. (2024) is a reference to a study on GPT-Swarm, which optimizes connections in agentic systems.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="RAFAILOV ET AL. (2024)">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FOUNDATIONAL MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundational models are large-scale machine learning models that serve as the basis for developing various AI applications, including ADAS algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CONSTITUTIONAL AI">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Constitutional AI is an approach that aims to ensure AI systems operate safely and ethically by incorporating predefined principles during their development.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="MULTI-OBJECTIVE SEARCH ALGORITHMS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-objective search algorithms are optimization techniques that consider multiple criteria simultaneously, such as performance, cost, and robustness.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="EVALUATION FUNCTIONS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Evaluation functions are metrics or criteria used to assess the performance and effectiveness of agents developed through ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="HUMAN ORGANIZATIONS">
      <data key="d0">SOCIETY</data>
      <data key="d1">Human organizations refer to structured groups of individuals working together, which can influence the design and complexity of agentic systems.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="COMPLEX DOMAINS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Complex domains refer to intricate environments or tasks that require advanced interaction and problem-solving capabilities from AI agents.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CLUNE">
      <data key="d0">PERSON</data>
      <data key="d1">Clune is a researcher whose work is cited in discussions about AI algorithms and their implications for safety and effectiveness.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="ECOFFET ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Ecoffet et al. is a reference to a study or work that contributes to the understanding of ADAS and its applications.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="YUDKOWSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Yudkowsky is a researcher known for his contributions to AI safety and ethics, referenced in the context of ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CALDWELL">
      <data key="d0">PERSON</data>
      <data key="d1">Caldwell is a researcher referenced in discussions about the benefits of open-source approaches to AI safety.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="LU ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Lu et al. is a reference to a study that discusses evaluation functions in the context of ADAS.)&lt;|COMPLETE|&gt;Lu et al. is a reference to a study that discusses higher-order ADAS and the potential for self-referential learning in agents.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEWIS ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis et al. is a reference to a study that discusses RAG (Retrieval-Augmented Generation) in the context of ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="HU ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Hu et al. is a reference to a study that discusses multi-objective optimization in agentic systems.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="HUANG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Huang et al. is a reference to a study that discusses considerations for optimizing agentic systems.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="DEB ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Deb et al. is a reference to a study that discusses multi-objective search algorithms relevant to ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CULLY &amp; DEMIRIS">
      <data key="d0">PERSON</data>
      <data key="d1">Cully &amp; Demiris is a reference to a study that discusses Quality-Diversity in the context of AI algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="MOURET &amp; CLUNE">
      <data key="d0">PERSON</data>
      <data key="d1">Mouret &amp; Clune is a reference to a study that discusses concepts related to diversity in AI solutions.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="FALDOR ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Faldor et al. is a reference to a study that discusses open-ended algorithms in AI development.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="STANLEY ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Stanley et al. is a reference to a study that discusses the evolution of algorithms in AI.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="ZHOU ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhou et al. is a reference to a study that discusses evaluation methods for agentic systems.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CHIANG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Chiang et al. is a reference to a study that discusses subjective evaluation tasks in AI.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="AGENTIC SYSTEM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The "AGENTIC SYSTEM" is defined as a comprehensive framework that integrates various agents and processes aimed at automating data generation and refining instructions. This system is particularly focused on machine learning applications that operate predominantly within the realm of natural language. Its design ensures that the outputs are interpretable by humans, thereby facilitating the construction and organization of human society. Through its multifaceted approach, the agentic system plays a crucial role in enhancing communication and collaboration within professional networks, especially in fields related to Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="HUMAN ORGANIZATION">
      <data key="d0">SOCIETY</data>
      <data key="d1">Human organization refers to the structured ways in which humans interact and collaborate, forming societies and communities.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="HONG ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Hong et al. (2023) is a reference to a study that incorporates organizational structures for human companies in agents.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="PARK ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Park et al. (2023) is a reference to a study that simulates a human town with agents.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="ANTHROPIC">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Anthropic is an organization known for developing AI technologies, including the Claude series of models.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CLAUDE 3">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Claude 3 is a next-generation AI model developed by Anthropic.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CLAUDE 3.5 SONNET">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Claude 3.5 Sonnet is an iteration of the Claude model developed by Anthropic.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="YUNTAO BAI ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Yuntao Bai et al. (2022) is a reference to a study discussing AI feedback for harmlessness.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="YOSHUA BENGIO ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Yoshua Bengio et al. (2024) is a reference to a study on managing extreme AI risks.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="N BOSTROM">
      <data key="d0">PERSON</data>
      <data key="d1">N Bostrom is a researcher known for analyzing human extinction scenarios and related hazards.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="ROBERT S BOYER AND J STROTHER MOORE">
      <data key="d0">PERSON</data>
      <data key="d1">Robert S Boyer and J Strother Moore are known for their work on the Turing completeness of pure LISP.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="TRACEY CALDWELL">
      <data key="d0">PERSON</data>
      <data key="d1">Tracey Caldwell is a researcher discussing ethical hacking.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="HARRISON CHASE">
      <data key="d0">PERSON</data>
      <data key="d1">Harrison Chase is a researcher who explores the concept of agents in AI.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="BANGHAO CHEN ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Banghao Chen et al. (2023) is a reference to a comprehensive review on prompt engineering in large language models.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="MARK CHEN ET AL. (2021)">
      <data key="d0">PERSON</data>
      <data key="d1">Mark Chen et al. (2021) is a reference to a study evaluating large language models trained on code.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="WEIZE CHEN ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Weize Chen et al. (2023) is a reference to a study on facilitating multi-agent collaboration.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="COMPLEXITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Complexity refers to the intricate and interconnected nature of systems, often emerging from simple rules or interactions in human organizations and societies.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="SOCIETY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Society is a structured community of individuals who interact and form relationships, often studied in the context of human organization and behavior.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="AI RISKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI risks refer to potential dangers and ethical concerns associated with the development and deployment of artificial intelligence technologies.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="STATE-OF-THE-ART AGENTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">State-of-the-art agents are advanced AI systems designed with the latest techniques and methodologies to perform optimally across various tasks.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="ORGANIZATIONAL STRUCTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Organizational structure refers to the way in which the components of an organization are arranged, influencing how information flows and decisions are made.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="AUTOMATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Automation is the use of technology to perform tasks with minimal human intervention, often aimed at increasing efficiency and reducing errors.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="RESEARCH DIRECTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research direction refers to the focus or path of inquiry in a particular field, guiding the development of new theories, technologies, or methodologies.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="VECTOR INSTITUTE">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The Vector Institute is a research organization focused on advancing artificial intelligence and machine learning through collaboration and innovation.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CANADA CIFAR AI CHAIRS">
      <data key="d0">PROGRAM</data>
      <data key="d1">The Canada CIFAR AI Chairs program supports research in artificial intelligence by funding leading researchers in the field.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="SCHMIDT FUTURES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Schmidt Futures is an organization that funds initiatives aimed at advancing science and technology for the public good.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="OPEN PHILANTHROPY">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Open Philanthropy is a philanthropic organization that aims to promote effective altruism and support high-impact charitable initiatives.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="NSERC DISCOVERY GRANT">
      <data key="d0">FUNDING</data>
      <data key="d1">The NSERC Discovery Grant is a funding program in Canada that supports research in natural sciences and engineering.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="RAFAEL COSMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Rafael Cosman is a donor who contributed to the research efforts discussed in the paper.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="YUSHENG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yusheng Chen is a researcher involved in the study of multi-agent collaboration and emergent behaviors in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SU JINGWEI">
      <data key="d0">PERSON</data>
      <data key="d1">Su Jingwei is a researcher contributing to the exploration of multi-agent collaboration in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ZUO CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zuo Cheng is a researcher focused on multi-agent collaboration and emergent behaviors in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHENFEI YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Chenfei Yuan is a researcher involved in the study of multi-agent collaboration in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHI-MIN CHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Chi-Min Chan is a researcher contributing to the exploration of emergent behaviors in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="HEYANG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Heyang Yu is a researcher focused on multi-agent collaboration in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YI-HSIN HUNG">
      <data key="d0">PERSON</data>
      <data key="d1">Yi-Hsin Hung is a researcher contributing to the exploration of multi-agent collaboration in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHEN QIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Qian is a researcher focused on multi-agent collaboration and emergent behaviors in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">EVENT</data>
      <data key="d1">The Twelfth International Conference on Learning Representations is a conference where research on learning representations, including multi-agent systems, is presented.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="WEI-LIN CHIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Wei-Lin Chiang is a researcher involved in creating an open platform for evaluating language models based on human preference.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="LIANMIN ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Lianmin Zheng is a researcher contributing to the development of an open platform for evaluating language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YING SHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Ying Sheng is a researcher focused on evaluating language models through human preference.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ANASTASIOS NIKOLAS ANGELOPOULOS">
      <data key="d0">PERSON</data>
      <data key="d1">Anastasios Nikolas Angelopoulos is a researcher involved in the evaluation of language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="TIANLE LI">
      <data key="d0">PERSON</data>
      <data key="d1">Tianle Li is a researcher contributing to the development of an open platform for evaluating language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="DACHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Dacheng Li is a researcher focused on evaluating language models through human preference.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="HAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Zhang is a researcher involved in the evaluation of language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="BANGHUA ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Banghua Zhu is a researcher contributing to the development of an open platform for evaluating language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="MICHAEL JORDAN">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Jordan is a prominent researcher in machine learning and AI, contributing to the evaluation of language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JOSEPH E. GONZALEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Joseph E. Gonzalez is a researcher involved in the evaluation of language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ION STOICA">
      <data key="d0">PERSON</data>
      <data key="d1">Ion Stoica is a researcher contributing to the development of an open platform for evaluating language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHATBOT ARENA">
      <data key="d0">PLATFORM</data>
      <data key="d1">Chatbot Arena is an open platform designed for evaluating language models based on human preferences.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="FRAN&#199;OIS CHOLLET">
      <data key="d0">PERSON</data>
      <data key="d1">Fran&#231;ois Chollet is a researcher known for his work on the measure of intelligence in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="AI-GAS">
      <data key="d0">RESEARCH</data>
      <data key="d1">AI-GAS refers to AI-generating algorithms, a paradigm for producing general artificial intelligence.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="KARL COBBE">
      <data key="d0">PERSON</data>
      <data key="d1">Karl Cobbe is a researcher recognized for his contributions to the field of education, specifically in the area of training verifiers to effectively solve math word problems. His work focuses on developing methodologies and tools that enhance the understanding and resolution of mathematical challenges presented in verbal form, thereby improving educational outcomes in mathematics.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="KALYANMOY DEB">
      <data key="d0">PERSON</data>
      <data key="d1">Kalyanmoy Deb is a prominent researcher recognized for his significant contributions to the field of multi-objective genetic algorithms. He has co-authored influential papers, including one focused on neural architecture search utilizing genetic algorithms, showcasing his expertise in integrating genetic algorithms with advanced neural network techniques. Additionally, he co-authored a paper that revisits residual networks to enhance adversarial robustness, which was presented at the prestigious IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023. Through these works, Kalyanmoy Deb has established himself as a key figure in the intersection of genetic algorithms and neural network research.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AMRIT PRATAP">
      <data key="d0">PERSON</data>
      <data key="d1">Amrit Pratap is a researcher contributing to the development of multi-objective genetic algorithms.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SAMEER AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Sameer Agarwal is a researcher focused on multi-objective genetic algorithms.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="TAMT MEYARIVAN">
      <data key="d0">PERSON</data>
      <data key="d1">Tamt Meyarivan is a researcher involved in the development of multi-objective genetic algorithms.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="NSGA-II">
      <data key="d0">ALGORITHM</data>
      <data key="d1">NSGA-II is a fast and elitist multi-objective genetic algorithm used for optimization problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="AARON DHARNA">
      <data key="d0">PERSON</data>
      <data key="d1">Aaron Dharna is a researcher involved in the co-generation of game levels and game-playing agents.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JULIAN TOGELIUS">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Togelius is a researcher focused on the co-generation of game levels and agents.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="LISA B SOROS">
      <data key="d0">PERSON</data>
      <data key="d1">Lisa B Soros is a researcher contributing to the co-generation of game levels and game-playing agents.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SHUANG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Shuang Li is a researcher focused on enhancing factuality and reasoning in language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ANTONIO TORRALBA">
      <data key="d0">PERSON</data>
      <data key="d1">Antonio Torralba is a researcher contributing to the improvement of factuality in language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JOSHUA B TENENBAUM">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua B Tenenbaum is a researcher involved in enhancing reasoning in language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="DHEERU DUA">
      <data key="d0">PERSON</data>
      <data key="d1">Dheeru Dua is a researcher involved in the development of a reading comprehension benchmark requiring discrete reasoning.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YIZHONG WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yizhong Wang is a researcher contributing to the development of a reading comprehension benchmark.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PRADEEP DASIGI">
      <data key="d0">PERSON</data>
      <data key="d1">Pradeep Dasigi is a researcher focused on creating a reading comprehension benchmark.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GABRIEL STANOVSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Gabriel Stanovsky is a researcher involved in the development of a reading comprehension benchmark.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAMEER SINGH">
      <data key="d0">PERSON</data>
      <data key="d1">Sameer Singh is a researcher contributing to the creation of a reading comprehension benchmark.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MATT GARDNER">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Gardner is a researcher focused on developing a reading comprehension benchmark.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YAN DUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Yan Duan is a researcher involved in fast reinforcement learning techniques.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="XI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xi Chen is a researcher focused on reinforcement learning techniques.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="PETER L BARTLETT">
      <data key="d0">PERSON</data>
      <data key="d1">Peter L Bartlett is a researcher involved in reinforcement learning research.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="RL^2">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">RL^2 is a method for fast reinforcement learning via slow reinforcement learning techniques.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="ADRIEN ECOFFET">
      <data key="d0">PERSON</data>
      <data key="d1">Adrien Ecoffet is a researcher involved in creating safe open-ended AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOEL LEHMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Joel Lehman is a prominent researcher in the field of artificial intelligence, particularly focused on the development of safe open-ended AI systems and open-ended reinforcement learning systems. He has made significant contributions to the academic community, co-authoring a book that explores the myth of objectivity in planning. Additionally, he has co-authored several influential papers, including one published in 2011 that discusses evolution through the search for novelty alone, as well as research on language model crossover and the concept of open-endedness in models related to human notions of interestingness. Through his work, Joel Lehman plays a vital role in advancing the understanding and implementation of innovative AI methodologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OPEN QUESTIONS IN CREATING SAFE OPEN-ENDED AI">
      <data key="d0">RESEARCH</data>
      <data key="d1">Open questions in creating safe open-ended AI address the tensions between control and creativity in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">RESEARCH</data>
    </node>
    <node id="THOMAS ELSKEN">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Elsken is a researcher known for his work on neural architecture search.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JAN HENDRIK METZEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jan Hendrik Metzen is a researcher contributing to neural architecture search.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FRANK HUTTER">
      <data key="d0">PERSON</data>
      <data key="d1">Frank Hutter is a prominent researcher specializing in neural architecture search techniques. He has made significant contributions to the field of automated machine learning, co-authoring a book published in 2019 that explores various methods, systems, and challenges associated with this area of study. His work reflects a deep engagement with the complexities of machine learning, positioning him as a key figure in advancing the understanding and application of these technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAXENCE FALDOR">
      <data key="d0">PERSON</data>
      <data key="d1">Maxence Faldor is a researcher involved in open-endedness in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JENNY ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jenny Zhang is a researcher actively contributing to the study of open-endedness in artificial intelligence (AI) systems. Her work focuses on understanding how AI can exhibit open-ended behaviors, which is crucial for developing more advanced and adaptable AI technologies. Additionally, she has co-authored a paper that explores open-endedness in relation to human notions of interestingness, further emphasizing her commitment to advancing knowledge in this area. Through her research, Jenny Zhang plays a significant role in enhancing the understanding of how AI can evolve and respond to complex, dynamic environments.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANTOINE CULLY">
      <data key="d0">PERSON</data>
      <data key="d1">Antoine Cully is a researcher focused on open-endedness in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHRISANTHA FERNANDO">
      <data key="d0">PERSON</data>
      <data key="d1">Chrisantha Fernando is a researcher involved in self-referential self-improvement in AI.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DYLAN SUNIL BANARSE">
      <data key="d0">PERSON</data>
      <data key="d1">Dylan Sunil Banarse is a researcher contributing to self-referential self-improvement in AI.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HENRYK MICHALIEWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Henryk Michaliewski is a researcher focused on self-referential self-improvement in AI.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SIMON OSINDERO">
      <data key="d0">PERSON</data>
      <data key="d1">Simon Osindero is a researcher involved in self-referential self-improvement in AI.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TIM ROCKT&#196;SCHEL">
      <data key="d0">PERSON</data>
      <data key="d1">Tim Rockt&#228;schel is a prominent researcher in the field of artificial intelligence, particularly known for his contributions to self-referential self-improvement in AI. He co-authored a significant paper in 2020 that focused on retrieval-augmented generation for knowledge-intensive natural language processing (NLP) tasks, showcasing his expertise in enhancing AI capabilities. Additionally, he is the author of a book on artificial intelligence, further solidifying his role as a thought leader in the domain. Through his work, Rockt&#228;schel plays a vital role in advancing the understanding and application of AI technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MODEL-AGNOSTIC META-LEARNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Model-agnostic meta-learning is a method for fast adaptation of deep networks.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="AMAN MADAAN">
      <data key="d0">PERSON</data>
      <data key="d1">Aman Madaan is a researcher focused on program-aided language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GETTING 50% SOTA ON ARC-AGI WITH GPT-4">
      <data key="d0">RESEARCH</data>
      <data key="d1">Getting 50% SOTA on ARC-AGI with GPT-4 is a study focused on achieving state-of-the-art performance using the GPT-4 model.Getting 50% SOTA on ARC-AGI with GPT-4 is a study focused on achieving state-of-the-art performance using the GPT-4 model.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">RESEARCH</data>
    </node>
    <node id="RYAN GREENBLATT">
      <data key="d0">PERSON</data>
      <data key="d1">Ryan Greenblatt is a researcher who authored a technical report on achieving state-of-the-art performance with GPT-4 in July 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DAN HENDRYCKS">
      <data key="d0">PERSON</data>
      <data key="d1">Dan Hendrycks is a prominent researcher recognized for his contributions to the field of mathematical problem-solving capabilities. He has co-authored a significant paper on measuring massive multitask language understanding, which was presented at the International Conference on Learning Representations in 2021. His work highlights the intersection of mathematical reasoning and language processing, underscoring his expertise in both areas within the broader context of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="COLLIN BURNS">
      <data key="d0">PERSON</data>
      <data key="d1">Collin Burns is a researcher with a focus on measuring mathematical problem-solving capabilities. He has also co-authored a significant paper on measuring massive multitask language understanding, which was presented at the International Conference on Learning Representations in 2021. This dual expertise highlights his contributions to both mathematical and linguistic domains, showcasing his involvement in advancing research in these critical areas.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="STEVEN BASART">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Basart is a researcher recognized for his contributions to the field of language understanding and mathematical problem-solving. He co-authored a paper on measuring massive multitask language understanding, which was presented at the International Conference on Learning Representations in 2021. Additionally, he has made significant contributions to the assessment of mathematical problem-solving capabilities, further highlighting his expertise in evaluating complex cognitive tasks within the realms of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ANDY ZOU">
      <data key="d0">PERSON</data>
      <data key="d1">Andy Zou is a researcher who co-authored a paper on measuring massive multitask language understanding presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MANTAS MAZEIKA">
      <data key="d0">PERSON</data>
      <data key="d1">Mantas Mazeika is a researcher who co-authored a paper on measuring massive multitask language understanding presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DAWN SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Dawn Song is a prominent researcher in the field of Artificial Intelligence, particularly focusing on the intricacies of language models. She has engaged in critical discussions regarding the limitations of imitating proprietary language models, highlighting the challenges and ethical considerations in this area. Additionally, she co-authored a significant paper on measuring massive multitask language understanding, which was presented at the International Conference on Learning Representations in 2021. This work underscores her contributions to advancing the understanding of language processing capabilities within the AI community.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JACOB STEINHARDT">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Steinhardt is a researcher who co-authored a paper on measuring massive multitask language understanding presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SIRUI HONG">
      <data key="d0">PERSON</data>
      <data key="d1">Sirui Hong is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="XIAWU ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiawu Zheng is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JONATHAN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Chen is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YUHENG CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuheng Cheng is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JINLIN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jinlin Wang is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CEYAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ceyao Zhang is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZILI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zili Wang is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="STEVEN KA SHING YAU">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Ka Shing Yau is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZIJUAN LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Zijuan Lin is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LIYANG ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Liyang Zhou is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHICHAO LU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhichao Lu is a prominent researcher in the field of artificial intelligence, particularly known for his contributions to neural architecture search and algorithm design. He co-authored a paper on neural architecture search utilizing genetic algorithms, showcasing his expertise in optimizing AI models. Additionally, he contributed to a significant paper presented at the International Conference on Machine Learning in 2024, which focused on the evolution of heuristics for efficient automatic algorithm design using large language models. Furthermore, in 2021, he co-authored a paper that explored methods for accelerating multi-objective neural architecture search through random-weight evaluation. Collectively, these works highlight Zhichao Lu's active engagement in advancing methodologies that enhance the efficiency and effectiveness of AI systems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VISHNU NARESH BODDETI">
      <data key="d0">PERSON</data>
      <data key="d1">Vishnu Naresh Boddeti is a researcher who co-authored a paper on revisiting residual networks for adversarial robustness, presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LARS KOTTHOFF">
      <data key="d0">PERSON</data>
      <data key="d1">Lars Kotthoff is a researcher who co-authored a book on automated machine learning, discussing methods, systems, and challenges, published in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JOAQUIN VANSCHOREN">
      <data key="d0">PERSON</data>
      <data key="d1">Joaquin Vanschoren is a researcher who co-authored a book on automated machine learning, discussing methods, systems, and challenges, published in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="OMAR KHATTAB">
      <data key="d0">PERSON</data>
      <data key="d1">Omar Khattab is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ARNAV SINGHVI">
      <data key="d0">PERSON</data>
      <data key="d1">Arnav Singhvi is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PARIDHI MAHESHWARI">
      <data key="d0">PERSON</data>
      <data key="d1">Paridhi Maheshwari is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHIZHUAN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Zhang is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="KESHAV SANTHANAM">
      <data key="d0">PERSON</data>
      <data key="d1">Keshav Santhanam is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SAIFUL HAQ">
      <data key="d0">PERSON</data>
      <data key="d1">Saiful Haq is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ASHUTOSH SHARMA">
      <data key="d0">PERSON</data>
      <data key="d1">Ashutosh Sharma is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="THOMAS T JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas T Joshi is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HANNA MOAZAM">
      <data key="d0">PERSON</data>
      <data key="d1">Hanna Moazam is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HEATHER MILLER">
      <data key="d0">PERSON</data>
      <data key="d1">Heather Miller is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEX KRIZHEVSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Krizhevsky is a researcher known for his work on ImageNet classification using deep convolutional neural networks, published in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ILYAS SUTSKEVER">
      <data key="d0">PERSON</data>
      <data key="d1">Ilya Sutskever is a researcher known for his work on ImageNet classification using deep convolutional neural networks, published in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="GEOFFREY HINTON">
      <data key="d0">PERSON</data>
      <data key="d1">Geoffrey Hinton is a researcher known for his work on ImageNet classification using deep convolutional neural networks, published in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ABRAHIM LADHA">
      <data key="d0">PERSON</data>
      <data key="d1">Abrahim Ladha is a researcher who authored a lecture on Turing-completeness, available online in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LANGCHAINAI">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">LangChainAI is an organization that focuses on building context-aware reasoning applications, with resources available on GitHub since 2022.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="KENNETH O STANLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Kenneth O. Stanley is a prominent researcher known for his contributions to the fields of planning and evolutionary theory. He authored a book that explores the myth of objectivity in planning, challenging conventional perspectives on decision-making processes. Additionally, he co-authored a significant paper in 2011 that discusses the concept of evolution driven solely by the search for novelty, highlighting his innovative approach to understanding evolutionary dynamics. Through these works, Stanley has established himself as a thought leader in his areas of expertise, influencing both academic discourse and practical applications.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PATRICK LEWIS">
      <data key="d0">PERSON</data>
      <data key="d1">Patrick Lewis is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ETHAN PEREZ">
      <data key="d0">PERSON</data>
      <data key="d1">Ethan Perez is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEKSANDRA PIKTUS">
      <data key="d0">PERSON</data>
      <data key="d1">Aleksandra Piktus is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FABIO PETRONI">
      <data key="d0">PERSON</data>
      <data key="d1">Fabio Petroni is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VLADIMIR KARPUKHIN">
      <data key="d0">PERSON</data>
      <data key="d1">Vladimir Karpukhin is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HEINRICH K&#220;TTLER">
      <data key="d0">PERSON</data>
      <data key="d1">Heinrich K&#252;ttler is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MIKE LEWIS">
      <data key="d0">PERSON</data>
      <data key="d1">Mike Lewis is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="WEN-TAU YIH">
      <data key="d0">PERSON</data>
      <data key="d1">Wen-tau Yih is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FEI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Fei Liu is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="TONG XIALIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Tong Xialiang is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MINGXUAN YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Mingxuan Yuan is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="XI LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Xi Lin is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FU LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Fu Luo is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHENKUN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhenkun Wang is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="QINGFU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Qingfu Zhang is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZIJUN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zijun Liu is a researcher who co-authored a paper on dynamic LLM-agent networks, which focuses on collaboration frameworks with agent team optimization, presented as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YANZHE ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yanzhe Zhang is a researcher who co-authored a paper on dynamic LLM-agent networks, which focuses on collaboration frameworks with agent team optimization, presented as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Peng Li is a researcher who co-authored a paper on dynamic LLM-agent networks, which focuses on collaboration frameworks with agent team optimization, presented as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YANG LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Yang Liu is a researcher who co-authored a paper on dynamic LLM-agent networks, which focuses on collaboration frameworks with agent team optimization, presented as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DIYI YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Diyi Yang is a researcher who co-authored a paper on dynamic LLM-agent networks, which focuses on collaboration frameworks with agent team optimization, presented as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CHRIS LU">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Lu is a researcher who co-authored a paper on arbitrary order meta-learning with simple population-based evolution, presented at the 2023 Artificial Life Conference.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SEBASTIAN TOWERS">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Towers is a researcher who co-authored a paper on arbitrary order meta-learning with simple population-based evolution, presented at the 2023 Artificial Life Conference.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JAKOB FOERSTER">
      <data key="d0">PERSON</data>
      <data key="d1">Jakob Foerster is a researcher who co-authored a paper on arbitrary order meta-learning with simple population-based evolution, presented at the 2023 Artificial Life Conference.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CLAUDIO FANCONI">
      <data key="d0">PERSON</data>
      <data key="d1">Claudio Fanconi is a researcher who co-authored a paper on discovering preference optimization algorithms with large language models, presented as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEX J CHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Alex J Chan is a researcher who co-authored a paper on discovering preference optimization("entity"</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="META PROGRAMMING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Meta programming refers to programming techniques that allow for the creation of programs that can manipulate other programs, as explored in the context of multi-agent collaboration in the MetaGPT paper.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="THOUGHT CLONING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Thought Cloning is a method that involves learning to think while acting by imitating human cognitive processes, as discussed in a paper by Shengran Hu and Jeff Clune in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUTOMATED MACHINE LEARNING">
      <data key="d0">FIELD</data>
      <data key="d1">Automated machine learning encompasses methods and systems designed to automate the process of applying machine learning to real-world problems, as discussed in a book by Frank Hutter and others in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="IMAGE CLASSIFICATION">
      <data key="d0">FIELD</data>
      <data key="d1">Image classification is a computer vision task that involves categorizing images into predefined classes, as exemplified by the work of Alex Krizhevsky and others in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="TURING-COMPLETENESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Turing-completeness is a concept in computer science that describes a system capable of performing any computation that can be described algorithmically, as discussed in Abrahim Ladha's lecture in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="EVOLUTIONARY COMPUTATION">
      <data key="d0">FIELD</data>
      <data key="d1">Evolutionary computation is a subset of artificial intelligence that involves algorithms inspired by natural selection, as discussed in the work of Joel Lehman and Kenneth O Stanley in 2011.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MULTI-OBJECTIVE OPTIMIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-objective optimization is a sophisticated technique that focuses on optimizing two or more conflicting objectives at the same time. This approach is particularly relevant in fields such as neural architecture search and complex decision-making scenarios. It is commonly implemented in various algorithms, including genetic algorithms, and is notably discussed in the context of NSGA-Net. By addressing multiple objectives simultaneously, multi-objective optimization enables more nuanced and effective solutions in complex problem spaces, making it a vital tool in the realms of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AGENT TEAM OPTIMIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Agent team optimization refers to strategies aimed at improving the performance and collaboration of multiple agents working together, as discussed in the context of dynamic LLM-agent networks.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HUMAN-COMPUTER INTERACTION">
      <data key="d0">FIELD</data>
      <data key="d1">Human-computer interaction is a field of study focused on the design and use of computer technology, emphasizing the interfaces between people and computers, relevant to many of the discussed techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUTOMATED DESIGN">
      <data key="d0">FIELD</data>
      <data key="d1">Automated Design refers to the application of algorithms and artificial intelligence to generate designs or solutions autonomously, without the need for human intervention. This concept is particularly relevant in the context of agentic systems, where automated design leverages computational methods to streamline the design process across various fields, including engineering and software development. By integrating these advanced technologies, Automated Design enhances efficiency and innovation in creating complex systems and solutions.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="KNOWLEDGE-INTENSIVE TASKS">
      <data key="d0">FIELD</data>
      <data key="d1">Knowledge-intensive tasks are tasks that require a significant amount of domain-specific knowledge, often addressed through advanced NLP techniques like retrieval-augmented generation.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="COLLABORATIVE FRAMEWORK">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Collaborative frameworks are systems designed to facilitate cooperation among multiple agents or entities, enhancing their collective performance and decision-making capabilities.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="STATE-OF-THE-ART PIPELINES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">State-of-the-art pipelines refer to the most advanced and effective processes or systems used in machine learning and data processing, as discussed in the context of DSpy.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CROSS-VALIDATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Cross-validation is a statistical method used to estimate the skill of machine learning models, ensuring that they generalize well to unseen data.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DATA AUGMENTATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Data augmentation involves creating new training examples by modifying existing data, enhancing the robustness and performance of machine learning models.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="NATURAL LANGUAGE PROCESSING">
      <data key="d0">FIELD</data>
      <data key="d1">Natural language processing is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language, encompassing various techniques and applications.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="COMPUTER VISION">
      <data key="d0">FIELD</data>
      <data key="d1">Computer vision is a field of artificial intelligence that enables computers to interpret and make decisions based on visual data from the world, relevant to many discussed techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MULTI-AGENT SYSTEMS">
      <data key="d0">FIELD</data>
      <data key="d1">Multi-agent systems are composed of multiple agents that interact or collaborate to achieve a common goal. These systems are particularly relevant in the context of discussions surrounding MetaGPT and dynamic LLM-agent networks. They serve as a significant area of study within AI research, focusing on the dynamics of collaboration and communication among agents. Through the exploration of these interactions, multi-agent systems provide valuable insights into how agents can effectively work together, enhancing the understanding of cooperative behaviors in artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUTOMATED DECISION-MAKING">
      <data key="d0">FIELD</data>
      <data key="d1">Automated decision-making refers to the process of using algorithms and data to make decisions without human intervention, relevant to many of the discussed techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DATA SCIENCE">
      <data key="d0">FIELD</data>
      <data key="d1">Data science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="COMPUTATIONAL INTELLIGENCE">
      <data key="d0">FIELD</data>
      <data key="d1">Computational intelligence is a field of study that focuses on the design of intelligent agents and systems that can solve complex problems through adaptive learning and reasoning.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALGORITHMIC DESIGN">
      <data key="d0">FIELD</data>
      <data key="d1">Algorithmic design refers to the process of creating algorithms to solve specific problems, often involving optimization and efficiency considerations.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SYSTEMS ENGINEERING">
      <data key="d0">FIELD</data>
      <data key="d1">Systems engineering is an interdisciplinary field that focuses on the design, integration, and management of complex systems over their life cycles.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DECISION SUPPORT SYSTEMS">
      <data key="d0">FIELD</data>
      <data key="d1">Decision support systems are computer-based information systems that support business or organizational decision-making activities.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DATA MINING">
      <data key="d0">FIELD</data>
      <data key="d1">Data mining is the process of discovering patterns and knowledge from large amounts of data, often used in conjunction with machine learning techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="BIG DATA">
      <data key="d0">FIELD</data>
      <data key="d1">Big data refers to large and complex data sets that traditional data processing applications cannot handle, often requiring advanced analytical techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CLOUD COMPUTING">
      <data key="d0">FIELD</data>
      <data key="d1">Cloud computing is the delivery of computing services over the internet, allowing for on-demand access to a shared pool of configurable resources.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PREDICTIVE ANALYTICS">
      <data key="d0">FIELD</data>
      <data key="d1">Predictive analytics involves using statistical algorithms and machine learning techniques to identify the likelihood of future outcomes based on historical data.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="STATISTICAL LEARNING">
      <data key="d0">FIELD</data>
      <data key="d1">Statistical learning is a framework for understanding and modeling the relationships between variables, often used in machine learning and data analysis.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="EXPLORATORY DATA ANALYSIS">
      <data key="d0">FIELD</data>
      <data key="d1">Exploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often using visual methods.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="INTERACTIVE SYSTEMS">
      <data key="d0">FIELD</data>
      <data key="d1">Interactive systems are systems designed to facilitate user interaction, often incorporating feedback mechanisms to enhance user experience.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="USER EXPERIENCE DESIGN">
      <data key="d0">FIELD</data>
      <data key="d1">User experience design is the process of enhancing user satisfaction by improving the usability, accessibility, and pleasure provided in the interaction with a product.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SOFTWARE ENGINEERING">
      <data key="d0">FIELD</data>
      <data key="d1">Software engineering is the application of engineering principles to software development in a methodical way, encompassing the entire software development life cycle.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DEVOPS">
      <data key="d0">FIELD</data>
      <data key="d1">DevOps is a set of practices that combines software development (Dev) and IT operations (Ops) to shorten the systems development life cycle and provide continuous delivery.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="BLOCKCHAIN">
      <data key="d0">FIELD</data>
      <data key="d1">Blockchain is a decentralized digital ledger technology that records transactions across many computers in a way that the registered transactions cannot be altered retroactively.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="QUANTUM COMPUTING">
      <data key="d0">FIELD</data>
      <data key="d1">Quantum computing is a type of computation that takes advantage of quantum mechanics to process information in fundamentally different ways than classical computers.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="NEUROMORPHIC COMPUTING">
      <data key="d0">FIELD</data>
      <data key="d1">Neuromorphic computing is a design approach that mimics the neural structure and functioning of the human brain to improve computational efficiency and performance.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUTONOMOUS SYSTEMS">
      <data key="d0">FIELD</data>
      <data key="d1">Autonomous systems are systems capable of performing tasks without human intervention, often utilizing AI and machine learning for decision-making.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="INTERNET OF THINGS">
      <data key="d0">FIELD</data>
      <data key="d1">The Internet of Things (IoT) refers to the interconnected network of physical devices that communicate and exchange data over the internet, often utilizing AI for data analysis and decision-making.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VIRTUAL REALITY">
      <data key="d0">FIELD</data>
      <data key="d1">Virtual reality is a simulated experience that can be similar to or completely different from the real world, often used in gaming, training, and education.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUGMENTED REALITY">
      <data key="d0">FIELD</data>
      <data key="d1">Augmented reality is an interactive experience where real-world environments are enhanced by computer-generated perceptual information, often used in applications like gaming and education.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MACHINE VISION">
      <data key="d0">FIELD</data>
      <data key="d1">Machine vision is the technology and methods used to provide imaging-based automatic inspection and analysis for process control and robot guidance.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SENSOR NETWORKS">
      <data key="d0">FIELD</data>
      <data key="d1">Sensor networks are networks of spatially distributed sensors that monitor physical or environmental conditions, often used in IoT applications.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CYBERSECURITY">
      <data key="d0">FIELD</data>
      <data key="d1">Cybersecurity is the practice of protecting systems, networks, and programs from digital attacks, often involving various technologies and strategies.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DATA PRIVACY">
      <data key="d0">FIELD</data>
      <data key="d1">Data privacy refers to the proper handling, processing, storage, and usage of personal data, ensuring that individuals' privacy rights are respected.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ETHICAL AI">
      <data key="d0">FIELD</data>
      <data key="d1">Ethical AI refers to the development and implementation of artificial intelligence systems that adhere to ethical principles and guidelines, ensuring fairness, accountability, and transparency.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AI GOVERNANCE">
      <data key="d0">FIELD</data>
      <data key="d1">AI governance involves the frameworks and policies that guide the development and use of AI technologies, ensuring they are used responsibly and ethically.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SUSTAINABLE TECHNOLOGY">
      <data key="d0">FIELD</data>
      <data key="d1">Sustainable technology refers to technologies that are designed to have a minimal impact on the environment, promoting sustainability and reducing resource consumption.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CIRCULAR ECONOMY">
      <data key="d0">FIELD</data>
      <data key="d1">Circular economy is an economic system aimed at eliminating waste and the continual use of resources, often involving innovative technologies and practices.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="GREEN TECHNOLOGY">
      <data key="d0">FIELD</data>
      <data key="d1">Green technology refers to technology that is environmentally friendly and sustainable, often focusing on renewable energy and resource efficiency.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SMART CITIES">
      <data key="d0">FIELD</data>
      <data key="d1">Smart cities are urban areas that use various types of electronic data collection sensors to supply information used to manage assets and resources efficiently.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DIGITAL TRANSFORMATION">
      <data key="d0">FIELD</data>
      <data key="d1">Digital transformation refers to the integration of digital technology into all areas of a business, fundamentally changing how it operates and delivers value to customers.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="INDUSTRY 4.0">
      <data key="d0">FIELD</data>
      <data key="d1">Industry 4.0 refers to the current trend of automation and data exchange in manufacturing technologies, including cyber-physical systems, IoT, and cloud computing.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AGRICULTURAL TECHNOLOGY">
      <data key="d0">FIELD</data>
      <data key="d1">Agricultural technology refers to the use of technology in agriculture to improve yield, efficiency, and sustainability, often involving precision farming techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FINTECH">
      <data key="d0">FIELD</data>
      <data key="d1">Fintech refers to technology that aims to improve and automate the delivery and use of financial services, often involving innovative solutions for banking and payments.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HEALTH TECH">
      <data key="d0">FIELD</data>
      <data key="d1">Health tech refers to technology that aims to improve health and healthcare delivery, often involving digital health solutions and medical devices.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="EDTECH">
      <data key="d0">FIELD</data>
      <data key="d1">Edtech refers to technology that enhances education and learning experiences, often involving online learning platforms and educational software.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MOBILITY TECHNOLOGY">
      <data key="d0">FIELD</data>
      <data key="d1">Mobility technology refers to technology that enhances transportation and mobility solutions, often involving smart transportation systems and electric vehicles.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SPACE TECHNOLOGY">
      <data key="d0">FIELD</data>
      <data key="d1">Space technology refers to the technology used in the exploration and utilization of outer space, often involving advanced engineering and scientific research.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AEROSPACE ENGINEERING">
      <data key="d0">FIELD</data>
      <data key="d1">Aerospace engineering is the branch of engineering that deals with the design, development, and production of aircraft and spacecraft.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ROBOTIC PROCESS AUTOMATION">
      <data key="d0">FIELD</data>
      <data key="d1">Robotic process automation refers to the use of software robots to automate repetitive tasks, improving efficiency and accuracy in business processes.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="QUANTUM MACHINE LEARNING">
      <data key="d0">FIELD</data>
      <data key="d1">Quantum machine learning is an interdisciplinary field that combines quantum computing and machine learning, exploring how quantum algorithms can enhance machine learning tasks.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="BIOINFORMATICS">
      <data key="d0">FIELD</data>
      <data key="d1">Bioinformatics is an interdisciplinary field that develops methods and software tools for understanding biological data, particularly in genomics and molecular biology.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="NEUROSCIENCE">
      <data key="d0">FIELD</data>
      <data key="d1">Neuroscience is the scientific study of the nervous system, often intersecting with fields like artificial intelligence and cognitive science.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="COGNITIVE SCIENCE">
      <data key="d0">FIELD</data>
      <data key="d1">Cognitive science is the interdisciplinary study of the mind and its processes, including how people think, learn, and remember.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SOCIAL ROBOTICS">
      <data key="d0">FIELD</data>
      <data key="d1">Social robotics is a field of study focused on the design and development of robots that can interact with humans in a social context.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HUMAN-ROBOT INTERACTION">
      <data key="d0">FIELD</data>
      <data key="d1">Human-robot interaction is the study of how humans and robots communicate and collaborate, often focusing on improving user experience and effectiveness.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VIRTUAL ASSISTANTS">
      <data key="d0">FIELD</data>
      <data key="d1">Virtual assistants are AI-powered software agents that can perform tasks or services for individuals based on commands or questions.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CHATBOTS">
      <data key="d0">FIELD</data>
      <data key="d1">Chatbots are AI programs that simulate</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="IAN WHALEN">
      <data key="d0">PERSON</data>
      <data key="d1">Ian Whalen is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="VISHNU BODDETI">
      <data key="d0">PERSON</data>
      <data key="d1">Vishnu Boddeti is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="YASHESH DHEBAR">
      <data key="d0">PERSON</data>
      <data key="d1">Yashesh Dhebar is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ERIK GOODMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Erik Goodman is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="WOLFGANG BANZHAF">
      <data key="d0">PERSON</data>
      <data key="d1">Wolfgang Banzhaf is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="YECHENG JASON MA">
      <data key="d0">PERSON</data>
      <data key="d1">Yecheng Jason Ma is a researcher who co-authored a paper on human-level reward design using large language models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="WILLIAM LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">William Liang is a researcher who co-authored a paper on human-level reward design using large language models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="OSBERT BASTANI">
      <data key="d0">PERSON</data>
      <data key="d1">Osbert Bastani is a researcher who co-authored a paper on human-level reward design using large language models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="DINESH JAYARAMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Dinesh Jayaraman is a researcher who co-authored a paper on human-level reward design using large language models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ELLIOT MEYERSON">
      <data key="d0">PERSON</data>
      <data key="d1">Elliot Meyerson is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="MARK J NELSON">
      <data key="d0">PERSON</data>
      <data key="d1">Mark J Nelson is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="HERBIE BRADLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Herbie Bradley is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ADAM GAIER">
      <data key="d0">PERSON</data>
      <data key="d1">Adam Gaier is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ARASH MORADI">
      <data key="d0">PERSON</data>
      <data key="d1">Arash Moradi is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AMY K HOOVER">
      <data key="d0">PERSON</data>
      <data key="d1">Amy K Hoover is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="JEAN-BAPTISTE MOURET">
      <data key="d0">PERSON</data>
      <data key="d1">Jean-Baptiste Mouret is a researcher who co-authored a paper on mapping elites in search spaces.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="JEFF WU">
      <data key="d0">PERSON</data>
      <data key="d1">Jeff Wu is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="LONG OUYANG">
      <data key="d0">PERSON</data>
      <data key="d1">Long Ouyang is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="CHRISTINA KIM">
      <data key="d0">PERSON</data>
      <data key="d1">Christina Kim is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="WILLIAM SAUNDERS">
      <data key="d0">PERSON</data>
      <data key="d1">William Saunders is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="GENERIC AGENTS">
      <data key="d0">RESEARCH</data>
      <data key="d1">Generative agents are interactive models that simulate human behavior, as discussed in a paper by Joon Sung Park and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="JOON SUNG PARK">
      <data key="d0">PERSON</data>
      <data key="d1">Joon Sung Park is a researcher who co-authored a paper on generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="JOSEPH O&#8217;BRIEN">
      <data key="d0">PERSON</data>
      <data key="d1">Joseph O&#8217;Brien is a researcher who co-authored a paper on generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="CARRIE JUN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Carrie Jun Cai is a researcher who co-authored a paper on generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="MEREDITH RINGEL MORRIS">
      <data key="d0">PERSON</data>
      <data key="d1">Meredith Ringel Morris is a researcher who co-authored a paper on generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="PERCY LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Percy Liang is a prominent researcher in the field of Artificial Intelligence, particularly focused on the development of communicative agents that facilitate the exploration of large language model societies. His contributions include co-authoring significant papers, one of which addresses an automatic evaluator designed for instruction-following models, and another that delves into the realm of generative agents. Through his work, Liang plays a crucial role in advancing the understanding and capabilities of AI systems, particularly in enhancing their communicative and generative functionalities.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MICHAEL S BERNSTEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Michael S Bernstein is a researcher who co-authored a paper on generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="LANGUAGE MODEL CROSSOVER">
      <data key="d0" />
      <data key="d1">Language model crossover is a technique that explores variations in language models through few-shot prompting, as discussed in a paper by Elliot Meyerson and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH</data>
    </node>
    <node id="ILLUMINATING SEARCH SPACES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="BROWSER-ASSISTED QUESTION-ANSWERING">
      <data key="d0" />
      <data key="d1">Browser-assisted question-answering is a technique that combines web browsing capabilities with question-answering systems to enhance information retrieval, as discussed in the context of WebGPT.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="NSGA-NET">
      <data key="d0">RESEARCH</data>
      <data key="d1">NSGA-Net is a method for neural architecture search using a multi-objective genetic algorithm, as discussed in a paper by Zhichao Lu and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="TOOL LEARNING">
      <data key="d0">RESEARCH</data>
      <data key="d1">Tool learning with large language models is a survey discussing how LLMs can learn to use tools effectively, as discussed in a paper by Changle Qu and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="COMMUNICATIVE AGENTS">
      <data key="d0">RESEARCH</data>
      <data key="d1">The entity "COMMUNICATIVE AGENTS" refers to models specifically designed to assist in software development through enhanced communication. This concept is elaborated in a paper by Chen Qian and colleagues, highlighting the role of communicative agents in facilitating interactions and collaboration within the software development process. These agents aim to improve the efficiency and effectiveness of communication among developers, thereby contributing to better project outcomes.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SCALING MULTI-AGENT COLLABORATION">
      <data key="d0">RESEARCH</data>
      <data key="d1">Scaling large-language-model-based multi-agent collaboration refers to research on enhancing collaboration among multiple agents using large language models, as discussed in a paper by Chen Qian and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="DIRECT PREFERENCE OPTIMIZATION">
      <data key="d0">RESEARCH</data>
      <data key="d1">Direct Preference Optimization is a method that enhances the performance of language models by treating them as reward models. This approach aims to optimize preferences in the outputs generated by these models. The concept is elaborated in a paper authored by Rafael Rafailov and colleagues, highlighting its significance in improving the efficacy of language models in various applications. By focusing on the alignment of model outputs with user preferences, Direct Preference Optimization represents a crucial advancement in the field of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The Genetic and Evolutionary Computation Conference is an academic conference where research related to genetic algorithms and evolutionary computation is presented, including work by Zhichao Lu and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The Twelfth International Conference on Learning Representations is an academic conference focused on machine learning and representation learning, where research by Yecheng Jason Ma and others was presented.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ASSOCIATION FOR COMPUTATIONAL LINGUISTICS">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The Association for Computational Linguistics is a professional organization that promotes research and education in computational linguistics, associated with various conferences and publications.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The ACM Symposium on User Interface Software and Technology is a conference focused on user interface software and technology, where research by Joon Sung Park and others was presented.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="FEW-SHOT PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Few-shot prompting is a technique in which a model is given a few examples to learn from in order to perform a task, as discussed in the context of language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ITERATIVE REFINEMENT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Iterative refinement is a process of gradually improving a model's performance through repeated adjustments, as discussed in the context of self-refine.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="HUMAN FEEDBACK">
      <data key="d0">CONCEPT</data>
      <data key="d1">Human feedback refers to the input provided by users to improve the performance of AI systems, particularly in the context of training models like WebGPT.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="META">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Meta is a technology company known for its work in social media and artificial intelligence, including initiatives related to open-source AI.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="GENETIC ALGORITHMS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Genetic algorithms are optimization algorithms inspired by the process of natural selection, used in various research contexts including NSGA-Net.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="REWARD DESIGN">
      <data key="d0">CONCEPT</data>
      <data key="d1">Reward design involves creating reward structures for training AI models, particularly in reinforcement learning contexts, as discussed in the context of Eureka.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="MATH WORD PROBLEMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Math word problems are problems that require mathematical reasoning to solve, relevant to the research on evaluating and developing solvers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="LANGUAGE MODELING">
      <data key="d0">FIELD</data>
      <data key="d1">Language modeling is a field of study focused on predicting the next word in a sequence, foundational to many AI applications including chatbots and text generation.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="INTERACTIVE SIMULACRA">
      <data key="d0">CONCEPT</data>
      <data key="d1">Interactive simulacra refer to models that simulate human behavior in an interactive manner, as discussed in the context of generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="HUMAN-LEVEL AI">
      <data key="d0">CONCEPT</data>
      <data key="d1">Human-level AI refers to artificial intelligence systems that can perform tasks at a level comparable to human intelligence, a goal of many research efforts.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="NEURAL NETWORKS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Neural networks are computational models inspired by the human brain, widely used in AI for tasks such as image and speech recognition.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="NLP MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">NLP models are models designed for natural language processing tasks, relevant to many discussions in the context of AI research.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="MULTI-OBJECTIVE GENETIC ALGORITHM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-objective genetic algorithms are optimization techniques that evolve solutions to optimize multiple objectives simultaneously, as discussed in the context of NSGA-Net.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="HUMAN-CENTERED AI">
      <data key="d0">CONCEPT</data>
      <data key="d1">Human-centered AI refers to the design and implementation of AI systems that prioritize human needs and values, relevant to discussions on AI ethics and usability.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AUTOMATED SCIENTIFIC DISCOVERY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Automated scientific discovery refers to the use of AI and algorithms to conduct scientific research and make discoveries without human intervention.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="RESEARCH COLLABORATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research collaboration refers to the joint effort of researchers to achieve common goals, often seen in the co-authorship of papers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="TECHNICAL REPORT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A technical report is a document that describes the process, progress, or results of technical or scientific research, often published by organizations like OpenAI.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="PREPRINT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A preprint is a version of a scholarly paper that precedes formal peer review and publication in a scientific journal, often shared on platforms like arXiv.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="PAPER">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A paper is a written work that presents original research findings, often published in academic journals or presented at conferences.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="RESEARCH PAPER">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A research paper is a detailed document that presents the results of original research, typically peer-reviewed and published in academic journals.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="TECHNOLOGY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Technology refers to the application of scientific knowledge for practical purposes, especially in industry and research.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AUTOMATED SYSTEMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Automated systems are systems that operate automatically with minimal human intervention, often used in various applications including manufacturing and AI.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="RESEARCH FINDINGS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research findings are the results or conclusions drawn from scientific studies, often published in academic papers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="DATASETS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Datasets are collections of data used for training and testing AI models, crucial for the development of machine learning algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="RESEARCH INITIATIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research initiatives are organized efforts to conduct research in specific areas, often involving collaboration among multiple researchers or institutions.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="RESEARCH NETWORKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research networks are collaborative groups of researchers and institutions that work together to advance knowledge in specific fields.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI FUTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The future of AI refers to the anticipated developments and impacts of artificial intelligence technologies on society and various industries.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI RESEARCH COMMUNITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">The AI research community encompasses researchers, practitioners, and organizations involved in the study and development of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI POLICY">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI policy refers to the guidelines and regulations governing the development and use of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI ETHICS COMMITTEES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">AI ethics committees are groups formed to address ethical considerations in the development and deployment of AI technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI RESEARCH FUNDING">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI research funding refers to financial support provided for research projects in the field of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI STARTUPS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI startups are new companies focused on developing innovative artificial intelligence technologies and applications.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI INVESTMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI investment refers to the allocation of financial resources towards the development and commercialization of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI CONSULTING">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI consulting involves providing expert advice and services related to the implementation and use of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI RESEARCH LABS">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">AI research labs are specialized facilities dedicated to conducting research and development in the field of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI CONFERENCES">
      <data key="d0">EVENT</data>
      <data key="d1">AI conferences are events where researchers and practitioners gather to share knowledge and advancements in artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI SYMPOSIUMS">
      <data key="d0">EVENT</data>
      <data key="d1">AI symposiums are formal meetings or conferences focused on discussing specific topics in artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI WORKSHOPS">
      <data key="d0">EVENT</data>
      <data key="d1">AI workshops are interactive sessions where participants engage in hands-on learning and discussions about artificial intelligence topics.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI SEMINARS">
      <data key="d0">EVENT</data>
      <data key="d1">AI seminars are educational sessions focused on specific aspects of artificial intelligence, often featuring expert speakers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI WEBINARS">
      <data key="d0">EVENT</data>
      <data key="d1">AI webinars are online seminars that provide information and discussions on various artificial intelligence topics.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI PODCASTS">
      <data key="d0">MEDIA</data>
      <data key="d1">AI podcasts are audio programs that discuss topics related to artificial intelligence, featuring interviews and expert insights.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI BLOGS">
      <data key="d0">MEDIA</data>
      <data key="d1">AI blogs are online platforms where articles and discussions about artificial intelligence are published.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI NEWSLETTERS">
      <data key="d0">MEDIA</data>
      <data key="d1">AI newsletters are periodic publications that provide updates and insights on developments in the field of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI REPORTS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">AI reports are comprehensive documents that analyze trends, challenges, and advancements in artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI WHITE PAPERS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">AI white papers are authoritative reports that provide detailed information on specific topics in artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI CASE STUDIES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">AI case studies are detailed analyses of specific applications or implementations of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI SURVEYS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">AI surveys are research studies that gather data and insights on various aspects of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI ANALYTICS">
      <data key="d0">FIELD</data>
      <data key="d1">AI analytics refers to the use of artificial intelligence techniques to analyze data and extract insights.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI METRICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI metrics are standards used to measure the performance and effectiveness of artificial intelligence systems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI BENCHMARKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI benchmarks are reference points used</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="QIANG WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Qiang Wang is a researcher who co-authored a survey on tool learning with large language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DAWEI YIN">
      <data key="d0">PERSON</data>
      <data key="d1">Dawei Yin is a researcher who co-authored a survey on tool learning with large language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JUN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Jun Xu is a researcher who co-authored a survey on tool learning with large language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JI-RONG WEN">
      <data key="d0">PERSON</data>
      <data key="d1">Ji-Rong Wen is a prominent researcher recognized for his contributions to the field of Artificial Intelligence, particularly in the context of large language models. He has co-authored significant surveys that explore critical aspects of these models, including their memory mechanisms and the process of tool learning. Through his work, Ji-Rong Wen has helped to advance the understanding of how large language model-based agents operate and interact with various tools, thereby enhancing the knowledge base within the AI research community.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RAFAEL RAFAILOV">
      <data key="d0">PERSON</data>
      <data key="d1">Rafael Rafailov is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARCHIT SHARMA">
      <data key="d0">PERSON</data>
      <data key="d1">Archit Sharma is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ERIC MITCHELL">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Mitchell is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHRISTOPHER D MANNING">
      <data key="d0">PERSON</data>
      <data key="d1">Christopher D Manning is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="STEFANO ERMON">
      <data key="d0">PERSON</data>
      <data key="d1">Stefano Ermon is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DAVID REIN">
      <data key="d0">PERSON</data>
      <data key="d1">David Rein is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BETTY LI HOU">
      <data key="d0">PERSON</data>
      <data key="d1">Betty Li Hou is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ASA COOPER STICKLAND">
      <data key="d0">PERSON</data>
      <data key="d1">Asa Cooper Stickland is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JACKSON PETTY">
      <data key="d0">PERSON</data>
      <data key="d1">Jackson Petty is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RICHARD YUANZHE PANG">
      <data key="d0">PERSON</data>
      <data key="d1">Richard Yuanzhe Pang is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JULIEN DIRANI">
      <data key="d0">PERSON</data>
      <data key="d1">Julien Dirani is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JULIAN MICHAEL">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Michael is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SAMUEL R BOWMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Samuel R. Bowman is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TORAN BRUCE RICHARDS">
      <data key="d0">PERSON</data>
      <data key="d1">Toran Bruce Richards is a researcher who developed AutoGPT, a GitHub repository.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MD OMAR FARUK ROKON">
      <data key="d0">PERSON</data>
      <data key="d1">Md Omar Faruk Rokon is a researcher who co-authored a paper on malware source code detection.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RISUL ISLAM">
      <data key="d0">PERSON</data>
      <data key="d1">Risul Islam is a researcher who co-authored a paper on malware source code detection.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AHMAD DARKI">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmad Darki is a researcher who co-authored a paper on malware source code detection.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="EVANGELOS E PAPALEXAKIS">
      <data key="d0">PERSON</data>
      <data key="d1">Evangelos E Papalexakis is a researcher who co-authored a paper on malware source code detection.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MICHAELIS FALOUTSOS">
      <data key="d0">PERSON</data>
      <data key="d1">Michalis Faloutsos is a researcher who co-authored a paper on malware source code detection.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BERNARDINO ROMERA-PAREDES">
      <data key="d0">PERSON</data>
      <data key="d1">Bernardino Romera-Paredes is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MOHAMMADAMIN BAREKATAIN">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammadamin Barekatain is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ALEXANDER NOVIKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Alexander Novikov is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATEJ BALOG">
      <data key="d0">PERSON</data>
      <data key="d1">Matej Balog is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="M PAWAN KUMAR">
      <data key="d0">PERSON</data>
      <data key="d1">M Pawan Kumar is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="EMILIEN DUPONT">
      <data key="d0">PERSON</data>
      <data key="d1">Emilien Dupont is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FRANCISCO JR RUIZ">
      <data key="d0">PERSON</data>
      <data key="d1">Francisco JR Ruiz is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JORDAN S ELLENBERG">
      <data key="d0">PERSON</data>
      <data key="d1">Jordan S Ellenberg is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="PENGMING WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Pengming Wang is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="OMAR FAWZI">
      <data key="d0">PERSON</data>
      <data key="d1">Omar Fawzi is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ERIC HAMBRO">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Hambro is a researcher who co-authored a paper on Toolformer.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SANDER SCHULHOFF">
      <data key="d0">PERSON</data>
      <data key="d1">Sander Schulhoff is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MICHAEL ILIE">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Ilie is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NISHANT BALEPUR">
      <data key="d0">PERSON</data>
      <data key="d1">Nishant Balepur is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="KONSTANTINE KAHADZE">
      <data key="d0">PERSON</data>
      <data key="d1">Konstantine Kahadze is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AMANDA LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Amanda Liu is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHENGLEI SI">
      <data key="d0">PERSON</data>
      <data key="d1">Chenglei Si is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YINHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yinheng Li is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AAYUSH GUPTA">
      <data key="d0">PERSON</data>
      <data key="d1">Aayush Gupta is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HYOJUNG HAN">
      <data key="d0">PERSON</data>
      <data key="d1">HyoJung Han is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FREDA SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Freda Shi is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MIRAC SUZGUN">
      <data key="d0">PERSON</data>
      <data key="d1">Mirac Suzgun is a researcher recognized for his contributions to the field of Artificial Intelligence, particularly in the area of Natural Language Processing. In 2022, he co-authored a paper that addressed challenging big-bench tasks, showcasing his expertise in evaluating and advancing AI capabilities. Additionally, he has collaborated on research focused on multilingual chain-of-thought reasoning, further emphasizing his commitment to enhancing AI's understanding and processing of diverse languages. Through these contributions, Mirac Suzgun plays a significant role in the ongoing development and refinement of AI methodologies.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MARKUS FREITAG">
      <data key="d0">PERSON</data>
      <data key="d1">Markus Freitag is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SURAJ SRIVATS">
      <data key="d0">PERSON</data>
      <data key="d1">Suraj Srivats is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SOROUSH VOSOUGHI">
      <data key="d0">PERSON</data>
      <data key="d1">Soroush Vosoughi is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SEBASTIAN RUDER">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Ruder is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DIPANJAN DAS">
      <data key="d0">PERSON</data>
      <data key="d1">Dipanjan Das is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NOAH SHINN">
      <data key="d0">PERSON</data>
      <data key="d1">Noah Shinn is a researcher who co-authored a paper on language agents with verbal reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FEDERICO CASSANO">
      <data key="d0">PERSON</data>
      <data key="d1">Federico Cassano is a researcher who co-authored a paper on language agents with verbal reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ASHWIN GOPINATH">
      <data key="d0">PERSON</data>
      <data key="d1">Ashwin Gopinath is a researcher who co-authored a paper on language agents with verbal reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="KARTHIK NARASIMHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Karthik Narasimhan is a researcher who co-authored a paper on language agents with verbal reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SHUNYU YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Shunyu Yao is a researcher who co-authored a paper on language agents with verbal reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RISTO MIIKKULAINEN">
      <data key="d0">PERSON</data>
      <data key="d1">Risto Miikkulainen is a researcher who co-authored a paper on designing neural networks through neuroevolution.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RICHARD S SUTTON">
      <data key="d0">PERSON</data>
      <data key="d1">Richard S Sutton is a researcher who co-authored a book on reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ANDREW G BARTO">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew G Barto is a researcher who co-authored a book on reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SAI VEMPRALA">
      <data key="d0">PERSON</data>
      <data key="d1">Sai Vemprala is a researcher who authored a technical report on ChatGPT for robotics.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROGERIO BONATTI">
      <data key="d0">PERSON</data>
      <data key="d1">Rogerio Bonatti is a researcher who co-authored a technical report on ChatGPT for robotics.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARTHUR BUCKER">
      <data key="d0">PERSON</data>
      <data key="d1">Arthur Bucker is a researcher who co-authored a technical report on ChatGPT for robotics.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ASHISH KAPOOR">
      <data key="d0">PERSON</data>
      <data key="d1">Ashish Kapoor is a researcher who co-authored a technical report on ChatGPT for robotics.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YUQI XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yuqi Xie is a researcher who co-authored a paper on Voyager, an open-ended embodied agent.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHAOWEI XIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Chaowei Xiao is a researcher who co-authored a paper on Voyager, an open-ended embodied agent.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JANE X WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jane X Wang is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZEB KURTH-NELSON">
      <data key="d0">PERSON</data>
      <data key="d1">Zeb Kurth-Nelson is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DHRUVA TIRUMALA">
      <data key="d0">PERSON</data>
      <data key="d1">Dhruva Tirumala is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HUBERT SOYER">
      <data key="d0">PERSON</data>
      <data key="d1">Hubert Soyer is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JOEL Z LEIBO">
      <data key="d0">PERSON</data>
      <data key="d1">Joel Z Leibo is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="REMI MUNOS">
      <data key="d0">PERSON</data>
      <data key="d1">Remi Munos is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHARLES BLUNDELL">
      <data key="d0">PERSON</data>
      <data key="d1">Charles Blundell is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DHARSHAN KUMARAN">
      <data key="d0">PERSON</data>
      <data key="d1">Dharshan Kumaran is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATT BOTVINICK">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Botvinick is a prominent researcher known for his significant contributions to the fields of reinforcement learning and cognitive science. He has co-authored a paper focused on the concept of learning to reinforcement learn, further establishing his expertise and influence in the intersection of these disciplines. His work is recognized for advancing the understanding of how cognitive processes can be modeled and improved through reinforcement learning techniques.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LEI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Lei Wang is a researcher recognized for his contributions to the field of artificial intelligence, particularly in the study of large language model-based autonomous agents. He co-authored a comprehensive survey that explores the capabilities and implications of these advanced systems, highlighting his expertise and involvement in this cutting-edge area of research. Through his work, Lei Wang has significantly advanced the understanding of how large language models can be utilized in autonomous agent development.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHEN MA">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Ma is a researcher actively engaged in the study of large language model-based autonomous agents. He has co-authored significant surveys that explore various aspects of this field, including a comprehensive survey on large language model-based autonomous agents and another focused on the memory mechanisms utilized by these agents. Through his work, Chen Ma contributes valuable insights into the development and understanding of advanced AI systems, particularly in the context of natural language processing.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ZEYU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zeyu Zhang is a researcher actively contributing to the field of large language model-based autonomous agents. He has co-authored a survey that explores this area, highlighting his involvement in advancing the understanding and application of these technologies. Through his work, Zeyu Zhang plays a significant role in the ongoing research and development of autonomous agents powered by large language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HAO YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Yang is a researcher actively engaged in the study of large language model-based autonomous agents. He has contributed to the field by co-authoring a survey that explores various aspects of these agents, highlighting his involvement in advancing knowledge and understanding within this area of research.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JINGSEN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jingsen Zhang is a researcher actively contributing to the field of large language model-based autonomous agents. He has co-authored a survey that explores this area, highlighting his involvement in advancing the understanding and application of these technologies. Through his research, Zhang plays a significant role in the development and analysis of autonomous agents that leverage large language models, positioning him as a key figure in this emerging domain.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZHIYUAN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Chen is a researcher actively engaged in the study of large language model-based autonomous agents. He has co-authored a comprehensive survey that explores this emerging field, contributing valuable insights into the capabilities and applications of these advanced AI systems. Through his work, Chen plays a significant role in advancing the understanding of how large language models can be utilized in autonomous agent development.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="(&quot;ENTITY&quot;">
      <data key="d0">TOOL LEARNING WITH LARGE LANGUAGE MODELS</data>
      <data key="d1">The entity referred to as "ENTITY" is associated with research activities. However, the provided descriptions lack specific details or context regarding the nature of the research, its objectives, or the areas of focus within the field. As a result, the summary highlights that "ENTITY" is engaged in research, but further information is necessary to provide a more comprehensive understanding of its contributions or significance within its domain.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AUTOGPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AutoGPT is a tool developed to automate tasks using large language models, available as a GitHub repository.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATHEMATICAL DISCOVERIES FROM PROGRAM SEARCH">
      <data key="d0">RESEARCH</data>
      <data key="d1">This research discusses the mathematical insights gained from using large language models in program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TOOLFORMER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Toolformer is a framework that allows language models to learn how to use tools effectively.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="PROMPT REPORT">
      <data key="d0">RESEARCH</data>
      <data key="d1">The prompt report is a systematic survey that analyzes various prompting techniques used in language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DEEPMAD">
      <data key="d0">RESEARCH</data>
      <data key="d1">Deepmad is a study focused on the mathematical architecture design for deep convolutional neural networks.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LANGUAGE AGENTS WITH VERBAL REINFORCEMENT LEARNING">
      <data key="d0">RESEARCH</data>
      <data key="d1">This research explores the development of language agents that utilize verbal reinforcement learning techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LEARNING TO REINFORCEMENT LEARN">
      <data key="d0">RESEARCH</data>
      <data key="d1">Learning to reinforcement learn is a study that investigates methods for improving reinforcement learning algorithms.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d0">RESEARCH</data>
      <data key="d1">This survey focuses on the development and capabilities of autonomous agents that utilize large language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TOOL LEARNING WITH LARGE LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SHAN KUMARAN">
      <data key="d0">PERSON</data>
      <data key="d1">Shan Kumaran is a researcher known for contributions in the field of reinforcement learning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="XUEYANG FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xueyang Feng is a researcher who has worked on large language model-based autonomous agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JIAKAI TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiakai Tang is a researcher contributing to the field of large language model-based autonomous agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="XU CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xu Chen is a researcher actively engaged in the exploration of large language model-based autonomous agents. He has contributed to the field by co-authoring a survey that focuses on the memory mechanisms utilized by these agents. Through his work, Xu Chen plays a significant role in advancing the understanding of how large language models operate and their potential applications in autonomous systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RUI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Rui Wang is a researcher known for work on open-ended coevolution in reinforcement learning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="KENNETH O. STANLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Kenneth O. Stanley is a researcher known for his work in evolutionary algorithms and reinforcement learning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="QUOC V LE">
      <data key="d0">PERSON</data>
      <data key="d1">Quoc V Le is a prominent researcher recognized for his contributions to the fields of machine learning and language models. He has co-authored significant papers that explore advanced concepts in this domain, including self-discovery in large language models and reasoning via abstraction in large language models. His work is instrumental in enhancing the understanding and capabilities of artificial intelligence systems, particularly in how they process and generate language.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ED H. CHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ed H. Chi is a prominent researcher engaged in the exploration of language models and their diverse applications. In 2022, he co-authored a significant paper addressing challenging big-bench tasks, contributing to the advancement of knowledge in the field. His work reflects a commitment to understanding and enhancing the capabilities of language models, positioning him as a key figure in the ongoing development of artificial intelligence and natural language processing.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QINGYUN WU">
      <data key="d0">PERSON</data>
      <data key="d1">Qingyun Wu is a researcher specializing in multi-agent conversation frameworks. In 2023, Wu co-authored a paper focused on enabling next-generation large language model (LLM) applications, showcasing a commitment to advancing the field of artificial intelligence. Additionally, Wu contributed to another paper that addresses the offline training of language model agents, further emphasizing their expertise in developing innovative solutions within natural language processing. Through these contributions, Qingyun Wu plays a significant role in enhancing collaborative efforts and communication in the AI research community.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="GAGAN BANSAL">
      <data key="d0">PERSON</data>
      <data key="d1">Gagan Bansal is a researcher actively contributing to advancements in language model applications. In 2023, he co-authored a paper focused on enabling next-generation large language model (LLM) applications, highlighting his involvement in cutting-edge research within the field. His work reflects a commitment to enhancing the capabilities and applications of language models, positioning him as a significant figure in the ongoing development of artificial intelligence technologies.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIEYU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jieyu Zhang is a prominent researcher specializing in the synthesis of robotic skills through the application of language models. In 2023, Zhang co-authored a significant paper focused on enabling next-generation applications of large language models (LLMs), showcasing their potential in advancing the field. Additionally, Zhang contributed to another research paper that explored the offline training of language model agents, further emphasizing their expertise in the intersection of robotics and natural language processing. Through these contributions, Jieyu Zhang is actively shaping the future of AI and its applications in robotics.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIRAN WU">
      <data key="d0">PERSON</data>
      <data key="d1">Yiran Wu is a researcher actively contributing to advancements in language model applications. In 2023, Yiran co-authored a paper focused on enabling next-generation large language model (LLM) applications, highlighting their role in the evolving landscape of artificial intelligence and natural language processing. Through this work, Yiran Wu is positioned as a significant figure in the ongoing development and application of innovative language technologies.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SHAOKUN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shaokun Zhang is a prominent researcher specializing in the field of multi-agent generation through evolutionary algorithms. In 2023, he co-authored a significant paper focused on enabling next-generation large language model (LLM) applications, showcasing his contributions to advancing AI technologies. Additionally, he collaborated on another paper that addresses the offline training of language model agents, further emphasizing his expertise and involvement in cutting-edge research within the realms of artificial intelligence and natural language processing.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ELIEZER YUDKOWSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Eliezer Yudkowsky is a researcher known for his work on AI and global risks.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="MATEI ZAHARIA">
      <data key="d0">PERSON</data>
      <data key="d1">Matei Zaharia is a researcher involved in the development of compound AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="OMNI">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">OMNI is a research project and system dedicated to exploring the concept of open-endedness through the lens of human notions of interestingness. It aims to develop models that capture and analyze what humans find intriguing, thereby facilitating a deeper understanding of open-ended exploration in various contexts. Through its innovative approach, OMNI seeks to contribute to the broader discourse on creativity and discovery in artificial intelligence and related fields.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="AUTOGEN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Autogen is a framework enabling next-generation applications of large language models through multi-agent conversations.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JIALE ZHI">
      <data key="d0">PERSON</data>
      <data key="d1">Jiale Zhi is a researcher involved in the study of enhanced open-ended reinforcement learning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YULUN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yulun Li is a researcher contributing to advancements in open-ended reinforcement learning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NIMROD GILEADI">
      <data key="d0">PERSON</data>
      <data key="d1">Nimrod Gileadi is a researcher involved in the development of language model applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SEAN KIRMANI">
      <data key="d0">PERSON</data>
      <data key="d1">Sean Kirmani is a researcher involved in the study of language models and their applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="MONTSERRAT GONZALEZ ARENAS">
      <data key="d0">PERSON</data>
      <data key="d1">Montserrat Gonzalez Arenas is a researcher involved in language model applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="HAO-TIEN LEWIS CHIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Hao-Tien Lewis Chiang is a researcher contributing to advancements in language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="TOM EREZ">
      <data key="d0">PERSON</data>
      <data key="d1">Tom Erez is a researcher involved in the study of language models and their applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LEONARD HASENCLEVER">
      <data key="d0">PERSON</data>
      <data key="d1">Leonard Hasenclever is a researcher contributing to advancements in language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JAN HUMPLIK">
      <data key="d0">PERSON</data>
      <data key="d1">Jan Humplik is a researcher involved in the development of language model applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="BENFENG XU">
      <data key="d0">PERSON</data>
      <data key="d1">Benfeng Xu is a researcher contributing to advancements in agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="AN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">An Yang is a researcher involved in the study of agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JUNYANG LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Junyang Lin is a researcher contributing to advancements in agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="QUAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Quan Wang is a researcher involved in the study of agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHANG ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Chang Zhou is a researcher contributing to advancements in agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YONGDONG ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yongdong Zhang is a researcher involved in the study of agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ZHENDONG MAO">
      <data key="d0">PERSON</data>
      <data key="d1">Zhendong Mao is a researcher contributing to advancements in agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NICHOLAS FULLAGAR">
      <data key="d0">PERSON</data>
      <data key="d1">Nicholas Fullagar is a researcher contributing to advancements in AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="GREGORY DARDYK">
      <data key="d0">PERSON</data>
      <data key="d1">Gregory Dardyk is a researcher involved in the study of AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="J BRADLEY CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">J Bradley Chen is a researcher contributing to advancements in AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ROBERT MUTH">
      <data key="d0">PERSON</data>
      <data key="d1">Robert Muth is a researcher involved in the study of AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="TAVIS ORMANDY">
      <data key="d0">PERSON</data>
      <data key="d1">Tavis Ormandy is a researcher contributing to advancements in AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SHIKI OKASAKA">
      <data key="d0">PERSON</data>
      <data key="d1">Shiki Okasaka is a researcher involved in the study of AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NEHA NARULA">
      <data key="d0">PERSON</data>
      <data key="d1">Neha Narula is a researcher contributing to advancements in AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ADITYA RAWAL">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="KENNETH STANLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Kenneth Stanley is a researcher who co-authored a paper on open-endedness in models of human notions of interestingness.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIALE LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Jiale Liu is a researcher recognized for co-authoring significant papers in the field of Artificial Intelligence, particularly focusing on language models. In 2023, Liu contributed to a paper that explores enabling next-generation large language model (LLM) applications, showcasing a commitment to advancing the capabilities and functionalities of AI technologies. Additionally, Liu co-authored another paper that addresses the offline training of language model agents, further emphasizing a dedication to improving the training processes and operational efficiency of language models. Through these contributions, Jiale Liu plays a vital role in the ongoing development and innovation within the realm of Natural Language Processing.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LINXIN SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Linxin Song is a researcher who co-authored a paper on offline training of language model agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="CHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chi Wang is a researcher recognized for his contributions to the field of Artificial Intelligence, particularly in Natural Language Processing. In 2023, he co-authored a paper focused on enabling next-generation large language model (LLM) applications, showcasing his commitment to advancing the capabilities of AI technologies. Additionally, he has collaborated on research concerning the offline training of language model agents, further emphasizing his expertise in developing innovative methodologies for training AI systems. Through these contributions, Chi Wang plays a significant role in shaping the future of language models and their applications.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RANJAY KRISHNA">
      <data key="d0">PERSON</data>
      <data key="d1">Ranjay Krishna is a researcher who co-authored a paper on offline training of language model agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="MEMORY MECHANISM">
      <data key="d0">RESEARCH</data>
      <data key="d1">The memory mechanism refers to the methods and structures used in large language model-based agents to manage and utilize memory.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ZEU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zeyu Zhang is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIAOHE BO">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaohe Bo is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RUI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Rui Li is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="QUANYU DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Quanyu Dai is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIEMING ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Jieming Zhu is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ZHENHUA DONG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhenhua Dong is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="HENG-TZE CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Heng-Tze Cheng is a researcher who co-authored a paper on self-discovery in large language models.Heng-Tze Cheng is a researcher who co-authored a paper on reasoning via abstraction in large language models.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ED H CHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ed H Chi is a researcher who co-authored a paper on reasoning via abstraction in large language models.Ed H Chi is a researcher who co-authored a paper on self-discovery in large language models.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PEI ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Pei Zhou is a researcher who co-authored a paper on self-discovery in large language models.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JAY PUJARA">
      <data key="d0">PERSON</data>
      <data key="d1">Jay Pujara is a researcher who co-authored a paper on self-discovery in large language models.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIANG REN">
      <data key="d0">PERSON</data>
      <data key="d1">Xiang Ren is a researcher who co-authored a paper on self-discovery in large language models.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WANGCHUNSHU ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Wangchunshu Zhou is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="YIXIN OU">
      <data key="d0">PERSON</data>
      <data key="d1">Yixin Ou is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHENGWEI DING">
      <data key="d0">PERSON</data>
      <data key="d1">Shengwei Ding is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LONG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Long Li is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIALONG WU">
      <data key="d0">PERSON</data>
      <data key="d1">Jialong Wu is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="TIANNAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Tiannan Wang is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIAMIN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jiamin Chen is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHUAI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shuai Wang is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIAOHUA XU">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaohua Xu is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="MINGCHEN ZHUGE">
      <data key="d0">PERSON</data>
      <data key="d1">Mingchen Zhuge is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WENYI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Wenyi Wang is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LOUIS KIRSCH">
      <data key="d0">PERSON</data>
      <data key="d1">Louis Kirsch is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FRANCESCO FACCIO">
      <data key="d0">PERSON</data>
      <data key="d1">Francesco Faccio is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DMITRII KHIZBULLIN">
      <data key="d0">PERSON</data>
      <data key="d1">Dmitrii Khizbullin is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J&#220;RGEN SCHMIDHUBER">
      <data key="d0">PERSON</data>
      <data key="d1">J&#252;rgen Schmidhuber is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VARIBAD">
      <data key="d0">RESEARCH</data>
      <data key="d1">Varibad is a research project focused on variational Bayes-adaptive deep reinforcement learning via meta-learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">RESEARCH</data>
    </node>
    <node id="LUISA ZINTGRAF">
      <data key="d0">PERSON</data>
      <data key="d1">Luisa Zintgraf is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SEBASTIAN SCHULZE">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Schulze is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEO FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Leo Feng is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAXIMILIAN IGL">
      <data key="d0">PERSON</data>
      <data key="d1">Maximilian Igl is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KYRIACOS SHIARLIS">
      <data key="d0">PERSON</data>
      <data key="d1">Kyriacos Shiarlis is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YARIN GAL">
      <data key="d0">PERSON</data>
      <data key="d1">Yarin Gal is a prominent researcher known for his contributions to the fields of Artificial Intelligence and Natural Language Processing. In 2024, he co-authored a paper that explores the impact of training on generated data, highlighting the significance of training methodologies in enhancing the quality and reliability of AI-generated outputs. Additionally, he has collaborated on a paper focused on variational Bayes-adaptive deep reinforcement learning, which delves into advanced techniques for improving learning algorithms in dynamic environments. Through these works, Yarin Gal demonstrates a commitment to advancing the understanding and application of complex AI systems.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KATJA HOFMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Katja Hofmann is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHIMON WHITESON">
      <data key="d0">PERSON</data>
      <data key="d1">Shimon Whiteson is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OFFLINE TRAINING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SELF-DISCOVERY">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SELF(&quot;ENTITY&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LANGUAGE AGENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="META AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The meta agent is a system designed to generate code and improve its quality through self-reflection and iterative design processes.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="OUTPUT INSTRUCTION">
      <data key="d0">PROCESS</data>
      <data key="d1">Output instruction refers to the guidelines provided for formatting the output of the meta agent, including keys like "thought," "name," and "code."</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="AGENT ARCHITECTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Agent architecture is the design framework for creating agents, detailing their structure and functionality.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FORWARD FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">The forward function is a specific implementation in Python that defines how the agent processes input and generates output.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPLEMENTATION MISTAKES">
      <data key="d0">ERROR TYPE</data>
      <data key="d1">Implementation mistakes refer to errors made during the coding process that need to be identified and corrected.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPROVEMENT SUGGESTIONS">
      <data key="d0">PROCESS</data>
      <data key="d1">Improvement suggestions are recommendations made to enhance the performance or effectiveness of the agent's implementation.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="RUNTIME ERROR">
      <data key="d0">ERROR TYPE</data>
      <data key="d1">A runtime error is an error that occurs during the execution of the code, prompting the need for debugging and reflection.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FRAMEWORK CODE">
      <data key="d0">CODE</data>
      <data key="d1">Framework code is the foundational code provided to the meta agent, enabling it to perform basic functions like querying and formatting prompts.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="NAMEDTUPLE INFO OBJECT">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The namedtuple Info object is a data structure used to encapsulate various types of information for easy communication between modules.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="PROMPT">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">A prompt is a specific instruction given to the meta agent to guide its output and reasoning process.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="EXAMPLES OF POTENTIAL MISTAKES">
      <data key="d0">ERROR TYPE</data>
      <data key="d1">Examples of potential mistakes are instances of incorrect implementations that the meta agent may encounter during its coding process.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="DEBUG_THOUGHT">
      <data key="d0">PROCESS</data>
      <data key="d1">Debug_thought is a reflective process where the meta agent analyzes its code to identify and fix errors during execution.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="APPENDICES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FM MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The FM Module is a functional component utilized by agents to process tasks and deliver solutions effectively. It serves as a foundational class that manages the functionality of a framework module. Key attributes of the FM Module include output fields, name, role, model, temperature, and a unique identifier, all of which contribute to its operational capabilities within the system. This design ensures that the FM Module can efficiently handle various tasks while maintaining a structured approach to functionality management.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="INFO">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Info is a named tuple that holds task information, including attributes such as name, author, content, and iteration index.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="AGENT SYSTEM">
      <data key="d0">SYSTEM</data>
      <data key="d1">The Agent System is a framework component that processes task information and is designed to implement functionalities like self-reflection.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="JSON RESPONSE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The JSON response is a structured output format returned by the FM module after processing a user message through a model.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="GPT MODEL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The GPT model is a generative pre-trained transformer model used for generating text responses based on input messages.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="BACKOFF">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Backoff is a technique used to handle exceptions, specifically for managing rate limit errors when querying the GPT model.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Chain-of-Thought (COT) instruction is a directive for the model to think step by step before solving a task.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="OUTPUT FIELDS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Output fields are the expected fields in the output generated by the FM Module, defining the structure of the response.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="SYSTEM MESSAGE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The system message is a directive provided to the GPT model that sets the context for generating responses.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="ITERATION INDEX">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The iteration index is a numerical identifier used to track the iteration of a task within the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="RESPONSE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Response refers to the output generated by the FM Module or Agent System after processing input information and instructions.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TASK INFORMATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_REFLECT_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">The cot_reflect_instruction is a directive for the system to consider previous attempts and feedback to improve the current task solution.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="COT_MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The cot_module is a functional module that processes inputs related to thinking and answering, utilizing a chain-of-thought approach.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="CRITIC_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">The critic_instruction is a directive for the system to review and critique the answer provided, determining its correctness.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="CRITIC_MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The critic_module is a functional module that provides feedback and correctness status on the answers generated by the system.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="N_MAX">
      <data key="d0">PARAMETER</data>
      <data key="d1">N_max is a parameter that defines the maximum number of attempts the system can make to solve a task.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="COT_INPUTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">COT_inputs are the inputs provided to the cot_module for processing, including task information and previous feedback.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="ARC_CHALLENGE">
      <data key="d0">CHALLENGE</data>
      <data key="d1">The ARC (Abstraction and Reasoning Corpus) challenge is a task that involves predicting outputs based on transformation rules applied to input grids.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="EXAMPLE_INPUT_OUTPUT_GRID">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Example input-output grids are paired examples used in the ARC challenge to demonstrate the transformation rules.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="TEST_GRID">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The test grid is an input grid provided in the ARC challenge for which the output is unknown and needs to be predicted.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="GTP-4O-2024-05-13">
      <data key="d0">MODEL</data>
      <data key="d1">GPT-4O-2024-05-13 is a specific version of the GPT model utilized by the meta agent in the ARC challenge for generating solutions. This model is also employed for evaluations within the meta agent context, highlighting its role in assessing performance and outcomes. Additionally, GPT-4O-2024-05-13 serves as a processing tool for the meta agent, indicating its versatility and importance in various operational aspects related to the challenge.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="GPT-3.5-TURBO-0125">
      <data key="d0">MODEL</data>
      <data key="d1">GPT-3.5-TURBO-0125 is a version of the GPT-3.5 model developed by OpenAI, specifically utilized for evaluating discovered agents and baselines in the ARC challenge. This language model is designed to perform a variety of tasks, including reasoning and problem-solving, making it a versatile tool in the field of artificial intelligence. Its application in the ARC challenge highlights its role in assessing the performance of different agents and methodologies, thereby contributing to advancements in AI research and development.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="CORRECT">
      <data key="d0">STATUS</data>
      <data key="d1">Correct is a status indicating whether the answer generated by the system is accurate, as determined by the critic_module.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="INPUT_GRID">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Input_grid is a rectangular matrix of integers representing the initial state in the ARC challenge, from which transformation rules are derived.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="OUTPUT_GRID">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Output_grid is a rectangular matrix of integers representing the expected result after applying transformation rules to the input grid in the ARC challenge.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="TRANSFORMATION_RULE">
      <data key="d0">RULE</data>
      <data key="d1">Transformation_rule refers to the logic or method applied to the input grid to derive the output grid in the ARC challenge.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="TASK_INFO">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="STRUCTURED FEEDBACK AND ENSEMBLE AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">The Structured Feedback and Ensemble Agent is a specific AI agent developed to generate solutions through structured feedback mechanisms.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="FM_MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The FM_MODULE is a versatile framework designed for processing thoughts and feedback across various roles, including human-like feedback and expert evaluation. It serves as a modular system that facilitates the decomposition, integration, and specialized problem-solving of tasks. Additionally, the FM_MODULE functions as a crucial component within an agent, enabling the generation of candidate solutions based on specific instructions. This multifaceted approach allows for enhanced collaboration and communication in environments that require sophisticated processing capabilities.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="TASKINFO">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">TaskInfo refers to the contextual information or parameters associated with a specific task that is being evaluated or solved. It serves as the input data structure that encompasses all relevant details about the task to be addressed by the agent. This information is crucial for guiding the agent's actions and decisions in effectively completing the task at hand.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="CORRECT EXAMPLES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Correct examples are instances where the generated solutions successfully meet the task requirements, used to assess the performance of the agent.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="WRONG EXAMPLES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Wrong examples are instances where the generated solutions fail to meet the task requirements, providing insights into the agent's shortcomings.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="INITIAL CANDIDATE SOLUTIONS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="HUMAN-LIKE FEEDBACK MODULE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Human-Like Feedback Module is a component designed to simulate human feedback for code solutions, focusing on common mistakes and best practices.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="INITIAL_SOLUTIONS">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Initial Solutions is a collection of candidate solutions that have been generated and are awaiting evaluation and feedback.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT ADVISORS">
      <data key="d0">ROLE</data>
      <data key="d1">Expert Advisors are specialized roles assigned to evaluate code solutions and provide targeted feedback for improvement.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINEMENT MODULE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Refinement Module is a component that iteratively refines solutions based on structured feedback to enhance performance.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL DECISION MODULE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The **Final Decision Module** is a critical component designed to synthesize outputs from various agents, enabling it to arrive at a definitive answer. It functions by evaluating and integrating the best-performing solutions, thereby facilitating a final decision regarding the code. This module plays a pivotal role in ensuring that the decision-making process is informed by a comprehensive analysis of multiple inputs, ultimately enhancing the reliability and effectiveness of the outcomes it produces.</data>
      <data key="d2">84317ae35cc75d612287186d93461447,97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="CORRECT_EXAMPLES">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Correct Examples are instances of solutions that have successfully passed evaluation criteria, indicating their correctness.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="WRONG_EXAMPLES">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Wrong Examples are instances of solutions that failed to meet evaluation criteria, highlighting areas for improvement.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="LLM-DEBATE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">LLM-Debate is a specialized hand-designed agent baseline developed for reasoning tasks. This innovative method involves the assignment of specific roles to debate modules, which engage in structured discussions to collaboratively arrive at solutions. By facilitating dialogue among these modules, LLM-Debate enhances the reasoning process, making it a valuable tool in the fields of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="INDIANS">
      <data key="d0">NATIONALITY</data>
      <data key="d1">Indians are a nationality represented in Bahrain, with a population of approximately 290,000 according to reports from 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="BANGLADESHIS">
      <data key="d0">NATIONALITY</data>
      <data key="d1">Bangladeshis are a nationality represented in Bahrain, with a population of approximately 125,000 according to reports from 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PAKISTANIS">
      <data key="d0">NATIONALITY</data>
      <data key="d1">Pakistanis are a nationality represented in Bahrain, with a population of approximately 45,000 according to reports from 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="FILIPINOS">
      <data key="d0">NATIONALITY</data>
      <data key="d1">Filipinos are a nationality represented in Bahrain, with a population of approximately 45,000 according to reports from 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="INDONESIANS">
      <data key="d0">NATIONALITY</data>
      <data key="d1">Indonesians are a nationality represented in Bahrain, with a population of approximately 8,000 according to reports from 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="BAHRAIN">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CRITIC MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Critic Module is a component used in the agents to provide feedback and evaluate the correctness of answers.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="TASK INFO">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Task Info represents the information or context provided to the agents for processing and problem-solving.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="FM QUERY">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="DECOMPOSITION MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The Decomposition Module is responsible for breaking down complex problems into manageable sub-problems for further analysis.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SPECIALIZED EXPERTS">
      <data key="d0">ROLE</data>
      <data key="d1">Specialized Experts are designated roles within the framework, each focusing on specific domains such as Physics, Chemistry, and Biology to solve sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INTEGRATION MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The Integration Module combines the solutions of sub-problems into a final answer, ensuring coherence and completeness.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB-PROBLEMS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Sub-problems are the individual components derived from a larger problem, which are addressed by specialized experts.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB-SOLUTIONS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Sub-solutions are the answers generated by specialized experts for each sub-problem.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL REPRESENTATION MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The Visual Representation Module creates visual aids, such as diagrams or graphs, to assist in problem-solving.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VERIFICATION MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The Verification Module checks the accuracy and relevance of visual representations, providing feedback for improvement.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="CHAIN-OF-THOUGHT MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The Chain-of-Thought Module facilitates step-by-step reasoning to solve problems using verified visual aids.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="DECOMPOSITION INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Decomposition Instruction is a directive given to the Decomposition Module to guide the breakdown of a problem into sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INTEGRATION INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Integration Instruction is a directive given to the Integration Module to guide the combination of sub-solutions into a final answer.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB-PROBLEM">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A Sub-Problem is an individual component of a larger problem that requires specialized attention for resolution.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB-PROBLEM INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Sub-Problem Instruction is a directive given to specialized experts to guide them in solving their assigned sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="AGENTINSTRUCT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">AGENTINSTRUCT is a comprehensive methodology designed to curate a large dataset of instructions aimed at teaching various skills. It synthesizes a diverse corpus of data with varying degrees of difficulty, specifically tailored for training AI models. This approach enhances the proficiency of AI systems across multiple tasks, including math problem-solving and format-following. AGENTINSTRUCT serves as a fine-tuning method for language models, enabling them to generate high-quality synthetic data. It is characterized as an agentic solution for Generative Teaching, focusing on the creation of demonstration and feedback data from raw documents. Furthermore, AGENTINSTRUCT employs agentic flows to produce diverse and high-quality synthetic data, making it an extensible framework for automatically generating substantial amounts of training data for language models.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SYNTHETIC DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Synthetic data is a form of artificially generated information utilized primarily for training models in various applications, including language models. It plays a crucial role in creating customized datasets that can enhance the performance and accuracy of these models. The quality and diversity of synthetic data can vary, impacting its effectiveness in different contexts. Overall, synthetic data serves as a valuable resource in the development and refinement of machine learning algorithms, particularly in the fields of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MISTRAL-7B">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-7B is a base language model that has undergone post-training and fine-tuning processes utilizing synthetic data generated by AgentInstruct. This model is specifically designed for various tasks and has been evaluated on the MIRAGE datasets, ensuring its effectiveness and adaptability in practical applications. The combination of post-training and fine-tuning with synthetic datasets allows Mistral-7B to enhance its performance and applicability in the field of natural language processing.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="ORCA-3">
      <data key="d0">MODEL</data>
      <data key="d1">ORCA-3 is a sophisticated machine learning model that has been trained using a dataset comprising approximately 25.8 million paired instructions, enabling it to perform a variety of tasks effectively. As a 7B model, ORCA-3 has demonstrated notable advancements in performance compared to its predecessors, such as Orca 2.5 and Mistral-7B-Instruct, particularly excelling in reading comprehension and math problem-solving tasks. This language model has further enhanced its capabilities through post-training with a dataset generated by the AgentInstruct approach. Evaluated against several baseline models within the Orca-Bench dataset, ORCA-3 is recognized as a finetuned version of the Mistral-7B model, showcasing significant improvements across various benchmarks. The model's development involved post-training Mistral-7B with synthetic data, which has contributed to its enhanced performance metrics.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LLAMA-8B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">LLAMA-8B-Instruct is a language model that is utilized for comparative analysis against Orca-3, particularly focusing on performance metrics. It serves as a benchmark in the evaluation of instruction-tuned models, highlighting its role in assessing the effectiveness and capabilities of various language models within the field of artificial intelligence and natural language processing.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="AGIEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">AGIEval is a comprehensive benchmark designed to assess the performance of instruction-tuned AI models, particularly in the domains of reading comprehension and mathematics. It provides comparative scores across various models, enabling a clear evaluation of their capabilities. Additionally, AGIEval focuses on human-centric assessments, evaluating models on tasks that relate to human cognition and problem-solving, including standardized exams. This multifaceted approach ensures that AGIEval serves as a valuable tool for understanding the effectiveness of language models in real-world applications.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="BBH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">BBH, or Big Bench Hard, is a benchmark designed to evaluate the performance of language models across a range of tasks that necessitate complex, multi-step reasoning. It serves as a critical tool for assessing how well these models perform in specific academic subjects, providing insights into their capabilities and limitations. By focusing on various tasks, BBH helps researchers and developers understand the effectiveness of language models in handling intricate reasoning challenges.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="ALPACA EVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">ALPACA EVAL is an automatic evaluator specifically designed to assess instruction-following models. It serves as a benchmark for chat-based language models, focusing on their ability to follow instructions during single-turn interactions. Additionally, ALPACA EVAL evaluates the performance of instruction-tuned models in various instruction-following tasks. One of its key features is measuring the win-rates of model outputs in comparison to reference answers, providing a quantitative assessment of model effectiveness in adhering to given instructions.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="POST-TRAINING">
      <data key="d0">PROCESS</data>
      <data key="d1">The term "POST-TRAINING" refers to a critical phase in the model training process within the fields of Artificial Intelligence and Natural Language Processing. During this phase, additional training is conducted using specific datasets following the initial training. The primary objective of post-training is to enhance the model's performance, ensuring that it is better equipped to handle various tasks and improve its overall accuracy and efficiency. This stage is essential for refining the model and addressing any shortcomings identified during the initial training phase.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="INSTRUCTION TUNING">
      <data key="d0">PROCESS</data>
      <data key="d1">Instruction tuning is a process that involves refining a language model's ability to follow instructions by training it on specific datasets. This technique enhances the model's performance in understanding and executing user commands, thereby improving its overall utility in various applications.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="RLHF">
      <data key="d0">PROCESS</data>
      <data key="d1">Reinforcement Learning from Human Feedback (RLHF) is a training method that incorporates human feedback to improve model performance.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MULTI-AGENT WORKFLOWS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Multi-agent workflows involve multiple agents working together to generate high-quality data and improve the capabilities of language models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="REFLECTION AND ITERATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Reflection and iteration are processes used in agentic workflows where agents review and improve their outputs based on previous results.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="DATA GENERATION WORKFLOWS">
      <data key="d0">PROCESS</data>
      <data key="d1">Data generation workflows are structured processes for creating datasets, often involving automation to reduce human intervention.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MODEL COLLAPSE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Model collapse refers to the phenomenon where a model's performance degrades over time, often due to training on low-quality synthetic data.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SEEDS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Seeds are initial data points or prompts used to generate further instructions or responses in the synthetic data generation process.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="TEXT DOCUMENTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Text documents are raw data sources used as seeds for generating synthetic data in the AgentInstruct framework.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CODE FILES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Code files are raw data sources used as seeds for generating synthetic data in the AgentInstruct framework.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="GENERATIVE TEACHING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Generative Teaching is a methodology designed to create diverse, challenging, and high-quality synthetic data specifically for the purpose of teaching skills to AI models. This approach emphasizes the importance of effective learning outcomes, prioritizing the development of skills over simply generating data to meet predefined benchmarks. By focusing on the educational aspect, Generative Teaching aims to enhance the overall learning experience and improve the capabilities of AI systems.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="SYNTHETIC DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The synthetic dataset created by AgentInstruct consists of 25 million prompt and response pairs covering a wide array of skills.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="AGENTIC FLOWS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Agentic Flows refers to a sophisticated set of transformation agents specifically designed to enhance reading comprehension tasks. These automated processes not only streamline the generation of diverse data but also utilize raw articles as foundational seeds for problem generation. Furthermore, Agentic Flows are adept at producing synthetic data by leveraging various raw materials and agents, thereby enriching the data landscape for various applications. This multifaceted approach positions Agentic Flows as a pivotal tool in the realm of data generation and comprehension enhancement.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,f4e98ee0b7fb42428f3312f29cb444dd,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CONTENT TRANSFORMATION AGENTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Content Transformation Agents are tools used in the AgentInstruct methodology to transform raw seeds into diverse instructions.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="INSTRUCTION CREATION AGENTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Instruction Creation Agents are components of the AgentInstruct methodology that generate a diverse set of instructions from transformed seeds.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="REFINEMENT AGENTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Refinement Agents are used in the AgentInstruct methodology to iteratively improve the complexity and quality of generated instructions.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="DIVERSE DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Diverse data refers to the variety of synthetic data generated by AgentInstruct, ensuring broad coverage and complexity.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="HIGH-QUALITY DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">High-quality data is the result of using powerful models and agentic flows to generate effective synthetic datasets.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="RAW DOCUMENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="RAW ARTICLES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Raw articles are unprocessed texts used as seeds in the agentic flows to foster diversity in generated problems.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CONTENT TRANSFORMATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">The "CONTENT TRANSFORMATION FLOW" is a versatile method designed to enhance the processing and utilization of textual information. It transforms arbitrary articles into structured formats, enabling the generation of a variety of reading comprehension questions. Additionally, this method converts raw seeds into an intermediate representation, which simplifies the creation of tailored instructions. Furthermore, the Content Transformation Flow synthesizes API descriptions or lists from source code snippets or other inputs, thereby streamlining the integration of technical documentation. Overall, this process facilitates improved comprehension and application of content across different contexts.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTION GENERATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">Seed Instruction Generation Flow generates diverse instructions based on transformed content, following a comprehensive taxonomy.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INSTRUCTION REFINEMENT FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">The "Instruction Refinement Flow" is a systematic process designed to iteratively improve the quality, diversity, and complexity of instructions derived from the Seed Instruction Flow. This flow enhances the generated instructions by incorporating input text and task modification instructions, ensuring that the instructions evolve to meet varying requirements and complexities. Through this iterative enhancement, the Instruction Refinement Flow aims to produce more sophisticated and adaptable instructions, thereby facilitating better outcomes in tasks that rely on precise and varied guidance.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SUGGESTER-EDITOR AGENTS">
      <data key="d0">AGENT</data>
      <data key="d1">Suggester-Editor Agents are specialized agents that propose and modify instructions to increase their complexity and quality.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SKILLS">
      <data key="d0">CATEGORY</data>
      <data key="d1">Skills refer to various competencies such as reading comprehension, question answering, and coding, each having multiple subcategories.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="READING COMPREHENSION">
      <data key="d0">SKILL</data>
      <data key="d1">Reading comprehension refers to the ability to process and understand written text, which is crucial for effective learning. This skill encompasses several key components, including decoding, fluency, and vocabulary knowledge. Decoding involves translating written symbols into sounds, fluency pertains to the speed and accuracy of reading, and vocabulary knowledge encompasses the understanding of words and their meanings. Together, these elements enable individuals to interpret and engage with text meaningfully.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,cc20c99cad8edecc66b82ac751ff7172,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT MODIFICATION">
      <data key="d0">SKILL</data>
      <data key="d1">**TEXT MODIFICATION** refers to the process of editing and refining written content to enhance its clarity, flow, and overall effectiveness. This practice often employs automated agents to assist in the modification process. Additionally, text modification involves altering text to improve its quality or adapt it to fit specific contexts, making it a crucial component in content creation and editing. Through these methods, TEXT MODIFICATION aims to produce high-quality written material that meets the needs of its intended audience.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d0">SKILL</data>
      <data key="d1">Open domain question answering is the ability to generate responses to questions across a wide range of topics without domain restrictions.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="WEB AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">A web agent is a software program that autonomously performs tasks on the web, such as navigation and interaction with web elements.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="BRAIN TEASER">
      <data key="d0">TASK</data>
      <data key="d1">A brain teaser is a problem or puzzle that requires thought to solve, often used for amusement or to train logical thinking skills.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ANALYTICAL REASONING">
      <data key="d0">SKILL</data>
      <data key="d1">Analytical reasoning involves discerning patterns within qualitative or quantitative information to draw logical conclusions.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MULTIPLE CHOICE QUESTIONS">
      <data key="d0">ASSESSMENT</data>
      <data key="d1">Multiple choice questions are a widely used assessment format that presents respondents with several options from which to choose. This format not only allows for the evaluation of knowledge but also serves to assess models in an open-ended generation setting. By requiring respondents to select the best answer from a list of options, multiple choice questions facilitate a structured approach to gauging understanding and decision-making skills.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="DATA TO TEXT">
      <data key="d0">PROCESS</data>
      <data key="d1">Data-to-text refers to generating human-readable textual summaries from structured data for reports or narratives.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="FERMI PROBLEMS">
      <data key="d0">TASK</data>
      <data key="d1">Fermi problems are estimation challenges that require making justified guesses to arrive at rough solutions for difficult-to-measure quantities.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CODING">
      <data key="d0">SKILL</data>
      <data key="d1">Coding is a multifaceted process that encompasses writing code according to specific instructions, as well as understanding, debugging, and testing that code. It involves not only the creation of code but also the ability to trace and write test cases to ensure functionality and reliability. This comprehensive approach to coding highlights the importance of both technical skills and problem-solving abilities in the software development process.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT EXTRACTION">
      <data key="d0">PROCESS</data>
      <data key="d1">TEXT EXTRACTION refers to the process of retrieving relevant information from larger text documents. This encompasses various tasks, including named entity recognition and keyword extraction. By focusing on these specific tasks, TEXT EXTRACTION aims to distill essential data from extensive textual sources, facilitating easier access and analysis of information.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SKILL">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ASSESSMENT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="PROCESS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TRANSFORMED CONTENT">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Transformed content refers to the output generated from the Content Transformation Flow, which simplifies the creation of instructions tailored to specific objectives.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INTERMEDIATE REPRESENTATION">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Intermediate representation is a simplified version of the raw seed that facilitates the creation of tailored instructions in the Content Transformation Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="COMPREHENSIVE TAXONOMY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Comprehensive taxonomy is a structured classification system used to guide the generation of instructions in the Seed Instruction Generation Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ITERATIVE PROCESS">
      <data key="d0">PROCESS</data>
      <data key="d1">Iterative process refers to the method of refining instructions through repeated cycles to enhance their quality and complexity in the Instruction Refinement Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="OUTPUTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Outputs refer to the results generated from the workflows, including instructions and data summaries.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="PROBLEM GENERATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Problem generation is the process of creating distinct and diverse problems through the use of agentic flows and raw articles as seeds.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INSTRUCTION CREATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Instruction creation is the process of developing specific directives or tasks based on transformed content in the workflows.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTION FLOW">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ENRICO FERMI">
      <data key="d0">PERSON</data>
      <data key="d1">Enrico Fermi was a physicist known for his contributions to nuclear physics and for the development of the Fermi problem, which involves making rough estimates of quantities that are difficult to measure.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="TEXT CLASSIFICATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Text classification is a machine learning task where text documents are automatically categorized into predefined categories, such as spam detection and sentiment analysis.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="RETRIEVAL AUGMENTED GENERATION (RAG)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Retrieval Augmented Generation (RAG) is a method in natural language processing that combines retrieval-based and generative models to generate responses based on retrieved documents.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CREATIVE CONTENT GENERATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Creative content generation involves creating original content, such as text, music, or images, that is novel, valuable, and meaningful.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FEW SHOT REASONING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Few-shot reasoning is the ability of a machine learning model to understand new concepts or tasks with minimal examples, mimicking human learning.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CONVERSATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Conversation refers to the interaction of conversational agents or chatbots with humans in a natural, human-like manner.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="HYPERURICEMIA">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Hyperuricemia is a medical condition defined by elevated levels of uric acid in the bloodstream. This condition is associated with an increased risk of cardiovascular disease. It can arise from a variety of dietary and lifestyle factors, highlighting the importance of managing one's diet and habits to mitigate potential health risks.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PURINE">
      <data key="d0">COMPOUND</data>
      <data key="d1">Purine is a type of dietary protein that, when broken down, produces uric acid, which can lead to health complications if present in excess.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FERMI PROBLEM">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="ARGUMENT PASSAGE GENERATOR">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Argument Passage Generator is a specialized tool within the Content Transformation Flow designed to produce argumentative text passages specifically for reading comprehension tasks. This tool functions as an agent that generates passages articulating various arguments, which may occasionally include logical inconsistencies. Its primary purpose is to aid in the development of reading comprehension materials by providing diverse argumentative content.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LSAT LOGICAL REASONING">
      <data key="d0">TEST</data>
      <data key="d1">The LSAT Logical Reasoning test features specialized question categories designed to evaluate critical thinking and reasoning skills in prospective law students.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CARDIOVASCULAR DISEASE">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Cardiovascular disease encompasses a variety of conditions that impact the heart and blood vessels. It is frequently linked to elevated uric acid levels, among other risk factors. This broad category of diseases highlights the importance of understanding the underlying causes and associated health implications for effective prevention and management.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPURICEMIA">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Hypouricemia is a condition characterized by low levels of uric acid in the blood, which can indicate underlying health issues but is less common than hyperuricemia.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="URIC ACID">
      <data key="d0">COMPOUND</data>
      <data key="d1">Uric acid is a byproduct of purine metabolism in the body, formed from the breakdown of purines. Its levels in the blood can serve as important indicators of various health conditions, including hyperuricemia, hypouricemia, cardiovascular disease, and kidney issues. Monitoring uric acid levels is crucial for assessing overall health and diagnosing potential medical concerns.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="AGENTINSTRUCT FLOWS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="HYPOURICEMIA">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Hypouricemia is a condition with low levels of uric acid in the blood, often without symptoms, but may indicate underlying health issues.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LABORATORY TESTS">
      <data key="d0">PROCEDURE</data>
      <data key="d1">Laboratory blood and urine tests are diagnostic procedures used to measure uric acid levels and assess kidney and liver function.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="READING COMPREHENSION QUESTIONS">
      <data key="d0">EDUCATIONAL TOOL</data>
      <data key="d1">Reading comprehension questions are designed to assess understanding of a text, including various types such as literal, critical, and evaluative questions.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PASSAGE-QUESTION PAIRS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Passage-question pairs are combinations of text excerpts and corresponding questions used for comprehension assessment.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PARAPHRASING AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The "PARAPHRASING AGENT" is identified as a specialized automated system designed to rewrite text while maintaining the original meaning but using different wording. This technology plays a crucial role in various applications, such as content creation, academic writing, and enhancing communication by providing alternative expressions of ideas.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="PHYSICAL INACTIVITY">
      <data key="d0">LIFESTYLE CHOICE</data>
      <data key="d1">Physical inactivity is a lifestyle choice characterized by a lack of sufficient physical activity, which can affect overall health and uric acid levels.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="KIDNEY ISSUES">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Kidney issues refer to various health problems affecting kidney function, which can be indicated by low uric acid levels.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LIVER ISSUES">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Liver issues encompass a range of conditions affecting liver function, which may also be indicated by low uric acid levels.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CROSS-SECTIONAL STUDY">
      <data key="d0">RESEARCH METHOD</data>
      <data key="d1">A cross-sectional study is a type of observational research that analyzes data from a population at a specific point in time, often used to assess relationships between variables.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPERTENSION">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Hypertension, or high blood pressure, is a medical condition that can be associated with cardiovascular disease and other health issues.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="DIABETES">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Diabetes is a chronic medical condition that affects how the body processes blood sugar (glucose) and can be linked to cardiovascular disease.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPERURICEMIA AND CARDIOVASCULAR DISEASE RELATIONSHIP">
      <data key="d0">RESEARCH FINDING</data>
      <data key="d1">The relationship between hyperuricemia and cardiovascular disease is a subject of research, exploring how elevated uric acid levels may contribute to heart-related health risks.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="DISTRATOR OPTION">
      <data key="d0">EDUCATIONAL TOOL</data>
      <data key="d1">A distractor option is a choice in a multiple-choice question designed to mislead or confuse the test-taker, testing their understanding of the material.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="GENETIC PREDISPOSITION">
      <data key="d0">BIOLOGICAL FACTOR</data>
      <data key="d1">Genetic predisposition refers to the increased likelihood of developing certain health conditions based on one's genetic makeup, which can influence uric acid levels and cardiovascular health.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="FINANCIALIZATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Financialization is a broad concept that encompasses the increasing social impact and interconnection of financial discourses, markets, actors, and institutions in recent years.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="NATASCHA VAN DER ZWAN">
      <data key="d0">PERSON</data>
      <data key="d1">Natascha van der Zwan is a researcher who identifies three distinct research streams related to financialization.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="RESEARCH STREAMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research streams are distinct approaches to studying financialization, including accumulation regimes, the influence of financial markets on non-financial corporations, and discourses of risk-taking.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SOCIAL LIFE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Social life refers to the interactions and relationships among individuals and groups within society, which can be transformed by financial instruments.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUPPLY CHAINS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Supply chains of financial products connect different places and political projects globally, impacting social dynamics.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="AMERICAN ANTHROPOLOGICAL ASSOCIATION">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The American Anthropological Association is a professional organization that hosts meetings and conferences related to anthropology.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SEA 2017 ANNUAL MEETING">
      <data key="d0">EVENT</data>
      <data key="d1">The SEA 2017 Annual Meeting is an event organized by the American Anthropological Association, scheduled for April 6-8, 2017, at the University of Iowa.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="RANDOM SEED">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A random seed is a value used to initialize a process, which in this context is used to generate text modification instructions.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTER-EDITOR PAIR">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Suggester-Editor pair is a collaborative mechanism that generates and refines instructions for text modification tasks.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="API DESCRIPTION">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">An API description outlines the functionality and parameters of an API, detailing how it can be used by clients.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="LIBRARY RECONSTRUCTION">
      <data key="d0">PROCESS</data>
      <data key="d1">Library Reconstruction is a process that involves synthesizing a list of APIs from a given seed, often using an API retrieval agent.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SEARCH FOOD ITEMS">
      <data key="d0">API</data>
      <data key="d1">The Search Food Items API allows clients to search for food items by name and retrieve a list of matching items.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET FOOD ITEM DETAILS">
      <data key="d0">API</data>
      <data key="d1">The Get Food Item Details API retrieves detailed information about a specific food item.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="CREATE MEAL PLAN">
      <data key="d0">API</data>
      <data key="d1">The Create Meal Plan API generates a meal plan based on user dietary preferences and caloric goals.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="UPDATE FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">The Update Food Item API allows clients to modify the details of an existing food item in the database.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="TRACK USER MEAL">
      <data key="d0">API</data>
      <data key="d1">The Track User Meal API enables users to log their daily meals for tracking purposes.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET DIETARY RECOMMENDATIONS">
      <data key="d0">API</data>
      <data key="d1">The Get Dietary Recommendations API provides users with suggestions for food items based on their dietary preferences.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="ADD NEW FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">The Add New Food Item API allows clients to add a new food item to the database.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="DELETE FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">The Delete Food Item API enables clients to remove a food item from the database.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET USER NUTRITIONAL STATS">
      <data key="d0">API</data>
      <data key="d1">The Get User Nutritional Stats API retrieves nutritional information for a user based on their logged meals.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="SEED INSTRUCTION CREATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">The Seed Instruction Creation Flow is a process that utilizes a list of APIs to create various tasks for users.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="REFINEMENT FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">The Refinement Flow aims to increase task complexity by suggesting refinements based on user input and conversation context.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="ASSISTANT">
      <data key="d0">ROLE</data>
      <data key="d1">The Assistant is an AI entity designed to help users achieve their dietary goals by utilizing various APIs.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="CALORIC GOAL">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The caloric goal is a target number of calories that a user aims to consume daily as part of their diet plan.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="DIETARY PREFERENCES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Dietary preferences refer to the specific dietary choices or restrictions a user has, such as vegetarianism.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="MEAL PLAN">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The "MEAL PLAN" is a comprehensive and structured outline designed to guide users in their dietary choices over a specified period. It is tailored to meet individual dietary goals and includes a detailed representation of meals planned for each day. This encompasses breakfast, lunch, and dinner, along with the respective food items and their total caloric content. The meal plan serves as a practical tool for individuals seeking to manage their nutrition effectively, ensuring that their dietary needs are met in an organized manner.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="NUTRITIONAL SUMMARY">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A nutritional summary provides an overview of a user's nutritional intake over a specified period, summarizing calories and nutrients consumed.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="VEGETARIAN MEAL PLAN">
      <data key="d0">DIET</data>
      <data key="d1">A vegetarian meal plan designed to meet a caloric goal of 1500 calories per day, consisting of three meals each day.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="API_CALL">
      <data key="d0">ACTION</data>
      <data key="d1">An action type indicating a request to create a meal plan based on specified dietary preferences and caloric goals.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 1">
      <data key="d0">MEAL PLAN DAY</data>
      <data key="d1">The first day of the meal plan, detailing specific meals and their caloric content.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 2">
      <data key="d0">MEAL PLAN DAY</data>
      <data key="d1">The second day of the meal plan, detailing specific meals and their caloric content.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="QUINOA SALAD">
      <data key="d0">RECIPE</data>
      <data key="d1">A specific recipe that the user wishes to add to the database, requiring nutritional information for completion.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CHANA MASALA">
      <data key="d0">RECIPE</data>
      <data key="d1">A recipe that the user wants to update in the database, requiring its unique identifier for modification.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="BUTTER CHICKEN">
      <data key="d0">RECIPE</data>
      <data key="d1">A recipe that the user wants to remove from the database, requiring its unique identifier for deletion.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MISTRAL-7B-V0.1">
      <data key="d0">MODEL</data>
      <data key="d1">A base model used for finetuning with the AgentInstruct dataset, known for its publicly available weights.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-BENCH">
      <data key="d0">DATASET</data>
      <data key="d1">ORCA-BENCH is a specialized test dataset designed to assess the performance of models trained using the AgentInstruct methodology. It serves as a benchmark for evaluating various AI models, including advanced iterations like GPT-4. The evaluation is conducted on a scale from 0 to 10, providing a structured framework for measuring the effectiveness and capabilities of these models in real-world applications. This dataset plays a crucial role in the ongoing development and refinement of AI technologies, ensuring that models are rigorously tested and validated against established performance metrics.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="TOTAL CALORIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Total calories represent the caloric content of each meal, providing a breakdown of energy intake for the meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="NUTRITIONAL INFORMATION">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Nutritional information includes details about the caloric and nutritional content of specific recipes, such as the Quinoa Salad.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="INSTRUCTIONS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Instructions are the specific guidelines or steps provided for preparing each recipe included in the meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="TOKENIZATION PROCESS">
      <data key="d0">PROCESS</data>
      <data key="d1">The tokenization process involves converting text data into tokens for processing by machine learning models.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="TRAINING DETAILS">
      <data key="d0">PROCESS</data>
      <data key="d1">Training details encompass the methodologies and parameters used to train machine learning models, including batch size and learning rates.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="EVALUATION RESULTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The "EVALUATION RESULTS" encompass the performance metrics derived from testing language models on designated datasets, including MIRAGE. These results provide a comprehensive summary of the performance metrics and outcomes of the models evaluated against these specific datasets, offering insights into their effectiveness and reliability in various applications.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="FOOD ITEMS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-2.5">
      <data key="d0">MODEL</data>
      <data key="d1">Orca-2.5 is a baseline AI model that has been evaluated against GPT-4 using the Orca-Bench dataset. It represents a previous iteration of the Orca language model, specifically designed to serve as a benchmark for performance comparisons with newer models, such as Orca-3. This model plays a crucial role in assessing advancements in AI capabilities by providing a standard reference point for evaluating the performance of subsequent iterations in the Orca series.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MISTRAL-INSTRUCT-7B">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-Instruct-7B is a baseline AI model evaluated against GPT-4 in the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="LLAMA3-8B">
      <data key="d0">MODEL</data>
      <data key="d1">LLAMA3-8B is a baseline AI model evaluated against GPT-4 in the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="GPT-3.5-TURBO">
      <data key="d0">MODEL</data>
      <data key="d1">GPT-3.5-Turbo is a variant of the GPT-3 model, specifically designed to enhance efficiency in conversational AI tasks. It serves as a baseline AI model in evaluations against GPT-4 within the Orca-Bench dataset. Additionally, GPT-3.5-Turbo is utilized in comparative assessments alongside other models, particularly focusing on summarization performance. This multifaceted role underscores its significance in the landscape of artificial intelligence and natural language processing.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="PERFORMANCE COMPARISON">
      <data key="d0">ANALYSIS</data>
      <data key="d1">Performance comparison refers to the evaluation of different AI models based on their scores in the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MULTI-TURN INTERACTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Multi-turn interaction refers to a sequence of exchanges in a conversation, where multiple user inputs and assistant responses are involved.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="STUDENT RESPONSE">
      <data key="d0">RESPONSE</data>
      <data key="d1">The term "Student Response" encompasses two distinct yet related interpretations within the context of educational interactions. Firstly, it refers to the generated reply from an AI model, which is conditioned on the preceding conversation history established by a teacher model. This highlights the role of artificial intelligence in facilitating dialogue and learning by generating contextually relevant responses based on prior exchanges. Secondly, "student response" also pertains to the answer provided by a student in reaction to a question posed, which may include multiple answers or options chosen. This duality illustrates the interplay between AI-generated responses and traditional student engagement, emphasizing the importance of both technological and human elements in the learning process.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="TEACHER RESPONSE">
      <data key="d0">RESPONSE</data>
      <data key="d1">Teacher response is the original reply generated by the GPT-4 model, used as a benchmark for evaluating student responses.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="SCORE NORMALIZATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Score normalization is the process of adjusting scores to a standard scale, in this case, converting student scores to a 0 to 10 scale.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="PERFORMANCE AUGMENTATION">
      <data key="d0">ANALYSIS</data>
      <data key="d1">Performance augmentation refers to the improvement in model performance as a result of incorporating additional training data, such as AgentInstruct.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="COMPLEX ODQA">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="EQBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">EQBench is an emotional intelligence benchmark that evaluates language models' abilities to comprehend emotions and social interactions through conversation analysis.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="FOFO">
      <data key="d0">BENCHMARK</data>
      <data key="d1">FOFO is a benchmark designed to assess the format-following capabilities of AI models, particularly utilizing GPT-4 as a judge. It evaluates how well these models adhere to complex, domain-specific formats in various real-world applications. By focusing on format correctness, FOFO serves as a critical tool for understanding and improving the performance of AI models in practical scenarios.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="IFEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">IFEval is a benchmark designed to assess the capability of models in adhering to verifiable instructions provided in prompts. It specifically focuses on Instruction-Following Evaluation, which measures a model's proficiency in following natural language instructions through a series of prompts. This evaluation framework aims to ensure that models can accurately interpret and execute tasks as specified, thereby enhancing their reliability and effectiveness in practical applications.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="MT-BENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">MT-Bench is a benchmark specifically designed to evaluate the competence of chat assistants in handling multi-turn conversations. It utilizes GPT-4 as the evaluator to assess the quality of model responses. The evaluation process involves analyzing responses based on both first-turn and second-turn queries, ensuring a comprehensive assessment of conversational capabilities. Through this methodology, MT-Bench aims to provide insights into the effectiveness and performance of chat assistants in dynamic dialogue scenarios.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="INFOBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">INFOBENCH is an evaluation framework designed to assess the instruction-following capabilities of various models. It employs a specific metric known as the Decomposed Requirements Following Ratio (DRFR) to quantify how well models adhere to detailed instructions. In this process, INFOBENCH utilizes GPT-4 as a judge to evaluate the responses generated by the models, ensuring a rigorous assessment of their performance in following decomposed instructions. This dual approach of using a defined metric alongside a sophisticated AI judge highlights INFOBENCH's commitment to providing a comprehensive evaluation of model capabilities in the realm of instruction adherence.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="MISTRAL-7B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-7B-Instruct is a language model utilized as a baseline for comparison in various benchmarks, particularly excelling in reading comprehension tasks. It has been evaluated against other AI models, specifically Orca-3 and Orca-2.5, in performance assessments that focus on reading comprehension and mathematical capabilities. Additionally, Mistral-7B-Instruct serves as a reference point for evaluating the performance of Orca-3-7B, further establishing its role in the comparative analysis of language models within the field of artificial intelligence.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="MISTRAL">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral is a language model that has shown improvements in reading comprehension capabilities through targeted training.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="ELEMENTARY MATH">
      <data key="d0">SUBJECT</data>
      <data key="d1">Elementary math refers to basic mathematical concepts and skills typically taught at the primary education level, where AI models have shown considerable improvement.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="HIGH SCHOOL MATHEMATICS">
      <data key="d0">SUBJECT</data>
      <data key="d1">High school mathematics encompasses more complex mathematical concepts taught at the secondary education level, where AI models often struggle.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="COLLEGE MATHEMATICS">
      <data key="d0">SUBJECT</data>
      <data key="d1">College mathematics includes advanced mathematical topics taught at the tertiary education level, presenting challenges for AI models.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="LSATS">
      <data key="d0">EXAM</data>
      <data key="d1">The Law School Admission Tests (LSATs) are standardized tests used for law school admissions, known for their difficulty, particularly in reading comprehension.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="MATH PROBLEMS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="ORCA-3-7B">
      <data key="d0">MODEL</data>
      <data key="d1">Orca-3-7B is a language model evaluated for its performance on various summarization benchmarks, showing improvements over previous versions like Orca 2.5 and Mistral-7B-Instruct.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="HALLUCINATION RATE">
      <data key="d0">METRIC</data>
      <data key="d1">Hallucination rate is a metric used to measure the frequency of incorrect or fabricated information generated by language models during summarization tasks.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="QUALITY SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">Quality score is a metric that evaluates the overall quality of the summarization output from language models, rated on a scale from 1 to 10.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="ACI-BENCH">
      <data key="d0">DATASET</data>
      <data key="d1">ACI-Bench is a dataset designed for benchmarking automatic report generation from doctor-patient conversations, consisting of 120 data points.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="INSTRUSUM">
      <data key="d0">DATASET</data>
      <data key="d1">InstruSum is a dataset for evaluating instruction-controllable summarization capabilities of language models, containing 100 data points.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="ORCA-SUM">
      <data key="d0">DATASET</data>
      <data key="d1">Orca-Sum is a benchmark created to evaluate language models' ability to follow summarization and grounded data transformation instructions, with a total of 458 data points.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MIRAGE">
      <data key="d0">DATASET</data>
      <data key="d1">MIRAGE is a benchmark focusing on answering medical questions by referring to information retrieved from a medical corpus, used to assess RAG capabilities of language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="DATA TRANSFORMATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Data transformation refers to the process of converting data from one format or structure into another, often used in conjunction with summarization tasks.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="HUGGING FACE">
      <data key="d0">PLATFORM</data>
      <data key="d1">Hugging Face is a platform that hosts various datasets and models for natural language processing, including those used for summarization tasks.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MIRAGE DATASETS">
      <data key="d0">DATASET</data>
      <data key="d1">MIRAGE Datasets are a collection of datasets used for evaluating the performance of various language models on specific tasks.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="ORCA-2.5-7B">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Orca-2.5-7B is a language model that has been evaluated for its performance on various datasets, including MIRAGE.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="PUBMEDQA">
      <data key="d0">DATASET</data>
      <data key="d1">PubMedQA is a dataset used for evaluating the performance of models in retrieving and generating answers from medical literature.PubMedQA is a dataset used for assessing the ability of models to perform retrieval-augmented generation (RAG) tasks.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">RAG (Retrieval-Augmented Generation) is a technique that combines retrieval of relevant documents with generative capabilities of language models.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="USMEDMCQA">
      <data key="d0">DATASET</data>
      <data key="d1">USMedMCQA is a dataset designed for assessing the capabilities of language models in medical question-answering scenarios.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="CO-T">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">CoT (Chain of Thought) is a technique used in language models to improve reasoning and performance on complex tasks.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MEDMEDQA">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="AZURE">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Azure is a cloud computing service created by Microsoft, providing various services including AI and machine learning capabilities.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CONTENT HARMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Content harms refer to the negative impacts that large language models can have, including the generation of disinformation or harmful content.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CONTENT MODERATION SERVICES">
      <data key="d0">SERVICE</data>
      <data key="d1">Content moderation services are tools and systems provided by companies and institutions to help manage and mitigate harmful content generated by AI models.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="REGULATIONS AND STANDARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Regulations and standards are guidelines proposed for government and technology leaders to ensure safe and ethical use of AI technologies.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HALLUCINATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Hallucination in AI refers to the phenomenon where language models generate fabricated or misleading content, which can lead to misinformation.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="UNSTRUCTURED DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Unstructured data refers to information that does not have a predefined data model, making it more challenging to analyze but valuable for generating insights.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RESEARCH COMMUNITY">
      <data key="d0">GROUP</data>
      <data key="d1">The research community consists of individuals and organizations engaged in the study and development of AI technologies, contributing to advancements and ethical considerations.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SAM ADE JACOBS">
      <data key="d0">PERSON</data>
      <data key="d1">Sam Ade Jacobs is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMMAR AHMAD AWAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ammar Ahmad Awan is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JYOTI ANEJA">
      <data key="d0">PERSON</data>
      <data key="d1">Jyoti Aneja is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AHMED AWADALLAH">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmed Awadallah is a prominent researcher in the field of Artificial Intelligence, particularly known for his contributions to the development of advanced AI technologies. He has played a significant role in the creation of the Phi-3 technical report, showcasing his expertise and involvement in cutting-edge research. Additionally, Awadallah has co-authored several papers on Orca and Orca 2, where he has focused on enhancing language models, further solidifying his position as a key figure in the advancement of natural language processing. His work reflects a commitment to pushing the boundaries of AI and improving the capabilities of language models in various applications.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HANY AWADALLA">
      <data key="d0">PERSON</data>
      <data key="d1">Hany Awadalla is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NGUYEN BACH">
      <data key="d0">PERSON</data>
      <data key="d1">Nguyen Bach is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIT BAHREE">
      <data key="d0">PERSON</data>
      <data key="d1">Amit Bahree is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ARASH BAKHTIARI">
      <data key="d0">PERSON</data>
      <data key="d1">Arash Bakhtiari is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIANMIN BAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jianmin Bao is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HARKIRAT BEHL">
      <data key="d0">PERSON</data>
      <data key="d1">Harkirat Behl is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ALON BENHAIM">
      <data key="d0">PERSON</data>
      <data key="d1">Alon Benhaim is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MISHA BILENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Misha Bilenko is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JOHAN BJORCK">
      <data key="d0">PERSON</data>
      <data key="d1">Johan Bjorck is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="S&#201;BASTIEN BUBECK">
      <data key="d0">PERSON</data>
      <data key="d1">S&#233;bastien Bubeck is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="QIN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Qin Cai is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARTIN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Martin Cai is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CAIO C&#201;SAR TEODORO MENDES">
      <data key="d0">PERSON</data>
      <data key="d1">Caio C&#233;sar Teodoro Mendes is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="VISHRAV CHAUDHARY">
      <data key="d0">PERSON</data>
      <data key="d1">Vishrav Chaudhary is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Dong Chen is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONGDONG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Dongdong Chen is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YEN-CHUN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yen-Chun Chen is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YI-LING CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yi-Ling Chen is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PARUL CHOPRA">
      <data key="d0">PERSON</data>
      <data key="d1">Parul Chopra is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIYANG DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Xiyang Dai is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ALLIE DEL GIORNO">
      <data key="d0">PERSON</data>
      <data key="d1">Allie Del Giorno is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GUSTAVO DE ROSA">
      <data key="d0">PERSON</data>
      <data key="d1">Gustavo de Rosa is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MATTHEW DIXON">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew Dixon is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RONEN ELDAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ronen Eldan is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="VICTOR FRAGOSO">
      <data key="d0">PERSON</data>
      <data key="d1">Victor Fragoso is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DAN ITER">
      <data key="d0">PERSON</data>
      <data key="d1">Dan Iter is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MEI GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Mei Gao is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MIN GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Min Gao is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIANFENG GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jianfeng Gao is a prominent researcher in the field of Artificial Intelligence, actively contributing to the advancement of AI technologies. He has played a significant role in the development of the Phi-3 technical report, showcasing his expertise and involvement in cutting-edge AI research. Additionally, Jianfeng Gao co-authored a paper focused on instruction tuning with GPT-4, further highlighting his contributions to the evolving landscape of Natural Language Processing. His work reflects a commitment to enhancing AI capabilities and understanding, positioning him as a key figure in the AI research community.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIT GARG">
      <data key="d0">PERSON</data>
      <data key="d1">Amit Garg is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ABHISHEK GOSWAMI">
      <data key="d0">PERSON</data>
      <data key="d1">Abhishek Goswami is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SURIYA GUNASEKAR">
      <data key="d0">PERSON</data>
      <data key="d1">Suriya Gunasekar is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="EMMAN HAIDER">
      <data key="d0">PERSON</data>
      <data key="d1">Emman Haider is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JUNHENG HAO">
      <data key="d0">PERSON</data>
      <data key="d1">Junheng Hao is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RUSSELL J. HEWETT">
      <data key="d0">PERSON</data>
      <data key="d1">Russell J. Hewett is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JAMIE HUYNH">
      <data key="d0">PERSON</data>
      <data key="d1">Jamie Huynh is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MOJAN JAVAHERIPI">
      <data key="d0">PERSON</data>
      <data key="d1">Mojan Javaheripi is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIN JIN">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Jin is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PIERO KAUFFMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Piero Kauffmann is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NIKOS KARAMPATZIAKIS">
      <data key="d0">PERSON</data>
      <data key="d1">Nikos Karampatziakis is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONGWOO KIM">
      <data key="d0">PERSON</data>
      <data key="d1">Dongwoo Kim is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MAHOUD KHADEMI">
      <data key="d0">PERSON</data>
      <data key="d1">Mahoud Khademi is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LEV KURILENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Lev Kurilenko is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JAMES R. LEE">
      <data key="d0">PERSON</data>
      <data key="d1">James R. Lee is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YIN TAT LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Yin Tat Lee is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YUANZHI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yuanzhi Li is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YUNSHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yunsheng Li is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHEN LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Liang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LARS LIDEN">
      <data key="d0">PERSON</data>
      <data key="d1">Lars Liden is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CE LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Ce Liu is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MENGCHEN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Mengchen Liu is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="WEISHUNG LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Weishung Liu is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ERIC LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Lin is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHONG LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Chong Luo is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PIYUSH MADAN">
      <data key="d0">PERSON</data>
      <data key="d1">Piyush Madan is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MATT MAZZOLA">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Mazzola is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ARINDAM MITRA">
      <data key="d0">PERSON</data>
      <data key="d1">Arindam Mitra is a prominent researcher in the field of Artificial Intelligence, particularly known for his contributions to the development of advanced AI technologies. He has played a significant role in the creation of the Phi-3 technical report, showcasing his expertise and involvement in cutting-edge research. Additionally, Mitra has co-authored several influential papers focused on enhancing language models, including notable works such as Orca 2 and Orca-Math. His contributions reflect a deep commitment to advancing the capabilities of AI and Natural Language Processing.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HARDIK MODI">
      <data key="d0">PERSON</data>
      <data key="d1">Hardik Modi is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BRANDON NORICK">
      <data key="d0">PERSON</data>
      <data key="d1">Brandon Norick is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BARUN PATRA">
      <data key="d0">PERSON</data>
      <data key="d1">Barun Patra is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DANIEL PEREZ-BECKER">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Perez-Becker is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="THOMAS PORTET">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Portet is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="REID PRYZANT">
      <data key="d0">PERSON</data>
      <data key="d1">Reid Pryzant is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HEYANG QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Heyang Qin is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARKO RADMILAC">
      <data key="d0">PERSON</data>
      <data key="d1">Marko Radmilac is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CORBY ROSSET">
      <data key="d0">PERSON</data>
      <data key="d1">Corby Rosset is a dedicated researcher in the field of Artificial Intelligence, particularly noted for his contributions to the development of advanced AI technologies. He has played a significant role in the creation of the Phi-3 technical report, showcasing his expertise and commitment to the advancement of AI. Additionally, Rosset has co-authored several papers on Orca and Orca 2, where he has focused on enhancing language models, further solidifying his position as a key figure in the ongoing evolution of natural language processing. Through his work, Corby Rosset continues to influence the landscape of AI research and development.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SAMBUDHA ROY">
      <data key="d0">PERSON</data>
      <data key="d1">Sambudha Roy is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OLATUNJI RUWASE">
      <data key="d0">PERSON</data>
      <data key="d1">Olatunji Ruwase is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OLLI SAARIKIVI">
      <data key="d0">PERSON</data>
      <data key="d1">Olli Saarikivi is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIN SAIED">
      <data key="d0">PERSON</data>
      <data key="d1">Amin Saied is a dedicated researcher actively engaged in the advancement of artificial intelligence technologies. He has made significant contributions to the Phi-3 technical report, showcasing his expertise in the field. In addition to this, he co-authored a paper in 2023 that focuses on a human-centric benchmark for evaluating foundation models, further emphasizing his commitment to enhancing the evaluation processes within AI research. Through these efforts, Amin Saied plays a vital role in shaping the future of AI and its applications.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ADIL SALIM">
      <data key="d0">PERSON</data>
      <data key="d1">Adil Salim is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MICHAEL SANTACROCE">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Santacroce is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SHITAL SHAH">
      <data key="d0">PERSON</data>
      <data key="d1">Shital Shah is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NING SHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ning Shang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HITESHI SHARMA">
      <data key="d0">PERSON</data>
      <data key="d1">Hiteshi Sharma is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SWADHEEN SHUKLA">
      <data key="d0">PERSON</data>
      <data key="d1">Swadheen Shukla is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIA SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Xia Song is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MASAHIRO TANAKA">
      <data key="d0">PERSON</data>
      <data key="d1">Masahiro Tanaka is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ANDREA TUPINI">
      <data key="d0">PERSON</data>
      <data key="d1">Andrea Tupini is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Wang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LIJUAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Lijuan Wang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHUNYU WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chunyu Wang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YU WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Wang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RACHEL WARD">
      <data key="d0">PERSON</data>
      <data key="d1">Rachel Ward is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GUANHUA WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Guanhua Wang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PHILIPP WITTE">
      <data key="d0">PERSON</data>
      <data key="d1">Philipp Witte is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PHI-3">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Phi-3 is a highly capable language model designed to operate locally on mobile devices, as detailed in the technical report from 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ISAAC COWHEY">
      <data key="d0">PERSON</data>
      <data key="d1">Isaac Cowhey is a researcher who contributed to the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OREN ETZIONI">
      <data key="d0">PERSON</data>
      <data key="d1">Oren Etzioni is a researcher involved in the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TUSHAR KHOT">
      <data key="d0">PERSON</data>
      <data key="d1">Tushar Khot is a researcher who worked on the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ASHISH SABHARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Ashish Sabharwal is a researcher associated with the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CARISSA SCHOENICK">
      <data key="d0">PERSON</data>
      <data key="d1">Carissa Schoenick is a researcher who contributed to the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OYVIND TAFJORD">
      <data key="d0">PERSON</data>
      <data key="d1">Oyvind Tafjord is a researcher involved in the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NING DING">
      <data key="d0">PERSON</data>
      <data key="d1">Ning Ding is a researcher known for enhancing chat language models through instructional conversations.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YULIN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yulin Chen is a researcher involved in enhancing chat language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BOKAI XU">
      <data key="d0">PERSON</data>
      <data key="d1">Bokai Xu is a researcher who contributed to enhancing chat language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHI ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhi Zheng is a researcher who contributed to enhancing chat language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHENGDING HU">
      <data key="d0">PERSON</data>
      <data key="d1">Shengding Hu is a researcher involved in enhancing chat language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHIYUAN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Liu is a researcher who contributed to enhancing chat language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DROPS">
      <data key="d0">RESEARCH</data>
      <data key="d1">DROP is a reading comprehension benchmark that requires discrete reasoning over paragraphs, as discussed in a 2019 conference paper.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHAOYE FEI">
      <data key="d0">PERSON</data>
      <data key="d1">Zhaoye Fei is a researcher known for unearthing large-scale domain-specific knowledge from public corpora.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUNFAN SHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yunfan Shao is a researcher involved in unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LINYANG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Linyang Li is a researcher who contributed to unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHIYUAN ZENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Zeng is a researcher involved in unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANG YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Hang Yan is a researcher who contributed to unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XIPENG QIU">
      <data key="d0">PERSON</data>
      <data key="d1">Xipeng Qiu is a researcher involved in unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DAHUA LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Dahua Lin is a researcher who contributed to unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ARNA GUDIBANDE">
      <data key="d0">PERSON</data>
      <data key="d1">Arnav Gudibande is a researcher known for discussing the limitations of imitating proprietary language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC WALLACE">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Wallace is a researcher involved in discussing the limitations of imitating proprietary language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHARLIE SNELL">
      <data key="d0">PERSON</data>
      <data key="d1">Charlie Snell is a researcher who contributed to the discussion on imitating proprietary language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XINYANG GENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyang Geng is a researcher involved in discussing the limitations of imitating proprietary language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAO LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Liu is a researcher who contributed to the discussion on imitating proprietary language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SAURAV KADAVATH">
      <data key="d0">PERSON</data>
      <data key="d1">Saurav Kadavath is a researcher who contributed to measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AKUL ARORA">
      <data key="d0">PERSON</data>
      <data key="d1">Akul Arora is a researcher involved in measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Tang is a researcher involved in measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NOAH A. SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Noah A. Smith is a researcher who contributed to measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="IZ BELTAGY">
      <data key="d0">PERSON</data>
      <data key="d1">Iz Beltagy is a researcher involved in measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANNANEH HAJISHIRZI">
      <data key="d0">PERSON</data>
      <data key="d1">Hannaneh Hajishirzi is a researcher who contributed to measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CAMELS">
      <data key="d0">RESEARCH</data>
      <data key="d1">Camels in a changing climate is a study focused on enhancing language model adaptation, as discussed in a 2023 paper.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALBERT Q. JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Albert Q. Jiang is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALEXANDRE SABLAYROLLES">
      <data key="d0">PERSON</data>
      <data key="d1">Alexandre Sablayrolles is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ARTHUR MENSCH">
      <data key="d0">PERSON</data>
      <data key="d1">Arthur Mensch is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHRIS BAMFORD">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Bamford is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DEVENDRA SINGH CHAPLOT">
      <data key="d0">PERSON</data>
      <data key="d1">Devendra Singh Chaplot is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DIEGO DE LAS CASAS">
      <data key="d0">PERSON</data>
      <data key="d1">Diego de las Casas is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="FLORIAN BRESSAND">
      <data key="d0">PERSON</data>
      <data key="d1">Florian Bressand is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GIANNA LENGYEL">
      <data key="d0">PERSON</data>
      <data key="d1">Gianna Lengyel is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GUILLAUME LAMPLE">
      <data key="d0">PERSON</data>
      <data key="d1">Guillaume Lample is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LUCILE SAULNIER">
      <data key="d0">PERSON</data>
      <data key="d1">Lucile Saulnier is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="L&#201;LIO RENARD LAVAUD">
      <data key="d0">PERSON</data>
      <data key="d1">L&#233;lio Renard Lavaud is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PIERRE STOCK">
      <data key="d0">PERSON</data>
      <data key="d1">Pierre Stock is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TEVEN LE SCAO">
      <data key="d0">PERSON</data>
      <data key="d1">Teven Le Scao is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="THOMAS WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Wang is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TIMOTH&#201;E LACROIX">
      <data key="d0">PERSON</data>
      <data key="d1">Timoth&#233;e Lacroix is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="WILLIAM EL SAYED">
      <data key="d0">PERSON</data>
      <data key="d1">William El Sayed is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AI2 REASONING CHALLENGE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TRAINING VERIFIERS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="UNEARTHING DOMAIN-SPECIFIC KNOWLEDGE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XUECHEN LI">
      <data key="d0" />
      <data key="d1">Xuechen Li is a researcher known for co-authoring a paper focused on an automatic evaluator designed for instruction-following models. This work contributes to the field of Artificial Intelligence, particularly in enhancing the evaluation processes of models that follow specific instructions.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TIANYI ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Tianyi Zhang is a researcher recognized for significant contributions in the field of Artificial Intelligence, particularly in the development of advanced models and communicative agents. Zhang co-authored a paper focused on an automatic evaluator designed for instruction-following models, showcasing expertise in evaluating AI performance. Additionally, Zhang has played a pivotal role in the development of communicative agents aimed at exploring the dynamics within large language model societies, further emphasizing a commitment to enhancing interaction and understanding in AI systems. Through these efforts, Tianyi Zhang is actively contributing to the advancement of AI technologies and their applications in real-world scenarios.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YANN DUBOIS">
      <data key="d0">PERSON</data>
      <data key="d1">Yann Dubois is a researcher actively engaged in the development of communicative agents aimed at exploring the societal implications of large language models. In addition to his work on communicative agents, he has co-authored a paper focused on an automatic evaluator designed for instruction-following models. Through these contributions, Dubois plays a significant role in advancing the understanding and functionality of artificial intelligence within the context of natural language processing.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ROHAN TAORI">
      <data key="d0">PERSON</data>
      <data key="d1">Rohan Taori is a researcher recognized for his contributions to the field of Artificial Intelligence, particularly in the development of advanced models and communicative agents. He co-authored a paper focused on an automatic evaluator designed for instruction-following models, showcasing his expertise in evaluating AI systems. Additionally, he has played a significant role in the development of communicative agents aimed at exploring the dynamics within large language model societies. Through these efforts, Rohan Taori is actively contributing to the advancement of AI technologies and their applications in understanding and enhancing human-computer interactions.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ISHAAN GULRAJANI">
      <data key="d0">PERSON</data>
      <data key="d1">Ishaan Gulrajani is a researcher actively engaged in the development of communicative agents aimed at exploring the societal implications of large language models. In addition to this work, he has co-authored a paper focused on an automatic evaluator designed for instruction-following models, contributing to the advancement of evaluation methodologies in the field of artificial intelligence. His research efforts reflect a commitment to enhancing the understanding and functionality of AI systems within their societal contexts.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CARLOS GUESTRIN">
      <data key="d0">PERSON</data>
      <data key="d1">Carlos Guestrin is a prominent researcher known for his contributions to the field of Artificial Intelligence, particularly in the development of advanced models and communicative agents. He co-authored a paper focused on an automatic evaluator designed for instruction-following models, showcasing his expertise in evaluating AI systems. Additionally, Guestrin has played a significant role in the development of communicative agents aimed at exploring the dynamics within large language model societies. His work reflects a deep commitment to enhancing the capabilities and understanding of AI technologies.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TATSUNORI B. HASHIMOTO">
      <data key="d0">PERSON</data>
      <data key="d1">Tatsunori B. Hashimoto is a researcher who contributed to the development of communicative agents for exploring large language model society.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="KHIZBULLIN">
      <data key="d0">PERSON</data>
      <data key="d1">Khizbullin is a researcher involved in the study of communicative agents for exploring large language model society.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BERNARD GHANEM">
      <data key="d0">PERSON</data>
      <data key="d1">Bernard Ghanem is a researcher who co-authored a work on communicative agents for mind exploration in large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CAMEL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Camel refers to a system of communicative agents designed for exploring the capabilities and interactions within large language model societies.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="TATSUNORI HASHIMOTO">
      <data key="d0">PERSON</data>
      <data key="d1">Tatsunori Hashimoto is a researcher who co-authored a paper on an automatic evaluator for instruction-following models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YIXIN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Yixin Liu is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ALEXANDER R. FABBRI">
      <data key="d0">PERSON</data>
      <data key="d1">Alexander R. Fabbri is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JIAWEN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jiawen Chen is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YILUN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yilun Zhao is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SIMENG HAN">
      <data key="d0">PERSON</data>
      <data key="d1">Simeng Han is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SHAFIQ JOTY">
      <data key="d0">PERSON</data>
      <data key="d1">Shafiq Joty is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DRAGOMIR RADEV">
      <data key="d0">PERSON</data>
      <data key="d1">Dragomir Radev is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CHIEN-SHENG WU">
      <data key="d0">PERSON</data>
      <data key="d1">Chien-Sheng Wu is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ARMAN COHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Arman Cohan is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="COSMOPEDIA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Cosmopedia is a project focused on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ORCA 2">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Orca 2 is a system designed to teach small language models how to reason effectively.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ORCA-MATH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Orca-Math is a project aimed at enhancing the capabilities of small language models in grade school math.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XTREMEDISTIL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Xtremedistil is a method for multi-stage distillation aimed at creating massive multilingual models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DIRECT NASH OPTIMIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Direct Nash Optimization is a method for teaching language models to self-improve based on general preferences.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="THE CURSE OF RECURSION">
      <data key="d0">RESEARCH</data>
      <data key="d1">The Curse of Recursion refers to a phenomenon where training on generated data causes models to forget previous knowledge.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BENCHMARKING GENERATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LOUBNA BEN ALLAL">
      <data key="d0">PERSON</data>
      <data key="d1">Loubna Ben Allal is a researcher who co-authored a paper on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ANTON LOZHKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Anton Lozhkov is a researcher who co-authored a paper on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LUCIANO DEL CORRO">
      <data key="d0">PERSON</data>
      <data key="d1">Luciano Del Corro is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SHWETI MAHAJAN">
      <data key="d0">PERSON</data>
      <data key="d1">Shweti Mahajan is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ANDRES CODAS">
      <data key="d0">PERSON</data>
      <data key="d1">Andres Codas is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CLARISSE SIMOES">
      <data key="d0">PERSON</data>
      <data key="d1">Clarisse Simoes is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SAHAJ AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Sahaj Agarwal is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XUXI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xuxi Chen is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ANASTASIA RAZDAIBIEDINA">
      <data key="d0">PERSON</data>
      <data key="d1">Anastasia Razdaibiedina is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ERIK JONES">
      <data key="d0">PERSON</data>
      <data key="d1">Erik Jones is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KRITI AGGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Kriti Aggarwal is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="HAMID PALANGI">
      <data key="d0">PERSON</data>
      <data key="d1">Hamid Palangi is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="GUOQING ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Guoqing Zheng is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="HAMED KHANPOUR">
      <data key="d0">PERSON</data>
      <data key="d1">Hamed Khanpour is a researcher who co-authored multiple papers on Orca and Orca 2, focusing on enhancing language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SAMUEL J. PAECH">
      <data key="d0">PERSON</data>
      <data key="d1">Samuel J. Paech is a researcher who co-authored a paper on an emotional intelligence benchmark for large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BAOLIN PENG">
      <data key="d0">PERSON</data>
      <data key="d1">Baolin Peng is a researcher who co-authored a paper on instruction tuning with GPT-4.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CHUNYUAN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Chunyuan Li is a researcher who co-authored a paper on instruction tuning with GPT-4.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="PENGCHENG HE">
      <data key="d0">PERSON</data>
      <data key="d1">Pengcheng He is a researcher who co-authored a paper on instruction tuning with GPT-4.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="MICHEL GALLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Michel Galley is a researcher who co-authored a paper on instruction tuning with GPT-4.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DANIEL VAN STRIEN">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="EQ-BENCH">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ILIA SHUMAILOV">
      <data key="d0">PERSON</data>
      <data key="d1">Ilia Shumailov is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZAKHAR SHUMAYLOV">
      <data key="d0">PERSON</data>
      <data key="d1">Zakhar Shumaylov is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIREN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiren Zhao is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NICOLAS PAPERNOT">
      <data key="d0">PERSON</data>
      <data key="d1">Nicolas Papernot is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ROSS ANDERSON">
      <data key="d0">PERSON</data>
      <data key="d1">Ross Anderson is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MOHAMMED LATIF SIDDIQ">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammed Latif Siddiq is a researcher who co-authored a paper on evaluating generated regular expressions in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAHAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiahao Zhang is a researcher who co-authored a paper on evaluating generated regular expressions in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LINDSAY RONEY">
      <data key="d0">PERSON</data>
      <data key="d1">Lindsay Roney is a researcher who co-authored a paper on evaluating generated regular expressions in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JOANNA C. S. SANTOS">
      <data key="d0">PERSON</data>
      <data key="d1">Joanna C. S. Santos is a researcher who co-authored a paper on evaluating generated regular expressions in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NATHAN SCALES">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Scales is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NATHANAEL SCH&#196;RLI">
      <data key="d0">PERSON</data>
      <data key="d1">Nathanael Sch&#228;rli is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QUOC V. LE">
      <data key="d0">PERSON</data>
      <data key="d1">Quoc V. Le is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEN WAI YIM">
      <data key="d0">PERSON</data>
      <data key="d1">Wen Wai Yim is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YUJUAN FU">
      <data key="d0">PERSON</data>
      <data key="d1">Yujuan Fu is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ASMA BEN ABACHA">
      <data key="d0">PERSON</data>
      <data key="d1">Asma Ben Abacha is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NEAL SNIDER">
      <data key="d0">PERSON</data>
      <data key="d1">Neal Snider is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="THOMAS LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Lin is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MELIHA YETISGEN">
      <data key="d0">PERSON</data>
      <data key="d1">Meliha Yetisgen is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="BEIBIN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Beibin Li is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ERKANG ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Erkang Zhu is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LI JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Li Jiang is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIAOYUN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaoyun Zhang is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AHMED HASSAN AWADALLAH">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmed Hassan Awadallah is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RYEN W WHITE">
      <data key="d0">PERSON</data>
      <data key="d1">Ryen W White is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DOUG BURGER">
      <data key="d0">PERSON</data>
      <data key="d1">Doug Burger is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CONGYING XIA">
      <data key="d0">PERSON</data>
      <data key="d1">Congying Xia is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHEN XING">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Xing is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIANGSHU DU">
      <data key="d0">PERSON</data>
      <data key="d1">Jiangshu Du is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XINYI YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyi Yang is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIHAO FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Yihao Feng is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RAN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Ran Xu is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WENPENG YIN">
      <data key="d0">PERSON</data>
      <data key="d1">Wenpeng Yin is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CAIMING XIONG">
      <data key="d0">PERSON</data>
      <data key="d1">Caiming Xiong is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CAN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Can Xu is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QINGFENG SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Qingfeng Sun is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="KAI ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Kai Zheng is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIUBO GENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiubo Geng is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="PU ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Pu Zhao is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAZHAN FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiazhan Feng is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHONGYANG TAO">
      <data key="d0">PERSON</data>
      <data key="d1">Chongyang Tao is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DAXIN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Daxin Jiang is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LONGHUI YU">
      <data key="d0">PERSON</data>
      <data key="d1">Longhui Yu is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEISEN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Weisen Jiang is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="HAN SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Han Shi is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JINCHENG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Jincheng Yu is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHENGYING LI">
      <data key="d0">PERSON</data>
      <data key="d1">Zhengying Li is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Zhang is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JAMES T KWOK">
      <data key="d0">PERSON</data>
      <data key="d1">James T Kwok is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHENGUO LI">
      <data key="d0">PERSON</data>
      <data key="d1">Zhenguo Li is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ADRIAN WELLER">
      <data key="d0">PERSON</data>
      <data key="d1">Adrian Weller is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEIYANG LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Weiyang Liu is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIFAN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yifan Zhang is a researcher who co-authored a paper on autonomous data selection for mathematical texts in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIFAN LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Yifan Luo is a researcher who co-authored a paper on autonomous data selection for mathematical texts in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YANG YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Yang Yuan is a researcher who co-authored a paper on autonomous data selection for mathematical texts in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ANDREW CHI-CHIH YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Chi-Chih Yao is a researcher who co-authored a paper on autonomous data selection for mathematical texts in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WANJUN ZHONG">
      <data key="d0">PERSON</data>
      <data key="d1">Wanjun Zhong is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RUIXIANG CUI">
      <data key="d0">PERSON</data>
      <data key="d1">Ruixiang Cui is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIDUO GUO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiduo Guo is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YAOBO LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yaobo Liang is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SHUAI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Shuai Lu is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YANLIN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yanlin Wang is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NAN DUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Nan Duan is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JEFFREY ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Jeffrey Zhou is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="TIANJIAN LU">
      <data key="d0">PERSON</data>
      <data key="d1">Tianjian Lu is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SIDDHARTHA BRAHMA">
      <data key="d0">PERSON</data>
      <data key="d1">Siddhartha Brahma is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SUJOY BASU">
      <data key="d0">PERSON</data>
      <data key="d1">Sujoy Basu is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YI LUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Luan is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LE HOU">
      <data key="d0">PERSON</data>
      <data key="d1">Le Hou is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DEBATE PASSAGE GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Debate Passage Generator specializes in crafting passages that mimic debate transcripts.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CON(&quot;ENTITY&quot;">
      <data key="d0">CONVERSATION PASSAGE GENERATOR</data>
      <data key="d1">AGENT</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MEETING TRANSCRIPT GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Meeting Transcript Generator is designed to produce transcripts of meetings.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="POEM GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Poem Generator creates poems based on given prompts or themes.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SATIRICAL PASSAGE GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Satirical Passage Generator creates texts infused with satirical wit.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="INSTRUCTIONAL PASSAGE GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Instructional Passage Generator generates passages resembling instructional manuals.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LONG TEXT GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Long Text Generator extends original texts by incorporating additional information.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="IDENTITY AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">The Identity Agent replicates the input text verbatim without modifications.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LITERAL COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">A Literal Comprehension Question asks for specific details or facts clearly stated in the text.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NUMERICAL DISCRETE REASONING">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Numerical Discrete Reasoning refers to a type of questioning that necessitates the application of numerical reasoning skills by the reader. These questions require the reader to synthesize and analyze multiple facts presented in the text to arrive at a solution. Essentially, Numerical Discrete Reasoning challenges individuals to engage with numerical data in a comprehensive manner, drawing connections between various pieces of information to effectively interpret and respond to the questions posed.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CRITICAL COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">The entity "CRITICAL COMPREHENSION QUESTION" refers to a type of assessment that focuses on evaluating the understanding of a text. It involves analyzing two statements related to the text and determining their truthfulness, specifically assessing whether they are true or false. Additionally, critical comprehension questions require the construction of true/false statements that reflect the text's purpose or point of view. This dual approach emphasizes not only the comprehension of the material but also the ability to critically engage with its underlying messages and intentions.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="EVALUATIVE COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">The "Evaluative Comprehension Question" is a type of inquiry that necessitates the reader to engage in a deeper analysis of a text. It requires the construction of an essay that reflects on the text's purpose or point of view, encouraging the reader to critically assess the underlying themes and the effectiveness of the arguments presented. This form of questioning promotes a comprehensive understanding of the material, pushing readers to evaluate not just the content but also the intent and impact of the text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CONVERSATION PASSAGE GENERATOR">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="VOCABULARY AND LANGUAGE USE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Vocabulary and language use questions test understanding of specific words or phrases in the text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="RELATIONSHIP COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Relationship comprehension questions require matching items based on a specific criterion.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SEQUENCING EVENTS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Sequencing events questions ask respondents to arrange a series of events from the text in chronological order.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="STRENGTHEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Strengthen questions identify information that would make an argument's conclusion more likely to be true.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="WEAKEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Weaken questions find evidence or arguments that would make a conclusion less likely to be true.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="ASSUMPTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Assumption questions determine what must be true for an argument to hold.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="FLAW">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Flaw questions point out mistakes in an argument's reasoning.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="INFERENCE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Inference questions require choosing an option that logically follows from the provided information.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PRINCIPLE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Principle questions recognize the general rule or principle underlying an argument.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="METHOD OF REASONING">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Method of reasoning questions describe how an argument is logically constructed.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="RESOLVE THE PARADOX">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Resolve the paradox questions offer explanations that reconcile seemingly contradictory information.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PARAPHRASING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Paraphrasing involves rewriting text using different words and structures while maintaining the original meaning.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT SIMPLIFICATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text simplification makes text easier to read and understand, often for children or language learners.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT EXPANSION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text expansion adds more information or detail to make text more comprehensive.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT TRANSLATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text translation converts text from one language to another while preserving the original meaning.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT FORMATTING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text formatting alters the appearance of text to improve readability or for stylistic purposes.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SENTIMENT MODIFICATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Sentiment modification changes the tone of the text to alter its emotional impact.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT ANNOTATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text annotation adds notes or comments to a text for analysis or additional context.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="KEYWORD REPLACEMENT">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Keyword replacement substitutes specific words with synonyms or related terms.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT REMOVING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text removing involves redacting or removing content from text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT CAPITALIZATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text capitalization adjusts the case of letters in text for consistency.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT STYLING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text styling applies styles like bold or italics to emphasize parts of the text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="CONTENT REWRITING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Content rewriting extensively modifies text to produce a new version.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="DATA NORMALIZATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Data normalization standardizes text for consistency.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PLAGIARISM REWORDING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Plagiarism rewording alters text to avoid plagiarism.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="CODE SWITCHING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Code switching alternates between languages or dialects within a text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT OBFUSCATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text obfuscation intentionally makes text vague or harder to understand.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXTUAL ENTAILMENT">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Textual entailment modifies a sentence to either entail or contradict another.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="REWRITING WITH VOCABULARY LIMITATIONS">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Rewriting with vocabulary limitations involves rewriting text using a limited vocabulary.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">EVALUATION METHOD</data>
      <data key="d1">The GPT-4 extraction system message is used to parse student responses in multiple choice questions.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="INSTRUCTION TAXONOMY">
      <data key="d0">FRAMEWORK</data>
      <data key="d1">Instruction taxonomy is a classification system that organizes different types of instructions for generating text modifications.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="EVALUATION DETAILS">
      <data key="d0">PROCESS</data>
      <data key="d1">Evaluation details outline the methods and benchmarks used to assess the performance of models in generating responses.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="OPEN-ENDED GENERATION SETTING">
      <data key="d0">EVALUATION CONTEXT</data>
      <data key="d1">An open-ended generation setting allows models to produce responses without predefined constraints, facilitating creative output.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="GROUND TRUTH">
      <data key="d0">REFERENCE</data>
      <data key="d1">Ground truth refers to the accurate and verified information used as a benchmark for evaluating model predictions.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="ACCURACY SCORES">
      <data key="d0">METRIC</data>
      <data key="d1">Accuracy scores measure the correctness of model predictions against the ground truth in assessments.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT MODIFICATION FLOW">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="OPTIONS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Options are the possible answers provided to the student, typically formatted as a list of choices with corresponding letters.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE</data>
      <data key="d1">The Maths GPT-4 Extraction System Message is a set of instructions for evaluating a student's answer to a math problem, focusing on the final answer's correctness.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE</data>
      <data key="d1">The General Extraction System Message is a set of instructions for parsing student responses and matching them with the correct answer.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE</data>
      <data key="d1">The EQBench GPT-4 Extraction System Message is a set of instructions for extracting emotion scores from a student agent response based on a critique.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="MULTIPLE ANSWERS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Multiple answers refer to the scenario where a student provides more than one option as their response to a question.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ERROR ANALYSIS">
      <data key="d0">PROCESS</data>
      <data key="d1">Error analysis is the process of comparing the student's final answer with the correct answer to determine if they match.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="FINAL VERDICT">
      <data key="d0">PROCESS</data>
      <data key="d1">The final verdict is the conclusion drawn from the error analysis, indicating whether the student's answer is 'Correct' or 'Incorrect'.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ALPHABET ID">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ELLIOT">
      <data key="d0">PERSON</data>
      <data key="d1">Elliot is a character who has just confessed his feelings to Alex, experiencing a mix of emotions including resignation, anger, hopefulness, and embarrassment.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ALEX">
      <data key="d0">PERSON</data>
      <data key="d1">Alex is a character who is already in a relationship, which complicates Elliot's feelings after his confession.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMOTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Emotions are the feelings experienced by Elliot, including resignation, anger, hopefulness, and embarrassment, each rated on a scale.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="RESIGNED">
      <data key="d0">EMOTION</data>
      <data key="d1">Resigned is an emotion felt by Elliot, rated 7, indicating a sense of acceptance of his situation.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ANGRY">
      <data key="d0">EMOTION</data>
      <data key="d1">Angry is an emotion felt by Elliot, rated 3, indicating frustration with himself for his situation.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HOPEFUL">
      <data key="d0">EMOTION</data>
      <data key="d1">Hopeful is an emotion felt by Elliot, rated 5, indicating a desire for Alex to reciprocate his feelings.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMBARRASSED">
      <data key="d0">EMOTION</data>
      <data key="d1">Embarrassed is an emotion felt by Elliot, rated 8, indicating discomfort for putting Alex in an awkward position.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="OPEN-ENDED GENERATION">
      <data key="d0">TASK</data>
      <data key="d1">Open-ended generation refers to tasks where a model generates answers to questions without a specific ground-truth to match.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="RESIGNED SCORE">
      <data key="d0">DATA POINT</data>
      <data key="d1">The resigned score is a numerical value of 7, indicating the intensity of Elliot's feeling of resignation.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ANGRY SCORE">
      <data key="d0">DATA POINT</data>
      <data key="d1">The angry score is a numerical value of 3, indicating the intensity of Elliot's feeling of anger.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HOPEFUL SCORE">
      <data key="d0">DATA POINT</data>
      <data key="d1">The hopeful score is a numerical value of 5, indicating the intensity of Elliot's feeling of hopefulness.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMBARRASSED SCORE">
      <data key="d0">DATA POINT</data>
      <data key="d1">The embarrassed score is a numerical value of 8, indicating the intensity of Elliot's feeling of embarrassment.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="SCORES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <edge source="GRAPH RAG APPROACH" target="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach is designed to improve query-focused summarization by utilizing a graph-based text index for better responses.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d4">9.0</data>
      <data key="d5">The Graph RAG approach employs large language models to build a graph-based text index and generate summaries.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="SOURCE DOCUMENTS">
      <data key="d4">8.0</data>
      <data key="d5">Source documents are the basis for the Graph RAG approach, providing the text from which information is extracted and summarized.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="COMMUNITY SUMMARIES">
      <data key="d4">14.0</data>
      <data key="d5">The "GRAPH RAG APPROACH" utilizes "COMMUNITY SUMMARIES" as a key component in its methodology. Community summaries are generated to deliver partial answers to user queries, enhancing the overall user experience. Additionally, these summaries offer aggregated insights that bolster the analytical capabilities of the Graph RAG approach. Together, they facilitate a more effective understanding of community dynamics and support informed decision-making within the context of the approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach builds upon the principles of retrieval-augmented generation to enhance query-focused summarization capabilities.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="COMMUNITY DETECTION">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach utilizes community detection to partition the graph index into groups for more effective summarization.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="TOKEN RANGE">
      <data key="d4">1.0</data>
      <data key="d5">The token range of a dataset influences the performance of the Graph RAG approach, particularly in terms of comprehensiveness and diversity of answers.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach aims to enhance query-focused abstractive summarization by utilizing a knowledge graph for better context handling.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="LLM">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach employs LLMs to generate summaries and extract information from text chunks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="KURATOV ET AL. (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Kuratov et al. (2024) provides insights relevant to the performance and limitations of the Graph RAG approach in handling longer text chunks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="LIU ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Liu et al. (2023) provides insights relevant to the performance and limitations of the Graph RAG approach in handling longer text chunks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">7.0</data>
      <data key="d5">The Graph RAG approach utilizes community detection algorithms to partition graphs into modular communities for summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GPT">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach leverages the capabilities of GPT models for summarization tasks, enhancing performance through advanced language processing.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="LLAMA">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach utilizes Llama models to improve the efficiency and effectiveness of text summarization.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GEMINI">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach incorporates Gemini models to enhance its summarization capabilities through in-context learning.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ACHIAM ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Achiam et al. (2023) provides insights into the performance of GPT models, relevant to the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="BROWN ET AL. (2020)">
      <data key="d4">5.0</data>
      <data key="d5">Brown et al. (2020) discusses foundational aspects of LLMs that inform the design of the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="TOUVRON ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Touvron et al. (2023) provides insights into the Llama models that are relevant to the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ANIL ET AL. (2023)">
      <data key="d4">1.0</data>
      <data key="d5">Anil et al. (2023) discusses the capabilities of Gemini models, which are relevant to the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="DATASET">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach utilizes datasets to generate questions and tasks for users, facilitating data analysis.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GRAPH COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach utilizes different graph communities (C0, C1, C2, C3) to structure and summarize data for answering user queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="PODCAST DATASET">
      <data key="d4">7.0</data>
      <data key="d5">The Podcast dataset is used in the evaluation of the Graph RAG approach, contributing to the analysis of its effectiveness.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The News dataset is used in the evaluation of the Graph RAG approach, contributing to the analysis of its effectiveness.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="KNOWLEDGE GRAPHS">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach utilizes knowledge graphs to enhance data processing and reasoning capabilities.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="NATURAL MODULARITY">
      <data key="d4">7.0</data>
      <data key="d5">The Graph RAG approach leverages natural modularity to effectively partition data for summarization.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="SOURCE TEXTS">
      <data key="d4">8.0</data>
      <data key="d5">Source texts are the foundational data that the Graph RAG approach processes for analysis.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="SENSEMAKING QUESTIONS">
      <data key="d4">6.0</data>
      <data key="d5">Sensemaking questions guide the analysis process within the Graph RAG approach, helping to extract insights from data.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GRAPH-FREE APPROACH">
      <data key="d4">5.0</data>
      <data key="d5">The Graph RAG approach is compared to the graph-free approach, which summarizes source texts without graph structures.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="OPEN-SOURCE IMPLEMENTATION">
      <data key="d4">9.0</data>
      <data key="d5">An open-source implementation of the Graph RAG approach allows users to access and modify the techniques used.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d4">8.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="AMBER HOAK">
      <data key="d4">8.0</data>
      <data key="d5">Amber Hoak contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d4">8.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="BEN CUTLER">
      <data key="d4">8.0</data>
      <data key="d5">Ben Cutler contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="BILLIE RINALDI">
      <data key="d4">8.0</data>
      <data key="d5">Billie Rinaldi contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="CHRIS SANCHEZ">
      <data key="d4">8.0</data>
      <data key="d5">Chris Sanchez contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="CHRIS TREVI&#209;O">
      <data key="d4">8.0</data>
      <data key="d5">Chris Trevi&#241;o contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="CHRISTINE CAGGIANO">
      <data key="d4">8.0</data>
      <data key="d5">Christine Caggiano contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="DAVID TITTSWORTH">
      <data key="d4">8.0</data>
      <data key="d5">David Tittsworth contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="DAYENNE DE SOUZA">
      <data key="d4">8.0</data>
      <data key="d5">Dayenne de Souza contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="DOUGLAS ORBAKER">
      <data key="d4">8.0</data>
      <data key="d5">Douglas Orbaker contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ED CLARK">
      <data key="d4">8.0</data>
      <data key="d5">Ed Clark contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GABRIEL NIEVES-PONCE">
      <data key="d4">8.0</data>
      <data key="d5">Gabriel Nieves-Ponce contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GAUDY BLANCO MENES">
      <data key="d4">8.0</data>
      <data key="d5">Gaudy Blanco Meneses contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="KATE LYTVYNETS">
      <data key="d4">8.0</data>
      <data key="d5">Kate Lytvynets contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="KATY SMITH">
      <data key="d4">8.0</data>
      <data key="d5">Katy Smith contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="M&#211;NICA CARVAJAL">
      <data key="d4">8.0</data>
      <data key="d5">M&#243;nica Carvajal contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="NATHAN EVANS">
      <data key="d4">8.0</data>
      <data key="d5">Nathan Evans contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="RICHARD ORTEGA">
      <data key="d4">8.0</data>
      <data key="d5">Richard Ortega contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="RODRIGO RACANICCI">
      <data key="d4">8.0</data>
      <data key="d5">Rodrigo Racanicci contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="SARAH SMITH">
      <data key="d4">8.0</data>
      <data key="d5">Sarah Smith contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="SHANE SOLOMON">
      <data key="d4">1.0</data>
      <data key="d5">Shane Solomon contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="GLOBAL SENSEMAKING">
      <data key="d4">7.0</data>
      <data key="d5">Query-focused summarization is a key component of global sensemaking, as it helps derive insights from large datasets based on specific queries.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="TEXT CHUNKS">
      <data key="d4">7.0</data>
      <data key="d5">Text chunks are derived from source documents for further processing in the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are used to generate the global answer for user queries, synthesizing information from various levels of the community structure.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GRAPH RAG">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are generated as part of the Graph RAG approach to enhance the quality of responses.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="DARREN EDGE">
      <data key="d4">8.0</data>
      <data key="d5">Darren Edge is a researcher at Microsoft Research, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="HA TRINH">
      <data key="d4">8.0</data>
      <data key="d5">Ha Trinh is a researcher at Microsoft Research, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="JONATHAN LARSON">
      <data key="d4">1.0</data>
      <data key="d5">Jonathan Larson is a researcher at Microsoft Research, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES" target="NEWMAN CHENG">
      <data key="d4">8.0</data>
      <data key="d5">Newman Cheng is a researcher at Microsoft Strategic Missions and Technologies, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES" target="JOSHUA BRADLEY">
      <data key="d4">8.0</data>
      <data key="d5">Joshua Bradley is a researcher at Microsoft Strategic Missions and Technologies, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES" target="STEVEN TRUITT">
      <data key="d4">8.0</data>
      <data key="d5">Steven Truitt is a researcher at Microsoft Strategic Missions and Technologies, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT OFFICE OF THE CTO" target="ALEX CHAO">
      <data key="d4">8.0</data>
      <data key="d5">Alex Chao is a researcher at Microsoft Office of the CTO, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT OFFICE OF THE CTO" target="APURVA MODY">
      <data key="d4">8.0</data>
      <data key="d5">Apurva Mody is a researcher at Microsoft Office of the CTO, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="LEIDEN ALGORITHM">
      <data key="d4">6.0</data>
      <data key="d5">Community detection can be performed using the Leiden algorithm, which is known for its effectiveness in identifying clusters within data.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="FORTUNATO S. (2010)">
      <data key="d4">7.0</data>
      <data key="d5">Fortunato S. (2010) provides foundational knowledge on community detection in graphs, relevant to network analysis.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LEIDEN ALGORITHM" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">The Leiden algorithm is a specific type of community detection algorithm used for efficiently partitioning graphs.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="NAMED ENTITIES">
      <data key="d4">8.0</data>
      <data key="d5">The LLM is used to extract named entities from text, identifying specific categories of information like people and organizations.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="FEW-SHOT EXAMPLES">
      <data key="d4">7.0</data>
      <data key="d5">Few-shot examples are provided to the LLM to enhance its ability to extract relevant information in specialized domains.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="EXTRACTION PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">The extraction prompt guides the LLM in identifying and extracting relevant information from the text.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="GLEANINGS">
      <data key="d4">7.0</data>
      <data key="d5">The LLM performs gleanings to ensure that all relevant entities are extracted, even those missed in previous attempts.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="ABSTRACTIVE SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">The LLM utilizes abstractive summarization to create meaningful summaries of entities and relationships from the text.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="ENTITY GRAPH">
      <data key="d4">8.0</data>
      <data key="d5">The LLM contributes to the creation of an entity graph by extracting and summarizing relationships between entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="MULTIHOP-RAG DATASET">
      <data key="d4">7.0</data>
      <data key="d5">The MultiHop-RAG dataset is utilized by the LLM for testing and evaluating the performance of the Graph RAG approach.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="GRAPH INDEX">
      <data key="d4">8.0</data>
      <data key="d5">The LLM contributes to the creation of a graph index by extracting and summarizing relationships between entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="USER">
      <data key="d4">9.0</data>
      <data key="d5">The LLM interacts with users to generate questions based on dataset descriptions, aiding in their tasks.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="LLM" target="GRAPH RAG">
      <data key="d4">9.0</data>
      <data key="d5">The Graph RAG approach utilizes LLMs to process and generate summaries from text data effectively.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="TEXT CHUNKS" target="HOTPOTQA">
      <data key="d4">6.0</data>
      <data key="d5">Text chunks are evaluated using the HotPotQA dataset to measure the effectiveness of entity reference detection.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="TEXT CHUNKS" target="SS">
      <data key="d4">8.0</data>
      <data key="d5">The SS method retrieves text chunks to build context for answering queries, adding them until a token limit is reached.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="KURATOV ET AL. (2024)" target="LATS">
      <data key="d4">10.0</data>
      <data key="d5">Kuratov et al. (2024) offers valuable insights into the performance of the LATS algorithm, particularly in its ability to process text chunks and facilitate decision-making. This research highlights the effectiveness of LATS in handling textual data, underscoring its relevance in the fields of Artificial Intelligence and Natural Language Processing.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LIU ET AL. (2023)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">1.0</data>
      <data key="d5">Liu et al. (2023) examines the integration of search algorithms with language model agents, contributing to the understanding of their capabilities.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LIU ET AL. (2023)" target="SEARCH SPACE">
      <data key="d4">5.0</data>
      <data key="d5">Liu et al. (2023) explores various designs of search spaces applicable to agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="HOTPOTQA" target="LATS">
      <data key="d4">58.0</data>
      <data key="d5">LATS has undergone extensive empirical evaluation using the HotPotQA dataset, which is designed to assess its effectiveness in various question-answering and reasoning tasks. The evaluations highlight LATS's capability to handle complex questions that necessitate reasoning across multiple documents, showcasing its proficiency in multi-hop reasoning scenarios. Overall, the assessments confirm LATS's strong performance in addressing intricate question-answering challenges within the context of the HotPotQA benchmark.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HOTPOTQA" target="GPT-3.5">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5 is evaluated on the HotpotQA dataset to measure its reasoning capabilities and performance in tasks.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="HOTPOTQA" target="API CALLS">
      <data key="d4">7.0</data>
      <data key="d5">In the context of HotPotQA, API calls are utilized to enhance the agent's ability to retrieve information for answering questions.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HOTPOTQA" target="YANG ET AL. (2018)">
      <data key="d4">8.0</data>
      <data key="d5">Yang et al. (2018) is a foundational reference for the HotPotQA benchmark, discussing its design and evaluation.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="MODULARITY">
      <data key="d4">1.0</data>
      <data key="d5">Modularity is a key concept in community detection algorithms, influencing how graphs are partitioned into communities.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="ENTITY GRAPH">
      <data key="d4">7.0</data>
      <data key="d5">Community detection algorithms analyze the entity graph to identify groups of closely related nodes.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="HIERARCHICAL CLUSTERING">
      <data key="d4">1.0</data>
      <data key="d5">Hierarchical clustering is a technique used within community detection algorithms to organize nodes into a hierarchy.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="BROWN ET AL. (2020)" target="LANGUAGE MODELS">
      <data key="d4">7.0</data>
      <data key="d5">Brown et al. (2020) discusses the capabilities of language models, establishing their role in few-shot learning.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN ET AL. (2020)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">5.0</data>
      <data key="d5">Brown et al. (2020) discusses the capabilities of language models, which are utilized in LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="TOUVRON ET AL. (2023)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">5.0</data>
      <data key="d5">Touvron et al. (2023) discusses advancements in language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="NAMED ENTITIES" target="COVARIATES">
      <data key="d4">6.0</data>
      <data key="d5">Covariates are linked to named entities, providing additional context and attributes related to those entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="NAMED ENTITIES" target="CLAIMS">
      <data key="d4">1.0</data>
      <data key="d5">Claims are associated with named entities, providing context and additional information relevant to those entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COVARIATES" target="NODES">
      <data key="d4">7.0</data>
      <data key="d5">Covariates provide additional context to nodes, enhancing the understanding of their significance within the community structure.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="GLOBAL SUMMARIZATION" target="GRAPH INDEX">
      <data key="d4">7.0</data>
      <data key="d5">Global summarization utilizes the graph index to provide comprehensive insights into the dataset's structure and semantics.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="NODE" target="EDGE">
      <data key="d4">8.0</data>
      <data key="d5">Nodes are connected by edges in a graph, illustrating the relationships between different entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="HIGHER-LEVEL COMMUNITIES">
      <data key="d4">7.0</data>
      <data key="d5">Leaf-level communities serve as the foundational elements that contribute to the summaries of higher-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="LLM CONTEXT WINDOW">
      <data key="d4">8.0</data>
      <data key="d5">The LLM context window limits the amount of information that can be processed from leaf-level communities at one time.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="HIGHER-LEVEL COMMUNITIES" target="SUB-COMMUNITIES">
      <data key="d4">1.0</data>
      <data key="d5">Sub-communities are components of higher-level communities, contributing to the overall structure and summaries generated from them.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="USER QUERY">
      <data key="d4">8.0</data>
      <data key="d5">A user query initiates the process of generating a global answer based on community summaries.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="DATASET EXAMPLES" target="PODCAST TRANSCRIPTS">
      <data key="d4">6.0</data>
      <data key="d5">Dataset examples illustrate potential user tasks and questions derived from podcast transcripts.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="DATASET EXAMPLES" target="NEWS ARTICLES">
      <data key="d4">6.0</data>
      <data key="d5">Dataset examples illustrate potential user tasks and questions derived from news articles.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="DATASET EXAMPLES" target="EVALUATION">
      <data key="d4">1.0</data>
      <data key="d5">Evaluation assesses the effectiveness of the generated questions based on dataset examples.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NODES" target="EDGES">
      <data key="d4">9.0</data>
      <data key="d5">Nodes are connected by edges, forming the fundamental structure of a community and representing relationships between entities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="USER" target="TASK">
      <data key="d4">8.0</data>
      <data key="d5">Users perform tasks that involve generating questions and analyzing datasets using the LLM.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="USER" target="CREATE MEAL PLAN">
      <data key="d4">9.0</data>
      <data key="d5">The User requests the creation of a meal plan based on their dietary preferences and caloric goals.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="UPDATE FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The User requests an update to the calorie count for 'Chana Masala', which is facilitated by the Update Food Item API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="TRACK USER MEAL">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to track their daily meals, which is facilitated by the Track User Meal API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="GET DIETARY RECOMMENDATIONS">
      <data key="d4">8.0</data>
      <data key="d5">The User is interested in receiving new food recommendations, which is provided by the Get Dietary Recommendations API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="ADD NEW FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to add a new recipe (Quinoa Salad) to the database, which is done through the Add New Food Item API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="DELETE FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to remove 'Butter Chicken' from their list, which is done through the Delete Food Item API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="GET USER NUTRITIONAL STATS">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to see their nutritional summary at the end of the week, which is retrieved by the Get User Nutritional Stats API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="ASSISTANT">
      <data key="d4">1.0</data>
      <data key="d5">The Assistant interacts with the User to help them achieve their dietary goals using various APIs.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="CALORIC GOAL">
      <data key="d4">8.0</data>
      <data key="d5">The User has a specific caloric goal of 1500 calories per day as part of their diet plan.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="DIETARY PREFERENCES">
      <data key="d4">8.0</data>
      <data key="d5">The User has specified dietary preferences, indicating they prefer vegetarian meals.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="MEAL PLAN">
      <data key="d4">9.0</data>
      <data key="d5">The User requests a meal plan that includes three meals a day based on their dietary preferences and caloric goal.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="NUTRITIONAL SUMMARY">
      <data key="d4">1.0</data>
      <data key="d5">The User wants to see a nutritional summary at the end of the week to assess their dietary adherence.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="VEGETARIAN MEAL PLAN">
      <data key="d4">8.0</data>
      <data key="d5">The user requested the creation of a vegetarian meal plan tailored to their caloric needs.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="USER" target="QUINOA SALAD">
      <data key="d4">6.0</data>
      <data key="d5">The user is involved in the process of adding the Quinoa Salad recipe to the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="USER" target="CHANA MASALA">
      <data key="d4">6.0</data>
      <data key="d5">The user is involved in updating the Chana Masala recipe in the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="USER" target="BUTTER CHICKEN">
      <data key="d4">6.0</data>
      <data key="d5">The user is involved in the process of removing the Butter Chicken recipe from the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="TASK" target="QUESTION">
      <data key="d4">7.0</data>
      <data key="d5">Tasks often result in the generation of questions that require understanding of the dataset for effective answers.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TASK" target="BRAIN TEASER">
      <data key="d4">6.0</data>
      <data key="d5">Brain teasers are examples of problems generated through the workflows that require logical thinking to solve.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TASK" target="FERMI PROBLEMS">
      <data key="d4">6.0</data>
      <data key="d5">Fermi problems are examples of estimation tasks that can be generated through the workflows in the agentic flows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="QUESTION" target="EVALUATION METRICS">
      <data key="d4">6.0</data>
      <data key="d5">Evaluation metrics are used to assess the quality of the questions generated by the LLM and the answers provided.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="QUESTION" target="OPTIONS">
      <data key="d4">9.0</data>
      <data key="d5">The question is associated with the options provided, which are the possible answers to the question.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="QUESTION" target="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">7.0</data>
      <data key="d5">The Maths GPT-4 Extraction System Message is used to evaluate the correctness of the answer to the question posed.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="QUESTION" target="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d4">7.0</data>
      <data key="d5">The General Extraction System Message is used to parse the student's response to the question and determine correctness.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EVALUATION METRICS" target="COMPREHENSIVENESS">
      <data key="d4">7.0</data>
      <data key="d5">Comprehensiveness is one of the evaluation metrics used to measure the quality of answers generated by the LLM.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION METRICS" target="DIVERSITY">
      <data key="d4">7.0</data>
      <data key="d5">Diversity is another evaluation metric that assesses the variety of answers generated by the LLM.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION METRICS" target="EMPOWERMENT">
      <data key="d4">7.0</data>
      <data key="d5">Empowerment is an evaluation metric that measures how well answers help users understand topics.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION METRICS" target="DIRECTNESS">
      <data key="d4">1.0</data>
      <data key="d5">Directness is an evaluation metric that assesses how clearly answers address the questions posed.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION METRICS" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Evaluation metrics are used in the Meta Agent Search to measure the performance of generated agents during the evaluation phase.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="GRAPH RAG">
      <data key="d4">9.0</data>
      <data key="d5">The Graph RAG approach aims to improve comprehensiveness in responses as one of its key performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIVERSITY" target="GRAPH RAG">
      <data key="d4">9.0</data>
      <data key="d5">The Graph RAG approach aims to improve diversity in responses as one of its key performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIVERSITY" target="AGENTIC FLOWS">
      <data key="d4">8.0</data>
      <data key="d5">Diversity is a key objective of agentic flows, aimed at ensuring a wide range of generated problems and instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="EMPOWERMENT" target="GRAPH RAG">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach aims to enhance empowerment in responses as one of its key performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIRECTNESS" target="GRAPH RAG">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach aims to improve directness in responses as one of its key performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C0" target="C1">
      <data key="d4">7.0</data>
      <data key="d5">C1 serves as a sub-community of C0, providing more detailed summaries for answering user queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="C0" target="GRAPH RAG">
      <data key="d4">7.0</data>
      <data key="d5">C0 is one of the conditions evaluated in the Graph RAG approach to assess performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C1" target="C2">
      <data key="d4">7.0</data>
      <data key="d5">C2 serves as a sub-community of C1, providing further granularity in summarization for answering queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="C1" target="GRAPH RAG">
      <data key="d4">7.0</data>
      <data key="d5">C1 is one of the conditions evaluated in the Graph RAG approach to assess performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C2" target="C3">
      <data key="d4">7.0</data>
      <data key="d5">C3 serves as a sub-community of C2, offering the most detailed summaries for answering user queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="C2" target="GRAPH RAG">
      <data key="d4">7.0</data>
      <data key="d5">C2 is one of the conditions evaluated in the Graph RAG approach to assess performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C3" target="GRAPH RAG">
      <data key="d4">7.0</data>
      <data key="d5">C3 is one of the conditions evaluated in the Graph RAG approach to assess performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="TS" target="SOURCE TEXTS">
      <data key="d4">8.0</data>
      <data key="d5">The TS method applies a map-reduce approach to source texts, shuffling and chunking them for summarization stages.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TS" target="GRAPH RAG">
      <data key="d4">8.0</data>
      <data key="d5">TS is used as a baseline for comparison against the Graph RAG conditions in performance evaluations.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="PODCAST DATASET" target="GRAPH RAG">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach is applied to the Podcast dataset to evaluate its performance in summarization and response quality.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="NEWS DATASET" target="GRAPH RAG">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach is applied to the News dataset to evaluate its performance in summarization and response quality.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="TAYLOR SWIFT" target="PUBLIC FIGURES">
      <data key="d4">9.0</data>
      <data key="d5">Taylor Swift is a public figure frequently mentioned in entertainment articles due to her influence and popularity in the music industry.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="TRAVIS KELCE" target="PUBLIC FIGURES">
      <data key="d4">9.0</data>
      <data key="d5">Travis Kelce is a public figure frequently mentioned in entertainment articles due to his achievements in sports and cultural relevance.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="PUBLIC FIGURES">
      <data key="d4">9.0</data>
      <data key="d5">Britney Spears is a public figure frequently mentioned in entertainment articles, often due to her music career and personal life controversies.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="PUBLIC FIGURES">
      <data key="d4">9.0</data>
      <data key="d5">Justin Timberlake is a public figure frequently mentioned in entertainment articles for his contributions to music and entertainment.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ENTERTAINMENT ARTICLES">
      <data key="d4">1.0</data>
      <data key="d5">Public figures are often the subjects of entertainment articles, highlighting their influence and relevance in popular culture.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ATHLETES">
      <data key="d4">8.0</data>
      <data key="d5">Athletes are often considered public figures due to their visibility and influence in sports and entertainment.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="COACHES">
      <data key="d4">7.0</data>
      <data key="d5">Coaches can also be public figures, especially when they gain recognition for their leadership and impact on athletes and teams.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="INFLUENCERS">
      <data key="d4">9.0</data>
      <data key="d5">Influencers are public figures who shape trends and opinions through their platforms and reach.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ENTREPRENEURS">
      <data key="d4">8.0</data>
      <data key="d5">Entrepreneurs often become public figures as they influence markets and cultural trends through their businesses.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="CULTURAL NARRATIVES">
      <data key="d4">9.0</data>
      <data key="d5">Public figures play a significant role in shaping cultural narratives through their actions and public personas.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="SOCIAL DISCUSSIONS">
      <data key="d4">1.0</data>
      <data key="d5">Public figures often become central to social discussions, influencing public opinion and discourse.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="GRAPH RAG" target="CONTEXT WINDOW SIZE">
      <data key="d4">7.0</data>
      <data key="d5">The context window size is a critical parameter that affects the performance of the Graph RAG approach in processing text data.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="WIN RATE">
      <data key="d4">9.0</data>
      <data key="d5">Win rate is a key performance metric used to evaluate the effectiveness of the Graph RAG approach across different conditions.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="TOKEN COUNT">
      <data key="d4">8.0</data>
      <data key="d5">Token count is a metric that influences the performance and efficiency of the Graph RAG approach in processing data.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY SUMMARY LEVEL">
      <data key="d4">1.0</data>
      <data key="d5">Community summary levels are utilized in the Graph RAG approach to organize and evaluate the generated summaries.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="SOURCE TEXT SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG is a more efficient alternative to source text summarization, requiring fewer tokens while maintaining performance.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="PODCAST INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Podcast intermediate-level summaries are generated using the Graph RAG approach, which enhances their efficiency.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWS LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">News low-level community summaries are produced through the Graph RAG method, showcasing its application in diverse contexts.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="EMPOWERMENT COMPARISONS">
      <data key="d4">6.0</data>
      <data key="d5">Empowerment comparisons evaluate the effectiveness of the Graph RAG method in aiding user understanding compared to other approaches.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="SELF-MEMORY">
      <data key="d4">7.0</data>
      <data key="d5">Self-memory is a concept integrated into the Graph RAG approach to enhance the retrieval and generation process.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="GENERATING HIERARCHICAL INDEX">
      <data key="d4">8.0</data>
      <data key="d5">Generating a hierarchical index is a technique employed within the Graph RAG framework to improve summarization efficiency.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="KNOWLEDGE GRAPH">
      <data key="d4">7.0</data>
      <data key="d5">Knowledge graphs are utilized in the Graph RAG approach to enhance the organization and retrieval of information.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="EMPOWERMENT COMPARISONS" target="AD-HOC LLM USE">
      <data key="d4">5.0</data>
      <data key="d5">Ad-hoc LLM use is analyzed in the context of empowerment comparisons to assess its impact on user comprehension.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="TRAJANOSKA, M.">
      <data key="d4">7.0</data>
      <data key="d5">Trajanoska, M. co-authored a paper on enhancing knowledge graph construction using large language models.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="TRIVEDI, H.">
      <data key="d4">6.0</data>
      <data key="d5">Trivedi, H. co-authored a paper on interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions, relevant to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="WANG, S.">
      <data key="d4">6.0</data>
      <data key="d5">Wang, S. co-authored a paper evaluating federated search in the context of retrieval-augmented generation, which relates to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="YAO, L.">
      <data key="d4">8.0</data>
      <data key="d5">Yao, L. co-authored a paper exploring large language models for knowledge graph completion, directly related to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="ZHANG, Y.">
      <data key="d4">7.0</data>
      <data key="d5">Zhang, Y. co-authored a paper on causal graph discovery with retrieval-augmented generation based large language models, relevant to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="LI, Z.">
      <data key="d4">8.0</data>
      <data key="d5">Li, Z. co-authored a paper on knowledge graph prompting for multi-document question answering, directly related to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="DERR, T.">
      <data key="d4">8.0</data>
      <data key="d5">Derr, T. co-authored a paper on knowledge graph prompting for multi-document question answering, directly related to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="ZHANG, R.">
      <data key="d4">8.0</data>
      <data key="d5">Zhang, R. co-authored a paper on knowledge graph prompting for multi-document question answering, directly related to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="GRAPH DATABASES" target="LANGCHAIN">
      <data key="d4">6.0</data>
      <data key="d5">LangChain supports the use of graph databases, facilitating the integration of graph structures in applications utilizing LLMs.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH DATABASES" target="LLAMAINDEX">
      <data key="d4">1.0</data>
      <data key="d5">LlamaIndex provides support for graph databases, enabling efficient management of graph-based data in LLM applications.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="LANGCHAIN" target="NEO4J">
      <data key="d4">7.0</data>
      <data key="d5">LangChain is involved in projects related to Neo4J, particularly in graph-based applications.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LANGCHAIN" target="NEBULAGRAPH">
      <data key="d4">14.0</data>
      <data key="d5">NebulaGraph's graph-based retrieval-augmented generation system is relevant to LangChain's functionalities.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LANGCHAIN" target="SEARCH SPACE">
      <data key="d4">7.0</data>
      <data key="d5">LangChain provides a framework that allows for the exploration of search spaces in building agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LANGCHAIN" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">LangChain provides essential tools that can enhance the development of ADAS by facilitating the integration of language models.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="YAO ET AL. (2023)" target="REACT">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. (2023) discusses the ReAct technique and its applications in enhancing language model performance.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="YAO ET AL. (2023)" target="LATS">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. (2023) explores the Wikipedia web API, highlighting its crucial role in the information retrieval tasks performed by LATS. The study offers valuable insights into the performance of LATS across various tasks, emphasizing the significance of the API in enhancing the system's efficiency and effectiveness in processing and retrieving information.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="ZHANG ET AL. (2024)" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Zhang et al. (2024) contributes to ADAS by discussing AgentOptimizer and its role in learning tools for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="WANG ET AL. (2023)" target="LATS">
      <data key="d4">6.0</data>
      <data key="d5">LATS is connected to the adaptation of language models in interactive environments as discussed by Wang et al. (2023).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHENG ET AL. (2024)" target="RETRIEVAL-AUGMENTED TEXT GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Cheng et al. (2024) explores retrieval-augmented text generation, contributing to advancements in this area.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DANG H. T. (2006)" target="QUESTION-FOCUSED SUMMARIZATION">
      <data key="d4">6.0</data>
      <data key="d5">Dang H. T. (2006) evaluates systems focused on summarization, relevant to the field of question-focused summarization.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="ES ET AL. (2023)" target="AUTOMATED EVALUATION">
      <data key="d4">7.0</data>
      <data key="d5">Es et al. (2023) provides insights into automated evaluation methods for retrieval-augmented generation.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="FENG ET AL. (2023)" target="RETRIEVAL-GENERATION SYNERGY">
      <data key="d4">8.0</data>
      <data key="d5">Feng et al. (2023) discusses the synergy between retrieval and generation in large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GAO ET AL. (2023)" target="SURVEY ON RETRIEVAL-AUGMENTED GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Gao et al. (2023) surveys the landscape of retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GAO ET AL. (2023)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">5.0</data>
      <data key="d5">Gao et al. (2023) discusses prompting techniques for language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="GOODWIN ET AL. (2020)" target="TRANSFORMERS">
      <data key="d4">7.0</data>
      <data key="d5">Goodwin et al. (2020) compares transformers, contributing to the understanding of their performance in summarization tasks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="HE ET AL. (2024)" target="TEXTUAL GRAPH UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">He et al. (2024) focuses on retrieval-augmented generation for understanding textual graphs, linking retrieval and comprehension.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="JACOMY ET AL. (2014)" target="GRAPH LAYOUT ALGORITHM">
      <data key="d4">6.0</data>
      <data key="d5">Jacomy et al. (2014) discusses a graph layout algorithm, relevant for visualizing network data.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="JIN ET AL. (2021)" target="COMMUNITY DETECTION APPROACHES">
      <data key="d4">7.0</data>
      <data key="d5">Jin et al. (2021) surveys community detection methods, contributing to the understanding of this field.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KANG ET AL. (2023)" target="KNOWLEDGE-GROUNDED DIALOGUE">
      <data key="d4">8.0</data>
      <data key="d5">Kang et al. (2023) explores knowledge graph-augmented models for dialogue generation, linking knowledge and dialogue.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KHATTAB ET AL. (2022)" target="RETRIEVAL AND LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Khattab et al. (2022) discusses the integration of retrieval and language models, relevant for knowledge-intensive NLP tasks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KIM ET AL. (2023)" target="AMBIGUOUS QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Kim et al. (2023) addresses the challenge of answering ambiguous questions using retrieval-augmented models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KLEIN ET AL. (2006)" target="SENSEMAKING">
      <data key="d4">6.0</data>
      <data key="d5">Klein et al. (2006) provides perspectives on sensemaking, contributing to cognitive models in understanding information.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KOESTEN ET AL. (2021)" target="DATA SENSEMAKING">
      <data key="d4">1.0</data>
      <data key="d5">Koesten et al. (2021) investigates behaviors related to data sensemaking, relevant for human-computer interaction studies.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="PAL">
      <data key="d4">8.0</data>
      <data key="d5">PAL aims to enhance large language models through programmatic assistance, improving their capabilities.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="AGENTBENCH">
      <data key="d4">8.0</data>
      <data key="d5">AgentBench evaluates large language models as agents, assessing their performance in various tasks.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="DUAL-PROCESS PERSPECTIVE">
      <data key="d4">1.0</data>
      <data key="d5">The dual-process perspective can be applied to understand reasoning in large language models, linking cognitive theories to AI.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="LIMITATIONS" target="LATS">
      <data key="d4">6.0</data>
      <data key="d5">Limitations highlight the challenges faced by the LATS algorithm in its application to decision-making tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LIMITATIONS" target="RAG">
      <data key="d4">1.0</data>
      <data key="d5">RAG techniques face various limitations, including biases and challenges in synthetic data generation.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="KOESTEN, L." target="GREGORY, K.">
      <data key="d4">8.0</data>
      <data key="d5">L. Koesten and K. Gregory co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KOESTEN, L." target="GROTH, P.">
      <data key="d4">8.0</data>
      <data key="d5">L. Koesten and P. Groth co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KOESTEN, L." target="SIMPURL, E.">
      <data key="d4">8.0</data>
      <data key="d5">L. Koesten and E. Simperl co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="GREGORY, K." target="GROTH, P.">
      <data key="d4">8.0</data>
      <data key="d5">K. Gregory and P. Groth co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="GREGORY, K." target="SIMPURL, E.">
      <data key="d4">8.0</data>
      <data key="d5">K. Gregory and E. Simperl co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="GROTH, P." target="SIMPURL, E.">
      <data key="d4">8.0</data>
      <data key="d5">P. Groth and E. Simperl co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV, Y." target="BULATOV, A.">
      <data key="d4">8.0</data>
      <data key="d5">Y. Kuratov and A. Bulatov co-authored a study on the limitations of large language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV, Y." target="ANOKHIN, P.">
      <data key="d4">8.0</data>
      <data key="d5">Y. Kuratov and P. Anokhin co-authored a study on the limitations of large language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV, Y." target="SOROKIN, D.">
      <data key="d4">8.0</data>
      <data key="d5">Y. Kuratov and D. Sorokin co-authored a study on the limitations of large language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV, Y." target="SOROKIN, A.">
      <data key="d4">8.0</data>
      <data key="d5">Y. Kuratov and A. Sorokin co-authored a study on the limitations of large language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV, Y." target="BURTSEV, M.">
      <data key="d4">8.0</data>
      <data key="d5">Y. Kuratov and M. Burtsev co-authored a study on the limitations of large language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="HOQUE, E.">
      <data key="d4">16.0</data>
      <data key="d5">M. T. R. Laskar and E. Hoque co-authored studies on query-focused abstractive summarization.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="HUANG, J.">
      <data key="d4">16.0</data>
      <data key="d5">M. T. R. Laskar and J. Huang co-authored studies on query-focused abstractive summarization.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="SU, D.">
      <data key="d4">2.0</data>
      <data key="d5">D. Su and M. T. R. Laskar co-authored a study on question answering and multi-document summarization.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="HOQUE, E." target="HUANG, J.">
      <data key="d4">16.0</data>
      <data key="d5">E. Hoque and J. Huang co-authored studies on query-focused abstractive summarization.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="PEREZ, E.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and E. Perez co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="PIKTUS, A.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and A. Piktus co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="PETRONI, F.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and F. Petroni co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="KARPUKHIN, V.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and V. Karpukhin co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="GOYAL, N.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and N. Goyal co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="K&#220;TTLER, H.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and H. K&#252;ttler co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="RAM, O.">
      <data key="d4">16.0</data>
      <data key="d5">O. Ram and P. Lewis co-authored a study on in-context retrieval-augmented language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="SHAO, Z.">
      <data key="d4">16.0</data>
      <data key="d5">Z. Shao and P. Lewis co-authored a study on enhancing retrieval-augmented language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="RANADE, P." target="SARTHI, P.">
      <data key="d4">16.0</data>
      <data key="d5">P. Ranade and P. Sarthi co-authored a study on retrieval-augmented narrative construction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="SU, D." target="XU, Y.">
      <data key="d4">8.0</data>
      <data key="d5">Su, D. and Xu, Y. co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SU, D." target="BAREZI, E. J.">
      <data key="d4">8.0</data>
      <data key="d5">Su, D. and Barezi, E. J. co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SU, D." target="SIDDIQUE, F. B.">
      <data key="d4">8.0</data>
      <data key="d5">Su, D. and Siddique, F. B. co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SU, D." target="FUNG, P.">
      <data key="d4">8.0</data>
      <data key="d5">Su, D. and Fung, P. co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="DUAN, N." target="CHEN, W.">
      <data key="d4">8.0</data>
      <data key="d5">Duan, N. and Chen, W. co-authored a paper on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="YANG, Y." target="TANG, Y.">
      <data key="d4">8.0</data>
      <data key="d5">Yang, Y. and Tang, Y. co-authored a paper on MultiHop-RAG, benchmarking retrieval-augmented generation for multi-hop queries.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TOUVRON, H." target="MARTIN, L.">
      <data key="d4">8.0</data>
      <data key="d5">Touvron, H. and Martin, L. co-authored a paper on Llama 2, which includes open foundation and fine-tuned chat models.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, J." target="CHATGPT">
      <data key="d4">7.0</data>
      <data key="d5">Wang, J. co-authored a preliminary study on whether ChatGPT is a good NLG evaluator, indicating its relevance in natural language generation.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, S." target="KRAMTSOVA, E.">
      <data key="d4">8.0</data>
      <data key="d5">Khramtsova, E. and Wang, S. co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, S." target="ZHUANG, S.">
      <data key="d4">8.0</data>
      <data key="d5">Zhuang, S. and Wang, S. co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, S." target="ZUCCON, G.">
      <data key="d4">1.0</data>
      <data key="d5">Zuccon, G. and Wang, S. co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ZHANG, J." target="CHATGPT">
      <data key="d4">7.0</data>
      <data key="d5">Zhang, J. co-authored a paper on Graph-toolformer, which empowers LLMs with graph reasoning ability via prompts augmented by ChatGPT.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ZHENG, L." target="CHATGPT">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. co-authored a paper judging LLMs as judges with MT-bench and Chatbot Arena, which involves ChatGPT.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LLAMA 2" target="HUGO TOUVRON">
      <data key="d4">8.0</data>
      <data key="d5">Hugo Touvron is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="LOUIS MARTIN">
      <data key="d4">8.0</data>
      <data key="d5">Louis Martin is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="KEVIN R. STONE">
      <data key="d4">8.0</data>
      <data key="d5">Kevin R. Stone is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="PETER ALBERT">
      <data key="d4">8.0</data>
      <data key="d5">Peter Albert is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="AMJAD ALMAHAIRI">
      <data key="d4">8.0</data>
      <data key="d5">Amjad Almahairi is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="YASMINE BABAIE">
      <data key="d4">8.0</data>
      <data key="d5">Yasmine Babaie is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="NIKOLAY BASHLYKOV">
      <data key="d4">8.0</data>
      <data key="d5">Nikolay Bashlykov is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="SOUMYA BATRA">
      <data key="d4">8.0</data>
      <data key="d5">Soumya Batra is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="PRAJJWAL BHARGAVA">
      <data key="d4">8.0</data>
      <data key="d5">Prajjwal Bhargava is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="SHRUTI BHOSALE">
      <data key="d4">8.0</data>
      <data key="d5">Shruti Bhosale is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="DANIEL M. BIKEL">
      <data key="d4">8.0</data>
      <data key="d5">Daniel M. Bikel is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="LUKAS BLECHER">
      <data key="d4">8.0</data>
      <data key="d5">Lukas Blecher is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="CRISTIAN CANT&#211;N FERRER">
      <data key="d4">8.0</data>
      <data key="d5">Cristian Cant&#243;n Ferrer is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="MOYA CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Moya Chen is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="GUILLEM CUCURULL">
      <data key="d4">8.0</data>
      <data key="d5">Guillem Cucurull is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="DAVID ESIOSU">
      <data key="d4">8.0</data>
      <data key="d5">David Esiosu is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="JUDE FERNANDES">
      <data key="d4">8.0</data>
      <data key="d5">Jude Fernandes is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="JEREMY FU">
      <data key="d4">8.0</data>
      <data key="d5">Jeremy Fu is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="WENYIN FU">
      <data key="d4">8.0</data>
      <data key="d5">Wenyin Fu is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="BRIAN FULLER">
      <data key="d4">8.0</data>
      <data key="d5">Brian Fuller is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="CYNTHIA GAO">
      <data key="d4">8.0</data>
      <data key="d5">Cynthia Gao is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="VEDANUJ GOSWAMI">
      <data key="d4">8.0</data>
      <data key="d5">Vedanuj Goswami is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="NAMAN GOYAL">
      <data key="d4">8.0</data>
      <data key="d5">Naman Goyal is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="ANTHONY S. HARTSHORN">
      <data key="d4">1.0</data>
      <data key="d5">Anthony S. Hartshorn is involved in the development of Llama 2, contributing to advancements in language models("entity"</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="CHATGPT" target="ORCA-3">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 is evaluated against ChatGPT to demonstrate its performance improvements in the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="BENGIO, Y." target="HOTSPOTQA">
      <data key="d4">8.0</data>
      <data key="d5">Bengio, Y. co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SALAKHUTDINOV, R." target="HOTSPOTQA">
      <data key="d4">8.0</data>
      <data key="d5">Salakhutdinov, R. co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="MANNING, C. D." target="HOTSPOTQA">
      <data key="d4">8.0</data>
      <data key="d5">Manning, C. D. co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="XIAO, J." target="DOCUMENT SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Xiao, J. co-authored a paper on recent advances in document summarization.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">9.0</data>
      <data key="d5">LATS utilizes language models to enhance reasoning, acting, and planning capabilities in decision-making tasks.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MONTE CARLO TREE SEARCH (MCTS)">
      <data key="d4">8.0</data>
      <data key="d5">LATS incorporates MCTS to improve decision-making processes in language models.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="EXTERNAL ENVIRONMENT">
      <data key="d4">8.0</data>
      <data key="d5">LATS leverages external feedback from the environment to enhance its decision-making capabilities.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PROGRAMMING">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated in the programming domain, demonstrating its effectiveness in coding tasks.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="INTERACTIVE QUESTION-ANSWERING (QA)">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated in the interactive QA domain, showcasing its capabilities in answering user queries.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="WEB NAVIGATION">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated in web navigation, demonstrating its ability to assist users in finding information online.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MATH">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated in the math domain, showcasing its capabilities in numerical reasoning tasks.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="HUMAN EVAL">
      <data key="d4">9.0</data>
      <data key="d5">LATS achieves state-of-the-art performance on the HumanEval benchmark for programming tasks.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GPT-4">
      <data key="d4">9.0</data>
      <data key="d5">LATS demonstrates high accuracy in programming tasks when evaluated with GPT-4.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GPT-3.5">
      <data key="d4">8.0</data>
      <data key="d5">LATS shows comparable performance in web navigation tasks when evaluated with GPT-3.5.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="REACT">
      <data key="d4">16.0</data>
      <data key="d5">The LANGUAGE AGENT TREE SEARCH (LATS) is an advanced methodology that builds upon the foundational ReAct technique by integrating a search mechanism over both reasoning and acting steps. This enhancement allows LATS to improve upon the capabilities of ReAct, particularly in the context of decision-making tasks. Evaluations conducted on LATS against ReAct have shown that LATS exhibits superior performance and efficiency, highlighting its effectiveness in navigating complex decision-making scenarios.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="WOOLDRIDGE AND JENNINGS (1995)">
      <data key="d4">5.0</data>
      <data key="d5">Wooldridge and Jennings' work provides foundational insights into the development of autonomous agents, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SLOMAN (1996)">
      <data key="d4">5.0</data>
      <data key="d5">Sloman (1996) discusses human-like decision-making characteristics, relevant to the design of LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="EVANS (2010)">
      <data key="d4">1.0</data>
      <data key="d5">Evans (2010) discusses human-like decision-making characteristics, relevant to the design of LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MCTS">
      <data key="d4">8.0</data>
      <data key="d5">LATS improves upon MCTS by incorporating search algorithms and external feedback for better decision-making performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="RAP">
      <data key="d4">8.0</data>
      <data key="d5">LATS is compared with RAP to showcase its advantages in terms of performance and computational efficiency.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="HOT-POTQA">
      <data key="d4">9.0</data>
      <data key="d5">LATS is evaluated using the HotPotQA dataset to assess its performance in question answering tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="LATS PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">LATS shows improved performance metrics, indicating its effectiveness in comparison to other methods like ReAct and RAP.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="NODES EXPANDED">
      <data key="d4">7.0</data>
      <data key="d5">LATS requires fewer nodes expanded compared to other methods, demonstrating its efficiency in search operations.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="TRAJECTORIES">
      <data key="d4">8.0</data>
      <data key="d5">LATS constructs trajectories to enhance its decision-making capabilities, integrating search algorithms effectively.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GROUND-TRUTH FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">LATS utilizes ground-truth feedback to improve its learning and performance in decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="COMPUTATIONAL COST">
      <data key="d4">1.0</data>
      <data key="d5">LATS has a higher computational cost compared to simpler methods, which may limit its practicality in certain situations.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="CHOWDHERY ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Chowdhery et al. (2023) discusses advancements in language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="OPENAI (2023)">
      <data key="d4">5.0</data>
      <data key="d5">OpenAI's work in language models is foundational to the development of LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="NALLAPATI ET AL. (2016)">
      <data key="d4">5.0</data>
      <data key="d5">Nallapati et al. (2016) discusses summarization tasks, showcasing capabilities of language models relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="BOWMAN ET AL. (2015)">
      <data key="d4">5.0</data>
      <data key="d5">Bowman et al. (2015) discusses language inference tasks, showcasing capabilities of language models relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="COBBE ET AL. (2021)">
      <data key="d4">5.0</data>
      <data key="d5">Cobbe et al. (2021) discusses reasoning capabilities of language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SAPAROV AND HE (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Saparov and He (2023) discusses reasoning capabilities of language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="YAO ET AL. (2022)">
      <data key="d4">5.0</data>
      <data key="d5">Yao et al. (2022) discusses web navigation tasks, showcasing capabilities of language models relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="DENG ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Deng et al. (2023) discusses web navigation tasks, showcasing capabilities of language models relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SCHICK ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Schick et al. (2023) discusses tool-use capabilities of language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="FAN ET AL. (2022)">
      <data key="d4">5.0</data>
      <data key="d5">Fan et al. (2022) discusses open-ended games, showcasing capabilities of language models relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="XIE ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Xie et al. (2023) discusses search-guided language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="YAO ET AL. (2023A)">
      <data key="d4">5.0</data>
      <data key="d5">Yao et al. (2023A) discusses search-guided language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="YAO ET AL. (2023B)">
      <data key="d4">5.0</data>
      <data key="d5">Yao et al. (2023B) discusses the ReAct technique, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SHINN ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Shinn et al. (2023) discusses prompting techniques for language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="LATS">
      <data key="d4">9.0</data>
      <data key="d5">LATS enhances the performance of language models by integrating reasoning, acting, and planning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="EXTERNAL TOOLS">
      <data key="d4">9.0</data>
      <data key="d5">Language models can enhance their reasoning and practical abilities by utilizing external tools such as APIs and search engines.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="PROBLEM SETTING AND PROMPTING">
      <data key="d4">7.0</data>
      <data key="d5">The problem setting and prompting techniques are essential for effectively utilizing language models in reasoning and decision-making tasks.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="TOOL USE">
      <data key="d4">9.0</data>
      <data key="d5">The use of external tools significantly enhances the functionality and performance of language models in various tasks.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="LATS">
      <data key="d4">8.0</data>
      <data key="d5">LATS is based on MCTS, utilizing its principles to enhance the decision-making capabilities of language models.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="DECISION-MAKING TASKS">
      <data key="d4">9.0</data>
      <data key="d5">MCTS is specifically designed for decision-making tasks, providing a structured approach to explore possible actions and outcomes.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="HEURISTICS">
      <data key="d4">6.0</data>
      <data key="d5">Heuristics guide the search process in MCTS, helping to evaluate the potential of different states and actions in the decision tree.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="SEARCH ALGORITHMS">
      <data key="d4">7.0</data>
      <data key="d5">Search algorithms are integral to MCTS, guiding the exploration of the decision tree to find optimal actions.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="DECISION TREE">
      <data key="d4">1.0</data>
      <data key="d5">MCTS builds a decision tree to represent states and actions in decision-making environments, facilitating the search for solutions.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="PROGRAMMING" target="LATS">
      <data key="d4">14.0</data>
      <data key="d5">LATS is a versatile tool that enhances programming tasks by leveraging its advanced reasoning and decision-making capabilities. It is particularly recommended for scenarios where performance is prioritized over efficiency, making it a valuable asset in programming environments that demand high levels of output and effectiveness.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="PROGRAMMING" target="HUMANEVAL DATASET">
      <data key="d4">9.0</data>
      <data key="d5">The HumanEval dataset is used to evaluate programming models, assessing their ability to synthesize code from natural language descriptions.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="PROGRAMMING" target="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d4">8.0</data>
      <data key="d5">The MBPP benchmark is designed to evaluate program synthesis techniques, similar to the HumanEval dataset.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="INTERACTIVE QUESTION-ANSWERING (QA)" target="LATS">
      <data key="d4">8.0</data>
      <data key="d5">LATS improves performance in interactive QA tasks by integrating reasoning and planning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WEB NAVIGATION" target="LATS">
      <data key="d4">6.0</data>
      <data key="d5">LATS can assist in web navigation tasks by providing intelligent responses based on user queries.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MATH" target="LATS">
      <data key="d4">1.0</data>
      <data key="d5">LATS enhances the ability of language models to solve mathematical problems through its advanced reasoning techniques.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="GPT-4" target="LATS">
      <data key="d4">18.0</data>
      <data key="d5">LATS demonstrates exceptional performance in programming tasks, particularly on the HumanEval benchmark, when utilized in conjunction with the GPT-4 model. It achieves a high Pass@1 rate, underscoring its advanced capabilities. Furthermore, LATS shows significant improvements in task performance compared to its predecessor, GPT-3.5, solidifying its status as a state-of-the-art solution in the field. The integration of GPT-4 enhances LATS's effectiveness, making it a leading tool for developers and researchers in artificial intelligence and natural language processing.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-4" target="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d4">6.0</data>
      <data key="d5">GPT-4 also employs value function hyperparameters to enhance its performance in language processing tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-4" target="GPT-3.5">
      <data key="d4">8.0</data>
      <data key="d5">Knowledge and performance from GPT-3.5 are transferred to GPT-4, improving the capabilities of the agents generated by Meta Agent Search.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="GPT-4" target="META AGENT SEARCH">
      <data key="d4">24.0</data>
      <data key="d5">GPT-4 and Meta Agent Search are interconnected entities in the realm of artificial intelligence, particularly in the evaluation and adaptability of agents. GPT-4 is employed to test the transferability of agents identified through Meta Agent Search, demonstrating their ability to adapt across different models. Additionally, Meta Agent Search leverages GPT-4 to assess the performance of these discovered agents, ensuring a comprehensive evaluation process. This collaboration highlights the synergy between GPT-4's capabilities and the functionalities of Meta Agent Search in advancing the development and performance assessment of AI agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-4" target="GPT-3.5-TURBO-0125">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4 is a more cost-effective and higher-performing alternative to GPT-3.5-turbo-0125 for similar tasks.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="GPT-4" target="SYNTHETIC DATA">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is utilized to generate responses for prompts in the synthetic data generation process, enhancing the quality of the data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="GPT-4" target="AGENTINSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct utilizes GPT-4 to generate high-quality synthetic data for training AI models.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="GPT-4" target="ORCA-BENCH">
      <data key="d4">9.0</data>
      <data key="d5">Orca-Bench is used to evaluate the performance of GPT-4, which serves as the benchmark model with a score of 10.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GPT-4" target="MISTRAL">
      <data key="d4">1.0</data>
      <data key="d5">Mistral's reading comprehension capabilities are compared to those of GPT-4, indicating advancements in model performance.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPT-4" target="ORCA-3">
      <data key="d4">17.0</data>
      <data key="d5">The entities in focus are **GPT-4** and **ORCA-3**. ORCA-3's performance is evaluated against GPT-4, which is recognized as a benchmark for language model capabilities. Notably, ORCA-3 has demonstrated significant advancements, particularly in reading comprehension sections of the LSATs, where its performance has been elevated to align with that of GPT-4. This indicates that ORCA-3 holds a competitive position among contemporary language models, showcasing its effectiveness in tasks traditionally associated with high-level language understanding.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="ORCA-3-7B">
      <data key="d4">9.0</data>
      <data key="d5">GPT-4 is used to evaluate the performance of Orca-3-7B, establishing a relationship between the model and its evaluator.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 has been evaluated on the MIRAGE datasets to assess its performance in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="CO-T">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 utilizes the CoT technique to enhance its reasoning capabilities in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-3.5" target="LATS">
      <data key="d4">49.0</data>
      <data key="d5">GPT-3.5 is a pivotal component within the LATS framework, significantly enhancing its capabilities in various domains. It is employed to analyze and report performance metrics specifically in the Game of 24, demonstrating its utility in performance evaluation. Additionally, GPT-3.5 improves decision-making and reasoning capabilities across a range of tasks, serving as the foundational language model that underpins LATS's operations. The integration of GPT-3.5 allows LATS to achieve high performance in reasoning and programming tasks, showcasing its adaptability to different language models. Furthermore, LATS utilizes GPT-3.5 for its prompting methods, which are essential for evaluating performance in diverse tasks, including HotPotQA. Overall, the collaboration between GPT-3.5 and LATS exemplifies a robust synergy that enhances the effectiveness of both entities in their respective applications.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-3.5" target="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d4">6.0</data>
      <data key="d5">GPT-3.5 utilizes specific value function hyperparameters to optimize its performance in various tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-3.5" target="META AGENT SEARCH">
      <data key="d4">24.0</data>
      <data key="d5">GPT-3.5 is utilized as a foundational model in the context of Meta Agent Search, where it plays a crucial role in evaluating the performance of both discovered agents and baseline agents. This evaluation process enables a comprehensive comparison of the effectiveness of the agents identified through Meta Agent Search. By leveraging GPT-3.5, the Meta Agent Search framework enhances its ability to assess and refine the capabilities of various agents, ensuring a robust analysis of their performance metrics.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-3.5" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">The study of ADAS involves insights gained from the performance of GPT-3.5 in refining answers through feedback mechanisms.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="GPT-3.5" target="MISTRAL-7B">
      <data key="d4">1.0</data>
      <data key="d5">Mistral-7B is compared with GPT-3.5 to assess the performance of instruction-tuned models.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="REACT" target="LATS">
      <data key="d4">38.0</data>
      <data key="d5">LATS is a sophisticated system that incorporates the ReAct prompting method to significantly enhance its performance in decision-making and reasoning tasks. By utilizing ReAct, LATS adapts its approach based on prior successes or failures, allowing for a more flexible and adaptive problem-solving strategy. While LATS is compared to simpler prompting methods like ReAct in terms of computational cost and performance, it ultimately offers a more advanced solution, demonstrating its capability to improve upon the foundational techniques provided by ReAct.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="REACT" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">7.0</data>
      <data key="d5">ReAct and CoT are both prompting techniques used to enhance reasoning and decision-making in language models, but they have different approaches and limitations.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="SELF-REFINE">
      <data key="d4">8.0</data>
      <data key="d5">Self-refine is an extension proposed to improve upon the limitations of ReAct, focusing on self-improvement in reasoning and decision-making.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="ADAPLANNER">
      <data key="d4">6.0</data>
      <data key="d5">AdaPlanner incorporates feedback mechanisms that can enhance the decision-making process in a manner similar to ReAct.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="KURATOV ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Kuratov et al. (2023) provides insights relevant to the effectiveness of the ReAct technique in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="CHAIN-OF-THOUGHT PROMPTING">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-thought prompting and ReAct both aim to improve reasoning capabilities in language models, but ReAct incorporates external interactions for enhanced performance.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">ReAct is applied in decision-making tasks where interaction with an external environment is necessary for effective reasoning and action.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="YAO ET AL. (2023B)">
      <data key="d4">5.0</data>
      <data key="d5">Yao et al. (2023b) discusses the efficiency of the ReAct method, which is compared to LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="REACT" target="OMNI">
      <data key="d4">1.0</data>
      <data key="d5">OMNI and React are both systems designed to enhance the capabilities of language models in different ways.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="COBBE ET AL. (2021)" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">LATS builds upon the reasoning principles discussed by Cobbe et al. (2021).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="YAO ET AL. (2022)" target="LATS">
      <data key="d4">5.0</data>
      <data key="d5">Yao et al. (2022) provides insights into the WebShop domain that may relate to LATS's applications.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="YAO ET AL. (2022)" target="WEB SHOP">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. (2022) discusses the WebShop environment, providing foundational knowledge for its application in decision-making tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="FAN ET AL. (2022)" target="LATS">
      <data key="d4">6.0</data>
      <data key="d5">LATS is relevant to the use of language models in complex multimodal games as discussed by Fan et al. (2022).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="YAO ET AL. (2023A)" target="LATS">
      <data key="d4">13.0</data>
      <data key="d5">YAO ET AL. (2023A) and LATS are interconnected through advancements in search algorithms, as highlighted in Yao et al. (2023A). This work discusses the Game of 24, which may enhance LATS's reasoning capabilities. Additionally, Yao et al. (2023A) offers valuable insights into the sample complexity of the LATS algorithm, further contributing to its development and effectiveness. Together, these elements underscore the significance of Yao et al.'s research in informing and advancing the functionalities of LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="SHINN ET AL. (2023)" target="LATS">
      <data key="d4">5.0</data>
      <data key="d5">Shinn et al. (2023) offers evaluations that can be compared with LATS's performance in reasoning tasks.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="SHINN ET AL. (2023)" target="REFLEXION">
      <data key="d4">6.0</data>
      <data key="d5">Shinn et al. (2023) evaluates the effectiveness of Reflexion in enhancing agent performance in decision-making tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="AGENTBENCH">
      <data key="d4">7.0</data>
      <data key="d5">Reinforcement learning techniques are evaluated within the AgentBench framework to assess agent performance.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="FEEDBACK" target="REFINEMENT">
      <data key="d4">8.0</data>
      <data key="d5">Refinement relies on feedback from experts to improve the quality of answers generated by agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="FEEDBACK" target="CRITIC_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The critic_module generates feedback based on the answers provided by the cot_module, assessing their correctness.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="FEEDBACK" target="STRUCTURED FEEDBACK AND ENSEMBLE AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent uses feedback to refine its generated solutions and improve performance.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="INITIAL_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is derived from the evaluation of initial solutions, providing insights into their performance and areas for improvement.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="SELF-REFINE">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is a crucial element in the Self-Refine method, guiding the iterative improvement of answers.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LATS" target="SELF-REFINEMENT">
      <data key="d4">7.0</data>
      <data key="d5">LATS incorporates self-refinement to enhance model sensibility and learning from experience.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SELF-CONSISTENCY">
      <data key="d4">6.0</data>
      <data key="d5">LATS utilizes self-consistency to improve the reliability of its outputs during reasoning tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">7.0</data>
      <data key="d5">LATS builds upon the principles of CoT prompting to enhance reasoning capabilities in language models.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="YANG ET AL. (2018)">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated using the HotPotQA dataset, which was introduced by Yang et al. (2018).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SILVER ET AL. (2017)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is inspired by the success of MCTS discussed by Silver et al. (2017).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="WEI ET AL. (2022)">
      <data key="d4">7.0</data>
      <data key="d5">LATS incorporates ideas from chain-of-thought prompting as discussed by Wei et al. (2022).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="GUO ET AL. (2018)">
      <data key="d4">6.0</data>
      <data key="d5">LATS addresses the error propagation issues highlighted by Guo et al. (2018).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="CHEN ET AL. (2021)">
      <data key="d4">13.0</data>
      <data key="d5">LATS, as highlighted in the work of Chen et al. (2021), showcases enhanced performance in programming tasks, particularly when evaluated using the HumanEval dataset. The findings presented by Chen et al. emphasize the relevance of LATS's capabilities in these applications, indicating a significant improvement in its performance metrics. This relationship underscores the importance of LATS in advancing programming task evaluations and its alignment with the insights provided by Chen et al. (2021).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="HAO ET AL. (2023)">
      <data key="d4">17.0</data>
      <data key="d5">Hao et al. (2023) offers a comprehensive comparative analysis of the LATS algorithm, focusing on its performance in decision-making tasks. The study highlights how LATS integrates various planning techniques, providing insights into its effectiveness relative to other methods. This analysis not only underscores the strengths of LATS but also situates it within the broader context of algorithmic performance in decision-making scenarios.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="BESTA ET AL. (2023)">
      <data key="d4">7.0</data>
      <data key="d5">LATS builds upon advancements in search algorithms discussed by Besta et al. (2023).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="AHN ET AL. (2022)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is related to the application of language models in robotics as discussed by Ahn et al. (2022).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="HUANG ET AL. (2022)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is connected to the use of language models in robotics as discussed by Huang et al. (2022).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="DRIESS ET AL. (2023)">
      <data key="d4">6.0</data>
      <data key="d5">LATS relates to the application of language models in robotics as discussed by Driess et al. (2023).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="BAKER ET AL. (2022)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is relevant to the adaptation of language models in complex multimodal games as discussed by Baker et al. (2022).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="GUSS ET AL. (2019)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is related to the application of language models in games like Minecraft as discussed by Guss et al. (2019).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="LIU ET AL. (2018)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is connected to the application of language models in text-based environments as discussed by Liu et al. (2018).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SHRIDHAR ET AL. (2020)">
      <data key="d4">6.0</data>
      <data key="d5">LATS relates to the use of language models in interactive environments as discussed by Shridhar et al. (2020).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="LIU ET AL. (2024)">
      <data key="d4">1.0</data>
      <data key="d5">LATS is relevant to the application of language models in text-based environments as discussed by Liu et al. (2024).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="MCTS">
      <data key="d4">25.0</data>
      <data key="d5">LATS is an innovative entity that adapts Monte Carlo Tree Search (MCTS) to develop a specialized search algorithm tailored for language agents. This adaptation integrates reasoning and planning capabilities, allowing LATS to effectively navigate complex decision-making scenarios. By employing MCTS, LATS explores and selects high-value options, thereby enhancing its decision-making performance in intricate environments. Overall, LATS leverages MCTS as a principled search algorithm to optimize its operations and improve outcomes in the realm of language processing and agent-based interactions.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LM AGENT">
      <data key="d4">8.0</data>
      <data key="d5">LATS utilizes the LM Agent as a core component to facilitate decision-making and planning through language model representations.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="REFLECTION">
      <data key="d4">6.0</data>
      <data key="d5">Reflection is a key operation in LATS that helps improve the search algorithm by using feedback from previous attempts to enhance future performance.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SEARCH ALGORITHM">
      <data key="d4">1.0</data>
      <data key="d5">LATS is a specific type of search algorithm that integrates reasoning, acting, and planning for language models, enhancing decision-making capabilities.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="VALUE FUNCTION">
      <data key="d4">16.0</data>
      <data key="d5">LATS employs a value function to effectively quantify the agent's progress in completing tasks, which plays a crucial role in guiding its decision-making process. This value function scores various states, thereby directing the search process based on anticipated future rewards. Through this mechanism, LATS enhances its ability to navigate complex tasks by evaluating potential outcomes and optimizing its actions accordingly.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENTAL FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">Environmental feedback is integral to LATS, providing assessments that influence the agent's learning and decision-making.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="SELF-REFLECTION">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection is a mechanism in LATS that allows the agent to learn from unsuccessful outcomes and improve future performance.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="TRIAL AND ERROR">
      <data key="d4">7.0</data>
      <data key="d5">LATS incorporates a trial and error approach, enabling the agent to learn from past experiences without costly optimization methods.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="PROGRAMMED HEURISTICS">
      <data key="d4">7.0</data>
      <data key="d5">LATS aims to improve upon programmed heuristics by offering a more flexible and adaptive decision-making framework.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="LEARNED HEURISTICS">
      <data key="d4">1.0</data>
      <data key="d5">LATS seeks to outperform learned heuristics in terms of efficiency and adaptability in various problem-solving scenarios.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="REFLEXION">
      <data key="d4">35.0</data>
      <data key="d5">LATS and REFLEXION are entities that are closely examined in the context of their performance on various tasks, particularly HotPotQA. LATS demonstrates superior results compared to REFLEXION, indicating its enhanced capabilities in reasoning tasks. The comparison between LATS and REFLEXION also highlights LATS's ability to incorporate the Reflexion method, which serves to improve its reasoning performance through effective feedback mechanisms. Furthermore, LATS is evaluated against simpler prompting methods, including REFLEXION, in terms of both computational cost and overall performance. By utilizing REFLEXION, LATS gains additional semantic signals that significantly enhance the agent's decision-making process, showcasing the synergistic relationship between the two methods.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="TO">
      <data key="d4">7.0</data>
      <data key="d5">LATS extends the ToT method by integrating it with ReAct prompting for better decision-making.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="RAP">
      <data key="d4">15.0</data>
      <data key="d5">LATS integrates RAP strategies to enhance its performance in reasoning tasks through external retrieval, while also incorporating aspects of the RAP method to improve its reasoning and acting strategies. This collaboration between LATS and RAP signifies a concerted effort to bolster reasoning capabilities, demonstrating a commitment to leveraging external resources and methodologies for improved outcomes in reasoning and action-oriented tasks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="AUSTIN ET AL. (2022)">
      <data key="d4">5.0</data>
      <data key="d5">Austin et al. (2022) evaluates language models in domains that may include applications of LATS.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="COT">
      <data key="d4">7.0</data>
      <data key="d5">LATS incorporates CoT prompting to enhance reasoning performance in tasks like HotPotQA.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="TOT">
      <data key="d4">8.0</data>
      <data key="d5">LATS employs ToT methods to sample and explore outputs, improving its reasoning capabilities.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="HUMANEVAL">
      <data key="d4">17.0</data>
      <data key="d5">LATS is a system that is evaluated using the HumanEval dataset, which is specifically designed for programming tasks in language models. This evaluation focuses on LATS's capability to generate accurate Python code based on natural language descriptions. Through testing on the HumanEval dataset, LATS's performance in translating natural language prompts into functional Python code is assessed, highlighting its effectiveness in programming-related applications.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="MBPP">
      <data key="d4">9.0</data>
      <data key="d5">LATS is evaluated on the MBPP dataset to measure its performance in programming tasks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="IL">
      <data key="d4">14.0</data>
      <data key="d5">LATS is evaluated against IL to assess its performance in decision-making tasks. To improve its reasoning and acting capabilities, LATS employs Imitation Learning techniques. This comparison highlights the effectiveness of LATS in various decision-making scenarios, showcasing its advanced methodologies in artificial intelligence.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="IL+RL">
      <data key="d4">7.0</data>
      <data key="d5">LATS employs Imitation Learning with Reinforcement Learning to optimize its performance in complex reasoning tasks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="EXTERNAL OBSERVATIONS">
      <data key="d4">8.0</data>
      <data key="d5">LATS integrates external observations to augment its reasoning process and improve task performance.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="SYNTHETIC TEST SUITE">
      <data key="d4">1.0</data>
      <data key="d5">LATS uses a synthetic test suite to evaluate the correctness of generated programming solutions.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="WEB SHOP">
      <data key="d4">8.0</data>
      <data key="d5">LATS is applied in the WebShop environment to enhance decision-making performance for agents navigating the online shopping platform.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="COACHING OF THOUGHT (COT)">
      <data key="d4">8.0</data>
      <data key="d5">LATS employs CoT as a prompting design to guide agents in reasoning tasks effectively.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="GAME OF 24">
      <data key="d4">16.0</data>
      <data key="d5">LATS is a method utilized within the context of the Game of 24, specifically designed to assess success rates under various parameter settings. This method is evaluated through the Game of 24 task, showcasing its reasoning capabilities in tackling mathematical challenges. By applying LATS, researchers can gain insights into the effectiveness of different strategies employed in the Game of 24, thereby enhancing the understanding of mathematical problem-solving within this framework.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="LATS" target="DFS">
      <data key="d4">1.0</data>
      <data key="d5">LATS incorporates DFS as a search strategy to explore decision-making paths in its framework.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="RL">
      <data key="d4">7.0</data>
      <data key="d5">LATS is compared against RL-based training methods to assess its effectiveness in improving scores and success rates.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="FURUTA ET AL. (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Furuta et al. (2024) provides insights relevant to the fine-tuning methods that can be applied in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="TOOL OF THOUGHT (TOT)">
      <data key="d4">1.0</data>
      <data key="d5">LATS incorporates ToT as a prompting method to enhance reasoning capabilities in decision-making tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="SYSTEM-2 LM APPROACHES">
      <data key="d4">8.0</data>
      <data key="d5">LATS is an example of a System-2 LM approach that enhances decision-making through interactions with environments.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="DECISION-MAKING COMMUNITY">
      <data key="d4">7.0</data>
      <data key="d5">LATS contributes to the decision-making community by improving autonomous decision-making processes using language models.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="DANIEL CAMPOS">
      <data key="d4">6.0</data>
      <data key="d5">Daniel Campos provided feedback on the development of LATS, indicating his involvement in the research process.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NSF GRANT 2106825">
      <data key="d4">7.0</data>
      <data key="d5">NSF Grant 2106825 supports research related to the development and application of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NIFA AWARD 2020-67021-32799">
      <data key="d4">7.0</data>
      <data key="d5">NIFA Award 2020-67021-32799 supports research related to the development and application of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="IBM-ILLINOIS DISCOVERY ACCELERATOR INSTITUTE">
      <data key="d4">7.0</data>
      <data key="d5">The IBM-Illinois Discovery Accelerator Institute supports research initiatives like LATS, enhancing language model capabilities.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NVIDIA GPUS">
      <data key="d4">8.0</data>
      <data key="d5">NVIDIA GPUs are utilized in the implementation of LATS for computational tasks, enhancing its performance.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ACCESS PROGRAM">
      <data key="d4">7.0</data>
      <data key="d5">The ACCESS program provides computational resources that support the research and development of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="MICHAEL AHN">
      <data key="d4">6.0</data>
      <data key="d5">Michael Ahn is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ANTHONY BROHAN">
      <data key="d4">6.0</data>
      <data key="d5">Anthony Brohan is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NOAH BROWN">
      <data key="d4">6.0</data>
      <data key="d5">Noah Brown is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="YEVGEN CHEBOTAR">
      <data key="d4">6.0</data>
      <data key="d5">Yevgen Chebotar is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="OMAR CORTES">
      <data key="d4">6.0</data>
      <data key="d5">Omar Cortes is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="BYRON DAVID">
      <data key="d4">6.0</data>
      <data key="d5">Byron David is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="CHELSEA FINN">
      <data key="d4">6.0</data>
      <data key="d5">Chelsea Finn is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="CHUYUAN FU">
      <data key="d4">6.0</data>
      <data key="d5">Chuyuan Fu is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="KEERTHANA GOPALAKRISHNAN">
      <data key="d4">6.0</data>
      <data key="d5">Keerthana Gopalakrishnan is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="KAROL HAUSMAN">
      <data key="d4">6.0</data>
      <data key="d5">Karol Hausman is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ALEX HERZOG">
      <data key="d4">6.0</data>
      <data key="d5">Alex Herzog is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="DANIEL HO">
      <data key="d4">6.0</data>
      <data key="d5">Daniel Ho is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="JASMINE HSU">
      <data key="d4">6.0</data>
      <data key="d5">Jasmine Hsu is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="JULIAN IBARZ">
      <data key="d4">6.0</data>
      <data key="d5">Julian Ibarz is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="BRIAN ICHTER">
      <data key="d4">6.0</data>
      <data key="d5">Brian Ichter is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ALEX IRPAN">
      <data key="d4">6.0</data>
      <data key="d5">Alex Irpan is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ERIC JANG">
      <data key="d4">6.0</data>
      <data key="d5">Eric Jang is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ROSARIO JAUREGUI RUANO">
      <data key="d4">6.0</data>
      <data key="d5">Rosario Jauregui Ruano is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="KYLE JEFFREY">
      <data key="d4">6.0</data>
      <data key="d5">Kyle Jeffrey is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="SALLY JESMONTH">
      <data key="d4">6.0</data>
      <data key="d5">Sally Jesmonth is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NIKHIL J JOSHI">
      <data key="d4">6.0</data>
      <data key="d5">Nikhil J Joshi is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="RYAN JULIAN">
      <data key="d4">6.0</data>
      <data key="d5">Ryan Julian is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="DMITRY KALASHNIKOV">
      <data key="d4">6.0</data>
      <data key="d5">Dmitry Kalashnikov is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="YUHENG KUANG">
      <data key="d4">6.0</data>
      <data key="d5">Yuheng Kuang is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="KUANG-HUEI LEE">
      <data key="d4">6.0</data>
      <data key="d5">Kuang-Huei Lee is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="SERGEY LEVINE">
      <data key="d4">6.0</data>
      <data key="d5">Sergey Levine is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="YAO LU">
      <data key="d4">6.0</data>
      <data key="d5">Yao Lu is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="LINDA LUU">
      <data key="d4">6.0</data>
      <data key="d5">Linda Luu is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="CAROLINA PARADA">
      <data key="d4">6.0</data>
      <data key="d5">Carolina Parada is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="PETER PASTOR">
      <data key="d4">6.0</data>
      <data key="d5">Peter Pastor is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="PROGRAM SYNTHESIS">
      <data key="d4">7.0</data>
      <data key="d5">LATS can be applied in program synthesis to enhance decision-making processes through interactions with programming environments.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="VIDEO PRETRAINING (VPT)">
      <data key="d4">6.0</data>
      <data key="d5">LATS may utilize techniques from video pretraining to improve its performance in action-related tasks within language models.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="GRAPH OF THOUGHTS">
      <data key="d4">7.0</data>
      <data key="d5">LATS can incorporate the Graph of Thoughts methodology to enhance structured reasoning in decision-making processes.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NATURAL LANGUAGE INFERENCE">
      <data key="d4">6.0</data>
      <data key="d5">LATS can benefit from natural language inference techniques to improve its understanding of logical relationships in decision-making.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="DEEP BLUE">
      <data key="d4">5.0</data>
      <data key="d5">LATS shares similarities with Deep Blue in terms of enhancing decision-making capabilities through advanced computational techniques.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="CODET">
      <data key="d4">1.0</data>
      <data key="d5">LATS can leverage techniques from CodeT for generating and testing code in decision-making scenarios.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="OLIVIER BOUSQUET">
      <data key="d4">8.0</data>
      <data key="d5">Olivier Bousquet is a researcher who contributed to the development of the LATS algorithm for reasoning in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="QUOC LE">
      <data key="d4">8.0</data>
      <data key="d5">Quoc Le is a researcher involved in the development of the LATS algorithm for reasoning in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="ED CHI">
      <data key="d4">8.0</data>
      <data key="d5">Ed Chi is a researcher who contributed to the study of reasoning in language models through the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="MONTE CARLO TREE SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">LATS utilizes Monte Carlo Tree Search as part of its decision-making process.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="WEBSHOP">
      <data key="d4">8.0</data>
      <data key="d5">LATS is evaluated using the WebShop dataset for web search tasks in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="ALFWORLD">
      <data key="d4">7.0</data>
      <data key="d5">LATS is applicable in environments like Alfworld for text-based manipulation tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="TOOLBENCH">
      <data key="d4">7.0</data>
      <data key="d5">LATS can be evaluated in environments that utilize ToolBench for tool use capabilities.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="WANG ET AL. (2022)">
      <data key="d4">1.0</data>
      <data key="d5">Wang et al. (2022) provides insights relevant to the performance of LATS in comparison to CoT-SC.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="A* SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm employs A* search as part of its action space navigation strategy.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="EXPERIMENTAL RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">Experimental results are used to evaluate the effectiveness of the LATS algorithm in various tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENT DETAILS">
      <data key="d4">7.0</data>
      <data key="d5">Environment details are crucial for understanding the context in which the LATS algorithm operates.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="PROMPTS">
      <data key="d4">8.0</data>
      <data key="d5">Prompts are utilized within the LATS algorithm to guide the language model's responses in different scenarios.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="COMPUTATIONAL COST">
      <data key="d4">7.0</data>
      <data key="d5">Computational cost is a significant factor when evaluating the efficiency of the LATS algorithm compared to simpler methods.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="SAMPLE COMPLEXITY">
      <data key="d4">6.0</data>
      <data key="d5">Sample complexity is an important metric for assessing the performance of the LATS algorithm in various scenarios.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="TRIALS">
      <data key="d4">8.0</data>
      <data key="d5">Trials are conducted to test the performance and efficiency of the LATS algorithm in different environments.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="RESOURCE CONSTRAINTS">
      <data key="d4">6.0</data>
      <data key="d5">Resource constraints can impact the implementation and performance of the LATS algorithm in real-world applications.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="DECISION-MAKING">
      <data key="d4">8.0</data>
      <data key="d5">Decision-making is a core function of the LATS algorithm, enabling it to evaluate and select actions based on reasoning.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="REAL-WORLD ENVIRONMENTS">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm is designed to be applicable in real-world environments, enhancing its utility in practical tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="INTERACTIVE ENVIRONMENTS">
      <data key="d4">1.0</data>
      <data key="d5">Interactive environments provide a context for the LATS algorithm to engage in tasks that require reasoning and decision-making.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENT">
      <data key="d4">7.0</data>
      <data key="d5">LATS operates within a defined environment that includes the state space and task dynamics, influencing its decision-making process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ACTION SPACE">
      <data key="d4">8.0</data>
      <data key="d5">LATS utilizes a specific action space that defines the actions it can take, such as searching for entities and looking up strings.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="TRAJECTORIES">
      <data key="d4">7.0</data>
      <data key="d5">LATS evaluates its performance based on the trajectories it generates during its decision-making process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SAMPLING SIZE">
      <data key="d4">6.0</data>
      <data key="d5">The sampling size affects the performance of LATS, as different sizes can lead to varying results in task completion.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="EXPLORATION WEIGHT">
      <data key="d4">8.0</data>
      <data key="d5">The exploration weight is a critical parameter in LATS that influences the effectiveness of its search strategy.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="DEPTH">
      <data key="d4">7.0</data>
      <data key="d5">The depth parameter in LATS limits the number of steps taken during the search process, impacting overall performance.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="REWARD">
      <data key="d4">7.0</data>
      <data key="d5">Rewards from the environment provide feedback to LATS, influencing its learning and decision-making process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="PERFORMANCE">
      <data key="d4">1.0</data>
      <data key="d5">The performance of LATS is assessed based on its ability to successfully complete tasks, such as answering questions in HotPotQA.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SELF-CONSISTENCY SCORE">
      <data key="d4">1.0</data>
      <data key="d5">The self-consistency score is evaluated as part of the LATS method to determine the accuracy and reliability of the results in the Game of 24.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT)" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search incorporates Chain-of-Thought as a baseline technique for agent evaluation.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT)" target="DROP">
      <data key="d4">5.0</data>
      <data key="d5">Chain-of-Thought (COT) is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="HAO ET AL. (2023)" target="MCTS">
      <data key="d4">5.0</data>
      <data key="d5">Hao et al. (2023) explores the use of planning and search algorithms, including MCTS, in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="SELF-REFINE" target="REFLEXION">
      <data key="d4">8.0</data>
      <data key="d5">Reflexion builds on the self-improvement concept introduced by Self-Refine, enhancing reasoning and decision-making capabilities.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="SELF-REFINE" target="META AGENT SEARCH">
      <data key="d4">14.0</data>
      <data key="d5">The entities "SELF-REFINE" and "META AGENT SEARCH" are interconnected in their focus on enhancing agent performance through iterative processes. Meta Agent Search evaluates agents that employ Self-Refine, which is specifically designed to improve their outputs by implementing iterative corrections. This collaborative approach allows for the continuous refinement of agent capabilities, ensuring that the agents not only learn from their previous outputs but also enhance their overall effectiveness in various tasks. Through this synergy, both Self-Refine and Meta Agent Search contribute to advancing the field of artificial intelligence by fostering improved performance and adaptability in agent systems.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="SELF-REFINE" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">Self-Refine is a baseline technique that is compared against state-of-the-art hand-designed agents to assess its effectiveness in improving responses.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="SELF-REFINE" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Self-Refine is a technique used by manually designed agents to enhance their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="SELF-REFINE" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Self-Refine is a manually designed agent that can be enhanced by the methodologies proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="SELF-REFINE" target="DROP">
      <data key="d4">5.0</data>
      <data key="d5">Self-Refine is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="SELF-REFINE" target="STEP-BACK ABSTRACTION">
      <data key="d4">7.0</data>
      <data key="d5">Step-back Abstraction is implemented as part of the Self-Refine process in reasoning and problem-solving experiments.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="SELF-REFINE" target="MULTI-STEP PEER REVIEW AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Multi-Step Peer Review Agent utilizes the Self-Refine method to enhance the quality of answers through iterative feedback.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MCTS" target="TREE-BASED SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">MCTS is a specific implementation of tree-based search techniques used for exploring multiple outcomes in decision-making processes.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="MCTS" target="UCT ALGORITHM">
      <data key="d4">1.0</data>
      <data key="d5">The UCT algorithm is a fundamental component of MCTS, used to guide the selection of nodes in the search tree based on exploration and exploitation balance.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="DFS">
      <data key="d4">7.0</data>
      <data key="d5">MCTS is compared to DFS as a more principled search algorithm, highlighting differences in performance and methodology.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="DECISION-MAKING" target="REASONING">
      <data key="d4">8.0</data>
      <data key="d5">Reasoning is a fundamental component of decision-making processes in language models, guiding the generation of outputs based on inputs.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="DECISION-MAKING" target="PLANNING">
      <data key="d4">7.0</data>
      <data key="d5">Planning techniques are often employed to enhance the decision-making capabilities of language models, allowing for more structured outputs.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="DECISION-MAKING" target="LANGUAGE MODEL AGENT">
      <data key="d4">1.0</data>
      <data key="d5">Decision-making is a core function of the language model agent, determining its actions based on reasoning and available data.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="REASONING" target="TOOL USE">
      <data key="d4">1.0</data>
      <data key="d5">Utilizing external tools can improve the reasoning capabilities of language models by providing additional information and context.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REASONING" target="HUAIXIU STEVEN ZHENG">
      <data key="d4">8.0</data>
      <data key="d5">Huaixiu Steven Zheng is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="SWAROOP MISHRA">
      <data key="d4">8.0</data>
      <data key="d5">Swaroop Mishra is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="XINYUN CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Xinyun Chen is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="HENG-TZE CHENG">
      <data key="d4">8.0</data>
      <data key="d5">Heng-Tze Cheng is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="ED H CHI">
      <data key="d4">8.0</data>
      <data key="d5">Ed H Chi is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="QUOC V LE">
      <data key="d4">8.0</data>
      <data key="d5">Quoc V Le is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="DENNY ZHOU">
      <data key="d4">8.0</data>
      <data key="d5">Denny Zhou is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="TOOL USE" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">6.0</data>
      <data key="d5">Tool use is a critical component for agents to solve complex tasks, as discussed in the context of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="TOOL USE" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Agentic Systems employ Tool Use to accomplish tasks effectively.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="TOOL USE" target="SKILLS">
      <data key="d4">8.0</data>
      <data key="d5">Tool use is a skill that is also developed through the workflows in the agentic flows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TOOL USE" target="CODING">
      <data key="d4">6.0</data>
      <data key="d5">Tool use in AI often involves coding to manipulate tools and resources effectively for problem-solving.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT PROMPTING" target="TREE-OF-THOUGHT PROMPTING">
      <data key="d4">8.0</data>
      <data key="d5">Tree-of-thought prompting builds upon chain-of-thought prompting by exploring multiple reasoning paths, enhancing the complexity of the reasoning process.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT PROMPTING" target="ERROR PROPAGATION">
      <data key="d4">1.0</data>
      <data key="d5">Error propagation can occur in chain-of-thought prompting if earlier reasoning steps lead to incorrect conclusions, affecting the final output.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT PROMPTING" target="LANGUAGE MODEL (LM)">
      <data key="d4">8.0</data>
      <data key="d5">The language model utilizes chain-of-thought prompting to enhance its reasoning capabilities by generating intermediate thoughts.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT PROMPTING" target="THOUGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Thoughts are generated as part of the chain-of-thought prompting process, acting as stepping stones between input and output.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="OUTPUT" target="INPUT PROMPT">
      <data key="d4">9.0</data>
      <data key="d5">The input prompt is transformed into an output by the language model, representing the model's response to the provided instructions or examples.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="THOUGHTS" target="FM_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">FM_Module produces thoughts that include reasoning and code as outputs for the task at hand.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="THOUGHTS" target="INITIAL_SOLUTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Thoughts are generated as part of the evaluation process for each initial solution, reflecting the cognitive analysis performed.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="LM AGENT" target="ENVIRONMENT">
      <data key="d4">9.0</data>
      <data key="d5">The LM Agent interacts with the environment, receiving observations and feedback that guide its decision-making process.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="POLICY &#928;">
      <data key="d4">7.0</data>
      <data key="d5">The policy &#960; is employed by the LM Agent to determine the actions it should take based on its observations and previous actions.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="ACTIONS">
      <data key="d4">9.0</data>
      <data key="d5">The LM Agent takes actions based on its observations and policy, which influence the state of the environment.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="REFLECTION" target="SEARCH ACTION">
      <data key="d4">1.0</data>
      <data key="d5">The user's search action leads to reflection on their experience, prompting them to refine their search strategy.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="REFLECTION" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Agentic Systems incorporate Reflection to evaluate actions and improve future performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="VALUE FUNCTION" target="BACKPROPAGATION">
      <data key="d4">7.0</data>
      <data key="d5">Backpropagation is used to update the value function based on the returns received, ensuring that the search algorithm learns from past experiences.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="VALUE FUNCTION" target="SELF-CONSISTENCY SCORE">
      <data key="d4">7.0</data>
      <data key="d5">The self-consistency score is a component of the value function in LATS, contributing to the overall assessment of the agent's performance.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="VALUE FUNCTION" target="AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The agent in LATS utilizes the value function to assess its progress and make informed decisions during task execution.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="VALUE FUNCTION" target="REWARD">
      <data key="d4">9.0</data>
      <data key="d5">The reward received at a terminal state is used to update the value function, influencing the agent's future actions and decisions.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="OBSERVATION" target="ACTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Each action taken by the LM Agent results in an observation from the environment, which is crucial for the agent's decision-making process.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="OBSERVATION" target="ACTION">
      <data key="d4">1.0</data>
      <data key="d5">Action leads to Observation, where information is gathered that influences subsequent Thoughts and Actions in the task.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The agent employs a search algorithm to navigate through the decision tree, optimizing its path based on feedback and heuristics.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="TERMINAL STATE">
      <data key="d4">7.0</data>
      <data key="d5">The search algorithm in LATS aims to reach a terminal state, where the outcome of the task can be evaluated for success or failure.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="UCT FORMULA">
      <data key="d4">8.0</data>
      <data key="d5">The UCT formula guides the search algorithm in LATS, helping to select the next node based on updated values and exploration strategies.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">8.0</data>
      <data key="d5">The search algorithm is crucial for exploring the search space in ADAS to find optimal agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="ZHUKE ET AL. (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Zhuge et al. (2024) discusses search algorithms relevant to the exploration of search spaces in ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="EXPLORATION-EXPLOITATION TRADE-OFF">
      <data key="d4">7.0</data>
      <data key="d5">The exploration-exploitation trade-off is a critical consideration in the design of search algorithms for ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SELF-REFLECTION" target="AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The agent utilizes self-reflection to analyze its performance and improve its decision-making process based on past experiences.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="SELF-REFLECTION" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">6.0</data>
      <data key="d5">Self-reflection is another building block proposed for enhancing agentic systems within the ADAS research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SELF-REFLECTION" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Self-reflection is integrated into the Meta Agent Search process to enhance the quality of generated agents through iterative refinement.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="SELF-REFLECTION" target="META AGENT">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent engages in self-reflection to improve its code generation and overall performance.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPLEMENTATION MISTAKES">
      <data key="d4">8.0</data>
      <data key="d5">During self-reflection, the meta agent identifies implementation mistakes to correct them in future iterations.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPROVEMENT SUGGESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection leads to improvement suggestions that enhance the agent's functionality and effectiveness.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="RUNTIME ERROR">
      <data key="d4">9.0</data>
      <data key="d5">When a runtime error occurs, the meta agent uses self-reflection to debug and correct the issue.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="EXAMPLES OF POTENTIAL MISTAKES">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection includes reviewing examples of potential mistakes to avoid similar errors in future implementations.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="TERMINAL STATE" target="TRAJECTORY">
      <data key="d4">8.0</data>
      <data key="d5">A trajectory in LATS culminates in a terminal state, providing feedback that influences future decision-making processes.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="REWARD" target="WEB SHOP">
      <data key="d4">7.0</data>
      <data key="d5">The reward metric is used to evaluate the performance of the Web Shop based on user interactions and item selections.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="EXTERNAL FEEDBACK" target="LANGUAGE MODEL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The language model agent utilizes external feedback to improve its reasoning and decision-making capabilities.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="INTERNAL REASONING" target="LANGUAGE MODEL AGENT">
      <data key="d4">7.0</data>
      <data key="d5">The language model agent employs internal reasoning to generate answers based on its existing knowledge.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="OBSERVATION SPACE" target="LANGUAGE MODEL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The observation space provides critical information to the language model agent for making informed decisions.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="SAMPLE TRAJECTORIES" target="LANGUAGE MODEL AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Sample trajectories are used by the language model agent to evaluate its performance in decision-making tasks.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="FEEDBACK CORRECTNESS" target="LANGUAGE MODEL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">Feedback correctness is essential for the language model agent to assess its performance and improve its responses.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="PROMPTING DESIGNS" target="LANGUAGE MODEL AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Prompting designs guide the language model agent in generating appropriate responses for various tasks.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="COT" target="COT-SC">
      <data key="d4">6.0</data>
      <data key="d5">COT-SC builds upon the COT technique by incorporating sampling and ensemble methods for decision-making.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="WEB SHOP" target="ACTION SPACE">
      <data key="d4">8.0</data>
      <data key="d5">The action space defines the various interactions users can perform within the Web Shop system, guiding their navigation and choices.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="SUCCESS RATE (SR)">
      <data key="d4">7.0</data>
      <data key="d5">Success Rate (SR) measures the effectiveness of the Web Shop in executing user instructions successfully.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The Web Shop allows users to select and purchase various items based on their attributes and user preferences.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="EPISODE">
      <data key="d4">7.0</data>
      <data key="d5">Each episode represents a unique interaction session within the Web Shop, where users can engage with the system and perform actions.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="ENVIRONMENTS">
      <data key="d4">6.0</data>
      <data key="d5">Different environments are used to conduct experiments that assess the performance and effectiveness of the Web Shop system.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d4">7.0</data>
      <data key="d5">Value function hyperparameters are utilized to fine-tune the decision-making processes within the Web Shop system.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="BRIGHT CITRUS DEODORANT">
      <data key="d4">1.0</data>
      <data key="d5">The Web Shop allows users to search for products like Bright Citrus Deodorant based on specific criteria such as scent and price.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="WEB SHOP" target="SEARCH ACTION">
      <data key="d4">8.0</data>
      <data key="d5">The search action is performed within the Web Shop to locate products that meet specific user requirements.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="WEB SHOP" target="CLICK ACTION">
      <data key="d4">1.0</data>
      <data key="d5">The click action is performed within the Web Shop to view more details about a selected product from the search results.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="TOKEN CONSUMPTION" target="SAMPLE COMPLEXITY">
      <data key="d4">1.0</data>
      <data key="d5">Token consumption and sample complexity are metrics used to evaluate the efficiency and performance of search algorithms like LATS, ReAct, and RAP.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="JORNELL QUIAMBAO&lt;|(&quot;ENTITY&quot;" target="PROGRAM SYNTHESIS">
      <data key="d4">1.0</data>
      <data key="d5">TECHNIQUE</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="PROGRAM SYNTHESIS" target="HUMANEVAL DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The HumanEval dataset is specifically designed to evaluate models on their ability to perform program synthesis from natural language descriptions.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="MARK CHEN" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Mark Chen is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="JERRY TWOREK" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Jerry Tworek is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="HEEWOO JUN" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Heewoo Jun is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="LUKASZ KAISER" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Lukasz Kaiser is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="MOHAMMAD BAVARIAN" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Mohammad Bavarian is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="MATTHIAS PLAPPERT" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Matthias Plappert is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="MAARTEN BOSMA" target="JASON WEI">
      <data key="d4">8.0</data>
      <data key="d5">Maarten Bosma and Jason Wei are co-authors on research related to prompting techniques for large language models.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="VINEET KOSARAJU" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Vineet Kosaraju is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="JACOB HILTON" target="BROWSER-ASSISTED QUESTION-ANSWERING">
      <data key="d4">1.0</data>
      <data key="d5">Jacob Hilton is a co-author of a paper discussing browser-assisted question-answering techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JACOB HILTON" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Jacob Hilton is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="REIICHIRO NAKANO" target="BROWSER-ASSISTED QUESTION-ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Reiichiro Nakano is a co-author of a paper discussing browser-assisted question-answering techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="REIICHIRO NAKANO" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Reiichiro Nakano is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="YILUN DU" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Yilun Du is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="YILUN DU">
      <data key="d4">6.0</data>
      <data key="d5">Yilun Du is involved in the development of an embodied multi-modal language model, which is related to the MineDojo project.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="MENGJIAO YANG">
      <data key="d4">6.0</data>
      <data key="d5">Mengjiao Yang collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="BO DAI">
      <data key="d4">6.0</data>
      <data key="d5">Bo Dai collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="HANJUN DAI">
      <data key="d4">6.0</data>
      <data key="d5">Hanjun Dai collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="OFIR NACHUM">
      <data key="d4">6.0</data>
      <data key="d5">Ofir Nachum collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="JOSHUA B. TENENBAUM">
      <data key="d4">6.0</data>
      <data key="d5">Joshua B. Tenenbaum collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="DALE SCHUURMANS">
      <data key="d4">6.0</data>
      <data key="d5">Dale Schuurmans collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="PIETER ABBEEL">
      <data key="d4">6.0</data>
      <data key="d5">Pieter Abbeel collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="MENGJIAO YANG" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Mengjiao Yang is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="BO DAI" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Bo Dai is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="HANJUN DAI" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Hanjun Dai is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="OFIR NACHUM" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Ofir Nachum is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="JOSHUA B. TENENBAUM" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Joshua B. Tenenbaum is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="DALE SCHUURMANS" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Dale Schuurmans is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="PIETER ABBEEL" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Pieter Abbeel is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="MINE DOJO" target="MINE RL">
      <data key="d4">7.0</data>
      <data key="d5">MineRL is a dataset used in the MineDojo project for training AI agents in complex environments.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="LINXI FAN" target="YECHENG JASON MA">
      <data key="d4">8.0</data>
      <data key="d5">Linxi Fan and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="GUANZHI WANG" target="YECHENG JASON MA">
      <data key="d4">8.0</data>
      <data key="d5">Guanzhi Wang and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="DE-AN HUANG" target="YECHENG JASON MA">
      <data key="d4">8.0</data>
      <data key="d5">De-An Huang and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="YUKE ZHU" target="YECHENG JASON MA">
      <data key="d4">8.0</data>
      <data key="d5">Yuke Zhu and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ANIMA ANANDKUMAR" target="YECHENG JASON MA">
      <data key="d4">8.0</data>
      <data key="d5">Yecheng Jason Ma and Anima Anandkumar co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="LUYU GAO" target="AMAN MAADAAN">
      <data key="d4">8.0</data>
      <data key="d5">Luyu Gao and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="NIKET TANDON">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Niket Tandon co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="PRAKHAR GUPTA">
      <data key="d4">8.0</data>
      <data key="d5">Prakhar Gupta and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="SKYLER HALLINAN">
      <data key="d4">8.0</data>
      <data key="d5">Skyler Hallinan and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="SARAH WIEGREFFE">
      <data key="d4">8.0</data>
      <data key="d5">Sarah Wiegreffe and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="URI ALON">
      <data key="d4">8.0</data>
      <data key="d5">Uri Alon and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="NOUHA DZIRI">
      <data key="d4">8.0</data>
      <data key="d5">Nouha Dziri and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="SHRIMAI PRABHUMOYE">
      <data key="d4">8.0</data>
      <data key="d5">Shrimai Prabhumoye and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="YIMING YANG">
      <data key="d4">8.0</data>
      <data key="d5">Yiming Yang and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="PENGFEI LIU" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Pengfei Liu co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XINYUN CHEN" target="SELF-DISCOVERY">
      <data key="d4">8.0</data>
      <data key="d5">Xinyun Chen is a co-author of a paper on self-discovery in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="PETER CLARK" target="PHI-3">
      <data key="d4">5.0</data>
      <data key="d5">The Phi-3 model is relevant to the research community that includes Peter Clark, who works on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="PETER CLARK" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Peter Clark is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="BOWEN ZHOU" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Bowen Zhou is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="YUJIA QIN" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Yujia Qin is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="YAXI LU" target="AGENTVERSE">
      <data key="d4">8.0</data>
      <data key="d5">Yaxi Lu is a researcher involved in the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="MAOSONG SUN" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Maosong Sun is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="TIMO SCHICK" target="TOOLFORMER">
      <data key="d4">8.0</data>
      <data key="d5">Timo Schick co-authored a paper on Toolformer, which focuses on how language models can learn to use tools.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="TOOLCHAIN*">
      <data key="d4">8.0</data>
      <data key="d5">Yuchen Zhuang co-authored the ToolChain* paper, which focuses on efficient action space navigation in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHAO ZHANG" target="TOOLCHAIN*">
      <data key="d4">8.0</data>
      <data key="d5">Chao Zhang is a co-author of the ToolChain* paper, contributing to advancements in action space navigation.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH" target="VALUE FUNCTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The Language Agent Tree Search utilizes the Value Function Prompt to analyze and improve decision-making in purchasing scenarios.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="WEBSHOP" target="AGENTS">
      <data key="d4">9.0</data>
      <data key="d5">WebShop provides an environment for agents to perform tasks related to e-commerce, such as searching for and purchasing products.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEBSHOP" target="PRODUCTS">
      <data key="d4">8.0</data>
      <data key="d5">Products are the items available for interaction within the WebShop environment, forming the basis of the e-commerce simulation.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEBSHOP" target="E-COMMERCE">
      <data key="d4">1.0</data>
      <data key="d5">WebShop simulates e-commerce activities, allowing agents to engage in buying and selling products online.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="TOOLCHAIN*" target="XIANG CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Xiang Chen is a co-author of the ToolChain* paper, contributing to action space navigation in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="TONG YU">
      <data key="d4">8.0</data>
      <data key="d5">Tong Yu is a co-author of the ToolChain* paper, focusing on navigation in large language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="SAAYAN MITRA">
      <data key="d4">8.0</data>
      <data key="d5">Saayan Mitra is a co-author of the ToolChain* paper, contributing to advancements in action space navigation.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="VICTOR BURSZTYN">
      <data key="d4">8.0</data>
      <data key="d5">Victor Bursztyn is a co-author of the ToolChain* paper, focusing on efficient navigation in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="RYAN A. ROSSI">
      <data key="d4">8.0</data>
      <data key="d5">Ryan A. Rossi is a co-author of the ToolChain* paper, contributing to action space navigation in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="SOMDEB SARKHEL">
      <data key="d4">8.0</data>
      <data key="d5">Somdeb Sarkhel is a co-author of the ToolChain* paper, focusing on large language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="XUEZHI WANG" target="JASON WEI">
      <data key="d4">8.0</data>
      <data key="d5">Xuezhi Wang and Jason Wei are co-authors on research related to reasoning in language models.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="ACTION SPACE" target="WIKIPEDIA">
      <data key="d4">7.0</data>
      <data key="d5">The action space of LATS includes actions that interact with the Wikipedia API to retrieve information about entities and strings.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="INTERACTIVE INFORMATION RETRIEVAL" target="SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Interactive information retrieval utilizes the search function to retrieve information from entity wiki pages or suggest similar entities.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="ENTITY WIKI PAGE" target="SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">The search function retrieves information from an entity wiki page if it exists.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="ENTITY WIKI PAGE" target="LOOKUP">
      <data key="d4">6.0</data>
      <data key="d5">The lookup function accesses the content of an entity wiki page based on a specified string.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="FINISH" target="FUNCTION">
      <data key="d4">5.0</data>
      <data key="d5">The finish function is part of the interactive information retrieval process, completing tasks with answers.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL DATASET" target="PASS@K">
      <data key="d4">7.0</data>
      <data key="d5">The pass@k metric is used to evaluate the performance of models on the HumanEval dataset by measuring the success rate of generated samples.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="AGENTS" target="AGENTIC SYSTEM">
      <data key="d4">9.0</data>
      <data key="d5">Agents are integral components of the agentic system, performing specific roles in the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTS" target="READING COMPREHENSION QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Agents generate reading comprehension questions based on text passages for educational purposes.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="AGENTS" target="TEXT MODIFICATION">
      <data key="d4">8.0</data>
      <data key="d5">Agents are utilized in the process of text modification to enhance written content.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HOTPOTQA PROMPTS" target="THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">HotPotQA prompts guide the reasoning process (Thought) during question-answering tasks, structuring the approach to finding answers.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="THOUGHT" target="ACTION">
      <data key="d4">9.0</data>
      <data key="d5">Thought informs the Action taken during a question-answering task, creating a logical flow in the problem-solving process.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ITEM-DETAIL" target="ITEM">
      <data key="d4">8.0</data>
      <data key="d5">Each item in the Web Shop has an associated Item-Detail that provides users with essential information for making purchasing decisions.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PLAINS" target="ELEVATION">
      <data key="d4">7.0</data>
      <data key="d5">Plains can rise in elevation, indicating a change in height from lower to higher altitudes, typically measured in feet.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="FIRST FOR WOMEN">
      <data key="d4">1.0</data>
      <data key="d5">Both Arthur&#8217;s Magazine and First for Women are publications, but they differ in their historical context and target audience.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="TIMOTHY SHAY ARTHUR">
      <data key="d4">8.0</data>
      <data key="d5">Timothy Shay Arthur served as the editor of Arthur&#8217;s Magazine, shaping its content and direction.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="EDGAR A. POE">
      <data key="d4">7.0</data>
      <data key="d5">Edgar A. Poe contributed literary works to Arthur&#8217;s Magazine, enhancing its reputation in the 19th century.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="J.H. INGRAHAM">
      <data key="d4">7.0</data>
      <data key="d5">J.H. Ingraham's works were published in Arthur&#8217;s Magazine, contributing to its literary diversity.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="SARAH JOSEPHA HALE">
      <data key="d4">7.0</data>
      <data key="d5">Sarah Josepha Hale's contributions to Arthur&#8217;s Magazine helped promote women's literature in the 19th century.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="THOMAS G. SPEAR">
      <data key="d4">1.0</data>
      <data key="d5">Thomas G. Spear's works were featured in Arthur&#8217;s Magazine, contributing to its literary content.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ADD FUNCTION" target="UNIT TEST RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">The unit test results evaluate the performance of the add function, indicating whether it meets the expected outcomes.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="REFLECTION ON IMPLEMENTATION">
      <data key="d4">7.0</data>
      <data key="d5">The reflection on the implementation analyzes the failures in the add function based on the unit test results, providing insights for improvement.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="IMPROVED IMPLEMENTATION">
      <data key="d4">9.0</data>
      <data key="d5">The improved implementation of the add function is a direct response to the issues identified in the previous implementation and its reflection.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="UNIT TEST">
      <data key="d4">8.0</data>
      <data key="d5">Unit tests are designed to validate the functionality of the add function, ensuring it performs as intended.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="UNIT TEST RESULTS" target="UNIT TEST">
      <data key="d4">8.0</data>
      <data key="d5">Unit tests are used to generate unit test results, which indicate the success or failure of the tests performed on a function.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS">
      <data key="d4">4.0</data>
      <data key="d5">Both products are examples of items that can be searched for and evaluated in an online shopping context.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="ENJOY LIFE FOODS">
      <data key="d4">1.0</data>
      <data key="d5">Enjoy Life Foods is a brand that may offer similar products to Bright Citrus Deodorant, focusing on allergen-free and natural ingredients.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="GINGER FRESH DEODORANT">
      <data key="d4">6.0</data>
      <data key="d5">Both Bright Citrus and Ginger Fresh Deodorants are products offered by Earth Mama, designed for sensitive skin and pregnancy.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="CALMING LAVENDER DEODORANT">
      <data key="d4">6.0</data>
      <data key="d5">Both Bright Citrus and Calming Lavender Deodorants are products offered by Earth Mama, designed for sensitive skin and pregnancy.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="TRAVEL SET (4-PACK)">
      <data key="d4">5.0</data>
      <data key="d5">The Travel Set (4-Pack) may include Bright Citrus Deodorant as one of its options, catering to users who prefer various scents.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="3 OUNCE (PACK OF 1)">
      <data key="d4">7.0</data>
      <data key="d5">The 3 Ounce (Pack of 1) refers to the size of the Bright Citrus Deodorant, indicating its individual packaging.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="3-OUNCE (2-PACK)">
      <data key="d4">7.0</data>
      <data key="d5">The 3-Ounce (2-Pack) refers to a packaging option for the Bright Citrus Deodorant, providing users with two units for convenience.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="NATURAL AND SAFE FOR SENSITIVE SKIN">
      <data key="d4">8.0</data>
      <data key="d5">The Bright Citrus Deodorant is marketed as natural and safe for sensitive skin, appealing to users with skin sensitivities.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="ORGANIC CALENDULA">
      <data key="d4">1.0</data>
      <data key="d5">Organic Calendula is an ingredient in the Bright Citrus Deodorant, contributing to its soothing properties for sensitive skin.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="SEARCH ACTION" target="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS">
      <data key="d4">6.0</data>
      <data key="d5">The Search Action is executed to find the Dairy Free and Apple Variety Pack of Chips based on user preferences.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="SEARCH ACTION" target="4 OUNCE PACK">
      <data key="d4">1.0</data>
      <data key="d5">The user is looking for products that fulfill the constraint of being in a 4 ounce pack, indicating a specific size preference.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="CORRECTNESS SCORE">
      <data key="d4">8.0</data>
      <data key="d5">The Value Function Prompt is used to determine the Correctness Score of a purchasing trajectory based on how well it meets the specified criteria.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS" target="LENTIL CHIPS VARIETY PACK">
      <data key="d4">7.0</data>
      <data key="d5">The dairy-free and apple variety pack of chips is similar to the lentil chips variety pack, both being dairy-free snack options.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS" target="VARIETY PACK">
      <data key="d4">7.0</data>
      <data key="d5">The dairy-free and apple variety pack of chips is a specific example of a variety pack that includes multiple flavors or types of chips.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS" target="BUDGET">
      <data key="d4">8.0</data>
      <data key="d5">The budget of $30 influences the decision to purchase the dairy-free and apple variety pack of chips.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE FOODS" target="SOFT BAKED OVALS">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Foods produces Soft Baked Ovals, which are part of their allergen-free product line.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE FOODS" target="SOFT BAKED CHEWY BARS">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Foods produces Soft Baked Chewy Bars, which are part of their allergen-free product line.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE FOODS" target="LENTIL CHIPS VARIETY PACK">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Foods produces the Lentil Chips Variety Pack, which is part of their allergen-free product line.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="CALMING LAVENDER DEODORANT" target="GINGER FRESH DEODORANT">
      <data key="d4">6.0</data>
      <data key="d5">Both Ginger Fresh and Calming Lavender Deodorants are products offered by Earth Mama, designed for sensitive skin and pregnancy.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="SOFT BAKED OVALS" target="PRICE">
      <data key="d4">6.0</data>
      <data key="d5">The price of Soft Baked Ovals is a key factor for consumers when considering a purchase.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SOFT BAKED CHEWY BARS" target="PRICE">
      <data key="d4">6.0</data>
      <data key="d5">The price of Soft Baked Chewy Bars is a key factor for consumers when considering a purchase.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LENTIL CHIPS VARIETY PACK" target="VARIETY PACK">
      <data key="d4">7.0</data>
      <data key="d5">The Lentil Chips Variety Pack is a specific example of a variety pack that includes multiple flavors of lentil chips.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LENTIL CHIPS VARIETY PACK" target="PRICE">
      <data key="d4">6.0</data>
      <data key="d5">The price of the Lentil Chips Variety Pack is a key factor for consumers when considering a purchase.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="LOUISVILLE VEGAN JERKY">
      <data key="d4">6.0</data>
      <data key="d5">Both products cater to dietary restrictions, with the gluten-free vegetarian smoked peppered bacon being a meat alternative similar to the offerings from Louisville Vegan Jerky.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="PRICE">
      <data key="d4">6.0</data>
      <data key="d5">The price of gluten-free vegetarian smoked peppered bacon is a key factor for consumers when considering a purchase.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="BUDGET">
      <data key="d4">1.0</data>
      <data key="d5">The budget of $40 influences the decision to purchase gluten-free vegetarian smoked peppered bacon.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="SMOKED BACON SEA SALT 3-PACK">
      <data key="d4">5.0</data>
      <data key="d5">Louisville Vegan Jerky and the Smoked Bacon Sea Salt 3-Pack both offer flavor profiles that appeal to consumers looking for savory snacks.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="SPICY HOT PEPPER SEA SALT 3-PACK">
      <data key="d4">1.0</data>
      <data key="d5">Louisville Vegan Jerky and the Spicy Hot Pepper Sea Salt 3-Pack both cater to consumers looking for spicy and flavorful snack options.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="PRICE">
      <data key="d4">6.0</data>
      <data key="d5">The price of Louisville Vegan Jerky is a key factor for consumers when considering a purchase.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="NON-GMO">
      <data key="d4">7.0</data>
      <data key="d5">Louisville Vegan Jerky is also labeled as Non-GMO, appealing to health-conscious consumers.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="GLUTEN-FREE">
      <data key="d4">8.0</data>
      <data key="d5">Louisville Vegan Jerky is gluten-free, catering to individuals with dietary restrictions.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="PEPPER FLAVORS">
      <data key="d4">6.0</data>
      <data key="d5">Louisville Vegan Jerky features flavors that may include pepper varieties, contributing to its overall flavor.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="BLACK PEPPER">
      <data key="d4">6.0</data>
      <data key="d5">Louisville Vegan Jerky may contain Black Pepper as a seasoning, enhancing its overall flavor.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="BUFFALO DILL">
      <data key="d4">8.0</data>
      <data key="d5">Buffalo Dill is one of the flavor variants of Louisville Vegan Jerky, contributing to its diverse taste offerings.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="PEPPERONI">
      <data key="d4">8.0</data>
      <data key="d5">Pepperoni is one of the flavor variants of Louisville Vegan Jerky, appealing to those who enjoy spicy flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="MAPLE BACON">
      <data key="d4">8.0</data>
      <data key="d5">Maple Bacon is a flavor variant of Louisville Vegan Jerky, combining sweet and savory elements.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="CAROLINA BBQ">
      <data key="d4">8.0</data>
      <data key="d5">Carolina BBQ is a flavor variant of Louisville Vegan Jerky, reflecting regional barbecue flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="NON-GMO" target="SPICY HOT PEPPER SEA SALT">
      <data key="d4">7.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt is labeled as Non-GMO, indicating it meets specific dietary standards.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT" target="GLUTEN-FREE">
      <data key="d4">8.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt is marketed as gluten-free, making it suitable for those with gluten sensitivities.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT" target="PEPPER FLAVORS">
      <data key="d4">6.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt includes various pepper flavors, enhancing its taste profile.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT" target="GHOST PEPPER">
      <data key="d4">7.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt includes Ghost Pepper as one of its flavor components, contributing to its spiciness.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT" target="JALAPENO">
      <data key="d4">6.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt may include Jalapeno as part of its pepper blend, enhancing its flavor profile.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT" target="HABANERO">
      <data key="d4">6.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt may include Habanero, adding to its heat and flavor complexity.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SHENGRAN HU" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">8.0</data>
      <data key="d5">Shengran Hu is a researcher contributing to the development of the Automated Design of Agentic Systems (ADAS) research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="JEFF CLUNE">
      <data key="d4">8.0</data>
      <data key="d5">Shengran Hu and Jeff Clune co-authored a paper on intelligent exploration using foundation models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="CONG LU" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">8.0</data>
      <data key="d5">Cong Lu is a researcher contributing to the development of the Automated Design of Agentic Systems (ADAS) research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONG LU" target="JEFF CLUNE">
      <data key="d4">8.0</data>
      <data key="d5">Cong Lu and Jeff Clune co-authored a paper on intelligent exploration using foundation models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="CONG LU" target="VARIBAD">
      <data key="d4">8.0</data>
      <data key="d5">Cong Lu is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JEFF CLUNE" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune is a researcher contributing to the development of the Automated Design of Agentic Systems (ADAS) research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="AI SCIENTIST">
      <data key="d4">7.0</data>
      <data key="d5">Jeff Clune is involved in research related to the AI Scientist concept, contributing to automated scientific discovery.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JEFF CLUNE" target="ZHICHAO LU">
      <data key="d4">8.0</data>
      <data key="d5">Zhichao Lu and Jeff Clune co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JEFF CLUNE" target="RUI WANG">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune and Rui Wang are co-authors on multiple papers related to open-ended reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JEFF CLUNE" target="KENNETH O. STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune and Kenneth O. Stanley are co-authors on multiple papers related to evolutionary algorithms and reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JEFF CLUNE" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune is a co-author of the OMNI research project focused on open-endedness in models of human notions of interestingness.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="FOUNDATION MODELS (FMS)">
      <data key="d4">15.0</data>
      <data key="d5">The Automated Design of Agentic Systems (ADAS) is a research area that emphasizes the integration of Foundation Models (FMs) as essential modules within the control flow of agentic systems. This approach highlights the role of Foundation Models in enhancing the functionality and efficiency of agentic systems, thereby facilitating the resolution of various tasks. The interplay between ADAS and FMs underscores a collaborative framework where Foundation Models serve as foundational components, driving innovation and effectiveness in the design and operation of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="META AGENT SEARCH">
      <data key="d4">24.0</data>
      <data key="d5">The Automated Design of Agentic Systems (ADAS) is a comprehensive framework that includes the Meta Agent Search algorithm, specifically developed to facilitate the automation of creating agentic systems. This algorithm not only embodies the core principles of ADAS but also serves as a practical tool for discovering and generating new agentic systems. Through its innovative approach, Meta Agent Search exemplifies the objectives of ADAS, highlighting the synergy between the two entities in advancing the field of automated system design.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="CHAIN-OF-THOUGHT PLANNING">
      <data key="d4">6.0</data>
      <data key="d5">Chain-of-thought planning is one of the effective building blocks proposed for agentic systems in the ADAS research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="ROCKT&#196;SCHEL (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Rockt&#228;schel (2024) provides insights relevant to the development of compound agentic systems in the context of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="ZAHARIA ET AL. (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Zaharia et al. (2024) provides insights relevant to the development of compound agentic systems in the context of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">6.0</data>
      <data key="d5">AI-Generating Algorithms are relevant to the ADAS research area as they demonstrate the potential of learned AI systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="NEURAL ARCHITECTURE SEARCH">
      <data key="d4">1.0</data>
      <data key="d5">Neural Architecture Search is a technique that can be applied within the ADAS research area to improve agentic system designs.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="AI SCIENTIST">
      <data key="d4">8.0</data>
      <data key="d5">The AI Scientist exemplifies the goals of ADAS by automating the development of machine learning algorithms.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="OMNI-EPIC">
      <data key="d4">7.0</data>
      <data key="d5">OMNI-EPIC showcases the potential of ADAS by automatically generating diverse learning environments for robotics.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="FERNANDO ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Fernando et al. (2024) explores existing methods in ADAS, focusing on prompt design limitations.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="YANG ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Yang et al. (2024) examines the constraints of current ADAS methods, particularly in designing prompts.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="SEARCH SPACE">
      <data key="d4">8.0</data>
      <data key="d5">The search space is a fundamental component of ADAS, defining the agentic systems that can be represented.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="EVALUATION FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">The evaluation function is used in ADAS to assess the performance of candidate agents based on defined objectives.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="CHASE (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Chase (2024) contributes to the foundational understanding of agentic systems within the context of ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="NG (2024)">
      <data key="d4">1.0</data>
      <data key="d5">Ng (2024) contributes to the foundational understanding of agentic systems within the context of ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Agentic systems are the focus of the research area ADAS, which aims to automate their design and optimization.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="OPTIMIZATION PROCESS">
      <data key="d4">8.0</data>
      <data key="d5">The optimization process is a key component in the development of ADAS algorithms to enhance agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="ITERATIVE PROCESSING">
      <data key="d4">7.0</data>
      <data key="d5">Foundation Models often utilize iterative processing to refine their outputs and improve task performance.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="EUREKA">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models are utilized in the Eureka method to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="LANGUAGE-TO-REWARD">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models enable the language-to-reward technique to create reward functions for reinforcement learning.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="OMNI-EPIC">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models are used in OMNI-EPIC to create robotics learning environments through programming.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="RAFAILOV ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Rafailov et al. (2024) discusses the application of Foundation Models in preference learning for FM alignment training.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="YU ET AL. (2023)">
      <data key="d4">6.0</data>
      <data key="d5">Yu et al. (2023) provides insights into how Foundation Models can be used to create reward functions for reinforcement learning.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="FALDOR ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Faldor et al. (2024) discusses the role of Foundation Models in creating robotics learning environments through OMNI-EPIC.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="META AGENT SEARCH" target="AGENT ARCHIVE">
      <data key="d4">7.0</data>
      <data key="d5">The agent archive is utilized by the Meta Agent Search algorithm to inform the programming of new agents.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-STEP PEER REVIEW AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Multi-step Peer Review Agent is an example of an agent discovered through the Meta Agent Search algorithm.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VERIFIED MULTIMODAL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Verified Multimodal Agent is an example of an agent discovered through the Meta Agent Search algorithm.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DIVIDE AND CONQUER AGENT">
      <data key="d4">1.0</data>
      <data key="d5">The Divide and Conquer Agent is an example of an agent discovered through the Meta Agent Search algorithm.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXAMPLE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is responsible for creating new example agents through its iterative design process.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BOYER &amp; MOORE (1983)">
      <data key="d4">5.0</data>
      <data key="d5">Boyer &amp; Moore (1983) discusses Turing completeness, relevant to the capabilities of the Meta Agent Search algorithm.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LADHA (2024)">
      <data key="d4">1.0</data>
      <data key="d5">Ladha (2024) provides insights into Turing completeness, which is significant for understanding the Meta Agent Search algorithm's potential.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FOUNDATIONAL MODELS (FMS)">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search utilizes foundational models (FMs) as meta agents to create new agents based on previous discoveries.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is designed to define and search for agentic systems, programming them iteratively.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARCHIVE">
      <data key="d4">7.0</data>
      <data key="d5">The archive is used in Meta Agent Search to store previously discovered agents and their evaluation metrics, informing future proposals.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="PROMPTING TECHNIQUES">
      <data key="d4">7.0</data>
      <data key="d5">Prompting techniques are employed in Meta Agent Search to guide the meta agent in generating new agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC LOGIC PUZZLE TASK">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search is evaluated using the ARC logic puzzle task to assess the performance of the generated agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DROP">
      <data key="d4">13.0</data>
      <data key="d5">META AGENT SEARCH utilizes the DROP dataset as a benchmark to assess the reading comprehension capabilities of the agents it discovers. DROP serves as a critical tool in evaluating the performance of these agents in various reading comprehension tasks, ensuring that the agents developed by META AGENT SEARCH meet the necessary standards for understanding and processing textual information effectively.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MGSM">
      <data key="d4">21.0</data>
      <data key="d5">META AGENT SEARCH and MGSM are interconnected entities within the realm of evaluating artificial intelligence agents, particularly in mathematical tasks. MGSM serves as a benchmark specifically designed to assess the performance and math capabilities of agents identified through the Meta Agent Search process. The effectiveness of these agents in handling various math tasks is rigorously evaluated using the MGSM dataset, highlighting its critical role in measuring their performance in this domain. Overall, MGSM provides a structured framework for understanding and enhancing the mathematical proficiency of agents developed through Meta Agent Search.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FUNSEARCH">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search references FunSearch as a framework for defining new agents based on tasks.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ITERATIONS">
      <data key="d4">14.0</data>
      <data key="d5">The **META AGENT SEARCH** process heavily relies on **ITERATIONS**, which are essential for the continuous enhancement of agent proposals. These iterations represent the cycles of evaluation that agents experience throughout the Meta Agent Search process, significantly influencing their performance outcomes. By facilitating ongoing assessments and refinements, iterations play a crucial role in optimizing the effectiveness of agents within this framework.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VALIDATION DATA">
      <data key="d4">1.0</data>
      <data key="d5">Validation data is utilized in the Meta Agent Search to assess the effectiveness of newly generated agents in the target domain.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC CHALLENGE">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search is applied to the ARC Challenge to discover novel agentic systems that outperform existing agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SELF-CONSISTENCY WITH COT (COT-SC)">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search compares its discovered agents against Self-Consistency with COT to assess improvements in accuracy.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LLM DEBATE">
      <data key="d4">14.0</data>
      <data key="d5">The **META AGENT SEARCH** utilizes **LLM DEBATE** as a key technique to improve the reasoning capabilities of agents it discovers. By evaluating agents that incorporate LLM Debate, Meta Agent Search aims to leverage diverse perspectives, ultimately enhancing the quality of answers provided by these agents. This integration highlights the importance of collaborative reasoning in artificial intelligence, showcasing how different viewpoints can contribute to more effective problem-solving and decision-making processes within the network of agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="QUALITY-DIVERSITY">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search incorporates Quality-Diversity as a pivotal method for exploring a wide range of solutions in the discovery of agents. This approach emphasizes the generation of diverse and high-quality agents tailored for various tasks, thereby enhancing the effectiveness and adaptability of the search process. Quality-Diversity is not only a technique utilized within Meta Agent Search but is also assessed for its ability to produce agents that meet both diversity and quality criteria, ensuring that the outcomes are robust and versatile.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXPERTS">
      <data key="d4">1.0</data>
      <data key="d5">Experts provide structured feedback to the agents discovered through Meta Agent Search, evaluating their performance on various traits.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ADAS">
      <data key="d4">22.0</data>
      <data key="d5">META AGENT SEARCH and ADAS are interconnected entities within the realm of automated agent discovery and programming. ADAS proposes the utilization of Meta Agent Search to facilitate the automatic discovery of new agents through iterative programming methods. This technique is instrumental in ADAS, as it effectively programs new agents by leveraging existing algorithms. Furthermore, Meta Agent Search exemplifies the capabilities of ADAS by identifying agents that surpass the performance of traditional systems, showcasing innovative design patterns that enhance overall efficiency and effectiveness in agent development.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FEEDBACK MECHANISM">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search utilizes a sophisticated feedback mechanism to refine agent performance iteratively.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STEP-BACK ABSTRACTION">
      <data key="d4">6.0</data>
      <data key="d5">Step-back Abstraction is one of the baseline techniques compared against the performance of agents discovered by Meta Agent Search.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ROLE ASSIGNMENT">
      <data key="d4">6.0</data>
      <data key="d5">Role Assignment is another baseline technique used for comparison with agents discovered by Meta Agent Search.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MMLU">
      <data key="d4">7.0</data>
      <data key="d5">MMLU is a benchmark used to evaluate the multi-task problem-solving capabilities of agents discovered by Meta Agent Search.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPQA">
      <data key="d4">7.0</data>
      <data key="d5">GPQA is a benchmark used to evaluate the capability of agents in solving hard science questions in the context of Meta Agent Search.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MEYERSON ET AL. (2023)">
      <data key="d4">1.0</data>
      <data key="d5">Meyerson et al. (2023) provides insights relevant to the development and performance of the feedback mechanisms in Meta Agent Search.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is compared against state-of-the-art hand-designed agents to demonstrate its superior performance across various domains.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="AGENT NAME">
      <data key="d4">7.0</data>
      <data key="d5">Agent Name is used to identify and evaluate the performance of agents discovered through the Meta Agent Search process.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HOLD-OUT TEST SETS">
      <data key="d4">1.0</data>
      <data key="d5">Hold-out test sets are utilized in the Meta Agent Search to ensure unbiased evaluation of agent performance after training.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FOUNDATION MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search discovers agents that can be transferred across different foundation models, demonstrating their generalizability.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CLAUDE-HAIKU">
      <data key="d4">7.0</data>
      <data key="d5">Claude-Haiku is used to evaluate the performance of agents discovered by Meta Agent Search, contributing to the assessment of their effectiveness.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CLAUDE-SONNET">
      <data key="d4">7.0</data>
      <data key="d5">Claude-Sonnet is evaluated for its performance with agents discovered by Meta Agent Search, highlighting the effectiveness of these agents.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC">
      <data key="d4">16.0</data>
      <data key="d5">META AGENT SEARCH and ARC are interconnected entities within the realm of Artificial Intelligence evaluation. ARC serves as a benchmark designed to assess the accuracy of agents identified through the Meta Agent Search initiative. This benchmark specifically measures the performance of these agents in reading comprehension tasks, providing a critical metric for evaluating their effectiveness. In turn, Meta Agent Search is focused on identifying agents that excel on the ARC benchmark, thereby facilitating advancements in AI evaluation methodologies. Together, these entities contribute significantly to the development and assessment of AI capabilities, particularly in understanding and processing natural language.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CHAIN-OF-THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought is one of the techniques evaluated for its effectiveness in the context of Meta Agent Search, contributing to the discovery of effective agents.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="COT-SC">
      <data key="d4">7.0</data>
      <data key="d5">COT-SC is another technique assessed within the framework of Meta Agent Search, aimed at improving agent performance.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM8K">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search improves accuracy on the GSM8K dataset by discovering effective agents.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM-HARD">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search improves accuracy on the GSM-HARD dataset by discovering effective agents.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SVAMP">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search improves performance on the SVAMP dataset by discovering effective agents.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ASDIV">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search improves performance on the ASDiv dataset by discovering effective agents.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d4">8.0</data>
      <data key="d5">Dynamic Role-Playing Architecture is a top-performing agent discovered through Meta Agent Search.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d4">8.0</data>
      <data key="d5">Structured Multimodal Feedback Loop is a top-performing agent discovered through Meta Agent Search.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d4">1.0</data>
      <data key="d5">Interactive Multimodal Feedback Loop is a top-performing agent discovered through Meta Agent Search.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="DIVIDE AND CONQUER AGENT">
      <data key="d4">5.0</data>
      <data key="d5">Both agents are examples of discovered agents that utilize structured methodologies for problem-solving.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="CRITIC MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Critic Module is employed in the Multi-Step Peer Review Agent to assess and provide feedback on answers.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="TASK INFO">
      <data key="d4">6.0</data>
      <data key="d5">Task Info is the input provided to the Multi-Step Peer Review Agent for processing and generating answers.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="DIVIDE AND CONQUER AGENT">
      <data key="d4">1.0</data>
      <data key="d5">The Verified Multimodal Agent and Divide and Conquer Agent are both discovered agents focusing on different domains of problem-solving.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="HOG" target="DALAL &amp; TRIGGS (2005)">
      <data key="d4">6.0</data>
      <data key="d5">Dalal &amp; Triggs (2005) introduced the HOG feature, which is a significant example of hand-designed features in computer vision.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HOG" target="CNNS">
      <data key="d4">7.0</data>
      <data key="d5">HOG features have been surpassed by learned features from CNNs in the field of computer vision.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CNNS" target="NEURAL ARCHITECTURE SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">CNNs are often optimized through Neural Architecture Search methods to achieve better performance.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="HUTTER ET AL. (2019)" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">6.0</data>
      <data key="d5">Hutter et al. (2019) discusses AutoML methods that highlight the effectiveness of AI-Generating Algorithms.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HUTTER ET AL. (2019)" target="AUTOML METHODS">
      <data key="d4">6.0</data>
      <data key="d5">Hutter et al. (2019) provides foundational insights into the development and effectiveness of AutoML methods.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ELSEN ET AL. (2019)">
      <data key="d4">6.0</data>
      <data key="d5">Elsken et al. (2019) provides insights into the application of Neural Architecture Search in optimizing CNN models.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="SHEN ET AL. (2023)">
      <data key="d4">6.0</data>
      <data key="d5">Shen et al. (2023) contributes to the understanding of Neural Architecture Search techniques in CNN development.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="META-LEARNING ARCHITECTURES">
      <data key="d4">8.0</data>
      <data key="d5">Neural Architecture Search is a specific application of meta-learning architectures aimed at optimizing neural networks.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Neural Architecture Search provides insights that can enhance the design and understanding of agentic systems in ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AUTOML METHODS" target="AI-GENERATING ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">AI-GAs are a subset of AutoML methods that focus on generating AI systems automatically.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="CLUNE (2019)">
      <data key="d4">7.0</data>
      <data key="d5">Clune (2019) discusses the advantages of AI-Generating Algorithms, contributing to the understanding of their superiority over traditional methods.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">ADAS aims to invent novel building blocks that can be developed using AI-Generating Algorithms for automated systems.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="AUTOML">
      <data key="d4">8.0</data>
      <data key="d5">AI-Generating Algorithms and AutoML both focus on automating components in AI systems to enhance efficiency and performance.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="META-LEARNING ARCHITECTURES">
      <data key="d4">8.0</data>
      <data key="d5">AI-Generating Algorithms include meta-learning architectures as a key component for improving AI system design.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="META-LEARNING ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">AI-Generating Algorithms utilize meta-learning algorithms to enhance the learning capabilities of AI systems.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="LEARNING ENVIRONMENTS">
      <data key="d4">7.0</data>
      <data key="d5">AI-Generating Algorithms aim to create effective learning environments for training AI models.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LEARNED LOSS FUNCTIONS" target="DPO">
      <data key="d4">6.0</data>
      <data key="d5">Learned loss functions are compared against DPO to demonstrate their superior performance in training AI models.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="LEARNED LOSS FUNCTIONS" target="LU ET AL. (2024A)">
      <data key="d4">7.0</data>
      <data key="d5">Lu et al. (2024a) compares learned loss functions with traditional methods, highlighting their effectiveness in LLM alignment.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="DPO" target="RAFALIOV ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Rafailov et al. (2024) discusses the DPO loss function, providing context for its use in AI training.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AI SCIENTIST" target="LU ET AL. (2024B)">
      <data key="d4">7.0</data>
      <data key="d5">Lu et al. (2024b) presents the AI Scientist, illustrating its role in automated research and algorithm development.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="OMNI-EPIC" target="FALDOR ET AL. (2024)">
      <data key="d4">7.0</data>
      <data key="d5">Faldor et al. (2024) discusses the OMNI-EPIC framework, showcasing its capabilities in generating robotics learning environments.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="OMNI-EPIC" target="FOUNDATION MODELS">
      <data key="d4">8.0</data>
      <data key="d5">OMNI-EPIC utilizes Foundation Models to automate the creation of robotics learning environments.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="F1 SCORES" target="DROP">
      <data key="d4">7.0</data>
      <data key="d5">F1 scores are used to evaluate the performance of agents on the DROP dataset for reading comprehension tasks.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="F1 SCORES" target="MGSM">
      <data key="d4">7.0</data>
      <data key="d5">F1 scores are also used to assess the performance of agents on the MGSM dataset for math tasks.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="F1 SCORES" target="GSM8K">
      <data key="d4">7.0</data>
      <data key="d5">F1 scores are utilized to measure the effectiveness of agents on the GSM8K dataset for math tasks.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="F1 SCORES" target="GSM-HARD">
      <data key="d4">1.0</data>
      <data key="d5">F1 scores are applied to evaluate agents on the GSM-HARD dataset, which presents challenging math problems.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="DROP" target="INITIAL_SOLUTIONS">
      <data key="d4">6.0</data>
      <data key="d5">DROP is a dataset that influences the style of questions used in evaluating initial solutions, particularly in reading comprehension.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="DROP" target="GTP-4O-2024-05-13">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent uses GPT-4O-2024-05-13 to perform well on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="GPT-3.5-TURBO-0125">
      <data key="d4">6.0</data>
      <data key="d5">Discovered agents and baselines are evaluated using GPT-3.5-Turbo-0125 for the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="SELF-CONSISTENCY WITH COT (COT-SC)">
      <data key="d4">5.0</data>
      <data key="d5">Self-Consistency with Chain-of-Thought (COT-SC) is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="LLM-DEBATE">
      <data key="d4">5.0</data>
      <data key="d5">LLM-Debate is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="QUALITY-DIVERSITY">
      <data key="d4">5.0</data>
      <data key="d5">Quality-Diversity is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="STEP-BACK ABSTRACTION">
      <data key="d4">5.0</data>
      <data key="d5">Step-back Abstraction is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="ROLE ASSIGNMENT">
      <data key="d4">1.0</data>
      <data key="d5">Role Assignment is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="MMLU">
      <data key="d4">6.0</data>
      <data key="d5">DROP's focus on reading comprehension contributes to the overall multitask understanding evaluated by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MGSM" target="GSM8K">
      <data key="d4">6.0</data>
      <data key="d5">GSM8K is one of the datasets used in the MGSM benchmark to evaluate the performance of agents in solving math problems.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="MGSM" target="GSM-HARD">
      <data key="d4">6.0</data>
      <data key="d5">GSM-HARD is another dataset used in the MGSM benchmark for evaluating agent performance in challenging math tasks.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="MGSM" target="SVAMP">
      <data key="d4">6.0</data>
      <data key="d5">SVAMP is included in the MGSM benchmark to assess the performance of agents in solving various math problems.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="MGSM" target="ASDIV">
      <data key="d4">1.0</data>
      <data key="d5">ASDIV is part of the MGSM benchmark used to evaluate the performance of agents in diverse math tasks.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="MGSM" target="GTP-4O-2024-05-13">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent uses GPT-4O-2024-05-13 to perform well on the MGSM benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MGSM" target="GPT-3.5-TURBO-0125">
      <data key="d4">6.0</data>
      <data key="d5">Discovered agents and baselines are evaluated using GPT-3.5-Turbo-0125 for the MGSM benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GSM8K" target="GSM-HARD">
      <data key="d4">1.0</data>
      <data key="d5">Both GSM8K and GSM-HARD are datasets used to evaluate the performance of agents in math tasks, providing benchmarks for comparison.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="GSM8K" target="ORCA-3">
      <data key="d4">18.0</data>
      <data key="d5">GSM8K and ORCA-3 are interconnected entities in the realm of artificial intelligence, particularly focusing on mathematical problem-solving. GSM8K serves as a benchmark specifically designed to evaluate the performance of models like ORCA-3 on multi-step arithmetic tasks. The descriptions indicate that ORCA-3 exhibits a notable enhancement in its mathematical reasoning capabilities when assessed against the GSM8K benchmark. This improvement highlights ORCA-3's effectiveness in tackling complex math problems, showcasing its advanced problem-solving skills in the context of the GSM8K evaluations.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GSM8K" target="MMLU">
      <data key="d4">5.0</data>
      <data key="d5">GSM8K's math problems require reasoning skills that are relevant to the multitask understanding measured by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="FERNANDO ET AL. (2024)" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Fernando et al. (2024) contributes to ADAS by discussing PromptBreeder for improving prompt engineering.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="YANG ET AL. (2024)" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Yang et al. (2024) contributes to the ADAS framework by discussing OPRO for automating prompt engineering.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SEARCH SPACE" target="PROMPTBREEDER">
      <data key="d4">6.0</data>
      <data key="d5">PromptBreeder operates within a specific search space by mutating text prompts while maintaining other components.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="ACCURACY">
      <data key="d4">8.0</data>
      <data key="d5">Accuracy is one of the key metrics used in the evaluation function to assess the performance of agents in ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="COST">
      <data key="d4">8.0</data>
      <data key="d5">Cost is another important metric considered in the evaluation function for optimizing agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="LATENCY">
      <data key="d4">7.0</data>
      <data key="d5">Latency is a metric that can be included in the evaluation function to assess the efficiency of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="SAFETY">
      <data key="d4">1.0</data>
      <data key="d5">Safety is a crucial metric in the evaluation function to ensure that agentic systems operate without causing harm.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="PROMPTBREEDER" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">ADAS includes the use of PromptBreeder to improve prompt engineering for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ACCURACY" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Accuracy is another metric used to assess the performance of state-of-the-art hand-designed agents in various tasks.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="PROMPTING TECHNIQUES">
      <data key="d4">8.0</data>
      <data key="d5">Agentic Systems utilize Prompting Techniques to enhance their problem-solving capabilities.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="EXTERNAL MEMORY">
      <data key="d4">8.0</data>
      <data key="d5">Agentic Systems use External Memory to store and retrieve information, enhancing their capabilities.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="FM MODULES">
      <data key="d4">8.0</data>
      <data key="d5">FM Modules are integral to Agentic Systems, allowing for role assignment and collaboration among different components.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="ADAS">
      <data key="d4">1.0</data>
      <data key="d5">ADAS aims to develop new building blocks and design powerful Agentic Systems in an automated manner.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="FUNSEARCH" target="FOUNDATION MODELS">
      <data key="d4">8.0</data>
      <data key="d5">FunSearch employs Foundation Models to discover better optimization algorithms through automated coding.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LLM DEBATE" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">LLM Debate is a baseline technique evaluated against state-of-the-art hand-designed agents to measure enhancements in reasoning.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="LLM DEBATE" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">LLM Debate is a technique used by manually designed agents to improve their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="LLM DEBATE" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">LLM Debate is a manually designed agent that can be optimized through the principles of ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">Quality-Diversity is a baseline technique that is compared with state-of-the-art hand-designed agents to evaluate its impact on solution quality.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Quality-Diversity is a technique used by manually designed agents to improve their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Quality-Diversity is a manually designed agent that can benefit from the advancements proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="HUMAN-LIKE CRITIC" target="REFINEMENT">
      <data key="d4">8.0</data>
      <data key="d5">Human-like critics provide feedback during the refinement process to enhance the agents' performance.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="EFFICIENCY EXPERT" target="REFINEMENT">
      <data key="d4">7.0</data>
      <data key="d5">Efficiency experts contribute to the refinement process by evaluating the speed and effectiveness of agents' answers.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="READABILITY EXPERT" target="REFINEMENT">
      <data key="d4">7.0</data>
      <data key="d5">Readability experts play a role in the refinement process by assessing the clarity of the agents' answers.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="SIMPLICITY EXPERT" target="REFINEMENT">
      <data key="d4">7.0</data>
      <data key="d5">Simplicity experts assist in the refinement process by evaluating how straightforward the agents' answers are.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="TOP-3 ANSWERS" target="FINAL ANSWER">
      <data key="d4">1.0</data>
      <data key="d5">The final answer is derived from the evaluation of the top-3 answers generated by the agents during the refinement process.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="FINAL ANSWER" target="STUDENT RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">The student response contains the final answer extracted from the student's answer to the question.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="FINAL ANSWER" target="ALPHABET ID">
      <data key="d4">8.0</data>
      <data key="d5">The final answer is represented by the alphabet ID that corresponds to the option chosen by the student.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="ADAS" target="CHAIN-OF-THOUGHT">
      <data key="d4">6.0</data>
      <data key="d5">Chain-of-Thought is an example of a manually designed agent that can be improved through the principles of ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="COT-SC">
      <data key="d4">6.0</data>
      <data key="d5">COT-SC is an example of a manually designed agent that can benefit from the innovations proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="STEP-BACK ABSTRACTION">
      <data key="d4">6.0</data>
      <data key="d5">Step-back Abstraction is a manually designed agent that can be improved by the innovations proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="ROLE ASSIGNMENT">
      <data key="d4">6.0</data>
      <data key="d5">Role Assignment is a manually designed agent that can be enhanced through the methodologies proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d4">6.0</data>
      <data key="d5">Dynamic Role-Playing Architecture is an agent that can be optimized through the principles of ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d4">6.0</data>
      <data key="d5">Structured Multimodal Feedback Loop is an agent that can be improved by the innovations proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d4">1.0</data>
      <data key="d5">Interactive Multimodal Feedback Loop is an agent that can benefit from the advancements proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="OPRO">
      <data key="d4">7.0</data>
      <data key="d5">ADAS involves the use of OPRO to automate prompt engineering for agents, enhancing their reasoning capabilities.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="SELF-DISCOVER">
      <data key="d4">7.0</data>
      <data key="d5">ADAS incorporates Self-Discover to automate the creation of effective prompts for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="EVOAGENT">
      <data key="d4">7.0</data>
      <data key="d5">EvoAgent is part of the ADAS framework, optimizing role definitions in prompts for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENTVERSE">
      <data key="d4">7.0</data>
      <data key="d5">AgentVerse contributes to ADAS by optimizing agent roles and definitions to improve performance.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="DYLAN">
      <data key="d4">7.0</data>
      <data key="d5">DyLAN is utilized in ADAS to score response quality in agent networks and prune connections.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="DSPY">
      <data key="d4">7.0</data>
      <data key="d5">DSPy is part of ADAS, generating and optimizing nodes in agentic systems.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="GPT-SWARM">
      <data key="d4">7.0</data>
      <data key="d5">GPT-Swarm represents agentic systems in a graph format, optimizing connections as part of ADAS.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENTOPTIMIZER">
      <data key="d4">7.0</data>
      <data key="d5">AgentOptimizer is a component of ADAS that learns the tools used in agentic systems.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENT SYMBOLIC LEARNING">
      <data key="d4">7.0</data>
      <data key="d5">Agent Symbolic Learning is related to ADAS as it learns prompts, tools, and control flow in agentic systems.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="SAFETY CONSIDERATIONS">
      <data key="d4">6.0</data>
      <data key="d5">Safety considerations are crucial in the context of ADAS, especially when executing untrusted model-generated code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="ARTIFICIAL GENERAL INTELLIGENCE (AGI)">
      <data key="d4">1.0</data>
      <data key="d5">ADAS is a new area of research that could contribute to the development of Artificial General Intelligence (AGI).</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="ZHOU ET AL. (2024)">
      <data key="d4">7.0</data>
      <data key="d5">Zhou et al. (2024) contributes to ADAS by discussing Self-Discover for automating prompt creation.Zhou et al. (2024) contributes to ADAS by discussing Agent Symbolic Learning and its learning of prompts, tools, and control flow.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="KHATTAB ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Khattab et al. (2024) provides insights relevant to ADAS through the study of DSPy and its optimization of nodes.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="ZHUGE ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Zhuge et al. (2024) contributes to ADAS by discussing GPT-Swarm and its optimization of connections in agentic systems.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="FOUNDATIONAL MODELS">
      <data key="d4">8.0</data>
      <data key="d5">ADAS utilizes foundational models to create powerful algorithms for developing intelligent agents without the need for expensive hardware.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="CONSTITUTIONAL AI">
      <data key="d4">6.0</data>
      <data key="d5">ADAS aims to incorporate Constitutional AI principles to ensure the safe and ethical operation of the agents it develops.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="MULTI-OBJECTIVE SEARCH ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">Integrating multi-objective search algorithms into ADAS can improve its ability to optimize for various performance criteria simultaneously.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="EVALUATION FUNCTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Evaluation functions are critical for assessing the performance of agents created through ADAS, guiding improvements and refinements.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="HUMAN ORGANIZATIONS">
      <data key="d4">5.0</data>
      <data key="d5">Research in ADAS provides insights into how complexity arises from human organizations, influencing the design of agentic systems.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="COMPLEX DOMAINS">
      <data key="d4">1.0</data>
      <data key="d5">Exploring complex domains can enhance the capabilities of agents developed through ADAS, allowing them to perform in more intricate environments.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="YUNTAO BAI ET AL. (2022)">
      <data key="d4">5.0</data>
      <data key="d5">Yuntao Bai et al. (2022) provides insights relevant to the development of agentic systems in the context of AI feedback.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="YOSHUA BENGIO ET AL. (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Yoshua Bengio et al. (2024) discusses risks that may inform the design of agentic systems in ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="N BOSTROM">
      <data key="d4">5.0</data>
      <data key="d5">N Bostrom's analysis of existential risks can provide a framework for understanding the implications of agentic systems in society.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="TRACEY CALDWELL">
      <data key="d4">5.0</data>
      <data key="d5">Tracey Caldwell's work on ethical hacking may inform the ethical considerations in the design of agentic systems.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="BANGHAO CHEN ET AL. (2023)">
      <data key="d4">6.0</data>
      <data key="d5">Banghao Chen et al. (2023) provides insights into prompt engineering that can enhance the design of agentic systems in ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="MARK CHEN ET AL. (2021)">
      <data key="d4">5.0</data>
      <data key="d5">Mark Chen et al. (2021) offers evaluations that may inform the development of agentic systems in ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="WEIZE CHEN ET AL. (2023)">
      <data key="d4">1.0</data>
      <data key="d5">Weize Chen et al. (2023) discusses multi-agent collaboration, relevant to the design of agentic systems in ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="STEP-BACK ABSTRACTION" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Step-back Abstraction is a technique used by manually designed agents to enhance their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Role Assignment is a technique used by manually designed agents to enable collaboration among modules.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="LLM-DEBATE">
      <data key="d4">8.0</data>
      <data key="d5">Role Assignment is a key component of the LLM-Debate method, where specific roles are assigned to debate modules.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="FM QUERY">
      <data key="d4">7.0</data>
      <data key="d5">FM Query is utilized in the Role Assignment technique to select roles for agents based on predefined criteria.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MMLU" target="GTP-4O-2024-05-13">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent uses GPT-4O-2024-05-13 to perform well on the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="GPT-3.5-TURBO-0125">
      <data key="d4">6.0</data>
      <data key="d5">Discovered agents and baselines are evaluated using GPT-3.5-Turbo-0125 for the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="ORCA-3">
      <data key="d4">23.0</data>
      <data key="d5">MMLU and ORCA-3 are interconnected entities in the realm of performance evaluation in artificial intelligence. MMLU serves as a benchmark utilized to assess ORCA-3's capabilities across various academic subjects, particularly in mathematics, where it showcases its proficiency in complex problem-solving. Furthermore, ORCA-3 has demonstrated improved performance on the MMLU benchmark compared to Mistral-7B-Instruct, indicating its enhanced abilities across a range of tasks. Overall, the relationship between MMLU and ORCA-3 highlights the latter's advancements in performance evaluation, particularly in academic contexts.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MMLU" target="EQBENCH">
      <data key="d4">7.0</data>
      <data key="d5">EQBench shows a strong correlation with MMLU, indicating that emotional intelligence is related to multitask understanding in language models.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="AGIEVAL">
      <data key="d4">6.0</data>
      <data key="d5">AGIEval assesses cognitive abilities that may overlap with the multitask understanding measured by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="ARC">
      <data key="d4">6.0</data>
      <data key="d5">ARC evaluates reasoning abilities that are essential for multitask understanding, as measured by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="BBH">
      <data key="d4">6.0</data>
      <data key="d5">BBH requires complex reasoning, which is a component of multitask understanding evaluated by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="GPQA">
      <data key="d4">6.0</data>
      <data key="d5">GPQA's challenging questions test specialized knowledge, which is part of the multitask understanding assessed by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="FOFO">
      <data key="d4">5.0</data>
      <data key="d5">FoFo's evaluation of format following may relate to the structured understanding required in MMLU assessments.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="IFEVAL">
      <data key="d4">5.0</data>
      <data key="d5">IFEval's focus on instruction-following is relevant to the comprehension skills assessed by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="MT-BENCH">
      <data key="d4">5.0</data>
      <data key="d5">MT-Bench assesses conversational competence, which may relate to the understanding required in MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="ALPACA EVAL">
      <data key="d4">5.0</data>
      <data key="d5">AlpacaEval's focus on instruction-following tasks is relevant to the multitask understanding evaluated by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="INFOBENCH">
      <data key="d4">1.0</data>
      <data key="d5">InFoBench's evaluation of instruction-following capabilities contributes to the overall understanding assessed by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPQA" target="DAVID REIN">
      <data key="d4">8.0</data>
      <data key="d5">David Rein co-authored a paper on GPQA, contributing to the development of a benchmark for question and answer systems.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="GPQA" target="INITIAL_SOLUTIONS">
      <data key="d4">6.0</data>
      <data key="d5">GPQA is a dataset used to generate and evaluate initial solutions in the context of reasoning and problem-solving.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPQA" target="GTP-4O-2024-05-13">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent uses GPT-4O-2024-05-13 to perform well on the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="GPT-3.5-TURBO-0125">
      <data key="d4">6.0</data>
      <data key="d5">Discovered agents and baselines are evaluated using GPT-3.5-Turbo-0125 for the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="KHIZBULLIN">
      <data key="d4">6.0</data>
      <data key="d5">GPQA is a benchmark that may involve Khizbullin in testing language models' question-and-answer capabilities.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="F1 SCORE" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">F1 Score is used to evaluate the performance of state-of-the-art hand-designed agents in reading comprehension and math tasks.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">Chain-of-Thought is a baseline technique that is compared against state-of-the-art hand-designed agents to evaluate reasoning improvements.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought is a reasoning method used by manually designed agents to enhance their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="COT-SC" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">COT-SC is a baseline technique that is evaluated alongside state-of-the-art hand-designed agents for performance comparison.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="COT-SC" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">COT-SC is a technique used by manually designed agents to improve their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="COT-SC" target="FINAL DECISION MODULE">
      <data key="d4">1.0</data>
      <data key="d5">The Final Decision Module is used in the COT-SC technique to consolidate multiple sampled answers into a final response.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="FOUNDATION MODELS" target="DISCOPOP">
      <data key="d4">8.0</data>
      <data key="d5">DiscoPOP uses Foundation Models to program loss functions for preference learning in AI training.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS" target="EUREKA">
      <data key="d4">8.0</data>
      <data key="d5">Eureka enables Foundation Models to write reward functions for reinforcement learning applications.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS" target="LANGUAGE-TO-REWARD">
      <data key="d4">1.0</data>
      <data key="d5">Language-to-reward allows Foundation Models to create reward functions for robotics reinforcement learning.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ARC" target="GPT-3.5-TURBO-0125">
      <data key="d4">6.0</data>
      <data key="d5">ARC utilizes the GPT-3.5-turbo-0125 model for evaluating discovered agents in reasoning and problem-solving tasks.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="META-LEARNING ALGORITHMS" target="MAML">
      <data key="d4">9.0</data>
      <data key="d5">MAML is a prominent example of a meta-learning algorithm that enhances learning efficiency across tasks.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-LEARNING ALGORITHMS" target="META-RL">
      <data key="d4">9.0</data>
      <data key="d5">Meta-RL is another example of a meta-learning algorithm that focuses on reinforcement learning efficiency.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LEARNING ENVIRONMENTS" target="POET">
      <data key="d4">8.0</data>
      <data key="d5">POET generates learning environments in an open-ended manner, contributing to the development of effective training settings.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AGENTVERSE" target="YUSHENG CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Yusheng Chen is a researcher involved in the development of the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="SU JINGWEI">
      <data key="d4">8.0</data>
      <data key="d5">Su Jingwei is a researcher contributing to the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="ZUO CHENG">
      <data key="d4">8.0</data>
      <data key="d5">Zuo Cheng is a researcher focused on the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="CHENFEI YUAN">
      <data key="d4">8.0</data>
      <data key="d5">Chenfei Yuan is a researcher involved in the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="CHI-MIN CHAN">
      <data key="d4">8.0</data>
      <data key="d5">Chi-Min Chan is a researcher contributing to the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="HEYANG YU">
      <data key="d4">8.0</data>
      <data key="d5">Heyang Yu is a researcher focused on the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="YI-HSIN HUNG">
      <data key="d4">8.0</data>
      <data key="d5">Yi-Hsin Hung is a researcher contributing to the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="CHEN QIAN">
      <data key="d4">8.0</data>
      <data key="d5">Chen Qian is a researcher focused on the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="HUMAN ORGANIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Agentic systems are closely connected to human organizations as they simulate and model human interactions and structures.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="HONG ET AL. (2023)">
      <data key="d4">7.0</data>
      <data key="d5">Hong et al. (2023) discusses the incorporation of organizational structures in agentic systems, linking them to human organizations.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="PARK ET AL. (2023)">
      <data key="d4">7.0</data>
      <data key="d5">Park et al. (2023) simulates a human town with agents, illustrating the application of agentic systems in modeling human society.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="HARRISON CHASE">
      <data key="d4">6.0</data>
      <data key="d5">Harrison Chase's exploration of agents contributes to the understanding of agentic systems in AI.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ANTHROPIC" target="CLAUDE 3">
      <data key="d4">9.0</data>
      <data key="d5">Anthropic developed Claude 3, a significant advancement in AI technology.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ANTHROPIC" target="CLAUDE 3.5 SONNET">
      <data key="d4">9.0</data>
      <data key="d5">Anthropic developed Claude 3.5 Sonnet, an iteration of their AI model series.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="WEI-LIN CHIANG" target="CHATBOT ARENA">
      <data key="d4">8.0</data>
      <data key="d5">Wei-Lin Chiang is a researcher involved in the development of the Chatbot Arena platform for evaluating language models.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="LIANMIN ZHENG" target="CHATBOT ARENA">
      <data key="d4">8.0</data>
      <data key="d5">Lianmin Zheng is a researcher contributing to the Chatbot Arena platform for evaluating language models.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YING SHENG" target="CHATBOT ARENA">
      <data key="d4">8.0</data>
      <data key="d5">Ying Sheng is a researcher focused on the Chatbot Arena platform for evaluating language models.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="ANASTASIOS NIKOLAS ANGELOPOULOS" target="CHATBOT ARENA">
      <data key="d4">8.0</data>
      <data key="d5">Anastasios Nikolas Angelopoulos is a researcher involved in the Chatbot Arena platform for evaluating language models.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="TIANLE LI" target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Tianle Li is a researcher contributing to the Chatbot Arena platform for evaluating language models.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="KARL COBBE" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Karl Cobbe is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="KALYANMOY DEB" target="ZHICHAO LU">
      <data key="d4">8.0</data>
      <data key="d5">Kalyanmoy Deb and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JOEL LEHMAN" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Joel Lehman is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JOEL LEHMAN" target="RUI WANG">
      <data key="d4">8.0</data>
      <data key="d5">Rui Wang and Joel Lehman co-authored a paper on open-ended coevolution in reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JOEL LEHMAN" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Joel Lehman is a co-author of the OMNI research project focused on open-endedness in models of human notions of interestingness.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JENNY ZHANG" target="MATEI ZAHARIA">
      <data key="d4">6.0</data>
      <data key="d5">Jenny Zhang and Matei Zaharia are both involved in discussions about open-endedness in AI systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JENNY ZHANG" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Jenny Zhang is a co-author of the OMNI research project focused on open-endedness in models of human notions of interestingness.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ZHICHAO LU" target="IAN WHALEN">
      <data key="d4">8.0</data>
      <data key="d5">Ian Whalen and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ZHICHAO LU" target="VISHNU BODDETI">
      <data key="d4">8.0</data>
      <data key="d5">Vishnu Boddeti and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ZHICHAO LU" target="YASHESH DHEBAR">
      <data key="d4">8.0</data>
      <data key="d5">Yashesh Dhebar and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ZHICHAO LU" target="ERIK GOODMAN">
      <data key="d4">8.0</data>
      <data key="d5">Erik Goodman and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ZHICHAO LU" target="WOLFGANG BANZHAF">
      <data key="d4">8.0</data>
      <data key="d5">Wolfgang Banzhaf and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="YECHENG JASON MA" target="WILLIAM LIANG">
      <data key="d4">8.0</data>
      <data key="d5">William Liang and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="YECHENG JASON MA" target="OSBERT BASTANI">
      <data key="d4">8.0</data>
      <data key="d5">Osbert Bastani and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="YECHENG JASON MA" target="DINESH JAYARAMAN">
      <data key="d4">8.0</data>
      <data key="d5">Dinesh Jayaraman and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ELLIOT MEYERSON" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Elliot Meyerson is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="MARK J NELSON" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Mark J Nelson is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="HERBIE BRADLEY" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Herbie Bradley is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ADAM GAIER" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Adam Gaier is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ARASH MORADI" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Arash Moradi is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMY K HOOVER" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Amy K Hoover is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JEAN-BAPTISTE MOURET" target="ILLUMINATING SEARCH SPACES">
      <data key="d4">8.0</data>
      <data key="d5">Jean-Baptiste Mouret co-authored a paper on mapping elites to illuminate search spaces.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="PERCY LIANG" target="COMMUNICATIVE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Percy Liang is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="PERCY LIANG" target="ALPACA EVAL">
      <data key="d4">8.0</data>
      <data key="d5">Percy Liang co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="XUECHEN LI">
      <data key="d4">8.0</data>
      <data key="d5">Xuechen Li is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="TIANYI ZHANG">
      <data key="d4">8.0</data>
      <data key="d5">Tianyi Zhang is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="YANN DUBOIS">
      <data key="d4">8.0</data>
      <data key="d5">Yann Dubois is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="ROHAN TAORI">
      <data key="d4">8.0</data>
      <data key="d5">Rohan Taori is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="ISHAAN GULRAJANI">
      <data key="d4">8.0</data>
      <data key="d5">Ishaan Gulrajani is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="CARLOS GUESTRIN">
      <data key="d4">8.0</data>
      <data key="d5">Carlos Guestrin is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">1.0</data>
      <data key="d5">Tatsunori B. Hashimoto is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="DIRECT PREFERENCE OPTIMIZATION" target="RAFAEL RAFAILOV">
      <data key="d4">8.0</data>
      <data key="d5">Rafael Rafailov co-authored a paper on direct preference optimization, contributing to the understanding of reward models in language processing.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="QIANG WANG" target="TOOL LEARNING WITH LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Qiang Wang co-authored a survey on tool learning with large language models, contributing to the research in this area.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="JI-RONG WEN" target="MEMORY MECHANISM">
      <data key="d4">8.0</data>
      <data key="d5">Ji-Rong Wen is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="TORAN BRUCE RICHARDS" target="AUTOGPT">
      <data key="d4">9.0</data>
      <data key="d5">Toran Bruce Richards developed AutoGPT, a tool for automating tasks using language models.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="BERNARDINO ROMERA-PAREDES" target="MATHEMATICAL DISCOVERIES FROM PROGRAM SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Bernardino Romera-Paredes co-authored a paper discussing mathematical discoveries from program search with large language models.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="SANDER SCHULHOFF" target="PROMPT REPORT">
      <data key="d4">8.0</data>
      <data key="d5">Sander Schulhoff co-authored a systematic survey on prompting techniques, contributing to the understanding of effective prompts in language models.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="FREDA SHI" target="LANGUAGE AGENTS WITH VERBAL REINFORCEMENT LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">Freda Shi co-authored a paper on language agents that utilize verbal reinforcement learning techniques.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="JANE X WANG" target="LEARNING TO REINFORCEMENT LEARN">
      <data key="d4">8.0</data>
      <data key="d5">Jane X Wang co-authored a paper on learning to reinforcement learn, contributing to advancements in reinforcement learning methodologies.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="MATT BOTVINICK" target="SHAN KUMARAN">
      <data key="d4">8.0</data>
      <data key="d5">Shan Kumaran and Matt Botvinick are co-authors of a paper on reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="LEI WANG" target="LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">1.0</data>
      <data key="d5">Lei Wang co-authored a survey on large language model-based autonomous agents, contributing to the field of autonomous systems.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="LEI WANG" target="CHEN MA">
      <data key="d4">8.0</data>
      <data key="d5">Lei Wang and Chen Ma are co-authors of a survey on large language model-based autonomous agents.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="CHEN MA" target="MEMORY MECHANISM">
      <data key="d4">8.0</data>
      <data key="d5">Chen Ma is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="(&quot;ENTITY&quot;" target="XUECHEN LI">
      <data key="d4">1.0</data>
      <data key="d5">PERSON</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="XU CHEN" target="MEMORY MECHANISM">
      <data key="d4">8.0</data>
      <data key="d5">Xu Chen is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="RUI WANG" target="ADITYA RAWAL">
      <data key="d4">8.0</data>
      <data key="d5">Aditya Rawal and Rui Wang co-authored a paper on enhanced open-ended reinforcement learning techniques.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="RUI WANG" target="JIALE ZHI">
      <data key="d4">8.0</data>
      <data key="d5">Jiale Zhi and Rui Wang are co-authors on research related to enhanced open-ended reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="RUI WANG" target="YULUN LI">
      <data key="d4">8.0</data>
      <data key="d5">Yulun Li and Rui Wang are co-authors on research related to open-ended reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QUOC V LE" target="SELF(&quot;ENTITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">MINGCHEN ZHUGE</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="QINGYUN WU" target="GAGAN BANSAL">
      <data key="d4">8.0</data>
      <data key="d5">Qingyun Wu and Gagan Bansal are co-authors on advancements in multi-agent conversation frameworks.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QINGYUN WU" target="NIMROD GILEADI">
      <data key="d4">8.0</data>
      <data key="d5">Nimrod Gileadi and Qingyun Wu are co-authors on advancements in multi-agent conversation frameworks.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QINGYUN WU" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Qingyun Wu is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIEYU ZHANG" target="SHAOKUN ZHANG">
      <data key="d4">16.0</data>
      <data key="d5">Shaokun Zhang and Jieyu Zhang are co-authors on research related to robotic skill synthesis using language models.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JIEYU ZHANG" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Jieyu Zhang is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="SHAOKUN ZHANG" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Shaokun Zhang is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ELIEZER YUDKOWSKY" target="MATEI ZAHARIA">
      <data key="d4">6.0</data>
      <data key="d5">Eliezer Yudkowsky and Matei Zaharia are both involved in discussions about AI and its implications for global risks.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="OMNI" target="KENNETH STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Kenneth Stanley is a co-author of the OMNI research project focused on open-endedness in models of human notions of interestingness.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="BENFENG XU" target="AN YANG">
      <data key="d4">8.0</data>
      <data key="d5">Benfeng Xu and An Yang are co-authors on advancements in agentic systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="NICHOLAS FULLAGAR" target="GREGORY DARDYK">
      <data key="d4">8.0</data>
      <data key="d5">Nicholas Fullagar and Gregory Dardyk are co-authors on advancements in AI systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="NICHOLAS FULLAGAR" target="NEHA NARULA">
      <data key="d4">1.0</data>
      <data key="d5">Neha Narula and Nicholas Fullagar are co-authors on advancements in AI systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="J BRADLEY CHEN" target="ROBERT MUTH">
      <data key="d4">8.0</data>
      <data key="d5">J Bradley Chen and Robert Muth are co-authors on advancements in AI systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="TAVIS ORMANDY" target="SHIKI OKASAKA">
      <data key="d4">8.0</data>
      <data key="d5">Tavis Ormandy and Shiki Okasaka are co-authors on advancements in AI systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JIALE LIU" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Jiale Liu is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="LINXIN SONG" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Linxin Song is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="CHI WANG" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Chi Wang is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="RANJAY KRISHNA" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Ranjay Krishna is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="ZEU ZHANG">
      <data key="d4">8.0</data>
      <data key="d5">Zeyu Zhang is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="XIAOHE BO">
      <data key="d4">8.0</data>
      <data key="d5">Xiaohe Bo is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="RUI LI">
      <data key="d4">8.0</data>
      <data key="d5">Rui Li is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="QUANYU DAI">
      <data key="d4">8.0</data>
      <data key="d5">Quanyu Dai is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="JIEMING ZHU">
      <data key="d4">8.0</data>
      <data key="d5">Jieming Zhu is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="ZHENHUA DONG">
      <data key="d4">8.0</data>
      <data key="d5">Zhenhua Dong is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="HENG-TZE CHENG" target="SELF-DISCOVERY">
      <data key="d4">8.0</data>
      <data key="d5">Heng-Tze Cheng is a co-author of a paper on self-discovery in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="PEI ZHOU" target="SELF-DISCOVERY">
      <data key="d4">8.0</data>
      <data key="d5">Pei Zhou is a co-author of a paper on self-discovery in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JAY PUJARA" target="SELF-DISCOVERY">
      <data key="d4">8.0</data>
      <data key="d5">Jay Pujara is a co-author of a paper on self-discovery in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="XIANG REN" target="SELF-DISCOVERY">
      <data key="d4">8.0</data>
      <data key="d5">Xiang Ren is a co-author of a paper on self-discovery in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MINGCHEN ZHUGE" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Mingchen Zhuge is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="WENYI WANG" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Wenyi Wang is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="LOUIS KIRSCH" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Louis Kirsch is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="FRANCESCO FACCIO" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Francesco Faccio is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="DMITRII KHIZBULLIN" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Dmitrii Khizbullin is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="J&#220;RGEN SCHMIDHUBER" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">J&#252;rgen Schmidhuber is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="LUISA ZINTGRAF">
      <data key="d4">8.0</data>
      <data key="d5">Luisa Zintgraf is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="SEBASTIAN SCHULZE">
      <data key="d4">8.0</data>
      <data key="d5">Sebastian Schulze is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="LEO FENG">
      <data key="d4">8.0</data>
      <data key="d5">Leo Feng is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="MAXIMILIAN IGL">
      <data key="d4">8.0</data>
      <data key="d5">Maximilian Igl is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="KYRIACOS SHIARLIS">
      <data key="d4">8.0</data>
      <data key="d5">Kyriacos Shiarlis is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="YARIN GAL">
      <data key="d4">8.0</data>
      <data key="d5">Yarin Gal is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="KATJA HOFMANN">
      <data key="d4">8.0</data>
      <data key="d5">Katja Hofmann is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="SHIMON WHITESON">
      <data key="d4">1.0</data>
      <data key="d5">Shimon Whiteson is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="META AGENT" target="OUTPUT INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent follows output instructions to format its responses correctly, ensuring clarity and structure.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="AGENT ARCHITECTURE">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent operates based on a specific agent architecture that defines its design and functionality.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent uses prompts to guide its output and reasoning, ensuring it follows the intended instructions.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="AGENT ARCHITECTURE" target="FORWARD FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">The forward function is a critical component of the agent architecture, defining how the agent processes tasks.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="RUNTIME ERROR" target="DEBUG_THOUGHT">
      <data key="d4">1.0</data>
      <data key="d5">When a runtime error occurs, the meta agent engages in debug_thought to analyze and resolve the issue.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FRAMEWORK CODE" target="NAMEDTUPLE INFO OBJECT">
      <data key="d4">1.0</data>
      <data key="d5">The framework code utilizes the namedtuple Info object to facilitate communication and organization of information.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FRAMEWORK CODE" target="APPENDICES">
      <data key="d4">7.0</data>
      <data key="d5">The framework code is detailed in the appendices, providing additional context and examples for implementation.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FM MODULE" target="INFO">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module utilizes the Info data structure to hold and manage task-related information for processing.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="AGENT SYSTEM">
      <data key="d4">7.0</data>
      <data key="d5">The Agent System interacts with the FM Module to process task information and implement functionalities like self-reflection.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="JSON RESPONSE">
      <data key="d4">9.0</data>
      <data key="d5">The FM Module generates a JSON response as output after processing user messages through the GPT model.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="GPT MODEL">
      <data key="d4">9.0</data>
      <data key="d5">The FM Module queries the GPT model to obtain responses based on user input and instructions.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="OUTPUT FIELDS">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module defines the output fields that are expected in the responses it generates for tasks.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module utilizes a system message to provide context for the GPT model when generating responses.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="ITERATION INDEX">
      <data key="d4">6.0</data>
      <data key="d5">The FM Module uses the iteration index to manage and track the progress of tasks across multiple iterations.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="AGENT SYSTEM" target="COT INSTRUCTION">
      <data key="d4">1.0</data>
      <data key="d5">The Agent System uses Chain-of-Thought instructions to guide the reasoning process for solving tasks.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="AGENT SYSTEM" target="TASK INFORMATION">
      <data key="d4">8.0</data>
      <data key="d5">The Agent System processes task information to derive answers or outputs based on the defined instructions.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="AGENT SYSTEM" target="RESPONSE">
      <data key="d4">1.0</data>
      <data key="d5">The Agent System generates a response based on the processed task information and instructions provided to it.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GPT MODEL" target="BACKOFF">
      <data key="d4">6.0</data>
      <data key="d5">The Backoff technique is applied when querying the GPT model to manage rate limit errors effectively.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="COT_REFLECT_INSTRUCTION" target="COT_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The cot_reflect_instruction guides the cot_module to refine answers based on previous attempts and feedback.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="COT_MODULE" target="COT_INPUTS">
      <data key="d4">8.0</data>
      <data key="d5">The cot_module processes the cot_inputs to generate thinking and answers based on the provided task information.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="CRITIC_MODULE" target="COT_INPUTS">
      <data key="d4">8.0</data>
      <data key="d5">The critic_module uses cot_inputs to provide feedback and correctness status on the answers generated by the cot_module.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="CRITIC_MODULE" target="CORRECT">
      <data key="d4">8.0</data>
      <data key="d5">The critic_module determines the correct status of the answer generated by the cot_module, indicating its accuracy.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="COT_INPUTS" target="TASK_INFO">
      <data key="d4">7.0</data>
      <data key="d5">COT_inputs include task_info as part of the data processed by the cot_module to generate answers.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC_CHALLENGE" target="EXAMPLE_INPUT_OUTPUT_GRID">
      <data key="d4">9.0</data>
      <data key="d5">The ARC challenge utilizes example input-output grids to teach the transformation rules necessary for predicting outputs.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC_CHALLENGE" target="TEST_GRID">
      <data key="d4">9.0</data>
      <data key="d5">The test grid is part of the ARC challenge, where the system must apply learned transformation rules to predict the output.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC_CHALLENGE" target="GTP-4O-2024-05-13">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4O-2024-05-13 is used by the meta agent to generate solutions for tasks in the ARC challenge.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC_CHALLENGE" target="GPT-3.5-TURBO-0125">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-Turbo-0125 is used to evaluate the performance of agents and baselines in the ARC challenge.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="GTP-4O-2024-05-13" target="INITIAL_SOLUTIONS">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4O-2024-05-13 is utilized in the evaluation of the initial solutions generated by the meta agent.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPT-3.5-TURBO-0125" target="INITIAL_SOLUTIONS">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-Turbo-125 is used for evaluating discovered agents and baselines related to the initial solutions.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INPUT_GRID" target="OUTPUT_GRID">
      <data key="d4">9.0</data>
      <data key="d5">The output_grid is derived from the input_grid by applying the transformation_rule in the ARC challenge.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="INPUT_GRID" target="TRANSFORMATION_RULE">
      <data key="d4">9.0</data>
      <data key="d5">The transformation_rule is applied to the input_grid to predict the output_grid in the ARC challenge.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="OUTPUT_GRID" target="TRANSFORMATION_RULE">
      <data key="d4">1.0</data>
      <data key="d5">The transformation_rule defines how the input_grid is transformed into the output_grid in the ARC challenge.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="STRUCTURED FEEDBACK AND ENSEMBLE AGENT" target="FM_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent utilizes FM_Module to generate initial candidate solutions for tasks.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="STRUCTURED FEEDBACK AND ENSEMBLE AGENT" target="TASKINFO">
      <data key="d4">8.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent processes TaskInfo to generate solutions based on the provided task details.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="STRUCTURED FEEDBACK AND ENSEMBLE AGENT" target="INITIAL CANDIDATE SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent generates initial candidate solutions as part of its problem-solving process.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="STRUCTURED FEEDBACK AND ENSEMBLE AGENT" target="CORRECT EXAMPLES">
      <data key="d4">7.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent considers correct examples to evaluate the success of its generated solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="STRUCTURED FEEDBACK AND ENSEMBLE AGENT" target="WRONG EXAMPLES">
      <data key="d4">1.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent analyzes wrong examples to identify areas for improvement in its solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM_MODULE" target="TASKINFO">
      <data key="d4">9.0</data>
      <data key="d5">The FM_MODULE utilizes TASKINFO as a critical input to generate candidate solutions for the agent's tasks. By processing TASKINFO, the FM_MODULE effectively derives solutions tailored to the specific problems at hand. This relationship highlights the integral role of TASKINFO in enabling the FM_MODULE to function optimally, ensuring that the agent can address its tasks with appropriate and relevant solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2,ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="DECOMPOSITION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The FM_Module includes the Decomposition Module as a key component for breaking down problems into sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="TASKINFO" target="INITIAL_SOLUTIONS">
      <data key="d4">1.0</data>
      <data key="d5">TaskInfo provides the necessary context and parameters for evaluating the initial solutions effectively.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="HUMAN-LIKE FEEDBACK MODULE" target="INITIAL_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The Human-Like Feedback Module processes the initial solutions to provide simulated human feedback on their quality.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="EXPERT ADVISORS">
      <data key="d4">8.0</data>
      <data key="d5">Expert Advisors evaluate the initial solutions and provide targeted feedback for improvement.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="REFINEMENT MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The Refinement Module iteratively refines the initial solutions based on structured feedback received from various sources.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="CORRECT_EXAMPLES">
      <data key="d4">6.0</data>
      <data key="d5">Correct Examples are identified from the initial solutions that have met the evaluation criteria successfully.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="WRONG_EXAMPLES">
      <data key="d4">6.0</data>
      <data key="d5">Wrong Examples are identified from the initial solutions that have not met the evaluation criteria, indicating failures.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINEMENT MODULE" target="FINAL DECISION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Final Decision Module uses the refined solutions to make a final decision on the best-performing code.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INDIANS" target="BAHRAIN">
      <data key="d4">8.0</data>
      <data key="d5">Indians make up a significant portion of the non-national population in Bahrain, with approximately 290,000 residing there.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="BANGLADESHIS" target="BAHRAIN">
      <data key="d4">8.0</data>
      <data key="d5">Bangladeshis make up a significant portion of the non-national population in Bahrain, with approximately 125,000 residing there.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="PAKISTANIS" target="BAHRAIN">
      <data key="d4">7.0</data>
      <data key="d5">Pakistanis make up a portion of the non-national population in Bahrain, with approximately 45,000 residing there.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="FILIPINOS" target="BAHRAIN">
      <data key="d4">7.0</data>
      <data key="d5">Filipinos make up a portion of the non-national population in Bahrain, with approximately 45,000 residing there.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="INDONESIANS" target="BAHRAIN">
      <data key="d4">1.0</data>
      <data key="d5">Indonesians make up a portion of the non-national population in Bahrain, with approximately 8,000 residing there.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DECOMPOSITION MODULE" target="SUB-PROBLEMS">
      <data key="d4">7.0</data>
      <data key="d5">The Decomposition Module generates sub-problems from a larger task for specialized experts to address.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="DECOMPOSITION MODULE" target="DECOMPOSITION INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">The Decomposition Module uses Decomposition Instruction to effectively break down problems into sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERTS" target="SUB-SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Specialized Experts provide sub-solutions for each sub-problem they are assigned to solve.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERTS" target="SUB-PROBLEM">
      <data key="d4">8.0</data>
      <data key="d5">Specialized Experts are assigned specific sub-problems to solve based on their expertise.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERTS" target="SUB-PROBLEM INSTRUCTION">
      <data key="d4">1.0</data>
      <data key="d5">Specialized Experts receive Sub-Problem Instruction to guide their problem-solving process.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="INTEGRATION MODULE" target="SUB-SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The Integration Module combines the sub-solutions into a final answer to the original problem.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="INTEGRATION MODULE" target="INTEGRATION INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">The Integration Module follows Integration Instruction to combine sub-solutions into a coherent final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VISUAL REPRESENTATION MODULE" target="CHAIN-OF-THOUGHT MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The Visual Representation Module aids the Chain-of-Thought Module by providing visual aids for problem-solving.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VISUAL REPRESENTATION MODULE" target="VERIFICATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Verification Module ensures the accuracy of the visual aids created by the Visual Representation Module.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SYNTHETIC DATA">
      <data key="d4">16.0</data>
      <data key="d5">AgentInstruct is a specialized tool that generates synthetic data aimed at enhancing model training, particularly in the realm of language models. It addresses critical issues related to diversity and quality in datasets, ensuring that the training data is both varied and high-quality. By focusing on these aspects, AgentInstruct plays a vital role in improving the performance and robustness of artificial intelligence systems, particularly in Natural Language Processing applications.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-7B">
      <data key="d4">16.0</data>
      <data key="d5">Mistral-7B is a base model that has undergone post-training utilizing synthetic data generated by the AgentInstruct method. This approach has been specifically designed to enhance the model's performance, indicating a focused effort to refine Mistral-7B's capabilities through advanced techniques associated with AgentInstruct.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="GENERATIVE TEACHING">
      <data key="d4">15.0</data>
      <data key="d5">AgentInstruct is a practical implementation of the Generative Teaching methodology, specifically designed to create synthetic data for training artificial intelligence systems. This innovative approach has demonstrated its effectiveness in enhancing learning outcomes, particularly within mathematical datasets. The relationship between AgentInstruct and Generative Teaching highlights the latter's foundational role in developing tools that improve educational results through the generation of high-quality, relevant data for AI training purposes.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="RAW DOCUMENTS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct uses raw documents as seeds to generate synthetic data, enabling the creation of diverse datasets.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="AGENTIC FLOWS">
      <data key="d4">9.0</data>
      <data key="d5">AgentInstruct employs agentic flows to automate the data generation process, enhancing efficiency and diversity.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTENT TRANSFORMATION AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Agents are utilized within the AgentInstruct methodology to modify raw seeds for instruction generation.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="INSTRUCTION CREATION AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Creation Agents are part of the AgentInstruct process, generating diverse instructions from transformed seeds.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="REFINEMENT AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Refinement Agents are involved in the AgentInstruct methodology to enhance the quality and complexity of generated instructions.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="DIVERSE DATA">
      <data key="d4">9.0</data>
      <data key="d5">AgentInstruct aims to produce diverse data through its structured approach, ensuring a wide range of generated content.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="HIGH-QUALITY DATA">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct focuses on generating high-quality data by leveraging advanced models and methodologies.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3">
      <data key="d4">34.0</data>
      <data key="d5">AgentInstruct and Orca-3 are interconnected entities in the realm of artificial intelligence, specifically focusing on enhancing model performance. AgentInstruct data plays a crucial role in improving Orca-3, resulting in significant advancements over baseline models. This methodology has been effectively applied to boost Orca-3's proficiency in tackling various mathematical challenges, showcasing its direct impact on the model's capabilities. Furthermore, Orca-3 is specifically trained using the AgentInstruct approach, which emphasizes the generation of instructional data. The post-training phase of Orca-3, utilizing a dataset derived from the AgentInstruct methodology, has led to marked improvements in its overall performance.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="PERFORMANCE AUGMENTATION">
      <data key="d4">1.0</data>
      <data key="d5">Performance augmentation is achieved through the integration of AgentInstruct data, enhancing the capabilities of models like Orca-3.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MATH PROBLEMS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct enhances the ability of AI models to solve math problems across various difficulty levels, indicating a direct application of the technique.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct is applied to Orca-3-7B to enhance its summarization capabilities by reducing hallucinations.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="UNSTRUCTURED DATA">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct utilizes unstructured data to create tailored datasets for model training, enhancing the learning process.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="MISTRAL-7B" target="ORCA-3">
      <data key="d4">26.0</data>
      <data key="d5">Orca-3 is a fine-tuned version of the Mistral-7B model, showcasing enhanced performance in specific tasks. This improvement is attributed to the post-training process that utilized synthetic data, which has led to notable advancements in the model's capabilities. Overall, Orca-3 represents a significant evolution within the Mistral model family, reflecting the benefits of targeted training methodologies.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="MISTRAL-7B" target="SYNTHETIC DATASET">
      <data key="d4">8.0</data>
      <data key="d5">The synthetic dataset created by AgentInstruct is used to fine-tune the Mistral-7B model, enhancing its capabilities.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="MISTRAL-7B" target="LLAMA-8B-INSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">Mistral-7B is compared with LLAMA-8B-instruct to evaluate the effectiveness of instruction-tuning.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="MISTRAL-7B" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">Mistral-7B has been evaluated on the MIRAGE datasets to assess its performance in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3" target="LLAMA-8B-INSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 outperforms LLAMA-8B-Instruct in various benchmarks, demonstrating the effectiveness of the synthetic data used.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="ORCA-3" target="AGIEVAL">
      <data key="d4">24.0</data>
      <data key="d5">Orca-3 demonstrates notable advancements on the AGIEval benchmark, significantly outperforming previous models and other instruction-tuned counterparts. AGIEval serves as a critical evaluation tool, providing performance scores that highlight Orca-3's effectiveness in tasks related to reading comprehension and mathematics. This improvement underscores Orca-3's enhanced capabilities in these areas, marking it as a leading model in its field.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="BBH">
      <data key="d4">16.0</data>
      <data key="d5">ORCA-3 is a cutting-edge model that demonstrates superior performance on the BBH benchmark, surpassing previous models and highlighting its enhanced capabilities. The improvements shown by ORCA-3 on the BBH benchmark underscore its effectiveness across a range of tasks, establishing it as a significant advancement in the field.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="ALPACA EVAL">
      <data key="d4">10.0</data>
      <data key="d5">ORCA-3 is a model that demonstrates significant advancements in instruction-following tasks, particularly highlighted by its performance on the AlpacaEval benchmark. In this context, AlpacaEval serves as a critical evaluation tool where ORCA-3 not only achieves substantial improvements but also outperforms other models. This showcases ORCA-3's effectiveness in instruction tuning, reinforcing its position as a leading entity in the field of artificial intelligence and natural language processing.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-V0.1">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 is a finetuned version of the Mistral-7B-v0.1 model, adapted for specific tasks using the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-BENCH">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3 is evaluated using the Orca-Bench dataset to assess its performance across various skills.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="TRAINING DETAILS">
      <data key="d4">9.0</data>
      <data key="d5">Orca-3 was trained using specific training details that outline the process and parameters used during its development.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="EVALUATION RESULTS">
      <data key="d4">1.0</data>
      <data key="d5">The evaluation results provide insights into the performance of Orca-3 when tested against the Orca-Bench dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-2.5">
      <data key="d4">15.0</data>
      <data key="d5">The entities ORCA-3 and ORCA-2.5 are part of a comparative analysis in the field of artificial intelligence, specifically focusing on reading comprehension tasks. ORCA-3 has demonstrated an 18% improvement over ORCA-2.5, highlighting its enhanced capabilities in this area. This performance comparison is substantiated through evaluations conducted on the Orca-Bench dataset, which serves as a benchmark for assessing the advancements made by ORCA-3 relative to its predecessor, ORCA-2.5.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-INSTRUCT-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 is evaluated against Mistral-Instruct-7B to demonstrate its performance improvements in the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="LLAMA3-8B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 is evaluated against LLAMA3-8B to demonstrate its performance improvements in the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="GPT-3.5-TURBO">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 is evaluated against GPT-3.5-turbo to demonstrate its performance improvements in the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="PERFORMANCE COMPARISON">
      <data key="d4">1.0</data>
      <data key="d5">Performance comparison illustrates the enhancements in Orca-3's capabilities during post-training, enabled by the AgentInstruct data.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">16.0</data>
      <data key="d5">Orca-3 has shown a significant advancement in artificial intelligence capabilities, achieving a 21% performance gain compared to Mistral-7B-Instruct. This improvement is evident across various benchmarks, which further emphasizes the differences in capabilities between the two entities. The comparison underscores Orca-3's enhanced performance metrics, positioning it as a more advanced option in the realm of AI development relative to Mistral-7B-Instruct.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="LSATS">
      <data key="d4">9.0</data>
      <data key="d5">Orca-3's performance on LSAT reading comprehension sections has been elevated to match that of GPT-4, indicating its effectiveness in tackling difficult exams.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="POST-TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Post-training is a critical phase for Orca-3, allowing it to leverage synthetic data for improved performance across benchmarks.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="ALPACA EVAL" target="XUECHEN LI">
      <data key="d4">8.0</data>
      <data key="d5">Xuechen Li co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="TIANYI ZHANG">
      <data key="d4">8.0</data>
      <data key="d5">Tianyi Zhang co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="YANN DUBOIS">
      <data key="d4">8.0</data>
      <data key="d5">Yann Dubois co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="ROHAN TAORI">
      <data key="d4">8.0</data>
      <data key="d5">Rohan Taori co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="ISHAAN GULRAJANI">
      <data key="d4">8.0</data>
      <data key="d5">Ishaan Gulrajani co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="CARLOS GUESTRIN">
      <data key="d4">8.0</data>
      <data key="d5">Carlos Guestrin co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="TATSUNORI HASHIMOTO">
      <data key="d4">8.0</data>
      <data key="d5">Tatsunori Hashimoto co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">5.0</data>
      <data key="d5">Open-ended generation tasks are evaluated using the AlpacaEval benchmark for win-rate comparisons.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="BAOLIN PENG">
      <data key="d4">8.0</data>
      <data key="d5">Baolin Peng co-authored a paper on instruction tuning with GPT-4, focusing on enhancing model performance.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="CHUNYUAN LI">
      <data key="d4">8.0</data>
      <data key="d5">Chunyuan Li co-authored a paper on instruction tuning with GPT-4, focusing on enhancing model performance.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="PENGCHENG HE">
      <data key="d4">8.0</data>
      <data key="d5">Pengcheng He co-authored a paper on instruction tuning with GPT-4, focusing on enhancing model performance.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="MICHEL GALLEY">
      <data key="d4">8.0</data>
      <data key="d5">Michel Galley co-authored a paper on instruction tuning with GPT-4, focusing on enhancing model performance.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="JIANFENG GAO">
      <data key="d4">1.0</data>
      <data key="d5">Jianfeng Gao co-authored a paper on instruction tuning with GPT-4, focusing on enhancing model performance.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="RAW ARTICLES">
      <data key="d4">8.0</data>
      <data key="d5">Agentic flows utilize raw articles as seeds to generate diverse problems through automation.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="WEB AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Web agents are utilized within agentic flows to perform automated tasks on the web, enhancing the generation process.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="OUTPUTS">
      <data key="d4">7.0</data>
      <data key="d5">Outputs are the results generated from the workflows of the agentic flows, including instructions and data summaries.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="PROBLEM GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Problem generation is a process facilitated by agentic flows to create distinct and diverse problems from raw articles.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="ARGUMENT PASSAGE GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Argument Passage Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="DEBATE PASSAGE GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Debate Passage Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="CONVERSATION PASSAGE GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Conversation Passage Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="MEETING TRANSCRIPT GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Meeting Transcript Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="POEM GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Poem Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="SATIRICAL PASSAGE GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Satirical Passage Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="INSTRUCTIONAL PASSAGE GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Instructional Passage Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="LONG TEXT GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Long Text Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="IDENTITY AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Identity Agent as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="LITERAL COMPREHENSION QUESTION">
      <data key="d4">6.0</data>
      <data key="d5">Agentic Flows utilizes Literal Comprehension Questions as part of its reading comprehension transformation agents.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="NUMERICAL DISCRETE REASONING">
      <data key="d4">6.0</data>
      <data key="d5">Agentic Flows utilizes Numerical Discrete Reasoning as part of its reading comprehension transformation agents.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="CRITICAL COMPREHENSION QUESTION">
      <data key="d4">6.0</data>
      <data key="d5">Agentic Flows utilizes Critical Comprehension Questions as part of its reading comprehension transformation agents.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="EVALUATIVE COMPREHENSION QUESTION">
      <data key="d4">1.0</data>
      <data key="d5">Agentic Flows utilizes Evaluative Comprehension Questions as part of its reading comprehension transformation agents.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="RAW ARTICLES" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">Content Transformation Flow converts raw articles into an intermediate representation for instruction creation.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="SEED INSTRUCTION GENERATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow takes transformed content from the Content Transformation Flow to generate diverse instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="INTERMEDIATE REPRESENTATION">
      <data key="d4">7.0</data>
      <data key="d5">Content Transformation Flow produces an intermediate representation that simplifies the creation of tailored instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="INSTRUCTION CREATION">
      <data key="d4">1.0</data>
      <data key="d5">Instruction creation is a key outcome of the Content Transformation Flow, which simplifies the process of developing specific tasks.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="READING COMPREHENSION">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Flow aims to create materials that improve reading comprehension skills by generating diverse question types.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="ARGUMENT PASSAGE GENERATOR">
      <data key="d4">8.0</data>
      <data key="d5">The Argument Passage Generator is a component of the Content Transformation Flow, specifically designed to create argumentative passages for comprehension tasks.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="API DESCRIPTION">
      <data key="d4">9.0</data>
      <data key="d5">The Content Transformation Flow synthesizes API descriptions from source code snippets or other inputs, detailing their functionality.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="LIBRARY RECONSTRUCTION">
      <data key="d4">1.0</data>
      <data key="d5">Library Reconstruction is a specific application of the Content Transformation Flow, focusing on synthesizing API lists.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow enhances the instructions generated from the Seed Instruction Generation Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="COMPREHENSIVE TAXONOMY">
      <data key="d4">8.0</data>
      <data key="d5">The comprehensive taxonomy guides the Seed Instruction Generation Flow in creating diverse instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR AGENTS">
      <data key="d4">9.0</data>
      <data key="d5">Suggester-Editor Agents are involved in the Instruction Refinement Flow to propose and modify instructions for quality improvement.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="ITERATIVE PROCESS">
      <data key="d4">8.0</data>
      <data key="d5">The Instruction Refinement Flow employs an iterative process to enhance the quality and complexity of instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">8.0</data>
      <data key="d5">The Instruction Refinement Flow employs a Suggester-Editor pair to enhance the complexity of generated instructions.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SKILLS" target="READING COMPREHENSION">
      <data key="d4">8.0</data>
      <data key="d5">Reading comprehension is one of the skills developed through the workflows implemented in the agentic flows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SKILLS" target="TEXT MODIFICATION">
      <data key="d4">8.0</data>
      <data key="d5">Text modification is another skill targeted by the workflows in the agentic flows for enhancing content quality.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SKILLS" target="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Open domain question answering is a skill that is part of the competencies developed through the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="CONVERSATION">
      <data key="d4">6.0</data>
      <data key="d5">Conversational agents can be designed to assist in reading comprehension by engaging users in discussions about texts.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="AGENTINSTRUCT FLOWS">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct Flows are implemented to enhance reading comprehension capabilities in AI systems.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="LSAT LOGICAL REASONING">
      <data key="d4">7.0</data>
      <data key="d5">The LSAT Logical Reasoning test assesses reading comprehension and critical reasoning skills, making it relevant to the study of reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="DROPS">
      <data key="d4">9.0</data>
      <data key="d5">DROP is a benchmark for reading comprehension that requires discrete reasoning over paragraphs.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="PARAPHRASING AGENT">
      <data key="d4">1.0</data>
      <data key="d5">The paraphrasing agent is a tool used in text modification to rewrite content while maintaining its original meaning.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="ANALYTICAL REASONING" target="SKILL">
      <data key="d4">8.0</data>
      <data key="d5">Analytical reasoning is a skill that is developed through the workflows in the agentic flows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="ASSESSMENT">
      <data key="d4">7.0</data>
      <data key="d5">Multiple choice questions are a common assessment method used to evaluate skills developed through the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">1.0</data>
      <data key="d5">The GPT-4 extraction system message is used to evaluate responses to multiple choice questions.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="EVALUATION DETAILS">
      <data key="d4">8.0</data>
      <data key="d5">Evaluation details specify the methods used to assess the performance of models on multiple choice questions.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="OPEN-ENDED GENERATION SETTING">
      <data key="d4">6.0</data>
      <data key="d5">The open-ended generation setting contrasts with multiple choice questions by allowing more freedom in responses.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="DATA TO TEXT" target="PROCESS">
      <data key="d4">7.0</data>
      <data key="d5">Data-to-text processes are used to generate human-readable summaries from the outputs of the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CODING" target="SKILL">
      <data key="d4">8.0</data>
      <data key="d5">Coding is a skill that is also developed through the workflows implemented in the agentic flows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CODING" target="TEXT EXTRACTION">
      <data key="d4">6.0</data>
      <data key="d5">Coding can be involved in the development of algorithms for text extraction processes, enhancing the retrieval of relevant information.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="PROCESS">
      <data key="d4">1.0</data>
      <data key="d5">Text extraction is a process involved in retrieving relevant information from generated outputs in the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="TEXT CLASSIFICATION">
      <data key="d4">7.0</data>
      <data key="d5">Text extraction can be a preliminary step before text classification, as relevant information needs to be retrieved before categorization.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="RETRIEVAL AUGMENTED GENERATION (RAG)">
      <data key="d4">8.0</data>
      <data key="d5">RAG utilizes text extraction to retrieve relevant documents before generating responses, linking the two processes.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TRANSFORMED CONTENT" target="SEED INSTRUCTION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Flow generates diverse instructions based on the transformed content from the Content Transformation Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="ENRICO FERMI" target="FERMI PROBLEM">
      <data key="d4">7.0</data>
      <data key="d5">The Fermi problem is named after Enrico Fermi, who is known for making justified guesses to solve complex estimation problems.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CREATIVE CONTENT GENERATION" target="FEW SHOT REASONING">
      <data key="d4">5.0</data>
      <data key="d5">Few-shot reasoning can enhance creative content generation by allowing models to create original content with minimal examples.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPERURICEMIA" target="PURINE">
      <data key="d4">1.0</data>
      <data key="d5">Hyperuricemia is often caused by a diet high in purines, which can lead to elevated uric acid levels in the body.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPERURICEMIA" target="CARDIOVASCULAR DISEASE">
      <data key="d4">17.0</data>
      <data key="d5">Hyperuricemia is recognized as a significant risk factor for the development of cardiovascular disease. The relationship between these two medical conditions is well-established, with hyperuricemia being associated with an increased risk of cardiovascular complications. This connection highlights the importance of monitoring uric acid levels as part of cardiovascular health assessments, emphasizing the need for awareness and potential intervention strategies to mitigate the risks associated with hyperuricemia in patients at risk for cardiovascular disease.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPERURICEMIA" target="URIC ACID">
      <data key="d4">10.0</data>
      <data key="d5">HYPERURICEMIA is characterized by high levels of uric acid in the blood, a condition that can lead to various health complications. Elevated uric acid levels are a clear indicator of hyperuricemia, underscoring the importance of monitoring uric acid concentrations to prevent potential health issues associated with this condition.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="CARDIOVASCULAR DISEASE" target="URIC ACID">
      <data key="d4">8.0</data>
      <data key="d5">Elevated uric acid levels are associated with an increased risk of cardiovascular disease.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPURICEMIA" target="URIC ACID">
      <data key="d4">8.0</data>
      <data key="d5">Hypouricemia is characterized by low levels of uric acid in the blood, indicating a potential health issue.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="URIC ACID" target="LABORATORY TESTS">
      <data key="d4">8.0</data>
      <data key="d5">Laboratory tests are used to assess uric acid levels in the blood and diagnose related conditions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY TESTS">
      <data key="d4">7.0</data>
      <data key="d5">Hypouricemia may be diagnosed through laboratory tests that measure uric acid levels.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="READING COMPREHENSION QUESTIONS" target="PASSAGE-QUESTION PAIRS">
      <data key="d4">7.0</data>
      <data key="d5">Passage-question pairs are created to evaluate understanding of reading comprehension questions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="PARAPHRASING AGENT" target="RANDOM SEED">
      <data key="d4">7.0</data>
      <data key="d5">The Paraphrasing Agent utilizes a random seed to create text modification tasks based on the seed's value.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="FINANCIALIZATION" target="SUPPLY CHAINS">
      <data key="d4">7.0</data>
      <data key="d5">Financialization influences supply chains of financial products, connecting various global locations and political projects.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="NATASCHA VAN DER ZWAN" target="RESEARCH STREAMS">
      <data key="d4">8.0</data>
      <data key="d5">Natascha van der Zwan identifies and categorizes three distinct research streams related to the concept of financialization.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SOCIAL LIFE" target="SUPPLY CHAINS">
      <data key="d4">6.0</data>
      <data key="d5">The supply chains of financial products can transform social life by altering interactions and relationships within society.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="AMERICAN ANTHROPOLOGICAL ASSOCIATION" target="SEA 2017 ANNUAL MEETING">
      <data key="d4">1.0</data>
      <data key="d5">The SEA 2017 Annual Meeting is organized by the American Anthropological Association, which facilitates professional gatherings in anthropology.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CREATE MEAL PLAN" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes creating a meal plan as one of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="UPDATE FOOD ITEM" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes updating food items as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="TRACK USER MEAL" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow encompasses tracking user meals as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="GET DIETARY RECOMMENDATIONS" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes providing dietary recommendations as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="ADD NEW FOOD ITEM" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes adding new food items as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="DELETE FOOD ITEM" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes deleting food items as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="GET USER NUTRITIONAL STATS" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes retrieving user nutritional stats as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="MEAL PLAN" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Day 1 is a component of the overall meal plan, detailing specific meals and their caloric values.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="MEAL PLAN" target="DAY 2">
      <data key="d4">8.0</data>
      <data key="d5">Day 2 is a component of the overall meal plan, detailing specific meals and their caloric values.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="MEAL PLAN" target="FOOD ITEMS">
      <data key="d4">8.0</data>
      <data key="d5">The meal plan consists of various food items that make up each meal, detailing what is included in the diet.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="API_CALL">
      <data key="d4">7.0</data>
      <data key="d5">The API call is the action taken to create the vegetarian meal plan based on user specifications.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="DAY 1" target="TOTAL CALORIES">
      <data key="d4">7.0</data>
      <data key="d5">Day 1 includes a total caloric breakdown for each meal, providing insight into daily energy intake.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="DAY 2" target="TOTAL CALORIES">
      <data key="d4">7.0</data>
      <data key="d5">Day 2 includes a total caloric breakdown for each meal, providing insight into daily energy intake.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="QUINOA SALAD" target="NUTRITIONAL INFORMATION">
      <data key="d4">6.0</data>
      <data key="d5">The Quinoa Salad recipe requires nutritional information to be added to the database for completeness.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="CHANA MASALA" target="NUTRITIONAL INFORMATION">
      <data key="d4">6.0</data>
      <data key="d5">The Chana Masala recipe requires nutritional information for updating in the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BUTTER CHICKEN" target="NUTRITIONAL INFORMATION">
      <data key="d4">6.0</data>
      <data key="d5">The Butter Chicken recipe requires nutritional information for removal from the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-BENCH" target="COMPLEX ODQA">
      <data key="d4">6.0</data>
      <data key="d5">The Orca-Bench dataset includes evaluations of complex questions, which are part of the Complex ODQA subset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="MULTI-TURN INTERACTION">
      <data key="d4">7.0</data>
      <data key="d5">Multi-turn interaction is a key feature in the Orca-Bench dataset, allowing for the evaluation of conversational AI models over multiple exchanges.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="EVALUATION RESULTS" target="MIRAGE DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">Evaluation results provide insights into the performance of models tested on the MIRAGE datasets.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B shows performance improvements compared to Orca-2.5, indicating a direct relationship in their development.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="ORCA-3-7B">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-turbo is compared with Orca-3-7B in summarization evaluations, establishing a relationship in performance assessment.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">GPT-3.5-Turbo has been evaluated on the MIRAGE datasets to assess its performance in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="CO-T">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-Turbo utilizes the CoT technique to enhance its reasoning capabilities in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="TEACHER RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">Student responses are evaluated against teacher responses to assess the performance of AI models in the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="SCORE NORMALIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Score normalization is applied to student responses to standardize their scores on a 0 to 10 scale for comparison.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">1.0</data>
      <data key="d5">The EQBench GPT-4 Extraction System Message is used to extract emotion scores from the student agent response based on the critique provided.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="MULTIPLE ANSWERS">
      <data key="d4">7.0</data>
      <data key="d5">The student response may include multiple answers if the student provides more than one option for the question.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="FOFO" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">1.0</data>
      <data key="d5">FoFo benchmarks assess the format-following capabilities of Mistral-7B-Instruct, indicating its applicability in real-world scenarios.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="FOFO" target="OPEN-ENDED GENERATION">
      <data key="d4">5.0</data>
      <data key="d5">Open-ended generation tasks are evaluated using the FOFO benchmark for format correctness.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="IFEVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">5.0</data>
      <data key="d5">Open-ended generation tasks are evaluated using the IFEval benchmark for adherence to instructions.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="MT-BENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">5.0</data>
      <data key="d5">Open-ended generation tasks are evaluated using the MT-Bench benchmark for response quality.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="INFOBENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">Open-ended generation tasks are evaluated using the InfoBench benchmark for instruction adherence.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT" target="MISTRAL">
      <data key="d4">7.0</data>
      <data key="d5">Mistral's improvements in reading comprehension are evaluated against the baseline of Mistral-7B-Instruct.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated against Mistral-7B-Instruct, highlighting its advancements in summarization capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ELEMENTARY MATH" target="MATH PROBLEMS">
      <data key="d4">7.0</data>
      <data key="d5">Elementary math problems are designed to assess basic mathematical skills, where AI models have shown significant improvement.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="HIGH SCHOOL MATHEMATICS" target="MATH PROBLEMS">
      <data key="d4">6.0</data>
      <data key="d5">High school mathematics problems present challenges for AI models, indicating areas where performance typically falters.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="COLLEGE MATHEMATICS" target="MATH PROBLEMS">
      <data key="d4">6.0</data>
      <data key="d5">College mathematics problems are complex and often difficult for AI models, highlighting the need for advanced reasoning capabilities.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3-7B" target="HALLUCINATION RATE">
      <data key="d4">7.0</data>
      <data key="d5">The hallucination rate is measured for Orca-3-7B, indicating its performance in generating accurate summaries.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="QUALITY SCORE">
      <data key="d4">7.0</data>
      <data key="d5">The quality score is assigned to Orca-3-7B's summarization outputs, reflecting its effectiveness in generating high-quality summaries.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="ACI-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated using the ACI-Bench dataset, linking its performance to this specific benchmark.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="INSTRUSUM">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is assessed on the InstruSum dataset, indicating its capabilities in instruction-controllable summarization.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="ORCA-SUM">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated on the Orca-Sum benchmark, which tests its summarization and data transformation abilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="MIRAGE">
      <data key="d4">1.0</data>
      <data key="d5">MIRAGE is used to assess the RAG capabilities of Orca-3-7B, linking the model to medical question answering performance.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="DATA TRANSFORMATION">
      <data key="d4">7.0</data>
      <data key="d5">Data transformation techniques are utilized in conjunction with Orca-3-7B to evaluate its ability to follow complex instructions.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-SUM" target="HUGGING FACE">
      <data key="d4">8.0</data>
      <data key="d5">The Orca-Sum benchmark utilizes datasets collected from Hugging Face, linking the platform to the evaluation process.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE DATASETS" target="ORCA-2.5-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-2.5-7B has been evaluated on the MIRAGE datasets to assess its performance in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE DATASETS" target="MEDMEDQA">
      <data key="d4">8.0</data>
      <data key="d5">MedMedQA is one of the datasets included in the MIRAGE collection for evaluating language models.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE DATASETS" target="USMEDMCQA">
      <data key="d4">8.0</data>
      <data key="d5">USMedMCQA is one of the datasets included in the MIRAGE collection for evaluating language models.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE DATASETS" target="PUBMEDQA">
      <data key="d4">8.0</data>
      <data key="d5">PubMedQA is one of the datasets included in the MIRAGE collection for evaluating language models.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="PUBMEDQA" target="RAG">
      <data key="d4">9.0</data>
      <data key="d5">PubMedQA serves as an effective testbed for assessing models' abilities to perform RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AZURE" target="CONTENT HARMS">
      <data key="d4">7.0</data>
      <data key="d5">Azure provides transparency notes that discuss the content harms associated with large language models, highlighting the importance of awareness and mitigation.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="CONTENT HARMS" target="CONTENT MODERATION SERVICES">
      <data key="d4">8.0</data>
      <data key="d5">Content harms can be mitigated through the use of content moderation services, which help manage harmful outputs from AI models.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="CONTENT HARMS" target="REGULATIONS AND STANDARDS">
      <data key="d4">9.0</data>
      <data key="d5">Regulations and standards are necessary to address and prevent content harms associated with AI technologies.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="CONTENT HARMS" target="HALLUCINATION">
      <data key="d4">8.0</data>
      <data key="d5">Hallucination is a specific type of content harm that can mislead users and create misinformation, necessitating caution in AI usage.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="REGULATIONS AND STANDARDS" target="RESEARCH COMMUNITY">
      <data key="d4">1.0</data>
      <data key="d5">The research community plays a vital role in advocating for better regulations and standards in AI technologies to prevent content harms.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AHMED AWADALLAH" target="ORCA 2">
      <data key="d4">8.0</data>
      <data key="d5">Ahmed Awadallah co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ARINDAM MITRA" target="ORCA 2">
      <data key="d4">8.0</data>
      <data key="d5">Arindam Mitra co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="CORBY ROSSET" target="ORCA 2">
      <data key="d4">8.0</data>
      <data key="d5">Corby Rosset co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ISAAC COWHEY" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Isaac Cowhey is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="OREN ETZIONI" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Oren Etzioni is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="TUSHAR KHOT" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Tushar Khot is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ASHISH SABHARWAL" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Ashish Sabharwal is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="CARISSA SCHOENICK" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Carissa Schoenick is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="OYVIND TAFJORD" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Oyvind Tafjord is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="NING DING" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Ning Ding is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="YULIN CHEN" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Yulin Chen is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="BOKAI XU" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Bokai Xu is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ZHI ZHENG" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Zhi Zheng is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="SHENGDING HU" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Shengding Hu is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ZHIYUAN LIU" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Zhiyuan Liu is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ZHAOYE FEI" target="UNEARTHING DOMAIN-SPECIFIC KNOWLEDGE">
      <data key="d4">8.0</data>
      <data key="d5">Zhaoye Fei is involved in unearthing large-scale domain-specific knowledge from public corpora.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="KHIZBULLIN" target="BERNARD GHANEM">
      <data key="d4">8.0</data>
      <data key="d5">Khizbullin and Bernard Ghanem co-authored a work on communicative agents for mind exploration in large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="CAMEL">
      <data key="d4">7.0</data>
      <data key="d5">Camel is a system developed by Khizbullin for exploring large language model societies.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="COSMOPEDIA">
      <data key="d4">6.0</data>
      <data key="d5">Cosmopedia is a project that may involve Khizbullin in creating large-scale synthetic data for pre-training language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="ORCA 2">
      <data key="d4">6.0</data>
      <data key="d5">Orca 2 is a project that may involve Khizbullin in teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="ORCA-MATH">
      <data key="d4">6.0</data>
      <data key="d5">Orca-Math is a project that may involve Khizbullin in enhancing small language models' capabilities in grade school math.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="XTREMEDISTIL">
      <data key="d4">6.0</data>
      <data key="d5">Xtremedistil is a method that may involve Khizbullin in creating massive multilingual models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="DIRECT NASH OPTIMIZATION">
      <data key="d4">6.0</data>
      <data key="d5">Direct Nash Optimization is a method that may involve Khizbullin in teaching language models to self-improve.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="THE CURSE OF RECURSION">
      <data key="d4">1.0</data>
      <data key="d5">The Curse of Recursion is a phenomenon that may involve Khizbullin in understanding the effects of training on generated data.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="BERNARD GHANEM" target="CAMEL">
      <data key="d4">7.0</data>
      <data key="d5">Camel is a system co-developed by Bernard Ghanem for exploring large language model societies.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Yixin Liu co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALEXANDER R. FABBRI" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Alexander R. Fabbri co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="JIAWEN CHEN" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Jiawen Chen co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YILUN ZHAO" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Yilun Zhao co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="SIMENG HAN" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Simeng Han co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="SHAFIQ JOTY" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Shafiq Joty co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="DRAGOMIR RADEV" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Dragomir Radev co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="CHIEN-SHENG WU" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Chien-Sheng Wu co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ARMAN COHAN" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Arman Cohan co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="COSMOPEDIA" target="DANIEL VAN STRIEN">
      <data key="d4">8.0</data>
      <data key="d5">Daniel van Strien co-authored a paper on Cosmopedia, focusing on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="COSMOPEDIA" target="LOUBNA BEN ALLAL">
      <data key="d4">8.0</data>
      <data key="d5">Loubna Ben Allal co-authored a paper on Cosmopedia, focusing on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="COSMOPEDIA" target="ANTON LOZHKOV">
      <data key="d4">8.0</data>
      <data key="d5">Anton Lozhkov co-authored a paper on Cosmopedia, focusing on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="LUCIANO DEL CORRO">
      <data key="d4">8.0</data>
      <data key="d5">Luciano Del Corro co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="SHWETI MAHAJAN">
      <data key="d4">8.0</data>
      <data key="d5">Shweti Mahajan co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="ANDRES CODAS">
      <data key="d4">8.0</data>
      <data key="d5">Andres Codas co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="CLARISSE SIMOES">
      <data key="d4">8.0</data>
      <data key="d5">Clarisse Simoes co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="SAHAJ AGARWAL">
      <data key="d4">8.0</data>
      <data key="d5">Sahaj Agarwal co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="XUXI CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Xuxi Chen co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="ANASTASIA RAZDAIBIEDINA">
      <data key="d4">8.0</data>
      <data key="d5">Anastasia Razdaibiedina co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="ERIK JONES">
      <data key="d4">8.0</data>
      <data key="d5">Erik Jones co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="KRITI AGGARWAL">
      <data key="d4">8.0</data>
      <data key="d5">Kriti Aggarwal co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="HAMID PALANGI">
      <data key="d4">8.0</data>
      <data key="d5">Hamid Palangi co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="GUOQING ZHENG">
      <data key="d4">8.0</data>
      <data key="d5">Guoqing Zheng co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="HAMED KHANPOUR">
      <data key="d4">8.0</data>
      <data key="d5">Hamed Khanpour co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="SAMUEL J. PAECH" target="EQ-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Samuel J. Paech co-authored a paper on EQ-Bench, an emotional intelligence benchmark for large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="NUMERICAL DISCRETE REASONING" target="CRITICAL COMPREHENSION QUESTION">
      <data key="d4">6.0</data>
      <data key="d5">Both types of questions assess different aspects of comprehension and reasoning skills.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="CRITICAL COMPREHENSION QUESTION" target="EVALUATIVE COMPREHENSION QUESTION">
      <data key="d4">7.0</data>
      <data key="d5">Both question types require analysis of the text's arguments or themes.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="EVALUATIVE COMPREHENSION QUESTION" target="VOCABULARY AND LANGUAGE USE">
      <data key="d4">5.0</data>
      <data key="d5">Vocabulary questions can support evaluative comprehension by testing understanding of key terms.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="RELATIONSHIP COMPREHENSION QUESTION" target="SEQUENCING EVENTS">
      <data key="d4">6.0</data>
      <data key="d5">Both question types involve organizing information based on the text's content.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="STRENGTHEN" target="WEAKEN">
      <data key="d4">7.0</data>
      <data key="d5">Both types of questions focus on evaluating the strength of arguments presented in the text.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="ASSUMPTION" target="FLAW">
      <data key="d4">7.0</data>
      <data key="d5">Assumption and flaw questions both analyze the underlying logic of arguments in the text.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="FLAW" target="METHOD OF REASONING">
      <data key="d4">6.0</data>
      <data key="d5">Method of reasoning questions can help identify flaws in the argument's construction.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="INFERENCE" target="PRINCIPLE">
      <data key="d4">6.0</data>
      <data key="d5">Inference questions often rely on recognizing principles that underlie the text's arguments.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="PARAPHRASING" target="TEXT SIMPLIFICATION">
      <data key="d4">7.0</data>
      <data key="d5">Both text modification types aim to alter the original text while maintaining its meaning.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT SIMPLIFICATION" target="TEXT EXPANSION">
      <data key="d4">6.0</data>
      <data key="d5">Text expansion can complement simplification by adding detail while making it easier to understand.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT TRANSLATION" target="TEXT ANNOTATION">
      <data key="d4">5.0</data>
      <data key="d5">Both processes involve modifying text for clarity and understanding in different contexts.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="KEYWORD REPLACEMENT" target="TEXT REMOVING">
      <data key="d4">5.0</data>
      <data key="d5">Both text modification types involve altering the original text for specific purposes.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="INSTRUCTION TAXONOMY" target="TEXT MODIFICATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The text modification flow is guided by the instruction taxonomy, which categorizes different modification techniques.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="GROUND TRUTH" target="ACCURACY SCORES">
      <data key="d4">1.0</data>
      <data key="d5">Ground truth is essential for calculating accuracy scores, as it provides the standard for comparison.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="ERROR ANALYSIS" target="FINAL VERDICT">
      <data key="d4">1.0</data>
      <data key="d5">Error analysis leads to the final verdict, determining the correctness of the student's answer based on the comparison.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="ELLIOT" target="ALEX">
      <data key="d4">8.0</data>
      <data key="d5">Elliot has confessed his feelings to Alex, who is already in a relationship, creating emotional conflict for Elliot.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ELLIOT" target="EMOTIONS">
      <data key="d4">9.0</data>
      <data key="d5">Elliot experiences a range of emotions including resignation, anger, hopefulness, and embarrassment after confessing to Alex.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ELLIOT" target="SCORES">
      <data key="d4">9.0</data>
      <data key="d5">Elliot's emotions are quantified by scores that reflect the intensity of each feeling he experiences after his confession.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMOTIONS" target="RESIGNED">
      <data key="d4">7.0</data>
      <data key="d5">Resigned is one of the emotions felt by Elliot, indicating acceptance of his situation.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMOTIONS" target="ANGRY">
      <data key="d4">6.0</data>
      <data key="d5">Angry is one of the emotions felt by Elliot, indicating frustration with himself.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMOTIONS" target="HOPEFUL">
      <data key="d4">6.0</data>
      <data key="d5">Hopeful is one of the emotions felt by Elliot, indicating a desire for a positive outcome with Alex.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMOTIONS" target="EMBARRASSED">
      <data key="d4">7.0</data>
      <data key="d5">Embarrassed is one of the emotions felt by Elliot, indicating discomfort for putting Alex in an awkward position.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="RESIGNED" target="RESIGNED SCORE">
      <data key="d4">8.0</data>
      <data key="d5">The resigned emotion is quantified by a score of 7, indicating its intensity in Elliot's emotional state.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ANGRY" target="ANGRY SCORE">
      <data key="d4">8.0</data>
      <data key="d5">The angry emotion is quantified by a score of 3, indicating its intensity in Elliot's emotional state.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HOPEFUL" target="HOPEFUL SCORE">
      <data key="d4">8.0</data>
      <data key="d5">The hopeful emotion is quantified by a score of 5, indicating its intensity in Elliot's emotional state.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMBARRASSED" target="EMBARRASSED SCORE">
      <data key="d4">1.0</data>
      <data key="d5">The embarrassed emotion is quantified by a score of 8, indicating its intensity in Elliot's emotional state.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
  </graph>
</graphml>