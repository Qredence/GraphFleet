<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d6" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d5" for="edge" attr.name="description" attr.type="string" />
  <key id="d4" for="edge" attr.name="weight" attr.type="double" />
  <key id="d3" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d2" for="node" attr.name="source_id" attr.type="string" />
  <key id="d1" for="node" attr.name="description" attr.type="string" />
  <key id="d0" for="node" attr.name="type" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="GRAPH RAG APPROACH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Graph RAG approach is a method for query-focused summarization that combines retrieval-augmented generation with a graph-based text index to improve the comprehensiveness and diversity of generated answers over large text corpora.
The Graph RAG approach is a method for processing text data that focuses on global summarization using a knowledge graph derived from LLM outputs.
The Graph RAG approach is a method for automating the generation of questions based on dataset descriptions, utilizing a structured pipeline for processing and analysis.
The Graph RAG approach is a method for processing text data that combines knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) to support human sensemaking over entire text corpora.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Query-focused summarization (QFS) is a task that aims to generate summaries based on specific user queries, rather than simply retrieving text excerpts.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Large language models (LLMs) are advanced AI models designed to understand and generate human-like text, often used for tasks like summarization and question answering.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="SOURCE DOCUMENTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Source documents are the original texts from which information is extracted for processing in the Graph RAG approach.
Source documents are the original texts from which input texts are extracted for processing in the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="COMMUNITY SUMMARIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Community summaries are condensed representations of groups of closely-related entities, generated to provide partial responses to user queries.
Community summaries are aggregated descriptions of elements within a community, used to generate answers to user queries.
Community summaries are condensed representations of information derived from the original texts, aimed at improving response quality in the Graph RAG approach.
Community summaries are aggregated insights derived from groups within a knowledge graph, providing a high-level overview of information.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,4930fce6da868f894757a9da465807ba,ac21ebe9a9d70d691c717f961d3f10c8,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="MICROSOFT RESEARCH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Research is a division of Microsoft focused on advancing the state of the art in computing through research and innovation.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Strategic Missions and Technologies is a division within Microsoft that focuses on strategic initiatives and technological advancements.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="MICROSOFT OFFICE OF THE CTO">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Office of the CTO is a division that oversees technological strategy and innovation within Microsoft.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="DARREN EDGE">
      <data key="d0">PERSON</data>
      <data key="d1">Darren Edge is a researcher affiliated with Microsoft Research, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="HA TRINH">
      <data key="d0">PERSON</data>
      <data key="d1">Ha Trinh is a researcher affiliated with Microsoft Research, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="NEWMAN CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Newman Cheng is a researcher affiliated with Microsoft Strategic Missions and Technologies, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="JOSHUA BRADLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Bradley is a researcher affiliated with Microsoft Strategic Missions and Technologies, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="ALEX CHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Chao is a researcher affiliated with Microsoft Office of the CTO, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="APURVA MODY">
      <data key="d0">PERSON</data>
      <data key="d1">Apurva Mody is a researcher affiliated with Microsoft Office of the CTO, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="STEVEN TRUITT">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Truitt is a researcher affiliated with Microsoft Strategic Missions and Technologies, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="JONATHAN LARSON">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Larson is a researcher affiliated with Microsoft Research, contributing to advancements in AI and summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Retrieval-augmented generation (RAG) is an approach that combines retrieval of relevant information from external sources with generative models to answer user queries.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="GLOBAL SENSEMAKING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Global sensemaking refers to the process of understanding and interpreting large datasets to derive insights that go beyond the explicit information contained within the texts.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="COMMUNITY DETECTION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Community detection is a method used to identify groups of closely-related entities within a dataset, facilitating more efficient summarization and analysis.
Community detection is the process of identifying groups of nodes in a network that are more densely connected to each other than to the rest of the network.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LEIDEN ALGORITHM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Leiden algorithm is a specific method used for community detection in networks, known for its efficiency and accuracy in identifying clusters.
The Leiden algorithm is a community detection method known for efficiently recovering hierarchical structures in large-scale graphs.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TOKEN RANGE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Token range refers to the number of tokens (words or characters) in a dataset, which can impact the performance of summarization techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Query-focused abstractive summarization is a task that aims to summarize content based on specific queries, often requiring handling large volumes of text.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LLM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">LLM (Large Language Model) refers to advanced AI models capable of understanding and generating human-like text, used in various applications including summarization.
LLM (Large Language Model) refers to advanced AI models designed to understand and generate human-like text based on input prompts.
LLM stands for Large Language Model, which is an AI model designed to understand and generate human-like text based on input data.
LLM (Large Language Model) refers to advanced AI models designed to understand and generate human-like text based on input data.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TEXT CHUNKS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Text chunks are segments of input texts extracted from source documents, which are processed for further analysis.
</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="KURATOV ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Kuratov et al. (2024) is a reference to a study discussing the limitations of LLM context windows in processing longer text chunks.
Kuratov et al. (2024) is a reference to a study discussing the performance of longer text chunks in language models.
Kuratov et al. (2024) is a reference to a study or work that discusses the performance of algorithms in relation to text chunk processing.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LIU ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Liu et al. (2023) is a reference to a study discussing the limitations of LLM context windows in processing longer text chunks.
Liu et al. (2023) is a reference to a study that examines the combination of search algorithms with language model agents.
Liu et al. (2023) is a reference to a study discussing search spaces and their designs in the context of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,64476a39d7d8b87b399e3bd3cead79c7,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="HOTPOTQA">
      <data key="d0">DATASET</data>
      <data key="d1">HotPotQA is a dataset used for evaluating question answering systems, particularly in the context of entity reference detection.
HotPotQA is a dataset used for evaluating question-answering systems, requiring reasoning over multiple documents to answer questions.
HotpotQA is a dataset used to evaluate the reasoning capabilities of language models, including LATS, by measuring exact match scores.
HotPotQA is a multi-hop question-answering benchmark that requires retrieval over multiple Wikipedia passages to answer questions.
HotPotQA is a question-answering dataset that evaluates the ability of models to reason and retrieve information from multiple sources.
HotPotQA is a question-answering task that evaluates the reasoning ability of models based on their performance in answering complex questions.
HotpotQA is a dataset designed for diverse, explainable multi-hop question answering.
HotPotQA is a dataset used for evaluating question answering systems, particularly in the context of reasoning tasks.
HotPotQA is a question-answering dataset that requires reasoning over multiple supporting documents to answer questions, containing 113k diverse, multi-hop, and explainable question-answer pairs crafted by crowdworkers.
HotPotQA is a dataset used for evaluating question answering systems, particularly in multi-hop reasoning tasks.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,64476a39d7d8b87b399e3bd3cead79c7,8180bf20b7577f3eee40df5991e2886d,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="COMMUNITY DETECTION ALGORITHMS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Community detection algorithms are methods used to identify and partition graphs into modular communities of closely-related nodes.
Community detection algorithms are methods used to identify groups of closely related nodes within a graph.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="MODULARITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Modularity is a property of a graph that measures the strength of division of a network into modules or communities.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LLAMA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Llama is a series of large language models designed for efficient text processing and generation, capable of handling various natural language tasks.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="GEMINI">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Gemini is a series of advanced language models that utilize in-context learning to summarize and process text effectively.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="ACHIAM ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Achiam et al. (2023) is a reference to a study discussing the capabilities of the GPT series in summarization tasks.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="BROWN ET AL. (2020)">
      <data key="d0">PERSON</data>
      <data key="d1">Brown et al. (2020) is a reference to a study that discusses the foundational aspects of large language models, including their training and applications.
Brown et al. (2020) is a reference to a study discussing the capabilities of language models as few-shot learners.
Brown et al. (2020) is a reference to a study that discusses the capabilities of language models.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,93cb0d0456e0822b5fe30a3e627405f8,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TOUVRON ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Touvron et al. (2023) is a reference to a study that discusses the Llama series of models and their performance in various tasks.
Touvron et al. (2023) is a reference to a study that discusses advancements in language models.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="ANIL ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Anil et al. (2023) is a reference to a study that discusses the Gemini series of models and their capabilities in text processing.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="GPT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="NAMED ENTITIES">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Named entities are specific categories of information such as people, places, and organizations that are extracted from text.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="FEW-SHOT EXAMPLES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Few-shot examples are specific instances provided to the LLM to improve its performance in specialized domains by offering context and guidance.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="COVARIATES">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Covariates are additional variables or attributes associated with extracted entities, such as claims linked to those entities.
</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="EXTRACTION PROMPT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">An extraction prompt is a specific instruction given to the LLM to guide it in identifying and extracting relevant information from text.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="GLEANINGS">
      <data key="d0">PROCESS</data>
      <data key="d1">Gleanings refer to multiple rounds of extraction attempts aimed at identifying any missed entities in the text.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Abstractive summarization is a method where the LLM generates concise summaries that capture the essence of the original text, including implied relationships.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ENTITY GRAPH">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">An entity graph is a representation of entities and their relationships, structured as nodes and edges to illustrate connections.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="MULTIHOP-RAG DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The MultiHop-RAG dataset is a collection of data used for testing and evaluating the performance of the Graph RAG approach.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HIERARCHICAL CLUSTERING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Hierarchical clustering is a method of organizing data into a hierarchy of clusters based on similarity.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="GLOBAL SUMMARIZATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Global summarization refers to the process of creating comprehensive summaries that capture the overall structure and semantics of a dataset.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="NODE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">A node is an individual entity within a graph, representing a specific item or concept connected to other nodes through relationships.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="EDGE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">An edge is a connection between two nodes in a graph, representing the relationship or interaction between those entities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="CLAIMS">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Claims are assertions or statements linked to entities, providing additional context or information about them.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="GRAPH INDEX">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LEAF-LEVEL COMMUNITIES">
      <data key="d0">COMMUNITY STRUCTURE</data>
      <data key="d1">Leaf-level communities are the lowest hierarchical level in a community structure, where element summaries are prioritized and added to the LLM context window for processing.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="HIGHER-LEVEL COMMUNITIES">
      <data key="d0">COMMUNITY STRUCTURE</data>
      <data key="d1">Higher-level communities are the upper hierarchical levels in a community structure, which summarize element summaries and manage sub-communities based on token limits.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="LLM CONTEXT WINDOW">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The LLM context window is a limit on the amount of information that can be processed at one time, affecting how summaries and answers are generated.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="GLOBAL ANSWER">
      <data key="d0">OUTPUT</data>
      <data key="d1">The global answer is the final response generated for a user query, synthesized from community summaries and evaluated for helpfulness.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="USER QUERY">
      <data key="d0">REQUEST</data>
      <data key="d1">A user query is a question posed by a user seeking information or insights from the community summaries.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="DATASET EXAMPLES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Dataset examples are specific instances of data used to illustrate potential user tasks and questions in the context of information retrieval.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="PODCAST TRANSCRIPTS">
      <data key="d0">DATASET</data>
      <data key="d1">Podcast transcripts are written records of conversations between technology leaders, used as a dataset for analysis and question generation.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="NEWS ARTICLES">
      <data key="d0">DATASET</data>
      <data key="d1">News articles are written reports on current events, used as a dataset for analysis and question generation in various categories.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="EVALUATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Evaluation is the process of assessing the effectiveness of RAG systems in generating high-level understanding questions from datasets.
Evaluation is the process of assessing the performance or effectiveness of a model or technique in specific tasks or domains.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="NODES">
      <data key="d0">DATA ELEMENT</data>
      <data key="d1">Nodes are the individual elements or entities within a community structure that represent distinct points of interest or data.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="EDGES">
      <data key="d0">DATA ELEMENT</data>
      <data key="d1">Edges are the connections between nodes in a community structure, indicating relationships or interactions between the entities.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="SUB-COMMUNITIES">
      <data key="d0">COMMUNITY STRUCTURE</data>
      <data key="d1">Sub-communities are smaller groups within higher-level communities that can be summarized and substituted to fit within the LLM context window.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="DATASET">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A dataset is a collection of related data that can be analyzed to generate insights or questions, often used in machine learning and data analysis.
A dataset is a collection of data used for analysis and training in machine learning and AI.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="USER">
      <data key="d0">PERSON</data>
      <data key="d1">A user is an individual or entity that interacts with the dataset and LLM to generate questions or perform tasks related to data analysis.
The User is an individual seeking assistance in creating a diet plan and tracking their meals.
The individual requesting the creation of a vegetarian meal plan and providing feedback on the meal plan's success.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a,26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="TASK">
      <data key="d0">ACTIVITY</data>
      <data key="d1">A task is a specific activity or job that a user aims to accomplish using the dataset and LLM, often involving question generation or data interpretation.
</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="QUESTION">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A question is an inquiry generated by the LLM that requires understanding of the dataset and its contents for a comprehensive answer.
The question is the prompt or problem presented to the student, requiring a response based on the provided options.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="EVALUATION METRICS">
      <data key="d0">CRITERIA</data>
      <data key="d1">Evaluation metrics are standards or criteria used to assess the quality and effectiveness of the generated answers or questions.
Evaluation metrics are quantitative measures used to assess the performance of models and systems in various tasks, including summarization and generation.
Evaluation metrics are quantitative measures, such as success rate or F1 score, used to assess the performance of the generated agents.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,26b2dad01a219bc034ac7d6a32d07582,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COMPREHENSIVENESS">
      <data key="d0">CRITERIA</data>
      <data key="d1">Comprehensiveness is a metric that measures how thoroughly an answer covers all aspects of a question.
Comprehensiveness is a metric used to evaluate the quality of responses, indicating how well the responses cover the necessary information.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DIVERSITY">
      <data key="d0">CRITERIA</data>
      <data key="d1">Diversity is a metric that evaluates the variety and richness of perspectives provided in an answer.
Diversity is a metric used to evaluate the quality of responses, indicating the variety of responses generated from the same input.
Diversity refers to the variety and range of generated problems or instructions, which is a key goal of the agentic flows.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="EMPOWERMENT">
      <data key="d0">CRITERIA</data>
      <data key="d1">Empowerment is a metric that assesses how well an answer helps the reader understand and make informed judgments about a topic.
Empowerment is a metric used to evaluate the quality of responses, indicating how well the responses enable user understanding or action.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DIRECTNESS">
      <data key="d0">CRITERIA</data>
      <data key="d1">Directness is a metric that measures how clearly and specifically an answer addresses the question posed.
Directness is a metric used to evaluate the quality of responses, indicating how straightforward and clear the responses are.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C0">
      <data key="d0">GRAPH COMMUNITY</data>
      <data key="d1">C0 is the root-level community summary used to answer user queries, representing the highest level of abstraction in the Graph RAG approach.
</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C1">
      <data key="d0">GRAPH COMMUNITY</data>
      <data key="d1">C1 is a high-level community summary that provides answers to queries, serving as sub-communities of C0 when available.
C1 is a condition used in the Graph RAG approach to evaluate performance metrics across datasets and comparisons.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C2">
      <data key="d0">GRAPH COMMUNITY</data>
      <data key="d1">C2 is an intermediate-level community summary that answers queries, serving as sub-communities of C1 when available.
C2 is a condition used in the Graph RAG approach to evaluate performance metrics across datasets and comparisons.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C3">
      <data key="d0">GRAPH COMMUNITY</data>
      <data key="d1">C3 is a low-level community summary that provides the greatest number of answers to queries, serving as sub-communities of C2 when available.
C3 is a condition used in the Graph RAG approach to evaluate performance metrics across datasets and comparisons.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="TS">
      <data key="d0">METHOD</data>
      <data key="d1">TS refers to a text summarization method that applies a map-reduce approach directly to source texts for generating summaries.
TS refers to the global text summarization condition used for comparison against the Graph RAG conditions.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="SS">
      <data key="d0">METHOD</data>
      <data key="d1">SS is a na &#239;ve semantic search RAG approach that retrieves text chunks and adds them to the context window until a specified token limit is reached.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PODCAST DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The Podcast dataset is a specific dataset used in the evaluation of the Graph RAG approach, characterized by its unique content and structure.
The Podcast dataset consists of transcripts used for evaluating the performance of the Graph RAG approach in terms of summarization and response quality.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="NEWS DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The News dataset is another specific dataset used in the evaluation of the Graph RAG approach, characterized by its unique content and structure.
The News dataset consists of articles used for evaluating the performance of the Graph RAG approach in terms of summarization and response quality.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="GRAPH COMMUNITIES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="SOURCE TEXTS">
      <data key="d0" />
      <data key="d1">
Source texts are the original documents or data from which information is extracted for processing in the Graph RAG approach.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="TAYLOR SWIFT">
      <data key="d0">PERSON</data>
      <data key="d1">Taylor Swift is a prominent musician known for her significant contributions to the music industry and her influence on popular culture.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TRAVIS KELCE">
      <data key="d0">PERSON</data>
      <data key="d1">Travis Kelce is a well-known athlete, recognized for his achievements in sports and his impact on popular culture.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="BRITNEY SPEARS">
      <data key="d0">PERSON</data>
      <data key="d1">Britney Spears is a famous musician and public figure, noted for her influence in the music industry and her personal life controversies.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="JUSTIN TIMBERLAKE">
      <data key="d0">PERSON</data>
      <data key="d1">Justin Timberlake is a renowned musician and entertainer, recognized for his contributions to music and his public persona.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PUBLIC FIGURES">
      <data key="d0">CATEGORY</data>
      <data key="d1">Public figures are individuals who have gained significant attention and influence in various sectors, including entertainment, sports, and media.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTERTAINMENT ARTICLES">
      <data key="d0">MEDIA FORMAT</data>
      <data key="d1">Entertainment articles are written pieces that cover various aspects of the entertainment industry, including news about public figures and cultural trends.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="COACHES">
      <data key="d0">CATEGORY</data>
      <data key="d1">Coaches are individuals who train and guide athletes, playing a significant role in sports and team dynamics.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="INFLUENCERS">
      <data key="d0">CATEGORY</data>
      <data key="d1">Influencers are individuals who have the power to affect the purchasing decisions of others due to their authority, knowledge, position, or relationship with their audience.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTREPRENEURS">
      <data key="d0">CATEGORY</data>
      <data key="d1">Entrepreneurs are individuals who create and manage businesses, often influencing trends and economic landscapes.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="CULTURAL NARRATIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Cultural narratives are the stories and themes that shape societal values and beliefs, often influenced by public figures in entertainment.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="SOCIAL DISCUSSIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Social discussions are conversations and debates that occur in public discourse, often involving topics related to public figures and their influence.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ATHLETES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="GRAPH RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Graph RAG is a method for processing and summarizing text data using a graph-based approach to improve comprehensiveness and diversity in responses.
Graph RAG is a method for processing and summarizing text data, emphasizing efficiency and scalability in comparison to traditional source text summarization methods.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="CONTEXT WINDOW SIZE">
      <data key="d0">PARAMETER</data>
      <data key="d1">Context window size refers to the number of tokens that can be processed at once by the model, affecting the performance of the Graph RAG approach.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="WIN RATE">
      <data key="d0">METRIC</data>
      <data key="d1">Win rate is a performance metric indicating the percentage of successful outcomes in comparisons between different conditions.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="TOKEN COUNT">
      <data key="d0">METRIC</data>
      <data key="d1">Token count refers to the number of tokens processed or generated in the context of the Graph RAG approach.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="COMMUNITY SUMMARY LEVEL">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Community summary levels refer to the hierarchical structure of summaries generated from the original texts in the Graph RAG approach.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="SOURCE TEXT SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Source text summarization refers to the process of condensing original texts into shorter summaries while retaining essential information.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="PODCAST INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Podcast intermediate-level summaries are summaries derived from podcast content, aimed at providing a balanced overview of the material.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="NEWS LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">News low-level community summaries are concise summaries of news articles, focusing on community-related content.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="EMPOWERMENT COMPARISONS">
      <data key="d0">ANALYSIS</data>
      <data key="d1">Empowerment comparisons analyze the effectiveness of different summarization approaches in helping users achieve informed understanding.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="AD-HOC LLM USE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Ad-hoc LLM use involves employing large language models for specific tasks, such as analyzing reasoning and providing examples or citations.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SELF-MEMORY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Self-memory refers to a mechanism in which generated summaries serve as a memory aid for future retrieval and generation tasks.
Self-memory refers to a mechanism in retrieval-augmented generation that allows models to retain and utilize past information for generating relevant responses.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GENERATING HIERARCHICAL INDEX">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Generating a hierarchical index involves organizing text chunks into a structured format to facilitate efficient retrieval and summarization.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="KNOWLEDGE GRAPH">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">A knowledge graph is a structured representation of information that captures relationships between entities, often used for enhancing AI understanding.
Knowledge graphs are structured representations of knowledge that can be enhanced using large language models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GRAPH DATABASES">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Graph databases are specialized databases designed to store and manage graph structures, enabling efficient querying and analysis of relationships.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="LANGCHAIN">
      <data key="d0">SOFTWARE</data>
      <data key="d1">LangChain is a software library that supports the development of applications utilizing large language models and graph databases.
LangChain is a framework for building applications with language models, including graph-based functionalities.
LangChain is an open-source framework that facilitates the building of agentic systems by providing existing building blocks for development.
LangChain is a framework that provides tools and components for building applications with language models, which can be utilized in ADAS.
LangChain is a framework for building context-aware reasoning applications, enabling developers to create applications that can understand and utilize context effectively, as mentioned in resources from LangChainAI in 2022.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6109537356a2ce2339f77c827aa3668e,6bdf681c0bd9e401ac72344a6a0ae479,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="LLAMAINDEX">
      <data key="d0">SOFTWARE</data>
      <data key="d1">LlamaIndex is a software library that facilitates the integration of large language models with graph-based data structures.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="NA&#207;VE RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Na&#239;ve RAG refers to basic retrieval-augmented generation methods that convert documents to text and split them into chunks for embedding in a vector space.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="PRE-RETRIEVAL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Pre-retrieval is a strategy in advanced RAG systems that involves preparing data before the retrieval process to improve efficiency and accuracy.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="RETRIEVAL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Retrieval is the process of fetching relevant information from a dataset or external source to assist in generating responses.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="POST-RETRIEVAL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Post-retrieval refers to strategies applied after the retrieval process to refine or enhance the generated output.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="MODULAR RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Modular RAG systems incorporate patterns for iterative and dynamic cycles of retrieval and generation, improving the overall process of information synthesis.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="MULTI-DOCUMENT SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-document summarization involves condensing information from multiple sources into a coherent summary, often using advanced techniques like RAG.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-hop question answering refers to the ability of a system to answer questions that require information from multiple sources or steps.
Multi-hop Question Answering is a task in AI that involves answering questions that require reasoning across multiple pieces of information.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="HIERARCHICAL INDEX">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">A hierarchical index organizes data in a tree-like structure, facilitating efficient retrieval and summarization of information.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TEXT EMBEDDINGS">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Text embeddings are numerical representations of text data that capture semantic meaning, often used in machine learning and natural language processing.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="VECTOR SPACE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Vector space is a mathematical representation where text data is transformed into vectors for similarity comparisons and retrieval tasks.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="KAPING">
      <data key="d0">PERSON</data>
      <data key="d1">KAPING refers to a study or work that discusses advanced RAG systems and their applications in knowledge graph contexts.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TRAJANOSKA ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Trajanoska et al. (2023) is a reference to a study that explores the use of LLMs for knowledge graph creation and completion.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="YAO ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Yao et al. (2023) is a reference to a study that discusses the extraction of causal graphs from source texts using LLMs.
Yao et al. (2023) is a reference to a study that discusses the ReAct technique and its applications in language models.
Yao et al. (2023) is a reference to a study that discusses various prompting methods and their performance in language models.
Yao et al. (2023) is a reference to a study or work that proposes the Wikipedia web API and discusses its application in the context of LATS.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,c95e02c0dca4a4a36b701cbc7dd14da6,edab4014b8f55e5b25bd7f396314be1f,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="BAN ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Ban et al. (2023) is a reference to a study that focuses on the extraction of causal graphs from textual data.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="ZHANG ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang et al. (2024) is a reference to a study that discusses advancements in the extraction of causal graphs from source texts.
Zhang et al. (2024) is a reference to a study on AgentOptimizer, which learns tools used in agents.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="G-RETRIEVER">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">G-Retriever is a system that focuses on retrieving subsets of graph structures for enhanced information retrieval tasks.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GRAPH-TOOLFORMER">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Graph-ToolFormer is a method that utilizes derived graph metrics for various analytical tasks in the context of RAG.
Graph-toolformer is a system designed to empower large language models with graph reasoning abilities through prompts augmented by ChatGPT.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SURGE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">SURGE is a system that emphasizes narrative outputs grounded in the facts of retrieved subgraphs for enhanced storytelling.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="FABULA">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">FABULA is a method that serializes event-plot sub-graphs using narrative templates to create coherent stories.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="WANG ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Wang et al. (2023) is a reference to a study that discusses systems supporting the creation and traversal of text-relationship graphs for multi-hop question answering.)&lt;|COMPLETE|&gt;
Wang et al. (2023) is a reference to a study that discusses the adaptation of language models in interactive environments.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="KNOWLEDGE GRAPHS">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Knowledge graphs are structured representations of information that allow for reasoning and querying over interconnected data points.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="NATURAL MODULARITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Natural modularity refers to the inherent structure within graphs that allows for effective partitioning of data for summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SENSEMAKING QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Sensemaking questions are inquiries designed to extract meaningful insights from data, guiding the analysis process.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GRAPH-FREE APPROACH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The graph-free approach is a method of summarizing source texts without utilizing graph structures, often employing map-reduce techniques.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="OPEN-SOURCE IMPLEMENTATION">
      <data key="d0">SOFTWARE</data>
      <data key="d1">An open-source implementation refers to publicly available software that allows users to access and modify the Graph RAG approaches.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Alonso Guevara Fern&#225;ndez is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="AMBER HOAK">
      <data key="d0">PERSON</data>
      <data key="d1">Amber Hoak is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d0">PERSON</data>
      <data key="d1">Andr&#233;s Morales Esquivel is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BEN CUTLER">
      <data key="d0">PERSON</data>
      <data key="d1">Ben Cutler is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BILLIE RINALDI">
      <data key="d0">PERSON</data>
      <data key="d1">Billie Rinaldi is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRIS SANCHEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Sanchez is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRIS TREVI&#209;O">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Trevi&#241;o is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRISTINE CAGGIANO">
      <data key="d0">PERSON</data>
      <data key="d1">Christine Caggiano is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DAVID TITTSWORTH">
      <data key="d0">PERSON</data>
      <data key="d1">David Tittsworth is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DAYENNE DE SOUZA">
      <data key="d0">PERSON</data>
      <data key="d1">Dayenne de Souza is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DOUGLAS ORBAKER">
      <data key="d0">PERSON</data>
      <data key="d1">Douglas Orbaker is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ED CLARK">
      <data key="d0">PERSON</data>
      <data key="d1">Ed Clark is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GABRIEL NIEVES-PONCE">
      <data key="d0">PERSON</data>
      <data key="d1">Gabriel Nieves-Ponce is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GAUDY BLANCO MENES">
      <data key="d0">PERSON</data>
      <data key="d1">Gaudy Blanco Meneses is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATE LYTVYNETS">
      <data key="d0">PERSON</data>
      <data key="d1">Kate Lytvynets is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATY SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Katy Smith is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="M&#211;NICA CARVAJAL">
      <data key="d0">PERSON</data>
      <data key="d1">M&#243;nica Carvajal is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="NATHAN EVANS">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Evans is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RICHARD ORTEGA">
      <data key="d0">PERSON</data>
      <data key="d1">Richard Ortega is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RODRIGO RACANICCI">
      <data key="d0">PERSON</data>
      <data key="d1">Rodrigo Racanicci is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SARAH SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Smith is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SHANE SOLOMON">
      <data key="d0">PERSON</data>
      <data key="d1">Shane Solomon is one of the contributors to the work on the Graph RAG approach.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="FABRICATION RATES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Fabrication rates refer to the frequency of inaccuracies or false information generated by language models, which is crucial for assessing their performance.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Query-focused summarization is a method that tailors summaries based on specific queries, enhancing the relevance of the information presented.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="HYBRID RAG SCHEMES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Hybrid RAG schemes combine different retrieval-augmented generation techniques to improve the efficiency and effectiveness of information retrieval.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="EMBEDDING-BASED MATCHING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Embedding-based matching is a technique that uses vector representations of data to find relevant information based on user queries.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="MAP-REDUCE SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Map-reduce summarization is a computational approach that processes large datasets by dividing them into smaller chunks for efficient summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Hierarchical community structure refers to the organization of data into nested groups, facilitating better analysis and understanding of relationships within the data.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="TOKEN COST">
      <data key="d0">CONCEPT</data>
      <data key="d1">Token cost refers to the computational expense associated with processing text data in language models, impacting the efficiency of various approaches.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHENG ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Cheng et al. (2024) is a reference to a study on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DANG H. T. (2006)">
      <data key="d0">PERSON</data>
      <data key="d1">Dang H. T. (2006) is a reference to a study evaluating question-focused summarization systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ES ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Es et al. (2023) is a reference to a study on automated evaluation of retrieval-augmented generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FENG ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Feng et al. (2023) is a reference to a study on retrieval-generation synergy augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FORTUNATO S. (2010)">
      <data key="d0">PERSON</data>
      <data key="d1">Fortunato S. (2010) is a reference to a study on community detection in graphs.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GAO ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Gao et al. (2023) is a reference to a survey on retrieval-augmented generation for large language models.
Gao et al. (2023) is a reference to a study that discusses prompting techniques for language models.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GOODWIN ET AL. (2020)">
      <data key="d0">PERSON</data>
      <data key="d1">Goodwin et al. (2020) is a reference to a study comparing transformers on multi-document abstractive summarization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HE ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">He et al. (2024) is a reference to a study on retrieval-augmented generation for textual graph understanding.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JACOMY ET AL. (2014)">
      <data key="d0">PERSON</data>
      <data key="d1">Jacomy et al. (2014) is a reference to a study on a graph layout algorithm for network visualization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIN ET AL. (2021)">
      <data key="d0">PERSON</data>
      <data key="d1">Jin et al. (2021) is a reference to a survey of community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KANG ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Kang et al. (2023) is a reference to a study on knowledge graph-augmented language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KHATTAB ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Khattab et al. (2022) is a reference to a study on composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KIM ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Kim et al. (2023) is a reference to a study on answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KLEIN ET AL. (2006)">
      <data key="d0">PERSON</data>
      <data key="d1">Klein et al. (2006) is a reference to a study on sensemaking perspectives.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KOESTEN ET AL. (2021)">
      <data key="d0">PERSON</data>
      <data key="d1">Koesten et al. (2021) is a reference to a study on understanding data sensemaking behaviors.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1">Language models are statistical models that predict the next word in a sequence, playing a crucial role in natural language processing tasks.
Language models are algorithms designed to understand and generate human language, often trained on large datasets.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED TEXT GENERATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="QUESTION-FOCUSED SUMMARIZATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="AUTOMATED EVALUATION">
      <data key="d0" />
      <data key="d1">Automated evaluation refers to the use of algorithms and metrics to assess the quality of generated text without human intervention.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="RETRIEVAL-GENERATION SYNERGY">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SURVEY ON RETRIEVAL-AUGMENTED GENERATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TRANSFORMERS">
      <data key="d0" />
      <data key="d1">Transformers are a type of neural network architecture that has become the foundation for many state-of-the-art models in natural language processing.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="TEXTUAL GRAPH UNDERSTANDING">
      <data key="d0" />
      <data key="d1">Textual graph understanding involves interpreting and analyzing information represented in graph structures derived from text.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TASK</data>
    </node>
    <node id="GRAPH LAYOUT ALGORITHM">
      <data key="d0" />
      <data key="d1">Graph layout algorithms are methods used to visualize graph structures in a way that highlights relationships and patterns among nodes.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="COMMUNITY DETECTION APPROACHES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KNOWLEDGE-GROUNDED DIALOGUE">
      <data key="d0" />
      <data key="d1">Knowledge-grounded dialogue refers to conversational systems that utilize external knowledge sources to provide contextually relevant responses.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TASK</data>
    </node>
    <node id="RETRIEVAL AND LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1">The integration of retrieval and language models involves combining information retrieval techniques with language generation capabilities for improved performance.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AMBIGUOUS QUESTIONS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SENSEMAKING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DATA SENSEMAKING">
      <data key="d0" />
      <data key="d1">Data sensemaking refers to the process of interpreting and understanding data to derive insights and inform decision-making.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SEQ2SEQ MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Sequence-to-sequence (seq2seq) models are a type of neural network architecture used for tasks such as translation and summarization, where input sequences are transformed into output sequences.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FAST UNFOLDING OF COMMUNITIES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Fast unfolding of communities is a method for detecting community structures in large networks, as discussed by Blondel et al. (2008).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Retrieval-augmented generation is a technique that combines retrieval of relevant information with generation of text, enhancing the quality of generated outputs.
Retrieval-augmented generation is a technique that combines retrieval of information with generative models to enhance performance on knowledge-intensive NLP tasks, as discussed in a paper by Patrick Lewis and others in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MULTI-DOCUMENT ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">Multi-document abstractive summarization is the task of generating concise summaries from multiple documents, capturing the main ideas and information.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="EVALUATION OF QUESTION-FOCUSED SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">Evaluation of question-focused summarization involves assessing the effectiveness of summarization systems that target specific questions.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d0">CONFERENCE</data>
      <data key="d1">Neural Information Processing Systems (NeurIPS) is a prominent conference focused on machine learning and computational neuroscience.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COLING">
      <data key="d0">CONFERENCE</data>
      <data key="d1">COLING is the International Conference on Computational Linguistics, which focuses on research in natural language processing and computational linguistics.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING">
      <data key="d0">JOURNAL</data>
      <data key="d1">IEEE Transactions on Knowledge and Data Engineering is a scholarly journal that publishes research on knowledge and data engineering topics.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JOURNAL OF STATISTICAL MECHANICS">
      <data key="d0">JOURNAL</data>
      <data key="d1">Journal of Statistical Mechanics is a scientific journal that publishes research in statistical mechanics and related fields.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PLOS ONE">
      <data key="d0">JOURNAL</data>
      <data key="d1">PLoS ONE is a multidisciplinary open-access journal that publishes research across all areas of science and medicine.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d0">JOURNAL</data>
      <data key="d1">Advances in Neural Information Processing Systems is a conference proceedings publication that features research in machine learning and artificial intelligence.
Advances in Neural Information Processing Systems is a prominent journal that publishes research in the field of neural information processing, including work by Aman Madaan and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d0">JOURNAL</data>
      <data key="d1">International Journal of Human-Computer Studies is a journal that publishes research on the interaction between humans and computers.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NIH PUBLIC ACCESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">NIH Public Access refers to the policy that ensures public access to research funded by the National Institutes of Health.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ARXIV">
      <data key="d0">REPOSITORY</data>
      <data key="d1">arXiv is a free distribution service and an open-access archive for scholarly articles in various fields, including physics, mathematics, and computer science.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TASK-FOCUSED SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">Task-focused summarization is the process of generating summaries that are specifically tailored to answer particular questions or fulfill specific tasks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZERO-SHOT LEARNING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Zero-shot learning is a machine learning paradigm where a model is able to recognize objects or perform tasks it has not been explicitly trained on.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FEW-SHOT LEARNING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Few-shot learning is a machine learning approach that enables models to learn from a small number of training examples.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LARGE LANGUAGE MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Large language models are advanced neural networks trained on vast amounts of text data to perform a variety of language tasks.
Large language models are advanced AI systems designed to understand and generate human-like text based on vast amounts of data.
Large language models are AI models trained on vast amounts of text data to understand and generate human-like text, relevant to many discussed papers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,68e5573b596d253a03047b1e41988598,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GRAPH RETRIEVER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Graph retrievers are systems designed to extract relevant information from graph structures to support various applications, including question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TEXT GENERATION">
      <data key="d0">TASK</data>
      <data key="d1">Text generation is the process of creating coherent and contextually relevant text based on input data or prompts.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NEURAL NETWORK ARCHITECTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Neural network architecture refers to the design and structure of neural networks, which determine how they process information.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CROSS-DOMAIN LEARNING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Cross-domain learning involves applying knowledge or models from one domain to improve performance in another domain.
Cross-domain learning involves transferring knowledge from one domain to another, enhancing the performance of models in new, unseen domains, relevant to various research efforts in machine learning.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MULTIMODAL LEARNING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Multimodal learning refers to the integration of multiple types of data (e.g., text, images) to enhance learning and understanding.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DATA VISUALIZATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Data visualization is the graphical representation of information and data, making complex data more accessible and understandable.
Data visualization is the graphical representation of information and data, using visual elements like charts, graphs, and maps to communicate information clearly.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NLP">
      <data key="d0">FIELD</data>
      <data key="d1">Natural Language Processing (NLP) is a field of artificial intelligence focused on the interaction between computers and human language.
Natural Language Processing (NLP) is a field of AI focused on the interaction between computers and human language.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEEP LEARNING">
      <data key="d0">FIELD</data>
      <data key="d1">Deep learning is a subset of machine learning that uses neural networks with many layers to analyze various forms of data.
Deep learning is a subset of machine learning that uses neural networks with many layers to analyze various forms of data, widely applied in image and speech recognition.
Deep learning is a subset of machine learning that uses neural networks with many layers to analyze various forms of data, relevant to many of the discussed papers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MACHINE LEARNING">
      <data key="d0">FIELD</data>
      <data key="d1">Machine learning is a field of artificial intelligence that focuses on the development of algorithms that allow computers to learn from and make predictions based on data.
Machine learning is a subset of artificial intelligence that focuses on the development of algorithms that allow computers to learn from and make predictions based on data.
Machine learning is a subset of AI that focuses on the development of algorithms that allow computers to learn from and make predictions based on data.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COMPUTATIONAL LINGUISTICS">
      <data key="d0">FIELD</data>
      <data key="d1">Computational linguistics is an interdisciplinary field that combines linguistics and computer science to process and analyze human language.
Computational linguistics is the study of using computational methods to process and analyze human language, relevant to many discussed papers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="STATISTICAL MODELING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Statistical modeling involves using statistical methods to represent and analyze data, often to make predictions or infer relationships.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEEP LEARNING MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Deep learning models are advanced algorithms that use multiple layers of processing to learn representations of data for various tasks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL SYSTEMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Retrieval systems are technologies designed to search and retrieve relevant information from large datasets or databases.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KNOWLEDGE BASES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Knowledge bases are organized collections of information that can be used to support reasoning and decision-making in various applications.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="INFORMATION RETRIEVAL">
      <data key="d0">CONCEPT</data>
      <data key="d1">Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources.
Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DATA ANALYSIS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Data analysis involves inspecting, cleaning, and modeling data to discover useful information and support decision-making.
Data analysis is the process of inspecting, cleansing, transforming, and modeling data to discover useful information, inform conclusions, and support decision-making.
Data analysis is the process of inspecting, cleansing, transforming, and modeling data to discover useful information, inform conclusions, and support decision-making.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="EXPERIMENTAL STUDIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Experimental studies are research designs that involve manipulating one or more variables to determine their effect on a dependent variable.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RESEARCH PAPERS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research papers are scholarly articles that present original findings or reviews of existing research in a specific field.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TECHNICAL REPORTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Technical reports are documents that describe the process, progress, or results of technical or scientific research.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SURVEYS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Surveys are research methods used to collect data from a predefined group of respondents to gain insights into specific topics.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WORKSHOPS">
      <data key="d0">EVENT</data>
      <data key="d1">Workshops are interactive training sessions focused on specific topics, often involving hands-on activities and discussions.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CONFERENCES">
      <data key="d0">EVENT</data>
      <data key="d1">Conferences are formal meetings where researchers and professionals gather to discuss and share findings in a specific field.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SYMPOSIA">
      <data key="d0">EVENT</data>
      <data key="d1">Symposia are formal gatherings of experts to discuss a particular topic, often resulting in published proceedings.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PRESENTATIONS">
      <data key="d0">EVENT</data>
      <data key="d1">Presentations are formal displays of information or research findings, often delivered at conferences or workshops.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="POSTERS">
      <data key="d0">EVENT</data>
      <data key="d1">Posters are visual presentations of research findings, typically displayed at conferences for attendees to review and discuss.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEMONSTRATIONS">
      <data key="d0">EVENT</data>
      <data key="d1">Demonstrations are practical displays of a product or process, often used to showcase new technologies or methods.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TUTORIALS">
      <data key="d0">EVENT</data>
      <data key="d1">Tutorials are instructional sessions designed to teach specific skills or knowledge, often in a hands-on format.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COLLABORATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Collaborations involve partnerships between researchers or organizations to work together on projects or studies.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NETWORKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Networks refer to interconnected systems or structures, often used to represent relationships among entities in various fields.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SYSTEMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Systems refer to organized collections of components that work together to achieve a specific goal or function.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="APPLICATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Applications refer to practical uses of theories, models, or technologies in real-world scenarios.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PLATFORMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Platforms refer to foundational technologies or services that support the development and deployment of applications.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TOOLS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Tools refer to software or hardware resources used to perform specific tasks or functions in various fields.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TECHNOLOGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Technologies refer to the application of scientific knowledge for practical purposes, often resulting in new tools or methods.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="METHODS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Methods refer to systematic approaches or techniques used to conduct research or analysis in various fields.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PROCESSES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Processes refer to series of actions or steps taken to achieve a particular end in various contexts.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FRAMEWORKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Frameworks refer to structured approaches or systems that provide guidance for developing or analyzing specific topics.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MODELS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Models refer to simplified representations of complex systems or phenomena used for analysis or prediction.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="STRATEGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Strategies refer to plans of action designed to achieve specific goals or objectives in various contexts.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="APPROACHES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Approaches refer to methods or ways of dealing with a particular situation or problem.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PRACTICES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Practices refer to established methods or techniques used in a particular field or profession.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="STANDARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Standards refer to established norms or criteria used to measure quality or performance in various fields.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GUIDELINES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Guidelines refer to recommended practices or procedures designed to assist in decision-making or actions.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="POLICIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Policies refer to formal rules or guidelines that govern actions and decisions within organizations or systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="REGULATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Regulations refer to rules or directives made and maintained by an authority to regulate conduct within a specific area.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LAWS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Laws refer to system of rules that are created and enforced through social or governmental institutions to regulate behavior.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ETHICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Ethics refer to moral principles that govern a person's behavior or the conducting of an activity.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="STUDIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Studies refer to systematic investigations or analyses conducted to discover or interpret facts or principles.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RESEARCH">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research refers to the systematic investigation into and study of materials and sources to establish facts and reach new conclusions.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FINDINGS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Findings refer to the results or conclusions drawn from research or analysis.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CONCLUSIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Conclusions refer to judgments or decisions reached after consideration of the relevant facts and evidence.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IMPLICATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Implications refer to the possible effects or outcomes that may result from a particular action or decision.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RECOMMENDATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Recommendations refer to suggestions or proposals for actions based on findings or conclusions.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FUTURE WORK">
      <data key="d0">CONCEPT</data>
      <data key="d1">Future work refers to proposed directions for further research or development based on current findings.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIMITATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Limitations refer to constraints or restrictions that may affect the validity or applicability of research findings.
Limitations refer to the constraints and challenges faced by the LATS algorithm, particularly in decision-making tasks.
Limitations refer to the challenges and constraints faced by language models, particularly in the context of synthetic data generation.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,aa79049289e6532592eec17b9e76adfb,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="CONTRIBUTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Contributions refer to the input or additions made to a field or area of study through research or practice.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PERSPECTIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Perspectives refer to particular attitudes or ways of considering a situation or topic.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="INSIGHTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Insights refer to deep understandings or perceptions gained from analysis or experience.
Insights are valuable understandings or discoveries gained from research or analysis, often leading to advancements in technology or methodology.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="EXAMPLES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Examples refer to specific instances or cases that illustrate a concept or principle.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CASE STUDIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Case studies refer to in-depth examinations of specific instances or examples within a real-world context.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FUTURE DIRECTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Future directions refer to potential paths for research or development based on current trends and findings.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RESEARCH AGENDA">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research agenda refers to a plan or outline of topics and questions to be explored in future research.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RESEARCH QUESTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research questions refer to specific queries that guide the focus and direction of a research study.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HYPOTHESES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Hypotheses refer to proposed explanations or predictions that can be tested through research.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="VARIABLES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Variables refer to elements or factors that can change and affect the outcome of a study or experiment.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DATA COLLECTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Data collection refers to the systematic gathering of information for analysis and interpretation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ANALYSIS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Analysis refers to the process of examining data to draw conclusions or insights.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RESULTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Results refer to the outcomes or findings derived from research or analysis.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="VALIDATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Validation refers to the process of confirming that a method or model is accurate and reliable.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="REPRODUCIBILITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Reproducibility refers to the ability to achieve consistent results using the same methods or procedures in research.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TRANSPARENCY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Transparency refers to the openness and clarity with which research processes and findings are communicated.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ACCOUNTABILITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Accountability refers to the obligation to explain, justify, and take responsibility for actions and decisions in research.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COLLABORATIVE RESEARCH">
      <data key="d0">CONCEPT</data>
      <data key="d1">Collaborative research refers to joint efforts by multiple researchers or institutions to conduct studies and
Collaborative research refers to research conducted by multiple parties working together towards a common goal, often resulting in co-authored publications.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KOESTEN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">L. Koesten is a researcher who co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GREGORY, K.">
      <data key="d0">PERSON</data>
      <data key="d1">K. Gregory is a researcher who co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GROTH, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Groth is a researcher who co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SIMPURL, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Simperl is a researcher who co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KURATOV, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Kuratov is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BULATOV, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Bulatov is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ANOKHIN, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Anokhin is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SOROKIN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Sorokin is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SOROKIN, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Sorokin is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BURTSEV, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Burtsev is a researcher who co-authored a study on the limitations of large language models in finding relevant information.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LASKAR, M. T. R.">
      <data key="d0">PERSON</data>
      <data key="d1">M. T. R. Laskar is a researcher who co-authored studies on query-focused abstractive summarization.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HOQUE, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Hoque is a researcher who co-authored studies on query-focused abstractive summarization.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HUANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Huang is a researcher who co-authored studies on query-focused abstractive summarization.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEWIS, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Lewis is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PEREZ, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Perez is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PIKTUS, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Piktus is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PETRONI, F.">
      <data key="d0">PERSON</data>
      <data key="d1">F. Petroni is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KARPUKHIN, V.">
      <data key="d0">PERSON</data>
      <data key="d1">V. Karpukhin is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GOYAL, N.">
      <data key="d0">PERSON</data>
      <data key="d1">N. Goyal is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="K&#220;TTLER, H.">
      <data key="d0">PERSON</data>
      <data key="d1">H. K&#252;ttler is a researcher who co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MARTIN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Martin is a researcher who co-authored a study on graph layout tools.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MICROSOFT">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft is a technology company that conducts research on the impact of large language models on scientific discovery.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NEBULAGRAPH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">NebulaGraph is a company that launched a graph-based retrieval-augmented generation system.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NEO4J">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Neo4J is a graph database company that is involved in projects related to language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NEWMAN, M. E.">
      <data key="d0">PERSON</data>
      <data key="d1">M. E. Newman is a researcher known for his work on modularity and community structure in networks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RAM, O.">
      <data key="d0">PERSON</data>
      <data key="d1">O. Ram is a researcher who co-authored a study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RANADE, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Ranade is a researcher who co-authored a study on intelligence report generation using retrieval-augmented narrative construction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SARTHI, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Sarthi is a researcher who co-authored a study on recursive abstractive processing for retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHAO, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Z. Shao is a researcher who co-authored a study on enhancing retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SU, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Su is a researcher who co-authored a study on question answering and multi-document summarization.
Su, D. is a researcher who co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DUAN, N.">
      <data key="d0">PERSON</data>
      <data key="d1">Duan, N. is a researcher who co-authored a paper on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="CHEN, W.">
      <data key="d0">PERSON</data>
      <data key="d1">Chen, W. is a researcher who co-authored a paper on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="XU, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Xu, Y. is a researcher who co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Yang, Y. is a researcher who co-authored a paper on MultiHop-RAG, benchmarking retrieval-augmented generation for multi-hop queries.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Tang, Y. is a researcher who co-authored a paper on MultiHop-RAG, benchmarking retrieval-augmented generation for multi-hop queries.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TOUVRON, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Touvron, H. is a researcher who co-authored a paper on Llama 2, which includes open foundation and fine-tuned chat models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MARTIN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Martin, L. is a researcher who co-authored a paper on Llama 2, which includes open foundation and fine-tuned chat models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRAJANOSKA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">Trajanoska, M. is a researcher who co-authored a paper on enhancing knowledge graph construction using large language models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRIVEDI, H.">
      <data key="d0">PERSON</data>
      <data key="d1">Trivedi, H. is a researcher who co-authored a paper on interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, J. is a researcher who co-authored a preliminary study on whether ChatGPT is a good NLG evaluator.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Wang, S. is a researcher who co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YAO, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Yao, L. is a researcher who co-authored a paper exploring large language models for knowledge graph completion.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, J. is a researcher who co-authored a paper on Graph-toolformer, empowering LLMs with graph reasoning ability via prompts augmented by ChatGPT.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, Y. is a researcher who co-authored a paper on causal graph discovery with retrieval-augmented generation based large language models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHENG, L.">
      <data key="d0">PERSON</data>
      <data key="d1">Zheng, L. is a researcher who co-authored a paper judging LLMs as judges with MT-bench and Chatbot Arena.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="CAIRE-COVID">
      <data key="d0">SYSTEM</data>
      <data key="d1">Caire-covid is a question answering and query-focused multi-document summarization system designed for managing COVID-19 scholarly information.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MULTIHOP-RAG">
      <data key="d0">SYSTEM</data>
      <data key="d1">MultiHop-RAG is a benchmarking system for retrieval-augmented generation focused on multi-hop queries.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LLAMA 2">
      <data key="d0">SYSTEM</data>
      <data key="d1">Llama 2 is a system that includes open foundation and fine-tuned chat models for various applications.
Llama 2 is an open foundation and fine-tuned chat model developed for various applications in AI.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="CHATGPT">
      <data key="d0" />
      <data key="d1">
ChatGPT is a conversational AI model developed by OpenAI, designed to generate human-like text responses.
ChatGPT is a conversational AI model that is also evaluated in the Orca-Bench dataset.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,bd4eb9459bc29b4c2da4658914fd4635,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SIDDIQUE, F. B.">
      <data key="d0">PERSON</data>
      <data key="d1">Siddique, F. B. is a researcher who co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="FUNG, P.">
      <data key="d0">PERSON</data>
      <data key="d1">Fung, P. is a researcher who co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BENGIO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Bengio, Y. is a researcher who co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SALAKHUTDINOV, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Salakhutdinov, R. is a researcher who co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MANNING, C. D.">
      <data key="d0">PERSON</data>
      <data key="d1">Manning, C. D. is a researcher who co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="XIAO, J.">
      <data key="d0">PERSON</data>
      <data key="d1">Xiao, J. is a researcher who co-authored a paper on recent advances in document summarization.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LI, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Li, Z. is a researcher who co-authored a paper on knowledge graph prompting for multi-document question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="DERR, T.">
      <data key="d0">PERSON</data>
      <data key="d1">Derr, T. is a researcher who co-authored a paper on knowledge graph prompting for multi-document question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, R.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhang, R. is a researcher who co-authored a paper on knowledge graph prompting for multi-document question answering.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="KRAMTSOVA, E.">
      <data key="d0">PERSON</data>
      <data key="d1">Khramtsova, E. is a researcher who co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHUANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuang, S. is a researcher who co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZUCCON, G.">
      <data key="d0">PERSON</data>
      <data key="d1">Zuccon, G. is a researcher who co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BAREZI, E. J.">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="HOTSPOTQA">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="DOCUMENT SUMMARIZATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Language Agent Tree Search (LATS) is a framework that integrates reasoning, acting, and planning capabilities of language models to enhance decision-making processes.
LATS is a framework designed to unify reasoning, acting, and planning for enhanced problem-solving in language models, addressing limitations of prior prompting techniques by incorporating search algorithms and external feedback.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="LANGUAGE MODELS (LMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Language models (LMs) are AI systems designed to understand and generate human language, capable of performing various tasks including reasoning and decision-making.
Language models are AI systems designed to understand and generate human language, often used for tasks like text generation, question answering, and more.
Language models (LMs) are AI systems designed to understand and generate human-like text based on input prompts.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MONTE CARLO TREE SEARCH (MCTS)">
      <data key="d0">ALGORITHM</data>
      <data key="d1">Monte Carlo Tree Search (MCTS) is a search algorithm used to make decisions in AI, particularly in game playing and decision-making tasks.
MCTS is a search algorithm used in decision-making processes, particularly in reinforcement learning, to evaluate possible actions and their outcomes.
Monte Carlo Tree Search (MCTS) is a heuristic search algorithm used in decision-making environments, building a decision tree to explore states and actions iteratively.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="EXTERNAL ENVIRONMENT">
      <data key="d0">CONTEXT</data>
      <data key="d1">The external environment provides feedback to language models, enhancing their problem-solving capabilities and decision-making processes.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="PROGRAMMING">
      <data key="d0">DOMAIN</data>
      <data key="d1">Programming is a domain where language models can be applied to solve coding tasks and challenges.
Programming is a domain where language models can be applied to assist in writing code, debugging, and other related tasks.
Programming refers to the domain of writing code and developing software, often used as a benchmark for language models.

Programming is the process of designing and building executable computer software to accomplish specific tasks or solve problems.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,7de66b94cf868b37b1df51dc545c415f,93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="INTERACTIVE QUESTION-ANSWERING (QA)">
      <data key="d0">DOMAIN</data>
      <data key="d1">Interactive question-answering (QA) is a domain where language models engage in dialogue to answer user queries.
Interactive QA is a domain where language models are used to answer questions in real-time, often requiring reasoning and context understanding.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WEB NAVIGATION">
      <data key="d0">DOMAIN</data>
      <data key="d1">Web navigation involves using language models to assist users in finding information on the internet.
Web navigation involves using language models to assist users in finding information and navigating online resources.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MATH">
      <data key="d0">DOMAIN</data>
      <data key="d1">Math refers to tasks that involve numerical reasoning and problem-solving, which language models can perform.
Math is a domain where language models can assist in solving mathematical problems and providing explanations.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="HUMAN EVAL">
      <data key="d0">EVALUATION SET</data>
      <data key="d1">HumanEval is a benchmark used to evaluate the performance of programming models, particularly in coding tasks.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="GPT-4">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-4 is a state-of-the-art language model developed by OpenAI, known for its advanced capabilities in natural language processing and reasoning.
GPT-4 is a more advanced version of the Generative Pre-trained Transformer model, offering improved performance in various language tasks.
GPT-4 is a more advanced language model developed by OpenAI, showing improved performance in tasks compared to its predecessor, GPT-3.5.
GPT-4 is a more advanced language model developed by OpenAI, known for its enhanced capabilities in reasoning and programming tasks.
GPT-4 is a state-of-the-art language model developed by OpenAI, known for its advanced capabilities in natural language processing.
GPT-4 is an advanced version of the Generative Pre-trained Transformer model developed by OpenAI, known for its enhanced capabilities in language understanding.
GPT-4 is an advanced version of the Generative Pre-trained Transformer model developed by OpenAI, known for its improved capabilities over previous versions.
GPT-4 is a state-of-the-art language model developed by OpenAI, utilized in the Meta Agent Search for evaluating discovered agents.
GPT-4 is a state-of-the-art language model developed by OpenAI, utilized in the Meta Agent Search for evaluating discovered agents.
GPT-4 is an advanced language model developed by OpenAI, utilized for testing the transferability of agents discovered by Meta Agent Search.
GPT-4 is a state-of-the-art language model developed by OpenAI, known for its advanced capabilities in natural language processing.
GPT-4 is a more advanced language model developed by OpenAI, offering improved performance and cost-effectiveness compared to its predecessors.
GPT-4 is a powerful language model used to generate responses for prompts in the synthetic data generation process.
GPT-4 is a powerful language model used in the AgentInstruct methodology to generate high-quality data.
GPT-4 is a state-of-the-art AI model that serves as a benchmark for evaluating the performance of other models in the Orca-Bench dataset.
GPT-4 is a state-of-the-art language model used as a benchmark for evaluating the performance of other models in various tasks.
GPT-4 is a state-of-the-art language model known for its advanced capabilities, particularly in reading comprehension and problem-solving tasks.
GPT-4 is a state-of-the-art language model used as an evaluator for summarization performance, known for its high quality and low hallucination rates.
GPT-4 is a state-of-the-art language model developed by OpenAI, known for its advanced capabilities in natural language processing.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,1b1399c76420a477c0c97893d258ae69,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,2d4672dfb7bd4283f0b5f23ab4f26653,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635,ef75d2c866bee783577ed9f65707cf13,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="GPT-3.5">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-3.5 is a version of OpenAI's language model that is used for various applications, including web navigation.
GPT-3.5 is a version of the Generative Pre-trained Transformer model developed by OpenAI, known for its advanced language understanding and generation capabilities.
GPT-3.5 is a language model that serves as the base for LATS, providing reasoning capabilities and serving as a benchmark for performance evaluation.
GPT-3.5 is a language model developed by OpenAI, used in various prompting methods to evaluate performance in tasks like HotPotQA.
GPT-3.5 is a language model developed by OpenAI, used for various natural language processing tasks, including programming and reasoning.
GPT-3.5 is a language model that can be used for various tasks, including decision-making and reasoning in complex environments like WebShop.
GPT-3.5 is a version of the Generative Pre-trained Transformer model developed by OpenAI, used for various natural language processing tasks.
GPT-3.5 is a language model used in the context of the Game of 24 to analyze performance and success rates.
GPT-3.5 is a version of the Generative Pre-trained Transformer model developed by OpenAI, used as a baseline for transferring knowledge to newer models.
GPT-3.5 is a previous version of the language model developed by OpenAI, used for evaluating baselines in the Meta Agent Search.
GPT-3.5 is a language model developed by OpenAI, used to evaluate the performance of discovered agents and baselines in the study.
GPT-3.5 is a version of OpenAI's language model that serves as a foundation for testing and transferring discovered agents in the Meta Agent Search process.
GPT-3.5 is a language model that requires a complex feedback mechanism for better refinement of answers compared to other advanced models.
GPT-3.5 is a language model used for comparison in the evaluation of instruction-tuned models.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,594449768ae2dea9b2efbe677075096b,7de66b94cf868b37b1df51dc545c415f,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b88745a13b69cecbc0ee9c3af41389bf,b8dd0300033963bb4a3e1bad37f8e7b9,bc26e68b0b2783ba912b9e5606d9eb0b,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="REACT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">ReAct is a prompting technique that enhances language models by incorporating feedback from external environments.
ReAct is a prompting technique for language models that combines reasoning and acting to improve performance in interactive tasks.
ReAct is an acting-based prompting technique that has shown success in enhancing decision-making in language models, but it is limited by its simplicity and inability to adapt to environmental conditions.
ReAct is a technique that enhances language models by incorporating interactions with external environments, allowing for improved reasoning and acting in decision-making tasks.
ReAct is a prompting method that combines reasoning and acting strategies to enhance the performance of language models in various tasks.
ReAct is a prompting method that adapts based on the success of previous attempts, used in conjunction with LATS for improved performance.
ReAct is a prompting method used in conjunction with language models to enhance performance in decision-making tasks.
ReAct is a prompting method that utilizes reasoning and action in decision-making tasks, serving as a baseline for comparison with LATS.
ReAct is a technique that synergizes reasoning and acting in language models.
ReAct is a simpler prompting method used in language models for decision-making tasks.
React is a system that synergizes reasoning and acting in language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,8180bf20b7577f3eee40df5991e2886d,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="WOOLDRIDGE AND JENNINGS (1995)">
      <data key="d0">PERSON</data>
      <data key="d1">Wooldridge and Jennings (1995) is a reference to foundational work in the field of artificial intelligence regarding autonomous agents.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="CHOWDHERY ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Chowdhery et al. (2023) is a reference to a study that discusses advancements in language models.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="OPENAI (2023)">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">OpenAI is an artificial intelligence research organization known for developing advanced language models like GPT-4.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="NALLAPATI ET AL. (2016)">
      <data key="d0">PERSON</data>
      <data key="d1">Nallapati et al. (2016) is a reference to a study that discusses summarization tasks in natural language processing.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="BOWMAN ET AL. (2015)">
      <data key="d0">PERSON</data>
      <data key="d1">Bowman et al. (2015) is a reference to a study that discusses language inference tasks in natural language processing.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="COBBE ET AL. (2021)">
      <data key="d0">PERSON</data>
      <data key="d1">Cobbe et al. (2021) is a reference to a study that discusses the capabilities of language models in reasoning.
Cobbe et al. (2021) is a reference to a study that discusses reasoning in language models and the decomposition of complex inputs.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SAPAROV AND HE (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Saparov and He (2023) is a reference to a study that discusses the capabilities of language models in reasoning.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="YAO ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Yao et al. (2022) is a reference to a study that discusses language models in web navigation.
Yao et al. (2022) is a reference to a study that evaluates language models in the WebShop domain.
Yao et al. (2022) is a reference to a study that explores the WebShop environment and its applications in decision-making.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,93cb0d0456e0822b5fe30a3e627405f8,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="DENG ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Deng et al. (2023) is a reference to a study that discusses language models in web navigation.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="SCHICK ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Schick et al. (2023) is a reference to a study that discusses tool-use capabilities of language models.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="FAN ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Fan et al. (2022) is a reference to a study that discusses language models in open-ended games.
Fan et al. (2022) is a reference to a study that discusses the use of language models in complex multimodal games.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="XIE ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Xie et al. (2023) is a reference to a study that discusses search-guided language models.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="YAO ET AL. (2023A)">
      <data key="d0">PERSON</data>
      <data key="d1">Yao et al. (2023A) is a reference to a study that discusses search-guided language models.
Yao et al. (2023a) is a reference to a study that discusses improvements in search algorithms for language models.
Yao et al. (2023a) is a reference to a study that discusses the Game of 24 and its relation to language models.
Yao et al. (2023a) is a reference to a study that compares the sample complexity of LATS with other methods.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="YAO ET AL. (2023B)">
      <data key="d0">PERSON</data>
      <data key="d1">Yao et al. (2023B) is a reference to a study that discusses the ReAct technique.
Yao et al. (2023b) is a reference to a study that discusses the efficiency of the ReAct method.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="SHINN ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Shinn et al. (2023) is a reference to a study that discusses prompting techniques for language models.
Shinn et al. (2023) is a reference to a study that evaluates the performance of language models using the Reflexion method.
Shinn et al. (2023) is a reference to a study that discusses the performance of agents using semantic feedback in decision-making tasks.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,93cb0d0456e0822b5fe30a3e627405f8,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SLOMAN (1996)">
      <data key="d0">PERSON</data>
      <data key="d1">Sloman (1996) is a reference to a study that discusses human-like decision-making characteristics.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="EVANS (2010)">
      <data key="d0">PERSON</data>
      <data key="d1">Evans (2010) is a reference to a study that discusses human-like decision-making characteristics.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="AUTONOMOUS AGENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Autonomous agents are systems capable of performing tasks without human intervention, often utilizing reasoning and decision-making capabilities.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="REINFORCEMENT LEARNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Reinforcement learning is a type of machine learning where agents learn to make decisions by receiving rewards or penalties based on their actions.
Reinforcement learning is a machine learning technique where agents learn to make decisions by receiving rewards or penalties based on their actions.
Reinforcement Learning is a type of machine learning where agents learn to make decisions by receiving rewards or penalties.
Reinforcement learning is a type of machine learning where agents learn to make decisions by receiving rewards or penalties based on their actions, relevant to the context of agentic systems.
Reinforcement learning is a type of machine learning where agents learn to make decisions by receiving rewards or penalties, relevant to many discussed papers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="COMBINATORIAL SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Combinatorial space refers to the set of all possible combinations of actions or decisions that can be made in a given context.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="HEURISTICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Heuristics are strategies or rules of thumb that simplify decision-making processes, often used to make quick judgments.
Heuristics are strategies or methods used to guide decision-making and problem-solving, often based on experience or rules of thumb.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="EXPLORATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Exploration refers to the process of investigating or trying out different options or paths in decision-making.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="PROBLEM-SOLVING">
      <data key="d0">PROCESS</data>
      <data key="d1">Problem-solving is the process of finding solutions to complex issues or challenges, often requiring reasoning and decision-making.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="STATE-OF-THE-ART">
      <data key="d0">CONCEPT</data>
      <data key="d1">State-of-the-art refers to the highest level of development or performance achieved in a particular field or technology.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="GRADIENT-BASED FINE-TUNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Gradient-based fine-tuning is a method used to improve the performance of models by adjusting their parameters based on gradient descent techniques.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="GRADIENT-FREE PERFORMANCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Gradient-free performance refers to the ability of a model to perform tasks without relying on gradient-based optimization methods.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="EFFECTIVENESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Effectiveness refers to the degree to which a model or technique achieves its intended outcomes or goals.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="ADAPTIVE MECHANISM">
      <data key="d0">CONCEPT</data>
      <data key="d1">An adaptive mechanism is a system or process that adjusts its behavior based on feedback or changes in the environment.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="IN-CONTEXT LEARNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">In-context learning is a method where models learn from examples provided in the context of a task, enhancing their performance on similar tasks.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="FEEDBACK">
      <data key="d0">PROCESS</data>
      <data key="d1">Feedback is information provided to a model or agent about its performance, used to improve future actions or decisions.
Feedback is the information provided by experts to evaluate and enhance the performance of agents during the refinement process.
Feedback is the information provided by the critic_module regarding the correctness and quality of the answers generated.
Feedback is the evaluation provided to the generated solutions, indicating their correctness and areas for improvement.
Feedback is the information provided regarding the performance of the code solutions, including corrections and suggestions for improvement.
Feedback is the information provided by the Critic Module regarding the correctness of answers and suggestions for improvement.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,449db721e37968e073e3579b59e023b2,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,93cb0d0456e0822b5fe30a3e627405f8,97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="PROFICIENT EXPLORATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Proficient exploration refers to the ability of a model or agent to effectively investigate and evaluate different options in decision-making.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="LATS">
      <data key="d0">FRAMEWORK</data>
      <data key="d1">LATS is a framework that incorporates reasoning, acting, and planning to enhance the performance of language models (LMs) using Monte Carlo Tree Search (MCTS).
LATS (Language Agent Tree Search) is a search algorithm that integrates reasoning, acting, and planning in language models, adapting MCTS for language agents.
LATS is a novel framework for language models that integrates reasoning, acting, and planning through a tree search mechanism, enhancing decision-making and adaptability in various environments.
LATS is a method designed for reasoning and acting in various domains, utilizing language models to enhance performance in tasks such as question answering and programming.
LATS is a method that combines internal reasoning and external retrieval strategies to enhance performance in tasks like HotPotQA and programming challenges.
LATS is a method that improves decision-making performance in complex environments by utilizing advanced prompting strategies and self-reflection techniques.
LATS is a framework designed to enhance language model (LM) performance through interactions with various environments, focusing on autonomous decision-making and interpretability.
LATS (Language Agent Tree Search) is an algorithm designed for unifying reasoning, acting, and planning in language models.
LATS (Language Agent Tree Search) is an algorithm designed to unify reasoning, acting, and planning in language models, utilizing a structured approach to decision-making in complex environments.

LATS is a method used in the Game of 24 to evaluate success rates based on different configurations of parameters.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,4ae237a491bc8a84cc720e40c59a7464,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SELF-REFINEMENT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Self-refinement is a method used to improve the performance of models by allowing them to learn from their own outputs and experiences.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SELF-CONSISTENCY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Self-consistency is a technique that employs majority voting over multiple outputs to enhance the reliability of model predictions.
Self-consistency is a method that improves chain of thought reasoning in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (COT)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">CoT prompting is a method that encourages language models to generate answers by breaking down complex problems into sequential steps.
Chain-of-thought (CoT) prompting is a method that helps language models reason through complex tasks by providing structured prompts.
Chain-of-Thought (COT) is a method that instructs agents to output reasoning steps before arriving at an answer, enhancing complex problem-solving.
Chain-of-Thought (COT) is a hand-designed agent baseline for reasoning tasks.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SILVER ET AL. (2017)">
      <data key="d0">PERSON</data>
      <data key="d1">Silver et al. (2017) is a reference to a study that discusses the success of Monte Carlo Tree Search in model-based reinforcement learning.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WEI ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Wei et al. (2022) is a reference to a study that discusses chain-of-thought prompting and its variants in language models.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="GUO ET AL. (2018)">
      <data key="d0">PERSON</data>
      <data key="d1">Guo et al. (2018) is a reference to a study that addresses error propagation in reasoning tasks with language models.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CHEN ET AL. (2021)">
      <data key="d0">PERSON</data>
      <data key="d1">Chen et al. (2021) is a reference to a study that discusses the HumanEval dataset used for evaluating programming tasks.
Chen et al. (2021) is a reference to a study that discusses the application of language models in programming tasks.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="HAO ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Hao et al. (2023) is a reference to a study that discusses reasoning via planning using Monte Carlo Tree Search.
Hao et al. (2023) is a reference to a study that explores the use of planning and search algorithms in language models.
Hao et al. (2023) is a reference to a study that evaluates various prompting methods in decision-making tasks.
Hao et al. (2023) is a reference to a study discussing the performance of LATS in comparison to other methods.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="BESTA ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Besta et al. (2023) is a reference to a study that discusses advancements in search algorithms for language models.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="AHN ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Ahn et al. (2022) is a reference to a study that discusses the application of language models in robotics as high-level controllers.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="HUANG ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Huang et al. (2022) is a reference to a study that discusses the use of language models in robotics.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="DRIESS ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Driess et al. (2023) is a reference to a study that discusses the application of language models in robotics.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="BAKER ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Baker et al. (2022) is a reference to a study that discusses the adaptation of language models to complex multimodal games.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="GUSS ET AL. (2019)">
      <data key="d0">PERSON</data>
      <data key="d1">Guss et al. (2019) is a reference to a study that discusses the application of language models in games like Minecraft.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LIU ET AL. (2018)">
      <data key="d0">PERSON</data>
      <data key="d1">Liu et al. (2018) is a reference to a study that discusses the application of language models in text-based environments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SHRIDHAR ET AL. (2020)">
      <data key="d0">PERSON</data>
      <data key="d1">Shridhar et al. (2020) is a reference to a study that discusses the use of language models in interactive environments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LIU ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Liu et al. (2024) is a reference to a study that discusses the application of language models in text-based environments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="YANG ET AL. (2018)">
      <data key="d0" />
      <data key="d1">
Yang et al. (2018) is a reference to a study that discusses the HotPotQA benchmark.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SELF-REFINE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Self-refine is an extension of prompting techniques that uses self-improvement to enhance reasoning and decision-making in language models.
Self-Refine is a method that allows agents to iteratively reflect on and correct mistakes from previous attempts.
Self-Refine is a baseline technique that focuses on refining agents' responses through iterative feedback and adjustments.
Self-Refine is a technique that allows language models to iteratively improve their responses by refining their outputs based on feedback.
Self-Refine is a technique used in agentic systems to improve performance, referenced in the context of manually designed agents.
Self-Refine is a manually designed agent that exhibits performance metrics in tasks such as reading comprehension and science.
Self-refine is a technique involving iterative refinement with self-feedback to improve model performance, as discussed in a paper by Aman Madaan and others.
Self-Refine is a hand-designed agent baseline for reasoning and problem-solving tasks.
Self-Refine is a method that allows for iterative refinement of answers based on feedback, as described in the text.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,1b1399c76420a477c0c97893d258ae69,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="REFLEXION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Reflexion is a prompting technique that incorporates self-improvement to enhance reasoning and decision-making, addressing limitations of simpler methods.
Reflexion is a prompting method that focuses on enhancing the reasoning capabilities of language models through self-reflection.

Reflexion is a technique that provides semantic feedback to agents, aimed at improving their decision-making capabilities.
Reflexion is another prompting method that is simpler compared to LATS, used for decision-making in language models.
Reflexion is a method used in conjunction with LATS for decision-making, which is compared against LATS in terms of performance on tasks like HotPotQA.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="ADAPLANNER">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">AdaPlanner is a method that incorporates both positive and negative feedback to improve decision-making in language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="EXTERNAL TOOLS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">External tools include APIs, search engines, calculators, and other models that enhance the reasoning and practical abilities of language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="MCTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Monte Carlo Tree Search (MCTS) is a search algorithm used to explore multiple branches of outcomes in decision-making processes.
Monte Carlo Tree Search (MCTS) is a heuristic search algorithm used for decision-making processes, particularly in environments requiring exploration and exploitation strategies.
Monte Carlo Tree Search (MCTS) is a search algorithm utilized in LATS to explore and select options with high value while considering promising alternatives.
MCTS (Monte Carlo Tree Search) is a search algorithm used to make decisions in complex environments, providing principled performance gains.
Monte Carlo Tree Search (MCTS) is a principled search algorithm that serves as the foundation for performance improvements in various decision-making tasks.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TREE-BASED SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Tree-based search is a method used in planning algorithms and reinforcement learning that explores multiple branches of outcomes for effective decision-making.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="PROBLEM SETTING AND PROMPTING">
      <data key="d0">CONCEPT</data>
      <data key="d1">This section outlines the problem setting for using language models in reasoning and decision-making, including the role of prompts.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="KURATOV ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Kuratov et al. (2023) is a reference to a study discussing the effectiveness of various prompting techniques in language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="DECISION-MAKING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Decision-making is the process by which language models generate outputs based on input prompts, often involving reasoning and planning.
Decision-making involves the process by which the language model agent selects actions based on reasoning and available information.
Decision-making is the process by which the LATS algorithm evaluates options and selects actions based on its reasoning capabilities.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="REASONING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Reasoning is the cognitive process employed by language models to derive conclusions or make decisions based on given inputs.
</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="PLANNING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Planning involves the use of algorithms to determine a sequence of actions or decisions that a language model should take to achieve a specific goal.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="TOOL USE">
      <data key="d0" />
      <data key="d1">
Tool use refers to the capability of agents to utilize external tools such as search engines and code execution to solve complex tasks.
Tool Use refers to the ability of agents in agentic systems to utilize external tools to accomplish tasks.
Tool use involves employing functions or APIs to perform tasks or solve problems effectively.
Tool use refers to the manipulation of tools to achieve goals, particularly in AI, where it involves using resources to solve complex tasks.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c212c1467564ad33330b1f655a8e27e,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CHAIN-OF-THOUGHT PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain-of-thought (CoT) prompting is a method that enhances reasoning by creating intermediate thoughts that connect input queries to outputs, particularly in complex scenarios like mathematical problems.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="TREE-OF-THOUGHT PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Tree-of-thought (ToT) prompting extends CoT prompting by exploring multiple reasoning paths in a tree structure, where each node represents a partial solution state.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="DECISION-MAKING TASKS">
      <data key="d0">TASK TYPE</data>
      <data key="d1">Decision-making tasks involve scenarios where choices must be made based on reasoning, often requiring complex problem-solving strategies.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="ERROR PROPAGATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Error propagation refers to the phenomenon where errors in reasoning or decision-making can lead to further inaccuracies in subsequent steps or outputs.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="OUTPUT">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Output refers to the result generated by a language model in response to a given input prompt, often representing the final answer or solution.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="LANGUAGE MODEL (LM)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A language model (LM) is an AI system designed to understand and generate human-like text based on input data and prompts.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="THOUGHTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Thoughts are intermediate language sequences generated during the reasoning process, serving as steps between the input and output in prompting techniques.
Thoughts refer to the outputs generated by the FM_Module, which include the agent's reasoning and the corresponding code for the task.
</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="SEARCH ALGORITHMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Search algorithms are methods used to explore possible solutions or paths in decision-making processes, such as depth-first search (DFS) and breadth-first search (BFS).</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="DECISION TREE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">A decision tree is a model used to represent decisions and their possible consequences, structured as a tree with nodes representing states and edges representing actions.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="INPUT PROMPT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="LM AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The LM Agent is a decision-making entity that utilizes language models to perform reasoning and action-taking tasks based on observations from its environment.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="POLICY &#928;">
      <data key="d0">CONCEPT</data>
      <data key="d1">The policy &#960; defines the strategy that the LM Agent follows to take actions based on its observations and previous actions.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="ENVIRONMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The environment is the context in which the LM Agent operates, providing observations and feedback based on the actions taken by the agent.
The environment refers to the context or setting in which the LATS algorithm operates, including the state space and the dynamics of the tasks being performed.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="UCT ALGORITHM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Upper Confidence Bound for Trees (UCT) algorithm is used in MCTS to balance exploration and exploitation during the selection of nodes in the search tree.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="REFLECTION">
      <data key="d0">PROCESS</data>
      <data key="d1">Reflection is a process in LATS where feedback from failed trajectories is used to inform future decision-making and improve performance.
Reflection is the user's consideration of their previous actions and outcomes, leading to adjustments in future search strategies.
Reflection is a technique used in agentic systems to enable agents to evaluate their actions and improve future performance.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,5d356b8ff719763a38cecff22c4e17b7,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="VALUE FUNCTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">The value function is a mathematical representation that quantifies the expected return of states in the search tree, guiding the search algorithm towards promising areas.
The value function in LATS quantifies the agent's progress in task completion, combining a self-generated LM score and a self-consistency score to guide decision-making.
The value function is a component of the LATS algorithm that scores states based on expected future rewards, guiding the search process.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="OBSERVATION">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">An observation is the information received by the LM Agent from the environment after taking an action, which influences subsequent decisions.
Observation is the information gathered during the execution of an Action, which informs subsequent Thoughts and Actions.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="ACTIONS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Actions are the decisions made by the LM Agent based on its policy, which directly affect the environment and lead to new observations.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SEARCH ALGORITHM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A search algorithm is a systematic method used to explore possible actions and states in order to find optimal solutions or trajectories in decision-making tasks.
The search algorithm in LATS is responsible for navigating the decision tree, utilizing heuristics and feedback to select the most promising paths for task completion.
The search algorithm refers to the method used to explore the search space in ADAS, aiming to discover high-performance agentic systems.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,4884e8429ca1e567dadf5e22b4b68274,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="BACKPROPAGATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SELF-CONSISTENCY SCORE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The self-consistency score is a heuristic used in LATS to improve value assignment by evaluating actions sampled multiple times at the same state for accuracy.
Self-consistency score is a metric used to evaluate the reliability of the results produced by the LATS method in the Game of 24.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HYPERPARAMETER">
      <data key="d0">CONCEPT</data>
      <data key="d1">A hyperparameter in LATS, denoted as &#955;, is used to balance the contributions of the LM score and self-consistency score in the overall value function.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="ENVIRONMENTAL FEEDBACK">
      <data key="d0">CONCEPT</data>
      <data key="d1">Environmental feedback in LATS provides objective assessments of the correctness of trajectories, influencing the agent's learning and decision-making.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="SELF-REFLECTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Self-reflection in LATS allows the agent to analyze unsuccessful outcomes and propose better alternatives, enhancing learning from errors.
Self-reflection is a technique in agentic systems that allows agents to evaluate their own performance and improve over time.
Self-reflection is a technique used in the meta agent to iteratively refine the novelty and correctness of generated agents.
Self-reflection is a process where the meta agent reviews its previous outputs to identify mistakes and suggest improvements.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="TRIAL AND ERROR">
      <data key="d0">CONCEPT</data>
      <data key="d1">Trial and error is a learning process in LATS where the agent learns from past experiences without the need for expensive optimization methods like reinforcement learning.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="SCALAR VALUE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A scalar value in LATS is assigned to each new child node to quantify the agent's progress in task completion, serving as a heuristic for guiding the search algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="TERMINAL STATE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A terminal state in LATS is the endpoint of a trajectory where the outcome of the task is evaluated, providing feedback for the agent's learning process.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="TRAJECTORY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A trajectory in LATS refers to the path taken by the agent through the decision tree, from the initial state to a terminal state, which is evaluated for success or failure.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="REWARD">
      <data key="d0">CONCEPT</data>
      <data key="d1">A reward in LATS is a feedback signal received by the agent upon reaching a terminal state, influencing the value updates of nodes in the search tree.
Reward refers to the feedback received from the environment based on the actions taken, which is used to evaluate the success of trajectories in algorithms.
Reward is a metric used to evaluate the performance of the Web Shop system, calculated based on the number of attributes satisfied by the selected item.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="UCT FORMULA">
      <data key="d0">CONCEPT</data>
      <data key="d1">The Upper Confidence Bound for Trees (UCT) formula is used in LATS to guide the selection of the next node based on updated values and exploration strategies.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="PROGRAMMED HEURISTICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Programmed heuristics are predefined strategies used in decision-making processes, which LATS aims to improve upon with its flexible and adaptive approach.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="LEARNED HEURISTICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Learned heuristics are strategies developed through training, which LATS seeks to outperform in terms of efficiency and adaptability in various scenarios.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="AGENT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="TO">
      <data key="d0">METHOD</data>
      <data key="d1">ToT is a prompting method that adapts search algorithms for decision-making in language models.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="RAP">
      <data key="d0">METHOD</data>
      <data key="d1">RAP is a prompting method that integrates reasoning and acting strategies to improve language model performance.
RAP (Retrieval-Augmented Prompting) is a method that incorporates external retrieval strategies to enhance reasoning capabilities.
RAP is a prompting method that combines reasoning and action, used for comparison with LATS in terms of performance and efficiency.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="API CALLS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">API calls are used in the context of language models to search and retrieve information, enhancing the model's ability to answer questions.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="CO">
      <data key="d0">METHOD</data>
      <data key="d1">CoT is a prompting method that focuses on reasoning based on the existing knowledge of language models.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="AUSTIN ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Austin et al. (2022) is a reference to a study that evaluates language models in various domains.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="EXTERNAL FEEDBACK">
      <data key="d0">CONCEPT</data>
      <data key="d1">External feedback refers to information provided to the language model agent about the correctness of its answers, which can enhance its reasoning capabilities.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="INTERNAL REASONING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Internal reasoning involves the language model's ability to generate answers based solely on its existing knowledge without external input.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="OBSERVATION SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The observation space consists of the outputs from API calls and self-generated reflections that inform the language model's decision-making process.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SAMPLE TRAJECTORIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Sample trajectories are paths or sequences of actions taken by the language model agent during its decision-making process, used for evaluation.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="FEEDBACK CORRECTNESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Feedback correctness refers to the accuracy of the information provided to the language model agent regarding the correctness of its answers.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="PROMPTING DESIGNS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Prompting designs are structured formats or strategies used to guide the language model in generating responses or performing tasks.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="LANGUAGE MODEL AGENT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="COT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">CoT (Chain of Thought) is a prompting technique that encourages reasoning in language models, slightly enhancing performance on reasoning tasks.
COT (Chain of Thought) is a prompting technique that encourages the model to think step by step before providing an answer.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="TOT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">ToT (Tree of Thought) is a search method that samples and explores outputs to improve performance in reasoning tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="HUMANEVAL">
      <data key="d0">DATASET</data>
      <data key="d1">HumanEval is a dataset used to assess the correctness of synthesized Python programs from natural language descriptions.
HumanEval is a dataset used for evaluating programming tasks in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="MBPP">
      <data key="d0">DATASET</data>
      <data key="d1">MBPP (Multi-Choice Programming Problems) is a dataset that measures the performance of models in generating correct Python code from natural language prompts.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="IL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">IL (Imitation Learning) is a method that trains models to mimic expert behavior in various tasks, including reasoning and acting.
</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="IL+RL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">IL+RL (Imitation Learning with Reinforcement Learning) combines imitation learning with reinforcement learning to improve model performance in complex tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="EXTERNAL OBSERVATIONS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">External observations refer to additional context or feedback used to enhance the reasoning capabilities of models during tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="SYNTHETIC TEST SUITE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A synthetic test suite consists of generated test cases used to evaluate the correctness of programming solutions.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="WEB SHOP">
      <data key="d0">ENVIRONMENT</data>
      <data key="d1">WebShop is an online shopping environment consisting of a large number of real-world products and human instructions, where agents navigate to fulfill user specifications.
Web Shop is an online platform that allows users to search for products, view results, and make purchases through a structured interface.
The Web Shop is an online platform where users can search for and purchase various products, such as deodorants, based on specific criteria like size and price.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,785ad59c6a37896a4676ec5c1689735f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="COACHING OF THOUGHT (COT)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">CoT is a prompting method that guides agents in reasoning tasks, helping them to arrive at solutions through structured thinking.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="GAME OF 24">
      <data key="d0">TASK</data>
      <data key="d1">Game of 24 is a mathematical reasoning task where agents must create the number 24 using a set of numbers and basic operations.
Game of 24 is a mathematical reasoning challenge where players use basic arithmetic operations to create the number 24 from four given numbers.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="DFS">
      <data key="d0">ALGORITHM</data>
      <data key="d1">DFS (Depth-First Search) is a search algorithm that explores as far as possible along each branch before backtracking, used in decision-making tasks.
Depth-First Search (DFS) is a search algorithm that explores as far as possible along each branch before backtracking, used in comparison with MCTS.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="RL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">RL (Reinforcement Learning) is a type of machine learning where agents learn to make decisions by receiving rewards or penalties based on their actions.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="FURUTA ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Furuta et al. (2024) is a reference to a study that discusses fine-tuning methods in machine learning.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="TOOL OF THOUGHT (TOT)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">ToT is a prompting method that aids agents in reasoning tasks by providing structured guidance.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="HOT-POTQA">
      <data key="d0">DATASET</data>
      <data key="d1">HotPotQA is a dataset used for evaluating the performance of various methods in question answering tasks, particularly in the context of tree-based search methods.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TOKEN CONSUMPTION">
      <data key="d0">METRIC</data>
      <data key="d1">Token consumption refers to the number of tokens used during the execution of a method, which is a critical factor in evaluating the efficiency of search algorithms.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SAMPLE COMPLEXITY">
      <data key="d0">METRIC</data>
      <data key="d1">Sample complexity refers to the number of samples or tokens required for a method to achieve a certain level of performance, important for assessing the efficiency of algorithms.
Sample complexity is a measure of the number of samples needed for the LATS algorithm to achieve a certain level of performance.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="NODES EXPANDED">
      <data key="d0">METRIC</data>
      <data key="d1">Nodes expanded refers to the number of nodes processed during the search, which is a critical factor in evaluating the efficiency of search algorithms.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRAJECTORIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Trajectories are sequences of actions or decisions taken by the algorithm during the search process, used to evaluate performance and efficiency.
</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="GROUND-TRUTH FEEDBACK">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Ground-truth feedback is the actual correct information used to guide the learning process of the algorithm, enhancing its performance.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="COMPUTATIONAL COST">
      <data key="d0">METRIC</data>
      <data key="d1">Computational cost refers to the resources required to execute a method, which is a significant consideration when evaluating LATS against simpler methods.
Computational cost refers to the resources required to run the LATS algorithm, which can be higher compared to simpler methods.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="LATS PERFORMANCE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SYSTEM-2 LM APPROACHES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">System-2 LM approaches refer to advanced methods in language modeling that emphasize reasoning and decision-making over simple autoregressive generation.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DECISION-MAKING COMMUNITY">
      <data key="d0">COMMUNITY</data>
      <data key="d1">The decision-making community encompasses researchers and practitioners focused on improving decision-making processes using language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DANIEL CAMPOS">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Campos is an individual acknowledged for providing useful feedback on earlier versions of the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NSF GRANT 2106825">
      <data key="d0">FUNDING</data>
      <data key="d1">NSF Grant 2106825 is a financial support awarded for research related to language models and their applications.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NIFA AWARD 2020-67021-32799">
      <data key="d0">FUNDING</data>
      <data key="d1">NIFA Award 2020-67021-32799 is a financial support awarded for research related to language models and their applications.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="IBM-ILLINOIS DISCOVERY ACCELERATOR INSTITUTE">
      <data key="d0">INSTITUTION</data>
      <data key="d1">The IBM-Illinois Discovery Accelerator Institute is an institution that supports research and development in advanced computing and AI technologies.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NVIDIA GPUS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">NVIDIA GPUs are high-performance graphics processing units used for computational tasks, including those in language model research.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ACCESS PROGRAM">
      <data key="d0">PROGRAM</data>
      <data key="d1">The ACCESS program provides allocations for computational resources to support research initiatives, including those involving language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="MICHAEL AHN">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Ahn is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ANTHONY BROHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Anthony Brohan is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NOAH BROWN">
      <data key="d0">PERSON</data>
      <data key="d1">Noah Brown is a researcher who co-authored a paper on grounding language in robotic affordances.
Noah Brown is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YEVGEN CHEBOTAR">
      <data key="d0">PERSON</data>
      <data key="d1">Yevgen Chebotar is a researcher who co-authored a paper on grounding language in robotic affordances.
Yevgen Chebotar is a researcher involved in the development of PaLM-E, an embodied multimodal language model.
Yevgen Chebotar is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="OMAR CORTES">
      <data key="d0">PERSON</data>
      <data key="d1">Omar Cortes is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="BYRON DAVID">
      <data key="d0">PERSON</data>
      <data key="d1">Byron David is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CHELSEA FINN">
      <data key="d0">PERSON</data>
      <data key="d1">Chelsea Finn is a researcher who co-authored a paper on grounding language in robotic affordances.
Chelsea Finn is a researcher known for her work on model-agnostic meta-learning.
Chelsea Finn is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,34d0bb2211fc795fe1096442e086a2b3,4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CHUYUAN FU">
      <data key="d0">PERSON</data>
      <data key="d1">Chuyuan Fu is a researcher who co-authored a paper on grounding language in robotic affordances.
Chuyuan Fu is a researcher contributing to advancements in language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="KEERTHANA GOPALAKRISHNAN">
      <data key="d0">PERSON</data>
      <data key="d1">Keerthana Gopalakrishnan is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="KAROL HAUSMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Karol Hausman is a researcher who co-authored a paper on grounding language in robotic affordances.
Karol Hausman is a researcher involved in the development of PaLM-E, an embodied multimodal language model.
Karol Hausman is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEX HERZOG">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Herzog is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DANIEL HO">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Ho is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JASMINE HSU">
      <data key="d0">PERSON</data>
      <data key="d1">Jasmine Hsu is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JULIAN IBARZ">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Ibarz is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="BRIAN ICHTER">
      <data key="d0">PERSON</data>
      <data key="d1">Brian Ichter is a researcher who co-authored a paper on grounding language in robotic affordances.
Brian Ichter is a researcher involved in the development of PaLM-E, an embodied multimodal language model.
Brian Ichter is a researcher contributing to embodied reasoning through planning with language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEX IRPAN">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Irpan is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ERIC JANG">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Jang is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ROSARIO JAUREGUI RUANO">
      <data key="d0">PERSON</data>
      <data key="d1">Rosario Jauregui Ruano is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="KYLE JEFFREY">
      <data key="d0">PERSON</data>
      <data key="d1">Kyle Jeffrey is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="SALLY JESMONTH">
      <data key="d0">PERSON</data>
      <data key="d1">Sally Jesmonth is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NIKHIL J JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Nikhil J Joshi is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="RYAN JULIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ryan Julian is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DMITRY KALASHNIKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Dmitry Kalashnikov is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="YUHENG KUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuheng Kuang is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="KUANG-HUEI LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Kuang-Huei Lee is a researcher who co-authored a paper on grounding language in robotic affordances.
Kuang-Huei Lee is a researcher contributing to multimodal web navigation with instruction-finetuned foundation models.
Kuang-Huei Lee is a researcher contributing to advancements in language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SERGEY LEVINE">
      <data key="d0">PERSON</data>
      <data key="d1">Sergey Levine is a researcher who co-authored a paper on grounding language in robotic affordances.
Sergey Levine is a researcher involved in the development of PaLM-E, an embodied multimodal language model.
Sergey Levine is a researcher contributing to embodied reasoning through planning with language models.
Sergey Levine is a researcher involved in model-agnostic meta-learning.
Sergey Levine is a researcher who contributed to the discussion on imitating proprietary language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YAO LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yao Lu is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="LINDA LUU">
      <data key="d0">PERSON</data>
      <data key="d1">Linda Luu is a researcher who co-authored a paper on grounding language in robotic affordances.
Linda Luu is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CAROLINA PARADA">
      <data key="d0">PERSON</data>
      <data key="d1">Carolina Parada is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="PETER PASTOR">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Pastor is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JORNELL QUIAMBAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jornell Quiambao is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="KANISHKA RAO">
      <data key="d0">PERSON</data>
      <data key="d1">Kanishka Rao is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JAREK RETTINGHOUSE">
      <data key="d0">PERSON</data>
      <data key="d1">Jarek Rettinghouse is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DIEGO REYES">
      <data key="d0">PERSON</data>
      <data key="d1">Diego Reyes is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="PIERRE SERMANET">
      <data key="d0">PERSON</data>
      <data key="d1">Pierre Sermanet is a researcher who co-authored a paper on grounding language in robotic affordances.
Pierre Sermanet is a researcher involved in the development of PaLM-E, an embodied multimodal language model.
Pierre Sermanet is a researcher contributing to embodied reasoning through planning with language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NICOLAS SIEVERS">
      <data key="d0">PERSON</data>
      <data key="d1">Nicolas Sievers is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CLAYTON TAN">
      <data key="d0">PERSON</data>
      <data key="d1">Clayton Tan is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ALEXANDER TOSHEV">
      <data key="d0">PERSON</data>
      <data key="d1">Alexander Toshev is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="VINCENT VANHOUCKE">
      <data key="d0">PERSON</data>
      <data key="d1">Vincent Vanhoucke is a researcher who co-authored a paper on grounding language in robotic affordances.
Vincent Vanhoucke is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FEI XIA">
      <data key="d0">PERSON</data>
      <data key="d1">Fei Xia is a researcher who co-authored a paper on grounding language in robotic affordances.
Fei Xia is a researcher involved in the development of PaLM-E, an embodied multimodal language model.
Fei Xia is a researcher contributing to advancements in language models and their applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="TED XIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Ted Xiao is a researcher who co-authored a paper on grounding language in robotic affordances.
Ted Xiao is a researcher contributing to embodied reasoning through planning with language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PENG XU">
      <data key="d0">PERSON</data>
      <data key="d1">Peng Xu is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="SICHUN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Sichun Xu is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="MENGYUAN YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Mengyuan Yan is a researcher who co-authored a paper on grounding language in robotic affordances.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ANDY ZENG">
      <data key="d0">PERSON</data>
      <data key="d1">Andy Zeng is a researcher who co-authored a paper on grounding language in robotic affordances.
Andy Zeng is a researcher involved in the development of PaLM-E, an embodied multimodal language model.
Andy Zeng is a researcher contributing to embodied reasoning through planning with language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JORNELL QUIAMBAO&lt;|(&quot;ENTITY&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="PROGRAM SYNTHESIS">
      <data key="d0" />
      <data key="d1">
Program synthesis is the process of automatically generating code from high-level specifications or natural language descriptions.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="VIDEO PRETRAINING (VPT)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Video pretraining (VPT) is a technique that involves training models to learn to act by observing unlabeled online videos, enhancing their performance in action-related tasks.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="GRAPH OF THOUGHTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Graph of Thoughts is a method for solving complex problems using large language models, focusing on structured reasoning and decision-making.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NATURAL LANGUAGE INFERENCE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Natural language inference is a task in natural language processing that involves determining the logical relationship between sentences, often used for training language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DEEP BLUE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Deep Blue is a chess-playing computer developed by IBM, known for its ability to compete against and defeat human chess champions.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CODET">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">CodeT is a technique for code generation that includes generating tests to ensure the correctness of the generated code.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="AMODEI">
      <data key="d0">PERSON</data>
      <data key="d1">Dario Amodei is a researcher known for his work on language models and their capabilities as few-shot learners.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MURRAY CAMPBELL">
      <data key="d0">PERSON</data>
      <data key="d1">Murray Campbell is a researcher associated with the development of the Deep Blue chess program.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSEPH HOANE JR">
      <data key="d0">PERSON</data>
      <data key="d1">Joseph Hoane Jr is a researcher involved in the development of the Deep Blue chess program.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FENG-HSIUNG HSU">
      <data key="d0">PERSON</data>
      <data key="d1">Feng-hsiung Hsu is a researcher associated with the Deep Blue chess program.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BEI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Bei Chen is a researcher who co-authored a paper on CodeT, a code generation model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FENGJI ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Fengji Zhang is a researcher who co-authored a paper on CodeT, a code generation model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANH NGUYEN">
      <data key="d0">PERSON</data>
      <data key="d1">Anh Nguyen is a researcher who co-authored a paper on CodeT, a code generation model.
Anh Nguyen is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DAOGUANG ZAN">
      <data key="d0">PERSON</data>
      <data key="d1">Daoguang Zan is a researcher who co-authored a paper on CodeT, a code generation model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ZEQI LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Zeqi Lin is a researcher who co-authored a paper on CodeT, a code generation model.
Zeqi Lin is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIAN-GUANG LOU">
      <data key="d0">PERSON</data>
      <data key="d1">Jian-Guang Lou is a researcher who co-authored a paper on CodeT, a code generation model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WEIZHU CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Weizhu Chen is a researcher who co-authored a paper on CodeT, a code generation model.
Weizhu Chen is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.
Weizhu Chen is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MARK CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Mark Chen is a researcher involved in evaluating large language models trained on code.Mark Chen is a researcher involved in training verifiers to solve math word problems.
Mark Chen is a researcher involved in the training of verifiers for solving math word problems.
Mark Chen is a researcher who worked on training verifiers for math word problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JERRY TWOREK">
      <data key="d0">PERSON</data>
      <data key="d1">Jerry Tworek is a researcher involved in evaluating large language models trained on code.Jerry Tworek is a researcher involved in training verifiers to solve math word problems.
Jerry Tworek is a researcher contributing to the training of verifiers for solving math word problems.
Jerry Tworek is a researcher involved in the training of verifiers for math word problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HEEWOO JUN">
      <data key="d0">PERSON</data>
      <data key="d1">Heewoo Jun is a researcher involved in training verifiers to solve math word problems.Heewoo Jun is a researcher involved in evaluating large language models trained on code.
Heewoo Jun is a researcher contributing to the training of verifiers for math word problems.
Heewoo Jun is a researcher associated with the training of verifiers for math word problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QIMING YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Qiming Yuan is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HENRIQUE PONDE">
      <data key="d0">PERSON</data>
      <data key="d1">Henrique Ponde is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JARED KAPLAN">
      <data key="d0">PERSON</data>
      <data key="d1">Jared Kaplan is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HARRISON EDWARDS">
      <data key="d0">PERSON</data>
      <data key="d1">Harrison Edwards is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YURA BURDA">
      <data key="d0">PERSON</data>
      <data key="d1">Yura Burda is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NICHOLAS JOSEPH">
      <data key="d0">PERSON</data>
      <data key="d1">Nicholas Joseph is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GREG BROCKMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Greg Brockman is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEX RAY">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Ray is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="RAUL PURI">
      <data key="d0">PERSON</data>
      <data key="d1">Raul Puri is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GRETCHEN KRUEGER">
      <data key="d0">PERSON</data>
      <data key="d1">Gretchen Krueger is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MICHAEL PETROV">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Petrov is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HEIDY KHLAAF">
      <data key="d0">PERSON</data>
      <data key="d1">Heidy Khlaaf is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GIRISH SASTRY">
      <data key="d0">PERSON</data>
      <data key="d1">Girish Sastry is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PAMELA MISHKIN">
      <data key="d0">PERSON</data>
      <data key="d1">Pamela Mishkin is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BROOKE CHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Brooke Chan is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SCOTT GRAY">
      <data key="d0">PERSON</data>
      <data key="d1">Scott Gray is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NICK RYDER">
      <data key="d0">PERSON</data>
      <data key="d1">Nick Ryder is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MIKHAIL PAVLOV">
      <data key="d0">PERSON</data>
      <data key="d1">Mikhail Pavlov is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALETHEA POWER">
      <data key="d0">PERSON</data>
      <data key="d1">Alethea Power is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="LUKASZ KAISER">
      <data key="d0">PERSON</data>
      <data key="d1">Lukasz Kaiser is a researcher involved in evaluating large language models trained on code.Lukasz Kaiser is a researcher involved in training verifiers to solve math word problems.
Lukasz Kaiser is a researcher focused on training verifiers for solving math word problems.
Lukasz Kaiser is a researcher involved in the training of verifiers for math word problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MOHAMMAD BAVARIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammad Bavarian is a researcher involved in evaluating large language models trained on code.Mohammad Bavarian is a researcher involved in training verifiers to solve math word problems.
Mohammad Bavarian is a researcher focused on training verifiers for math word problems.
Mohammad Bavarian is a researcher involved in the training of verifiers for math word problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CLEMENS WINTER">
      <data key="d0">PERSON</data>
      <data key="d1">Clemens Winter is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PHILIPPE TILLET">
      <data key="d0">PERSON</data>
      <data key="d1">Philippe Tillet is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FELIPE PETROSKI SUCH">
      <data key="d0">PERSON</data>
      <data key="d1">Felipe Petroski Such is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DAVID W. CUMMINGS">
      <data key="d0">PERSON</data>
      <data key="d1">David W. Cummings is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MATTHIAS PLAPPERT">
      <data key="d0">PERSON</data>
      <data key="d1">Matthias Plappert is a researcher involved in training verifiers to solve math word problems.Matthias Plappert is a researcher involved in evaluating large language models trained on code.
Matthias Plappert is a researcher involved in the training of verifiers for math word problems.
Matthias Plappert is a researcher who contributed to the training of verifiers for math word problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FOTIOS CHANTZIS">
      <data key="d0">PERSON</data>
      <data key="d1">Fotios Chantzis is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ELIZABETH BARNES">
      <data key="d0">PERSON</data>
      <data key="d1">Elizabeth Barnes is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ARIEL HERBERT-VOSS">
      <data key="d0">PERSON</data>
      <data key="d1">Ariel Herbert-Voss is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WILLIAM H. GUSS">
      <data key="d0">PERSON</data>
      <data key="d1">William H. Guss is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEX NICOL">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Nicol is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="IGOR BABUSHKIN">
      <data key="d0">PERSON</data>
      <data key="d1">Igor Babushkin is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SUCHIR BALAJI">
      <data key="d0">PERSON</data>
      <data key="d1">Suchir Balaji is a researcher involved in evaluating large language models trained on code.
Suchir Balaji is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SHANTANU JAIN">
      <data key="d0">PERSON</data>
      <data key="d1">Shantanu Jain is a researcher involved in evaluating large language models trained on code.
Shantanu Jain is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANDREW CARR">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Carr is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JAN LEIKE">
      <data key="d0">PERSON</data>
      <data key="d1">Jan Leike is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA ACHIAM">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Achiam is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="VEDANT MISRA">
      <data key="d0">PERSON</data>
      <data key="d1">Vedant Misra is a researcher involved in evaluating large language models trained on code.Vedant Misra is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="EVAN MORIKAWA">
      <data key="d0">PERSON</data>
      <data key="d1">Evan Morikawa is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEC RADFORD">
      <data key="d0">PERSON</data>
      <data key="d1">Alec Radford is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MATTHEW M. KNIGHT">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew M. Knight is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MILES BRUNDAGE">
      <data key="d0">PERSON</data>
      <data key="d1">Miles Brundage is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MIRA MURATI">
      <data key="d0">PERSON</data>
      <data key="d1">Mira Murati is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KATIE MAYER">
      <data key="d0">PERSON</data>
      <data key="d1">Katie Mayer is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PETER WELINDER">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Welinder is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BOB MCGREW">
      <data key="d0">PERSON</data>
      <data key="d1">Bob McGrew is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DARIO AMODEI">
      <data key="d0">PERSON</data>
      <data key="d1">Dario Amodei is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SAM MCCANDLISH">
      <data key="d0">PERSON</data>
      <data key="d1">Sam McCandlish is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ILYA SUTSKEVER">
      <data key="d0">PERSON</data>
      <data key="d1">Ilya Sutskever is a researcher involved in evaluating large language models trained on code.
Ilya Sutskever is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.
Ilya Sutskever is a prominent researcher in the field of reinforcement learning.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,2d4672dfb7bd4283f0b5f23ab4f26653,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WOJCIECH ZAREMBA">
      <data key="d0">PERSON</data>
      <data key="d1">Wojciech Zaremba is a researcher involved in evaluating large language models trained on code.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WENHU CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Wenhu Chen is a researcher who co-authored a paper on program of thoughts prompting for numerical reasoning tasks.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XUEGUANG MA">
      <data key="d0">PERSON</data>
      <data key="d1">Xueguang Ma is a researcher who co-authored a paper on program of thoughts prompting for numerical reasoning tasks.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WILLIAM W. COHEN">
      <data key="d0">PERSON</data>
      <data key="d1">William W. Cohen is a researcher who co-authored a paper on program of thoughts prompting for numerical reasoning tasks.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="AAKANKSHA CHOWDHERY">
      <data key="d0">PERSON</data>
      <data key="d1">Aakanksha Chowdhery is a researcher involved in the development of PaLM-E, an embodied multimodal language model.Aakanksha Chowdhery is a researcher involved in the development of PaLM, a language model.
Aakanksha Chowdhery is a researcher involved in language model applications.
Aakanksha Chowdhery is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHARAN NARANG">
      <data key="d0">PERSON</data>
      <data key="d1">Sharan Narang is a researcher involved in the development of PaLM, a language model.
Sharan Narang is a researcher focused on advancements in language models.
Sharan Narang is a researcher contributing to advancements in language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JACOB DEVLIN">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Devlin is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MAARTEN BOSMA">
      <data key="d0">PERSON</data>
      <data key="d1">Maarten Bosma is a researcher involved in the development of PaLM, a language model.
Maarten Bosma is a researcher involved in prompting techniques for large language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GAURAV MISHRA">
      <data key="d0">PERSON</data>
      <data key="d1">Gaurav Mishra is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ADAM ROBERTS">
      <data key="d0">PERSON</data>
      <data key="d1">Adam Roberts is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PAUL BARHAM">
      <data key="d0">PERSON</data>
      <data key="d1">Paul Barham is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HYUNG WON CHUNG">
      <data key="d0">PERSON</data>
      <data key="d1">Hyung Won Chung is a researcher involved in the development of PaLM, a language model.
Hyung Won Chung is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.
Hyung Won Chung is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHARLES SUTTON">
      <data key="d0">PERSON</data>
      <data key="d1">Charles Sutton is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SEBASTIAN GEHRMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Gehrmann is a researcher involved in the development of PaLM, a language model.
Sebastian Gehrmann is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="PARKER SCHUH">
      <data key="d0">PERSON</data>
      <data key="d1">Parker Schuh is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KENSEN SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Kensen Shi is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SASHA TSVYASHCHENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Sasha Tsvyashchenko is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA MAYNEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Maynez is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ABHISHEK RAO">
      <data key="d0">PERSON</data>
      <data key="d1">Abhishek Rao is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YI TAY">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Tay is a researcher involved in the development of PaLM, a language model.
Yi Tay is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.
Yi Tay is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NOAM SHAZEER">
      <data key="d0">PERSON</data>
      <data key="d1">Noam Shazeer is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="VINODKUMAR PRABHAKARAN">
      <data key="d0">PERSON</data>
      <data key="d1">Vinodkumar Prabhakaran is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="EMILY REIF">
      <data key="d0">PERSON</data>
      <data key="d1">Emily Reif is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NAN DU">
      <data key="d0">PERSON</data>
      <data key="d1">Nan Du is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BEN HUTCHINSON">
      <data key="d0">PERSON</data>
      <data key="d1">Ben Hutchinson is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="REINER POPE">
      <data key="d0">PERSON</data>
      <data key="d1">Reiner Pope is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JAMES BRADBURY">
      <data key="d0">PERSON</data>
      <data key="d1">James Bradbury is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JACOB AUSTIN">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Austin is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MICHAEL ISARD">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Isard is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GUY GUR-ARI">
      <data key="d0">PERSON</data>
      <data key="d1">Guy Gur-Ari is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PENGCHENG YIN">
      <data key="d0">PERSON</data>
      <data key="d1">Pengcheng Yin is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="TOJU DUKE">
      <data key="d0">PERSON</data>
      <data key="d1">Toju Duke is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANSELM LEVSKAYA">
      <data key="d0">PERSON</data>
      <data key="d1">Anselm Levskaya is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SANJAY GHEMAWAT">
      <data key="d0">PERSON</data>
      <data key="d1">Sanjay Ghemawat is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SUNIPA DEV">
      <data key="d0">PERSON</data>
      <data key="d1">Sunipa Dev is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HENRYK MICHALIWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Henryk Michalewski is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XAVIER GARCIA">
      <data key="d0">PERSON</data>
      <data key="d1">Xavier Garcia is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KEVIN ROBINSON">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin Robinson is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="LIAM FEDUS">
      <data key="d0">PERSON</data>
      <data key="d1">Liam Fedus is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DENNY ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Denny Zhou is a researcher involved in the development of PaLM, a language model.
Denny Zhou is a researcher involved in large language models and their reasoning capabilities.
Denny Zhou is a researcher involved in the development of language models and AI technologies.
Denny Zhou is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.
Denny Zhou is a researcher known for contributions to language models and reasoning techniques.
Denny Zhou is a researcher who co-authored a paper on reasoning via abstraction in large language models.Denny Zhou is a researcher who co-authored a paper on self-discovery in large language models.
Denny Zhou is a researcher who co-authored a paper on challenging big-bench tasks in 2022.Denny Zhou is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DAPHNE IPPOLITO">
      <data key="d0">PERSON</data>
      <data key="d1">Daphne Ippolito is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DAVID LUAN">
      <data key="d0">PERSON</data>
      <data key="d1">David Luan is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HYEONTAEK LIM">
      <data key="d0">PERSON</data>
      <data key="d1">Hyeontaek Lim is a researcher involved in the development of PaLM, a language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BARRET ZOPH">
      <data key="d0">PERSON</data>
      <data key="d1">Barret Zoph is a researcher involved("entity"</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="VINEET KOSARAJU">
      <data key="d0">PERSON</data>
      <data key="d1">Vineet Kosaraju is a researcher involved in training verifiers to solve math word problems.
Vineet Kosaraju is a researcher contributing to the training of verifiers for solving math word problems.
Vineet Kosaraju is a researcher who co-authored a paper on browser-assisted question-answering.
Vineet Kosaraju is a researcher who contributed to the training of verifiers for math word problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JACOB HILTON">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Hilton is a researcher involved in training verifiers to solve math word problems.
Jacob Hilton is a researcher focused on training verifiers for math word problems.
Jacob Hilton is a researcher who co-authored a paper on browser-assisted question-answering.
Jacob Hilton is a researcher associated with the training of verifiers for math word problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="REIICHIRO NAKANO">
      <data key="d0">PERSON</data>
      <data key="d1">Reiichiro Nakano is a researcher involved in training verifiers to solve math word problems.
Reiichiro Nakano is a researcher involved in the training of verifiers for solving math word problems.
Reiichiro Nakano is a researcher who co-authored a paper on browser-assisted question-answering.
Reiichiro Nakano is a researcher who contributed to the training of verifiers for math word problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHRISTOPHER HESSE">
      <data key="d0">PERSON</data>
      <data key="d1">Christopher Hesse is a researcher involved in training verifiers to solve math word problems.
Christopher Hesse is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOHN SCHULMAN">
      <data key="d0">PERSON</data>
      <data key="d1">John Schulman is a researcher involved in training verifiers to solve math word problems.
John Schulman is a researcher contributing to fast reinforcement learning methods.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XIANG DENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiang Deng is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YU GU">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Gu is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BOYUAN ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Boyuan Zheng is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SHIJIE CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Shijie Chen is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SAMUEL STEVENS">
      <data key="d0">PERSON</data>
      <data key="d1">Samuel Stevens is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BOSHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Boshi Wang is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HUAN SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Huan Sun is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YU SU">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Su is a researcher involved in the development of Mind2Web, a generalist agent for the web.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DANNY DRIES">
      <data key="d0">PERSON</data>
      <data key="d1">Danny Driess is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MEHDI S. M. SAJJADI">
      <data key="d0">PERSON</data>
      <data key="d1">Mehdi S. M. Sajjadi is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="COREY LYNCH">
      <data key="d0">PERSON</data>
      <data key="d1">Corey Lynch is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="AYZAAN WAHID">
      <data key="d0">PERSON</data>
      <data key="d1">Ayzaan Wahid is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JONATHAN TOMPHSON">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Tompson is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="QUAN VUONG">
      <data key="d0">PERSON</data>
      <data key="d1">Quan Vuong is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="TIANHE YU">
      <data key="d0">PERSON</data>
      <data key="d1">Tianhe Yu is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WENLONG HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Wenlong Huang is a researcher involved in the development of PaLM-E, an embodied multimodal language model.
Wenlong Huang is a researcher contributing to embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DANIEL DUCKWORTH">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Duckworth is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MARC TOUSSAINT">
      <data key="d0">PERSON</data>
      <data key="d1">Marc Toussaint is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KLAUS GREFF">
      <data key="d0">PERSON</data>
      <data key="d1">Klaus Greff is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="IGOR MORDATCH">
      <data key="d0">PERSON</data>
      <data key="d1">Igor Mordatch is a researcher involved in the development of PaLM-E, an embodied multimodal language model.
Igor Mordatch is a researcher contributing to embodied reasoning through planning with language models.
Igor Mordatch is a researcher focused on improving factuality and reasoning in language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PETE FLORENCE">
      <data key="d0">PERSON</data>
      <data key="d1">Pete Florence is a researcher involved in the development of PaLM-E, an embodied multimodal language model.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YILUN DU">
      <data key="d0">PERSON</data>
      <data key="d1">Yilun Du is a researcher involved in learning universal policies via text-guided video generation.
Yilun Du is a researcher involved in the development of an embodied multi-modal language model, contributing to advancements in AI and machine learning.
Yilun Du is a researcher involved in improving factuality and reasoning in language models through multi-agent debate.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MENGJIAO YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Mengjiao Yang is a researcher involved in learning universal policies via text-guided video generation.
Mengjiao Yang is a researcher who co-authored a paper on embodied multi-modal language models, focusing on integrating various modalities in AI.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BO DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Bo Dai is a researcher involved in learning universal policies via text-guided video generation.
Bo Dai is a researcher contributing to the field of multi-modal language models, particularly in the context of embodied agents.
Bo Dai is a researcher who co-authored the AdaPlanner paper, contributing to advancements in adaptive planning techniques.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HANJUN DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Hanjun Dai is a researcher involved in learning universal policies via text-guided video generation.
Hanjun Dai is a researcher involved in the development of multi-modal language models, focusing on their applications in AI.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="OFIR NACHUM">
      <data key="d0">PERSON</data>
      <data key="d1">Ofir Nachum is a researcher involved in learning universal policies via text-guided video generation.
Ofir Nachum is a researcher who has contributed to the field of multi-modal language models and their applications in AI.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA B. TENENBAUM">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua B. Tenenbaum is a researcher involved in learning universal policies via text-guided video generation.
Joshua B. Tenenbaum is a prominent researcher in AI, known for his work on cognitive models and multi-modal learning.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DALE SCHUURMANS">
      <data key="d0">PERSON</data>
      <data key="d1">Dale Schuurmans is a researcher involved in learning universal policies via text-guided video generation.
Dale Schuurmans is a researcher contributing to advancements in AI, particularly in multi-modal language models.
Dale Schuurmans is a researcher involved in the development of language models.
Dale Schuurmans is a researcher contributing to advancements in language model reasoning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PIETER ABBEEL">
      <data key="d0">PERSON</data>
      <data key="d1">Pieter Abbeel is a researcher involved in learning universal policies via text-guided video generation.
Pieter Abbeel is a researcher known for his work in AI and robotics, contributing to the development of multi-modal language models.
Pieter Abbeel is a researcher focused on AI technologies and language models.
Pieter Abbeel is a researcher focused on meta-learning techniques.Pieter Abbeel is a researcher focused on reinforcement learning techniques.
Pieter Abbeel is a researcher involved in discussing the limitations of imitating proprietary language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JONATHAN ST BT EVANS">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan St BT Evans is a researcher known for his work on intuition and reasoning from a dual-process perspective.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PSYCHOLOGICAL INQUIRY">
      <data key="d0">PUBLICATION</data>
      <data key="d1">Psychological Inquiry is a journal that publishes research on psychological topics, including intuition and reasoning.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MINE DOJO">
      <data key="d0">PROJECT</data>
      <data key="d1">MineDojo is a project focused on building open-ended embodied agents using internet-scale knowledge, contributing to advancements in AI.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="INSTRUCTION-FINETUNED FOUNDATION MODELS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Instruction-finetuned foundation models are AI models that have been fine-tuned to follow specific instructions, enhancing their performance in various tasks.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PAL">
      <data key="d0">PROJECT</data>
      <data key="d1">PAL (Program-aided language models) is a project aimed at improving language models through programmatic assistance, enhancing their capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MINE RL">
      <data key="d0">PROJECT</data>
      <data key="d1">MineRL is a large-scale dataset of Minecraft demonstrations, used for training AI agents in complex environments.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AGENTBENCH">
      <data key="d0">PROJECT</data>
      <data key="d1">AgentBench is a framework for evaluating large language models (LLMs) as agents, assessing their performance in various tasks.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DUAL-PROCESS PERSPECTIVE">
      <data key="d0">THEORY</data>
      <data key="d1">The dual-process perspective is a psychological theory that explains reasoning and intuition as two distinct cognitive processes.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LINXI FAN">
      <data key="d0">PERSON</data>
      <data key="d1">Linxi Fan is a researcher involved in the development of MineDojo, focusing on building open-ended embodied agents.
Linxi Fan is a researcher who co-authored a paper on human-level reward design using large language models.
Linxi Fan is a researcher who co-authored a paper on Voyager, an open-ended embodied agent.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="GUANZHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Guanzhi Wang is a researcher contributing to the MineDojo project, focusing on embodied agents with internet-scale knowledge.
Guanzhi Wang is a researcher who co-authored a paper on human-level reward design using large language models.
Guanzhi Wang is a researcher who co-authored a paper on Voyager, an open-ended embodied agent.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUNFAN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yunfan Jiang is a researcher involved in the MineDojo project, contributing to the development of embodied agents.
Yunfan Jiang is a researcher who co-authored a paper on Voyager, an open-ended embodied agent.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AJAY MANDLEKAR">
      <data key="d0">PERSON</data>
      <data key="d1">Ajay Mandlekar is a researcher contributing to the MineDojo project, focusing on building embodied agents.
Ajay Mandlekar is a researcher who co-authored a paper on Voyager, an open-ended embodied agent.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUNCONG YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuncong Yang is a researcher involved in the MineDojo project, contributing to the development of embodied agents.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAOYI ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Haoyi Zhu is a researcher contributing to the MineDojo project, focusing on building embodied agents.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ANDREW TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Tang is a researcher involved in the MineDojo project, contributing to the development of embodied agents.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DE-AN HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">De-An Huang is a researcher contributing to the MineDojo project, focusing on building embodied agents.
De-An Huang is a researcher who co-authored a paper on human-level reward design using large language models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUKE ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Yuke Zhu is a researcher involved in the MineDojo project, contributing to the development of embodied agents.
Yuke Zhu is a researcher who co-authored a paper on human-level reward design using large language models.
Yuke Zhu is a researcher who co-authored a paper on Voyager, an open-ended embodied agent.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ANIMA ANANDKUMAR">
      <data key="d0">PERSON</data>
      <data key="d1">Anima Anandkumar is a researcher contributing to the MineDojo project, focusing on building embodied agents.
Anima Anandkumar is a researcher who co-authored a paper on human-level reward design using large language models.
Anima Anandkumar is a researcher who co-authored a paper on Voyager, an open-ended embodied agent.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HIROKI FURUTA">
      <data key="d0">PERSON</data>
      <data key="d1">Hiroki Furuta is a researcher involved in multimodal web navigation with instruction-finetuned foundation models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUTAKA MATSUNO">
      <data key="d0">PERSON</data>
      <data key="d1">Yutaka Matsuno is a researcher involved in multimodal web navigation with instruction-finetuned foundation models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHIXIANG SHANE GU">
      <data key="d0">PERSON</data>
      <data key="d1">Shixiang Shane Gu is a researcher contributing to multimodal web navigation with instruction-finetuned foundation models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="IZZEDDIN GUR">
      <data key="d0">PERSON</data>
      <data key="d1">Izzeddin Gur is a researcher involved in multimodal web navigation with instruction-finetuned foundation models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LUYU GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Luyu Gao is a researcher contributing to the development of PAL, focusing on program-aided language models.
Luyu Gao is a researcher who co-authored the Self-refine paper, focusing on iterative refinement techniques.
Luyu Gao is a researcher contributing to program-aided language models.
Luyu Gao is a researcher who co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AMAN MAADAAN">
      <data key="d0">PERSON</data>
      <data key="d1">Aman Madaan is a researcher involved in the development of PAL, focusing on program-aided language models.
Aman Madaan is a researcher involved in the development of the Self-refine method for iterative refinement with self-feedback.
Aman Madaan is a researcher who co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHUYAN ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Shuyan Zhou is a researcher contributing to the development of PAL, focusing on program-aided language models.
Shuyan Zhou is a researcher involved in program-aided language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="URI ALON">
      <data key="d0">PERSON</data>
      <data key="d1">Uri Alon is a researcher involved in the development of PAL, focusing on program-aided language models.
Uri Alon is a researcher who co-authored the Self-refine paper, focusing on iterative refinement in language models.
Uri Alon is a researcher contributing to program-aided language models.
Uri Alon is a researcher who co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PENGFEI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Pengfei Liu is a researcher contributing to the development of PAL, focusing on program-aided language models.
Pengfei Liu is a researcher focused on program-aided language models.
Pengfei Liu is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,3d1f6634f93f8a4c296dc8df7e59859e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YIMING YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yiming Yang is a researcher involved in the development of PAL, focusing on program-aided language models.
Yiming Yang is a researcher who co-authored the Self-refine paper, contributing to advancements in iterative refinement techniques.
Yiming Yang is a researcher involved in program-aided language models.
Yiming Yang is a researcher who co-authored a paper on program-aided language models presented at the International Conference on Machine Learning in 2023.
Yiming Yang is a researcher who co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JAMIE CALLAN">
      <data key="d0">PERSON</data>
      <data key="d1">Jamie Callan is a researcher contributing to the development of PAL, focusing on program-aided language models.
Jamie Callan is a researcher contributing to program-aided language models.
Jamie Callan is a researcher who co-authored a paper on program-aided language models presented at the International Conference on Machine Learning in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="GRAHAM NEUBIG">
      <data key="d0">PERSON</data>
      <data key="d1">Graham Neubig is a researcher involved in the development of PAL, focusing on program-aided language models.
Graham Neubig is a researcher focused on program-aided language models.
Graham Neubig is a researcher who co-authored a paper on program-aided language models presented at the International Conference on Machine Learning in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DANIJAR HAFNER">
      <data key="d0">PERSON</data>
      <data key="d1">Danijar Hafner is a researcher involved in learning latent dynamics for planning from pixels.
Danijar Hafner is a researcher contributing to advancements in AI and language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TIMOTHY LILLICRAP">
      <data key="d0">PERSON</data>
      <data key="d1">Timothy Lillicrap is a researcher contributing to learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="IAN FISCHER">
      <data key="d0">PERSON</data>
      <data key="d1">Ian Fischer is a researcher involved in learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="RUBEN VILLEGAS">
      <data key="d0">PERSON</data>
      <data key="d1">Ruben Villegas is a researcher contributing to learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DAVID HA">
      <data key="d0">PERSON</data>
      <data key="d1">David Ha is a researcher involved in learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HONGLAK LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Honglak Lee is a researcher contributing to learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JAMES DAVIDSON">
      <data key="d0">PERSON</data>
      <data key="d1">James Davidson is a researcher involved in learning latent dynamics for planning from pixels.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHIBO HAO">
      <data key="d0">PERSON</data>
      <data key="d1">Shibo Hao is a researcher contributing to reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YI GU">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Gu is a researcher involved in reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAODI MA">
      <data key="d0">PERSON</data>
      <data key="d1">Haodi Ma is a researcher contributing to reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JOSHUA JIAHUA HONG">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua Jiahua Hong is a researcher involved in reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHEN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhen Wang is a researcher contributing to reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DAISY ZHE WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Daisy Zhe Wang is a researcher involved in reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHITING HU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiting Hu is a researcher contributing to reasoning with language models in planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JIE HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jie Huang is a researcher involved in large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XINYUN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyun Chen is a researcher contributing to the study of large language models and their reasoning capabilities.
Xinyun Chen is a researcher who co-authored a paper on self-discovery in large language models.Xinyun Chen is a researcher who co-authored a paper on reasoning via abstraction in large language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SWAROOP MISHRA">
      <data key="d0">PERSON</data>
      <data key="d1">Swaroop Mishra is a researcher involved in large language models and their reasoning capabilities.
Swaroop Mishra is a researcher who co-authored a paper on reasoning via abstraction in large language models.
Swaroop Mishra is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="HUAIXIU STEVEN ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Huaixiu Steven Zheng is a researcher contributing to the study of large language models and their reasoning capabilities.
Huaixiu Steven Zheng is a researcher who co-authored a paper on reasoning via abstraction in large language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ADAMS WEI YU">
      <data key="d0">PERSON</data>
      <data key="d1">Adams Wei Yu is a researcher involved in large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XINYING SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinying Song is a researcher contributing to the study of large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="F. XIA">
      <data key="d0">PERSON</data>
      <data key="d1">F. Xia is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HARRIS CHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Harris Chan is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JACKY LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jacky Liang is a researcher contributing to embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PETER R. FLORENCE">
      <data key="d0">PERSON</data>
      <data key="d1">Peter R. Florence is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JONATHAN TOMPSON">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Tompson is a researcher involved in embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TOMAS JACKSON">
      <data key="d0">PERSON</data>
      <data key="d1">Tomas Jackson is a researcher contributing to embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LEVANTE KOCSIS">
      <data key="d0">PERSON</data>
      <data key="d1">Levente Kocsis is a researcher known for his work on bandit-based Monte Carlo planning.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CSABA SZEPESV&#193;RI">
      <data key="d0">PERSON</data>
      <data key="d1">Csaba Szepesv&#225;ri is a researcher contributing to bandit-based Monte Carlo planning.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TAKESHI KOJIMA">
      <data key="d0">PERSON</data>
      <data key="d1">Takeshi Kojima is a researcher involved in large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MACHEL REID">
      <data key="d0">PERSON</data>
      <data key="d1">Machel Reid is a researcher contributing to large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUSUKE IWASAWA">
      <data key="d0">PERSON</data>
      <data key="d1">Yusuke Iwasawa is a researcher involved in large language models and their reasoning capabilities.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHIHAN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhihan Liu is a researcher contributing to the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAO HU">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Hu is a researcher involved in the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHENAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shenao Zhang is a researcher contributing to the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HONGYI GUO">
      <data key="d0">PERSON</data>
      <data key="d1">Hongyi Guo is a researcher involved in the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHUQI KE">
      <data key="d0">PERSON</data>
      <data key="d1">Shuqi Ke is a researcher contributing to the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="BOYI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Boyi Liu is a researcher involved in the study of autonomous LLM agents with provable sample efficiency.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHAORAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhaoran Wang is a researcher contributing to the study of autonomous LLM agents with provable sample efficiency.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="NIKET TANDON">
      <data key="d0">PERSON</data>
      <data key="d1">Niket Tandon is a researcher who co-authored the Self-refine paper, contributing to advancements in iterative refinement techniques.
Niket Tandon is a researcher who co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PRAKHAR GUPTA">
      <data key="d0">PERSON</data>
      <data key="d1">Prakhar Gupta is a researcher who co-authored the Self-refine paper, focusing on self-feedback mechanisms.
Prakhar Gupta is a researcher who co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SKYLER HALLINAN">
      <data key="d0">PERSON</data>
      <data key="d1">Skyler Hallinan is a researcher who co-authored the Self-refine paper, contributing to the field of natural language processing.
Skyler Hallinan is a researcher who co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SARAH WIEGREFFE">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Wiegreffe is a researcher who co-authored the Self-refine paper, contributing to advancements in self-feedback methods.
Sarah Wiegreffe is a researcher who co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NOUHA DZIRI">
      <data key="d0">PERSON</data>
      <data key="d1">Nouha Dziri is a researcher who co-authored the Self-refine paper, contributing to the field of natural language processing.
Nouha Dziri is a researcher who co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SHRIMAI PRABHUMOYE">
      <data key="d0">PERSON</data>
      <data key="d1">Shrimai Prabhumoye is a researcher who co-authored the Self-refine paper, focusing on self-feedback mechanisms.
Shrimai Prabhumoye is a researcher who co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SHASHANK GUPTA">
      <data key="d0">PERSON</data>
      <data key="d1">Shashank Gupta is a researcher who co-authored the Self-refine paper, focusing on self-feedback methods.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BODHISATTVA PRASAD MAJUMDER">
      <data key="d0">PERSON</data>
      <data key="d1">Bodhisattwa Prasad Majumder is a researcher who co-authored the Self-refine paper, contributing to the field of natural language processing.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KATHERINE HERMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Katherine Hermann is a researcher who co-authored the Self-refine paper, focusing on iterative refinement techniques.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SEAN WELLECK">
      <data key="d0">PERSON</data>
      <data key="d1">Sean Welleck is a researcher who co-authored the Self-refine paper, contributing to advancements in self-feedback methods.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="AMIR YAZDANBAKHSH">
      <data key="d0">PERSON</data>
      <data key="d1">Amir Yazdanbakhsh is a researcher who co-authored the Self-refine paper, focusing on iterative refinement in language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PETER CLARK">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Clark is a researcher who co-authored the Self-refine paper, contributing to the field of natural language processing.
Peter Clark is a researcher known for his work on question answering and the AI2 Reasoning Challenge.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RAMESH NALLAPATI">
      <data key="d0">PERSON</data>
      <data key="d1">Ramesh Nallapati is a researcher who co-authored a paper on abstractive text summarization using sequence-to-sequence RNNs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BOWEN ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Bowen Zhou is a researcher who co-authored a paper on abstractive text summarization, focusing on sequence-to-sequence models.
Bowen Zhou is a researcher who contributed to enhancing chat language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CICERO DOS SANTOS">
      <data key="d0">PERSON</data>
      <data key="d1">Cicero dos Santos is a researcher who co-authored a paper on abstractive text summarization, contributing to advancements in RNNs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CAGLAR GULCEHRE">
      <data key="d0">PERSON</data>
      <data key="d1">Caglar Gulcehre is a researcher who co-authored a paper on abstractive text summarization, focusing on sequence-to-sequence techniques.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BING XIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Bing Xiang is a researcher who co-authored a paper on abstractive text summarization, contributing to the field of natural language processing.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="OPENAI">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">OpenAI is an artificial intelligence research organization known for developing models like GPT-4 and contributing to advancements in AI.
OpenAI is an artificial intelligence research organization known for developing models like ChatGPT and GPT-4.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUJIA QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Yujia Qin is a researcher who co-authored the ToolLLM paper, focusing on facilitating large language models to master real-world APIs.
Yujia Qin is a researcher involved in enhancing chat language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHIHAO LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shihao Liang is a researcher who co-authored the ToolLLM paper, contributing to advancements in API integration with language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YINING YE">
      <data key="d0">PERSON</data>
      <data key="d1">Yining Ye is a researcher who co-authored the ToolLLM paper, focusing on enhancing language models' capabilities.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KUNLUN ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Kunlun Zhu is a researcher who co-authored the ToolLLM paper, contributing to the integration of language models with APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="LAN YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Lan Yan is a researcher who co-authored the ToolLLM paper, focusing on facilitating language models' interactions with APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YAXI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yaxi Lu is a researcher who co-authored the ToolLLM paper, contributing to advancements in language model capabilities.
Yaxi Lu is a researcher involved in the study of emergent behaviors in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YANKAI LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Yankai Lin is a researcher who co-authored the ToolLLM paper, focusing on enhancing language models' API interactions.
Yankai Lin is a researcher contributing to the field of large language model-based autonomous agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XIN CONG">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Cong is a researcher who co-authored the ToolLLM paper, contributing to the integration of language models with real-world APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XIANGRU TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiangru Tang is a researcher who co-authored the ToolLLM paper, focusing on facilitating language models' capabilities.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BILL QIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Bill Qian is a researcher who co-authored the ToolLLM paper, contributing to advancements in language model integration.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SIHAN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Sihan Zhao is a researcher who co-authored the ToolLLM paper, focusing on enhancing language models' API interactions.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="RUNCHU TIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Runchu Tian is a researcher who co-authored the ToolLLM paper, contributing to the integration of language models with APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="RUOBING XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Ruobing Xie is a researcher who co-authored the ToolLLM paper, focusing on facilitating language models' capabilities.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JIE ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Jie Zhou is a researcher who co-authored the ToolLLM paper, contributing to advancements in language model integration.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARK GERSTEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Mark Gerstein is a researcher who co-authored the ToolLLM paper, focusing on enhancing language models' API interactions.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DAHAI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Dahai Li is a researcher who co-authored the ToolLLM paper, contributing to the integration of language models with real-world APIs.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ZHUYUAN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Liu is a researcher who co-authored the ToolLLM paper, focusing on facilitating language models' capabilities.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MAOSONG SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Maosong Sun is a researcher who co-authored the ToolLLM paper, contributing to advancements in language model integration.
Maosong Sun is a researcher involved in enhancing chat language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ABULHAIR SAPAROV">
      <data key="d0">PERSON</data>
      <data key="d1">Abulhair Saparov is a researcher who co-authored a paper analyzing the reasoning capabilities of language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HE HE">
      <data key="d0">PERSON</data>
      <data key="d1">He He is a researcher who co-authored a paper analyzing the reasoning capabilities of language models, focusing on chain-of-thought reasoning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="TIMO SCHICK">
      <data key="d0">PERSON</data>
      <data key="d1">Timo Schick is a researcher who co-authored the Toolformer paper, focusing on language models teaching themselves to use tools.
Timo Schick is a researcher who co-authored a paper on Toolformer.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JANE DWIVEDI-YU">
      <data key="d0">PERSON</data>
      <data key="d1">Jane Dwivedi-Yu is a researcher who co-authored the Toolformer paper, contributing to advancements in language model capabilities.
Jane Dwivedi-Yu is a researcher who co-authored a paper on Toolformer.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROBERTO DESSI">
      <data key="d0">PERSON</data>
      <data key="d1">Roberto Dess&#236; is a researcher who co-authored the Toolformer paper, focusing on language models' self-teaching capabilities.
Roberto Dessi is a researcher who co-authored a paper on Toolformer.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROBERTA RAILEANU">
      <data key="d0">PERSON</data>
      <data key="d1">Roberta Raileanu is a researcher who co-authored the Toolformer paper, contributing to advancements in language model integration.
Roberta Raileanu is a researcher who co-authored a paper on Toolformer.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MARIA LOMELI">
      <data key="d0">PERSON</data>
      <data key="d1">Maria Lomeli is a researcher who co-authored the Toolformer paper, focusing on enhancing language models' capabilities.
Maria Lomeli is a researcher who co-authored a paper on Toolformer.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LUKE ZETTLEMOYER">
      <data key="d0">PERSON</data>
      <data key="d1">Luke Zettlemoyer is a researcher who co-authored the Toolformer paper, contributing to advancements in language model integration.
Luke Zettlemoyer is a researcher who co-authored a paper on Toolformer.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NICOLA CANCEDDA">
      <data key="d0">PERSON</data>
      <data key="d1">Nicola Cancedda is a researcher who co-authored the Toolformer paper, focusing on language models' self-teaching capabilities.
Nicola Cancedda is a researcher who co-authored a paper on Toolformer.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="THOMAS SCIALOM">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Scialom is a researcher who co-authored the Toolformer paper, contributing to advancements in language model capabilities.
Thomas Scialom is a researcher contributing to the field of language models.Thomas Scialom is a researcher contributing to advancements in language models.
Thomas Scialom is a researcher who co-authored a paper on Toolformer.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YONATAN BISK">
      <data key="d0">PERSON</data>
      <data key="d1">Yonatan Bisk is a researcher who co-authored the ALFWorld paper, focusing on aligning text and embodied environments for interactive learning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ADAM TRISCHLER">
      <data key="d0">PERSON</data>
      <data key="d1">Adam Trischler is a researcher who co-authored the ALFWorld paper, contributing to advancements in interactive learning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MATTHEW HAUSKNECHT">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew Hausknecht is a researcher who co-authored the ALFWorld paper, focusing on aligning text and environments for learning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DAVID SILVER">
      <data key="d0">PERSON</data>
      <data key="d1">David Silver is a researcher known for his work on reinforcement learning and has co-authored papers on game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="AJA HUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Aja Huang is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CHRIS J. MADDISON">
      <data key="d0">PERSON</data>
      <data key="d1">Chris J. Maddison is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ARTHUR GUEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Arthur Guez is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="L. SIFRE">
      <data key="d0">PERSON</data>
      <data key="d1">L. Sifre is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="GEORGE VAN DEN DRIESSCHE">
      <data key="d0">PERSON</data>
      <data key="d1">George van den Driessche is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JULIAN SCHRITTWIESER">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Schrittwieser is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="IOANNIS ANTONOGLOU">
      <data key="d0">PERSON</data>
      <data key="d1">Ioannis Antonoglou is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="VEDAVYAS PANNEERSHELVAM">
      <data key="d0">PERSON</data>
      <data key="d1">Vedavyas Panneershelvam is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARC LANCTOT">
      <data key="d0">PERSON</data>
      <data key="d1">Marc Lanctot is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SANDER DIELEMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Sander Dieleman is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DOMINIK GREWE">
      <data key="d0">PERSON</data>
      <data key="d1">Dominik Grewe is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JOHN NHAM">
      <data key="d0">PERSON</data>
      <data key="d1">John Nham is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NAL KALCHBRENNER">
      <data key="d0">PERSON</data>
      <data key="d1">Nal Kalchbrenner is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="TIMOTHY P. LILLICRAP">
      <data key="d0">PERSON</data>
      <data key="d1">Timothy P. Lillicrap is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MADELEINE LEACH">
      <data key="d0">PERSON</data>
      <data key="d1">Madeleine Leach is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KORAY KAVUKCUOGLU">
      <data key="d0">PERSON</data>
      <data key="d1">Koray Kavukcuoglu is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="THORE GRAEPEL">
      <data key="d0">PERSON</data>
      <data key="d1">Thore Graepel is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DEMIS HASABIS">
      <data key="d0">PERSON</data>
      <data key="d1">Demis Hassabis is a researcher who co-authored papers on reinforcement learning and game mastery using deep neural networks.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HAOTIAN SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Haotian Sun is a researcher who co-authored the AdaPlanner paper, focusing on adaptive planning with language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUCHEN ZHUANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuchen Zhuang is a researcher who co-authored the AdaPlanner paper, contributing to advancements in adaptive planning.
Yuchen Zhuang is a researcher who co-authored a paper on efficient action space navigation in large language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="LINGKAI KONG">
      <data key="d0">PERSON</data>
      <data key="d1">Lingkai Kong is a researcher who co-authored the AdaPlanner paper, focusing on feedback mechanisms in planning.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CHAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chao Zhang is a researcher who co-authored the AdaPlanner paper, focusing on adaptive planning with language models.
Chao Zhang is a researcher who co-authored the ToolChain* paper, contributing to advancements in action space navigation.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="DIDAC SURIS">
      <data key="d0">PERSON</data>
      <data key="d1">D&#237;dac Sur&#237;s is a researcher who co-authored the ViperGPT paper, focusing on visual inference via Python execution.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SACHIT MENON">
      <data key="d0">PERSON</data>
      <data key="d1">Sachit Menon is a researcher who co-authored the ViperGPT paper, contributing to advancements in visual inference.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CARL VONDRICK">
      <data key="d0">PERSON</data>
      <data key="d1">Carl Vondrick is a researcher who co-authored the ViperGPT paper, focusing on reasoning through visual inference.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MACIEJ SWIECHOWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Maciej Swiechowski is a researcher who co-authored a review on Monte Carlo tree search and its applications.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KONRAD GODLEWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Konrad Godlewski is a researcher who co-authored a review on Monte Carlo tree search, focusing on recent modifications.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BARTOSZ SAWICKI">
      <data key="d0">PERSON</data>
      <data key="d1">Bartosz Sawicki is a researcher who co-authored a review on Monte Carlo tree search and its applications.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JACEK MA&#8217;NDZIUK">
      <data key="d0">PERSON</data>
      <data key="d1">Jacek Ma&#8217;ndziuk is a researcher who co-authored a review on Monte Carlo tree search, focusing on its applications in AI.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HUGO TOUVRON">
      <data key="d0">PERSON</data>
      <data key="d1">Hugo Touvron is a researcher who co-authored a paper on visual inference and its applications in AI.
Hugo Touvron is a researcher involved in the development of language models and related technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LOUIS MARTIN">
      <data key="d0">PERSON</data>
      <data key="d1">Louis Martin is a researcher who co-authored a paper on visual inference and its applications in AI.
Louis Martin is a researcher contributing to advancements in language models and AI technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KEVIN R. STONE">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin R. Stone is a researcher who co-authored a paper on visual inference and its applications in AI.
Kevin R. Stone is a researcher focused on language models and their applications.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PETER ALBERT">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Albert is a researcher who co-authored a paper on visual inference and its applications in AI.
Peter Albert is a researcher working on language models and AI methodologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AMJAD ALMAHAIRI">
      <data key="d0">PERSON</data>
      <data key="d1">Amjad Almahairi is a researcher who co-authored a paper on visual inference and its applications in AI.
Amjad Almahairi is a researcher contributing to the field of language models and AI.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YASMINE BABAIEI">
      <data key="d0">("ENTITY"</data>
      <data key="d1">YASMINE BABAIEI</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NIKOLAY BASHLYKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Nikolay Bashlykov is a researcher who co-authored a paper on visual inference and its applications in AI.
Nikolay Bashlykov is a researcher contributing to advancements in language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SOUMYA BATRA">
      <data key="d0">PERSON</data>
      <data key="d1">Soumya Batra is a researcher who co-authored a paper on visual inference and its applications in AI.
Soumya Batra is a researcher focused on language models and AI technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PRAJJWAL BHARGAVA">
      <data key="d0">PERSON</data>
      <data key="d1">Prajjwal Bhargava is a researcher who co-authored a paper on visual inference and its applications in AI.
Prajjwal Bhargava is a researcher working on language models and their applications.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SHRUTI BHOSALE">
      <data key="d0">PERSON</data>
      <data key="d1">Shruti Bhosale is a researcher who co-authored a paper on visual inference and its applications in AI.
Shruti Bhosale is a researcher contributing to the field of language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DANIEL M. BIKEL">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel M. Bikel is a researcher who co-authored a paper on visual inference and its applications in AI.
Daniel M. Bikel is a researcher involved in language model development.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LUKAS BLECHER">
      <data key="d0">PERSON</data>
      <data key="d1">Lukas Blecher is a researcher who co-authored a paper on visual inference and its applications in AI.
Lukas Blecher is a researcher focused on advancements in language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CRISTIAN CANT&#211;N FERRER">
      <data key="d0">PERSON</data>
      <data key="d1">Cristian Cant&#243;n Ferrer is a researcher who co-authored a paper on visual inference and its applications in AI.
Cristian Cant&#243;n Ferrer is a researcher contributing to language model technologies.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MOYA CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Moya Chen is a researcher who co-authored a paper on visual inference and its applications in AI.
Moya Chen is a researcher involved in the development of language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="GUILLEM CUCURULL">
      <data key="d0">PERSON</data>
      <data key="d1">Guillem Cucurull is a researcher who co-authored a paper on visual inference and its applications in AI.)&lt;|COMPLETE|&gt;
Guillem Cucurull is a researcher focused on language models and AI.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YASMINE BABAIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yasmine Babaie is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DAVID ESIOSU">
      <data key="d0">PERSON</data>
      <data key="d1">David Esiosu is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JUDE FERNANDES">
      <data key="d0">PERSON</data>
      <data key="d1">Jude Fernandes is a researcher working on language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEREMY FU">
      <data key="d0">PERSON</data>
      <data key="d1">Jeremy Fu is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WENYIN FU">
      <data key="d0">PERSON</data>
      <data key="d1">Wenyin Fu is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BRIAN FULLER">
      <data key="d0">PERSON</data>
      <data key="d1">Brian Fuller is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CYNTHIA GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Cynthia Gao is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VEDANUJ GOSWAMI">
      <data key="d0">PERSON</data>
      <data key="d1">Vedanuj Goswami is a researcher focused on language models and AI technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NAMAN GOYAL">
      <data key="d0">PERSON</data>
      <data key="d1">Naman Goyal is a researcher contributing to advancements in language models.
Naman Goyal is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANTHONY S. HARTSHORN">
      <data key="d0">PERSON</data>
      <data key="d1">Anthony S. Hartshorn is a researcher working on language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SAGHAR HOSSEINI">
      <data key="d0">PERSON</data>
      <data key="d1">Saghar Hosseini is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RUI HOU">
      <data key="d0">PERSON</data>
      <data key="d1">Rui Hou is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="HAKAN INAN">
      <data key="d0">PERSON</data>
      <data key="d1">Hakan Inan is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MARCIN KARDAS">
      <data key="d0">PERSON</data>
      <data key="d1">Marcin Kardas is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VIKTOR KERKEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Viktor Kerkez is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MADIAN KHABSA">
      <data key="d0">PERSON</data>
      <data key="d1">Madian Khabsa is a researcher contributing to language model technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ISABEL M. KLOUMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Isabel M. Kloumann is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="A. V. KORENEV">
      <data key="d0">PERSON</data>
      <data key="d1">A. V. Korenev is a researcher focused on language models and AI.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUNIT SINGH KOURA">
      <data key="d0">PERSON</data>
      <data key="d1">Punit Singh Koura is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MARIE-ANNE LACHAUX">
      <data key="d0">PERSON</data>
      <data key="d1">Marie-Anne Lachaux is a researcher working on language models and their applications.
Marie-Anne Lachaux is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="THIBAUT LAVRIL">
      <data key="d0">PERSON</data>
      <data key="d1">Thibaut Lavril is a researcher involved in the development of language models.
Thibaut Lavril is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JENYA LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Jenya Lee is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DIANA LISKOVICH">
      <data key="d0">PERSON</data>
      <data key="d1">Diana Liskovich is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YINGHAI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yinghai Lu is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUNING MAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yuning Mao is a researcher focused on language models and AI technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XAVIER MARTINET">
      <data key="d0">PERSON</data>
      <data key="d1">Xavier Martinet is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TODOR MIHAYLOV">
      <data key="d0">PERSON</data>
      <data key="d1">Todor Mihaylov is a researcher working on language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUSHKAR MISHRA">
      <data key="d0">PERSON</data>
      <data key="d1">Pushkar Mishra is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="IGOR MOLYBOG">
      <data key="d0">PERSON</data>
      <data key="d1">Igor Molybog is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YIXIN NIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yixin Nie is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANDREW POULTON">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Poulton is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEREMY REIZENSTEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Jeremy Reizenstein is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RASHI RUNGTA">
      <data key="d0">PERSON</data>
      <data key="d1">Rashi Rungta is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KALYAN SALADI">
      <data key="d0">PERSON</data>
      <data key="d1">Kalyan Saladi is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ALAN SCHELTON">
      <data key="d0">PERSON</data>
      <data key="d1">Alan Schelton is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RUAN SILVA">
      <data key="d0">PERSON</data>
      <data key="d1">Ruan Silva is a researcher contributing to language model technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ERIC MICHAEL SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Michael Smith is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="R. SUBRAMANIAN">
      <data key="d0">PERSON</data>
      <data key="d1">R. Subramanian is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XIA TAN">
      <data key="d0">PERSON</data>
      <data key="d1">Xia Tan is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BINH TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Binh Tang is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROSS TAYLOR">
      <data key="d0">PERSON</data>
      <data key="d1">Ross Taylor is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ADINA WILLIAMS">
      <data key="d0">PERSON</data>
      <data key="d1">Adina Williams is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JIAN XIANG KUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Jian Xiang Kuan is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUXIN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Puxin Xu is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ZHENGXU YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Zhengxu Yan is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ILIYAN ZAROV">
      <data key="d0">PERSON</data>
      <data key="d1">Iliyan Zarov is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANGELA FAN">
      <data key="d0">PERSON</data>
      <data key="d1">Angela Fan is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MELANIE KAMBADUR">
      <data key="d0">PERSON</data>
      <data key="d1">Melanie Kambadur is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AURELIEN RODRIGUEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Aurelien Rodriguez is a researcher contributing to the field of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROBERT STOJNIC">
      <data key="d0">PERSON</data>
      <data key="d1">Robert Stojnic is a researcher involved in language model development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SERGEY EDUNOV">
      <data key="d0">PERSON</data>
      <data key="d1">Sergey Edunov is a researcher involved in the development of language models.Sergey Edunov is a researcher focused on advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LANGUAGE AGENT TREE SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Language Agent Tree Search is a method that unifies reasoning, acting, and planning in language models.
The Language Agent Tree Search is a method that unifies reasoning, acting, and planning in language models, facilitating decision-making processes in various tasks.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="VOYAGER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Voyager is an open-ended embodied agent that utilizes large language models for various tasks.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHAIN OF THOUGHT PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain of thought prompting is a technique that elicits reasoning in large language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="INTELLIGENT AGENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Intelligent agents are systems that can reason, act, and plan, often discussed in the context of AI.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DAYDREAMER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Daydreamer is a model for physical robot learning that utilizes world models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DECOMPOSITION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Decomposition is a method that enhances reasoning through self-evaluation guided decoding.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WEBSHOP">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">WebShop is a system aimed at scalable real-world web interaction with grounded language agents.
WebShop is a dataset used for evaluating language models in the context of web search tasks.
WebShop is an interactive web-based environment that evaluates agents on grounded language understanding and decision-making in an e-commerce context.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="TREE OF THOUGHTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Tree of thoughts is a method for deliberate problem solving using large language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MASTERING ATARI GAMES">
      <data key="d0">RESEARCH</data>
      <data key="d1">Mastering Atari games with limited data is a research area focused on AI learning in gaming environments.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LEAST-TO-MOST PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Least-to-most prompting is a method that enables complex reasoning in large language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TOOLCHAIN*">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ToolChain* is a system for efficient action space navigation in large language models using A* search.
</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="HOWARD CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Howard Chen is a researcher contributing to the development of language models and AI systems.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JOHN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">John Yang is a researcher focused on advancements in language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KARTHIK R NARASIMHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Karthik R Narasimhan is a researcher involved in the development of language models and AI technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KEN GOLDBERG">
      <data key="d0">PERSON</data>
      <data key="d1">Ken Goldberg is a researcher involved in the development of AI systems and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XUEZHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xuezhi Wang is a researcher contributing to advancements in language models and AI technologies.
Xuezhi Wang is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.
Xuezhi Wang is a researcher who has contributed to reasoning in language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JASON WEI">
      <data key="d0">PERSON</data>
      <data key="d1">Jason Wei is a researcher focused on language models and their applications.
Jason Wei is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.
Jason Wei is a researcher involved in prompting techniques for large language models.
Jason Wei is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QUOC LE">
      <data key="d0">PERSON</data>
      <data key="d1">Quoc Le is a researcher contributing to advancements in language models and AI technologies.
Quoc Le is a researcher who has contributed to the development of prompting techniques for large language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ED CHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ed Chi is a researcher focused on AI systems and language models.
Ed Chi is a researcher involved in the study of reasoning in large language models, particularly through least-to-most prompting.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUXI XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yuxi Xie is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KENJI KAWAGUCHI">
      <data key="d0">PERSON</data>
      <data key="d1">Kenji Kawaguchi is a researcher focused on language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YIRAN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiran Zhao is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XU ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Xu Zhao is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MIN-YEN KAN">
      <data key="d0">PERSON</data>
      <data key="d1">Min-Yen Kan is a researcher focused on language models and their applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JUNXIAN HE">
      <data key="d0">PERSON</data>
      <data key="d1">Junxian He is a researcher involved in the development of language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="QIZHE XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Qizhe Xie is a researcher contributing to advancements in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PHILIPP WU">
      <data key="d0">PERSON</data>
      <data key="d1">Philipp Wu is a researcher focused on AI technologies and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MONTE CARLO TREE SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Monte Carlo Tree Search is a method used in reinforcement learning and decision-making processes.
Monte Carlo Tree Search is a heuristic search algorithm used for decision-making tasks, particularly in AI applications.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="A* SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A* Search is an algorithm used for pathfinding and graph traversal, commonly applied in AI.
A* search is an algorithm used for pathfinding and graph traversal, which is applied in the context of action space navigation in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MONTY CARLO TREE SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Monte Carlo Tree Search is a heuristic search algorithm for decision processes.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHAIN OF THOUGHT REASONING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain of Thought Reasoning is a method that enhances reasoning capabilities in language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PROBLEM SOLVING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Problem Solving is a cognitive process aimed at finding solutions to complex issues, often discussed in AI contexts.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SCALABLE WEB INTERACTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Scalable Web Interaction refers to systems designed for efficient interaction with web services using AI.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="EXPLAINABLE AI">
      <data key="d0">CONCEPT</data>
      <data key="d1">Explainable AI refers to methods and techniques that make the decision-making processes of AI systems understandable to humans.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="EMNLP">
      <data key="d0">CONFERENCE</data>
      <data key="d1">EMNLP is a conference focused on natural language processing and computational linguistics.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ICLR">
      <data key="d0">CONFERENCE</data>
      <data key="d1">ICLR is a conference that focuses on learning representations and deep learning.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NEURIPS">
      <data key="d0">CONFERENCE</data>
      <data key="d1">NeurIPS is a conference that covers advancements in neural information processing systems and machine learning.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CORL">
      <data key="d0">CONFERENCE</data>
      <data key="d1">CoRL is a conference focused on robot learning and reinforcement learning.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AI RESEARCH">
      <data key="d0">FIELD</data>
      <data key="d1">AI Research encompasses various studies and advancements in artificial intelligence technologies.
AI research encompasses the study and development of artificial intelligence technologies and methodologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROBOTICS">
      <data key="d0">FIELD</data>
      <data key="d1">Robotics is a field of engineering and AI focused on the design and application of robots.
Robotics is the branch of technology that deals with the design, construction, operation, and use of robots, often involving AI and machine learning techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AGENT-BASED SYSTEMS">
      <data key="d0">FIELD</data>
      <data key="d1">Agent-based systems are computational systems that use autonomous agents to perform tasks and solve problems.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AI ETHICS">
      <data key="d0">FIELD</data>
      <data key="d1">AI Ethics is a field that examines the moral implications and societal impacts of artificial intelligence technologies.
AI ethics is the field of study that examines the moral implications and societal impacts of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AI SYSTEMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Systems refer to computational systems that utilize artificial intelligence to perform tasks and make decisions.
AI systems are integrated systems that utilize artificial intelligence technologies to perform tasks or solve problems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI TECHNOLOGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Technologies encompass various tools and methods used in the development and application of artificial intelligence.
AI technologies encompass a wide range of tools and methods used to create intelligent systems, including machine learning, natural language processing, and robotics.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI APPLICATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Applications refer to the practical uses of artificial intelligence in various fields and industries.
AI applications refer to the practical uses of artificial intelligence technologies in various fields, including healthcare, finance, and education.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI MODELS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Models are mathematical representations used to simulate and predict behaviors in artificial intelligence systems.
AI models are algorithms or mathematical representations that simulate human-like intelligence to perform specific tasks, relevant to many discussed papers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI TOOLS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Tools are software and applications designed to assist in the development and implementation of AI technologies.
AI tools are software applications that utilize artificial intelligence to perform tasks, often enhancing productivity and efficiency in various fields.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI FRAMEWORKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Frameworks are structured environments that facilitate the development and deployment of AI applications.
AI frameworks are structured approaches or methodologies for developing and implementing artificial intelligence systems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI PLATFORMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Platforms are comprehensive solutions that provide tools and services for building and deploying AI applications.
AI platforms are software environments that provide tools and services for developing and deploying AI applications.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI SOLUTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Solutions refer to specific implementations of AI technologies to address particular problems or needs.
AI solutions are specific applications or systems designed to address particular problems using artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI STRATEGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Strategies are plans and approaches for effectively utilizing artificial intelligence in various contexts.
AI strategies are plans or approaches developed to effectively implement artificial intelligence technologies in various contexts.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI INNOVATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Innovations refer to new and creative advancements in the field of artificial intelligence.
AI innovations refer to new and improved methods, technologies, or applications in the field of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI TRENDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Trends are emerging patterns and directions in the development and application of artificial intelligence.
AI trends refer to the current directions and developments in the field of artificial intelligence, influencing research and applications.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI CHALLENGES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Challenges refer to the obstacles and issues faced in the development and implementation of AI technologies.
AI challenges are obstacles or issues faced in the development and implementation of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI OPPORTUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Opportunities are potential areas for growth and advancement in the field of artificial intelligence.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI RESEARCH DIRECTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Research Directions refer to the future paths and areas of focus in artificial intelligence research.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI COLLABORATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Collaborations are partnerships and joint efforts in the field of artificial intelligence research and development.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Communities are groups of individuals and organizations focused on advancing artificial intelligence technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI EDUCATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Education refers to the teaching and learning of artificial intelligence concepts and technologies.AI Education refers to
AI education refers to the teaching and learning of artificial intelligence concepts and technologies, often integrated into academic curricula.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI TRAINING">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Training involves the process of teaching AI models to perform specific tasks using data.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI EVALUATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Evaluation refers to the assessment of AI models and systems to determine their effectiveness and performance.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI DEPLOYMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Deployment is the process of implementing AI models and systems in real-world applications.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI MAINTENANCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Maintenance involves the ongoing support and updates of AI systems to ensure their functionality and relevance.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI REGULATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Regulations refer to the legal and ethical guidelines governing the use of artificial intelligence technologies.
AI regulations are laws and guidelines established to ensure the ethical and responsible use of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI STANDARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Standards are established criteria and benchmarks for the development and application of AI technologies.
AI standards are established criteria and benchmarks for the development and evaluation of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI POLICIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Policies are guidelines and rules governing the use and development of artificial intelligence technologies.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI BEST PRACTICES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Best Practices are recommended methods and techniques for effectively utilizing artificial intelligence.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AI METHODOLOGIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI Methodologies are systematic approaches to conducting research and development in artificial intelligence.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="OLIVIER BOUSQUET">
      <data key="d0">PERSON</data>
      <data key="d1">Olivier Bousquet is a researcher known for his work on prompting methods in large language models, particularly in the context of complex reasoning.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="XIANG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xiang Chen is a researcher who contributed to the development of the ToolChain* method for action space navigation in large language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="TONG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Tong Yu is a researcher involved in the ToolChain* project, focusing on navigation in large language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SAAYAN MITRA">
      <data key="d0">PERSON</data>
      <data key="d1">Saayan Mitra is a researcher who co-authored the ToolChain* paper, contributing to action space navigation in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="VICTOR BURSZTYN">
      <data key="d0">PERSON</data>
      <data key="d1">Victor Bursztyn is a researcher associated with the ToolChain* project, focusing on efficient navigation in large language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="RYAN A. ROSSI">
      <data key="d0">PERSON</data>
      <data key="d1">Ryan A. Rossi is a researcher who contributed to the ToolChain* project, which enhances action space navigation in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SOMDEB SARKHEL">
      <data key="d0">PERSON</data>
      <data key="d1">Somdeb Sarkhel is a researcher involved in the ToolChain* project, focusing on large language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="TOOLBENCH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ToolBench is a framework for evaluating language models with tool use capabilities.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ALFWORLD">
      <data key="d0">DATASET</data>
      <data key="d1">Alfworld is a dataset used for evaluating text-based manipulation tasks in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="WANG ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Wang et al. (2022) is a reference to a study discussing the CoT-SC method in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="EXPERIMENTAL RESULTS">
      <data key="d0">DATA</data>
      <data key="d1">Experimental results refer to the data and findings obtained from testing the LATS algorithm across various tasks and environments.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ENVIRONMENT DETAILS">
      <data key="d0">DATA</data>
      <data key="d1">Environment details provide information about the settings and conditions under which experiments with the LATS algorithm were conducted.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="PROMPTS">
      <data key="d0">DATA</data>
      <data key="d1">Prompts are specific queries or instructions used in the LATS algorithm to guide the language model's responses in different environments.
Prompts are specific instructions or queries used to elicit responses from language models during the training process.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="TRIALS">
      <data key="d0">DATA</data>
      <data key="d1">Trials refer to the repeated tests conducted to evaluate the performance and efficiency of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="RESOURCE CONSTRAINTS">
      <data key="d0">DATA</data>
      <data key="d1">Resource constraints refer to the limitations in computational resources that may affect the implementation of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="REAL-WORLD ENVIRONMENTS">
      <data key="d0">DATA</data>
      <data key="d1">Real-world environments are practical applications where the LATS algorithm can be utilized, such as programming and web search tasks.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="INTERACTIVE ENVIRONMENTS">
      <data key="d0">DATA</data>
      <data key="d1">Interactive environments are settings where the LATS algorithm can engage with users or systems to perform tasks.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ACTION SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The action space defines the set of possible actions that can be taken by the LATS algorithm, including searching for entities and looking up strings in the Wikipedia API.
The action space of Web Shop defines the various actions users can take while interacting with the platform, such as searching, selecting items, and viewing details.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="WIKIPEDIA">
      <data key="d0">RESOURCE</data>
      <data key="d1">Wikipedia is a free online encyclopedia that provides a wealth of information, which is utilized by the LATS algorithm for interactive information retrieval.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="SAMPLING SIZE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Sampling size refers to the number of trajectories or samples taken during the evaluation of an algorithm, impacting the performance and results observed.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="EXPLORATION WEIGHT">
      <data key="d0">PARAMETER</data>
      <data key="d1">Exploration weight is a parameter in the selection formula that influences the effectiveness of the search process in algorithms like LATS, affecting performance outcomes.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="DEPTH">
      <data key="d0">PARAMETER</data>
      <data key="d1">Depth is a parameter that limits the maximum number of steps an algorithm can take in a decision-making process, impacting the performance and efficiency of the search.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="PERFORMANCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Performance refers to the effectiveness of an algorithm in completing tasks, often measured through metrics like accuracy or efficiency in answering questions.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="INTERACTIVE INFORMATION RETRIEVAL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Interactive information retrieval is a method that allows users to search for entities and retrieve relevant information from a database or knowledge base, such as Wikipedia.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="ENTITY WIKI PAGE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">An entity wiki page is a dedicated page on Wikipedia that contains information about a specific entity, including its attributes and related topics.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="SEARCH">
      <data key="d0">FUNCTION</data>
      <data key="d1">Search is a function that retrieves the first five sentences from an entity's wiki page or suggests similar entities if the page does not exist.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="LOOKUP">
      <data key="d0">FUNCTION</data>
      <data key="d1">Lookup is a function that returns the next sentence in a page based on a given string.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="FINISH">
      <data key="d0">FUNCTION</data>
      <data key="d1">Finish is a function that completes the current task with a specified answer.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="HUMANEVAL DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The HumanEval dataset is a collection of programming problems used to evaluate the functional correctness of models that synthesize programs from natural language descriptions.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d0">DATASET</data>
      <data key="d1">The Mostly Basic Programming Problems (MBPP) benchmark is a dataset of short Python functions designed to assess program synthesis techniques.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="AGENTS">
      <data key="d0">AGENT</data>
      <data key="d1">Agents are automated systems that interact with the WebShop environment to perform tasks such as searching for products and making purchases.
Agents are entities powered by LLMs that perform specific roles within the workflows, contributing to the generation and refinement of instructions.
Agents are automated systems that generate questions or modify text based on predefined criteria in educational contexts.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="PRODUCTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Products are items available for purchase in the WebShop environment, containing various attributes and options for customization.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="E-COMMERCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">E-commerce refers to the buying and selling of goods and services over the internet, which is simulated in the WebShop environment.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="FUNCTION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="EXACT MATCH (EM)">
      <data key="d0">METRIC</data>
      <data key="d1">Exact Match (EM) is a metric used to evaluate the performance of models by checking if the generated answer exactly matches the ground truth.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="PASS@K">
      <data key="d0">METRIC</data>
      <data key="d1">Pass@k is a metric that evaluates the success rate of a model by determining if any of the k generated samples pass all tests for a given problem.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d0">PARAMETER</data>
      <data key="d1">Value function hyperparameters are settings used to optimize the performance of language models in various tasks, such as &#955; values for scoring.
Value function hyperparameters are specific settings used to optimize the performance of the Web Shop's decision-making algorithms.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="SUCCESS RATE (SR)">
      <data key="d0">METRIC</data>
      <data key="d1">Success Rate (SR) is a metric that measures the portion of instructions successfully executed by the system, defined as r=1.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HOTPOTQA PROMPTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">HotPotQA prompts are structured instructions designed to guide question-answering tasks using reasoning and observation steps.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Thought refers to the reasoning process that occurs during a question-answering task, guiding the actions taken to find an answer.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ACTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Action represents the steps taken in response to a Thought during a question-answering task, such as searching for information or finishing an answer.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITEM-DETAIL">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Item-Detail provides comprehensive information about a specific item, including its description, attributes, and purchasing options.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EPISODE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Episode refers to a distinct instance or session of interaction within the Web Shop, where users can perform actions and receive rewards.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ENVIRONMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Environments refer to the different settings or scenarios in which experiments are conducted to evaluate the performance of the Web Shop system.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITEM">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PLAINS">
      <data key="d0">GEOGRAPHICAL FEATURE</data>
      <data key="d1">Plains are flat or gently rolling areas of land that rise in elevation, typically characterized by their expansive and open landscapes.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="ELEVATION">
      <data key="d0">MEASUREMENT</data>
      <data key="d1">Elevation refers to the height of a geographical feature above a reference point, usually sea level, measured in feet or meters.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="ARTHUR&#8217;S MAGAZINE">
      <data key="d0">PUBLICATION</data>
      <data key="d1">Arthur&#8217;s Magazine was an American literary periodical published in Philadelphia in the 19th century, known for featuring works by notable authors.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="FIRST FOR WOMEN">
      <data key="d0">PUBLICATION</data>
      <data key="d1">First for Women is a magazine that focuses on topics relevant to women, including health, lifestyle, and personal stories.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="EDGAR A. POE">
      <data key="d0">PERSON</data>
      <data key="d1">Edgar A. Poe was a notable author whose work was featured in Arthur&#8217;s Magazine, known for his contributions to American literature.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="J.H. INGRAHAM">
      <data key="d0">PERSON</data>
      <data key="d1">J.H. Ingraham was an author whose works were published in Arthur&#8217;s Magazine, contributing to its literary significance.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="SARAH JOSEPHA HALE">
      <data key="d0">PERSON</data>
      <data key="d1">Sarah Josepha Hale was a prominent writer featured in Arthur&#8217;s Magazine, recognized for her contributions to literature and women&#8217;s rights.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="THOMAS G. SPEAR">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas G. Spear was an author whose works appeared in Arthur&#8217;s Magazine, adding to its diverse literary offerings.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="TIMOTHY SHAY ARTHUR">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="ADD FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">The add function is a Python function designed to take two integers as input and return their total value. However, the initial implementation incorrectly subtracts the second integer from the first instead of adding them together.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="UNIT TEST RESULTS">
      <data key="d0">TESTING</data>
      <data key="d1">Unit test results provide feedback on the performance of the add function, indicating which tests passed and which failed, thus guiding improvements in the implementation.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="REFLECTION ON IMPLEMENTATION">
      <data key="d0">ANALYSIS</data>
      <data key="d1">The reflection on the implementation discusses the errors in the add function, specifically the incorrect use of the subtraction operator instead of the addition operator, and suggests a fix.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="IMPROVED IMPLEMENTATION">
      <data key="d0">FUNCTION</data>
      <data key="d1">The improved implementation of the add function corrects the previous error by changing the operator from subtraction to addition, ensuring the function returns the correct output for the given input.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BRIGHT CITRUS DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">Bright Citrus Deodorant is a product designed for sensitive skin, available in a 3-ounce bottle, and is priced under $50.00.
Bright Citrus Deodorant by Earth Mama is a natural deodorant designed for sensitive skin, pregnancy, and breastfeeding, containing organic calendula and available in a 3-ounce size.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="TEST CASE">
      <data key="d0">TESTING</data>
      <data key="d1">A test case is a set of conditions or variables under which a tester will determine whether a function or system is working correctly.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="SEARCH ACTION">
      <data key="d0">ACTION</data>
      <data key="d1">The search action is a command executed in the Web Shop to find products based on user-defined criteria, such as product type and price.
The Search Action is a command executed to find specific items based on user-defined criteria in an online shopping context.
Search action refers to the user's attempt to find specific products online, indicating their preferences and constraints.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7,6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="CLICK ACTION">
      <data key="d0">ACTION</data>
      <data key="d1">The click action is a command executed in the Web Shop to select a specific product from the search results for more details.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="UNIT TEST">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="VALUE FUNCTION PROMPT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Value Function Prompt is a method used to analyze purchasing trajectories and evaluate their correctness based on specified criteria.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS">
      <data key="d0">PRODUCT</data>
      <data key="d1">The Dairy Free and Apple Variety Pack of Chips is a specific type of snack item that meets dietary restrictions and flavor preferences.
A specific type of snack that is both dairy-free and includes apple flavor, sought after for its dietary restrictions and flavor profile.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE FOODS">
      <data key="d0">BRAND</data>
      <data key="d1">Enjoy Life Foods is a brand that offers a variety of allergen-free snacks, including soft baked ovals and chewy bars, catering to dietary needs.
Enjoy Life Foods is a brand that specializes in allergen-free snacks, including various types of bars and chips.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="CORRECTNESS SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">The Correctness Score is a numerical evaluation of how well a purchasing action meets the specified requirements, ranging from 1 to 10.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="CALMING LAVENDER DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">Calming Lavender Deodorant by Earth Mama is a natural deodorant designed for sensitive skin, pregnancy, and breastfeeding, containing organic ingredients and available in a 3-ounce size.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="TRAVEL SET (4-PACK)">
      <data key="d0">PRODUCT</data>
      <data key="d1">The Travel Set (4-Pack) is a collection of various deodorant scents offered by Earth Mama, designed for convenience and portability.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="3 OUNCE (PACK OF 1)">
      <data key="d0">PRODUCT</data>
      <data key="d1">The 3 Ounce (Pack of 1) refers to a single unit of deodorant, suitable for individual use, particularly for sensitive skin.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="3-OUNCE (2-PACK)">
      <data key="d0">PRODUCT</data>
      <data key="d1">The 3-Ounce (2-Pack) is a collection of two units of deodorant, designed for users who prefer to have a backup or share with others.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="NATURAL AND SAFE FOR SENSITIVE SKIN">
      <data key="d0">FEATURE</data>
      <data key="d1">Natural and safe for sensitive skin indicates that the product is formulated without harsh chemicals, making it suitable for individuals with skin sensitivities.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ORGANIC CALENDULA">
      <data key="d0">INGREDIENT</data>
      <data key="d1">Organic Calendula is a natural ingredient used in the formulation of the deodorant, known for its soothing properties.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="GINGER FRESH DEODORANT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="SOFT BAKED OVALS">
      <data key="d0">PRODUCT</data>
      <data key="d1">Soft Baked Ovals are a type of breakfast bar produced by Enjoy Life Foods, designed to be nut-free, soy-free, dairy-free, and gluten-free.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SOFT BAKED CHEWY BARS">
      <data key="d0">PRODUCT</data>
      <data key="d1">Soft Baked Chewy Bars are another product from Enjoy Life Foods, available in a variety pack and meeting dietary restrictions.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="LENTIL CHIPS VARIETY PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">Lentil Chips Variety Pack is a snack option from Enjoy Life Foods that is dairy-free, soy-free, nut-free, and gluten-free.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON">
      <data key="d0">PRODUCT</data>
      <data key="d1">A specific type of vegetarian bacon that is gluten-free and sought after for its flavor and dietary compliance.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="LOUISVILLE VEGAN JERKY">
      <data key="d0">BRAND</data>
      <data key="d1">Louisville Vegan Jerky is a brand that offers a variety of vegan jerky products, including different flavor packs.
Louisville Vegan Jerky is a plant-based snack made from non-GMO soy protein, available in a variety pack with different flavors, and is gluten-free.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="SMOKED BACON SEA SALT 3-PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A product that includes three flavors of smoked bacon sea salt, marketed as gluten-free and non-GMO.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SPICY HOT PEPPER SEA SALT 3-PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A product that includes three flavors of spicy hot pepper sea salt, also marketed as gluten-free and non-GMO.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="0.8 OUNCE (PACK OF 24)">
      <data key="d0">PRODUCT</data>
      <data key="d1">A specific packaging size for snacks, indicating that the product contains 24 bags, each weighing 0.8 ounces.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="PRICE">
      <data key="d0">VALUE</data>
      <data key="d1">The cost associated with a product, which is a critical factor in consumer purchasing decisions, often compared against budget constraints.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="BUDGET">
      <data key="d0">VALUE</data>
      <data key="d1">The maximum amount of money a consumer is willing to spend on a product, influencing their purchasing choices.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="VARIETY PACK">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="NON-GMO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Non-GMO indicates that the product does not contain genetically modified organisms, ensuring it meets certain dietary preferences.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="SPICY HOT PEPPER SEA SALT">
      <data key="d0">PRODUCT</data>
      <data key="d1">Spicy Hot Pepper Sea Salt is a seasoning product that includes blends of various peppers and sea salt, marketed as all-natural and gluten-free.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="GLUTEN-FREE">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Gluten-free indicates that the product does not contain gluten, catering to individuals with gluten sensitivities or celiac disease.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="PEPPER FLAVORS">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Pepper flavors refer to the various types of peppers used in products, such as Ghost Pepper, Jalapeno, and Habanero, contributing to the taste profile.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="JALAPENO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Jalapeno is a medium-heat chili pepper commonly used in cooking, known for its distinct flavor and versatility in various dishes.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="HABANERO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Habanero is a very hot chili pepper that adds significant heat and flavor to food products.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="BLACK PEPPER">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Black Pepper is a common spice made from the dried fruit of the pepper plant, used to enhance the flavor of various dishes.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="BUFFALO DILL">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Buffalo Dill is a flavor variant of Louisville Vegan Jerky, combining the taste of buffalo sauce with dill seasoning.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="PEPPERONI">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Pepperoni is a type of spicy Italian-American sausage, often used as a flavor in various food products.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="MAPLE BACON">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Maple Bacon is a flavor variant that combines the sweetness of maple with the savory taste of bacon, used in Louisville Vegan Jerky.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="CAROLINA BBQ">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Carolina BBQ is a flavor variant that reflects the barbecue style from the Carolinas, known for its tangy and smoky taste.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="4 OUNCE PACK">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A 4 ounce pack refers to the size of the product packaging, indicating the quantity of the product contained within.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="GHOST PEPPER">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="SHENGRAN HU">
      <data key="d0">PERSON</data>
      <data key="d1">Shengran Hu is a researcher affiliated with the University of British Columbia and the Vector Institute, contributing to the field of automated design of agentic systems.
Shengran Hu is a researcher who co-authored a paper on Thought Cloning, which focuses on learning to think while acting by imitating human thinking, in 2024.
Shengran Hu is a researcher who co-authored a paper on intelligent exploration using foundation models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CONG LU">
      <data key="d0">PERSON</data>
      <data key="d1">Cong Lu is a researcher affiliated with the University of British Columbia and the Vector Institute, contributing to the field of automated design of agentic systems.
Cong Lu is a researcher who co-authored a paper on intelligent exploration using foundation models.
Cong Lu is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JEFF CLUNE">
      <data key="d0">PERSON</data>
      <data key="d1">Jeff Clune is a researcher affiliated with the University of British Columbia, the Vector Institute, and holds a Canada CIFAR AI Chair, focusing on agentic systems.
Jeff Clune is a researcher focused on AI-generating algorithms and their implications for general artificial intelligence.Jeff Clune is a researcher focused on the challenges of creating safe open-ended AI.
Jeff Clune is a researcher who co-authored a paper on Thought Cloning, which focuses on learning to think while acting by imitating human thinking, in 2024.
Jeff Clune is a researcher involved in multiple studies related to AI and intelligent exploration.
Jeff Clune is a researcher who co-authored a paper on designing neural networks through neuroevolution.
Jeff Clune is a researcher recognized for contributions to evolutionary computation and reinforcement learning.Jeff Clune is a researcher recognized for contributions to evolutionary computation and reinforcement learning, also mentioned in multiple papers.
Jeff Clune is a researcher who co-authored a paper on open-endedness in models of human notions of interestingness.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d0">RESEARCH AREA</data>
      <data key="d1">ADAS is a new research area aimed at automatically creating powerful agentic system designs, including novel building blocks and combinations.
ADAS is a proposed research area focused on the automated invention of novel building blocks and design of powerful agentic systems.
ADAS is a proposed research area focused on the automated design of agentic systems that utilize Foundation Models (FMs) for task-solving through planning and iterative processing.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="FOUNDATION MODELS (FMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundation Models are large-scale models like GPT and Claude that serve as powerful general-purpose agents for various tasks requiring flexible reasoning and planning.
Foundation Models are large-scale models that serve as modules in the control flow of agentic systems, enabling them to perform complex tasks.
Foundation Models (FMs) are advanced AI models that can be utilized for various tasks, including programming and reinforcement learning in robotics.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,c3d0436082aada237ee4bee645f16059,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="META AGENT SEARCH">
      <data key="d0">ALGORITHM</data>
      <data key="d1">Meta Agent Search is an algorithm that enables a meta agent to iteratively program new agents based on an archive of previous discoveries.
Meta Agent Search is an algorithm within ADAS that enables the design of agents in code space through iterative creation and evaluation.
Meta Agent Search is an algorithm designed to define and discover agentic systems through a search process.
Meta Agent Search is an algorithm designed to define and search for agents in code, utilizing foundational models (FMs) as meta agents to iteratively create new agents based on previous discoveries.
Meta Agent Search is a method for discovering high-performance agents through iterative evaluation and refinement based on previous discoveries in the ARC challenge.
Meta Agent Search is an algorithm designed to discover agents that outperform traditional hand-designed agents across various domains, including math, reading, and reasoning.
Meta Agent Search is a method for discovering effective agents tailored to specific tasks across various domains, showcasing its effectiveness in improving performance metrics.
Meta Agent Search is a method that improves the performance of agents in various domains, particularly in math, by discovering generalizable design patterns and systems.
Meta Agent Search is a method used within ADAS to program new agents by leveraging existing algorithms and frameworks.
Meta Agent Search is an approach where a meta agent iteratively builds on previous discoveries to program new agents automatically.
Meta Agent Search is a research initiative focused on discovering optimal agents for various tasks, including those evaluated on the ARC benchmark.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CHAIN-OF-THOUGHT PLANNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain-of-thought planning is a technique used in agentic systems to enhance reasoning and decision-making processes.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AGENT ARCHIVE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The agent archive is a collection of previously discovered agents that informs the meta agent during the programming of new agents.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="MULTI-STEP PEER REVIEW AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">The Multi-step Peer Review Agent is an example of an agent discovered through the Meta Agent Search algorithm, designed for reviewing tasks.
The Multi-Step Peer Review Agent is an example of an agent designed to review and refine answers through a structured process.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VERIFIED MULTIMODAL AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">The Verified Multimodal Agent is another example of an agent discovered through the Meta Agent Search algorithm, capable of handling visual tasks.
The Verified Multimodal Agent is another example of an agent discovered in the Math domain, focusing on multimodal problem-solving.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="DIVIDE AND CONQUER AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">The Divide and Conquer Agent is an agent designed to break down tasks into subproblems for more efficient processing.
The Divide and Conquer Agent is an example of an agent that decomposes problems into smaller sub-problems for specialized solutions.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ZAHARIA ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Zaharia et al. (2024) is a reference to a study that emphasizes the importance of compound agentic systems in solving complex tasks.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HOG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">HOG (Histogram of Oriented Gradients) is a hand-designed feature used in computer vision, which has been replaced by learned features over time.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="DALAL &amp; TRIGGS (2005)">
      <data key="d0">PERSON</data>
      <data key="d1">Dalal &amp; Triggs (2005) is a reference to a study that introduced the HOG feature in computer vision.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CNNS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Convolutional Neural Networks (CNNs) are a type of deep learning model that have surpassed hand-designed features in performance for image processing tasks.
Convolutional Neural Networks (CNNs) are a class of deep learning algorithms primarily used for image processing and recognition tasks.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HUTTER ET AL. (2019)">
      <data key="d0">PERSON</data>
      <data key="d1">Hutter et al. (2019) is a reference to a study discussing AutoML methods that demonstrate the superiority of learned AI systems.
</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AI-Generating Algorithms are methods that create AI systems automatically, showing better performance than hand-designed systems.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="NEURAL ARCHITECTURE SEARCH">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Neural Architecture Search is a method for automatically designing neural network architectures that outperform manually designed models.
Neural Architecture Search is a method for automating the design of neural networks, allowing for the discovery of optimal architectures.
Neural Architecture Search is a method for automating the design of neural network architectures to optimize performance.
Neural Architecture Search is a method that explores the architecture of neural networks to gain insights into their performance.
Neural architecture search is a method for automating the design of neural networks.
Neural architecture search is a method for automating the design of neural networks, often involving multi-objective optimization strategies, as discussed in the context of Shengran Hu's work in 2021.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ROCKT&#196;SCHEL (2024)">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="EXAMPLE AGENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Example agents refer to the specific implementations or instances of agents discussed in the context of automated design and AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AUTOML METHODS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AutoML methods are automated machine learning techniques that optimize the process of applying machine learning to real-world problems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AI-GENERATING ALGORITHMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AI-Generating Algorithms (AI-GAs) are algorithms designed to create AI systems automatically, demonstrating superior performance compared to traditional methods.
AI-Generating Algorithms (AI-GAs) are methods that aim to learn components in AI systems to replace handcrafted ones, enhancing automation in AI development.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LLM ALIGNMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">LLM alignment refers to the process of ensuring that large language models (LLMs) behave in accordance with human intentions and values.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LEARNED LOSS FUNCTIONS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Learned loss functions are loss functions that are optimized through learning processes, often outperforming traditional hand-designed loss functions.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="DPO">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">DPO (Differentiable Programming Optimization) is a hand-designed loss function used in training AI models.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AI SCIENTIST">
      <data key="d0">CONCEPT</data>
      <data key="d1">The AI Scientist is an automated research pipeline that develops novel machine learning algorithms and conducts experiments.
The AI Scientist is a concept focused on fully automated open-ended scientific discovery, as discussed in a preprint document.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="OMNI-EPIC">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">OMNI-EPIC is a framework for generating diverse robotics learning environments automatically, showcasing creativity and efficiency.
OMNI-EPIC is a framework that enables the creation of robotics learning environments through automated programming.
OMNI-EPIC is a framework that enables Foundation Models to create robotics learning environments through programming.
Omni-epic is a framework for achieving open-endedness in AI through human notions of interestingness.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="F1 SCORES">
      <data key="d0">METRIC</data>
      <data key="d1">F1 scores are a measure of a model's accuracy, balancing precision and recall, particularly in classification tasks.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="DROP">
      <data key="d0">DATASET</data>
      <data key="d1">DROP is a dataset used for evaluating reading comprehension tasks, particularly in logic puzzles.
DROP is a dataset used for evaluating reading comprehension tasks, providing a benchmark for assessing the performance of agents.
DROP is a benchmark for evaluating reading comprehension capabilities in agents, referenced in the context of Meta Agent Search.
DROP is a reading comprehension benchmark that requires discrete reasoning over paragraphs.
DROP (Reading Comprehension) is a dataset that employs one-shot style questions for evaluating reading comprehension abilities.
DROP (Reading Comprehension) is a benchmark that assesses the ability to perform discrete reasoning and comprehend detailed information across multiple paragraphs.
Discrete Reasoning over Paragraphs (DROP) is a reading comprehension benchmark that requires models to resolve references and perform operations on text.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,84317ae35cc75d612287186d93461447,86f77e15d41cbd0cb33f635ccb2cb66b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MGSM">
      <data key="d0">DATASET</data>
      <data key="d1">MGSM is a dataset used for evaluating math tasks in AI systems.
MGSM is a dataset used for evaluating math tasks, serving as a benchmark for assessing the performance of agents in mathematical problem-solving.
MGSM is a benchmark for evaluating math capabilities in agents, referenced in the context of Meta Agent Search.
MGSM (Math Generalization and Search Model) is a benchmark used to evaluate the performance of agents in math-related tasks.
MGSM (Multilingual Grade School Math Benchmark) evaluates mathematical problem-solving abilities across various languages.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="GSM8K">
      <data key="d0">DATASET</data>
      <data key="d1">GSM8K is a dataset used for assessing the performance of AI systems on math tasks.
GSM8K is a dataset used for evaluating math tasks, providing a benchmark for assessing the performance of agents in mathematical problem-solving.
GSM8K is a dataset used for evaluating the performance of agents in math tasks, specifically designed for challenging math problems.
GSM8K is a benchmark dataset used to evaluate the performance of mathematical problem-solving agents, referenced in the context of accuracy improvements.
GSM8K is a benchmark that evaluates language models on mathematical problem-solving.
GSM8K is a benchmark for evaluating mathematical reasoning capabilities of language models.
Grade School Math 8K (GSM8K) is a dataset of diverse grade school math word problems requiring multiple steps to solve.
GSM8K is a benchmark used to evaluate the performance of AI models on math problems, particularly in multi-step arithmetic tasks.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="GSM-HARD">
      <data key="d0">DATASET</data>
      <data key="d1">GSM-HARD is a dataset that presents challenging math problems for AI systems to solve.
GSM-HARD is a dataset used for evaluating challenging math tasks, serving as a benchmark for assessing the performance of agents.
GSM-HARD is a dataset that presents more difficult math problems for evaluating agent performance.
GSM-HARD is a challenging benchmark dataset for evaluating the performance of mathematical problem-solving agents, referenced in the context of accuracy improvements.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="CLUNE (2019)">
      <data key="d0">PERSON</data>
      <data key="d1">Clune (2019) is a reference to a study that highlights the advantages of AI-Generating Algorithms over traditional AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="ELSEN ET AL. (2019)">
      <data key="d0">PERSON</data>
      <data key="d1">Elsken et al. (2019) is a reference to a study that discusses the application of Neural Architecture Search in developing CNN models.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="SHEN ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Shen et al. (2023) is a reference to a study that contributes to the understanding of Neural Architecture Search in CNNs.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LU ET AL. (2024A)">
      <data key="d0">PERSON</data>
      <data key="d1">Lu et al. (2024a) is a reference to a study that compares learned loss functions with traditional loss functions in LLM alignment.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="RAFALIOV ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Rafailov et al. (2024) is a reference to a study that discusses the DPO loss function in AI training.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LU ET AL. (2024B)">
      <data key="d0">PERSON</data>
      <data key="d1">Lu et al. (2024b) is a reference to a study that presents the AI Scientist and its automated research capabilities.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="FALDOR ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Faldor et al. (2024) is a reference to a study that discusses the OMNI-EPIC framework for generating robotics learning environments.
Faldor et al. (2024) is a reference to a study on OMNI-EPIC, which enables Foundation Models to create robotics learning environments.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FERNANDO ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Fernando et al. (2024) is a reference to a study that explores existing methods in ADAS focused on designing prompts.
Fernando et al. (2024) is a reference to a study on PromptBreeder, which focuses on improving prompt engineering.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="YANG ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Yang et al. (2024) is a reference to a study that examines limitations in current ADAS methods related to prompt design.
Yang et al. (2024) is a reference to a study discussing OPRO, which automates prompt engineering for agents.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="BOYER &amp; MOORE (1983)">
      <data key="d0">PERSON</data>
      <data key="d1">Boyer &amp; Moore (1983) is a reference to a study discussing the Turing completeness of programming languages.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LADHA (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Ladha (2024) is a reference to a study that discusses the implications of Turing completeness in programming languages.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="SEARCH SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The search space defines the range of agentic systems that can be represented and discovered in ADAS, including various structures and components.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="EVALUATION FUNCTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">The evaluation function is a criterion used to assess the performance of candidate agents based on specific objectives such as accuracy or cost.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="PROMPTBREEDER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">PromptBreeder is a tool that mutates text prompts of agents while keeping other components, like control flow, unchanged.
PromptBreeder is a technique that employs Foundation Models to improve prompt engineering for agents.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ZHUKE ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuge et al. (2024) is a reference to a study discussing search algorithms and their application in exploring search spaces for agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="CHASE (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Chase (2024) is a reference to a work that contributes to the understanding of agentic systems and their definitions.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="NG (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Ng (2024) is a reference to a work that contributes to the understanding of agentic systems and their definitions.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="OPTIMIZATION PROCESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">An optimization process is a systematic approach to finding the best solution or outcome among various alternatives, often used in algorithm design.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="ITERATIVE PROCESSING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Iterative processing involves repeatedly applying a set of operations or algorithms to refine results or improve performance over time.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="EXPLORATION-EXPLOITATION TRADE-OFF">
      <data key="d0">CONCEPT</data>
      <data key="d1">The exploration-exploitation trade-off is a dilemma in decision-making where one must balance between exploring new options and exploiting known ones for optimal outcomes.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="ACCURACY">
      <data key="d0">METRIC</data>
      <data key="d1">Accuracy is a metric used to evaluate the performance of models or agents, indicating the proportion of correct predictions made.
Accuracy is a performance metric that measures the correctness of agents' responses in various tasks, including reading comprehension and math.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="COST">
      <data key="d0">METRIC</data>
      <data key="d1">Cost refers to the resources required to implement or operate a system, often considered in the evaluation of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="LATENCY">
      <data key="d0">METRIC</data>
      <data key="d1">Latency is the time delay between the initiation of a process and its completion, an important factor in assessing the performance of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="SAFETY">
      <data key="d0">METRIC</data>
      <data key="d1">Safety refers to the measures taken to ensure that systems operate without causing harm, a critical consideration in the design of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="AGENTIC SYSTEMS">
      <data key="d0" />
      <data key="d1">
Agentic systems are computational systems designed to perform tasks autonomously, which can be programmed by the meta agent in the Meta Agent Search framework.

Agentic systems are systems that can act autonomously and make decisions based on their environment, as explored in various research papers including those on MetaGPT and dynamic LLM-agent networks.Agentic systems refer to systems that can act autonomously and make decisions based on their environment, as explored in various research papers including those on MetaGPT and dynamic LLM-agent networks.
Agentic systems are systems that can act autonomously and make decisions based on their environment, relevant to discussions on AI and automation.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1b1399c76420a477c0c97893d258ae69,24d7b89ae9522ae60d2317984951355b,4884e8429ca1e567dadf5e22b4b68274,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FOUNDATIONAL MODELS (FMS)">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundational models (FMs) are large-scale machine learning models that serve as the basis for creating new agents in the Meta Agent Search algorithm.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="ARCHIVE">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The archive is a collection of previously discovered agents and their evaluation metrics, used to inform the meta agent's future proposals.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="PROMPTING TECHNIQUES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Prompting techniques are methods used to instruct the meta agent on how to generate new agents based on the information from the archive and academic literature.
Prompting Techniques are methods used to guide the behavior of agents in agentic systems, enhancing their problem-solving capabilities.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="ARC LOGIC PUZZLE TASK">
      <data key="d0">TASK</data>
      <data key="d1">The ARC logic puzzle task is a benchmark used to evaluate the performance of agents in logical reasoning and problem-solving.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="ITERATIONS">
      <data key="d0">PROCESS</data>
      <data key="d1">Iterations refer to the repeated cycles in the Meta Agent Search process where the meta agent refines its proposals based on previous evaluations.
Iterations refer to the repeated cycles of evaluation and improvement that agents undergo during the Meta Agent Search process.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="VALIDATION DATA">
      <data key="d0">DATA</data>
      <data key="d1">Validation data is the dataset used to evaluate the performance of newly generated agents in the target domain.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="FUNSEARCH">
      <data key="d0" />
      <data key="d1">
FunSearch is a method that utilizes Foundation Models to discover better optimization algorithms through automated coding.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="ARC CHALLENGE">
      <data key="d0">EVENT</data>
      <data key="d1">The ARC Challenge is a competition designed to evaluate the general intelligence of AI systems by testing their ability to learn transformation rules from visual input-output grid patterns.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="SELF-CONSISTENCY WITH COT (COT-SC)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Self-Consistency with Chain-of-Thought (COT-SC) is a technique that ensembles multiple answers from COT to improve accuracy.
Self-Consistency with Chain-of-Thought (COT-SC) is a hand-designed agent baseline that builds on the COT technique.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="LLM DEBATE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">LLM Debate is a technique that enables different language models to debate, leveraging diverse perspectives to find better answers.
LLM Debate is a baseline technique that utilizes debate-style interactions among agents to enhance reasoning and answer quality.
LLM Debate is a method where multiple language models engage in a debate format to enhance reasoning and decision-making capabilities.
LLM Debate is a technique used in agentic systems for problem-solving, referenced in the context of manually designed agents.
LLM Debate is a manually designed agent that performs across multiple tasks, including math and reading comprehension.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="QUALITY-DIVERSITY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Quality-Diversity is a simplified method that produces and ensembles diverse answers to explore potential solutions more effectively.
Quality-Diversity is a baseline technique that aims to improve the diversity and quality of solutions generated by agents.
Quality-Diversity is a method that focuses on generating a diverse set of high-quality solutions to a problem, enhancing the overall performance of language models.
Quality-Diversity is a technique used in agentic systems for problem-solving, referenced in the context of manually designed agents.
Quality-Diversity is a manually designed agent that demonstrates performance metrics across different tasks.
Quality-Diversity is a concept in evolutionary algorithms that focuses on generating a diverse set of high-quality solutions.
Quality-Diversity is a simplified version of Intelligent Go-Explore, used as a hand-designed agent baseline.
Quality-Diversity is a technique that aims to collect diverse answers through multiple iterations based on previous responses.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="EXPERTS">
      <data key="d0">ROLE</data>
      <data key="d1">Experts are evaluators that assess the performance of agents based on specific traits such as efficiency, readability, and simplicity.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="HUMAN-LIKE CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">Human-like critics are evaluators that simulate human feedback to assess the quality of answers produced by agents.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="EFFICIENCY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">Efficiency experts evaluate agents based on their ability to produce answers quickly and effectively.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="READABILITY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">Readability experts assess the clarity and comprehensibility of the answers generated by agents.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="SIMPLICITY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">Simplicity experts evaluate the straightforwardness and ease of understanding of the answers produced by agents.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="TOP-3 ANSWERS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Top-3 answers refer to the best three responses generated by agents, selected for further evaluation and potential ensemble.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="FINAL ANSWER">
      <data key="d0">OUTPUT</data>
      <data key="d1">The final answer is the conclusive response produced after evaluating and refining the top answers through the ensemble process.
The final answer is the specific choice made by the student from the provided options, which can be a single letter or a list of letters.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="REFINEMENT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="ADAS">
      <data key="d0">CONCEPT</data>
      <data key="d1">ADAS refers to Advanced Driver Assistance Systems, which are technologies designed to enhance vehicle safety and facilitate driving.
ADAS stands for Automated Design of Agentic Systems, a proposed research area focused on inventing novel building blocks for agentic systems.
ADAS is a proposed research area focused on inventing novel building blocks and designing powerful agentic systems in an automated manner.
Automated Design of Agentic Systems (ADAS) refers to a new area in AI research focused on automating the design and optimization of agentic systems.
ADAS (Automated Design of Agentic Systems) refers to algorithms designed to create intelligent agents that can operate autonomously, often utilizing powerful foundational models (FMs).
Automated Design of Agentic Systems (ADAS) is a research problem focused on automatically inventing novel building blocks and designing powerful agentic systems.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,bc26e68b0b2783ba912b9e5606d9eb0b,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FEEDBACK MECHANISM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The feedback mechanism is a sophisticated system that incorporates diverse feedback to refine answers and improve performance iteratively.
A feedback mechanism is a process that uses the outcomes of actions to adjust future actions, crucial for refining the performance of AI models.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="STEP-BACK ABSTRACTION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Step-back Abstraction is a baseline technique that instructs agents to consider the principles involved in solving tasks to enhance reasoning capabilities.
Step-back Abstraction is a technique used in agentic systems for problem-solving, referenced in the context of manually designed agents.
Step-back Abstraction is a manually designed agent that provides performance metrics in various learning tasks.
Step-back Abstraction is a hand-designed agent baseline for reasoning and problem-solving domains.
Step-back Abstraction is a method used in reasoning and problem-solving experiments, as referenced in the text.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ROLE ASSIGNMENT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Role Assignment is a baseline technique that assigns different roles to function models (FMs) to improve the quality of answers.
Role Assignment is a technique used in agentic systems to assign different roles to modules for collaboration, referenced in the context of manually designed agents.
Role Assignment is a manually designed agent that shows performance metrics in multi-task learning scenarios.
Role Assignment is a hand-designed agent baseline for reasoning and problem-solving domains.
Role Assignment is a technique that involves assigning specific roles to debate modules in problem-solving contexts, as mentioned in the text.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MMLU">
      <data key="d0">BENCHMARK</data>
      <data key="d1">MMLU is a benchmark for evaluating multi-task problem-solving capabilities in agents, referenced in the context of Meta Agent Search.
MMLU (Massive Multitask Language Understanding) benchmark assesses a model&#8217;s ability to answer questions across a wide range of subjects and difficulty levels.
MMLU is a benchmark used to assess the capabilities of language models in various tasks.
MMLU is a benchmark used to evaluate the performance of language models in various tasks.
Massive Multitask Language Understanding (MMLU) is a benchmark that measures a model's multitask understanding across various academic subjects through multiple-choice questions.
MMLU is a benchmark for assessing the performance of AI models in various academic subjects, including abstract algebra and college mathematics.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="GPQA">
      <data key="d0">BENCHMARK</data>
      <data key="d1">GPQA is a benchmark for evaluating the capability of solving hard (graduate-level) questions in science, referenced in the context of Meta Agent Search.
GPQA is a graduate-level benchmark designed to evaluate question and answer systems, ensuring they are robust against Google searches.
GPQA (Generalized Problem Solving Questions and Answers) is a dataset used for evaluating reasoning and problem-solving capabilities in various domains.
GPQA (Graduate-Level Google-Proof Q&amp;A Benchmark) consists of challenging multiple-choice questions across the domains of biology, physics, and chemistry.
Graduate-level Google-Proof Q&amp;A (GPQA) is a challenging benchmark with difficult multiple-choice questions created by domain experts in science fields.
GPQA is a graduate-level benchmark designed to test the question-and-answer capabilities of language models.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e,84317ae35cc75d612287186d93461447,86f77e15d41cbd0cb33f635ccb2cb66b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MEYERSON ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Meyerson et al. (2023) is a reference to a study that discusses the evolution of feedback mechanisms in the context of agent performance.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="F1 SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">F1 Score is a performance metric used to evaluate the accuracy of agents in tasks, particularly in reading comprehension and math.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="CHAIN-OF-THOUGHT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain-of-Thought is a baseline technique that enhances reasoning by encouraging agents to articulate their thought processes while solving tasks.

Chain-of-Thought is a reasoning method used in agentic systems to enhance problem-solving capabilities, referenced in the context of manually designed agents.
</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="COT-SC">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">COT-SC is a baseline technique that builds on Chain-of-Thought to improve reasoning and performance in various tasks.
COT-SC (Chain-of-Thought with Self-Consistency) is a technique that improves the performance of language models by generating multiple reasoning paths and selecting the best one.
COT-SC is a specific technique used in agentic systems for problem-solving, referenced in the context of manually designed agents.
COT-SC is a manually designed agent that shows specific performance metrics in multi-task learning scenarios.
COT-SC is a variation of COT that involves sampling multiple answers and using ensemble methods for final decision-making.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="AGENT NAME">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Agent Name refers to the identifier assigned to each agent evaluated in the performance comparison across various tasks.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="HOLD-OUT TEST SETS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Hold-out test sets are subsets of data reserved for evaluating the performance of agents after training, ensuring unbiased assessment.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="FOUNDATION MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundation models (FMs) are large-scale machine learning models that serve as the base for various applications, including those tested in the context of Meta Agent Search.
Foundation Models are large-scale models that serve as a base for various AI applications, often used for generating code and optimizing algorithms.
Foundation models are large-scale models trained on diverse data that can be fine-tuned for various downstream tasks, as referenced in the context of intelligent exploration and exploitation strategies.
Foundation models are large-scale models trained on diverse data that can be fine-tuned for various tasks, as referenced in the context of intelligent exploration.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2901d5e2711fa4f32d39cd8eea36cd71,6109537356a2ce2339f77c827aa3668e,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="CLAUDE-HAIKU">
      <data key="d0">MODEL</data>
      <data key="d1">Claude-Haiku is a language model developed by Anthropic, used to evaluate the performance of agents discovered through Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="CLAUDE-SONNET">
      <data key="d0">MODEL</data>
      <data key="d1">Claude-Sonnet is another language model from Anthropic, noted for its high performance in evaluations of agents discovered through Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ARC">
      <data key="d0">EVALUATION METRIC</data>
      <data key="d1">ARC (AI Reading Comprehension) is a benchmark used to evaluate the accuracy of agents in reading comprehension tasks.
ARC (AI Research Challenge) is a benchmark designed to evaluate the performance of AI agents on a variety of tasks.
ARC refers to a specific evaluation framework used for testing and assessing the performance of discovered agents.
The AI2 Reasoning Challenge (ARC) is a benchmark developed by AllenAI that evaluates reasoning and comprehension abilities of language models through multiple-choice questions.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2,86f77e15d41cbd0cb33f635ccb2cb66b,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SVAMP">
      <data key="d0">DATASET</data>
      <data key="d1">SVAMP is a dataset used for assessing the performance of agents in solving math problems.
SVAMP is a dataset used for evaluating the performance of agents in mathematical problem-solving tasks, referenced in the context of accuracy improvements.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ASDIV">
      <data key="d0">DATASET</data>
      <data key="d1">ASDIV is a dataset used for evaluating the performance of agents in diverse math tasks.
ASDiv is a dataset used for evaluating the performance of agents in mathematical problem-solving tasks, referenced in the context of accuracy improvements.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d0">AGENT</data>
      <data key="d1">Dynamic Role-Playing Architecture is a top-performing agent discovered by Meta Agent Search, evaluated across various math domains.
Dynamic Role-Playing Architecture is an agent that exhibits performance metrics when transferred from math to non-math domains.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d0">AGENT</data>
      <data key="d1">Structured Multimodal Feedback Loop is a top-performing agent discovered by Meta Agent Search, evaluated across various math domains.
Structured Multimodal Feedback Loop is an agent that shows performance metrics across various tasks.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d0">AGENT</data>
      <data key="d1">Interactive Multimodal Feedback Loop is a top-performing agent discovered by Meta Agent Search, evaluated across various math domains.
Interactive Multimodal Feedback Loop is an agent that provides performance metrics in multiple domains.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="MANUALLY DESIGNED AGENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="EXTERNAL MEMORY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">External Memory is a technique used in agentic systems to store and retrieve information, enhancing the agents' capabilities.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="FM MODULES">
      <data key="d0">CONCEPT</data>
      <data key="d1">FM Modules are functional modules within agentic systems that can be assigned different roles to collaborate effectively.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="AUTOML">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">AutoML refers to automated machine learning techniques that streamline the process of applying machine learning to real-world problems.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="META-LEARNING ARCHITECTURES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Meta-learning architectures are frameworks that enable systems to learn how to learn, improving efficiency and adaptability in AI models.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="META-LEARNING ALGORITHMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Meta-learning algorithms are techniques that allow models to improve their learning processes over time, enhancing their performance on various tasks.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="LEARNING ENVIRONMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Learning environments are settings or frameworks designed to facilitate the training and development of AI models.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="MAML">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">MAML (Model-Agnostic Meta-Learning) is a meta-learning algorithm that enables models to adapt quickly to new tasks with minimal data.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="META-RL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Meta-RL (Meta-Reinforcement Learning) is a framework that focuses on improving the learning efficiency of reinforcement learning agents.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="POET">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">POET (Population-Based Open-Ended Learning) is a method for generating learning environments in an open-ended manner.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DISCOPOP">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">DiscoPOP is a framework where Foundation Models program loss functions for preference learning in alignment training.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="EUREKA">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Eureka is a method that allows Foundation Models to write reward functions for reinforcement learning applications.
Eureka is a method that enables Foundation Models to write reward functions for reinforcement learning applications in robotics.
Eureka is a project focused on human-level reward design via coding large language models, as discussed in a paper by Yecheng Jason Ma and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="LANGUAGE-TO-REWARD">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Language-to-reward is a technique that enables Foundation Models to create reward functions for reinforcement learning in robotics.
Language-to-reward is a technique that allows Foundation Models to create reward functions for reinforcement learning.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="OPRO">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">OPRO is a method that utilizes Foundation Models to automate prompt engineering for agents, focusing on enhancing reasoning capabilities.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="SELF-DISCOVER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Self-Discover is a method that uses Foundation Models to automate the creation of effective prompts for agents.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="EVOAGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">EvoAgent is a framework that optimizes role definitions in prompts to enhance agent performance.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENTVERSE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AgentVerse is a system that optimizes agent roles and definitions to improve performance in agentic systems.
Agentverse is a framework designed to facilitate multi-agent collaboration and explore emergent behaviors in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DYLAN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">DyLAN is a method that uses Foundation Models to score response quality in agent networks and prune connections.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DSPY">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">DSPy is a framework that generates and optimizes nodes in agentic systems using Foundation Models.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="GPT-SWARM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">GPT-Swarm is a system that represents agentic systems in a graph format and optimizes connections using reinforcement learning.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENTOPTIMIZER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AgentOptimizer is a method that learns the tools used in agentic systems to enhance their functionality.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENT SYMBOLIC LEARNING">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Agent Symbolic Learning is a framework that learns prompts, tools, and control flow in agentic systems.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="SAFETY CONSIDERATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Safety considerations refer to the precautions and awareness needed when executing untrusted model-generated code in AI research.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ARTIFICIAL GENERAL INTELLIGENCE (AGI)">
      <data key="d0">CONCEPT</data>
      <data key="d1">Artificial General Intelligence (AGI) is a theoretical form of AI that possesses the ability to understand, learn, and apply intelligence across a wide range of tasks.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="YU ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Yu et al. (2023) is a reference to a study that discusses language-to-reward techniques for Foundation Models.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ZHOU ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Zhou et al. (2024) is a reference to a study discussing Self-Discover, which automates prompt creation for agents.Zhou et al. (2024) is a reference to a study on Agent Symbolic Learning, which learns prompts, tools, and control flow.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XU ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Xu et al. (2023) is a reference to a study that highlights the benefits of assigning personas or roles to agents.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="KHATTAB ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Khattab et al. (2024) is a reference to a study discussing DSPy and its optimization of nodes in agentic systems.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ZHUGE ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Zhuge et al. (2024) is a reference to a study on GPT-Swarm, which optimizes connections in agentic systems.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="RAFAILOV ET AL. (2024)">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FOUNDATIONAL MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Foundational models are large-scale machine learning models that serve as the basis for developing various AI applications, including ADAS algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CONSTITUTIONAL AI">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Constitutional AI is an approach that aims to ensure AI systems operate safely and ethically by incorporating predefined principles during their development.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="MULTI-OBJECTIVE SEARCH ALGORITHMS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-objective search algorithms are optimization techniques that consider multiple criteria simultaneously, such as performance, cost, and robustness.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="EVALUATION FUNCTIONS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Evaluation functions are metrics or criteria used to assess the performance and effectiveness of agents developed through ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="HUMAN ORGANIZATIONS">
      <data key="d0">SOCIETY</data>
      <data key="d1">Human organizations refer to structured groups of individuals working together, which can influence the design and complexity of agentic systems.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="COMPLEX DOMAINS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Complex domains refer to intricate environments or tasks that require advanced interaction and problem-solving capabilities from AI agents.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CLUNE">
      <data key="d0">PERSON</data>
      <data key="d1">Clune is a researcher whose work is cited in discussions about AI algorithms and their implications for safety and effectiveness.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="ECOFFET ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Ecoffet et al. is a reference to a study or work that contributes to the understanding of ADAS and its applications.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="YUDKOWSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Yudkowsky is a researcher known for his contributions to AI safety and ethics, referenced in the context of ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CALDWELL">
      <data key="d0">PERSON</data>
      <data key="d1">Caldwell is a researcher referenced in discussions about the benefits of open-source approaches to AI safety.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="LU ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Lu et al. is a reference to a study that discusses evaluation functions in the context of ADAS.)&lt;|COMPLETE|&gt;Lu et al. is a reference to a study that discusses higher-order ADAS and the potential for self-referential learning in agents.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEWIS ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Lewis et al. is a reference to a study that discusses RAG (Retrieval-Augmented Generation) in the context of ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="HU ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Hu et al. is a reference to a study that discusses multi-objective optimization in agentic systems.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="HUANG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Huang et al. is a reference to a study that discusses considerations for optimizing agentic systems.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="DEB ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Deb et al. is a reference to a study that discusses multi-objective search algorithms relevant to ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CULLY &amp; DEMIRIS">
      <data key="d0">PERSON</data>
      <data key="d1">Cully &amp; Demiris is a reference to a study that discusses Quality-Diversity in the context of AI algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="MOURET &amp; CLUNE">
      <data key="d0">PERSON</data>
      <data key="d1">Mouret &amp; Clune is a reference to a study that discusses concepts related to diversity in AI solutions.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="FALDOR ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Faldor et al. is a reference to a study that discusses open-ended algorithms in AI development.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="STANLEY ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Stanley et al. is a reference to a study that discusses the evolution of algorithms in AI.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="ZHOU ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Zhou et al. is a reference to a study that discusses evaluation methods for agentic systems.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CHIANG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Chiang et al. is a reference to a study that discusses subjective evaluation tasks in AI.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="AGENTIC SYSTEM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">An agentic system is a machine learning system that operates primarily over natural language, which is interpretable to humans and used in constructing human organization and society.
Agentic system refers to the overall framework that incorporates various agents and processes to automate data generation and instruction refinement.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="HUMAN ORGANIZATION">
      <data key="d0">SOCIETY</data>
      <data key="d1">Human organization refers to the structured ways in which humans interact and collaborate, forming societies and communities.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="HONG ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Hong et al. (2023) is a reference to a study that incorporates organizational structures for human companies in agents.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="PARK ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Park et al. (2023) is a reference to a study that simulates a human town with agents.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="ANTHROPIC">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Anthropic is an organization known for developing AI technologies, including the Claude series of models.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CLAUDE 3">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Claude 3 is a next-generation AI model developed by Anthropic.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CLAUDE 3.5 SONNET">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Claude 3.5 Sonnet is an iteration of the Claude model developed by Anthropic.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="YUNTAO BAI ET AL. (2022)">
      <data key="d0">PERSON</data>
      <data key="d1">Yuntao Bai et al. (2022) is a reference to a study discussing AI feedback for harmlessness.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="YOSHUA BENGIO ET AL. (2024)">
      <data key="d0">PERSON</data>
      <data key="d1">Yoshua Bengio et al. (2024) is a reference to a study on managing extreme AI risks.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="N BOSTROM">
      <data key="d0">PERSON</data>
      <data key="d1">N Bostrom is a researcher known for analyzing human extinction scenarios and related hazards.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="ROBERT S BOYER AND J STROTHER MOORE">
      <data key="d0">PERSON</data>
      <data key="d1">Robert S Boyer and J Strother Moore are known for their work on the Turing completeness of pure LISP.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="TRACEY CALDWELL">
      <data key="d0">PERSON</data>
      <data key="d1">Tracey Caldwell is a researcher discussing ethical hacking.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="HARRISON CHASE">
      <data key="d0">PERSON</data>
      <data key="d1">Harrison Chase is a researcher who explores the concept of agents in AI.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="BANGHAO CHEN ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Banghao Chen et al. (2023) is a reference to a comprehensive review on prompt engineering in large language models.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="MARK CHEN ET AL. (2021)">
      <data key="d0">PERSON</data>
      <data key="d1">Mark Chen et al. (2021) is a reference to a study evaluating large language models trained on code.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="WEIZE CHEN ET AL. (2023)">
      <data key="d0">PERSON</data>
      <data key="d1">Weize Chen et al. (2023) is a reference to a study on facilitating multi-agent collaboration.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="COMPLEXITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Complexity refers to the intricate and interconnected nature of systems, often emerging from simple rules or interactions in human organizations and societies.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="SOCIETY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Society is a structured community of individuals who interact and form relationships, often studied in the context of human organization and behavior.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="AI RISKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI risks refer to potential dangers and ethical concerns associated with the development and deployment of artificial intelligence technologies.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="STATE-OF-THE-ART AGENTS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">State-of-the-art agents are advanced AI systems designed with the latest techniques and methodologies to perform optimally across various tasks.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="ORGANIZATIONAL STRUCTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Organizational structure refers to the way in which the components of an organization are arranged, influencing how information flows and decisions are made.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="AUTOMATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Automation is the use of technology to perform tasks with minimal human intervention, often aimed at increasing efficiency and reducing errors.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="RESEARCH DIRECTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research direction refers to the focus or path of inquiry in a particular field, guiding the development of new theories, technologies, or methodologies.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="VECTOR INSTITUTE">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The Vector Institute is a research organization focused on advancing artificial intelligence and machine learning through collaboration and innovation.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CANADA CIFAR AI CHAIRS">
      <data key="d0">PROGRAM</data>
      <data key="d1">The Canada CIFAR AI Chairs program supports research in artificial intelligence by funding leading researchers in the field.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="SCHMIDT FUTURES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Schmidt Futures is an organization that funds initiatives aimed at advancing science and technology for the public good.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="OPEN PHILANTHROPY">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Open Philanthropy is a philanthropic organization that aims to promote effective altruism and support high-impact charitable initiatives.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="NSERC DISCOVERY GRANT">
      <data key="d0">FUNDING</data>
      <data key="d1">The NSERC Discovery Grant is a funding program in Canada that supports research in natural sciences and engineering.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="RAFAEL COSMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Rafael Cosman is a donor who contributed to the research efforts discussed in the paper.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="YUSHENG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yusheng Chen is a researcher involved in the study of multi-agent collaboration and emergent behaviors in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SU JINGWEI">
      <data key="d0">PERSON</data>
      <data key="d1">Su Jingwei is a researcher contributing to the exploration of multi-agent collaboration in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ZUO CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zuo Cheng is a researcher focused on multi-agent collaboration and emergent behaviors in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHENFEI YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Chenfei Yuan is a researcher involved in the study of multi-agent collaboration in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHI-MIN CHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Chi-Min Chan is a researcher contributing to the exploration of emergent behaviors in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="HEYANG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Heyang Yu is a researcher focused on multi-agent collaboration in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YI-HSIN HUNG">
      <data key="d0">PERSON</data>
      <data key="d1">Yi-Hsin Hung is a researcher contributing to the exploration of multi-agent collaboration in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHEN QIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Qian is a researcher focused on multi-agent collaboration and emergent behaviors in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">EVENT</data>
      <data key="d1">The Twelfth International Conference on Learning Representations is a conference where research on learning representations, including multi-agent systems, is presented.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="WEI-LIN CHIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Wei-Lin Chiang is a researcher involved in creating an open platform for evaluating language models based on human preference.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="LIANMIN ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Lianmin Zheng is a researcher contributing to the development of an open platform for evaluating language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YING SHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Ying Sheng is a researcher focused on evaluating language models through human preference.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ANASTASIOS NIKOLAS ANGELOPOULOS">
      <data key="d0">PERSON</data>
      <data key="d1">Anastasios Nikolas Angelopoulos is a researcher involved in the evaluation of language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="TIANLE LI">
      <data key="d0">PERSON</data>
      <data key="d1">Tianle Li is a researcher contributing to the development of an open platform for evaluating language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="DACHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Dacheng Li is a researcher focused on evaluating language models through human preference.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="HAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Zhang is a researcher involved in the evaluation of language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="BANGHUA ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Banghua Zhu is a researcher contributing to the development of an open platform for evaluating language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="MICHAEL JORDAN">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Jordan is a prominent researcher in machine learning and AI, contributing to the evaluation of language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JOSEPH E. GONZALEZ">
      <data key="d0">PERSON</data>
      <data key="d1">Joseph E. Gonzalez is a researcher involved in the evaluation of language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ION STOICA">
      <data key="d0">PERSON</data>
      <data key="d1">Ion Stoica is a researcher contributing to the development of an open platform for evaluating language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHATBOT ARENA">
      <data key="d0">PLATFORM</data>
      <data key="d1">Chatbot Arena is an open platform designed for evaluating language models based on human preferences.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="FRAN&#199;OIS CHOLLET">
      <data key="d0">PERSON</data>
      <data key="d1">Fran&#231;ois Chollet is a researcher known for his work on the measure of intelligence in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="AI-GAS">
      <data key="d0">RESEARCH</data>
      <data key="d1">AI-GAS refers to AI-generating algorithms, a paradigm for producing general artificial intelligence.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="KARL COBBE">
      <data key="d0">PERSON</data>
      <data key="d1">Karl Cobbe is a researcher involved in training verifiers to solve math word problems.
Karl Cobbe is a researcher known for his work on training verifiers for math word problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="KALYANMOY DEB">
      <data key="d0">PERSON</data>
      <data key="d1">Kalyanmoy Deb is a researcher known for his work on multi-objective genetic algorithms.
Kalyanmoy Deb is a researcher who co-authored a paper on revisiting residual networks for adversarial robustness, presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.
Kalyanmoy Deb is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AMRIT PRATAP">
      <data key="d0">PERSON</data>
      <data key="d1">Amrit Pratap is a researcher contributing to the development of multi-objective genetic algorithms.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SAMEER AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Sameer Agarwal is a researcher focused on multi-objective genetic algorithms.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="TAMT MEYARIVAN">
      <data key="d0">PERSON</data>
      <data key="d1">Tamt Meyarivan is a researcher involved in the development of multi-objective genetic algorithms.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="NSGA-II">
      <data key="d0">ALGORITHM</data>
      <data key="d1">NSGA-II is a fast and elitist multi-objective genetic algorithm used for optimization problems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="AARON DHARNA">
      <data key="d0">PERSON</data>
      <data key="d1">Aaron Dharna is a researcher involved in the co-generation of game levels and game-playing agents.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JULIAN TOGELIUS">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Togelius is a researcher focused on the co-generation of game levels and agents.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="LISA B SOROS">
      <data key="d0">PERSON</data>
      <data key="d1">Lisa B Soros is a researcher contributing to the co-generation of game levels and game-playing agents.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SHUANG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Shuang Li is a researcher focused on enhancing factuality and reasoning in language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ANTONIO TORRALBA">
      <data key="d0">PERSON</data>
      <data key="d1">Antonio Torralba is a researcher contributing to the improvement of factuality in language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JOSHUA B TENENBAUM">
      <data key="d0">PERSON</data>
      <data key="d1">Joshua B Tenenbaum is a researcher involved in enhancing reasoning in language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="DHEERU DUA">
      <data key="d0">PERSON</data>
      <data key="d1">Dheeru Dua is a researcher involved in the development of a reading comprehension benchmark requiring discrete reasoning.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YIZHONG WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yizhong Wang is a researcher contributing to the development of a reading comprehension benchmark.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PRADEEP DASIGI">
      <data key="d0">PERSON</data>
      <data key="d1">Pradeep Dasigi is a researcher focused on creating a reading comprehension benchmark.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GABRIEL STANOVSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Gabriel Stanovsky is a researcher involved in the development of a reading comprehension benchmark.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAMEER SINGH">
      <data key="d0">PERSON</data>
      <data key="d1">Sameer Singh is a researcher contributing to the creation of a reading comprehension benchmark.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MATT GARDNER">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Gardner is a researcher focused on developing a reading comprehension benchmark.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YAN DUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Yan Duan is a researcher involved in fast reinforcement learning techniques.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="XI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xi Chen is a researcher focused on reinforcement learning techniques.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="PETER L BARTLETT">
      <data key="d0">PERSON</data>
      <data key="d1">Peter L Bartlett is a researcher involved in reinforcement learning research.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="RL^2">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">RL^2 is a method for fast reinforcement learning via slow reinforcement learning techniques.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="ADRIEN ECOFFET">
      <data key="d0">PERSON</data>
      <data key="d1">Adrien Ecoffet is a researcher involved in creating safe open-ended AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOEL LEHMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Joel Lehman is a researcher contributing to the study of safe open-ended AI systems.
Joel Lehman is a researcher who co-authored a paper on evolution through the search for novelty alone, published in 2011.
Joel Lehman is a researcher who co-authored a paper on language model crossover.
Joel Lehman is a researcher who co-authored a book on the myth of the objective in planning.
Joel Lehman is a researcher involved in the development of open-ended reinforcement learning systems.
Joel Lehman is a researcher who co-authored a paper on open-endedness in models of human notions of interestingness.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OPEN QUESTIONS IN CREATING SAFE OPEN-ENDED AI">
      <data key="d0">RESEARCH</data>
      <data key="d1">Open questions in creating safe open-ended AI address the tensions between control and creativity in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">RESEARCH</data>
    </node>
    <node id="THOMAS ELSKEN">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Elsken is a researcher known for his work on neural architecture search.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JAN HENDRIK METZEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jan Hendrik Metzen is a researcher contributing to neural architecture search.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FRANK HUTTER">
      <data key="d0">PERSON</data>
      <data key="d1">Frank Hutter is a researcher focused on neural architecture search techniques.
Frank Hutter is a researcher who co-authored a book on automated machine learning, discussing methods, systems, and challenges, published in 2019.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAXENCE FALDOR">
      <data key="d0">PERSON</data>
      <data key="d1">Maxence Faldor is a researcher involved in open-endedness in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JENNY ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jenny Zhang is a researcher contributing to the study of open-endedness in AI.
Jenny Zhang is a researcher involved in the study of open-endedness in AI systems.
Jenny Zhang is a researcher who co-authored a paper on open-endedness in models of human notions of interestingness.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANTOINE CULLY">
      <data key="d0">PERSON</data>
      <data key="d1">Antoine Cully is a researcher focused on open-endedness in AI systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHRISANTHA FERNANDO">
      <data key="d0">PERSON</data>
      <data key="d1">Chrisantha Fernando is a researcher involved in self-referential self-improvement in AI.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DYLAN SUNIL BANARSE">
      <data key="d0">PERSON</data>
      <data key="d1">Dylan Sunil Banarse is a researcher contributing to self-referential self-improvement in AI.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HENRYK MICHALIEWSKI">
      <data key="d0">PERSON</data>
      <data key="d1">Henryk Michaliewski is a researcher focused on self-referential self-improvement in AI.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SIMON OSINDERO">
      <data key="d0">PERSON</data>
      <data key="d1">Simon Osindero is a researcher involved in self-referential self-improvement in AI.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TIM ROCKT&#196;SCHEL">
      <data key="d0">PERSON</data>
      <data key="d1">Tim Rockt&#228;schel is a researcher contributing to self-referential self-improvement in AI.
Tim Rockt&#228;schel is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.
Tim Rockt&#228;schel is an author of a book on artificial intelligence.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MODEL-AGNOSTIC META-LEARNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Model-agnostic meta-learning is a method for fast adaptation of deep networks.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="AMAN MADAAN">
      <data key="d0">PERSON</data>
      <data key="d1">Aman Madaan is a researcher focused on program-aided language models.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GETTING 50% SOTA ON ARC-AGI WITH GPT-4">
      <data key="d0">RESEARCH</data>
      <data key="d1">Getting 50% SOTA on ARC-AGI with GPT-4 is a study focused on achieving state-of-the-art performance using the GPT-4 model.Getting 50% SOTA on ARC-AGI with GPT-4 is a study focused on achieving state-of-the-art performance using the GPT-4 model.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
      <data key="d3">RESEARCH</data>
    </node>
    <node id="RYAN GREENBLATT">
      <data key="d0">PERSON</data>
      <data key="d1">Ryan Greenblatt is a researcher who authored a technical report on achieving state-of-the-art performance with GPT-4 in July 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DAN HENDRYCKS">
      <data key="d0">PERSON</data>
      <data key="d1">Dan Hendrycks is a researcher who co-authored a paper on measuring massive multitask language understanding presented at the International Conference on Learning Representations in 2021.
Dan Hendrycks is a researcher known for measuring mathematical problem-solving capabilities.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="COLLIN BURNS">
      <data key="d0">PERSON</data>
      <data key="d1">Collin Burns is a researcher who co-authored a paper on measuring massive multitask language understanding presented at the International Conference on Learning Representations in 2021.
Collin Burns is a researcher involved in measuring mathematical problem-solving capabilities.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="STEVEN BASART">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Basart is a researcher who co-authored a paper on measuring massive multitask language understanding presented at the International Conference on Learning Representations in 2021.
Steven Basart is a researcher who contributed to measuring mathematical problem-solving capabilities.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ANDY ZOU">
      <data key="d0">PERSON</data>
      <data key="d1">Andy Zou is a researcher who co-authored a paper on measuring massive multitask language understanding presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MANTAS MAZEIKA">
      <data key="d0">PERSON</data>
      <data key="d1">Mantas Mazeika is a researcher who co-authored a paper on measuring massive multitask language understanding presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DAWN SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Dawn Song is a researcher who co-authored a paper on measuring massive multitask language understanding presented at the International Conference on Learning Representations in 2021.
Dawn Song is a researcher involved in discussing the limitations of imitating proprietary language models.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JACOB STEINHARDT">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Steinhardt is a researcher who co-authored a paper on measuring massive multitask language understanding presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SIRUI HONG">
      <data key="d0">PERSON</data>
      <data key="d1">Sirui Hong is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="XIAWU ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiawu Zheng is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JONATHAN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jonathan Chen is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YUHENG CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Yuheng Cheng is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JINLIN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jinlin Wang is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CEYAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ceyao Zhang is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZILI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zili Wang is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="STEVEN KA SHING YAU">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Ka Shing Yau is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZIJUAN LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Zijuan Lin is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LIYANG ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Liyang Zhou is a researcher who co-authored a paper on MetaGPT, a meta programming framework for multi-agent collaboration, in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHICHAO LU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhichao Lu is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.Zhichao Lu is a researcher who co-authored a paper on accelerating multi-objective neural architecture search by random-weight evaluation, published in 2021.
Zhichao Lu is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VISHNU NARESH BODDETI">
      <data key="d0">PERSON</data>
      <data key="d1">Vishnu Naresh Boddeti is a researcher who co-authored a paper on revisiting residual networks for adversarial robustness, presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LARS KOTTHOFF">
      <data key="d0">PERSON</data>
      <data key="d1">Lars Kotthoff is a researcher who co-authored a book on automated machine learning, discussing methods, systems, and challenges, published in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JOAQUIN VANSCHOREN">
      <data key="d0">PERSON</data>
      <data key="d1">Joaquin Vanschoren is a researcher who co-authored a book on automated machine learning, discussing methods, systems, and challenges, published in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="OMAR KHATTAB">
      <data key="d0">PERSON</data>
      <data key="d1">Omar Khattab is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ARNAV SINGHVI">
      <data key="d0">PERSON</data>
      <data key="d1">Arnav Singhvi is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PARIDHI MAHESHWARI">
      <data key="d0">PERSON</data>
      <data key="d1">Paridhi Maheshwari is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHIZHUAN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Zhang is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="KESHAV SANTHANAM">
      <data key="d0">PERSON</data>
      <data key="d1">Keshav Santhanam is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SAIFUL HAQ">
      <data key="d0">PERSON</data>
      <data key="d1">Saiful Haq is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ASHUTOSH SHARMA">
      <data key="d0">PERSON</data>
      <data key="d1">Ashutosh Sharma is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="THOMAS T JOSHI">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas T Joshi is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HANNA MOAZAM">
      <data key="d0">PERSON</data>
      <data key="d1">Hanna Moazam is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HEATHER MILLER">
      <data key="d0">PERSON</data>
      <data key="d1">Heather Miller is a researcher who co-authored a paper on DSpy, which compiles declarative language model calls into state-of-the-art pipelines, presented at the International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEX KRIZHEVSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Alex Krizhevsky is a researcher known for his work on ImageNet classification using deep convolutional neural networks, published in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ILYAS SUTSKEVER">
      <data key="d0">PERSON</data>
      <data key="d1">Ilya Sutskever is a researcher known for his work on ImageNet classification using deep convolutional neural networks, published in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="GEOFFREY HINTON">
      <data key="d0">PERSON</data>
      <data key="d1">Geoffrey Hinton is a researcher known for his work on ImageNet classification using deep convolutional neural networks, published in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ABRAHIM LADHA">
      <data key="d0">PERSON</data>
      <data key="d1">Abrahim Ladha is a researcher who authored a lecture on Turing-completeness, available online in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LANGCHAINAI">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">LangChainAI is an organization that focuses on building context-aware reasoning applications, with resources available on GitHub since 2022.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="KENNETH O STANLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Kenneth O Stanley is a researcher who co-authored a paper on evolution through the search for novelty alone, published in 2011.
Kenneth O Stanley is a researcher who authored a book on the myth of the objective in planning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PATRICK LEWIS">
      <data key="d0">PERSON</data>
      <data key="d1">Patrick Lewis is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ETHAN PEREZ">
      <data key="d0">PERSON</data>
      <data key="d1">Ethan Perez is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEKSANDRA PIKTUS">
      <data key="d0">PERSON</data>
      <data key="d1">Aleksandra Piktus is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FABIO PETRONI">
      <data key="d0">PERSON</data>
      <data key="d1">Fabio Petroni is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VLADIMIR KARPUKHIN">
      <data key="d0">PERSON</data>
      <data key="d1">Vladimir Karpukhin is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HEINRICH K&#220;TTLER">
      <data key="d0">PERSON</data>
      <data key="d1">Heinrich K&#252;ttler is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MIKE LEWIS">
      <data key="d0">PERSON</data>
      <data key="d1">Mike Lewis is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="WEN-TAU YIH">
      <data key="d0">PERSON</data>
      <data key="d1">Wen-tau Yih is a researcher who co-authored a paper on retrieval-augmented generation for knowledge-intensive NLP tasks, published in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FEI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Fei Liu is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="TONG XIALIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Tong Xialiang is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MINGXUAN YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Mingxuan Yuan is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="XI LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Xi Lin is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FU LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Fu Luo is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHENKUN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhenkun Wang is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="QINGFU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Qingfu Zhang is a researcher who co-authored a paper on the evolution of heuristics for efficient automatic algorithm design using large language models, presented at the International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZIJUN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zijun Liu is a researcher who co-authored a paper on dynamic LLM-agent networks, which focuses on collaboration frameworks with agent team optimization, presented as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YANZHE ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yanzhe Zhang is a researcher who co-authored a paper on dynamic LLM-agent networks, which focuses on collaboration frameworks with agent team optimization, presented as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Peng Li is a researcher who co-authored a paper on dynamic LLM-agent networks, which focuses on collaboration frameworks with agent team optimization, presented as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YANG LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Yang Liu is a researcher who co-authored a paper on dynamic LLM-agent networks, which focuses on collaboration frameworks with agent team optimization, presented as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DIYI YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Diyi Yang is a researcher who co-authored a paper on dynamic LLM-agent networks, which focuses on collaboration frameworks with agent team optimization, presented as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CHRIS LU">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Lu is a researcher who co-authored a paper on arbitrary order meta-learning with simple population-based evolution, presented at the 2023 Artificial Life Conference.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SEBASTIAN TOWERS">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Towers is a researcher who co-authored a paper on arbitrary order meta-learning with simple population-based evolution, presented at the 2023 Artificial Life Conference.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JAKOB FOERSTER">
      <data key="d0">PERSON</data>
      <data key="d1">Jakob Foerster is a researcher who co-authored a paper on arbitrary order meta-learning with simple population-based evolution, presented at the 2023 Artificial Life Conference.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CLAUDIO FANCONI">
      <data key="d0">PERSON</data>
      <data key="d1">Claudio Fanconi is a researcher who co-authored a paper on discovering preference optimization algorithms with large language models, presented as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEX J CHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Alex J Chan is a researcher who co-authored a paper on discovering preference optimization("entity"</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="META PROGRAMMING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Meta programming refers to programming techniques that allow for the creation of programs that can manipulate other programs, as explored in the context of multi-agent collaboration in the MetaGPT paper.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="THOUGHT CLONING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Thought Cloning is a method that involves learning to think while acting by imitating human cognitive processes, as discussed in a paper by Shengran Hu and Jeff Clune in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUTOMATED MACHINE LEARNING">
      <data key="d0">FIELD</data>
      <data key="d1">Automated machine learning encompasses methods and systems designed to automate the process of applying machine learning to real-world problems, as discussed in a book by Frank Hutter and others in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="IMAGE CLASSIFICATION">
      <data key="d0">FIELD</data>
      <data key="d1">Image classification is a computer vision task that involves categorizing images into predefined classes, as exemplified by the work of Alex Krizhevsky and others in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="TURING-COMPLETENESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Turing-completeness is a concept in computer science that describes a system capable of performing any computation that can be described algorithmically, as discussed in Abrahim Ladha's lecture in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="EVOLUTIONARY COMPUTATION">
      <data key="d0">FIELD</data>
      <data key="d1">Evolutionary computation is a subset of artificial intelligence that involves algorithms inspired by natural selection, as discussed in the work of Joel Lehman and Kenneth O Stanley in 2011.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MULTI-OBJECTIVE OPTIMIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-objective optimization involves optimizing two or more conflicting objectives simultaneously, often used in neural architecture search and other complex decision-making scenarios.
Multi-objective optimization is a technique used in various algorithms, including genetic algorithms, to optimize multiple conflicting objectives simultaneously, as discussed in the context of NSGA-Net.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AGENT TEAM OPTIMIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Agent team optimization refers to strategies aimed at improving the performance and collaboration of multiple agents working together, as discussed in the context of dynamic LLM-agent networks.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HUMAN-COMPUTER INTERACTION">
      <data key="d0">FIELD</data>
      <data key="d1">Human-computer interaction is a field of study focused on the design and use of computer technology, emphasizing the interfaces between people and computers, relevant to many of the discussed techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUTOMATED DESIGN">
      <data key="d0">FIELD</data>
      <data key="d1">Automated design refers to the use of algorithms and computational methods to automate the design process in various fields, including engineering and software development, as explored in the context of agentic systems.
Automated design refers to the use of algorithms and AI to create designs or solutions without human intervention, relevant to the context of agentic systems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="KNOWLEDGE-INTENSIVE TASKS">
      <data key="d0">FIELD</data>
      <data key="d1">Knowledge-intensive tasks are tasks that require a significant amount of domain-specific knowledge, often addressed through advanced NLP techniques like retrieval-augmented generation.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="COLLABORATIVE FRAMEWORK">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Collaborative frameworks are systems designed to facilitate cooperation among multiple agents or entities, enhancing their collective performance and decision-making capabilities.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="STATE-OF-THE-ART PIPELINES">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">State-of-the-art pipelines refer to the most advanced and effective processes or systems used in machine learning and data processing, as discussed in the context of DSpy.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CROSS-VALIDATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Cross-validation is a statistical method used to estimate the skill of machine learning models, ensuring that they generalize well to unseen data.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DATA AUGMENTATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Data augmentation involves creating new training examples by modifying existing data, enhancing the robustness and performance of machine learning models.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="NATURAL LANGUAGE PROCESSING">
      <data key="d0">FIELD</data>
      <data key="d1">Natural language processing is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language, encompassing various techniques and applications.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="COMPUTER VISION">
      <data key="d0">FIELD</data>
      <data key="d1">Computer vision is a field of artificial intelligence that enables computers to interpret and make decisions based on visual data from the world, relevant to many discussed techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MULTI-AGENT SYSTEMS">
      <data key="d0">FIELD</data>
      <data key="d1">Multi-agent systems involve multiple agents interacting or working together to achieve a common goal, relevant to the discussions on MetaGPT and dynamic LLM-agent networks.
Multi-agent systems refer to systems composed of multiple interacting agents, often used in AI research to study collaboration and communication.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUTOMATED DECISION-MAKING">
      <data key="d0">FIELD</data>
      <data key="d1">Automated decision-making refers to the process of using algorithms and data to make decisions without human intervention, relevant to many of the discussed techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DATA SCIENCE">
      <data key="d0">FIELD</data>
      <data key="d1">Data science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.
Data science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="COMPUTATIONAL INTELLIGENCE">
      <data key="d0">FIELD</data>
      <data key="d1">Computational intelligence is a field of study that focuses on the design of intelligent agents and systems that can solve complex problems through adaptive learning and reasoning.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALGORITHMIC DESIGN">
      <data key="d0">FIELD</data>
      <data key="d1">Algorithmic design refers to the process of creating algorithms to solve specific problems, often involving optimization and efficiency considerations.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SYSTEMS ENGINEERING">
      <data key="d0">FIELD</data>
      <data key="d1">Systems engineering is an interdisciplinary field that focuses on the design, integration, and management of complex systems over their life cycles.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DECISION SUPPORT SYSTEMS">
      <data key="d0">FIELD</data>
      <data key="d1">Decision support systems are computer-based information systems that support business or organizational decision-making activities.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DATA MINING">
      <data key="d0">FIELD</data>
      <data key="d1">Data mining is the process of discovering patterns and knowledge from large amounts of data, often used in conjunction with machine learning techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="BIG DATA">
      <data key="d0">FIELD</data>
      <data key="d1">Big data refers to large and complex data sets that traditional data processing applications cannot handle, often requiring advanced analytical techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CLOUD COMPUTING">
      <data key="d0">FIELD</data>
      <data key="d1">Cloud computing is the delivery of computing services over the internet, allowing for on-demand access to a shared pool of configurable resources.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PREDICTIVE ANALYTICS">
      <data key="d0">FIELD</data>
      <data key="d1">Predictive analytics involves using statistical algorithms and machine learning techniques to identify the likelihood of future outcomes based on historical data.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="STATISTICAL LEARNING">
      <data key="d0">FIELD</data>
      <data key="d1">Statistical learning is a framework for understanding and modeling the relationships between variables, often used in machine learning and data analysis.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="EXPLORATORY DATA ANALYSIS">
      <data key="d0">FIELD</data>
      <data key="d1">Exploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often using visual methods.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="INTERACTIVE SYSTEMS">
      <data key="d0">FIELD</data>
      <data key="d1">Interactive systems are systems designed to facilitate user interaction, often incorporating feedback mechanisms to enhance user experience.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="USER EXPERIENCE DESIGN">
      <data key="d0">FIELD</data>
      <data key="d1">User experience design is the process of enhancing user satisfaction by improving the usability, accessibility, and pleasure provided in the interaction with a product.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SOFTWARE ENGINEERING">
      <data key="d0">FIELD</data>
      <data key="d1">Software engineering is the application of engineering principles to software development in a methodical way, encompassing the entire software development life cycle.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DEVOPS">
      <data key="d0">FIELD</data>
      <data key="d1">DevOps is a set of practices that combines software development (Dev) and IT operations (Ops) to shorten the systems development life cycle and provide continuous delivery.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="BLOCKCHAIN">
      <data key="d0">FIELD</data>
      <data key="d1">Blockchain is a decentralized digital ledger technology that records transactions across many computers in a way that the registered transactions cannot be altered retroactively.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="QUANTUM COMPUTING">
      <data key="d0">FIELD</data>
      <data key="d1">Quantum computing is a type of computation that takes advantage of quantum mechanics to process information in fundamentally different ways than classical computers.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="NEUROMORPHIC COMPUTING">
      <data key="d0">FIELD</data>
      <data key="d1">Neuromorphic computing is a design approach that mimics the neural structure and functioning of the human brain to improve computational efficiency and performance.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUTONOMOUS SYSTEMS">
      <data key="d0">FIELD</data>
      <data key="d1">Autonomous systems are systems capable of performing tasks without human intervention, often utilizing AI and machine learning for decision-making.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="INTERNET OF THINGS">
      <data key="d0">FIELD</data>
      <data key="d1">The Internet of Things (IoT) refers to the interconnected network of physical devices that communicate and exchange data over the internet, often utilizing AI for data analysis and decision-making.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VIRTUAL REALITY">
      <data key="d0">FIELD</data>
      <data key="d1">Virtual reality is a simulated experience that can be similar to or completely different from the real world, often used in gaming, training, and education.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUGMENTED REALITY">
      <data key="d0">FIELD</data>
      <data key="d1">Augmented reality is an interactive experience where real-world environments are enhanced by computer-generated perceptual information, often used in applications like gaming and education.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MACHINE VISION">
      <data key="d0">FIELD</data>
      <data key="d1">Machine vision is the technology and methods used to provide imaging-based automatic inspection and analysis for process control and robot guidance.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SENSOR NETWORKS">
      <data key="d0">FIELD</data>
      <data key="d1">Sensor networks are networks of spatially distributed sensors that monitor physical or environmental conditions, often used in IoT applications.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CYBERSECURITY">
      <data key="d0">FIELD</data>
      <data key="d1">Cybersecurity is the practice of protecting systems, networks, and programs from digital attacks, often involving various technologies and strategies.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DATA PRIVACY">
      <data key="d0">FIELD</data>
      <data key="d1">Data privacy refers to the proper handling, processing, storage, and usage of personal data, ensuring that individuals' privacy rights are respected.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ETHICAL AI">
      <data key="d0">FIELD</data>
      <data key="d1">Ethical AI refers to the development and implementation of artificial intelligence systems that adhere to ethical principles and guidelines, ensuring fairness, accountability, and transparency.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AI GOVERNANCE">
      <data key="d0">FIELD</data>
      <data key="d1">AI governance involves the frameworks and policies that guide the development and use of AI technologies, ensuring they are used responsibly and ethically.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SUSTAINABLE TECHNOLOGY">
      <data key="d0">FIELD</data>
      <data key="d1">Sustainable technology refers to technologies that are designed to have a minimal impact on the environment, promoting sustainability and reducing resource consumption.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CIRCULAR ECONOMY">
      <data key="d0">FIELD</data>
      <data key="d1">Circular economy is an economic system aimed at eliminating waste and the continual use of resources, often involving innovative technologies and practices.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="GREEN TECHNOLOGY">
      <data key="d0">FIELD</data>
      <data key="d1">Green technology refers to technology that is environmentally friendly and sustainable, often focusing on renewable energy and resource efficiency.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SMART CITIES">
      <data key="d0">FIELD</data>
      <data key="d1">Smart cities are urban areas that use various types of electronic data collection sensors to supply information used to manage assets and resources efficiently.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DIGITAL TRANSFORMATION">
      <data key="d0">FIELD</data>
      <data key="d1">Digital transformation refers to the integration of digital technology into all areas of a business, fundamentally changing how it operates and delivers value to customers.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="INDUSTRY 4.0">
      <data key="d0">FIELD</data>
      <data key="d1">Industry 4.0 refers to the current trend of automation and data exchange in manufacturing technologies, including cyber-physical systems, IoT, and cloud computing.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AGRICULTURAL TECHNOLOGY">
      <data key="d0">FIELD</data>
      <data key="d1">Agricultural technology refers to the use of technology in agriculture to improve yield, efficiency, and sustainability, often involving precision farming techniques.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FINTECH">
      <data key="d0">FIELD</data>
      <data key="d1">Fintech refers to technology that aims to improve and automate the delivery and use of financial services, often involving innovative solutions for banking and payments.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HEALTH TECH">
      <data key="d0">FIELD</data>
      <data key="d1">Health tech refers to technology that aims to improve health and healthcare delivery, often involving digital health solutions and medical devices.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="EDTECH">
      <data key="d0">FIELD</data>
      <data key="d1">Edtech refers to technology that enhances education and learning experiences, often involving online learning platforms and educational software.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MOBILITY TECHNOLOGY">
      <data key="d0">FIELD</data>
      <data key="d1">Mobility technology refers to technology that enhances transportation and mobility solutions, often involving smart transportation systems and electric vehicles.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SPACE TECHNOLOGY">
      <data key="d0">FIELD</data>
      <data key="d1">Space technology refers to the technology used in the exploration and utilization of outer space, often involving advanced engineering and scientific research.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AEROSPACE ENGINEERING">
      <data key="d0">FIELD</data>
      <data key="d1">Aerospace engineering is the branch of engineering that deals with the design, development, and production of aircraft and spacecraft.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ROBOTIC PROCESS AUTOMATION">
      <data key="d0">FIELD</data>
      <data key="d1">Robotic process automation refers to the use of software robots to automate repetitive tasks, improving efficiency and accuracy in business processes.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="QUANTUM MACHINE LEARNING">
      <data key="d0">FIELD</data>
      <data key="d1">Quantum machine learning is an interdisciplinary field that combines quantum computing and machine learning, exploring how quantum algorithms can enhance machine learning tasks.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="BIOINFORMATICS">
      <data key="d0">FIELD</data>
      <data key="d1">Bioinformatics is an interdisciplinary field that develops methods and software tools for understanding biological data, particularly in genomics and molecular biology.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="NEUROSCIENCE">
      <data key="d0">FIELD</data>
      <data key="d1">Neuroscience is the scientific study of the nervous system, often intersecting with fields like artificial intelligence and cognitive science.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="COGNITIVE SCIENCE">
      <data key="d0">FIELD</data>
      <data key="d1">Cognitive science is the interdisciplinary study of the mind and its processes, including how people think, learn, and remember.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SOCIAL ROBOTICS">
      <data key="d0">FIELD</data>
      <data key="d1">Social robotics is a field of study focused on the design and development of robots that can interact with humans in a social context.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HUMAN-ROBOT INTERACTION">
      <data key="d0">FIELD</data>
      <data key="d1">Human-robot interaction is the study of how humans and robots communicate and collaborate, often focusing on improving user experience and effectiveness.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VIRTUAL ASSISTANTS">
      <data key="d0">FIELD</data>
      <data key="d1">Virtual assistants are AI-powered software agents that can perform tasks or services for individuals based on commands or questions.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CHATBOTS">
      <data key="d0">FIELD</data>
      <data key="d1">Chatbots are AI programs that simulate</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="IAN WHALEN">
      <data key="d0">PERSON</data>
      <data key="d1">Ian Whalen is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="VISHNU BODDETI">
      <data key="d0">PERSON</data>
      <data key="d1">Vishnu Boddeti is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="YASHESH DHEBAR">
      <data key="d0">PERSON</data>
      <data key="d1">Yashesh Dhebar is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ERIK GOODMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Erik Goodman is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="WOLFGANG BANZHAF">
      <data key="d0">PERSON</data>
      <data key="d1">Wolfgang Banzhaf is a researcher who co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="YECHENG JASON MA">
      <data key="d0">PERSON</data>
      <data key="d1">Yecheng Jason Ma is a researcher who co-authored a paper on human-level reward design using large language models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="WILLIAM LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">William Liang is a researcher who co-authored a paper on human-level reward design using large language models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="OSBERT BASTANI">
      <data key="d0">PERSON</data>
      <data key="d1">Osbert Bastani is a researcher who co-authored a paper on human-level reward design using large language models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="DINESH JAYARAMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Dinesh Jayaraman is a researcher who co-authored a paper on human-level reward design using large language models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ELLIOT MEYERSON">
      <data key="d0">PERSON</data>
      <data key="d1">Elliot Meyerson is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="MARK J NELSON">
      <data key="d0">PERSON</data>
      <data key="d1">Mark J Nelson is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="HERBIE BRADLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Herbie Bradley is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ADAM GAIER">
      <data key="d0">PERSON</data>
      <data key="d1">Adam Gaier is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ARASH MORADI">
      <data key="d0">PERSON</data>
      <data key="d1">Arash Moradi is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AMY K HOOVER">
      <data key="d0">PERSON</data>
      <data key="d1">Amy K Hoover is a researcher who co-authored a paper on language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="JEAN-BAPTISTE MOURET">
      <data key="d0">PERSON</data>
      <data key="d1">Jean-Baptiste Mouret is a researcher who co-authored a paper on mapping elites in search spaces.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="JEFF WU">
      <data key="d0">PERSON</data>
      <data key="d1">Jeff Wu is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="LONG OUYANG">
      <data key="d0">PERSON</data>
      <data key="d1">Long Ouyang is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="CHRISTINA KIM">
      <data key="d0">PERSON</data>
      <data key="d1">Christina Kim is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="WILLIAM SAUNDERS">
      <data key="d0">PERSON</data>
      <data key="d1">William Saunders is a researcher who co-authored a paper on browser-assisted question-answering.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="GENERIC AGENTS">
      <data key="d0">RESEARCH</data>
      <data key="d1">Generative agents are interactive models that simulate human behavior, as discussed in a paper by Joon Sung Park and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="JOON SUNG PARK">
      <data key="d0">PERSON</data>
      <data key="d1">Joon Sung Park is a researcher who co-authored a paper on generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="JOSEPH O&#8217;BRIEN">
      <data key="d0">PERSON</data>
      <data key="d1">Joseph O&#8217;Brien is a researcher who co-authored a paper on generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="CARRIE JUN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Carrie Jun Cai is a researcher who co-authored a paper on generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="MEREDITH RINGEL MORRIS">
      <data key="d0">PERSON</data>
      <data key="d1">Meredith Ringel Morris is a researcher who co-authored a paper on generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="PERCY LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Percy Liang is a researcher who co-authored a paper on generative agents.
Percy Liang is a researcher involved in the development of communicative agents for exploring large language model society.
Percy Liang is a researcher who co-authored a paper on an automatic evaluator for instruction-following models.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MICHAEL S BERNSTEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Michael S Bernstein is a researcher who co-authored a paper on generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="LANGUAGE MODEL CROSSOVER">
      <data key="d0" />
      <data key="d1">Language model crossover is a technique that explores variations in language models through few-shot prompting, as discussed in a paper by Elliot Meyerson and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH</data>
    </node>
    <node id="ILLUMINATING SEARCH SPACES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="BROWSER-ASSISTED QUESTION-ANSWERING">
      <data key="d0" />
      <data key="d1">Browser-assisted question-answering is a technique that combines web browsing capabilities with question-answering systems to enhance information retrieval, as discussed in the context of WebGPT.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="NSGA-NET">
      <data key="d0">RESEARCH</data>
      <data key="d1">NSGA-Net is a method for neural architecture search using a multi-objective genetic algorithm, as discussed in a paper by Zhichao Lu and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="TOOL LEARNING">
      <data key="d0">RESEARCH</data>
      <data key="d1">Tool learning with large language models is a survey discussing how LLMs can learn to use tools effectively, as discussed in a paper by Changle Qu and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="COMMUNICATIVE AGENTS">
      <data key="d0">RESEARCH</data>
      <data key="d1">Communicative agents for software development are models designed to assist in software development through communication, as discussed in a paper by Chen Qian and others.
</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SCALING MULTI-AGENT COLLABORATION">
      <data key="d0">RESEARCH</data>
      <data key="d1">Scaling large-language-model-based multi-agent collaboration refers to research on enhancing collaboration among multiple agents using large language models, as discussed in a paper by Chen Qian and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="DIRECT PREFERENCE OPTIMIZATION">
      <data key="d0">RESEARCH</data>
      <data key="d1">Direct preference optimization is a method that treats language models as reward models to improve their performance, as discussed in a paper by Rafael Rafailov and others.
Direct preference optimization is a method that treats language models as reward models to optimize preferences in outputs.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The Genetic and Evolutionary Computation Conference is an academic conference where research related to genetic algorithms and evolutionary computation is presented, including work by Zhichao Lu and others.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The Twelfth International Conference on Learning Representations is an academic conference focused on machine learning and representation learning, where research by Yecheng Jason Ma and others was presented.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ASSOCIATION FOR COMPUTATIONAL LINGUISTICS">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The Association for Computational Linguistics is a professional organization that promotes research and education in computational linguistics, associated with various conferences and publications.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The ACM Symposium on User Interface Software and Technology is a conference focused on user interface software and technology, where research by Joon Sung Park and others was presented.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="FEW-SHOT PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Few-shot prompting is a technique in which a model is given a few examples to learn from in order to perform a task, as discussed in the context of language model crossover.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="ITERATIVE REFINEMENT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Iterative refinement is a process of gradually improving a model's performance through repeated adjustments, as discussed in the context of self-refine.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="HUMAN FEEDBACK">
      <data key="d0">CONCEPT</data>
      <data key="d1">Human feedback refers to the input provided by users to improve the performance of AI systems, particularly in the context of training models like WebGPT.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="META">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Meta is a technology company known for its work in social media and artificial intelligence, including initiatives related to open-source AI.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="GENETIC ALGORITHMS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Genetic algorithms are optimization algorithms inspired by the process of natural selection, used in various research contexts including NSGA-Net.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="REWARD DESIGN">
      <data key="d0">CONCEPT</data>
      <data key="d1">Reward design involves creating reward structures for training AI models, particularly in reinforcement learning contexts, as discussed in the context of Eureka.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="MATH WORD PROBLEMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Math word problems are problems that require mathematical reasoning to solve, relevant to the research on evaluating and developing solvers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="LANGUAGE MODELING">
      <data key="d0">FIELD</data>
      <data key="d1">Language modeling is a field of study focused on predicting the next word in a sequence, foundational to many AI applications including chatbots and text generation.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="INTERACTIVE SIMULACRA">
      <data key="d0">CONCEPT</data>
      <data key="d1">Interactive simulacra refer to models that simulate human behavior in an interactive manner, as discussed in the context of generative agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="HUMAN-LEVEL AI">
      <data key="d0">CONCEPT</data>
      <data key="d1">Human-level AI refers to artificial intelligence systems that can perform tasks at a level comparable to human intelligence, a goal of many research efforts.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="NEURAL NETWORKS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Neural networks are computational models inspired by the human brain, widely used in AI for tasks such as image and speech recognition.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="NLP MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">NLP models are models designed for natural language processing tasks, relevant to many discussions in the context of AI research.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="MULTI-OBJECTIVE GENETIC ALGORITHM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-objective genetic algorithms are optimization techniques that evolve solutions to optimize multiple objectives simultaneously, as discussed in the context of NSGA-Net.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="HUMAN-CENTERED AI">
      <data key="d0">CONCEPT</data>
      <data key="d1">Human-centered AI refers to the design and implementation of AI systems that prioritize human needs and values, relevant to discussions on AI ethics and usability.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AUTOMATED SCIENTIFIC DISCOVERY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Automated scientific discovery refers to the use of AI and algorithms to conduct scientific research and make discoveries without human intervention.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="RESEARCH COLLABORATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research collaboration refers to the joint effort of researchers to achieve common goals, often seen in the co-authorship of papers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="TECHNICAL REPORT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A technical report is a document that describes the process, progress, or results of technical or scientific research, often published by organizations like OpenAI.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="PREPRINT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A preprint is a version of a scholarly paper that precedes formal peer review and publication in a scientific journal, often shared on platforms like arXiv.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="PAPER">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A paper is a written work that presents original research findings, often published in academic journals or presented at conferences.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="RESEARCH PAPER">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A research paper is a detailed document that presents the results of original research, typically peer-reviewed and published in academic journals.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="TECHNOLOGY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Technology refers to the application of scientific knowledge for practical purposes, especially in industry and research.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AUTOMATED SYSTEMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Automated systems are systems that operate automatically with minimal human intervention, often used in various applications including manufacturing and AI.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="RESEARCH FINDINGS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research findings are the results or conclusions drawn from scientific studies, often published in academic papers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="DATASETS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Datasets are collections of data used for training and testing AI models, crucial for the development of machine learning algorithms.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="RESEARCH INITIATIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research initiatives are organized efforts to conduct research in specific areas, often involving collaboration among multiple researchers or institutions.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="RESEARCH NETWORKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research networks are collaborative groups of researchers and institutions that work together to advance knowledge in specific fields.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI FUTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The future of AI refers to the anticipated developments and impacts of artificial intelligence technologies on society and various industries.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI RESEARCH COMMUNITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">The AI research community encompasses researchers, practitioners, and organizations involved in the study and development of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI POLICY">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI policy refers to the guidelines and regulations governing the development and use of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI ETHICS COMMITTEES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">AI ethics committees are groups formed to address ethical considerations in the development and deployment of AI technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI RESEARCH FUNDING">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI research funding refers to financial support provided for research projects in the field of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI STARTUPS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI startups are new companies focused on developing innovative artificial intelligence technologies and applications.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI INVESTMENT">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI investment refers to the allocation of financial resources towards the development and commercialization of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI CONSULTING">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI consulting involves providing expert advice and services related to the implementation and use of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI RESEARCH LABS">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">AI research labs are specialized facilities dedicated to conducting research and development in the field of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI CONFERENCES">
      <data key="d0">EVENT</data>
      <data key="d1">AI conferences are events where researchers and practitioners gather to share knowledge and advancements in artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI SYMPOSIUMS">
      <data key="d0">EVENT</data>
      <data key="d1">AI symposiums are formal meetings or conferences focused on discussing specific topics in artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI WORKSHOPS">
      <data key="d0">EVENT</data>
      <data key="d1">AI workshops are interactive sessions where participants engage in hands-on learning and discussions about artificial intelligence topics.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI SEMINARS">
      <data key="d0">EVENT</data>
      <data key="d1">AI seminars are educational sessions focused on specific aspects of artificial intelligence, often featuring expert speakers.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI WEBINARS">
      <data key="d0">EVENT</data>
      <data key="d1">AI webinars are online seminars that provide information and discussions on various artificial intelligence topics.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI PODCASTS">
      <data key="d0">MEDIA</data>
      <data key="d1">AI podcasts are audio programs that discuss topics related to artificial intelligence, featuring interviews and expert insights.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI BLOGS">
      <data key="d0">MEDIA</data>
      <data key="d1">AI blogs are online platforms where articles and discussions about artificial intelligence are published.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI NEWSLETTERS">
      <data key="d0">MEDIA</data>
      <data key="d1">AI newsletters are periodic publications that provide updates and insights on developments in the field of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI REPORTS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">AI reports are comprehensive documents that analyze trends, challenges, and advancements in artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI WHITE PAPERS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">AI white papers are authoritative reports that provide detailed information on specific topics in artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI CASE STUDIES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">AI case studies are detailed analyses of specific applications or implementations of artificial intelligence technologies.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI SURVEYS">
      <data key="d0">DOCUMENT</data>
      <data key="d1">AI surveys are research studies that gather data and insights on various aspects of artificial intelligence.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI ANALYTICS">
      <data key="d0">FIELD</data>
      <data key="d1">AI analytics refers to the use of artificial intelligence techniques to analyze data and extract insights.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI METRICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI metrics are standards used to measure the performance and effectiveness of artificial intelligence systems.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="AI BENCHMARKS">
      <data key="d0">CONCEPT</data>
      <data key="d1">AI benchmarks are reference points used</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
    </node>
    <node id="QIANG WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Qiang Wang is a researcher who co-authored a survey on tool learning with large language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DAWEI YIN">
      <data key="d0">PERSON</data>
      <data key="d1">Dawei Yin is a researcher who co-authored a survey on tool learning with large language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JUN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Jun Xu is a researcher who co-authored a survey on tool learning with large language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JI-RONG WEN">
      <data key="d0">PERSON</data>
      <data key="d1">Ji-Rong Wen is a researcher who co-authored a survey on tool learning with large language models.
Ji-Rong Wen is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RAFAEL RAFAILOV">
      <data key="d0">PERSON</data>
      <data key="d1">Rafael Rafailov is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARCHIT SHARMA">
      <data key="d0">PERSON</data>
      <data key="d1">Archit Sharma is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ERIC MITCHELL">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Mitchell is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHRISTOPHER D MANNING">
      <data key="d0">PERSON</data>
      <data key="d1">Christopher D Manning is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="STEFANO ERMON">
      <data key="d0">PERSON</data>
      <data key="d1">Stefano Ermon is a researcher who co-authored a paper on direct preference optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DAVID REIN">
      <data key="d0">PERSON</data>
      <data key="d1">David Rein is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BETTY LI HOU">
      <data key="d0">PERSON</data>
      <data key="d1">Betty Li Hou is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ASA COOPER STICKLAND">
      <data key="d0">PERSON</data>
      <data key="d1">Asa Cooper Stickland is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JACKSON PETTY">
      <data key="d0">PERSON</data>
      <data key="d1">Jackson Petty is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RICHARD YUANZHE PANG">
      <data key="d0">PERSON</data>
      <data key="d1">Richard Yuanzhe Pang is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JULIEN DIRANI">
      <data key="d0">PERSON</data>
      <data key="d1">Julien Dirani is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JULIAN MICHAEL">
      <data key="d0">PERSON</data>
      <data key="d1">Julian Michael is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SAMUEL R BOWMAN">
      <data key="d0">PERSON</data>
      <data key="d1">Samuel R. Bowman is a researcher who co-authored a paper on the GPQA benchmark.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TORAN BRUCE RICHARDS">
      <data key="d0">PERSON</data>
      <data key="d1">Toran Bruce Richards is a researcher who developed AutoGPT, a GitHub repository.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MD OMAR FARUK ROKON">
      <data key="d0">PERSON</data>
      <data key="d1">Md Omar Faruk Rokon is a researcher who co-authored a paper on malware source code detection.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RISUL ISLAM">
      <data key="d0">PERSON</data>
      <data key="d1">Risul Islam is a researcher who co-authored a paper on malware source code detection.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AHMAD DARKI">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmad Darki is a researcher who co-authored a paper on malware source code detection.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="EVANGELOS E PAPALEXAKIS">
      <data key="d0">PERSON</data>
      <data key="d1">Evangelos E Papalexakis is a researcher who co-authored a paper on malware source code detection.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MICHAELIS FALOUTSOS">
      <data key="d0">PERSON</data>
      <data key="d1">Michalis Faloutsos is a researcher who co-authored a paper on malware source code detection.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BERNARDINO ROMERA-PAREDES">
      <data key="d0">PERSON</data>
      <data key="d1">Bernardino Romera-Paredes is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MOHAMMADAMIN BAREKATAIN">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammadamin Barekatain is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ALEXANDER NOVIKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Alexander Novikov is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATEJ BALOG">
      <data key="d0">PERSON</data>
      <data key="d1">Matej Balog is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="M PAWAN KUMAR">
      <data key="d0">PERSON</data>
      <data key="d1">M Pawan Kumar is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="EMILIEN DUPONT">
      <data key="d0">PERSON</data>
      <data key="d1">Emilien Dupont is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FRANCISCO JR RUIZ">
      <data key="d0">PERSON</data>
      <data key="d1">Francisco JR Ruiz is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JORDAN S ELLENBERG">
      <data key="d0">PERSON</data>
      <data key="d1">Jordan S Ellenberg is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="PENGMING WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Pengming Wang is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="OMAR FAWZI">
      <data key="d0">PERSON</data>
      <data key="d1">Omar Fawzi is a researcher who co-authored a paper on mathematical discoveries from program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ERIC HAMBRO">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Hambro is a researcher who co-authored a paper on Toolformer.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SANDER SCHULHOFF">
      <data key="d0">PERSON</data>
      <data key="d1">Sander Schulhoff is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MICHAEL ILIE">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Ilie is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NISHANT BALEPUR">
      <data key="d0">PERSON</data>
      <data key="d1">Nishant Balepur is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="KONSTANTINE KAHADZE">
      <data key="d0">PERSON</data>
      <data key="d1">Konstantine Kahadze is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AMANDA LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Amanda Liu is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHENGLEI SI">
      <data key="d0">PERSON</data>
      <data key="d1">Chenglei Si is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YINHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yinheng Li is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AAYUSH GUPTA">
      <data key="d0">PERSON</data>
      <data key="d1">Aayush Gupta is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HYOJUNG HAN">
      <data key="d0">PERSON</data>
      <data key="d1">HyoJung Han is a researcher who co-authored a systematic survey on prompting techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FREDA SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Freda Shi is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MIRAC SUZGUN">
      <data key="d0">PERSON</data>
      <data key="d1">Mirac Suzgun is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.
Mirac Suzgun is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MARKUS FREITAG">
      <data key="d0">PERSON</data>
      <data key="d1">Markus Freitag is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SURAJ SRIVATS">
      <data key="d0">PERSON</data>
      <data key="d1">Suraj Srivats is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SOROUSH VOSOUGHI">
      <data key="d0">PERSON</data>
      <data key="d1">Soroush Vosoughi is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SEBASTIAN RUDER">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Ruder is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DIPANJAN DAS">
      <data key="d0">PERSON</data>
      <data key="d1">Dipanjan Das is a researcher who co-authored a paper on multilingual chain-of-thought reasoning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NOAH SHINN">
      <data key="d0">PERSON</data>
      <data key="d1">Noah Shinn is a researcher who co-authored a paper on language agents with verbal reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FEDERICO CASSANO">
      <data key="d0">PERSON</data>
      <data key="d1">Federico Cassano is a researcher who co-authored a paper on language agents with verbal reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ASHWIN GOPINATH">
      <data key="d0">PERSON</data>
      <data key="d1">Ashwin Gopinath is a researcher who co-authored a paper on language agents with verbal reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="KARTHIK NARASIMHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Karthik Narasimhan is a researcher who co-authored a paper on language agents with verbal reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SHUNYU YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Shunyu Yao is a researcher who co-authored a paper on language agents with verbal reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RISTO MIIKKULAINEN">
      <data key="d0">PERSON</data>
      <data key="d1">Risto Miikkulainen is a researcher who co-authored a paper on designing neural networks through neuroevolution.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RICHARD S SUTTON">
      <data key="d0">PERSON</data>
      <data key="d1">Richard S Sutton is a researcher who co-authored a book on reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ANDREW G BARTO">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew G Barto is a researcher who co-authored a book on reinforcement learning.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SAI VEMPRALA">
      <data key="d0">PERSON</data>
      <data key="d1">Sai Vemprala is a researcher who authored a technical report on ChatGPT for robotics.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROGERIO BONATTI">
      <data key="d0">PERSON</data>
      <data key="d1">Rogerio Bonatti is a researcher who co-authored a technical report on ChatGPT for robotics.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARTHUR BUCKER">
      <data key="d0">PERSON</data>
      <data key="d1">Arthur Bucker is a researcher who co-authored a technical report on ChatGPT for robotics.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ASHISH KAPOOR">
      <data key="d0">PERSON</data>
      <data key="d1">Ashish Kapoor is a researcher who co-authored a technical report on ChatGPT for robotics.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YUQI XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Yuqi Xie is a researcher who co-authored a paper on Voyager, an open-ended embodied agent.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHAOWEI XIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Chaowei Xiao is a researcher who co-authored a paper on Voyager, an open-ended embodied agent.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JANE X WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jane X Wang is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZEB KURTH-NELSON">
      <data key="d0">PERSON</data>
      <data key="d1">Zeb Kurth-Nelson is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DHRUVA TIRUMALA">
      <data key="d0">PERSON</data>
      <data key="d1">Dhruva Tirumala is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HUBERT SOYER">
      <data key="d0">PERSON</data>
      <data key="d1">Hubert Soyer is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JOEL Z LEIBO">
      <data key="d0">PERSON</data>
      <data key="d1">Joel Z Leibo is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="REMI MUNOS">
      <data key="d0">PERSON</data>
      <data key="d1">Remi Munos is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHARLES BLUNDELL">
      <data key="d0">PERSON</data>
      <data key="d1">Charles Blundell is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DHARSHAN KUMARAN">
      <data key="d0">PERSON</data>
      <data key="d1">Dharshan Kumaran is a researcher who co-authored a paper on learning to reinforcement learn.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATT BOTVINICK">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Botvinick is a researcher who co-authored a paper on learning to reinforcement learn.
Matt Botvinick is a researcher recognized for his work in reinforcement learning and cognitive science.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LEI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Lei Wang is a researcher who co-authored a survey on large language model-based autonomous agents.
Lei Wang is a researcher who has contributed to the study of large language model-based autonomous agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHEN MA">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Ma is a researcher who co-authored a survey on large language model-based autonomous agents.
Chen Ma is a researcher involved in the survey of large language model-based autonomous agents.
Chen Ma is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ZEYU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zeyu Zhang is a researcher who co-authored a survey on large language model-based autonomous agents.
Zeyu Zhang is a researcher contributing to the field of large language model-based autonomous agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HAO YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Yang is a researcher who co-authored a survey on large language model-based autonomous agents.
Hao Yang is a researcher involved in the study of large language model-based autonomous agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JINGSEN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jingsen Zhang is a researcher who co-authored a survey on large language model-based autonomous agents.
Jingsen Zhang is a researcher contributing to the field of large language model-based autonomous agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZHIYUAN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Chen is a researcher who co-authored a survey on large language model-based autonomous agents.
Zhiyuan Chen is a researcher involved in the survey of large language model-based autonomous agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="(&quot;ENTITY&quot;">
      <data key="d0">TOOL LEARNING WITH LARGE LANGUAGE MODELS</data>
      <data key="d1">RESEARCH
</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AUTOGPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">AutoGPT is a tool developed to automate tasks using large language models, available as a GitHub repository.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATHEMATICAL DISCOVERIES FROM PROGRAM SEARCH">
      <data key="d0">RESEARCH</data>
      <data key="d1">This research discusses the mathematical insights gained from using large language models in program search.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TOOLFORMER">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Toolformer is a framework that allows language models to learn how to use tools effectively.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="PROMPT REPORT">
      <data key="d0">RESEARCH</data>
      <data key="d1">The prompt report is a systematic survey that analyzes various prompting techniques used in language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DEEPMAD">
      <data key="d0">RESEARCH</data>
      <data key="d1">Deepmad is a study focused on the mathematical architecture design for deep convolutional neural networks.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LANGUAGE AGENTS WITH VERBAL REINFORCEMENT LEARNING">
      <data key="d0">RESEARCH</data>
      <data key="d1">This research explores the development of language agents that utilize verbal reinforcement learning techniques.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LEARNING TO REINFORCEMENT LEARN">
      <data key="d0">RESEARCH</data>
      <data key="d1">Learning to reinforcement learn is a study that investigates methods for improving reinforcement learning algorithms.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d0">RESEARCH</data>
      <data key="d1">This survey focuses on the development and capabilities of autonomous agents that utilize large language models.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TOOL LEARNING WITH LARGE LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SHAN KUMARAN">
      <data key="d0">PERSON</data>
      <data key="d1">Shan Kumaran is a researcher known for contributions in the field of reinforcement learning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="XUEYANG FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xueyang Feng is a researcher who has worked on large language model-based autonomous agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JIAKAI TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiakai Tang is a researcher contributing to the field of large language model-based autonomous agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="XU CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xu Chen is a researcher involved in the study of large language model-based autonomous agents.
Xu Chen is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RUI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Rui Wang is a researcher known for work on open-ended coevolution in reinforcement learning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="KENNETH O. STANLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Kenneth O. Stanley is a researcher known for his work in evolutionary algorithms and reinforcement learning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="QUOC V LE">
      <data key="d0">PERSON</data>
      <data key="d1">Quoc V Le is a researcher known for his work in machine learning and language models.
Quoc V Le is a researcher who co-authored a paper on self-discovery in large language models.Quoc V Le is a researcher who co-authored a paper on reasoning via abstraction in large language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ED H. CHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ed H. Chi is a researcher involved in the study of language models and their applications.
Ed H. Chi is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QINGYUN WU">
      <data key="d0">PERSON</data>
      <data key="d1">Qingyun Wu is a researcher involved in multi-agent conversation frameworks.
Qingyun Wu is a researcher who co-authored a paper on offline training of language model agents.
Qingyun Wu is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="GAGAN BANSAL">
      <data key="d0">PERSON</data>
      <data key="d1">Gagan Bansal is a researcher contributing to advancements in language model applications.
Gagan Bansal is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIEYU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jieyu Zhang is a researcher involved in robotic skill synthesis using language models.
Jieyu Zhang is a researcher who co-authored a paper on offline training of language model agents.
Jieyu Zhang is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIRAN WU">
      <data key="d0">PERSON</data>
      <data key="d1">Yiran Wu is a researcher contributing to advancements in language model applications.
Yiran Wu is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SHAOKUN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shaokun Zhang is a researcher involved in multi-agent generation via evolutionary algorithms.
Shaokun Zhang is a researcher who co-authored a paper on offline training of language model agents.
Shaokun Zhang is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ELIEZER YUDKOWSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Eliezer Yudkowsky is a researcher known for his work on AI and global risks.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="MATEI ZAHARIA">
      <data key="d0">PERSON</data>
      <data key="d1">Matei Zaharia is a researcher involved in the development of compound AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="OMNI">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">OMNI is a system designed to explore open-endedness through models of human notions of interestingness.
OMNI is a research project focused on open-endedness via models of human notions of interestingness.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="AUTOGEN">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Autogen is a framework enabling next-generation applications of large language models through multi-agent conversations.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JIALE ZHI">
      <data key="d0">PERSON</data>
      <data key="d1">Jiale Zhi is a researcher involved in the study of enhanced open-ended reinforcement learning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YULUN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yulun Li is a researcher contributing to advancements in open-ended reinforcement learning.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NIMROD GILEADI">
      <data key="d0">PERSON</data>
      <data key="d1">Nimrod Gileadi is a researcher involved in the development of language model applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SEAN KIRMANI">
      <data key="d0">PERSON</data>
      <data key="d1">Sean Kirmani is a researcher involved in the study of language models and their applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="MONTSERRAT GONZALEZ ARENAS">
      <data key="d0">PERSON</data>
      <data key="d1">Montserrat Gonzalez Arenas is a researcher involved in language model applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="HAO-TIEN LEWIS CHIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Hao-Tien Lewis Chiang is a researcher contributing to advancements in language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="TOM EREZ">
      <data key="d0">PERSON</data>
      <data key="d1">Tom Erez is a researcher involved in the study of language models and their applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LEONARD HASENCLEVER">
      <data key="d0">PERSON</data>
      <data key="d1">Leonard Hasenclever is a researcher contributing to advancements in language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JAN HUMPLIK">
      <data key="d0">PERSON</data>
      <data key="d1">Jan Humplik is a researcher involved in the development of language model applications.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="BENFENG XU">
      <data key="d0">PERSON</data>
      <data key="d1">Benfeng Xu is a researcher contributing to advancements in agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="AN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">An Yang is a researcher involved in the study of agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JUNYANG LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Junyang Lin is a researcher contributing to advancements in agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="QUAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Quan Wang is a researcher involved in the study of agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHANG ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Chang Zhou is a researcher contributing to advancements in agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YONGDONG ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yongdong Zhang is a researcher involved in the study of agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ZHENDONG MAO">
      <data key="d0">PERSON</data>
      <data key="d1">Zhendong Mao is a researcher contributing to advancements in agentic systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NICHOLAS FULLAGAR">
      <data key="d0">PERSON</data>
      <data key="d1">Nicholas Fullagar is a researcher contributing to advancements in AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="GREGORY DARDYK">
      <data key="d0">PERSON</data>
      <data key="d1">Gregory Dardyk is a researcher involved in the study of AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="J BRADLEY CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">J Bradley Chen is a researcher contributing to advancements in AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ROBERT MUTH">
      <data key="d0">PERSON</data>
      <data key="d1">Robert Muth is a researcher involved in the study of AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="TAVIS ORMANDY">
      <data key="d0">PERSON</data>
      <data key="d1">Tavis Ormandy is a researcher contributing to advancements in AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SHIKI OKASAKA">
      <data key="d0">PERSON</data>
      <data key="d1">Shiki Okasaka is a researcher involved in the study of AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NEHA NARULA">
      <data key="d0">PERSON</data>
      <data key="d1">Neha Narula is a researcher contributing to advancements in AI systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ADITYA RAWAL">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="KENNETH STANLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Kenneth Stanley is a researcher who co-authored a paper on open-endedness in models of human notions of interestingness.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIALE LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Jiale Liu is a researcher who co-authored a paper on offline training of language model agents.
Jiale Liu is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LINXIN SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Linxin Song is a researcher who co-authored a paper on offline training of language model agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="CHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chi Wang is a researcher who co-authored a paper on offline training of language model agents.
Chi Wang is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RANJAY KRISHNA">
      <data key="d0">PERSON</data>
      <data key="d1">Ranjay Krishna is a researcher who co-authored a paper on offline training of language model agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="MEMORY MECHANISM">
      <data key="d0">RESEARCH</data>
      <data key="d1">The memory mechanism refers to the methods and structures used in large language model-based agents to manage and utilize memory.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ZEU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Zeyu Zhang is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIAOHE BO">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaohe Bo is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RUI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Rui Li is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="QUANYU DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Quanyu Dai is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIEMING ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Jieming Zhu is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ZHENHUA DONG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhenhua Dong is a researcher who co-authored a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="HENG-TZE CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Heng-Tze Cheng is a researcher who co-authored a paper on self-discovery in large language models.Heng-Tze Cheng is a researcher who co-authored a paper on reasoning via abstraction in large language models.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ED H CHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ed H Chi is a researcher who co-authored a paper on reasoning via abstraction in large language models.Ed H Chi is a researcher who co-authored a paper on self-discovery in large language models.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PEI ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Pei Zhou is a researcher who co-authored a paper on self-discovery in large language models.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JAY PUJARA">
      <data key="d0">PERSON</data>
      <data key="d1">Jay Pujara is a researcher who co-authored a paper on self-discovery in large language models.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIANG REN">
      <data key="d0">PERSON</data>
      <data key="d1">Xiang Ren is a researcher who co-authored a paper on self-discovery in large language models.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WANGCHUNSHU ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Wangchunshu Zhou is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="YIXIN OU">
      <data key="d0">PERSON</data>
      <data key="d1">Yixin Ou is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHENGWEI DING">
      <data key="d0">PERSON</data>
      <data key="d1">Shengwei Ding is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LONG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Long Li is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIALONG WU">
      <data key="d0">PERSON</data>
      <data key="d1">Jialong Wu is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="TIANNAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Tiannan Wang is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIAMIN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jiamin Chen is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHUAI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shuai Wang is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIAOHUA XU">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaohua Xu is a researcher who co-authored a paper on symbolic learning for self-evolving agents.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="MINGCHEN ZHUGE">
      <data key="d0">PERSON</data>
      <data key="d1">Mingchen Zhuge is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WENYI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Wenyi Wang is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LOUIS KIRSCH">
      <data key="d0">PERSON</data>
      <data key="d1">Louis Kirsch is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FRANCESCO FACCIO">
      <data key="d0">PERSON</data>
      <data key="d1">Francesco Faccio is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DMITRII KHIZBULLIN">
      <data key="d0">PERSON</data>
      <data key="d1">Dmitrii Khizbullin is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J&#220;RGEN SCHMIDHUBER">
      <data key="d0">PERSON</data>
      <data key="d1">J&#252;rgen Schmidhuber is a researcher who co-authored a paper on language agents as optimizable graphs.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VARIBAD">
      <data key="d0">RESEARCH</data>
      <data key="d1">Varibad is a research project focused on variational Bayes-adaptive deep reinforcement learning via meta-learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">RESEARCH</data>
    </node>
    <node id="LUISA ZINTGRAF">
      <data key="d0">PERSON</data>
      <data key="d1">Luisa Zintgraf is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SEBASTIAN SCHULZE">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Schulze is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEO FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Leo Feng is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAXIMILIAN IGL">
      <data key="d0">PERSON</data>
      <data key="d1">Maximilian Igl is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KYRIACOS SHIARLIS">
      <data key="d0">PERSON</data>
      <data key="d1">Kyriacos Shiarlis is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YARIN GAL">
      <data key="d0">PERSON</data>
      <data key="d1">Yarin Gal is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.
Yarin Gal is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KATJA HOFMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Katja Hofmann is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHIMON WHITESON">
      <data key="d0">PERSON</data>
      <data key="d1">Shimon Whiteson is a researcher who co-authored a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OFFLINE TRAINING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SELF-DISCOVERY">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SELF(&quot;ENTITY&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LANGUAGE AGENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="META AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The meta agent is a system designed to generate code and improve its quality through self-reflection and iterative design processes.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="OUTPUT INSTRUCTION">
      <data key="d0">PROCESS</data>
      <data key="d1">Output instruction refers to the guidelines provided for formatting the output of the meta agent, including keys like "thought," "name," and "code."</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="AGENT ARCHITECTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Agent architecture is the design framework for creating agents, detailing their structure and functionality.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FORWARD FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">The forward function is a specific implementation in Python that defines how the agent processes input and generates output.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPLEMENTATION MISTAKES">
      <data key="d0">ERROR TYPE</data>
      <data key="d1">Implementation mistakes refer to errors made during the coding process that need to be identified and corrected.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPROVEMENT SUGGESTIONS">
      <data key="d0">PROCESS</data>
      <data key="d1">Improvement suggestions are recommendations made to enhance the performance or effectiveness of the agent's implementation.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="RUNTIME ERROR">
      <data key="d0">ERROR TYPE</data>
      <data key="d1">A runtime error is an error that occurs during the execution of the code, prompting the need for debugging and reflection.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FRAMEWORK CODE">
      <data key="d0">CODE</data>
      <data key="d1">Framework code is the foundational code provided to the meta agent, enabling it to perform basic functions like querying and formatting prompts.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="NAMEDTUPLE INFO OBJECT">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The namedtuple Info object is a data structure used to encapsulate various types of information for easy communication between modules.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="PROMPT">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">A prompt is a specific instruction given to the meta agent to guide its output and reasoning process.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="EXAMPLES OF POTENTIAL MISTAKES">
      <data key="d0">ERROR TYPE</data>
      <data key="d1">Examples of potential mistakes are instances of incorrect implementations that the meta agent may encounter during its coding process.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="DEBUG_THOUGHT">
      <data key="d0">PROCESS</data>
      <data key="d1">Debug_thought is a reflective process where the meta agent analyzes its code to identify and fix errors during execution.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="APPENDICES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FM MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The FM Module is a base class designed for managing the functionality of a framework module, including attributes like output fields, name, role, model, temperature, and a unique identifier.
FM Module refers to a functional module used in the agents for processing tasks and providing solutions.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="INFO">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Info is a named tuple that holds task information, including attributes such as name, author, content, and iteration index.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="AGENT SYSTEM">
      <data key="d0">SYSTEM</data>
      <data key="d1">The Agent System is a framework component that processes task information and is designed to implement functionalities like self-reflection.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="JSON RESPONSE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The JSON response is a structured output format returned by the FM module after processing a user message through a model.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="GPT MODEL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The GPT model is a generative pre-trained transformer model used for generating text responses based on input messages.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="BACKOFF">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Backoff is a technique used to handle exceptions, specifically for managing rate limit errors when querying the GPT model.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Chain-of-Thought (COT) instruction is a directive for the model to think step by step before solving a task.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="OUTPUT FIELDS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Output fields are the expected fields in the output generated by the FM Module, defining the structure of the response.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="SYSTEM MESSAGE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The system message is a directive provided to the GPT model that sets the context for generating responses.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="ITERATION INDEX">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The iteration index is a numerical identifier used to track the iteration of a task within the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="RESPONSE">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Response refers to the output generated by the FM Module or Agent System after processing input information and instructions.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TASK INFORMATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_REFLECT_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">The cot_reflect_instruction is a directive for the system to consider previous attempts and feedback to improve the current task solution.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="COT_MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The cot_module is a functional module that processes inputs related to thinking and answering, utilizing a chain-of-thought approach.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="CRITIC_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">The critic_instruction is a directive for the system to review and critique the answer provided, determining its correctness.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="CRITIC_MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The critic_module is a functional module that provides feedback and correctness status on the answers generated by the system.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="N_MAX">
      <data key="d0">PARAMETER</data>
      <data key="d1">N_max is a parameter that defines the maximum number of attempts the system can make to solve a task.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="COT_INPUTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">COT_inputs are the inputs provided to the cot_module for processing, including task information and previous feedback.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="ARC_CHALLENGE">
      <data key="d0">CHALLENGE</data>
      <data key="d1">The ARC (Abstraction and Reasoning Corpus) challenge is a task that involves predicting outputs based on transformation rules applied to input grids.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="EXAMPLE_INPUT_OUTPUT_GRID">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Example input-output grids are paired examples used in the ARC challenge to demonstrate the transformation rules.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="TEST_GRID">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The test grid is an input grid provided in the ARC challenge for which the output is unknown and needs to be predicted.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="GTP-4O-2024-05-13">
      <data key="d0">MODEL</data>
      <data key="d1">GPT-4O-2024-05-13 is a version of the GPT model used by the meta agent in the ARC challenge for generating solutions.
GPT-4O-2024-05-13 is a version of the GPT model used for evaluations in the meta agent context.
GPT-4O-2024-05-13 is a version of the GPT-4 model used by the meta agent for processing.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="GPT-3.5-TURBO-0125">
      <data key="d0">MODEL</data>
      <data key="d1">GPT-3.5-Turbo-0125 is a version of the GPT model used for evaluating discovered agents and baselines in the ARC challenge.
GPT-3.5-Turbo-0125 is a version of the GPT model used for evaluating discovered agents and baselines.
GPT-3.5-Turbo-0125 is a version of the GPT-3.5 model used for evaluating discovered agents and baselines.
GPT-3.5-turbo-0125 is a language model developed by OpenAI, used for various tasks including reasoning and problem-solving.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="CORRECT">
      <data key="d0">STATUS</data>
      <data key="d1">Correct is a status indicating whether the answer generated by the system is accurate, as determined by the critic_module.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="INPUT_GRID">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Input_grid is a rectangular matrix of integers representing the initial state in the ARC challenge, from which transformation rules are derived.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="OUTPUT_GRID">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Output_grid is a rectangular matrix of integers representing the expected result after applying transformation rules to the input grid in the ARC challenge.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="TRANSFORMATION_RULE">
      <data key="d0">RULE</data>
      <data key="d1">Transformation_rule refers to the logic or method applied to the input grid to derive the output grid in the ARC challenge.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="TASK_INFO">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="STRUCTURED FEEDBACK AND ENSEMBLE AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">The Structured Feedback and Ensemble Agent is a specific AI agent developed to generate solutions through structured feedback mechanisms.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="FM_MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">FM_Module refers to a functional module used within the agent to generate candidate solutions based on given instructions.
FM Module refers to a framework or module used for processing thoughts and feedback in various roles, such as human-like feedback and expert evaluation.
FM_Module is a modular framework used for processing tasks, including decomposition, integration, and specialized problem-solving.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="TASKINFO">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">TaskInfo is the input data structure that contains information about the task to be solved by the agent.
TaskInfo is the contextual information or parameters related to the specific task being evaluated or solved.
</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="CORRECT EXAMPLES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Correct examples are instances where the generated solutions successfully meet the task requirements, used to assess the performance of the agent.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="WRONG EXAMPLES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Wrong examples are instances where the generated solutions fail to meet the task requirements, providing insights into the agent's shortcomings.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="INITIAL CANDIDATE SOLUTIONS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="HUMAN-LIKE FEEDBACK MODULE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Human-Like Feedback Module is a component designed to simulate human feedback for code solutions, focusing on common mistakes and best practices.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="INITIAL_SOLUTIONS">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Initial Solutions is a collection of candidate solutions that have been generated and are awaiting evaluation and feedback.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT ADVISORS">
      <data key="d0">ROLE</data>
      <data key="d1">Expert Advisors are specialized roles assigned to evaluate code solutions and provide targeted feedback for improvement.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINEMENT MODULE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Refinement Module is a component that iteratively refines solutions based on structured feedback to enhance performance.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL DECISION MODULE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Final Decision Module is a component that synthesizes the best-performing solutions to make a final decision on the code.
Final Decision Module is a component that synthesizes the outputs from various agents to arrive at a final answer.</data>
      <data key="d2">84317ae35cc75d612287186d93461447,97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="CORRECT_EXAMPLES">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Correct Examples are instances of solutions that have successfully passed evaluation criteria, indicating their correctness.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="WRONG_EXAMPLES">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">Wrong Examples are instances of solutions that failed to meet evaluation criteria, highlighting areas for improvement.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="LLM-DEBATE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">LLM-Debate is a hand-designed agent baseline for reasoning tasks.
LLM-Debate is a method where debate modules are assigned roles and engage in discussions to arrive at a solution.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="INDIANS">
      <data key="d0">NATIONALITY</data>
      <data key="d1">Indians are a nationality represented in Bahrain, with a population of approximately 290,000 according to reports from 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="BANGLADESHIS">
      <data key="d0">NATIONALITY</data>
      <data key="d1">Bangladeshis are a nationality represented in Bahrain, with a population of approximately 125,000 according to reports from 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PAKISTANIS">
      <data key="d0">NATIONALITY</data>
      <data key="d1">Pakistanis are a nationality represented in Bahrain, with a population of approximately 45,000 according to reports from 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="FILIPINOS">
      <data key="d0">NATIONALITY</data>
      <data key="d1">Filipinos are a nationality represented in Bahrain, with a population of approximately 45,000 according to reports from 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="INDONESIANS">
      <data key="d0">NATIONALITY</data>
      <data key="d1">Indonesians are a nationality represented in Bahrain, with a population of approximately 8,000 according to reports from 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="BAHRAIN">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CRITIC MODULE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Critic Module is a component used in the agents to provide feedback and evaluate the correctness of answers.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="TASK INFO">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Task Info represents the information or context provided to the agents for processing and problem-solving.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="FM QUERY">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="DECOMPOSITION MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The Decomposition Module is responsible for breaking down complex problems into manageable sub-problems for further analysis.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SPECIALIZED EXPERTS">
      <data key="d0">ROLE</data>
      <data key="d1">Specialized Experts are designated roles within the framework, each focusing on specific domains such as Physics, Chemistry, and Biology to solve sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INTEGRATION MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The Integration Module combines the solutions of sub-problems into a final answer, ensuring coherence and completeness.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB-PROBLEMS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Sub-problems are the individual components derived from a larger problem, which are addressed by specialized experts.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB-SOLUTIONS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Sub-solutions are the answers generated by specialized experts for each sub-problem.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL REPRESENTATION MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The Visual Representation Module creates visual aids, such as diagrams or graphs, to assist in problem-solving.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VERIFICATION MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The Verification Module checks the accuracy and relevance of visual representations, providing feedback for improvement.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="CHAIN-OF-THOUGHT MODULE">
      <data key="d0">MODULE</data>
      <data key="d1">The Chain-of-Thought Module facilitates step-by-step reasoning to solve problems using verified visual aids.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="DECOMPOSITION INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Decomposition Instruction is a directive given to the Decomposition Module to guide the breakdown of a problem into sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INTEGRATION INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Integration Instruction is a directive given to the Integration Module to guide the combination of sub-solutions into a final answer.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB-PROBLEM">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A Sub-Problem is an individual component of a larger problem that requires specialized attention for resolution.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB-PROBLEM INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">Sub-Problem Instruction is a directive given to specialized experts to guide them in solving their assigned sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="AGENTINSTRUCT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">AgentInstruct is an extensible agentic framework designed for automatically creating large amounts of diverse and high-quality synthetic data for language models.
AgentInstruct is an agentic solution for Generative Teaching, focusing on creating demonstration and feedback data using raw documents as input.
A methodology used to curate a large dataset of instructions aimed at teaching various skills.
AgentInstruct is a dataset aimed at synthesizing a large and diverse corpus of data with varying degrees of difficulty for training AI models.
AgentInstruct is a method used to enhance the proficiency of AI models across various tasks, including math problem-solving and format-following.

AgentInstruct is a method used to fine-tune language models, enabling them to generate high-quality synthetic data.
AgentInstruct is an approach to Generative Teaching that utilizes agentic flows for generating diverse and high-quality synthetic data for model training.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SYNTHETIC DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Synthetic data refers to artificially generated data used to train language models, which can vary in quality and diversity.
Synthetic data is artificially generated data used for training models, which can help in creating tailored datasets for various applications.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MISTRAL-7B">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-7B is a base language model that was post-trained using synthetic data generated by AgentInstruct.
Mistral-7B is a base model that is fine-tuned using synthetic datasets created by AgentInstruct.
Mistral-7B is a language model that has been fine-tuned for specific tasks and evaluated on the MIRAGE datasets.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="ORCA-3">
      <data key="d0">MODEL</data>
      <data key="d1">Orca-3 is the resulting model from post-training Mistral-7B with synthetic data, showing significant improvements in performance.
Orca-3 is the finetuned version of the Mistral-7B model, showing significant improvements in various benchmarks.
A machine learning model trained using a dataset of approximately 25.8 million paired instructions for various capabilities.
Orca-3 is an AI model that is evaluated against several baseline models in the Orca-Bench dataset.

Orca-3 is a 7B model that has shown significant improvements in performance over previous models like Orca 2.5 and Mistral-7B-Instruct, particularly in reading comprehension and math problem-solving tasks.

Orca-3 is a language model that has shown improved performance when post-trained with a dataset generated by the AgentInstruct approach.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LLAMA-8B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">LLAMA-8B-Instruct is another language model that is compared against Orca-3 in terms of performance.
LLAMA-8B-instruct is another model used for comparison in the evaluation of instruction-tuned models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="AGIEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">AGIEval is a benchmark used to evaluate the performance of language models.
AGIEval is a benchmark used to assess the performance of instruction-tuned models.
AGIEval is a human-centric benchmark that assesses a model's performance in tasks related to human cognition and problem-solving, including standardized exams.
AGIEval is a benchmark used to evaluate the performance of AI models on reading comprehension and math tasks, providing comparative scores across different models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="BBH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">BBH is a benchmark used to measure the performance of language models in specific tasks.
BBH is a benchmark used to assess the performance of language models in various tasks.
Big Bench Hard (BBH) is a benchmark consisting of tasks that require complex, multi-step reasoning across various academic subjects.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="ALPACA EVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">AlpacaEval is a benchmark used to evaluate the performance of language models in instruction-following tasks.
AlpacaEval is a benchmark used to evaluate the performance of instruction-tuned models.
AlpacaEval is a benchmark for chat-based language models to evaluate their instruction-following abilities in single-turn interactions.
Alpaca Eval is an automatic evaluator designed to assess instruction-following models.
AlpacaEval measures win-rates of model outputs compared to reference answers.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="POST-TRAINING">
      <data key="d0">PROCESS</data>
      <data key="d1">Post-training is a phase in the model training process where additional training is conducted using specific datasets to enhance model performance.
Post-training refers to the phase in model development where additional training is conducted after the initial training to improve performance.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="INSTRUCTION TUNING">
      <data key="d0">PROCESS</data>
      <data key="d1">Instruction tuning is a process that involves refining a language model's ability to follow instructions by training it on specific datasets.
</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="RLHF">
      <data key="d0">PROCESS</data>
      <data key="d1">Reinforcement Learning from Human Feedback (RLHF) is a training method that incorporates human feedback to improve model performance.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MULTI-AGENT WORKFLOWS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Multi-agent workflows involve multiple agents working together to generate high-quality data and improve the capabilities of language models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="REFLECTION AND ITERATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Reflection and iteration are processes used in agentic workflows where agents review and improve their outputs based on previous results.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="DATA GENERATION WORKFLOWS">
      <data key="d0">PROCESS</data>
      <data key="d1">Data generation workflows are structured processes for creating datasets, often involving automation to reduce human intervention.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MODEL COLLAPSE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Model collapse refers to the phenomenon where a model's performance degrades over time, often due to training on low-quality synthetic data.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SEEDS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Seeds are initial data points or prompts used to generate further instructions or responses in the synthetic data generation process.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="TEXT DOCUMENTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Text documents are raw data sources used as seeds for generating synthetic data in the AgentInstruct framework.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CODE FILES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Code files are raw data sources used as seeds for generating synthetic data in the AgentInstruct framework.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="GENERATIVE TEACHING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Generative Teaching is a methodology aimed at generating diverse, challenging, and high-quality synthetic data to teach specific skills to AI models.
Generative Teaching is an approach aimed at teaching skills rather than merely generating data to meet benchmarks, focusing on effective learning outcomes.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="SYNTHETIC DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The synthetic dataset created by AgentInstruct consists of 25 million prompt and response pairs covering a wide array of skills.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="AGENTIC FLOWS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Agentic flows are automated processes that facilitate the generation of synthetic data by leveraging raw materials and various agents.
Agentic flows are automated processes that facilitate the generation of diverse data by leveraging raw articles as seeds for problem generation.
Agentic Flows refers to a set of transformation agents designed for reading comprehension tasks.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,f4e98ee0b7fb42428f3312f29cb444dd,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CONTENT TRANSFORMATION AGENTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Content Transformation Agents are tools used in the AgentInstruct methodology to transform raw seeds into diverse instructions.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="INSTRUCTION CREATION AGENTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Instruction Creation Agents are components of the AgentInstruct methodology that generate a diverse set of instructions from transformed seeds.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="REFINEMENT AGENTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Refinement Agents are used in the AgentInstruct methodology to iteratively improve the complexity and quality of generated instructions.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="DIVERSE DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Diverse data refers to the variety of synthetic data generated by AgentInstruct, ensuring broad coverage and complexity.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="HIGH-QUALITY DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">High-quality data is the result of using powerful models and agentic flows to generate effective synthetic datasets.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="RAW DOCUMENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="RAW ARTICLES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Raw articles are unprocessed texts used as seeds in the agentic flows to foster diversity in generated problems.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CONTENT TRANSFORMATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">Content Transformation Flow is a method that converts raw seeds into an intermediate representation to simplify the creation of tailored instructions.
Content Transformation Flow is a method for transforming arbitrary articles into structured pieces that facilitate the generation of diverse reading comprehension questions.
The Content Transformation Flow is a process that synthesizes API descriptions or lists from source code snippets or other inputs.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTION GENERATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">Seed Instruction Generation Flow generates diverse instructions based on transformed content, following a comprehensive taxonomy.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INSTRUCTION REFINEMENT FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">Instruction Refinement Flow iteratively enhances the quality, diversity, and complexity of instructions generated from the Seed Instruction Flow.
The Instruction Refinement Flow is a process that enhances the complexity of generated instructions based on input text and task modification instructions.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SUGGESTER-EDITOR AGENTS">
      <data key="d0">AGENT</data>
      <data key="d1">Suggester-Editor Agents are specialized agents that propose and modify instructions to increase their complexity and quality.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SKILLS">
      <data key="d0">CATEGORY</data>
      <data key="d1">Skills refer to various competencies such as reading comprehension, question answering, and coding, each having multiple subcategories.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="READING COMPREHENSION">
      <data key="d0">SKILL</data>
      <data key="d1">Reading comprehension is the ability to understand and interpret written text, essential for learning and involves decoding, fluency, and vocabulary knowledge.
Reading comprehension is the ability to process and understand text, involving skills such as decoding, fluency, and vocabulary knowledge.
</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,cc20c99cad8edecc66b82ac751ff7172,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT MODIFICATION">
      <data key="d0">SKILL</data>
      <data key="d1">Text modification is the process of altering text to improve its quality or fit a specific context, commonly used in content creation and editing.
Text modification involves editing and refining written content to improve clarity, flow, and effectiveness, often using automated agents.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d0">SKILL</data>
      <data key="d1">Open domain question answering is the ability to generate responses to questions across a wide range of topics without domain restrictions.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="WEB AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">A web agent is a software program that autonomously performs tasks on the web, such as navigation and interaction with web elements.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="BRAIN TEASER">
      <data key="d0">TASK</data>
      <data key="d1">A brain teaser is a problem or puzzle that requires thought to solve, often used for amusement or to train logical thinking skills.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ANALYTICAL REASONING">
      <data key="d0">SKILL</data>
      <data key="d1">Analytical reasoning involves discerning patterns within qualitative or quantitative information to draw logical conclusions.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MULTIPLE CHOICE QUESTIONS">
      <data key="d0">ASSESSMENT</data>
      <data key="d1">Multiple choice questions are a form of assessment where respondents select the best answer from a list of options.
Multiple choice questions are a common assessment format that presents respondents with several options to choose from.Multiple choice questions evaluate models in an open-ended generation setting.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="DATA TO TEXT">
      <data key="d0">PROCESS</data>
      <data key="d1">Data-to-text refers to generating human-readable textual summaries from structured data for reports or narratives.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="FERMI PROBLEMS">
      <data key="d0">TASK</data>
      <data key="d1">Fermi problems are estimation challenges that require making justified guesses to arrive at rough solutions for difficult-to-measure quantities.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CODING">
      <data key="d0">SKILL</data>
      <data key="d1">Coding involves writing, understanding, debugging, and testing code based on given instructions.
Coding involves writing code according to instructions, understanding and debugging code, and tracing or writing test cases.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT EXTRACTION">
      <data key="d0">PROCESS</data>
      <data key="d1">Text extraction is the process of retrieving relevant information from larger text documents, including tasks like named entity recognition.
Text extraction is the process of retrieving relevant information from larger text documents, including tasks like named entity recognition and keyword extraction.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SKILL">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ASSESSMENT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="PROCESS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TRANSFORMED CONTENT">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Transformed content refers to the output generated from the Content Transformation Flow, which simplifies the creation of instructions tailored to specific objectives.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INTERMEDIATE REPRESENTATION">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Intermediate representation is a simplified version of the raw seed that facilitates the creation of tailored instructions in the Content Transformation Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="COMPREHENSIVE TAXONOMY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Comprehensive taxonomy is a structured classification system used to guide the generation of instructions in the Seed Instruction Generation Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ITERATIVE PROCESS">
      <data key="d0">PROCESS</data>
      <data key="d1">Iterative process refers to the method of refining instructions through repeated cycles to enhance their quality and complexity in the Instruction Refinement Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="OUTPUTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Outputs refer to the results generated from the workflows, including instructions and data summaries.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="PROBLEM GENERATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Problem generation is the process of creating distinct and diverse problems through the use of agentic flows and raw articles as seeds.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INSTRUCTION CREATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Instruction creation is the process of developing specific directives or tasks based on transformed content in the workflows.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTION FLOW">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ENRICO FERMI">
      <data key="d0">PERSON</data>
      <data key="d1">Enrico Fermi was a physicist known for his contributions to nuclear physics and for the development of the Fermi problem, which involves making rough estimates of quantities that are difficult to measure.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="TEXT CLASSIFICATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Text classification is a machine learning task where text documents are automatically categorized into predefined categories, such as spam detection and sentiment analysis.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="RETRIEVAL AUGMENTED GENERATION (RAG)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Retrieval Augmented Generation (RAG) is a method in natural language processing that combines retrieval-based and generative models to generate responses based on retrieved documents.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CREATIVE CONTENT GENERATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Creative content generation involves creating original content, such as text, music, or images, that is novel, valuable, and meaningful.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FEW SHOT REASONING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Few-shot reasoning is the ability of a machine learning model to understand new concepts or tasks with minimal examples, mimicking human learning.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CONVERSATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Conversation refers to the interaction of conversational agents or chatbots with humans in a natural, human-like manner.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="HYPERURICEMIA">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Hyperuricemia is a condition characterized by high levels of uric acid in the blood, which can increase the risk of cardiovascular disease and result from various dietary and lifestyle factors.
Hyperuricemia is a condition characterized by elevated levels of uric acid in the blood, which can increase the risk of cardiovascular disease.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PURINE">
      <data key="d0">COMPOUND</data>
      <data key="d1">Purine is a type of dietary protein that, when broken down, produces uric acid, which can lead to health complications if present in excess.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FERMI PROBLEM">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="ARGUMENT PASSAGE GENERATOR">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Argument Passage Generator is a specific tool within the Content Transformation Flow that creates argumentative text passages for reading comprehension tasks.
The Argument Passage Generator is an agent that creates passages articulating arguments, sometimes with logical inconsistencies.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LSAT LOGICAL REASONING">
      <data key="d0">TEST</data>
      <data key="d1">The LSAT Logical Reasoning test features specialized question categories designed to evaluate critical thinking and reasoning skills in prospective law students.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CARDIOVASCULAR DISEASE">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Cardiovascular disease refers to a range of conditions affecting the heart and blood vessels, often associated with high uric acid levels and other risk factors.
Cardiovascular disease refers to a range of conditions affecting the heart and blood vessels, often associated with high uric acid levels.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPURICEMIA">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Hypouricemia is a condition characterized by low levels of uric acid in the blood, which can indicate underlying health issues but is less common than hyperuricemia.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="URIC ACID">
      <data key="d0">COMPOUND</data>
      <data key="d1">Uric acid is a byproduct of purine metabolism in the body, and its levels can indicate various health conditions, including hyperuricemia and hypouricemia.
Uric acid is a waste product formed from the breakdown of purines, and its levels in the blood can indicate various health conditions, including cardiovascular disease and kidney issues.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="AGENTINSTRUCT FLOWS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="HYPOURICEMIA">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Hypouricemia is a condition with low levels of uric acid in the blood, often without symptoms, but may indicate underlying health issues.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LABORATORY TESTS">
      <data key="d0">PROCEDURE</data>
      <data key="d1">Laboratory blood and urine tests are diagnostic procedures used to measure uric acid levels and assess kidney and liver function.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="READING COMPREHENSION QUESTIONS">
      <data key="d0">EDUCATIONAL TOOL</data>
      <data key="d1">Reading comprehension questions are designed to assess understanding of a text, including various types such as literal, critical, and evaluative questions.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PASSAGE-QUESTION PAIRS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Passage-question pairs are combinations of text excerpts and corresponding questions used for comprehension assessment.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PARAPHRASING AGENT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The paraphrasing agent is a specific type of automated system that rewrites text to convey the same meaning in different words.
</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="PHYSICAL INACTIVITY">
      <data key="d0">LIFESTYLE CHOICE</data>
      <data key="d1">Physical inactivity is a lifestyle choice characterized by a lack of sufficient physical activity, which can affect overall health and uric acid levels.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="KIDNEY ISSUES">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Kidney issues refer to various health problems affecting kidney function, which can be indicated by low uric acid levels.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LIVER ISSUES">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Liver issues encompass a range of conditions affecting liver function, which may also be indicated by low uric acid levels.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CROSS-SECTIONAL STUDY">
      <data key="d0">RESEARCH METHOD</data>
      <data key="d1">A cross-sectional study is a type of observational research that analyzes data from a population at a specific point in time, often used to assess relationships between variables.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPERTENSION">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Hypertension, or high blood pressure, is a medical condition that can be associated with cardiovascular disease and other health issues.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="DIABETES">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Diabetes is a chronic medical condition that affects how the body processes blood sugar (glucose) and can be linked to cardiovascular disease.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPERURICEMIA AND CARDIOVASCULAR DISEASE RELATIONSHIP">
      <data key="d0">RESEARCH FINDING</data>
      <data key="d1">The relationship between hyperuricemia and cardiovascular disease is a subject of research, exploring how elevated uric acid levels may contribute to heart-related health risks.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="DISTRATOR OPTION">
      <data key="d0">EDUCATIONAL TOOL</data>
      <data key="d1">A distractor option is a choice in a multiple-choice question designed to mislead or confuse the test-taker, testing their understanding of the material.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="GENETIC PREDISPOSITION">
      <data key="d0">BIOLOGICAL FACTOR</data>
      <data key="d1">Genetic predisposition refers to the increased likelihood of developing certain health conditions based on one's genetic makeup, which can influence uric acid levels and cardiovascular health.)&lt;|COMPLETE|&gt;</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="FINANCIALIZATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Financialization is a broad concept that encompasses the increasing social impact and interconnection of financial discourses, markets, actors, and institutions in recent years.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="NATASCHA VAN DER ZWAN">
      <data key="d0">PERSON</data>
      <data key="d1">Natascha van der Zwan is a researcher who identifies three distinct research streams related to financialization.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="RESEARCH STREAMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Research streams are distinct approaches to studying financialization, including accumulation regimes, the influence of financial markets on non-financial corporations, and discourses of risk-taking.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SOCIAL LIFE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Social life refers to the interactions and relationships among individuals and groups within society, which can be transformed by financial instruments.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUPPLY CHAINS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Supply chains of financial products connect different places and political projects globally, impacting social dynamics.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="AMERICAN ANTHROPOLOGICAL ASSOCIATION">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The American Anthropological Association is a professional organization that hosts meetings and conferences related to anthropology.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SEA 2017 ANNUAL MEETING">
      <data key="d0">EVENT</data>
      <data key="d1">The SEA 2017 Annual Meeting is an event organized by the American Anthropological Association, scheduled for April 6-8, 2017, at the University of Iowa.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="RANDOM SEED">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A random seed is a value used to initialize a process, which in this context is used to generate text modification instructions.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTER-EDITOR PAIR">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Suggester-Editor pair is a collaborative mechanism that generates and refines instructions for text modification tasks.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="API DESCRIPTION">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">An API description outlines the functionality and parameters of an API, detailing how it can be used by clients.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="LIBRARY RECONSTRUCTION">
      <data key="d0">PROCESS</data>
      <data key="d1">Library Reconstruction is a process that involves synthesizing a list of APIs from a given seed, often using an API retrieval agent.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SEARCH FOOD ITEMS">
      <data key="d0">API</data>
      <data key="d1">The Search Food Items API allows clients to search for food items by name and retrieve a list of matching items.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET FOOD ITEM DETAILS">
      <data key="d0">API</data>
      <data key="d1">The Get Food Item Details API retrieves detailed information about a specific food item.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="CREATE MEAL PLAN">
      <data key="d0">API</data>
      <data key="d1">The Create Meal Plan API generates a meal plan based on user dietary preferences and caloric goals.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="UPDATE FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">The Update Food Item API allows clients to modify the details of an existing food item in the database.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="TRACK USER MEAL">
      <data key="d0">API</data>
      <data key="d1">The Track User Meal API enables users to log their daily meals for tracking purposes.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET DIETARY RECOMMENDATIONS">
      <data key="d0">API</data>
      <data key="d1">The Get Dietary Recommendations API provides users with suggestions for food items based on their dietary preferences.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="ADD NEW FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">The Add New Food Item API allows clients to add a new food item to the database.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="DELETE FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">The Delete Food Item API enables clients to remove a food item from the database.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET USER NUTRITIONAL STATS">
      <data key="d0">API</data>
      <data key="d1">The Get User Nutritional Stats API retrieves nutritional information for a user based on their logged meals.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="SEED INSTRUCTION CREATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">The Seed Instruction Creation Flow is a process that utilizes a list of APIs to create various tasks for users.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="REFINEMENT FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">The Refinement Flow aims to increase task complexity by suggesting refinements based on user input and conversation context.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="ASSISTANT">
      <data key="d0">ROLE</data>
      <data key="d1">The Assistant is an AI entity designed to help users achieve their dietary goals by utilizing various APIs.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="CALORIC GOAL">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">The caloric goal is a target number of calories that a user aims to consume daily as part of their diet plan.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="DIETARY PREFERENCES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Dietary preferences refer to the specific dietary choices or restrictions a user has, such as vegetarianism.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="MEAL PLAN">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A meal plan is a structured outline of meals that a user intends to consume over a specified period, tailored to their dietary goals.
A structured representation of meals planned for each day, including breakfast, lunch, and dinner with their respective food items and total calories.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="NUTRITIONAL SUMMARY">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">A nutritional summary provides an overview of a user's nutritional intake over a specified period, summarizing calories and nutrients consumed.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="VEGETARIAN MEAL PLAN">
      <data key="d0">DIET</data>
      <data key="d1">A vegetarian meal plan designed to meet a caloric goal of 1500 calories per day, consisting of three meals each day.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="API_CALL">
      <data key="d0">ACTION</data>
      <data key="d1">An action type indicating a request to create a meal plan based on specified dietary preferences and caloric goals.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 1">
      <data key="d0">MEAL PLAN DAY</data>
      <data key="d1">The first day of the meal plan, detailing specific meals and their caloric content.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 2">
      <data key="d0">MEAL PLAN DAY</data>
      <data key="d1">The second day of the meal plan, detailing specific meals and their caloric content.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="QUINOA SALAD">
      <data key="d0">RECIPE</data>
      <data key="d1">A specific recipe that the user wishes to add to the database, requiring nutritional information for completion.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CHANA MASALA">
      <data key="d0">RECIPE</data>
      <data key="d1">A recipe that the user wants to update in the database, requiring its unique identifier for modification.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="BUTTER CHICKEN">
      <data key="d0">RECIPE</data>
      <data key="d1">A recipe that the user wants to remove from the database, requiring its unique identifier for deletion.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MISTRAL-7B-V0.1">
      <data key="d0">MODEL</data>
      <data key="d1">A base model used for finetuning with the AgentInstruct dataset, known for its publicly available weights.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-BENCH">
      <data key="d0">DATASET</data>
      <data key="d1">A test dataset consisting of samples used to evaluate the performance of models trained with the AgentInstruct methodology.
Orca-Bench is a dataset used to evaluate the performance of various AI models, including GPT-4, on a scale from 0 to 10.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="TOTAL CALORIES">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Total calories represent the caloric content of each meal, providing a breakdown of energy intake for the meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="NUTRITIONAL INFORMATION">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Nutritional information includes details about the caloric and nutritional content of specific recipes, such as the Quinoa Salad.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="INSTRUCTIONS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Instructions are the specific guidelines or steps provided for preparing each recipe included in the meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="TOKENIZATION PROCESS">
      <data key="d0">PROCESS</data>
      <data key="d1">The tokenization process involves converting text data into tokens for processing by machine learning models.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="TRAINING DETAILS">
      <data key="d0">PROCESS</data>
      <data key="d1">Training details encompass the methodologies and parameters used to train machine learning models, including batch size and learning rates.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="EVALUATION RESULTS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Evaluation results summarize the performance metrics and outcomes of models tested against specific datasets.
Evaluation results refer to the performance metrics obtained from testing language models on specific datasets, such as MIRAGE.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="FOOD ITEMS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-2.5">
      <data key="d0">MODEL</data>
      <data key="d1">Orca-2.5 is a baseline AI model evaluated against GPT-4 in the Orca-Bench dataset.
Orca-2.5 is a previous version of the Orca model, serving as a baseline for performance comparisons with newer models like Orca-3.
Orca-2.5 is a previous version of the Orca language model, used as a baseline for comparison in performance evaluations.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MISTRAL-INSTRUCT-7B">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-Instruct-7B is a baseline AI model evaluated against GPT-4 in the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="LLAMA3-8B">
      <data key="d0">MODEL</data>
      <data key="d1">LLAMA3-8B is a baseline AI model evaluated against GPT-4 in the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="GPT-3.5-TURBO">
      <data key="d0">MODEL</data>
      <data key="d1">GPT-3.5-turbo is a baseline AI model evaluated against GPT-4 in the Orca-Bench dataset.
GPT-3.5-turbo is a variant of the GPT-3 model, used in evaluations alongside other models for summarization performance.
GPT-3.5-Turbo is a variant of the GPT-3 model, designed for efficient performance in conversational AI tasks.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="PERFORMANCE COMPARISON">
      <data key="d0">ANALYSIS</data>
      <data key="d1">Performance comparison refers to the evaluation of different AI models based on their scores in the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MULTI-TURN INTERACTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Multi-turn interaction refers to a sequence of exchanges in a conversation, where multiple user inputs and assistant responses are involved.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="STUDENT RESPONSE">
      <data key="d0">RESPONSE</data>
      <data key="d1">Student response is the generated reply from an AI model, conditioned on the preceding conversation history established by the teacher model.
The student response refers to the answer provided by a student in response to a question, which may include multiple answers or options chosen.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="TEACHER RESPONSE">
      <data key="d0">RESPONSE</data>
      <data key="d1">Teacher response is the original reply generated by the GPT-4 model, used as a benchmark for evaluating student responses.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="SCORE NORMALIZATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Score normalization is the process of adjusting scores to a standard scale, in this case, converting student scores to a 0 to 10 scale.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="PERFORMANCE AUGMENTATION">
      <data key="d0">ANALYSIS</data>
      <data key="d1">Performance augmentation refers to the improvement in model performance as a result of incorporating additional training data, such as AgentInstruct.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="COMPLEX ODQA">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="EQBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">EQBench is an emotional intelligence benchmark that evaluates language models' abilities to comprehend emotions and social interactions through conversation analysis.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="FOFO">
      <data key="d0">BENCHMARK</data>
      <data key="d1">Format Following (FoFo) is a benchmark that evaluates a model's ability to follow complex, domain-specific formats across various real-world applications.
FoFo is a benchmark used to evaluate the format-following capabilities of AI models in real-world applications.
FOFO is a benchmark for evaluating model responses based on format correctness, using GPT-4 as a judge.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="IFEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">Instruction-Following Evaluation (IFEval) measures a model's ability to follow natural language instructions through a set of prompts.
IFEval is a benchmark that checks if model responses follow verifiable instructions given in prompts.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="MT-BENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">MT-Bench is a benchmark designed to assess chat assistants' competence in multi-turn conversations using GPT-4 as the evaluator.
MT-Bench is a benchmark that evaluates model responses based on a first-turn and second-turn query, using GPT-4 for scoring.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="INFOBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">InFoBench evaluates models' instruction-following capabilities using a metric called Decomposed Requirements Following Ratio (DRFR).
InfoBench evaluates model responses based on adherence to decomposed instructions, using GPT-4 as a judge.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="MISTRAL-7B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-7B-Instruct is a language model used as a baseline for comparison in various benchmarks, particularly in reading comprehension tasks.
Mistral-7B-Instruct is another AI model that has been compared against Orca-3 and Orca-2.5 in various performance evaluations, particularly in reading comprehension and math.
Mistral-7B-Instruct is another language model that serves as a baseline for evaluating the performance of Orca-3-7B.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="MISTRAL">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral is a language model that has shown improvements in reading comprehension capabilities through targeted training.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="ELEMENTARY MATH">
      <data key="d0">SUBJECT</data>
      <data key="d1">Elementary math refers to basic mathematical concepts and skills typically taught at the primary education level, where AI models have shown considerable improvement.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="HIGH SCHOOL MATHEMATICS">
      <data key="d0">SUBJECT</data>
      <data key="d1">High school mathematics encompasses more complex mathematical concepts taught at the secondary education level, where AI models often struggle.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="COLLEGE MATHEMATICS">
      <data key="d0">SUBJECT</data>
      <data key="d1">College mathematics includes advanced mathematical topics taught at the tertiary education level, presenting challenges for AI models.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="LSATS">
      <data key="d0">EXAM</data>
      <data key="d1">The Law School Admission Tests (LSATs) are standardized tests used for law school admissions, known for their difficulty, particularly in reading comprehension.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="MATH PROBLEMS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="ORCA-3-7B">
      <data key="d0">MODEL</data>
      <data key="d1">Orca-3-7B is a language model evaluated for its performance on various summarization benchmarks, showing improvements over previous versions like Orca 2.5 and Mistral-7B-Instruct.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="HALLUCINATION RATE">
      <data key="d0">METRIC</data>
      <data key="d1">Hallucination rate is a metric used to measure the frequency of incorrect or fabricated information generated by language models during summarization tasks.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="QUALITY SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">Quality score is a metric that evaluates the overall quality of the summarization output from language models, rated on a scale from 1 to 10.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="ACI-BENCH">
      <data key="d0">DATASET</data>
      <data key="d1">ACI-Bench is a dataset designed for benchmarking automatic report generation from doctor-patient conversations, consisting of 120 data points.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="INSTRUSUM">
      <data key="d0">DATASET</data>
      <data key="d1">InstruSum is a dataset for evaluating instruction-controllable summarization capabilities of language models, containing 100 data points.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="ORCA-SUM">
      <data key="d0">DATASET</data>
      <data key="d1">Orca-Sum is a benchmark created to evaluate language models' ability to follow summarization and grounded data transformation instructions, with a total of 458 data points.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MIRAGE">
      <data key="d0">DATASET</data>
      <data key="d1">MIRAGE is a benchmark focusing on answering medical questions by referring to information retrieved from a medical corpus, used to assess RAG capabilities of language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="DATA TRANSFORMATION">
      <data key="d0">PROCESS</data>
      <data key="d1">Data transformation refers to the process of converting data from one format or structure into another, often used in conjunction with summarization tasks.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="HUGGING FACE">
      <data key="d0">PLATFORM</data>
      <data key="d1">Hugging Face is a platform that hosts various datasets and models for natural language processing, including those used for summarization tasks.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MIRAGE DATASETS">
      <data key="d0">DATASET</data>
      <data key="d1">MIRAGE Datasets are a collection of datasets used for evaluating the performance of various language models on specific tasks.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="ORCA-2.5-7B">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Orca-2.5-7B is a language model that has been evaluated for its performance on various datasets, including MIRAGE.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="PUBMEDQA">
      <data key="d0">DATASET</data>
      <data key="d1">PubMedQA is a dataset used for evaluating the performance of models in retrieving and generating answers from medical literature.PubMedQA is a dataset used for assessing the ability of models to perform retrieval-augmented generation (RAG) tasks.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">RAG (Retrieval-Augmented Generation) is a technique that combines retrieval of relevant documents with generative capabilities of language models.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="USMEDMCQA">
      <data key="d0">DATASET</data>
      <data key="d1">USMedMCQA is a dataset designed for assessing the capabilities of language models in medical question-answering scenarios.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="CO-T">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">CoT (Chain of Thought) is a technique used in language models to improve reasoning and performance on complex tasks.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MEDMEDQA">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="AZURE">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Azure is a cloud computing service created by Microsoft, providing various services including AI and machine learning capabilities.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CONTENT HARMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Content harms refer to the negative impacts that large language models can have, including the generation of disinformation or harmful content.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CONTENT MODERATION SERVICES">
      <data key="d0">SERVICE</data>
      <data key="d1">Content moderation services are tools and systems provided by companies and institutions to help manage and mitigate harmful content generated by AI models.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="REGULATIONS AND STANDARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Regulations and standards are guidelines proposed for government and technology leaders to ensure safe and ethical use of AI technologies.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HALLUCINATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Hallucination in AI refers to the phenomenon where language models generate fabricated or misleading content, which can lead to misinformation.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="UNSTRUCTURED DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Unstructured data refers to information that does not have a predefined data model, making it more challenging to analyze but valuable for generating insights.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RESEARCH COMMUNITY">
      <data key="d0">GROUP</data>
      <data key="d1">The research community consists of individuals and organizations engaged in the study and development of AI technologies, contributing to advancements and ethical considerations.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SAM ADE JACOBS">
      <data key="d0">PERSON</data>
      <data key="d1">Sam Ade Jacobs is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMMAR AHMAD AWAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ammar Ahmad Awan is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JYOTI ANEJA">
      <data key="d0">PERSON</data>
      <data key="d1">Jyoti Aneja is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AHMED AWADALLAH">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmed Awadallah is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.
Ahmed Awadallah is a researcher who co-authored multiple papers on Orca and Orca 2, focusing on enhancing language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HANY AWADALLA">
      <data key="d0">PERSON</data>
      <data key="d1">Hany Awadalla is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NGUYEN BACH">
      <data key="d0">PERSON</data>
      <data key="d1">Nguyen Bach is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIT BAHREE">
      <data key="d0">PERSON</data>
      <data key="d1">Amit Bahree is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ARASH BAKHTIARI">
      <data key="d0">PERSON</data>
      <data key="d1">Arash Bakhtiari is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIANMIN BAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jianmin Bao is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HARKIRAT BEHL">
      <data key="d0">PERSON</data>
      <data key="d1">Harkirat Behl is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ALON BENHAIM">
      <data key="d0">PERSON</data>
      <data key="d1">Alon Benhaim is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MISHA BILENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Misha Bilenko is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JOHAN BJORCK">
      <data key="d0">PERSON</data>
      <data key="d1">Johan Bjorck is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="S&#201;BASTIEN BUBECK">
      <data key="d0">PERSON</data>
      <data key="d1">S&#233;bastien Bubeck is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="QIN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Qin Cai is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARTIN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Martin Cai is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CAIO C&#201;SAR TEODORO MENDES">
      <data key="d0">PERSON</data>
      <data key="d1">Caio C&#233;sar Teodoro Mendes is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="VISHRAV CHAUDHARY">
      <data key="d0">PERSON</data>
      <data key="d1">Vishrav Chaudhary is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Dong Chen is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONGDONG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Dongdong Chen is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YEN-CHUN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yen-Chun Chen is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YI-LING CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yi-Ling Chen is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PARUL CHOPRA">
      <data key="d0">PERSON</data>
      <data key="d1">Parul Chopra is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIYANG DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Xiyang Dai is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ALLIE DEL GIORNO">
      <data key="d0">PERSON</data>
      <data key="d1">Allie Del Giorno is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GUSTAVO DE ROSA">
      <data key="d0">PERSON</data>
      <data key="d1">Gustavo de Rosa is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MATTHEW DIXON">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew Dixon is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RONEN ELDAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ronen Eldan is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="VICTOR FRAGOSO">
      <data key="d0">PERSON</data>
      <data key="d1">Victor Fragoso is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DAN ITER">
      <data key="d0">PERSON</data>
      <data key="d1">Dan Iter is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MEI GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Mei Gao is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MIN GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Min Gao is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIANFENG GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jianfeng Gao is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.
Jianfeng Gao is a researcher who co-authored a paper on instruction tuning with GPT-4.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIT GARG">
      <data key="d0">PERSON</data>
      <data key="d1">Amit Garg is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ABHISHEK GOSWAMI">
      <data key="d0">PERSON</data>
      <data key="d1">Abhishek Goswami is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SURIYA GUNASEKAR">
      <data key="d0">PERSON</data>
      <data key="d1">Suriya Gunasekar is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="EMMAN HAIDER">
      <data key="d0">PERSON</data>
      <data key="d1">Emman Haider is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JUNHENG HAO">
      <data key="d0">PERSON</data>
      <data key="d1">Junheng Hao is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RUSSELL J. HEWETT">
      <data key="d0">PERSON</data>
      <data key="d1">Russell J. Hewett is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JAMIE HUYNH">
      <data key="d0">PERSON</data>
      <data key="d1">Jamie Huynh is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MOJAN JAVAHERIPI">
      <data key="d0">PERSON</data>
      <data key="d1">Mojan Javaheripi is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIN JIN">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Jin is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PIERO KAUFFMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Piero Kauffmann is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NIKOS KARAMPATZIAKIS">
      <data key="d0">PERSON</data>
      <data key="d1">Nikos Karampatziakis is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONGWOO KIM">
      <data key="d0">PERSON</data>
      <data key="d1">Dongwoo Kim is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MAHOUD KHADEMI">
      <data key="d0">PERSON</data>
      <data key="d1">Mahoud Khademi is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LEV KURILENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Lev Kurilenko is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JAMES R. LEE">
      <data key="d0">PERSON</data>
      <data key="d1">James R. Lee is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YIN TAT LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Yin Tat Lee is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YUANZHI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yuanzhi Li is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YUNSHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yunsheng Li is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHEN LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Liang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LARS LIDEN">
      <data key="d0">PERSON</data>
      <data key="d1">Lars Liden is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CE LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Ce Liu is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MENGCHEN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Mengchen Liu is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="WEISHUNG LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Weishung Liu is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ERIC LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Lin is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHONG LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Chong Luo is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PIYUSH MADAN">
      <data key="d0">PERSON</data>
      <data key="d1">Piyush Madan is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MATT MAZZOLA">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Mazzola is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ARINDAM MITRA">
      <data key="d0">PERSON</data>
      <data key="d1">Arindam Mitra is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.
Arindam Mitra is a researcher who co-authored multiple papers on enhancing language models, including Orca 2 and Orca-Math.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HARDIK MODI">
      <data key="d0">PERSON</data>
      <data key="d1">Hardik Modi is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BRANDON NORICK">
      <data key="d0">PERSON</data>
      <data key="d1">Brandon Norick is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BARUN PATRA">
      <data key="d0">PERSON</data>
      <data key="d1">Barun Patra is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DANIEL PEREZ-BECKER">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Perez-Becker is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="THOMAS PORTET">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Portet is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="REID PRYZANT">
      <data key="d0">PERSON</data>
      <data key="d1">Reid Pryzant is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HEYANG QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Heyang Qin is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARKO RADMILAC">
      <data key="d0">PERSON</data>
      <data key="d1">Marko Radmilac is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CORBY ROSSET">
      <data key="d0">PERSON</data>
      <data key="d1">Corby Rosset is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.
Corby Rosset is a researcher who co-authored multiple papers on Orca and Orca 2, focusing on enhancing language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SAMBUDHA ROY">
      <data key="d0">PERSON</data>
      <data key="d1">Sambudha Roy is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OLATUNJI RUWASE">
      <data key="d0">PERSON</data>
      <data key="d1">Olatunji Ruwase is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OLLI SAARIKIVI">
      <data key="d0">PERSON</data>
      <data key="d1">Olli Saarikivi is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIN SAIED">
      <data key="d0">PERSON</data>
      <data key="d1">Amin Saied is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.
Amin Saied is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ADIL SALIM">
      <data key="d0">PERSON</data>
      <data key="d1">Adil Salim is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MICHAEL SANTACROCE">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Santacroce is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SHITAL SHAH">
      <data key="d0">PERSON</data>
      <data key="d1">Shital Shah is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NING SHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ning Shang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HITESHI SHARMA">
      <data key="d0">PERSON</data>
      <data key="d1">Hiteshi Sharma is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SWADHEEN SHUKLA">
      <data key="d0">PERSON</data>
      <data key="d1">Swadheen Shukla is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIA SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Xia Song is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MASAHIRO TANAKA">
      <data key="d0">PERSON</data>
      <data key="d1">Masahiro Tanaka is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ANDREA TUPINI">
      <data key="d0">PERSON</data>
      <data key="d1">Andrea Tupini is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Wang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LIJUAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Lijuan Wang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHUNYU WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chunyu Wang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YU WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Wang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RACHEL WARD">
      <data key="d0">PERSON</data>
      <data key="d1">Rachel Ward is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GUANHUA WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Guanhua Wang is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PHILIPP WITTE">
      <data key="d0">PERSON</data>
      <data key="d1">Philipp Witte is a researcher involved in the development of AI technologies, contributing to the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PHI-3">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Phi-3 is a highly capable language model designed to operate locally on mobile devices, as detailed in the technical report from 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ISAAC COWHEY">
      <data key="d0">PERSON</data>
      <data key="d1">Isaac Cowhey is a researcher who contributed to the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OREN ETZIONI">
      <data key="d0">PERSON</data>
      <data key="d1">Oren Etzioni is a researcher involved in the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TUSHAR KHOT">
      <data key="d0">PERSON</data>
      <data key="d1">Tushar Khot is a researcher who worked on the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ASHISH SABHARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Ashish Sabharwal is a researcher associated with the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CARISSA SCHOENICK">
      <data key="d0">PERSON</data>
      <data key="d1">Carissa Schoenick is a researcher who contributed to the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OYVIND TAFJORD">
      <data key="d0">PERSON</data>
      <data key="d1">Oyvind Tafjord is a researcher involved in the AI2 Reasoning Challenge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NING DING">
      <data key="d0">PERSON</data>
      <data key="d1">Ning Ding is a researcher known for enhancing chat language models through instructional conversations.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YULIN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yulin Chen is a researcher involved in enhancing chat language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BOKAI XU">
      <data key="d0">PERSON</data>
      <data key="d1">Bokai Xu is a researcher who contributed to enhancing chat language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHI ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhi Zheng is a researcher who contributed to enhancing chat language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHENGDING HU">
      <data key="d0">PERSON</data>
      <data key="d1">Shengding Hu is a researcher involved in enhancing chat language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHIYUAN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Liu is a researcher who contributed to enhancing chat language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DROPS">
      <data key="d0">RESEARCH</data>
      <data key="d1">DROP is a reading comprehension benchmark that requires discrete reasoning over paragraphs, as discussed in a 2019 conference paper.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHAOYE FEI">
      <data key="d0">PERSON</data>
      <data key="d1">Zhaoye Fei is a researcher known for unearthing large-scale domain-specific knowledge from public corpora.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUNFAN SHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yunfan Shao is a researcher involved in unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LINYANG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Linyang Li is a researcher who contributed to unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHIYUAN ZENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Zeng is a researcher involved in unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANG YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Hang Yan is a researcher who contributed to unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XIPENG QIU">
      <data key="d0">PERSON</data>
      <data key="d1">Xipeng Qiu is a researcher involved in unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DAHUA LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Dahua Lin is a researcher who contributed to unearthing large-scale domain-specific knowledge.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ARNA GUDIBANDE">
      <data key="d0">PERSON</data>
      <data key="d1">Arnav Gudibande is a researcher known for discussing the limitations of imitating proprietary language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC WALLACE">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Wallace is a researcher involved in discussing the limitations of imitating proprietary language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHARLIE SNELL">
      <data key="d0">PERSON</data>
      <data key="d1">Charlie Snell is a researcher who contributed to the discussion on imitating proprietary language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XINYANG GENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyang Geng is a researcher involved in discussing the limitations of imitating proprietary language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAO LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Liu is a researcher who contributed to the discussion on imitating proprietary language models.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SAURAV KADAVATH">
      <data key="d0">PERSON</data>
      <data key="d1">Saurav Kadavath is a researcher who contributed to measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AKUL ARORA">
      <data key="d0">PERSON</data>
      <data key="d1">Akul Arora is a researcher involved in measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Tang is a researcher involved in measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NOAH A. SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">Noah A. Smith is a researcher who contributed to measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="IZ BELTAGY">
      <data key="d0">PERSON</data>
      <data key="d1">Iz Beltagy is a researcher involved in measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANNANEH HAJISHIRZI">
      <data key="d0">PERSON</data>
      <data key="d1">Hannaneh Hajishirzi is a researcher who contributed to measuring mathematical problem-solving capabilities.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CAMELS">
      <data key="d0">RESEARCH</data>
      <data key="d1">Camels in a changing climate is a study focused on enhancing language model adaptation, as discussed in a 2023 paper.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALBERT Q. JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Albert Q. Jiang is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALEXANDRE SABLAYROLLES">
      <data key="d0">PERSON</data>
      <data key="d1">Alexandre Sablayrolles is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ARTHUR MENSCH">
      <data key="d0">PERSON</data>
      <data key="d1">Arthur Mensch is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHRIS BAMFORD">
      <data key="d0">PERSON</data>
      <data key="d1">Chris Bamford is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DEVENDRA SINGH CHAPLOT">
      <data key="d0">PERSON</data>
      <data key="d1">Devendra Singh Chaplot is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DIEGO DE LAS CASAS">
      <data key="d0">PERSON</data>
      <data key="d1">Diego de las Casas is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="FLORIAN BRESSAND">
      <data key="d0">PERSON</data>
      <data key="d1">Florian Bressand is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GIANNA LENGYEL">
      <data key="d0">PERSON</data>
      <data key="d1">Gianna Lengyel is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GUILLAUME LAMPLE">
      <data key="d0">PERSON</data>
      <data key="d1">Guillaume Lample is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LUCILE SAULNIER">
      <data key="d0">PERSON</data>
      <data key="d1">Lucile Saulnier is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="L&#201;LIO RENARD LAVAUD">
      <data key="d0">PERSON</data>
      <data key="d1">L&#233;lio Renard Lavaud is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PIERRE STOCK">
      <data key="d0">PERSON</data>
      <data key="d1">Pierre Stock is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TEVEN LE SCAO">
      <data key="d0">PERSON</data>
      <data key="d1">Teven Le Scao is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="THOMAS WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Wang is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TIMOTH&#201;E LACROIX">
      <data key="d0">PERSON</data>
      <data key="d1">Timoth&#233;e Lacroix is a researcher involved in the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="WILLIAM EL SAYED">
      <data key="d0">PERSON</data>
      <data key="d1">William El Sayed is a researcher who contributed to the Mistral 7b project.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AI2 REASONING CHALLENGE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TRAINING VERIFIERS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="UNEARTHING DOMAIN-SPECIFIC KNOWLEDGE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XUECHEN LI">
      <data key="d0" />
      <data key="d1">
Xuechen Li is a researcher who co-authored a paper on an automatic evaluator for instruction-following models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TIANYI ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Tianyi Zhang is a researcher who contributed to the development of communicative agents for exploring large language model society.
Tianyi Zhang is a researcher who co-authored a paper on an automatic evaluator for instruction-following models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YANN DUBOIS">
      <data key="d0">PERSON</data>
      <data key="d1">Yann Dubois is a researcher involved in the development of communicative agents for exploring large language model society.
Yann Dubois is a researcher who co-authored a paper on an automatic evaluator for instruction-following models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ROHAN TAORI">
      <data key="d0">PERSON</data>
      <data key="d1">Rohan Taori is a researcher who contributed to the development of communicative agents for exploring large language model society.
Rohan Taori is a researcher who co-authored a paper on an automatic evaluator for instruction-following models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ISHAAN GULRAJANI">
      <data key="d0">PERSON</data>
      <data key="d1">Ishaan Gulrajani is a researcher involved in the development of communicative agents for exploring large language model society.
Ishaan Gulrajani is a researcher who co-authored a paper on an automatic evaluator for instruction-following models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CARLOS GUESTRIN">
      <data key="d0">PERSON</data>
      <data key="d1">Carlos Guestrin is a researcher who contributed to the development of communicative agents for exploring large language model society.
Carlos Guestrin is a researcher who co-authored a paper on an automatic evaluator for instruction-following models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TATSUNORI B. HASHIMOTO">
      <data key="d0">PERSON</data>
      <data key="d1">Tatsunori B. Hashimoto is a researcher who contributed to the development of communicative agents for exploring large language model society.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="KHIZBULLIN">
      <data key="d0">PERSON</data>
      <data key="d1">Khizbullin is a researcher involved in the study of communicative agents for exploring large language model society.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BERNARD GHANEM">
      <data key="d0">PERSON</data>
      <data key="d1">Bernard Ghanem is a researcher who co-authored a work on communicative agents for mind exploration in large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CAMEL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Camel refers to a system of communicative agents designed for exploring the capabilities and interactions within large language model societies.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="TATSUNORI HASHIMOTO">
      <data key="d0">PERSON</data>
      <data key="d1">Tatsunori Hashimoto is a researcher who co-authored a paper on an automatic evaluator for instruction-following models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YIXIN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Yixin Liu is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ALEXANDER R. FABBRI">
      <data key="d0">PERSON</data>
      <data key="d1">Alexander R. Fabbri is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JIAWEN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jiawen Chen is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YILUN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yilun Zhao is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SIMENG HAN">
      <data key="d0">PERSON</data>
      <data key="d1">Simeng Han is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SHAFIQ JOTY">
      <data key="d0">PERSON</data>
      <data key="d1">Shafiq Joty is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DRAGOMIR RADEV">
      <data key="d0">PERSON</data>
      <data key="d1">Dragomir Radev is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CHIEN-SHENG WU">
      <data key="d0">PERSON</data>
      <data key="d1">Chien-Sheng Wu is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ARMAN COHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Arman Cohan is a researcher who co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="COSMOPEDIA">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Cosmopedia is a project focused on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ORCA 2">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Orca 2 is a system designed to teach small language models how to reason effectively.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ORCA-MATH">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Orca-Math is a project aimed at enhancing the capabilities of small language models in grade school math.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XTREMEDISTIL">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Xtremedistil is a method for multi-stage distillation aimed at creating massive multilingual models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DIRECT NASH OPTIMIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Direct Nash Optimization is a method for teaching language models to self-improve based on general preferences.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="THE CURSE OF RECURSION">
      <data key="d0">RESEARCH</data>
      <data key="d1">The Curse of Recursion refers to a phenomenon where training on generated data causes models to forget previous knowledge.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BENCHMARKING GENERATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LOUBNA BEN ALLAL">
      <data key="d0">PERSON</data>
      <data key="d1">Loubna Ben Allal is a researcher who co-authored a paper on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ANTON LOZHKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Anton Lozhkov is a researcher who co-authored a paper on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LUCIANO DEL CORRO">
      <data key="d0">PERSON</data>
      <data key="d1">Luciano Del Corro is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SHWETI MAHAJAN">
      <data key="d0">PERSON</data>
      <data key="d1">Shweti Mahajan is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ANDRES CODAS">
      <data key="d0">PERSON</data>
      <data key="d1">Andres Codas is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CLARISSE SIMOES">
      <data key="d0">PERSON</data>
      <data key="d1">Clarisse Simoes is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SAHAJ AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Sahaj Agarwal is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XUXI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xuxi Chen is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ANASTASIA RAZDAIBIEDINA">
      <data key="d0">PERSON</data>
      <data key="d1">Anastasia Razdaibiedina is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ERIK JONES">
      <data key="d0">PERSON</data>
      <data key="d1">Erik Jones is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KRITI AGGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Kriti Aggarwal is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="HAMID PALANGI">
      <data key="d0">PERSON</data>
      <data key="d1">Hamid Palangi is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="GUOQING ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Guoqing Zheng is a researcher who co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="HAMED KHANPOUR">
      <data key="d0">PERSON</data>
      <data key="d1">Hamed Khanpour is a researcher who co-authored multiple papers on Orca and Orca 2, focusing on enhancing language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SAMUEL J. PAECH">
      <data key="d0">PERSON</data>
      <data key="d1">Samuel J. Paech is a researcher who co-authored a paper on an emotional intelligence benchmark for large language models.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BAOLIN PENG">
      <data key="d0">PERSON</data>
      <data key="d1">Baolin Peng is a researcher who co-authored a paper on instruction tuning with GPT-4.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CHUNYUAN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Chunyuan Li is a researcher who co-authored a paper on instruction tuning with GPT-4.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="PENGCHENG HE">
      <data key="d0">PERSON</data>
      <data key="d1">Pengcheng He is a researcher who co-authored a paper on instruction tuning with GPT-4.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="MICHEL GALLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Michel Galley is a researcher who co-authored a paper on instruction tuning with GPT-4.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DANIEL VAN STRIEN">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="EQ-BENCH">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ILIA SHUMAILOV">
      <data key="d0">PERSON</data>
      <data key="d1">Ilia Shumailov is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZAKHAR SHUMAYLOV">
      <data key="d0">PERSON</data>
      <data key="d1">Zakhar Shumaylov is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIREN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiren Zhao is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NICOLAS PAPERNOT">
      <data key="d0">PERSON</data>
      <data key="d1">Nicolas Papernot is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ROSS ANDERSON">
      <data key="d0">PERSON</data>
      <data key="d1">Ross Anderson is a researcher who co-authored a paper discussing the impact of training on generated data in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MOHAMMED LATIF SIDDIQ">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammed Latif Siddiq is a researcher who co-authored a paper on evaluating generated regular expressions in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAHAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiahao Zhang is a researcher who co-authored a paper on evaluating generated regular expressions in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LINDSAY RONEY">
      <data key="d0">PERSON</data>
      <data key="d1">Lindsay Roney is a researcher who co-authored a paper on evaluating generated regular expressions in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JOANNA C. S. SANTOS">
      <data key="d0">PERSON</data>
      <data key="d1">Joanna C. S. Santos is a researcher who co-authored a paper on evaluating generated regular expressions in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NATHAN SCALES">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Scales is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NATHANAEL SCH&#196;RLI">
      <data key="d0">PERSON</data>
      <data key="d1">Nathanael Sch&#228;rli is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QUOC V. LE">
      <data key="d0">PERSON</data>
      <data key="d1">Quoc V. Le is a researcher who co-authored a paper on challenging big-bench tasks in 2022.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEN WAI YIM">
      <data key="d0">PERSON</data>
      <data key="d1">Wen Wai Yim is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YUJUAN FU">
      <data key="d0">PERSON</data>
      <data key="d1">Yujuan Fu is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ASMA BEN ABACHA">
      <data key="d0">PERSON</data>
      <data key="d1">Asma Ben Abacha is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NEAL SNIDER">
      <data key="d0">PERSON</data>
      <data key="d1">Neal Snider is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="THOMAS LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Lin is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MELIHA YETISGEN">
      <data key="d0">PERSON</data>
      <data key="d1">Meliha Yetisgen is a researcher who co-authored a paper on a novel ambient clinical intelligence dataset in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="BEIBIN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Beibin Li is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ERKANG ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Erkang Zhu is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LI JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Li Jiang is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIAOYUN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaoyun Zhang is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AHMED HASSAN AWADALLAH">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmed Hassan Awadallah is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RYEN W WHITE">
      <data key="d0">PERSON</data>
      <data key="d1">Ryen W White is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DOUG BURGER">
      <data key="d0">PERSON</data>
      <data key="d1">Doug Burger is a researcher who co-authored a paper on enabling next-gen LLM applications in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CONGYING XIA">
      <data key="d0">PERSON</data>
      <data key="d1">Congying Xia is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHEN XING">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Xing is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIANGSHU DU">
      <data key="d0">PERSON</data>
      <data key="d1">Jiangshu Du is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XINYI YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyi Yang is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIHAO FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Yihao Feng is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RAN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Ran Xu is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WENPENG YIN">
      <data key="d0">PERSON</data>
      <data key="d1">Wenpeng Yin is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CAIMING XIONG">
      <data key="d0">PERSON</data>
      <data key="d1">Caiming Xiong is a researcher who co-authored a paper on evaluating LLMs' format-following capability in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CAN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Can Xu is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QINGFENG SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Qingfeng Sun is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="KAI ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Kai Zheng is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIUBO GENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiubo Geng is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="PU ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Pu Zhao is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAZHAN FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiazhan Feng is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHONGYANG TAO">
      <data key="d0">PERSON</data>
      <data key="d1">Chongyang Tao is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DAXIN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Daxin Jiang is a researcher who co-authored a paper on benchmarking retrieval-augmented generation for medicine in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LONGHUI YU">
      <data key="d0">PERSON</data>
      <data key="d1">Longhui Yu is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEISEN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Weisen Jiang is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="HAN SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Han Shi is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JINCHENG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Jincheng Yu is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHENGYING LI">
      <data key="d0">PERSON</data>
      <data key="d1">Zhengying Li is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Zhang is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JAMES T KWOK">
      <data key="d0">PERSON</data>
      <data key="d1">James T Kwok is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHENGUO LI">
      <data key="d0">PERSON</data>
      <data key="d1">Zhenguo Li is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ADRIAN WELLER">
      <data key="d0">PERSON</data>
      <data key="d1">Adrian Weller is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEIYANG LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Weiyang Liu is a researcher who co-authored a paper on empowering large language models to follow complex instructions in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIFAN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yifan Zhang is a researcher who co-authored a paper on autonomous data selection for mathematical texts in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIFAN LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Yifan Luo is a researcher who co-authored a paper on autonomous data selection for mathematical texts in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YANG YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Yang Yuan is a researcher who co-authored a paper on autonomous data selection for mathematical texts in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ANDREW CHI-CHIH YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Chi-Chih Yao is a researcher who co-authored a paper on autonomous data selection for mathematical texts in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WANJUN ZHONG">
      <data key="d0">PERSON</data>
      <data key="d1">Wanjun Zhong is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RUIXIANG CUI">
      <data key="d0">PERSON</data>
      <data key="d1">Ruixiang Cui is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIDUO GUO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiduo Guo is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YAOBO LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yaobo Liang is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SHUAI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Shuai Lu is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YANLIN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yanlin Wang is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NAN DUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Nan Duan is a researcher who co-authored a paper on a human-centric benchmark for evaluating foundation models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JEFFREY ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Jeffrey Zhou is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="TIANJIAN LU">
      <data key="d0">PERSON</data>
      <data key="d1">Tianjian Lu is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SIDDHARTHA BRAHMA">
      <data key="d0">PERSON</data>
      <data key="d1">Siddhartha Brahma is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SUJOY BASU">
      <data key="d0">PERSON</data>
      <data key="d1">Sujoy Basu is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YI LUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Luan is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LE HOU">
      <data key="d0">PERSON</data>
      <data key="d1">Le Hou is a researcher who co-authored a paper on instruction-following evaluation for large language models in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DEBATE PASSAGE GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Debate Passage Generator specializes in crafting passages that mimic debate transcripts.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CON(&quot;ENTITY&quot;">
      <data key="d0">CONVERSATION PASSAGE GENERATOR</data>
      <data key="d1">AGENT</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MEETING TRANSCRIPT GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Meeting Transcript Generator is designed to produce transcripts of meetings.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="POEM GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Poem Generator creates poems based on given prompts or themes.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SATIRICAL PASSAGE GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Satirical Passage Generator creates texts infused with satirical wit.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="INSTRUCTIONAL PASSAGE GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Instructional Passage Generator generates passages resembling instructional manuals.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LONG TEXT GENERATOR">
      <data key="d0">AGENT</data>
      <data key="d1">The Long Text Generator extends original texts by incorporating additional information.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="IDENTITY AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">The Identity Agent replicates the input text verbatim without modifications.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LITERAL COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">A Literal Comprehension Question asks for specific details or facts clearly stated in the text.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NUMERICAL DISCRETE REASONING">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Numerical Discrete Reasoning questions require the reader to use numerical reasoning over multiple facts from the text.
Numerical discrete reasoning questions require the reader to apply numerical reasoning across multiple facts from the text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CRITICAL COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">A Critical Comprehension Question involves assessing two statements about the text as true or false.
Critical comprehension questions involve constructing true/false statements about the text's purpose or point of view.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="EVALUATIVE COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">An Evaluative Comprehension Question requires the reader to construct an essay based on the text's purpose or point of view.
Evaluative comprehension questions prompt in-depth analysis of the text&#8217;s theme or the effectiveness of an argument.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CONVERSATION PASSAGE GENERATOR">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="VOCABULARY AND LANGUAGE USE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Vocabulary and language use questions test understanding of specific words or phrases in the text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="RELATIONSHIP COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Relationship comprehension questions require matching items based on a specific criterion.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SEQUENCING EVENTS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Sequencing events questions ask respondents to arrange a series of events from the text in chronological order.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="STRENGTHEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Strengthen questions identify information that would make an argument's conclusion more likely to be true.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="WEAKEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Weaken questions find evidence or arguments that would make a conclusion less likely to be true.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="ASSUMPTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Assumption questions determine what must be true for an argument to hold.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="FLAW">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Flaw questions point out mistakes in an argument's reasoning.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="INFERENCE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Inference questions require choosing an option that logically follows from the provided information.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PRINCIPLE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Principle questions recognize the general rule or principle underlying an argument.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="METHOD OF REASONING">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Method of reasoning questions describe how an argument is logically constructed.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="RESOLVE THE PARADOX">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Resolve the paradox questions offer explanations that reconcile seemingly contradictory information.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PARAPHRASING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Paraphrasing involves rewriting text using different words and structures while maintaining the original meaning.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT SIMPLIFICATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text simplification makes text easier to read and understand, often for children or language learners.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT EXPANSION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text expansion adds more information or detail to make text more comprehensive.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT TRANSLATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text translation converts text from one language to another while preserving the original meaning.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT FORMATTING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text formatting alters the appearance of text to improve readability or for stylistic purposes.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SENTIMENT MODIFICATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Sentiment modification changes the tone of the text to alter its emotional impact.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT ANNOTATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text annotation adds notes or comments to a text for analysis or additional context.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="KEYWORD REPLACEMENT">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Keyword replacement substitutes specific words with synonyms or related terms.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT REMOVING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text removing involves redacting or removing content from text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT CAPITALIZATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text capitalization adjusts the case of letters in text for consistency.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT STYLING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text styling applies styles like bold or italics to emphasize parts of the text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="CONTENT REWRITING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Content rewriting extensively modifies text to produce a new version.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="DATA NORMALIZATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Data normalization standardizes text for consistency.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PLAGIARISM REWORDING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Plagiarism rewording alters text to avoid plagiarism.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="CODE SWITCHING">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Code switching alternates between languages or dialects within a text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT OBFUSCATION">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Text obfuscation intentionally makes text vague or harder to understand.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXTUAL ENTAILMENT">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Textual entailment modifies a sentence to either entail or contradict another.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="REWRITING WITH VOCABULARY LIMITATIONS">
      <data key="d0">TEXT MODIFICATION TYPE</data>
      <data key="d1">Rewriting with vocabulary limitations involves rewriting text using a limited vocabulary.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">EVALUATION METHOD</data>
      <data key="d1">The GPT-4 extraction system message is used to parse student responses in multiple choice questions.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="INSTRUCTION TAXONOMY">
      <data key="d0">FRAMEWORK</data>
      <data key="d1">Instruction taxonomy is a classification system that organizes different types of instructions for generating text modifications.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="EVALUATION DETAILS">
      <data key="d0">PROCESS</data>
      <data key="d1">Evaluation details outline the methods and benchmarks used to assess the performance of models in generating responses.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="OPEN-ENDED GENERATION SETTING">
      <data key="d0">EVALUATION CONTEXT</data>
      <data key="d1">An open-ended generation setting allows models to produce responses without predefined constraints, facilitating creative output.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="GROUND TRUTH">
      <data key="d0">REFERENCE</data>
      <data key="d1">Ground truth refers to the accurate and verified information used as a benchmark for evaluating model predictions.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="ACCURACY SCORES">
      <data key="d0">METRIC</data>
      <data key="d1">Accuracy scores measure the correctness of model predictions against the ground truth in assessments.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT MODIFICATION FLOW">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="OPTIONS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Options are the possible answers provided to the student, typically formatted as a list of choices with corresponding letters.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE</data>
      <data key="d1">The Maths GPT-4 Extraction System Message is a set of instructions for evaluating a student's answer to a math problem, focusing on the final answer's correctness.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE</data>
      <data key="d1">The General Extraction System Message is a set of instructions for parsing student responses and matching them with the correct answer.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE</data>
      <data key="d1">The EQBench GPT-4 Extraction System Message is a set of instructions for extracting emotion scores from a student agent response based on a critique.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="MULTIPLE ANSWERS">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Multiple answers refer to the scenario where a student provides more than one option as their response to a question.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ERROR ANALYSIS">
      <data key="d0">PROCESS</data>
      <data key="d1">Error analysis is the process of comparing the student's final answer with the correct answer to determine if they match.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="FINAL VERDICT">
      <data key="d0">PROCESS</data>
      <data key="d1">The final verdict is the conclusion drawn from the error analysis, indicating whether the student's answer is 'Correct' or 'Incorrect'.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ALPHABET ID">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ELLIOT">
      <data key="d0">PERSON</data>
      <data key="d1">Elliot is a character who has just confessed his feelings to Alex, experiencing a mix of emotions including resignation, anger, hopefulness, and embarrassment.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ALEX">
      <data key="d0">PERSON</data>
      <data key="d1">Alex is a character who is already in a relationship, which complicates Elliot's feelings after his confession.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMOTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Emotions are the feelings experienced by Elliot, including resignation, anger, hopefulness, and embarrassment, each rated on a scale.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="RESIGNED">
      <data key="d0">EMOTION</data>
      <data key="d1">Resigned is an emotion felt by Elliot, rated 7, indicating a sense of acceptance of his situation.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ANGRY">
      <data key="d0">EMOTION</data>
      <data key="d1">Angry is an emotion felt by Elliot, rated 3, indicating frustration with himself for his situation.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HOPEFUL">
      <data key="d0">EMOTION</data>
      <data key="d1">Hopeful is an emotion felt by Elliot, rated 5, indicating a desire for Alex to reciprocate his feelings.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMBARRASSED">
      <data key="d0">EMOTION</data>
      <data key="d1">Embarrassed is an emotion felt by Elliot, rated 8, indicating discomfort for putting Alex in an awkward position.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="OPEN-ENDED GENERATION">
      <data key="d0">TASK</data>
      <data key="d1">Open-ended generation refers to tasks where a model generates answers to questions without a specific ground-truth to match.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="RESIGNED SCORE">
      <data key="d0">DATA POINT</data>
      <data key="d1">The resigned score is a numerical value of 7, indicating the intensity of Elliot's feeling of resignation.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ANGRY SCORE">
      <data key="d0">DATA POINT</data>
      <data key="d1">The angry score is a numerical value of 3, indicating the intensity of Elliot's feeling of anger.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HOPEFUL SCORE">
      <data key="d0">DATA POINT</data>
      <data key="d1">The hopeful score is a numerical value of 5, indicating the intensity of Elliot's feeling of hopefulness.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMBARRASSED SCORE">
      <data key="d0">DATA POINT</data>
      <data key="d1">The embarrassed score is a numerical value of 8, indicating the intensity of Elliot's feeling of embarrassment.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="SCORES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <edge source="GRAPH RAG APPROACH" target="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach is designed to improve query-focused summarization by utilizing a graph-based text index for better responses.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d4">9.0</data>
      <data key="d5">The Graph RAG approach employs large language models to build a graph-based text index and generate summaries.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="SOURCE DOCUMENTS">
      <data key="d4">8.0</data>
      <data key="d5">Source documents are the basis for the Graph RAG approach, providing the text from which information is extracted and summarized.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="COMMUNITY SUMMARIES">
      <data key="d4">14.0</data>
      <data key="d5">Community summaries are generated as part of the Graph RAG approach to provide partial answers to user queries.
Community summaries provide aggregated insights that support the Graph RAG approach's analysis capabilities.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach builds upon the principles of retrieval-augmented generation to enhance query-focused summarization capabilities.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="COMMUNITY DETECTION">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach utilizes community detection to partition the graph index into groups for more effective summarization.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="TOKEN RANGE">
      <data key="d4">1.0</data>
      <data key="d5">The token range of a dataset influences the performance of the Graph RAG approach, particularly in terms of comprehensiveness and diversity of answers.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach aims to enhance query-focused abstractive summarization by utilizing a knowledge graph for better context handling.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="LLM">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach employs LLMs to generate summaries and extract information from text chunks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="KURATOV ET AL. (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Kuratov et al. (2024) provides insights relevant to the performance and limitations of the Graph RAG approach in handling longer text chunks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="LIU ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Liu et al. (2023) provides insights relevant to the performance and limitations of the Graph RAG approach in handling longer text chunks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">7.0</data>
      <data key="d5">The Graph RAG approach utilizes community detection algorithms to partition graphs into modular communities for summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GPT">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach leverages the capabilities of GPT models for summarization tasks, enhancing performance through advanced language processing.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="LLAMA">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach utilizes Llama models to improve the efficiency and effectiveness of text summarization.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GEMINI">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach incorporates Gemini models to enhance its summarization capabilities through in-context learning.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ACHIAM ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Achiam et al. (2023) provides insights into the performance of GPT models, relevant to the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="BROWN ET AL. (2020)">
      <data key="d4">5.0</data>
      <data key="d5">Brown et al. (2020) discusses foundational aspects of LLMs that inform the design of the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="TOUVRON ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Touvron et al. (2023) provides insights into the Llama models that are relevant to the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ANIL ET AL. (2023)">
      <data key="d4">1.0</data>
      <data key="d5">Anil et al. (2023) discusses the capabilities of Gemini models, which are relevant to the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="DATASET">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach utilizes datasets to generate questions and tasks for users, facilitating data analysis.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GRAPH COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach utilizes different graph communities (C0, C1, C2, C3) to structure and summarize data for answering user queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="PODCAST DATASET">
      <data key="d4">7.0</data>
      <data key="d5">The Podcast dataset is used in the evaluation of the Graph RAG approach, contributing to the analysis of its effectiveness.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="NEWS DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The News dataset is used in the evaluation of the Graph RAG approach, contributing to the analysis of its effectiveness.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="KNOWLEDGE GRAPHS">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach utilizes knowledge graphs to enhance data processing and reasoning capabilities.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="NATURAL MODULARITY">
      <data key="d4">7.0</data>
      <data key="d5">The Graph RAG approach leverages natural modularity to effectively partition data for summarization.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="SOURCE TEXTS">
      <data key="d4">8.0</data>
      <data key="d5">Source texts are the foundational data that the Graph RAG approach processes for analysis.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="SENSEMAKING QUESTIONS">
      <data key="d4">6.0</data>
      <data key="d5">Sensemaking questions guide the analysis process within the Graph RAG approach, helping to extract insights from data.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GRAPH-FREE APPROACH">
      <data key="d4">5.0</data>
      <data key="d5">The Graph RAG approach is compared to the graph-free approach, which summarizes source texts without graph structures.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="OPEN-SOURCE IMPLEMENTATION">
      <data key="d4">9.0</data>
      <data key="d5">An open-source implementation of the Graph RAG approach allows users to access and modify the techniques used.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d4">8.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="AMBER HOAK">
      <data key="d4">8.0</data>
      <data key="d5">Amber Hoak contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d4">8.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="BEN CUTLER">
      <data key="d4">8.0</data>
      <data key="d5">Ben Cutler contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="BILLIE RINALDI">
      <data key="d4">8.0</data>
      <data key="d5">Billie Rinaldi contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="CHRIS SANCHEZ">
      <data key="d4">8.0</data>
      <data key="d5">Chris Sanchez contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="CHRIS TREVI&#209;O">
      <data key="d4">8.0</data>
      <data key="d5">Chris Trevi&#241;o contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="CHRISTINE CAGGIANO">
      <data key="d4">8.0</data>
      <data key="d5">Christine Caggiano contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="DAVID TITTSWORTH">
      <data key="d4">8.0</data>
      <data key="d5">David Tittsworth contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="DAYENNE DE SOUZA">
      <data key="d4">8.0</data>
      <data key="d5">Dayenne de Souza contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="DOUGLAS ORBAKER">
      <data key="d4">8.0</data>
      <data key="d5">Douglas Orbaker contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="ED CLARK">
      <data key="d4">8.0</data>
      <data key="d5">Ed Clark contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GABRIEL NIEVES-PONCE">
      <data key="d4">8.0</data>
      <data key="d5">Gabriel Nieves-Ponce contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="GAUDY BLANCO MENES">
      <data key="d4">8.0</data>
      <data key="d5">Gaudy Blanco Meneses contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="KATE LYTVYNETS">
      <data key="d4">8.0</data>
      <data key="d5">Kate Lytvynets contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="KATY SMITH">
      <data key="d4">8.0</data>
      <data key="d5">Katy Smith contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="M&#211;NICA CARVAJAL">
      <data key="d4">8.0</data>
      <data key="d5">M&#243;nica Carvajal contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="NATHAN EVANS">
      <data key="d4">8.0</data>
      <data key="d5">Nathan Evans contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="RICHARD ORTEGA">
      <data key="d4">8.0</data>
      <data key="d5">Richard Ortega contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="RODRIGO RACANICCI">
      <data key="d4">8.0</data>
      <data key="d5">Rodrigo Racanicci contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="SARAH SMITH">
      <data key="d4">8.0</data>
      <data key="d5">Sarah Smith contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG APPROACH" target="SHANE SOLOMON">
      <data key="d4">1.0</data>
      <data key="d5">Shane Solomon contributed to the development of the Graph RAG approach.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="GLOBAL SENSEMAKING">
      <data key="d4">7.0</data>
      <data key="d5">Query-focused summarization is a key component of global sensemaking, as it helps derive insights from large datasets based on specific queries.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="TEXT CHUNKS">
      <data key="d4">7.0</data>
      <data key="d5">Text chunks are derived from source documents for further processing in the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are used to generate the global answer for user queries, synthesizing information from various levels of the community structure.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GRAPH RAG">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are generated as part of the Graph RAG approach to enhance the quality of responses.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="DARREN EDGE">
      <data key="d4">8.0</data>
      <data key="d5">Darren Edge is a researcher at Microsoft Research, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="HA TRINH">
      <data key="d4">8.0</data>
      <data key="d5">Ha Trinh is a researcher at Microsoft Research, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="JONATHAN LARSON">
      <data key="d4">1.0</data>
      <data key="d5">Jonathan Larson is a researcher at Microsoft Research, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES" target="NEWMAN CHENG">
      <data key="d4">8.0</data>
      <data key="d5">Newman Cheng is a researcher at Microsoft Strategic Missions and Technologies, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES" target="JOSHUA BRADLEY">
      <data key="d4">8.0</data>
      <data key="d5">Joshua Bradley is a researcher at Microsoft Strategic Missions and Technologies, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES" target="STEVEN TRUITT">
      <data key="d4">8.0</data>
      <data key="d5">Steven Truitt is a researcher at Microsoft Strategic Missions and Technologies, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT OFFICE OF THE CTO" target="ALEX CHAO">
      <data key="d4">8.0</data>
      <data key="d5">Alex Chao is a researcher at Microsoft Office of the CTO, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT OFFICE OF THE CTO" target="APURVA MODY">
      <data key="d4">8.0</data>
      <data key="d5">Apurva Mody is a researcher at Microsoft Office of the CTO, contributing to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="LEIDEN ALGORITHM">
      <data key="d4">6.0</data>
      <data key="d5">Community detection can be performed using the Leiden algorithm, which is known for its effectiveness in identifying clusters within data.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="FORTUNATO S. (2010)">
      <data key="d4">7.0</data>
      <data key="d5">Fortunato S. (2010) provides foundational knowledge on community detection in graphs, relevant to network analysis.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LEIDEN ALGORITHM" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">The Leiden algorithm is a specific type of community detection algorithm used for efficiently partitioning graphs.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="NAMED ENTITIES">
      <data key="d4">8.0</data>
      <data key="d5">The LLM is used to extract named entities from text, identifying specific categories of information like people and organizations.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="FEW-SHOT EXAMPLES">
      <data key="d4">7.0</data>
      <data key="d5">Few-shot examples are provided to the LLM to enhance its ability to extract relevant information in specialized domains.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="EXTRACTION PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">The extraction prompt guides the LLM in identifying and extracting relevant information from the text.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="GLEANINGS">
      <data key="d4">7.0</data>
      <data key="d5">The LLM performs gleanings to ensure that all relevant entities are extracted, even those missed in previous attempts.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="ABSTRACTIVE SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">The LLM utilizes abstractive summarization to create meaningful summaries of entities and relationships from the text.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="ENTITY GRAPH">
      <data key="d4">8.0</data>
      <data key="d5">The LLM contributes to the creation of an entity graph by extracting and summarizing relationships between entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="MULTIHOP-RAG DATASET">
      <data key="d4">7.0</data>
      <data key="d5">The MultiHop-RAG dataset is utilized by the LLM for testing and evaluating the performance of the Graph RAG approach.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="GRAPH INDEX">
      <data key="d4">8.0</data>
      <data key="d5">The LLM contributes to the creation of a graph index by extracting and summarizing relationships between entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="USER">
      <data key="d4">9.0</data>
      <data key="d5">The LLM interacts with users to generate questions based on dataset descriptions, aiding in their tasks.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="LLM" target="GRAPH RAG">
      <data key="d4">9.0</data>
      <data key="d5">The Graph RAG approach utilizes LLMs to process and generate summaries from text data effectively.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="TEXT CHUNKS" target="HOTPOTQA">
      <data key="d4">6.0</data>
      <data key="d5">Text chunks are evaluated using the HotPotQA dataset to measure the effectiveness of entity reference detection.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="TEXT CHUNKS" target="SS">
      <data key="d4">8.0</data>
      <data key="d5">The SS method retrieves text chunks to build context for answering queries, adding them until a token limit is reached.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="KURATOV ET AL. (2024)" target="LATS">
      <data key="d4">10.0</data>
      <data key="d5">Kuratov et al. (2024) provides insights relevant to the performance of the LATS algorithm.
Kuratov et al. (2024) provides insights relevant to the performance of LATS in processing text chunks and decision-making.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LIU ET AL. (2023)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">1.0</data>
      <data key="d5">Liu et al. (2023) examines the integration of search algorithms with language model agents, contributing to the understanding of their capabilities.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LIU ET AL. (2023)" target="SEARCH SPACE">
      <data key="d4">5.0</data>
      <data key="d5">Liu et al. (2023) explores various designs of search spaces applicable to agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="HOTPOTQA" target="LATS">
      <data key="d4">58.0</data>
      <data key="d5">LATS has been empirically evaluated on the HotPotQA dataset, demonstrating its effectiveness in question-answering tasks.
LATS is evaluated on the HotPotQA benchmark to demonstrate its effectiveness in reasoning and acting tasks.
LATS is evaluated on the HotPotQA dataset to measure its effectiveness in answering complex questions.
LATS is tested on HotPotQA to assess its performance in complex question-answering scenarios.
LATS is evaluated using the HotPotQA dataset for reasoning tasks in language models.
LATS is evaluated using the HotPotQA dataset to assess its performance in answering complex questions that require reasoning over multiple documents.
LATS is evaluated using the HotPotQA dataset to assess its performance in multi-hop reasoning tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HOTPOTQA" target="GPT-3.5">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5 is evaluated on the HotpotQA dataset to measure its reasoning capabilities and performance in tasks.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="HOTPOTQA" target="API CALLS">
      <data key="d4">7.0</data>
      <data key="d5">In the context of HotPotQA, API calls are utilized to enhance the agent's ability to retrieve information for answering questions.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="HOTPOTQA" target="YANG ET AL. (2018)">
      <data key="d4">8.0</data>
      <data key="d5">Yang et al. (2018) is a foundational reference for the HotPotQA benchmark, discussing its design and evaluation.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="MODULARITY">
      <data key="d4">1.0</data>
      <data key="d5">Modularity is a key concept in community detection algorithms, influencing how graphs are partitioned into communities.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="ENTITY GRAPH">
      <data key="d4">7.0</data>
      <data key="d5">Community detection algorithms analyze the entity graph to identify groups of closely related nodes.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="HIERARCHICAL CLUSTERING">
      <data key="d4">1.0</data>
      <data key="d5">Hierarchical clustering is a technique used within community detection algorithms to organize nodes into a hierarchy.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="BROWN ET AL. (2020)" target="LANGUAGE MODELS">
      <data key="d4">7.0</data>
      <data key="d5">Brown et al. (2020) discusses the capabilities of language models, establishing their role in few-shot learning.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN ET AL. (2020)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">5.0</data>
      <data key="d5">Brown et al. (2020) discusses the capabilities of language models, which are utilized in LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="TOUVRON ET AL. (2023)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">5.0</data>
      <data key="d5">Touvron et al. (2023) discusses advancements in language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="NAMED ENTITIES" target="COVARIATES">
      <data key="d4">6.0</data>
      <data key="d5">Covariates are linked to named entities, providing additional context and attributes related to those entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="NAMED ENTITIES" target="CLAIMS">
      <data key="d4">1.0</data>
      <data key="d5">Claims are associated with named entities, providing context and additional information relevant to those entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COVARIATES" target="NODES">
      <data key="d4">7.0</data>
      <data key="d5">Covariates provide additional context to nodes, enhancing the understanding of their significance within the community structure.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="GLOBAL SUMMARIZATION" target="GRAPH INDEX">
      <data key="d4">7.0</data>
      <data key="d5">Global summarization utilizes the graph index to provide comprehensive insights into the dataset's structure and semantics.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="NODE" target="EDGE">
      <data key="d4">8.0</data>
      <data key="d5">Nodes are connected by edges in a graph, illustrating the relationships between different entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="HIGHER-LEVEL COMMUNITIES">
      <data key="d4">7.0</data>
      <data key="d5">Leaf-level communities serve as the foundational elements that contribute to the summaries of higher-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="LLM CONTEXT WINDOW">
      <data key="d4">8.0</data>
      <data key="d5">The LLM context window limits the amount of information that can be processed from leaf-level communities at one time.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="HIGHER-LEVEL COMMUNITIES" target="SUB-COMMUNITIES">
      <data key="d4">1.0</data>
      <data key="d5">Sub-communities are components of higher-level communities, contributing to the overall structure and summaries generated from them.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="USER QUERY">
      <data key="d4">8.0</data>
      <data key="d5">A user query initiates the process of generating a global answer based on community summaries.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="DATASET EXAMPLES" target="PODCAST TRANSCRIPTS">
      <data key="d4">6.0</data>
      <data key="d5">Dataset examples illustrate potential user tasks and questions derived from podcast transcripts.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="DATASET EXAMPLES" target="NEWS ARTICLES">
      <data key="d4">6.0</data>
      <data key="d5">Dataset examples illustrate potential user tasks and questions derived from news articles.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="DATASET EXAMPLES" target="EVALUATION">
      <data key="d4">1.0</data>
      <data key="d5">Evaluation assesses the effectiveness of the generated questions based on dataset examples.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NODES" target="EDGES">
      <data key="d4">9.0</data>
      <data key="d5">Nodes are connected by edges, forming the fundamental structure of a community and representing relationships between entities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="USER" target="TASK">
      <data key="d4">8.0</data>
      <data key="d5">Users perform tasks that involve generating questions and analyzing datasets using the LLM.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="USER" target="CREATE MEAL PLAN">
      <data key="d4">9.0</data>
      <data key="d5">The User requests the creation of a meal plan based on their dietary preferences and caloric goals.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="UPDATE FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The User requests an update to the calorie count for 'Chana Masala', which is facilitated by the Update Food Item API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="TRACK USER MEAL">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to track their daily meals, which is facilitated by the Track User Meal API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="GET DIETARY RECOMMENDATIONS">
      <data key="d4">8.0</data>
      <data key="d5">The User is interested in receiving new food recommendations, which is provided by the Get Dietary Recommendations API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="ADD NEW FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to add a new recipe (Quinoa Salad) to the database, which is done through the Add New Food Item API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="DELETE FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to remove 'Butter Chicken' from their list, which is done through the Delete Food Item API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="GET USER NUTRITIONAL STATS">
      <data key="d4">8.0</data>
      <data key="d5">The User wants to see their nutritional summary at the end of the week, which is retrieved by the Get User Nutritional Stats API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="ASSISTANT">
      <data key="d4">1.0</data>
      <data key="d5">The Assistant interacts with the User to help them achieve their dietary goals using various APIs.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="CALORIC GOAL">
      <data key="d4">8.0</data>
      <data key="d5">The User has a specific caloric goal of 1500 calories per day as part of their diet plan.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="DIETARY PREFERENCES">
      <data key="d4">8.0</data>
      <data key="d5">The User has specified dietary preferences, indicating they prefer vegetarian meals.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="MEAL PLAN">
      <data key="d4">9.0</data>
      <data key="d5">The User requests a meal plan that includes three meals a day based on their dietary preferences and caloric goal.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="NUTRITIONAL SUMMARY">
      <data key="d4">1.0</data>
      <data key="d5">The User wants to see a nutritional summary at the end of the week to assess their dietary adherence.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="VEGETARIAN MEAL PLAN">
      <data key="d4">8.0</data>
      <data key="d5">The user requested the creation of a vegetarian meal plan tailored to their caloric needs.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="USER" target="QUINOA SALAD">
      <data key="d4">6.0</data>
      <data key="d5">The user is involved in the process of adding the Quinoa Salad recipe to the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="USER" target="CHANA MASALA">
      <data key="d4">6.0</data>
      <data key="d5">The user is involved in updating the Chana Masala recipe in the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="USER" target="BUTTER CHICKEN">
      <data key="d4">6.0</data>
      <data key="d5">The user is involved in the process of removing the Butter Chicken recipe from the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="TASK" target="QUESTION">
      <data key="d4">7.0</data>
      <data key="d5">Tasks often result in the generation of questions that require understanding of the dataset for effective answers.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TASK" target="BRAIN TEASER">
      <data key="d4">6.0</data>
      <data key="d5">Brain teasers are examples of problems generated through the workflows that require logical thinking to solve.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TASK" target="FERMI PROBLEMS">
      <data key="d4">6.0</data>
      <data key="d5">Fermi problems are examples of estimation tasks that can be generated through the workflows in the agentic flows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="QUESTION" target="EVALUATION METRICS">
      <data key="d4">6.0</data>
      <data key="d5">Evaluation metrics are used to assess the quality of the questions generated by the LLM and the answers provided.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="QUESTION" target="OPTIONS">
      <data key="d4">9.0</data>
      <data key="d5">The question is associated with the options provided, which are the possible answers to the question.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="QUESTION" target="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">7.0</data>
      <data key="d5">The Maths GPT-4 Extraction System Message is used to evaluate the correctness of the answer to the question posed.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="QUESTION" target="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d4">7.0</data>
      <data key="d5">The General Extraction System Message is used to parse the student's response to the question and determine correctness.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EVALUATION METRICS" target="COMPREHENSIVENESS">
      <data key="d4">7.0</data>
      <data key="d5">Comprehensiveness is one of the evaluation metrics used to measure the quality of answers generated by the LLM.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION METRICS" target="DIVERSITY">
      <data key="d4">7.0</data>
      <data key="d5">Diversity is another evaluation metric that assesses the variety of answers generated by the LLM.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION METRICS" target="EMPOWERMENT">
      <data key="d4">7.0</data>
      <data key="d5">Empowerment is an evaluation metric that measures how well answers help users understand topics.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION METRICS" target="DIRECTNESS">
      <data key="d4">1.0</data>
      <data key="d5">Directness is an evaluation metric that assesses how clearly answers address the questions posed.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION METRICS" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Evaluation metrics are used in the Meta Agent Search to measure the performance of generated agents during the evaluation phase.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="GRAPH RAG">
      <data key="d4">9.0</data>
      <data key="d5">The Graph RAG approach aims to improve comprehensiveness in responses as one of its key performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIVERSITY" target="GRAPH RAG">
      <data key="d4">9.0</data>
      <data key="d5">The Graph RAG approach aims to improve diversity in responses as one of its key performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIVERSITY" target="AGENTIC FLOWS">
      <data key="d4">8.0</data>
      <data key="d5">Diversity is a key objective of agentic flows, aimed at ensuring a wide range of generated problems and instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="EMPOWERMENT" target="GRAPH RAG">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach aims to enhance empowerment in responses as one of its key performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIRECTNESS" target="GRAPH RAG">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach aims to improve directness in responses as one of its key performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C0" target="C1">
      <data key="d4">7.0</data>
      <data key="d5">C1 serves as a sub-community of C0, providing more detailed summaries for answering user queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="C0" target="GRAPH RAG">
      <data key="d4">7.0</data>
      <data key="d5">C0 is one of the conditions evaluated in the Graph RAG approach to assess performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C1" target="C2">
      <data key="d4">7.0</data>
      <data key="d5">C2 serves as a sub-community of C1, providing further granularity in summarization for answering queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="C1" target="GRAPH RAG">
      <data key="d4">7.0</data>
      <data key="d5">C1 is one of the conditions evaluated in the Graph RAG approach to assess performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C2" target="C3">
      <data key="d4">7.0</data>
      <data key="d5">C3 serves as a sub-community of C2, offering the most detailed summaries for answering user queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="C2" target="GRAPH RAG">
      <data key="d4">7.0</data>
      <data key="d5">C2 is one of the conditions evaluated in the Graph RAG approach to assess performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="C3" target="GRAPH RAG">
      <data key="d4">7.0</data>
      <data key="d5">C3 is one of the conditions evaluated in the Graph RAG approach to assess performance metrics.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="TS" target="SOURCE TEXTS">
      <data key="d4">8.0</data>
      <data key="d5">The TS method applies a map-reduce approach to source texts, shuffling and chunking them for summarization stages.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TS" target="GRAPH RAG">
      <data key="d4">8.0</data>
      <data key="d5">TS is used as a baseline for comparison against the Graph RAG conditions in performance evaluations.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="PODCAST DATASET" target="GRAPH RAG">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach is applied to the Podcast dataset to evaluate its performance in summarization and response quality.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="NEWS DATASET" target="GRAPH RAG">
      <data key="d4">8.0</data>
      <data key="d5">The Graph RAG approach is applied to the News dataset to evaluate its performance in summarization and response quality.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="TAYLOR SWIFT" target="PUBLIC FIGURES">
      <data key="d4">9.0</data>
      <data key="d5">Taylor Swift is a public figure frequently mentioned in entertainment articles due to her influence and popularity in the music industry.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="TRAVIS KELCE" target="PUBLIC FIGURES">
      <data key="d4">9.0</data>
      <data key="d5">Travis Kelce is a public figure frequently mentioned in entertainment articles due to his achievements in sports and cultural relevance.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="PUBLIC FIGURES">
      <data key="d4">9.0</data>
      <data key="d5">Britney Spears is a public figure frequently mentioned in entertainment articles, often due to her music career and personal life controversies.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="PUBLIC FIGURES">
      <data key="d4">9.0</data>
      <data key="d5">Justin Timberlake is a public figure frequently mentioned in entertainment articles for his contributions to music and entertainment.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ENTERTAINMENT ARTICLES">
      <data key="d4">1.0</data>
      <data key="d5">Public figures are often the subjects of entertainment articles, highlighting their influence and relevance in popular culture.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ATHLETES">
      <data key="d4">8.0</data>
      <data key="d5">Athletes are often considered public figures due to their visibility and influence in sports and entertainment.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="COACHES">
      <data key="d4">7.0</data>
      <data key="d5">Coaches can also be public figures, especially when they gain recognition for their leadership and impact on athletes and teams.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="INFLUENCERS">
      <data key="d4">9.0</data>
      <data key="d5">Influencers are public figures who shape trends and opinions through their platforms and reach.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ENTREPRENEURS">
      <data key="d4">8.0</data>
      <data key="d5">Entrepreneurs often become public figures as they influence markets and cultural trends through their businesses.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="CULTURAL NARRATIVES">
      <data key="d4">9.0</data>
      <data key="d5">Public figures play a significant role in shaping cultural narratives through their actions and public personas.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="SOCIAL DISCUSSIONS">
      <data key="d4">1.0</data>
      <data key="d5">Public figures often become central to social discussions, influencing public opinion and discourse.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="GRAPH RAG" target="CONTEXT WINDOW SIZE">
      <data key="d4">7.0</data>
      <data key="d5">The context window size is a critical parameter that affects the performance of the Graph RAG approach in processing text data.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="WIN RATE">
      <data key="d4">9.0</data>
      <data key="d5">Win rate is a key performance metric used to evaluate the effectiveness of the Graph RAG approach across different conditions.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="TOKEN COUNT">
      <data key="d4">8.0</data>
      <data key="d5">Token count is a metric that influences the performance and efficiency of the Graph RAG approach in processing data.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY SUMMARY LEVEL">
      <data key="d4">1.0</data>
      <data key="d5">Community summary levels are utilized in the Graph RAG approach to organize and evaluate the generated summaries.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="SOURCE TEXT SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG is a more efficient alternative to source text summarization, requiring fewer tokens while maintaining performance.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="PODCAST INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Podcast intermediate-level summaries are generated using the Graph RAG approach, which enhances their efficiency.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWS LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">News low-level community summaries are produced through the Graph RAG method, showcasing its application in diverse contexts.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="EMPOWERMENT COMPARISONS">
      <data key="d4">6.0</data>
      <data key="d5">Empowerment comparisons evaluate the effectiveness of the Graph RAG method in aiding user understanding compared to other approaches.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="SELF-MEMORY">
      <data key="d4">7.0</data>
      <data key="d5">Self-memory is a concept integrated into the Graph RAG approach to enhance the retrieval and generation process.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="GENERATING HIERARCHICAL INDEX">
      <data key="d4">8.0</data>
      <data key="d5">Generating a hierarchical index is a technique employed within the Graph RAG framework to improve summarization efficiency.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="KNOWLEDGE GRAPH">
      <data key="d4">7.0</data>
      <data key="d5">Knowledge graphs are utilized in the Graph RAG approach to enhance the organization and retrieval of information.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="EMPOWERMENT COMPARISONS" target="AD-HOC LLM USE">
      <data key="d4">5.0</data>
      <data key="d5">Ad-hoc LLM use is analyzed in the context of empowerment comparisons to assess its impact on user comprehension.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="TRAJANOSKA, M.">
      <data key="d4">7.0</data>
      <data key="d5">Trajanoska, M. co-authored a paper on enhancing knowledge graph construction using large language models.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="TRIVEDI, H.">
      <data key="d4">6.0</data>
      <data key="d5">Trivedi, H. co-authored a paper on interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions, relevant to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="WANG, S.">
      <data key="d4">6.0</data>
      <data key="d5">Wang, S. co-authored a paper evaluating federated search in the context of retrieval-augmented generation, which relates to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="YAO, L.">
      <data key="d4">8.0</data>
      <data key="d5">Yao, L. co-authored a paper exploring large language models for knowledge graph completion, directly related to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="ZHANG, Y.">
      <data key="d4">7.0</data>
      <data key="d5">Zhang, Y. co-authored a paper on causal graph discovery with retrieval-augmented generation based large language models, relevant to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="LI, Z.">
      <data key="d4">8.0</data>
      <data key="d5">Li, Z. co-authored a paper on knowledge graph prompting for multi-document question answering, directly related to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="DERR, T.">
      <data key="d4">8.0</data>
      <data key="d5">Derr, T. co-authored a paper on knowledge graph prompting for multi-document question answering, directly related to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="ZHANG, R.">
      <data key="d4">8.0</data>
      <data key="d5">Zhang, R. co-authored a paper on knowledge graph prompting for multi-document question answering, directly related to knowledge graphs.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="GRAPH DATABASES" target="LANGCHAIN">
      <data key="d4">6.0</data>
      <data key="d5">LangChain supports the use of graph databases, facilitating the integration of graph structures in applications utilizing LLMs.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH DATABASES" target="LLAMAINDEX">
      <data key="d4">1.0</data>
      <data key="d5">LlamaIndex provides support for graph databases, enabling efficient management of graph-based data in LLM applications.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="LANGCHAIN" target="NEO4J">
      <data key="d4">7.0</data>
      <data key="d5">LangChain is involved in projects related to Neo4J, particularly in graph-based applications.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LANGCHAIN" target="NEBULAGRAPH">
      <data key="d4">14.0</data>
      <data key="d5">NebulaGraph's graph-based retrieval-augmented generation system is relevant to LangChain's functionalities.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LANGCHAIN" target="SEARCH SPACE">
      <data key="d4">7.0</data>
      <data key="d5">LangChain provides a framework that allows for the exploration of search spaces in building agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LANGCHAIN" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">LangChain provides essential tools that can enhance the development of ADAS by facilitating the integration of language models.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="YAO ET AL. (2023)" target="REACT">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. (2023) discusses the ReAct technique and its applications in enhancing language model performance.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="YAO ET AL. (2023)" target="LATS">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. (2023) provides insights relevant to the performance of LATS in various tasks.
Yao et al. (2023) discusses the Wikipedia web API, which is integral to the functioning of LATS in its information retrieval tasks.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="ZHANG ET AL. (2024)" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Zhang et al. (2024) contributes to ADAS by discussing AgentOptimizer and its role in learning tools for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="WANG ET AL. (2023)" target="LATS">
      <data key="d4">6.0</data>
      <data key="d5">LATS is connected to the adaptation of language models in interactive environments as discussed by Wang et al. (2023).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHENG ET AL. (2024)" target="RETRIEVAL-AUGMENTED TEXT GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Cheng et al. (2024) explores retrieval-augmented text generation, contributing to advancements in this area.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DANG H. T. (2006)" target="QUESTION-FOCUSED SUMMARIZATION">
      <data key="d4">6.0</data>
      <data key="d5">Dang H. T. (2006) evaluates systems focused on summarization, relevant to the field of question-focused summarization.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="ES ET AL. (2023)" target="AUTOMATED EVALUATION">
      <data key="d4">7.0</data>
      <data key="d5">Es et al. (2023) provides insights into automated evaluation methods for retrieval-augmented generation.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="FENG ET AL. (2023)" target="RETRIEVAL-GENERATION SYNERGY">
      <data key="d4">8.0</data>
      <data key="d5">Feng et al. (2023) discusses the synergy between retrieval and generation in large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GAO ET AL. (2023)" target="SURVEY ON RETRIEVAL-AUGMENTED GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Gao et al. (2023) surveys the landscape of retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GAO ET AL. (2023)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">5.0</data>
      <data key="d5">Gao et al. (2023) discusses prompting techniques for language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="GOODWIN ET AL. (2020)" target="TRANSFORMERS">
      <data key="d4">7.0</data>
      <data key="d5">Goodwin et al. (2020) compares transformers, contributing to the understanding of their performance in summarization tasks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="HE ET AL. (2024)" target="TEXTUAL GRAPH UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">He et al. (2024) focuses on retrieval-augmented generation for understanding textual graphs, linking retrieval and comprehension.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="JACOMY ET AL. (2014)" target="GRAPH LAYOUT ALGORITHM">
      <data key="d4">6.0</data>
      <data key="d5">Jacomy et al. (2014) discusses a graph layout algorithm, relevant for visualizing network data.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="JIN ET AL. (2021)" target="COMMUNITY DETECTION APPROACHES">
      <data key="d4">7.0</data>
      <data key="d5">Jin et al. (2021) surveys community detection methods, contributing to the understanding of this field.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KANG ET AL. (2023)" target="KNOWLEDGE-GROUNDED DIALOGUE">
      <data key="d4">8.0</data>
      <data key="d5">Kang et al. (2023) explores knowledge graph-augmented models for dialogue generation, linking knowledge and dialogue.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KHATTAB ET AL. (2022)" target="RETRIEVAL AND LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Khattab et al. (2022) discusses the integration of retrieval and language models, relevant for knowledge-intensive NLP tasks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KIM ET AL. (2023)" target="AMBIGUOUS QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Kim et al. (2023) addresses the challenge of answering ambiguous questions using retrieval-augmented models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KLEIN ET AL. (2006)" target="SENSEMAKING">
      <data key="d4">6.0</data>
      <data key="d5">Klein et al. (2006) provides perspectives on sensemaking, contributing to cognitive models in understanding information.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KOESTEN ET AL. (2021)" target="DATA SENSEMAKING">
      <data key="d4">1.0</data>
      <data key="d5">Koesten et al. (2021) investigates behaviors related to data sensemaking, relevant for human-computer interaction studies.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="PAL">
      <data key="d4">8.0</data>
      <data key="d5">PAL aims to enhance large language models through programmatic assistance, improving their capabilities.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="AGENTBENCH">
      <data key="d4">8.0</data>
      <data key="d5">AgentBench evaluates large language models as agents, assessing their performance in various tasks.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="DUAL-PROCESS PERSPECTIVE">
      <data key="d4">1.0</data>
      <data key="d5">The dual-process perspective can be applied to understand reasoning in large language models, linking cognitive theories to AI.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="LIMITATIONS" target="LATS">
      <data key="d4">6.0</data>
      <data key="d5">Limitations highlight the challenges faced by the LATS algorithm in its application to decision-making tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LIMITATIONS" target="RAG">
      <data key="d4">1.0</data>
      <data key="d5">RAG techniques face various limitations, including biases and challenges in synthetic data generation.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="KOESTEN, L." target="GREGORY, K.">
      <data key="d4">8.0</data>
      <data key="d5">L. Koesten and K. Gregory co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KOESTEN, L." target="GROTH, P.">
      <data key="d4">8.0</data>
      <data key="d5">L. Koesten and P. Groth co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KOESTEN, L." target="SIMPURL, E.">
      <data key="d4">8.0</data>
      <data key="d5">L. Koesten and E. Simperl co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="GREGORY, K." target="GROTH, P.">
      <data key="d4">8.0</data>
      <data key="d5">K. Gregory and P. Groth co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="GREGORY, K." target="SIMPURL, E.">
      <data key="d4">8.0</data>
      <data key="d5">K. Gregory and E. Simperl co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="GROTH, P." target="SIMPURL, E.">
      <data key="d4">8.0</data>
      <data key="d5">P. Groth and E. Simperl co-authored a study on data sensemaking behaviors in human-computer interaction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV, Y." target="BULATOV, A.">
      <data key="d4">8.0</data>
      <data key="d5">Y. Kuratov and A. Bulatov co-authored a study on the limitations of large language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV, Y." target="ANOKHIN, P.">
      <data key="d4">8.0</data>
      <data key="d5">Y. Kuratov and P. Anokhin co-authored a study on the limitations of large language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV, Y." target="SOROKIN, D.">
      <data key="d4">8.0</data>
      <data key="d5">Y. Kuratov and D. Sorokin co-authored a study on the limitations of large language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV, Y." target="SOROKIN, A.">
      <data key="d4">8.0</data>
      <data key="d5">Y. Kuratov and A. Sorokin co-authored a study on the limitations of large language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="KURATOV, Y." target="BURTSEV, M.">
      <data key="d4">8.0</data>
      <data key="d5">Y. Kuratov and M. Burtsev co-authored a study on the limitations of large language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="HOQUE, E.">
      <data key="d4">16.0</data>
      <data key="d5">M. T. R. Laskar and E. Hoque co-authored studies on query-focused abstractive summarization.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="HUANG, J.">
      <data key="d4">16.0</data>
      <data key="d5">M. T. R. Laskar and J. Huang co-authored studies on query-focused abstractive summarization.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LASKAR, M. T. R." target="SU, D.">
      <data key="d4">2.0</data>
      <data key="d5">D. Su and M. T. R. Laskar co-authored a study on question answering and multi-document summarization.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="HOQUE, E." target="HUANG, J.">
      <data key="d4">16.0</data>
      <data key="d5">E. Hoque and J. Huang co-authored studies on query-focused abstractive summarization.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="PEREZ, E.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and E. Perez co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="PIKTUS, A.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and A. Piktus co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="PETRONI, F.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and F. Petroni co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="KARPUKHIN, V.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and V. Karpukhin co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="GOYAL, N.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and N. Goyal co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="K&#220;TTLER, H.">
      <data key="d4">16.0</data>
      <data key="d5">P. Lewis and H. K&#252;ttler co-authored a study on retrieval-augmented generation for NLP tasks.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="RAM, O.">
      <data key="d4">16.0</data>
      <data key="d5">O. Ram and P. Lewis co-authored a study on in-context retrieval-augmented language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="LEWIS, P." target="SHAO, Z.">
      <data key="d4">16.0</data>
      <data key="d5">Z. Shao and P. Lewis co-authored a study on enhancing retrieval-augmented language models.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="RANADE, P." target="SARTHI, P.">
      <data key="d4">16.0</data>
      <data key="d5">P. Ranade and P. Sarthi co-authored a study on retrieval-augmented narrative construction.</data>
      <data key="d6">df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="SU, D." target="XU, Y.">
      <data key="d4">8.0</data>
      <data key="d5">Su, D. and Xu, Y. co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SU, D." target="BAREZI, E. J.">
      <data key="d4">8.0</data>
      <data key="d5">Su, D. and Barezi, E. J. co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SU, D." target="SIDDIQUE, F. B.">
      <data key="d4">8.0</data>
      <data key="d5">Su, D. and Siddique, F. B. co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SU, D." target="FUNG, P.">
      <data key="d4">8.0</data>
      <data key="d5">Su, D. and Fung, P. co-authored a paper on Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="DUAN, N." target="CHEN, W.">
      <data key="d4">8.0</data>
      <data key="d5">Duan, N. and Chen, W. co-authored a paper on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="YANG, Y." target="TANG, Y.">
      <data key="d4">8.0</data>
      <data key="d5">Yang, Y. and Tang, Y. co-authored a paper on MultiHop-RAG, benchmarking retrieval-augmented generation for multi-hop queries.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TOUVRON, H." target="MARTIN, L.">
      <data key="d4">8.0</data>
      <data key="d5">Touvron, H. and Martin, L. co-authored a paper on Llama 2, which includes open foundation and fine-tuned chat models.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, J." target="CHATGPT">
      <data key="d4">7.0</data>
      <data key="d5">Wang, J. co-authored a preliminary study on whether ChatGPT is a good NLG evaluator, indicating its relevance in natural language generation.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, S." target="KRAMTSOVA, E.">
      <data key="d4">8.0</data>
      <data key="d5">Khramtsova, E. and Wang, S. co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, S." target="ZHUANG, S.">
      <data key="d4">8.0</data>
      <data key="d5">Zhuang, S. and Wang, S. co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, S." target="ZUCCON, G.">
      <data key="d4">1.0</data>
      <data key="d5">Zuccon, G. and Wang, S. co-authored a paper on evaluating federated search in the context of retrieval-augmented generation.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ZHANG, J." target="CHATGPT">
      <data key="d4">7.0</data>
      <data key="d5">Zhang, J. co-authored a paper on Graph-toolformer, which empowers LLMs with graph reasoning ability via prompts augmented by ChatGPT.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ZHENG, L." target="CHATGPT">
      <data key="d4">1.0</data>
      <data key="d5">Zheng, L. co-authored a paper judging LLMs as judges with MT-bench and Chatbot Arena, which involves ChatGPT.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LLAMA 2" target="HUGO TOUVRON">
      <data key="d4">8.0</data>
      <data key="d5">Hugo Touvron is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="LOUIS MARTIN">
      <data key="d4">8.0</data>
      <data key="d5">Louis Martin is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="KEVIN R. STONE">
      <data key="d4">8.0</data>
      <data key="d5">Kevin R. Stone is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="PETER ALBERT">
      <data key="d4">8.0</data>
      <data key="d5">Peter Albert is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="AMJAD ALMAHAIRI">
      <data key="d4">8.0</data>
      <data key="d5">Amjad Almahairi is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="YASMINE BABAIE">
      <data key="d4">8.0</data>
      <data key="d5">Yasmine Babaie is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="NIKOLAY BASHLYKOV">
      <data key="d4">8.0</data>
      <data key="d5">Nikolay Bashlykov is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="SOUMYA BATRA">
      <data key="d4">8.0</data>
      <data key="d5">Soumya Batra is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="PRAJJWAL BHARGAVA">
      <data key="d4">8.0</data>
      <data key="d5">Prajjwal Bhargava is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="SHRUTI BHOSALE">
      <data key="d4">8.0</data>
      <data key="d5">Shruti Bhosale is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="DANIEL M. BIKEL">
      <data key="d4">8.0</data>
      <data key="d5">Daniel M. Bikel is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="LUKAS BLECHER">
      <data key="d4">8.0</data>
      <data key="d5">Lukas Blecher is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="CRISTIAN CANT&#211;N FERRER">
      <data key="d4">8.0</data>
      <data key="d5">Cristian Cant&#243;n Ferrer is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="MOYA CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Moya Chen is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="GUILLEM CUCURULL">
      <data key="d4">8.0</data>
      <data key="d5">Guillem Cucurull is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="DAVID ESIOSU">
      <data key="d4">8.0</data>
      <data key="d5">David Esiosu is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="JUDE FERNANDES">
      <data key="d4">8.0</data>
      <data key="d5">Jude Fernandes is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="JEREMY FU">
      <data key="d4">8.0</data>
      <data key="d5">Jeremy Fu is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="WENYIN FU">
      <data key="d4">8.0</data>
      <data key="d5">Wenyin Fu is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="BRIAN FULLER">
      <data key="d4">8.0</data>
      <data key="d5">Brian Fuller is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="CYNTHIA GAO">
      <data key="d4">8.0</data>
      <data key="d5">Cynthia Gao is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="VEDANUJ GOSWAMI">
      <data key="d4">8.0</data>
      <data key="d5">Vedanuj Goswami is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="NAMAN GOYAL">
      <data key="d4">8.0</data>
      <data key="d5">Naman Goyal is involved in the development of Llama 2, contributing to advancements in language models.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="LLAMA 2" target="ANTHONY S. HARTSHORN">
      <data key="d4">1.0</data>
      <data key="d5">Anthony S. Hartshorn is involved in the development of Llama 2, contributing to advancements in language models("entity"</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="CHATGPT" target="ORCA-3">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 is evaluated against ChatGPT to demonstrate its performance improvements in the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="BENGIO, Y." target="HOTSPOTQA">
      <data key="d4">8.0</data>
      <data key="d5">Bengio, Y. co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SALAKHUTDINOV, R." target="HOTSPOTQA">
      <data key="d4">8.0</data>
      <data key="d5">Salakhutdinov, R. co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="MANNING, C. D." target="HOTSPOTQA">
      <data key="d4">8.0</data>
      <data key="d5">Manning, C. D. co-authored a paper on HotpotQA, a dataset for diverse, explainable multi-hop question answering.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="XIAO, J." target="DOCUMENT SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Xiao, J. co-authored a paper on recent advances in document summarization.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">9.0</data>
      <data key="d5">LATS utilizes language models to enhance reasoning, acting, and planning capabilities in decision-making tasks.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MONTE CARLO TREE SEARCH (MCTS)">
      <data key="d4">8.0</data>
      <data key="d5">LATS incorporates MCTS to improve decision-making processes in language models.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="EXTERNAL ENVIRONMENT">
      <data key="d4">8.0</data>
      <data key="d5">LATS leverages external feedback from the environment to enhance its decision-making capabilities.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PROGRAMMING">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated in the programming domain, demonstrating its effectiveness in coding tasks.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="INTERACTIVE QUESTION-ANSWERING (QA)">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated in the interactive QA domain, showcasing its capabilities in answering user queries.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="WEB NAVIGATION">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated in web navigation, demonstrating its ability to assist users in finding information online.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MATH">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated in the math domain, showcasing its capabilities in numerical reasoning tasks.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="HUMAN EVAL">
      <data key="d4">9.0</data>
      <data key="d5">LATS achieves state-of-the-art performance on the HumanEval benchmark for programming tasks.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GPT-4">
      <data key="d4">9.0</data>
      <data key="d5">LATS demonstrates high accuracy in programming tasks when evaluated with GPT-4.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GPT-3.5">
      <data key="d4">8.0</data>
      <data key="d5">LATS shows comparable performance in web navigation tasks when evaluated with GPT-3.5.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="REACT">
      <data key="d4">16.0</data>
      <data key="d5">LATS expands upon the ReAct technique to incorporate search over reasoning and acting steps.
LATS is evaluated against ReAct to demonstrate its enhanced performance and efficiency in decision-making tasks.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="WOOLDRIDGE AND JENNINGS (1995)">
      <data key="d4">5.0</data>
      <data key="d5">Wooldridge and Jennings' work provides foundational insights into the development of autonomous agents, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SLOMAN (1996)">
      <data key="d4">5.0</data>
      <data key="d5">Sloman (1996) discusses human-like decision-making characteristics, relevant to the design of LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="EVANS (2010)">
      <data key="d4">1.0</data>
      <data key="d5">Evans (2010) discusses human-like decision-making characteristics, relevant to the design of LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MCTS">
      <data key="d4">8.0</data>
      <data key="d5">LATS improves upon MCTS by incorporating search algorithms and external feedback for better decision-making performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="RAP">
      <data key="d4">8.0</data>
      <data key="d5">LATS is compared with RAP to showcase its advantages in terms of performance and computational efficiency.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="HOT-POTQA">
      <data key="d4">9.0</data>
      <data key="d5">LATS is evaluated using the HotPotQA dataset to assess its performance in question answering tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="LATS PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">LATS shows improved performance metrics, indicating its effectiveness in comparison to other methods like ReAct and RAP.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="NODES EXPANDED">
      <data key="d4">7.0</data>
      <data key="d5">LATS requires fewer nodes expanded compared to other methods, demonstrating its efficiency in search operations.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="TRAJECTORIES">
      <data key="d4">8.0</data>
      <data key="d5">LATS constructs trajectories to enhance its decision-making capabilities, integrating search algorithms effectively.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GROUND-TRUTH FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">LATS utilizes ground-truth feedback to improve its learning and performance in decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="COMPUTATIONAL COST">
      <data key="d4">1.0</data>
      <data key="d5">LATS has a higher computational cost compared to simpler methods, which may limit its practicality in certain situations.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="CHOWDHERY ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Chowdhery et al. (2023) discusses advancements in language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="OPENAI (2023)">
      <data key="d4">5.0</data>
      <data key="d5">OpenAI's work in language models is foundational to the development of LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="NALLAPATI ET AL. (2016)">
      <data key="d4">5.0</data>
      <data key="d5">Nallapati et al. (2016) discusses summarization tasks, showcasing capabilities of language models relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="BOWMAN ET AL. (2015)">
      <data key="d4">5.0</data>
      <data key="d5">Bowman et al. (2015) discusses language inference tasks, showcasing capabilities of language models relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="COBBE ET AL. (2021)">
      <data key="d4">5.0</data>
      <data key="d5">Cobbe et al. (2021) discusses reasoning capabilities of language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SAPAROV AND HE (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Saparov and He (2023) discusses reasoning capabilities of language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="YAO ET AL. (2022)">
      <data key="d4">5.0</data>
      <data key="d5">Yao et al. (2022) discusses web navigation tasks, showcasing capabilities of language models relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="DENG ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Deng et al. (2023) discusses web navigation tasks, showcasing capabilities of language models relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SCHICK ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Schick et al. (2023) discusses tool-use capabilities of language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="FAN ET AL. (2022)">
      <data key="d4">5.0</data>
      <data key="d5">Fan et al. (2022) discusses open-ended games, showcasing capabilities of language models relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="XIE ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Xie et al. (2023) discusses search-guided language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="YAO ET AL. (2023A)">
      <data key="d4">5.0</data>
      <data key="d5">Yao et al. (2023A) discusses search-guided language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="YAO ET AL. (2023B)">
      <data key="d4">5.0</data>
      <data key="d5">Yao et al. (2023B) discusses the ReAct technique, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SHINN ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Shinn et al. (2023) discusses prompting techniques for language models, relevant to LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="LATS">
      <data key="d4">9.0</data>
      <data key="d5">LATS enhances the performance of language models by integrating reasoning, acting, and planning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="EXTERNAL TOOLS">
      <data key="d4">9.0</data>
      <data key="d5">Language models can enhance their reasoning and practical abilities by utilizing external tools such as APIs and search engines.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="PROBLEM SETTING AND PROMPTING">
      <data key="d4">7.0</data>
      <data key="d5">The problem setting and prompting techniques are essential for effectively utilizing language models in reasoning and decision-making tasks.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="TOOL USE">
      <data key="d4">9.0</data>
      <data key="d5">The use of external tools significantly enhances the functionality and performance of language models in various tasks.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="LATS">
      <data key="d4">8.0</data>
      <data key="d5">LATS is based on MCTS, utilizing its principles to enhance the decision-making capabilities of language models.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="DECISION-MAKING TASKS">
      <data key="d4">9.0</data>
      <data key="d5">MCTS is specifically designed for decision-making tasks, providing a structured approach to explore possible actions and outcomes.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="HEURISTICS">
      <data key="d4">6.0</data>
      <data key="d5">Heuristics guide the search process in MCTS, helping to evaluate the potential of different states and actions in the decision tree.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="SEARCH ALGORITHMS">
      <data key="d4">7.0</data>
      <data key="d5">Search algorithms are integral to MCTS, guiding the exploration of the decision tree to find optimal actions.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="DECISION TREE">
      <data key="d4">1.0</data>
      <data key="d5">MCTS builds a decision tree to represent states and actions in decision-making environments, facilitating the search for solutions.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="PROGRAMMING" target="LATS">
      <data key="d4">14.0</data>
      <data key="d5">LATS demonstrates versatility in enhancing programming tasks through its reasoning and decision-making capabilities.
LATS is recommended for programming tasks where performance is prioritized over efficiency.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="PROGRAMMING" target="HUMANEVAL DATASET">
      <data key="d4">9.0</data>
      <data key="d5">The HumanEval dataset is used to evaluate programming models, assessing their ability to synthesize code from natural language descriptions.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="PROGRAMMING" target="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d4">8.0</data>
      <data key="d5">The MBPP benchmark is designed to evaluate program synthesis techniques, similar to the HumanEval dataset.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="INTERACTIVE QUESTION-ANSWERING (QA)" target="LATS">
      <data key="d4">8.0</data>
      <data key="d5">LATS improves performance in interactive QA tasks by integrating reasoning and planning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WEB NAVIGATION" target="LATS">
      <data key="d4">6.0</data>
      <data key="d5">LATS can assist in web navigation tasks by providing intelligent responses based on user queries.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MATH" target="LATS">
      <data key="d4">1.0</data>
      <data key="d5">LATS enhances the ability of language models to solve mathematical problems through its advanced reasoning techniques.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="GPT-4" target="LATS">
      <data key="d4">18.0</data>
      <data key="d5">LATS achieves a high Pass@1 rate on HumanEval when used with GPT-4, indicating its advanced capabilities.
LATS also utilizes GPT-4, showing improved performance in tasks compared to GPT-3.5.
LATS sets state-of-the-art performance on HumanEval when used with the GPT-4 model.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-4" target="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d4">6.0</data>
      <data key="d5">GPT-4 also employs value function hyperparameters to enhance its performance in language processing tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-4" target="GPT-3.5">
      <data key="d4">8.0</data>
      <data key="d5">Knowledge and performance from GPT-3.5 are transferred to GPT-4, improving the capabilities of the agents generated by Meta Agent Search.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="GPT-4" target="META AGENT SEARCH">
      <data key="d4">24.0</data>
      <data key="d5">Meta Agent Search utilizes GPT-4 for evaluating the performance of discovered agents.
Meta Agent Search employs GPT-4 for evaluating the performance of the discovered agents.
GPT-4 is utilized to test the transferability of agents discovered through Meta Agent Search, showcasing their adaptability across models.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-4" target="GPT-3.5-TURBO-0125">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4 is a more cost-effective and higher-performing alternative to GPT-3.5-turbo-0125 for similar tasks.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="GPT-4" target="SYNTHETIC DATA">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is utilized to generate responses for prompts in the synthetic data generation process, enhancing the quality of the data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="GPT-4" target="AGENTINSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct utilizes GPT-4 to generate high-quality synthetic data for training AI models.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="GPT-4" target="ORCA-BENCH">
      <data key="d4">9.0</data>
      <data key="d5">Orca-Bench is used to evaluate the performance of GPT-4, which serves as the benchmark model with a score of 10.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GPT-4" target="MISTRAL">
      <data key="d4">1.0</data>
      <data key="d5">Mistral's reading comprehension capabilities are compared to those of GPT-4, indicating advancements in model performance.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPT-4" target="ORCA-3">
      <data key="d4">17.0</data>
      <data key="d5">Orca-3's performance is assessed in relation to GPT-4, which serves as a high standard for language model capabilities.
Orca-3's performance on reading comprehension sections of the LSATs has been elevated to match that of GPT-4, indicating a competitive standing among models.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="ORCA-3-7B">
      <data key="d4">9.0</data>
      <data key="d5">GPT-4 is used to evaluate the performance of Orca-3-7B, establishing a relationship between the model and its evaluator.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 has been evaluated on the MIRAGE datasets to assess its performance in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="CO-T">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 utilizes the CoT technique to enhance its reasoning capabilities in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-3.5" target="LATS">
      <data key="d4">49.0</data>
      <data key="d5">LATS achieves improved performance when used with GPT-3.5, showcasing its adaptability to different language models.
GPT-3.5 serves as the foundational language model for LATS, providing the necessary reasoning capabilities for its operations.
LATS uses GPT-3.5 for its prompting methods to evaluate performance in various tasks, including HotPotQA.
LATS achieves high performance using the GPT-3.5 model for reasoning and programming tasks.
GPT-3.5 is utilized within the LATS framework to improve decision-making and reasoning capabilities in various tasks.
GPT-3.5 is utilized in the context of LATS to analyze and report performance metrics in the Game of 24.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="GPT-3.5" target="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d4">6.0</data>
      <data key="d5">GPT-3.5 utilizes specific value function hyperparameters to optimize its performance in various tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-3.5" target="META AGENT SEARCH">
      <data key="d4">24.0</data>
      <data key="d5">Meta Agent Search uses GPT-3.5 to evaluate baseline agents, allowing for a comparison of performance.
GPT-3.5 is used to evaluate the performance of the discovered agents and baselines in the context of Meta Agent Search.
GPT-3.5 serves as a foundation model for testing the effectiveness of agents discovered through Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-3.5" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">The study of ADAS involves insights gained from the performance of GPT-3.5 in refining answers through feedback mechanisms.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="GPT-3.5" target="MISTRAL-7B">
      <data key="d4">1.0</data>
      <data key="d5">Mistral-7B is compared with GPT-3.5 to assess the performance of instruction-tuned models.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="REACT" target="LATS">
      <data key="d4">38.0</data>
      <data key="d5">LATS offers a more flexible and adaptive problem-solving approach compared to the ReAct technique.
LATS incorporates the ReAct method to enhance its performance in reasoning and acting tasks.
LATS utilizes the ReAct prompting method to adapt its approach based on previous successes or failures in reasoning tasks.
LATS incorporates ReAct as a base prompting method to enhance its performance in decision-making tasks.
LATS is compared to simpler prompting methods like ReAct in terms of computational cost and performance.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="REACT" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">7.0</data>
      <data key="d5">ReAct and CoT are both prompting techniques used to enhance reasoning and decision-making in language models, but they have different approaches and limitations.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="SELF-REFINE">
      <data key="d4">8.0</data>
      <data key="d5">Self-refine is an extension proposed to improve upon the limitations of ReAct, focusing on self-improvement in reasoning and decision-making.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="ADAPLANNER">
      <data key="d4">6.0</data>
      <data key="d5">AdaPlanner incorporates feedback mechanisms that can enhance the decision-making process in a manner similar to ReAct.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="KURATOV ET AL. (2023)">
      <data key="d4">5.0</data>
      <data key="d5">Kuratov et al. (2023) provides insights relevant to the effectiveness of the ReAct technique in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="CHAIN-OF-THOUGHT PROMPTING">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-thought prompting and ReAct both aim to improve reasoning capabilities in language models, but ReAct incorporates external interactions for enhanced performance.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">ReAct is applied in decision-making tasks where interaction with an external environment is necessary for effective reasoning and action.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="YAO ET AL. (2023B)">
      <data key="d4">5.0</data>
      <data key="d5">Yao et al. (2023b) discusses the efficiency of the ReAct method, which is compared to LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="REACT" target="OMNI">
      <data key="d4">1.0</data>
      <data key="d5">OMNI and React are both systems designed to enhance the capabilities of language models in different ways.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="COBBE ET AL. (2021)" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">LATS builds upon the reasoning principles discussed by Cobbe et al. (2021).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="YAO ET AL. (2022)" target="LATS">
      <data key="d4">5.0</data>
      <data key="d5">Yao et al. (2022) provides insights into the WebShop domain that may relate to LATS's applications.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="YAO ET AL. (2022)" target="WEB SHOP">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. (2022) discusses the WebShop environment, providing foundational knowledge for its application in decision-making tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="FAN ET AL. (2022)" target="LATS">
      <data key="d4">6.0</data>
      <data key="d5">LATS is relevant to the use of language models in complex multimodal games as discussed by Fan et al. (2022).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="YAO ET AL. (2023A)" target="LATS">
      <data key="d4">13.0</data>
      <data key="d5">LATS utilizes advancements in search algorithms discussed by Yao et al. (2023a).
Yao et al. (2023a) discusses the Game of 24, which may relate to LATS's reasoning capabilities.
Yao et al. (2023a) provides insights relevant to the sample complexity of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="SHINN ET AL. (2023)" target="LATS">
      <data key="d4">5.0</data>
      <data key="d5">Shinn et al. (2023) offers evaluations that can be compared with LATS's performance in reasoning tasks.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="SHINN ET AL. (2023)" target="REFLEXION">
      <data key="d4">6.0</data>
      <data key="d5">Shinn et al. (2023) evaluates the effectiveness of Reflexion in enhancing agent performance in decision-making tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="AGENTBENCH">
      <data key="d4">7.0</data>
      <data key="d5">Reinforcement learning techniques are evaluated within the AgentBench framework to assess agent performance.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="FEEDBACK" target="REFINEMENT">
      <data key="d4">8.0</data>
      <data key="d5">Refinement relies on feedback from experts to improve the quality of answers generated by agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="FEEDBACK" target="CRITIC_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The critic_module generates feedback based on the answers provided by the cot_module, assessing their correctness.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="FEEDBACK" target="STRUCTURED FEEDBACK AND ENSEMBLE AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent uses feedback to refine its generated solutions and improve performance.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="INITIAL_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is derived from the evaluation of initial solutions, providing insights into their performance and areas for improvement.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="SELF-REFINE">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is a crucial element in the Self-Refine method, guiding the iterative improvement of answers.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LATS" target="SELF-REFINEMENT">
      <data key="d4">7.0</data>
      <data key="d5">LATS incorporates self-refinement to enhance model sensibility and learning from experience.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SELF-CONSISTENCY">
      <data key="d4">6.0</data>
      <data key="d5">LATS utilizes self-consistency to improve the reliability of its outputs during reasoning tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">7.0</data>
      <data key="d5">LATS builds upon the principles of CoT prompting to enhance reasoning capabilities in language models.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="YANG ET AL. (2018)">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated using the HotPotQA dataset, which was introduced by Yang et al. (2018).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SILVER ET AL. (2017)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is inspired by the success of MCTS discussed by Silver et al. (2017).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="WEI ET AL. (2022)">
      <data key="d4">7.0</data>
      <data key="d5">LATS incorporates ideas from chain-of-thought prompting as discussed by Wei et al. (2022).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="GUO ET AL. (2018)">
      <data key="d4">6.0</data>
      <data key="d5">LATS addresses the error propagation issues highlighted by Guo et al. (2018).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="CHEN ET AL. (2021)">
      <data key="d4">13.0</data>
      <data key="d5">LATS demonstrates improved performance on tasks evaluated by the HumanEval dataset discussed by Chen et al. (2021).
Chen et al. (2021) discusses applications relevant to LATS's performance in programming tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="HAO ET AL. (2023)">
      <data key="d4">17.0</data>
      <data key="d5">LATS incorporates planning techniques discussed by Hao et al. (2023).
Hao et al. (2023) provides comparative analysis relevant to the performance of LATS in decision-making tasks.
Hao et al. (2023) provides insights relevant to the performance of the LATS algorithm compared to other methods.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="BESTA ET AL. (2023)">
      <data key="d4">7.0</data>
      <data key="d5">LATS builds upon advancements in search algorithms discussed by Besta et al. (2023).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="AHN ET AL. (2022)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is related to the application of language models in robotics as discussed by Ahn et al. (2022).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="HUANG ET AL. (2022)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is connected to the use of language models in robotics as discussed by Huang et al. (2022).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="DRIESS ET AL. (2023)">
      <data key="d4">6.0</data>
      <data key="d5">LATS relates to the application of language models in robotics as discussed by Driess et al. (2023).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="BAKER ET AL. (2022)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is relevant to the adaptation of language models in complex multimodal games as discussed by Baker et al. (2022).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="GUSS ET AL. (2019)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is related to the application of language models in games like Minecraft as discussed by Guss et al. (2019).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="LIU ET AL. (2018)">
      <data key="d4">6.0</data>
      <data key="d5">LATS is connected to the application of language models in text-based environments as discussed by Liu et al. (2018).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SHRIDHAR ET AL. (2020)">
      <data key="d4">6.0</data>
      <data key="d5">LATS relates to the use of language models in interactive environments as discussed by Shridhar et al. (2020).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="LIU ET AL. (2024)">
      <data key="d4">1.0</data>
      <data key="d5">LATS is relevant to the application of language models in text-based environments as discussed by Liu et al. (2024).</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="MCTS">
      <data key="d4">25.0</data>
      <data key="d5">LATS adapts MCTS to create a search algorithm specifically designed for language agents, integrating reasoning and planning capabilities.
LATS employs MCTS to explore and select high-value options during the decision-making process.
LATS utilizes MCTS as a principled search algorithm to enhance its decision-making performance in complex environments.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LM AGENT">
      <data key="d4">8.0</data>
      <data key="d5">LATS utilizes the LM Agent as a core component to facilitate decision-making and planning through language model representations.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="REFLECTION">
      <data key="d4">6.0</data>
      <data key="d5">Reflection is a key operation in LATS that helps improve the search algorithm by using feedback from previous attempts to enhance future performance.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SEARCH ALGORITHM">
      <data key="d4">1.0</data>
      <data key="d5">LATS is a specific type of search algorithm that integrates reasoning, acting, and planning for language models, enhancing decision-making capabilities.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="VALUE FUNCTION">
      <data key="d4">16.0</data>
      <data key="d5">LATS utilizes a value function to quantify the agent's progress in task completion, guiding its decision-making process.
The value function in LATS scores states to guide the search process based on expected future rewards.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENTAL FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">Environmental feedback is integral to LATS, providing assessments that influence the agent's learning and decision-making.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="SELF-REFLECTION">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection is a mechanism in LATS that allows the agent to learn from unsuccessful outcomes and improve future performance.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="TRIAL AND ERROR">
      <data key="d4">7.0</data>
      <data key="d5">LATS incorporates a trial and error approach, enabling the agent to learn from past experiences without costly optimization methods.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="PROGRAMMED HEURISTICS">
      <data key="d4">7.0</data>
      <data key="d5">LATS aims to improve upon programmed heuristics by offering a more flexible and adaptive decision-making framework.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="LEARNED HEURISTICS">
      <data key="d4">1.0</data>
      <data key="d5">LATS seeks to outperform learned heuristics in terms of efficiency and adaptability in various problem-solving scenarios.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="LATS" target="REFLEXION">
      <data key="d4">35.0</data>
      <data key="d5">LATS can be compared with the Reflexion method to evaluate its reasoning capabilities.
LATS incorporates the Reflexion method to improve reasoning performance through feedback mechanisms.
LATS uses Reflexion to provide additional semantic signals that improve the agent's decision-making process.
LATS is compared to simpler prompting methods like Reflexion in terms of computational cost and performance.
LATS and Reflexion are compared in terms of their performance on tasks like HotPotQA, with LATS showing superior results.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="TO">
      <data key="d4">7.0</data>
      <data key="d5">LATS extends the ToT method by integrating it with ReAct prompting for better decision-making.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="RAP">
      <data key="d4">15.0</data>
      <data key="d5">LATS integrates aspects of the RAP method to improve its reasoning and acting strategies.
LATS integrates RAP strategies to enhance its performance in reasoning tasks through external retrieval.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="AUSTIN ET AL. (2022)">
      <data key="d4">5.0</data>
      <data key="d5">Austin et al. (2022) evaluates language models in domains that may include applications of LATS.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="LATS" target="COT">
      <data key="d4">7.0</data>
      <data key="d5">LATS incorporates CoT prompting to enhance reasoning performance in tasks like HotPotQA.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="TOT">
      <data key="d4">8.0</data>
      <data key="d5">LATS employs ToT methods to sample and explore outputs, improving its reasoning capabilities.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="HUMANEVAL">
      <data key="d4">17.0</data>
      <data key="d5">LATS is tested on the HumanEval dataset to assess its ability to generate correct Python code from natural language descriptions.
LATS is evaluated using the HumanEval dataset for programming tasks in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="MBPP">
      <data key="d4">9.0</data>
      <data key="d5">LATS is evaluated on the MBPP dataset to measure its performance in programming tasks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="IL">
      <data key="d4">14.0</data>
      <data key="d5">LATS utilizes Imitation Learning techniques to enhance its reasoning and acting capabilities.
LATS is compared against IL to evaluate its performance in decision-making tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="IL+RL">
      <data key="d4">7.0</data>
      <data key="d5">LATS employs Imitation Learning with Reinforcement Learning to optimize its performance in complex reasoning tasks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="EXTERNAL OBSERVATIONS">
      <data key="d4">8.0</data>
      <data key="d5">LATS integrates external observations to augment its reasoning process and improve task performance.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="SYNTHETIC TEST SUITE">
      <data key="d4">1.0</data>
      <data key="d5">LATS uses a synthetic test suite to evaluate the correctness of generated programming solutions.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="WEB SHOP">
      <data key="d4">8.0</data>
      <data key="d5">LATS is applied in the WebShop environment to enhance decision-making performance for agents navigating the online shopping platform.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="COACHING OF THOUGHT (COT)">
      <data key="d4">8.0</data>
      <data key="d5">LATS employs CoT as a prompting design to guide agents in reasoning tasks effectively.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="GAME OF 24">
      <data key="d4">16.0</data>
      <data key="d5">LATS is evaluated on the Game of 24 task to demonstrate its reasoning capabilities in mathematical challenges.
LATS is a method applied in the Game of 24 to assess success rates based on different parameter settings.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="LATS" target="DFS">
      <data key="d4">1.0</data>
      <data key="d5">LATS incorporates DFS as a search strategy to explore decision-making paths in its framework.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="RL">
      <data key="d4">7.0</data>
      <data key="d5">LATS is compared against RL-based training methods to assess its effectiveness in improving scores and success rates.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="FURUTA ET AL. (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Furuta et al. (2024) provides insights relevant to the fine-tuning methods that can be applied in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="TOOL OF THOUGHT (TOT)">
      <data key="d4">1.0</data>
      <data key="d5">LATS incorporates ToT as a prompting method to enhance reasoning capabilities in decision-making tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="SYSTEM-2 LM APPROACHES">
      <data key="d4">8.0</data>
      <data key="d5">LATS is an example of a System-2 LM approach that enhances decision-making through interactions with environments.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="DECISION-MAKING COMMUNITY">
      <data key="d4">7.0</data>
      <data key="d5">LATS contributes to the decision-making community by improving autonomous decision-making processes using language models.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="DANIEL CAMPOS">
      <data key="d4">6.0</data>
      <data key="d5">Daniel Campos provided feedback on the development of LATS, indicating his involvement in the research process.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NSF GRANT 2106825">
      <data key="d4">7.0</data>
      <data key="d5">NSF Grant 2106825 supports research related to the development and application of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NIFA AWARD 2020-67021-32799">
      <data key="d4">7.0</data>
      <data key="d5">NIFA Award 2020-67021-32799 supports research related to the development and application of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="IBM-ILLINOIS DISCOVERY ACCELERATOR INSTITUTE">
      <data key="d4">7.0</data>
      <data key="d5">The IBM-Illinois Discovery Accelerator Institute supports research initiatives like LATS, enhancing language model capabilities.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NVIDIA GPUS">
      <data key="d4">8.0</data>
      <data key="d5">NVIDIA GPUs are utilized in the implementation of LATS for computational tasks, enhancing its performance.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ACCESS PROGRAM">
      <data key="d4">7.0</data>
      <data key="d5">The ACCESS program provides computational resources that support the research and development of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="MICHAEL AHN">
      <data key="d4">6.0</data>
      <data key="d5">Michael Ahn is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ANTHONY BROHAN">
      <data key="d4">6.0</data>
      <data key="d5">Anthony Brohan is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NOAH BROWN">
      <data key="d4">6.0</data>
      <data key="d5">Noah Brown is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="YEVGEN CHEBOTAR">
      <data key="d4">6.0</data>
      <data key="d5">Yevgen Chebotar is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="OMAR CORTES">
      <data key="d4">6.0</data>
      <data key="d5">Omar Cortes is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="BYRON DAVID">
      <data key="d4">6.0</data>
      <data key="d5">Byron David is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="CHELSEA FINN">
      <data key="d4">6.0</data>
      <data key="d5">Chelsea Finn is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="CHUYUAN FU">
      <data key="d4">6.0</data>
      <data key="d5">Chuyuan Fu is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="KEERTHANA GOPALAKRISHNAN">
      <data key="d4">6.0</data>
      <data key="d5">Keerthana Gopalakrishnan is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="KAROL HAUSMAN">
      <data key="d4">6.0</data>
      <data key="d5">Karol Hausman is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ALEX HERZOG">
      <data key="d4">6.0</data>
      <data key="d5">Alex Herzog is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="DANIEL HO">
      <data key="d4">6.0</data>
      <data key="d5">Daniel Ho is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="JASMINE HSU">
      <data key="d4">6.0</data>
      <data key="d5">Jasmine Hsu is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="JULIAN IBARZ">
      <data key="d4">6.0</data>
      <data key="d5">Julian Ibarz is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="BRIAN ICHTER">
      <data key="d4">6.0</data>
      <data key="d5">Brian Ichter is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ALEX IRPAN">
      <data key="d4">6.0</data>
      <data key="d5">Alex Irpan is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ERIC JANG">
      <data key="d4">6.0</data>
      <data key="d5">Eric Jang is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="ROSARIO JAUREGUI RUANO">
      <data key="d4">6.0</data>
      <data key="d5">Rosario Jauregui Ruano is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="KYLE JEFFREY">
      <data key="d4">6.0</data>
      <data key="d5">Kyle Jeffrey is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="SALLY JESMONTH">
      <data key="d4">6.0</data>
      <data key="d5">Sally Jesmonth is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NIKHIL J JOSHI">
      <data key="d4">6.0</data>
      <data key="d5">Nikhil J Joshi is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="RYAN JULIAN">
      <data key="d4">6.0</data>
      <data key="d5">Ryan Julian is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="DMITRY KALASHNIKOV">
      <data key="d4">6.0</data>
      <data key="d5">Dmitry Kalashnikov is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="YUHENG KUANG">
      <data key="d4">6.0</data>
      <data key="d5">Yuheng Kuang is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="KUANG-HUEI LEE">
      <data key="d4">6.0</data>
      <data key="d5">Kuang-Huei Lee is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="SERGEY LEVINE">
      <data key="d4">6.0</data>
      <data key="d5">Sergey Levine is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="YAO LU">
      <data key="d4">6.0</data>
      <data key="d5">Yao Lu is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="LINDA LUU">
      <data key="d4">6.0</data>
      <data key="d5">Linda Luu is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="CAROLINA PARADA">
      <data key="d4">6.0</data>
      <data key="d5">Carolina Parada is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="PETER PASTOR">
      <data key="d4">6.0</data>
      <data key="d5">Peter Pastor is a contributor to research on grounding language in robotic affordances, which relates to the applications of LATS.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="PROGRAM SYNTHESIS">
      <data key="d4">7.0</data>
      <data key="d5">LATS can be applied in program synthesis to enhance decision-making processes through interactions with programming environments.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="VIDEO PRETRAINING (VPT)">
      <data key="d4">6.0</data>
      <data key="d5">LATS may utilize techniques from video pretraining to improve its performance in action-related tasks within language models.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="GRAPH OF THOUGHTS">
      <data key="d4">7.0</data>
      <data key="d5">LATS can incorporate the Graph of Thoughts methodology to enhance structured reasoning in decision-making processes.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="NATURAL LANGUAGE INFERENCE">
      <data key="d4">6.0</data>
      <data key="d5">LATS can benefit from natural language inference techniques to improve its understanding of logical relationships in decision-making.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="DEEP BLUE">
      <data key="d4">5.0</data>
      <data key="d5">LATS shares similarities with Deep Blue in terms of enhancing decision-making capabilities through advanced computational techniques.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="CODET">
      <data key="d4">1.0</data>
      <data key="d5">LATS can leverage techniques from CodeT for generating and testing code in decision-making scenarios.</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="LATS" target="OLIVIER BOUSQUET">
      <data key="d4">8.0</data>
      <data key="d5">Olivier Bousquet is a researcher who contributed to the development of the LATS algorithm for reasoning in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="QUOC LE">
      <data key="d4">8.0</data>
      <data key="d5">Quoc Le is a researcher involved in the development of the LATS algorithm for reasoning in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="ED CHI">
      <data key="d4">8.0</data>
      <data key="d5">Ed Chi is a researcher who contributed to the study of reasoning in language models through the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="MONTE CARLO TREE SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">LATS utilizes Monte Carlo Tree Search as part of its decision-making process.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="WEBSHOP">
      <data key="d4">8.0</data>
      <data key="d5">LATS is evaluated using the WebShop dataset for web search tasks in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="ALFWORLD">
      <data key="d4">7.0</data>
      <data key="d5">LATS is applicable in environments like Alfworld for text-based manipulation tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="TOOLBENCH">
      <data key="d4">7.0</data>
      <data key="d5">LATS can be evaluated in environments that utilize ToolBench for tool use capabilities.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="WANG ET AL. (2022)">
      <data key="d4">1.0</data>
      <data key="d5">Wang et al. (2022) provides insights relevant to the performance of LATS in comparison to CoT-SC.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="A* SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm employs A* search as part of its action space navigation strategy.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="EXPERIMENTAL RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">Experimental results are used to evaluate the effectiveness of the LATS algorithm in various tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENT DETAILS">
      <data key="d4">7.0</data>
      <data key="d5">Environment details are crucial for understanding the context in which the LATS algorithm operates.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="PROMPTS">
      <data key="d4">8.0</data>
      <data key="d5">Prompts are utilized within the LATS algorithm to guide the language model's responses in different scenarios.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="COMPUTATIONAL COST">
      <data key="d4">7.0</data>
      <data key="d5">Computational cost is a significant factor when evaluating the efficiency of the LATS algorithm compared to simpler methods.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="SAMPLE COMPLEXITY">
      <data key="d4">6.0</data>
      <data key="d5">Sample complexity is an important metric for assessing the performance of the LATS algorithm in various scenarios.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="TRIALS">
      <data key="d4">8.0</data>
      <data key="d5">Trials are conducted to test the performance and efficiency of the LATS algorithm in different environments.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="RESOURCE CONSTRAINTS">
      <data key="d4">6.0</data>
      <data key="d5">Resource constraints can impact the implementation and performance of the LATS algorithm in real-world applications.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="DECISION-MAKING">
      <data key="d4">8.0</data>
      <data key="d5">Decision-making is a core function of the LATS algorithm, enabling it to evaluate and select actions based on reasoning.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="REAL-WORLD ENVIRONMENTS">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm is designed to be applicable in real-world environments, enhancing its utility in practical tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="INTERACTIVE ENVIRONMENTS">
      <data key="d4">1.0</data>
      <data key="d5">Interactive environments provide a context for the LATS algorithm to engage in tasks that require reasoning and decision-making.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENT">
      <data key="d4">7.0</data>
      <data key="d5">LATS operates within a defined environment that includes the state space and task dynamics, influencing its decision-making process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ACTION SPACE">
      <data key="d4">8.0</data>
      <data key="d5">LATS utilizes a specific action space that defines the actions it can take, such as searching for entities and looking up strings.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="TRAJECTORIES">
      <data key="d4">7.0</data>
      <data key="d5">LATS evaluates its performance based on the trajectories it generates during its decision-making process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SAMPLING SIZE">
      <data key="d4">6.0</data>
      <data key="d5">The sampling size affects the performance of LATS, as different sizes can lead to varying results in task completion.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="EXPLORATION WEIGHT">
      <data key="d4">8.0</data>
      <data key="d5">The exploration weight is a critical parameter in LATS that influences the effectiveness of its search strategy.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="DEPTH">
      <data key="d4">7.0</data>
      <data key="d5">The depth parameter in LATS limits the number of steps taken during the search process, impacting overall performance.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="REWARD">
      <data key="d4">7.0</data>
      <data key="d5">Rewards from the environment provide feedback to LATS, influencing its learning and decision-making process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="PERFORMANCE">
      <data key="d4">1.0</data>
      <data key="d5">The performance of LATS is assessed based on its ability to successfully complete tasks, such as answering questions in HotPotQA.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SELF-CONSISTENCY SCORE">
      <data key="d4">1.0</data>
      <data key="d5">The self-consistency score is evaluated as part of the LATS method to determine the accuracy and reliability of the results in the Game of 24.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT)" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search incorporates Chain-of-Thought as a baseline technique for agent evaluation.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT)" target="DROP">
      <data key="d4">5.0</data>
      <data key="d5">Chain-of-Thought (COT) is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="HAO ET AL. (2023)" target="MCTS">
      <data key="d4">5.0</data>
      <data key="d5">Hao et al. (2023) explores the use of planning and search algorithms, including MCTS, in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="SELF-REFINE" target="REFLEXION">
      <data key="d4">8.0</data>
      <data key="d5">Reflexion builds on the self-improvement concept introduced by Self-Refine, enhancing reasoning and decision-making capabilities.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="SELF-REFINE" target="META AGENT SEARCH">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search evaluates agents that utilize Self-Refine to enhance their performance through iterative corrections.
Self-Refine is tested in the context of Meta Agent Search to improve the outputs of agents through iterative refinement.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="SELF-REFINE" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">Self-Refine is a baseline technique that is compared against state-of-the-art hand-designed agents to assess its effectiveness in improving responses.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="SELF-REFINE" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Self-Refine is a technique used by manually designed agents to enhance their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="SELF-REFINE" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Self-Refine is a manually designed agent that can be enhanced by the methodologies proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="SELF-REFINE" target="DROP">
      <data key="d4">5.0</data>
      <data key="d5">Self-Refine is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="SELF-REFINE" target="STEP-BACK ABSTRACTION">
      <data key="d4">7.0</data>
      <data key="d5">Step-back Abstraction is implemented as part of the Self-Refine process in reasoning and problem-solving experiments.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="SELF-REFINE" target="MULTI-STEP PEER REVIEW AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Multi-Step Peer Review Agent utilizes the Self-Refine method to enhance the quality of answers through iterative feedback.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MCTS" target="TREE-BASED SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">MCTS is a specific implementation of tree-based search techniques used for exploring multiple outcomes in decision-making processes.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="MCTS" target="UCT ALGORITHM">
      <data key="d4">1.0</data>
      <data key="d5">The UCT algorithm is a fundamental component of MCTS, used to guide the selection of nodes in the search tree based on exploration and exploitation balance.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="DFS">
      <data key="d4">7.0</data>
      <data key="d5">MCTS is compared to DFS as a more principled search algorithm, highlighting differences in performance and methodology.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="DECISION-MAKING" target="REASONING">
      <data key="d4">8.0</data>
      <data key="d5">Reasoning is a fundamental component of decision-making processes in language models, guiding the generation of outputs based on inputs.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="DECISION-MAKING" target="PLANNING">
      <data key="d4">7.0</data>
      <data key="d5">Planning techniques are often employed to enhance the decision-making capabilities of language models, allowing for more structured outputs.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="DECISION-MAKING" target="LANGUAGE MODEL AGENT">
      <data key="d4">1.0</data>
      <data key="d5">Decision-making is a core function of the language model agent, determining its actions based on reasoning and available data.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="REASONING" target="TOOL USE">
      <data key="d4">1.0</data>
      <data key="d5">Utilizing external tools can improve the reasoning capabilities of language models by providing additional information and context.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REASONING" target="HUAIXIU STEVEN ZHENG">
      <data key="d4">8.0</data>
      <data key="d5">Huaixiu Steven Zheng is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="SWAROOP MISHRA">
      <data key="d4">8.0</data>
      <data key="d5">Swaroop Mishra is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="XINYUN CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Xinyun Chen is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="HENG-TZE CHENG">
      <data key="d4">8.0</data>
      <data key="d5">Heng-Tze Cheng is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="ED H CHI">
      <data key="d4">8.0</data>
      <data key="d5">Ed H Chi is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="QUOC V LE">
      <data key="d4">8.0</data>
      <data key="d5">Quoc V Le is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="REASONING" target="DENNY ZHOU">
      <data key="d4">8.0</data>
      <data key="d5">Denny Zhou is a co-author of a paper on reasoning via abstraction in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="TOOL USE" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">6.0</data>
      <data key="d5">Tool use is a critical component for agents to solve complex tasks, as discussed in the context of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="TOOL USE" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Agentic Systems employ Tool Use to accomplish tasks effectively.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="TOOL USE" target="SKILLS">
      <data key="d4">8.0</data>
      <data key="d5">Tool use is a skill that is also developed through the workflows in the agentic flows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TOOL USE" target="CODING">
      <data key="d4">6.0</data>
      <data key="d5">Tool use in AI often involves coding to manipulate tools and resources effectively for problem-solving.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT PROMPTING" target="TREE-OF-THOUGHT PROMPTING">
      <data key="d4">8.0</data>
      <data key="d5">Tree-of-thought prompting builds upon chain-of-thought prompting by exploring multiple reasoning paths, enhancing the complexity of the reasoning process.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT PROMPTING" target="ERROR PROPAGATION">
      <data key="d4">1.0</data>
      <data key="d5">Error propagation can occur in chain-of-thought prompting if earlier reasoning steps lead to incorrect conclusions, affecting the final output.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT PROMPTING" target="LANGUAGE MODEL (LM)">
      <data key="d4">8.0</data>
      <data key="d5">The language model utilizes chain-of-thought prompting to enhance its reasoning capabilities by generating intermediate thoughts.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT PROMPTING" target="THOUGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Thoughts are generated as part of the chain-of-thought prompting process, acting as stepping stones between input and output.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="OUTPUT" target="INPUT PROMPT">
      <data key="d4">9.0</data>
      <data key="d5">The input prompt is transformed into an output by the language model, representing the model's response to the provided instructions or examples.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="THOUGHTS" target="FM_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">FM_Module produces thoughts that include reasoning and code as outputs for the task at hand.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="THOUGHTS" target="INITIAL_SOLUTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Thoughts are generated as part of the evaluation process for each initial solution, reflecting the cognitive analysis performed.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="LM AGENT" target="ENVIRONMENT">
      <data key="d4">9.0</data>
      <data key="d5">The LM Agent interacts with the environment, receiving observations and feedback that guide its decision-making process.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="POLICY &#928;">
      <data key="d4">7.0</data>
      <data key="d5">The policy &#960; is employed by the LM Agent to determine the actions it should take based on its observations and previous actions.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM AGENT" target="ACTIONS">
      <data key="d4">9.0</data>
      <data key="d5">The LM Agent takes actions based on its observations and policy, which influence the state of the environment.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="REFLECTION" target="SEARCH ACTION">
      <data key="d4">1.0</data>
      <data key="d5">The user's search action leads to reflection on their experience, prompting them to refine their search strategy.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="REFLECTION" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Agentic Systems incorporate Reflection to evaluate actions and improve future performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="VALUE FUNCTION" target="BACKPROPAGATION">
      <data key="d4">7.0</data>
      <data key="d5">Backpropagation is used to update the value function based on the returns received, ensuring that the search algorithm learns from past experiences.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="VALUE FUNCTION" target="SELF-CONSISTENCY SCORE">
      <data key="d4">7.0</data>
      <data key="d5">The self-consistency score is a component of the value function in LATS, contributing to the overall assessment of the agent's performance.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="VALUE FUNCTION" target="AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The agent in LATS utilizes the value function to assess its progress and make informed decisions during task execution.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="VALUE FUNCTION" target="REWARD">
      <data key="d4">9.0</data>
      <data key="d5">The reward received at a terminal state is used to update the value function, influencing the agent's future actions and decisions.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="OBSERVATION" target="ACTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Each action taken by the LM Agent results in an observation from the environment, which is crucial for the agent's decision-making process.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="OBSERVATION" target="ACTION">
      <data key="d4">1.0</data>
      <data key="d5">Action leads to Observation, where information is gathered that influences subsequent Thoughts and Actions in the task.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The agent employs a search algorithm to navigate through the decision tree, optimizing its path based on feedback and heuristics.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="TERMINAL STATE">
      <data key="d4">7.0</data>
      <data key="d5">The search algorithm in LATS aims to reach a terminal state, where the outcome of the task can be evaluated for success or failure.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="UCT FORMULA">
      <data key="d4">8.0</data>
      <data key="d5">The UCT formula guides the search algorithm in LATS, helping to select the next node based on updated values and exploration strategies.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">8.0</data>
      <data key="d5">The search algorithm is crucial for exploring the search space in ADAS to find optimal agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="ZHUKE ET AL. (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Zhuge et al. (2024) discusses search algorithms relevant to the exploration of search spaces in ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="EXPLORATION-EXPLOITATION TRADE-OFF">
      <data key="d4">7.0</data>
      <data key="d5">The exploration-exploitation trade-off is a critical consideration in the design of search algorithms for ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SELF-REFLECTION" target="AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The agent utilizes self-reflection to analyze its performance and improve its decision-making process based on past experiences.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="SELF-REFLECTION" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">6.0</data>
      <data key="d5">Self-reflection is another building block proposed for enhancing agentic systems within the ADAS research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SELF-REFLECTION" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Self-reflection is integrated into the Meta Agent Search process to enhance the quality of generated agents through iterative refinement.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="SELF-REFLECTION" target="META AGENT">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent engages in self-reflection to improve its code generation and overall performance.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPLEMENTATION MISTAKES">
      <data key="d4">8.0</data>
      <data key="d5">During self-reflection, the meta agent identifies implementation mistakes to correct them in future iterations.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPROVEMENT SUGGESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection leads to improvement suggestions that enhance the agent's functionality and effectiveness.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="RUNTIME ERROR">
      <data key="d4">9.0</data>
      <data key="d5">When a runtime error occurs, the meta agent uses self-reflection to debug and correct the issue.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="EXAMPLES OF POTENTIAL MISTAKES">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection includes reviewing examples of potential mistakes to avoid similar errors in future implementations.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="TERMINAL STATE" target="TRAJECTORY">
      <data key="d4">8.0</data>
      <data key="d5">A trajectory in LATS culminates in a terminal state, providing feedback that influences future decision-making processes.</data>
      <data key="d6">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </edge>
    <edge source="REWARD" target="WEB SHOP">
      <data key="d4">7.0</data>
      <data key="d5">The reward metric is used to evaluate the performance of the Web Shop based on user interactions and item selections.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="EXTERNAL FEEDBACK" target="LANGUAGE MODEL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The language model agent utilizes external feedback to improve its reasoning and decision-making capabilities.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="INTERNAL REASONING" target="LANGUAGE MODEL AGENT">
      <data key="d4">7.0</data>
      <data key="d5">The language model agent employs internal reasoning to generate answers based on its existing knowledge.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="OBSERVATION SPACE" target="LANGUAGE MODEL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The observation space provides critical information to the language model agent for making informed decisions.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="SAMPLE TRAJECTORIES" target="LANGUAGE MODEL AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Sample trajectories are used by the language model agent to evaluate its performance in decision-making tasks.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="FEEDBACK CORRECTNESS" target="LANGUAGE MODEL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">Feedback correctness is essential for the language model agent to assess its performance and improve its responses.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="PROMPTING DESIGNS" target="LANGUAGE MODEL AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Prompting designs guide the language model agent in generating appropriate responses for various tasks.</data>
      <data key="d6">fb9cb0c0984d44c3da881886ed637e55</data>
    </edge>
    <edge source="COT" target="COT-SC">
      <data key="d4">6.0</data>
      <data key="d5">COT-SC builds upon the COT technique by incorporating sampling and ensemble methods for decision-making.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="WEB SHOP" target="ACTION SPACE">
      <data key="d4">8.0</data>
      <data key="d5">The action space defines the various interactions users can perform within the Web Shop system, guiding their navigation and choices.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="SUCCESS RATE (SR)">
      <data key="d4">7.0</data>
      <data key="d5">Success Rate (SR) measures the effectiveness of the Web Shop in executing user instructions successfully.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The Web Shop allows users to select and purchase various items based on their attributes and user preferences.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="EPISODE">
      <data key="d4">7.0</data>
      <data key="d5">Each episode represents a unique interaction session within the Web Shop, where users can engage with the system and perform actions.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="ENVIRONMENTS">
      <data key="d4">6.0</data>
      <data key="d5">Different environments are used to conduct experiments that assess the performance and effectiveness of the Web Shop system.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d4">7.0</data>
      <data key="d5">Value function hyperparameters are utilized to fine-tune the decision-making processes within the Web Shop system.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="BRIGHT CITRUS DEODORANT">
      <data key="d4">1.0</data>
      <data key="d5">The Web Shop allows users to search for products like Bright Citrus Deodorant based on specific criteria such as scent and price.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="WEB SHOP" target="SEARCH ACTION">
      <data key="d4">8.0</data>
      <data key="d5">The search action is performed within the Web Shop to locate products that meet specific user requirements.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="WEB SHOP" target="CLICK ACTION">
      <data key="d4">1.0</data>
      <data key="d5">The click action is performed within the Web Shop to view more details about a selected product from the search results.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="TOKEN CONSUMPTION" target="SAMPLE COMPLEXITY">
      <data key="d4">1.0</data>
      <data key="d5">Token consumption and sample complexity are metrics used to evaluate the efficiency and performance of search algorithms like LATS, ReAct, and RAP.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="JORNELL QUIAMBAO&lt;|(&quot;ENTITY&quot;" target="PROGRAM SYNTHESIS">
      <data key="d4">1.0</data>
      <data key="d5">TECHNIQUE</data>
      <data key="d6">4ae237a491bc8a84cc720e40c59a7464</data>
    </edge>
    <edge source="PROGRAM SYNTHESIS" target="HUMANEVAL DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The HumanEval dataset is specifically designed to evaluate models on their ability to perform program synthesis from natural language descriptions.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="MARK CHEN" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Mark Chen is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="JERRY TWOREK" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Jerry Tworek is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="HEEWOO JUN" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Heewoo Jun is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="LUKASZ KAISER" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Lukasz Kaiser is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="MOHAMMAD BAVARIAN" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Mohammad Bavarian is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="MATTHIAS PLAPPERT" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Matthias Plappert is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="MAARTEN BOSMA" target="JASON WEI">
      <data key="d4">8.0</data>
      <data key="d5">Maarten Bosma and Jason Wei are co-authors on research related to prompting techniques for large language models.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="VINEET KOSARAJU" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Vineet Kosaraju is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="JACOB HILTON" target="BROWSER-ASSISTED QUESTION-ANSWERING">
      <data key="d4">1.0</data>
      <data key="d5">Jacob Hilton is a co-author of a paper discussing browser-assisted question-answering techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JACOB HILTON" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Jacob Hilton is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="REIICHIRO NAKANO" target="BROWSER-ASSISTED QUESTION-ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Reiichiro Nakano is a co-author of a paper discussing browser-assisted question-answering techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="REIICHIRO NAKANO" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Reiichiro Nakano is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="YILUN DU" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Yilun Du is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="YILUN DU">
      <data key="d4">6.0</data>
      <data key="d5">Yilun Du is involved in the development of an embodied multi-modal language model, which is related to the MineDojo project.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="MENGJIAO YANG">
      <data key="d4">6.0</data>
      <data key="d5">Mengjiao Yang collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="BO DAI">
      <data key="d4">6.0</data>
      <data key="d5">Bo Dai collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="HANJUN DAI">
      <data key="d4">6.0</data>
      <data key="d5">Hanjun Dai collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="OFIR NACHUM">
      <data key="d4">6.0</data>
      <data key="d5">Ofir Nachum collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="JOSHUA B. TENENBAUM">
      <data key="d4">6.0</data>
      <data key="d5">Joshua B. Tenenbaum collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="DALE SCHUURMANS">
      <data key="d4">6.0</data>
      <data key="d5">Dale Schuurmans collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="YILUN DU" target="PIETER ABBEEL">
      <data key="d4">6.0</data>
      <data key="d5">Pieter Abbeel collaborates with Yilun Du on the development of multi-modal language models, contributing to the same research area.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="MENGJIAO YANG" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Mengjiao Yang is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="BO DAI" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Bo Dai is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="HANJUN DAI" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Hanjun Dai is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="OFIR NACHUM" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Ofir Nachum is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="JOSHUA B. TENENBAUM" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Joshua B. Tenenbaum is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="DALE SCHUURMANS" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Dale Schuurmans is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="PIETER ABBEEL" target="MINE DOJO">
      <data key="d4">7.0</data>
      <data key="d5">Pieter Abbeel is a contributor to the MineDojo project, focusing on building embodied agents with internet-scale knowledge.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="MINE DOJO" target="MINE RL">
      <data key="d4">7.0</data>
      <data key="d5">MineRL is a dataset used in the MineDojo project for training AI agents in complex environments.</data>
      <data key="d6">68e5573b596d253a03047b1e41988598</data>
    </edge>
    <edge source="LINXI FAN" target="YECHENG JASON MA">
      <data key="d4">8.0</data>
      <data key="d5">Linxi Fan and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="GUANZHI WANG" target="YECHENG JASON MA">
      <data key="d4">8.0</data>
      <data key="d5">Guanzhi Wang and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="DE-AN HUANG" target="YECHENG JASON MA">
      <data key="d4">8.0</data>
      <data key="d5">De-An Huang and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="YUKE ZHU" target="YECHENG JASON MA">
      <data key="d4">8.0</data>
      <data key="d5">Yuke Zhu and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ANIMA ANANDKUMAR" target="YECHENG JASON MA">
      <data key="d4">8.0</data>
      <data key="d5">Yecheng Jason Ma and Anima Anandkumar co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="LUYU GAO" target="AMAN MAADAAN">
      <data key="d4">8.0</data>
      <data key="d5">Luyu Gao and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="NIKET TANDON">
      <data key="d4">8.0</data>
      <data key="d5">Aman Madaan and Niket Tandon co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="PRAKHAR GUPTA">
      <data key="d4">8.0</data>
      <data key="d5">Prakhar Gupta and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="SKYLER HALLINAN">
      <data key="d4">8.0</data>
      <data key="d5">Skyler Hallinan and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="SARAH WIEGREFFE">
      <data key="d4">8.0</data>
      <data key="d5">Sarah Wiegreffe and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="URI ALON">
      <data key="d4">8.0</data>
      <data key="d5">Uri Alon and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="NOUHA DZIRI">
      <data key="d4">8.0</data>
      <data key="d5">Nouha Dziri and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="SHRIMAI PRABHUMOYE">
      <data key="d4">8.0</data>
      <data key="d5">Shrimai Prabhumoye and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMAN MAADAAN" target="YIMING YANG">
      <data key="d4">8.0</data>
      <data key="d5">Yiming Yang and Aman Madaan co-authored a paper on iterative refinement with self-feedback.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="PENGFEI LIU" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Pengfei Liu co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XINYUN CHEN" target="SELF-DISCOVERY">
      <data key="d4">8.0</data>
      <data key="d5">Xinyun Chen is a co-author of a paper on self-discovery in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="PETER CLARK" target="PHI-3">
      <data key="d4">5.0</data>
      <data key="d5">The Phi-3 model is relevant to the research community that includes Peter Clark, who works on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="PETER CLARK" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Peter Clark is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="BOWEN ZHOU" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Bowen Zhou is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="YUJIA QIN" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Yujia Qin is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="YAXI LU" target="AGENTVERSE">
      <data key="d4">8.0</data>
      <data key="d5">Yaxi Lu is a researcher involved in the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="MAOSONG SUN" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Maosong Sun is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="TIMO SCHICK" target="TOOLFORMER">
      <data key="d4">8.0</data>
      <data key="d5">Timo Schick co-authored a paper on Toolformer, which focuses on how language models can learn to use tools.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="TOOLCHAIN*">
      <data key="d4">8.0</data>
      <data key="d5">Yuchen Zhuang co-authored the ToolChain* paper, which focuses on efficient action space navigation in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHAO ZHANG" target="TOOLCHAIN*">
      <data key="d4">8.0</data>
      <data key="d5">Chao Zhang is a co-author of the ToolChain* paper, contributing to advancements in action space navigation.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH" target="VALUE FUNCTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The Language Agent Tree Search utilizes the Value Function Prompt to analyze and improve decision-making in purchasing scenarios.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="WEBSHOP" target="AGENTS">
      <data key="d4">9.0</data>
      <data key="d5">WebShop provides an environment for agents to perform tasks related to e-commerce, such as searching for and purchasing products.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEBSHOP" target="PRODUCTS">
      <data key="d4">8.0</data>
      <data key="d5">Products are the items available for interaction within the WebShop environment, forming the basis of the e-commerce simulation.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEBSHOP" target="E-COMMERCE">
      <data key="d4">1.0</data>
      <data key="d5">WebShop simulates e-commerce activities, allowing agents to engage in buying and selling products online.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="TOOLCHAIN*" target="XIANG CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Xiang Chen is a co-author of the ToolChain* paper, contributing to action space navigation in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="TONG YU">
      <data key="d4">8.0</data>
      <data key="d5">Tong Yu is a co-author of the ToolChain* paper, focusing on navigation in large language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="SAAYAN MITRA">
      <data key="d4">8.0</data>
      <data key="d5">Saayan Mitra is a co-author of the ToolChain* paper, contributing to advancements in action space navigation.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="VICTOR BURSZTYN">
      <data key="d4">8.0</data>
      <data key="d5">Victor Bursztyn is a co-author of the ToolChain* paper, focusing on efficient navigation in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="RYAN A. ROSSI">
      <data key="d4">8.0</data>
      <data key="d5">Ryan A. Rossi is a co-author of the ToolChain* paper, contributing to action space navigation in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="SOMDEB SARKHEL">
      <data key="d4">8.0</data>
      <data key="d5">Somdeb Sarkhel is a co-author of the ToolChain* paper, focusing on large language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="XUEZHI WANG" target="JASON WEI">
      <data key="d4">8.0</data>
      <data key="d5">Xuezhi Wang and Jason Wei are co-authors on research related to reasoning in language models.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="ACTION SPACE" target="WIKIPEDIA">
      <data key="d4">7.0</data>
      <data key="d5">The action space of LATS includes actions that interact with the Wikipedia API to retrieve information about entities and strings.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="INTERACTIVE INFORMATION RETRIEVAL" target="SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Interactive information retrieval utilizes the search function to retrieve information from entity wiki pages or suggest similar entities.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="ENTITY WIKI PAGE" target="SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">The search function retrieves information from an entity wiki page if it exists.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="ENTITY WIKI PAGE" target="LOOKUP">
      <data key="d4">6.0</data>
      <data key="d5">The lookup function accesses the content of an entity wiki page based on a specified string.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="FINISH" target="FUNCTION">
      <data key="d4">5.0</data>
      <data key="d5">The finish function is part of the interactive information retrieval process, completing tasks with answers.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL DATASET" target="PASS@K">
      <data key="d4">7.0</data>
      <data key="d5">The pass@k metric is used to evaluate the performance of models on the HumanEval dataset by measuring the success rate of generated samples.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="AGENTS" target="AGENTIC SYSTEM">
      <data key="d4">9.0</data>
      <data key="d5">Agents are integral components of the agentic system, performing specific roles in the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTS" target="READING COMPREHENSION QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Agents generate reading comprehension questions based on text passages for educational purposes.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="AGENTS" target="TEXT MODIFICATION">
      <data key="d4">8.0</data>
      <data key="d5">Agents are utilized in the process of text modification to enhance written content.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HOTPOTQA PROMPTS" target="THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">HotPotQA prompts guide the reasoning process (Thought) during question-answering tasks, structuring the approach to finding answers.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="THOUGHT" target="ACTION">
      <data key="d4">9.0</data>
      <data key="d5">Thought informs the Action taken during a question-answering task, creating a logical flow in the problem-solving process.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ITEM-DETAIL" target="ITEM">
      <data key="d4">8.0</data>
      <data key="d5">Each item in the Web Shop has an associated Item-Detail that provides users with essential information for making purchasing decisions.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PLAINS" target="ELEVATION">
      <data key="d4">7.0</data>
      <data key="d5">Plains can rise in elevation, indicating a change in height from lower to higher altitudes, typically measured in feet.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="FIRST FOR WOMEN">
      <data key="d4">1.0</data>
      <data key="d5">Both Arthur&#8217;s Magazine and First for Women are publications, but they differ in their historical context and target audience.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="TIMOTHY SHAY ARTHUR">
      <data key="d4">8.0</data>
      <data key="d5">Timothy Shay Arthur served as the editor of Arthur&#8217;s Magazine, shaping its content and direction.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="EDGAR A. POE">
      <data key="d4">7.0</data>
      <data key="d5">Edgar A. Poe contributed literary works to Arthur&#8217;s Magazine, enhancing its reputation in the 19th century.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="J.H. INGRAHAM">
      <data key="d4">7.0</data>
      <data key="d5">J.H. Ingraham's works were published in Arthur&#8217;s Magazine, contributing to its literary diversity.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="SARAH JOSEPHA HALE">
      <data key="d4">7.0</data>
      <data key="d5">Sarah Josepha Hale's contributions to Arthur&#8217;s Magazine helped promote women's literature in the 19th century.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ARTHUR&#8217;S MAGAZINE" target="THOMAS G. SPEAR">
      <data key="d4">1.0</data>
      <data key="d5">Thomas G. Spear's works were featured in Arthur&#8217;s Magazine, contributing to its literary content.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ADD FUNCTION" target="UNIT TEST RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">The unit test results evaluate the performance of the add function, indicating whether it meets the expected outcomes.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="REFLECTION ON IMPLEMENTATION">
      <data key="d4">7.0</data>
      <data key="d5">The reflection on the implementation analyzes the failures in the add function based on the unit test results, providing insights for improvement.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="IMPROVED IMPLEMENTATION">
      <data key="d4">9.0</data>
      <data key="d5">The improved implementation of the add function is a direct response to the issues identified in the previous implementation and its reflection.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="UNIT TEST">
      <data key="d4">8.0</data>
      <data key="d5">Unit tests are designed to validate the functionality of the add function, ensuring it performs as intended.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="UNIT TEST RESULTS" target="UNIT TEST">
      <data key="d4">8.0</data>
      <data key="d5">Unit tests are used to generate unit test results, which indicate the success or failure of the tests performed on a function.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS">
      <data key="d4">4.0</data>
      <data key="d5">Both products are examples of items that can be searched for and evaluated in an online shopping context.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="ENJOY LIFE FOODS">
      <data key="d4">1.0</data>
      <data key="d5">Enjoy Life Foods is a brand that may offer similar products to Bright Citrus Deodorant, focusing on allergen-free and natural ingredients.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="GINGER FRESH DEODORANT">
      <data key="d4">6.0</data>
      <data key="d5">Both Bright Citrus and Ginger Fresh Deodorants are products offered by Earth Mama, designed for sensitive skin and pregnancy.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="CALMING LAVENDER DEODORANT">
      <data key="d4">6.0</data>
      <data key="d5">Both Bright Citrus and Calming Lavender Deodorants are products offered by Earth Mama, designed for sensitive skin and pregnancy.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="TRAVEL SET (4-PACK)">
      <data key="d4">5.0</data>
      <data key="d5">The Travel Set (4-Pack) may include Bright Citrus Deodorant as one of its options, catering to users who prefer various scents.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="3 OUNCE (PACK OF 1)">
      <data key="d4">7.0</data>
      <data key="d5">The 3 Ounce (Pack of 1) refers to the size of the Bright Citrus Deodorant, indicating its individual packaging.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="3-OUNCE (2-PACK)">
      <data key="d4">7.0</data>
      <data key="d5">The 3-Ounce (2-Pack) refers to a packaging option for the Bright Citrus Deodorant, providing users with two units for convenience.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="NATURAL AND SAFE FOR SENSITIVE SKIN">
      <data key="d4">8.0</data>
      <data key="d5">The Bright Citrus Deodorant is marketed as natural and safe for sensitive skin, appealing to users with skin sensitivities.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="ORGANIC CALENDULA">
      <data key="d4">1.0</data>
      <data key="d5">Organic Calendula is an ingredient in the Bright Citrus Deodorant, contributing to its soothing properties for sensitive skin.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="SEARCH ACTION" target="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS">
      <data key="d4">6.0</data>
      <data key="d5">The Search Action is executed to find the Dairy Free and Apple Variety Pack of Chips based on user preferences.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="SEARCH ACTION" target="4 OUNCE PACK">
      <data key="d4">1.0</data>
      <data key="d5">The user is looking for products that fulfill the constraint of being in a 4 ounce pack, indicating a specific size preference.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="CORRECTNESS SCORE">
      <data key="d4">8.0</data>
      <data key="d5">The Value Function Prompt is used to determine the Correctness Score of a purchasing trajectory based on how well it meets the specified criteria.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS" target="LENTIL CHIPS VARIETY PACK">
      <data key="d4">7.0</data>
      <data key="d5">The dairy-free and apple variety pack of chips is similar to the lentil chips variety pack, both being dairy-free snack options.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS" target="VARIETY PACK">
      <data key="d4">7.0</data>
      <data key="d5">The dairy-free and apple variety pack of chips is a specific example of a variety pack that includes multiple flavors or types of chips.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="DAIRY FREE AND APPLE VARIETY PACK OF CHIPS" target="BUDGET">
      <data key="d4">8.0</data>
      <data key="d5">The budget of $30 influences the decision to purchase the dairy-free and apple variety pack of chips.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE FOODS" target="SOFT BAKED OVALS">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Foods produces Soft Baked Ovals, which are part of their allergen-free product line.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE FOODS" target="SOFT BAKED CHEWY BARS">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Foods produces Soft Baked Chewy Bars, which are part of their allergen-free product line.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE FOODS" target="LENTIL CHIPS VARIETY PACK">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Foods produces the Lentil Chips Variety Pack, which is part of their allergen-free product line.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="CALMING LAVENDER DEODORANT" target="GINGER FRESH DEODORANT">
      <data key="d4">6.0</data>
      <data key="d5">Both Ginger Fresh and Calming Lavender Deodorants are products offered by Earth Mama, designed for sensitive skin and pregnancy.</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="SOFT BAKED OVALS" target="PRICE">
      <data key="d4">6.0</data>
      <data key="d5">The price of Soft Baked Ovals is a key factor for consumers when considering a purchase.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="SOFT BAKED CHEWY BARS" target="PRICE">
      <data key="d4">6.0</data>
      <data key="d5">The price of Soft Baked Chewy Bars is a key factor for consumers when considering a purchase.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LENTIL CHIPS VARIETY PACK" target="VARIETY PACK">
      <data key="d4">7.0</data>
      <data key="d5">The Lentil Chips Variety Pack is a specific example of a variety pack that includes multiple flavors of lentil chips.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LENTIL CHIPS VARIETY PACK" target="PRICE">
      <data key="d4">6.0</data>
      <data key="d5">The price of the Lentil Chips Variety Pack is a key factor for consumers when considering a purchase.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="LOUISVILLE VEGAN JERKY">
      <data key="d4">6.0</data>
      <data key="d5">Both products cater to dietary restrictions, with the gluten-free vegetarian smoked peppered bacon being a meat alternative similar to the offerings from Louisville Vegan Jerky.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="PRICE">
      <data key="d4">6.0</data>
      <data key="d5">The price of gluten-free vegetarian smoked peppered bacon is a key factor for consumers when considering a purchase.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="BUDGET">
      <data key="d4">1.0</data>
      <data key="d5">The budget of $40 influences the decision to purchase gluten-free vegetarian smoked peppered bacon.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="SMOKED BACON SEA SALT 3-PACK">
      <data key="d4">5.0</data>
      <data key="d5">Louisville Vegan Jerky and the Smoked Bacon Sea Salt 3-Pack both offer flavor profiles that appeal to consumers looking for savory snacks.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="SPICY HOT PEPPER SEA SALT 3-PACK">
      <data key="d4">1.0</data>
      <data key="d5">Louisville Vegan Jerky and the Spicy Hot Pepper Sea Salt 3-Pack both cater to consumers looking for spicy and flavorful snack options.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="PRICE">
      <data key="d4">6.0</data>
      <data key="d5">The price of Louisville Vegan Jerky is a key factor for consumers when considering a purchase.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="NON-GMO">
      <data key="d4">7.0</data>
      <data key="d5">Louisville Vegan Jerky is also labeled as Non-GMO, appealing to health-conscious consumers.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="GLUTEN-FREE">
      <data key="d4">8.0</data>
      <data key="d5">Louisville Vegan Jerky is gluten-free, catering to individuals with dietary restrictions.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="PEPPER FLAVORS">
      <data key="d4">6.0</data>
      <data key="d5">Louisville Vegan Jerky features flavors that may include pepper varieties, contributing to its overall flavor.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="BLACK PEPPER">
      <data key="d4">6.0</data>
      <data key="d5">Louisville Vegan Jerky may contain Black Pepper as a seasoning, enhancing its overall flavor.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="BUFFALO DILL">
      <data key="d4">8.0</data>
      <data key="d5">Buffalo Dill is one of the flavor variants of Louisville Vegan Jerky, contributing to its diverse taste offerings.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="PEPPERONI">
      <data key="d4">8.0</data>
      <data key="d5">Pepperoni is one of the flavor variants of Louisville Vegan Jerky, appealing to those who enjoy spicy flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="MAPLE BACON">
      <data key="d4">8.0</data>
      <data key="d5">Maple Bacon is a flavor variant of Louisville Vegan Jerky, combining sweet and savory elements.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="CAROLINA BBQ">
      <data key="d4">8.0</data>
      <data key="d5">Carolina BBQ is a flavor variant of Louisville Vegan Jerky, reflecting regional barbecue flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="NON-GMO" target="SPICY HOT PEPPER SEA SALT">
      <data key="d4">7.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt is labeled as Non-GMO, indicating it meets specific dietary standards.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT" target="GLUTEN-FREE">
      <data key="d4">8.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt is marketed as gluten-free, making it suitable for those with gluten sensitivities.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT" target="PEPPER FLAVORS">
      <data key="d4">6.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt includes various pepper flavors, enhancing its taste profile.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT" target="GHOST PEPPER">
      <data key="d4">7.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt includes Ghost Pepper as one of its flavor components, contributing to its spiciness.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT" target="JALAPENO">
      <data key="d4">6.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt may include Jalapeno as part of its pepper blend, enhancing its flavor profile.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT" target="HABANERO">
      <data key="d4">6.0</data>
      <data key="d5">Spicy Hot Pepper Sea Salt may include Habanero, adding to its heat and flavor complexity.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SHENGRAN HU" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">8.0</data>
      <data key="d5">Shengran Hu is a researcher contributing to the development of the Automated Design of Agentic Systems (ADAS) research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="JEFF CLUNE">
      <data key="d4">8.0</data>
      <data key="d5">Shengran Hu and Jeff Clune co-authored a paper on intelligent exploration using foundation models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="CONG LU" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">8.0</data>
      <data key="d5">Cong Lu is a researcher contributing to the development of the Automated Design of Agentic Systems (ADAS) research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONG LU" target="JEFF CLUNE">
      <data key="d4">8.0</data>
      <data key="d5">Cong Lu and Jeff Clune co-authored a paper on intelligent exploration using foundation models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="CONG LU" target="VARIBAD">
      <data key="d4">8.0</data>
      <data key="d5">Cong Lu is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JEFF CLUNE" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune is a researcher contributing to the development of the Automated Design of Agentic Systems (ADAS) research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="AI SCIENTIST">
      <data key="d4">7.0</data>
      <data key="d5">Jeff Clune is involved in research related to the AI Scientist concept, contributing to automated scientific discovery.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JEFF CLUNE" target="ZHICHAO LU">
      <data key="d4">8.0</data>
      <data key="d5">Zhichao Lu and Jeff Clune co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JEFF CLUNE" target="RUI WANG">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune and Rui Wang are co-authors on multiple papers related to open-ended reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JEFF CLUNE" target="KENNETH O. STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune and Kenneth O. Stanley are co-authors on multiple papers related to evolutionary algorithms and reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JEFF CLUNE" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune is a co-author of the OMNI research project focused on open-endedness in models of human notions of interestingness.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="FOUNDATION MODELS (FMS)">
      <data key="d4">15.0</data>
      <data key="d5">Foundation Models are utilized as modules within agentic systems, which are a focus of the ADAS research area.
ADAS involves the use of Foundation Models as modules in the control flow for solving tasks.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="META AGENT SEARCH">
      <data key="d4">24.0</data>
      <data key="d5">Meta Agent Search is an algorithm developed within the ADAS research area to create new agentic systems.
ADAS encompasses the Meta Agent Search algorithm, which is designed to automate the creation of agentic systems.
Meta Agent Search is an algorithm that exemplifies the principles of ADAS by discovering agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="CHAIN-OF-THOUGHT PLANNING">
      <data key="d4">6.0</data>
      <data key="d5">Chain-of-thought planning is one of the effective building blocks proposed for agentic systems in the ADAS research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="ROCKT&#196;SCHEL (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Rockt&#228;schel (2024) provides insights relevant to the development of compound agentic systems in the context of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="ZAHARIA ET AL. (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Zaharia et al. (2024) provides insights relevant to the development of compound agentic systems in the context of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">6.0</data>
      <data key="d5">AI-Generating Algorithms are relevant to the ADAS research area as they demonstrate the potential of learned AI systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="NEURAL ARCHITECTURE SEARCH">
      <data key="d4">1.0</data>
      <data key="d5">Neural Architecture Search is a technique that can be applied within the ADAS research area to improve agentic system designs.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="AI SCIENTIST">
      <data key="d4">8.0</data>
      <data key="d5">The AI Scientist exemplifies the goals of ADAS by automating the development of machine learning algorithms.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="OMNI-EPIC">
      <data key="d4">7.0</data>
      <data key="d5">OMNI-EPIC showcases the potential of ADAS by automatically generating diverse learning environments for robotics.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="FERNANDO ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Fernando et al. (2024) explores existing methods in ADAS, focusing on prompt design limitations.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="YANG ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Yang et al. (2024) examines the constraints of current ADAS methods, particularly in designing prompts.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="SEARCH SPACE">
      <data key="d4">8.0</data>
      <data key="d5">The search space is a fundamental component of ADAS, defining the agentic systems that can be represented.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="EVALUATION FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">The evaluation function is used in ADAS to assess the performance of candidate agents based on defined objectives.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="CHASE (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Chase (2024) contributes to the foundational understanding of agentic systems within the context of ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="NG (2024)">
      <data key="d4">1.0</data>
      <data key="d5">Ng (2024) contributes to the foundational understanding of agentic systems within the context of ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Agentic systems are the focus of the research area ADAS, which aims to automate their design and optimization.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="OPTIMIZATION PROCESS">
      <data key="d4">8.0</data>
      <data key="d5">The optimization process is a key component in the development of ADAS algorithms to enhance agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="ITERATIVE PROCESSING">
      <data key="d4">7.0</data>
      <data key="d5">Foundation Models often utilize iterative processing to refine their outputs and improve task performance.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="EUREKA">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models are utilized in the Eureka method to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="LANGUAGE-TO-REWARD">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models enable the language-to-reward technique to create reward functions for reinforcement learning.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="OMNI-EPIC">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models are used in OMNI-EPIC to create robotics learning environments through programming.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="RAFAILOV ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Rafailov et al. (2024) discusses the application of Foundation Models in preference learning for FM alignment training.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="YU ET AL. (2023)">
      <data key="d4">6.0</data>
      <data key="d5">Yu et al. (2023) provides insights into how Foundation Models can be used to create reward functions for reinforcement learning.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="FALDOR ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Faldor et al. (2024) discusses the role of Foundation Models in creating robotics learning environments through OMNI-EPIC.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="META AGENT SEARCH" target="AGENT ARCHIVE">
      <data key="d4">7.0</data>
      <data key="d5">The agent archive is utilized by the Meta Agent Search algorithm to inform the programming of new agents.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-STEP PEER REVIEW AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Multi-step Peer Review Agent is an example of an agent discovered through the Meta Agent Search algorithm.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VERIFIED MULTIMODAL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Verified Multimodal Agent is an example of an agent discovered through the Meta Agent Search algorithm.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DIVIDE AND CONQUER AGENT">
      <data key="d4">1.0</data>
      <data key="d5">The Divide and Conquer Agent is an example of an agent discovered through the Meta Agent Search algorithm.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXAMPLE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is responsible for creating new example agents through its iterative design process.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BOYER &amp; MOORE (1983)">
      <data key="d4">5.0</data>
      <data key="d5">Boyer &amp; Moore (1983) discusses Turing completeness, relevant to the capabilities of the Meta Agent Search algorithm.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LADHA (2024)">
      <data key="d4">1.0</data>
      <data key="d5">Ladha (2024) provides insights into Turing completeness, which is significant for understanding the Meta Agent Search algorithm's potential.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FOUNDATIONAL MODELS (FMS)">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search utilizes foundational models (FMs) as meta agents to create new agents based on previous discoveries.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is designed to define and search for agentic systems, programming them iteratively.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARCHIVE">
      <data key="d4">7.0</data>
      <data key="d5">The archive is used in Meta Agent Search to store previously discovered agents and their evaluation metrics, informing future proposals.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="PROMPTING TECHNIQUES">
      <data key="d4">7.0</data>
      <data key="d5">Prompting techniques are employed in Meta Agent Search to guide the meta agent in generating new agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC LOGIC PUZZLE TASK">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search is evaluated using the ARC logic puzzle task to assess the performance of the generated agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DROP">
      <data key="d4">13.0</data>
      <data key="d5">The performance of agents generated by Meta Agent Search is evaluated using the DROP dataset for reading comprehension tasks.
DROP is one of the benchmarks used to evaluate the reading comprehension capabilities of agents discovered by Meta Agent Search.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MGSM">
      <data key="d4">21.0</data>
      <data key="d5">The performance of agents generated by Meta Agent Search is evaluated using the MGSM dataset for math tasks.
MGSM is a benchmark used to evaluate the math capabilities of agents discovered by Meta Agent Search.
MGSM is a benchmark used to assess the performance of agents in math tasks discovered through Meta Agent Search, demonstrating their effectiveness in this domain.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FUNSEARCH">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search references FunSearch as a framework for defining new agents based on tasks.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ITERATIONS">
      <data key="d4">14.0</data>
      <data key="d5">Iterations are a fundamental part of the Meta Agent Search process, allowing for continuous improvement of agent proposals.
Iterations refer to the cycles of evaluation that agents undergo during the Meta Agent Search process, impacting their performance outcomes.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VALIDATION DATA">
      <data key="d4">1.0</data>
      <data key="d5">Validation data is utilized in the Meta Agent Search to assess the effectiveness of newly generated agents in the target domain.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC CHALLENGE">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search is applied to the ARC Challenge to discover novel agentic systems that outperform existing agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SELF-CONSISTENCY WITH COT (COT-SC)">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search compares its discovered agents against Self-Consistency with COT to assess improvements in accuracy.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LLM DEBATE">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search assesses agents that employ LLM Debate to leverage diverse perspectives for better answers.
LLM Debate is evaluated as a technique within Meta Agent Search to enhance the reasoning capabilities of discovered agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="QUALITY-DIVERSITY">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search includes Quality-Diversity as a method for exploring diverse solutions in agent discovery.
Quality-Diversity is assessed as a technique in Meta Agent Search to generate diverse and high-quality agents for various tasks.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXPERTS">
      <data key="d4">1.0</data>
      <data key="d5">Experts provide structured feedback to the agents discovered through Meta Agent Search, evaluating their performance on various traits.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ADAS">
      <data key="d4">22.0</data>
      <data key="d5">Meta Agent Search showcases the potential of ADAS by discovering agents that outperform traditional systems through innovative design patterns.
Meta Agent Search is a technique employed within ADAS to program new agents effectively by leveraging existing algorithms.
ADAS proposes the use of Meta Agent Search to automatically discover new agents through iterative programming.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FEEDBACK MECHANISM">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search utilizes a sophisticated feedback mechanism to refine agent performance iteratively.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STEP-BACK ABSTRACTION">
      <data key="d4">6.0</data>
      <data key="d5">Step-back Abstraction is one of the baseline techniques compared against the performance of agents discovered by Meta Agent Search.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ROLE ASSIGNMENT">
      <data key="d4">6.0</data>
      <data key="d5">Role Assignment is another baseline technique used for comparison with agents discovered by Meta Agent Search.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MMLU">
      <data key="d4">7.0</data>
      <data key="d5">MMLU is a benchmark used to evaluate the multi-task problem-solving capabilities of agents discovered by Meta Agent Search.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPQA">
      <data key="d4">7.0</data>
      <data key="d5">GPQA is a benchmark used to evaluate the capability of agents in solving hard science questions in the context of Meta Agent Search.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MEYERSON ET AL. (2023)">
      <data key="d4">1.0</data>
      <data key="d5">Meyerson et al. (2023) provides insights relevant to the development and performance of the feedback mechanisms in Meta Agent Search.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is compared against state-of-the-art hand-designed agents to demonstrate its superior performance across various domains.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="AGENT NAME">
      <data key="d4">7.0</data>
      <data key="d5">Agent Name is used to identify and evaluate the performance of agents discovered through the Meta Agent Search process.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HOLD-OUT TEST SETS">
      <data key="d4">1.0</data>
      <data key="d5">Hold-out test sets are utilized in the Meta Agent Search to ensure unbiased evaluation of agent performance after training.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FOUNDATION MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search discovers agents that can be transferred across different foundation models, demonstrating their generalizability.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CLAUDE-HAIKU">
      <data key="d4">7.0</data>
      <data key="d5">Claude-Haiku is used to evaluate the performance of agents discovered by Meta Agent Search, contributing to the assessment of their effectiveness.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CLAUDE-SONNET">
      <data key="d4">7.0</data>
      <data key="d5">Claude-Sonnet is evaluated for its performance with agents discovered by Meta Agent Search, highlighting the effectiveness of these agents.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC">
      <data key="d4">16.0</data>
      <data key="d5">ARC is a benchmark used to evaluate the accuracy of agents discovered through Meta Agent Search, providing a measure of their performance in reading comprehension tasks.
Meta Agent Search aims to discover agents that perform well on the ARC benchmark, contributing to advancements in AI evaluation.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CHAIN-OF-THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought is one of the techniques evaluated for its effectiveness in the context of Meta Agent Search, contributing to the discovery of effective agents.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="COT-SC">
      <data key="d4">7.0</data>
      <data key="d5">COT-SC is another technique assessed within the framework of Meta Agent Search, aimed at improving agent performance.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM8K">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search improves accuracy on the GSM8K dataset by discovering effective agents.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM-HARD">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search improves accuracy on the GSM-HARD dataset by discovering effective agents.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SVAMP">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search improves performance on the SVAMP dataset by discovering effective agents.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ASDIV">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search improves performance on the ASDiv dataset by discovering effective agents.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d4">8.0</data>
      <data key="d5">Dynamic Role-Playing Architecture is a top-performing agent discovered through Meta Agent Search.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d4">8.0</data>
      <data key="d5">Structured Multimodal Feedback Loop is a top-performing agent discovered through Meta Agent Search.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="META AGENT SEARCH" target="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d4">1.0</data>
      <data key="d5">Interactive Multimodal Feedback Loop is a top-performing agent discovered through Meta Agent Search.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="DIVIDE AND CONQUER AGENT">
      <data key="d4">5.0</data>
      <data key="d5">Both agents are examples of discovered agents that utilize structured methodologies for problem-solving.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="CRITIC MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Critic Module is employed in the Multi-Step Peer Review Agent to assess and provide feedback on answers.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="TASK INFO">
      <data key="d4">6.0</data>
      <data key="d5">Task Info is the input provided to the Multi-Step Peer Review Agent for processing and generating answers.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="DIVIDE AND CONQUER AGENT">
      <data key="d4">1.0</data>
      <data key="d5">The Verified Multimodal Agent and Divide and Conquer Agent are both discovered agents focusing on different domains of problem-solving.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="HOG" target="DALAL &amp; TRIGGS (2005)">
      <data key="d4">6.0</data>
      <data key="d5">Dalal &amp; Triggs (2005) introduced the HOG feature, which is a significant example of hand-designed features in computer vision.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HOG" target="CNNS">
      <data key="d4">7.0</data>
      <data key="d5">HOG features have been surpassed by learned features from CNNs in the field of computer vision.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CNNS" target="NEURAL ARCHITECTURE SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">CNNs are often optimized through Neural Architecture Search methods to achieve better performance.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="HUTTER ET AL. (2019)" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">6.0</data>
      <data key="d5">Hutter et al. (2019) discusses AutoML methods that highlight the effectiveness of AI-Generating Algorithms.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HUTTER ET AL. (2019)" target="AUTOML METHODS">
      <data key="d4">6.0</data>
      <data key="d5">Hutter et al. (2019) provides foundational insights into the development and effectiveness of AutoML methods.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ELSEN ET AL. (2019)">
      <data key="d4">6.0</data>
      <data key="d5">Elsken et al. (2019) provides insights into the application of Neural Architecture Search in optimizing CNN models.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="SHEN ET AL. (2023)">
      <data key="d4">6.0</data>
      <data key="d5">Shen et al. (2023) contributes to the understanding of Neural Architecture Search techniques in CNN development.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="META-LEARNING ARCHITECTURES">
      <data key="d4">8.0</data>
      <data key="d5">Neural Architecture Search is a specific application of meta-learning architectures aimed at optimizing neural networks.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Neural Architecture Search provides insights that can enhance the design and understanding of agentic systems in ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AUTOML METHODS" target="AI-GENERATING ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">AI-GAs are a subset of AutoML methods that focus on generating AI systems automatically.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="CLUNE (2019)">
      <data key="d4">7.0</data>
      <data key="d5">Clune (2019) discusses the advantages of AI-Generating Algorithms, contributing to the understanding of their superiority over traditional methods.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">ADAS aims to invent novel building blocks that can be developed using AI-Generating Algorithms for automated systems.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="AUTOML">
      <data key="d4">8.0</data>
      <data key="d5">AI-Generating Algorithms and AutoML both focus on automating components in AI systems to enhance efficiency and performance.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="META-LEARNING ARCHITECTURES">
      <data key="d4">8.0</data>
      <data key="d5">AI-Generating Algorithms include meta-learning architectures as a key component for improving AI system design.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="META-LEARNING ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">AI-Generating Algorithms utilize meta-learning algorithms to enhance the learning capabilities of AI systems.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="LEARNING ENVIRONMENTS">
      <data key="d4">7.0</data>
      <data key="d5">AI-Generating Algorithms aim to create effective learning environments for training AI models.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LEARNED LOSS FUNCTIONS" target="DPO">
      <data key="d4">6.0</data>
      <data key="d5">Learned loss functions are compared against DPO to demonstrate their superior performance in training AI models.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="LEARNED LOSS FUNCTIONS" target="LU ET AL. (2024A)">
      <data key="d4">7.0</data>
      <data key="d5">Lu et al. (2024a) compares learned loss functions with traditional methods, highlighting their effectiveness in LLM alignment.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="DPO" target="RAFALIOV ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Rafailov et al. (2024) discusses the DPO loss function, providing context for its use in AI training.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AI SCIENTIST" target="LU ET AL. (2024B)">
      <data key="d4">7.0</data>
      <data key="d5">Lu et al. (2024b) presents the AI Scientist, illustrating its role in automated research and algorithm development.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="OMNI-EPIC" target="FALDOR ET AL. (2024)">
      <data key="d4">7.0</data>
      <data key="d5">Faldor et al. (2024) discusses the OMNI-EPIC framework, showcasing its capabilities in generating robotics learning environments.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="OMNI-EPIC" target="FOUNDATION MODELS">
      <data key="d4">8.0</data>
      <data key="d5">OMNI-EPIC utilizes Foundation Models to automate the creation of robotics learning environments.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="F1 SCORES" target="DROP">
      <data key="d4">7.0</data>
      <data key="d5">F1 scores are used to evaluate the performance of agents on the DROP dataset for reading comprehension tasks.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="F1 SCORES" target="MGSM">
      <data key="d4">7.0</data>
      <data key="d5">F1 scores are also used to assess the performance of agents on the MGSM dataset for math tasks.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="F1 SCORES" target="GSM8K">
      <data key="d4">7.0</data>
      <data key="d5">F1 scores are utilized to measure the effectiveness of agents on the GSM8K dataset for math tasks.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="F1 SCORES" target="GSM-HARD">
      <data key="d4">1.0</data>
      <data key="d5">F1 scores are applied to evaluate agents on the GSM-HARD dataset, which presents challenging math problems.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="DROP" target="INITIAL_SOLUTIONS">
      <data key="d4">6.0</data>
      <data key="d5">DROP is a dataset that influences the style of questions used in evaluating initial solutions, particularly in reading comprehension.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="DROP" target="GTP-4O-2024-05-13">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent uses GPT-4O-2024-05-13 to perform well on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="GPT-3.5-TURBO-0125">
      <data key="d4">6.0</data>
      <data key="d5">Discovered agents and baselines are evaluated using GPT-3.5-Turbo-0125 for the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="SELF-CONSISTENCY WITH COT (COT-SC)">
      <data key="d4">5.0</data>
      <data key="d5">Self-Consistency with Chain-of-Thought (COT-SC) is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="LLM-DEBATE">
      <data key="d4">5.0</data>
      <data key="d5">LLM-Debate is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="QUALITY-DIVERSITY">
      <data key="d4">5.0</data>
      <data key="d5">Quality-Diversity is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="STEP-BACK ABSTRACTION">
      <data key="d4">5.0</data>
      <data key="d5">Step-back Abstraction is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="ROLE ASSIGNMENT">
      <data key="d4">1.0</data>
      <data key="d5">Role Assignment is one of the hand-designed agent baselines implemented for experiments on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="MMLU">
      <data key="d4">6.0</data>
      <data key="d5">DROP's focus on reading comprehension contributes to the overall multitask understanding evaluated by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MGSM" target="GSM8K">
      <data key="d4">6.0</data>
      <data key="d5">GSM8K is one of the datasets used in the MGSM benchmark to evaluate the performance of agents in solving math problems.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="MGSM" target="GSM-HARD">
      <data key="d4">6.0</data>
      <data key="d5">GSM-HARD is another dataset used in the MGSM benchmark for evaluating agent performance in challenging math tasks.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="MGSM" target="SVAMP">
      <data key="d4">6.0</data>
      <data key="d5">SVAMP is included in the MGSM benchmark to assess the performance of agents in solving various math problems.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="MGSM" target="ASDIV">
      <data key="d4">1.0</data>
      <data key="d5">ASDIV is part of the MGSM benchmark used to evaluate the performance of agents in diverse math tasks.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="MGSM" target="GTP-4O-2024-05-13">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent uses GPT-4O-2024-05-13 to perform well on the MGSM benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MGSM" target="GPT-3.5-TURBO-0125">
      <data key="d4">6.0</data>
      <data key="d5">Discovered agents and baselines are evaluated using GPT-3.5-Turbo-0125 for the MGSM benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GSM8K" target="GSM-HARD">
      <data key="d4">1.0</data>
      <data key="d5">Both GSM8K and GSM-HARD are datasets used to evaluate the performance of agents in math tasks, providing benchmarks for comparison.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="GSM8K" target="ORCA-3">
      <data key="d4">18.0</data>
      <data key="d5">GSM8K is a benchmark where Orca-3 shows a notable improvement in mathematical problem-solving capabilities.
Orca-3 demonstrates improved performance on the GSM8K benchmark, showcasing its mathematical reasoning capabilities.
GSM8K benchmarks are used to evaluate Orca-3's performance on multi-step arithmetic tasks, showcasing its capabilities in math problem-solving.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GSM8K" target="MMLU">
      <data key="d4">5.0</data>
      <data key="d5">GSM8K's math problems require reasoning skills that are relevant to the multitask understanding measured by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="FERNANDO ET AL. (2024)" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Fernando et al. (2024) contributes to ADAS by discussing PromptBreeder for improving prompt engineering.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="YANG ET AL. (2024)" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Yang et al. (2024) contributes to the ADAS framework by discussing OPRO for automating prompt engineering.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SEARCH SPACE" target="PROMPTBREEDER">
      <data key="d4">6.0</data>
      <data key="d5">PromptBreeder operates within a specific search space by mutating text prompts while maintaining other components.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="ACCURACY">
      <data key="d4">8.0</data>
      <data key="d5">Accuracy is one of the key metrics used in the evaluation function to assess the performance of agents in ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="COST">
      <data key="d4">8.0</data>
      <data key="d5">Cost is another important metric considered in the evaluation function for optimizing agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="LATENCY">
      <data key="d4">7.0</data>
      <data key="d5">Latency is a metric that can be included in the evaluation function to assess the efficiency of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="SAFETY">
      <data key="d4">1.0</data>
      <data key="d5">Safety is a crucial metric in the evaluation function to ensure that agentic systems operate without causing harm.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="PROMPTBREEDER" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">ADAS includes the use of PromptBreeder to improve prompt engineering for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ACCURACY" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Accuracy is another metric used to assess the performance of state-of-the-art hand-designed agents in various tasks.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="PROMPTING TECHNIQUES">
      <data key="d4">8.0</data>
      <data key="d5">Agentic Systems utilize Prompting Techniques to enhance their problem-solving capabilities.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="EXTERNAL MEMORY">
      <data key="d4">8.0</data>
      <data key="d5">Agentic Systems use External Memory to store and retrieve information, enhancing their capabilities.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="FM MODULES">
      <data key="d4">8.0</data>
      <data key="d5">FM Modules are integral to Agentic Systems, allowing for role assignment and collaboration among different components.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="ADAS">
      <data key="d4">1.0</data>
      <data key="d5">ADAS aims to develop new building blocks and design powerful Agentic Systems in an automated manner.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="FUNSEARCH" target="FOUNDATION MODELS">
      <data key="d4">8.0</data>
      <data key="d5">FunSearch employs Foundation Models to discover better optimization algorithms through automated coding.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LLM DEBATE" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">LLM Debate is a baseline technique evaluated against state-of-the-art hand-designed agents to measure enhancements in reasoning.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="LLM DEBATE" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">LLM Debate is a technique used by manually designed agents to improve their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="LLM DEBATE" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">LLM Debate is a manually designed agent that can be optimized through the principles of ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">Quality-Diversity is a baseline technique that is compared with state-of-the-art hand-designed agents to evaluate its impact on solution quality.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Quality-Diversity is a technique used by manually designed agents to improve their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="ADAS">
      <data key="d4">6.0</data>
      <data key="d5">Quality-Diversity is a manually designed agent that can benefit from the advancements proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="HUMAN-LIKE CRITIC" target="REFINEMENT">
      <data key="d4">8.0</data>
      <data key="d5">Human-like critics provide feedback during the refinement process to enhance the agents' performance.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="EFFICIENCY EXPERT" target="REFINEMENT">
      <data key="d4">7.0</data>
      <data key="d5">Efficiency experts contribute to the refinement process by evaluating the speed and effectiveness of agents' answers.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="READABILITY EXPERT" target="REFINEMENT">
      <data key="d4">7.0</data>
      <data key="d5">Readability experts play a role in the refinement process by assessing the clarity of the agents' answers.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="SIMPLICITY EXPERT" target="REFINEMENT">
      <data key="d4">7.0</data>
      <data key="d5">Simplicity experts assist in the refinement process by evaluating how straightforward the agents' answers are.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="TOP-3 ANSWERS" target="FINAL ANSWER">
      <data key="d4">1.0</data>
      <data key="d5">The final answer is derived from the evaluation of the top-3 answers generated by the agents during the refinement process.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="FINAL ANSWER" target="STUDENT RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">The student response contains the final answer extracted from the student's answer to the question.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="FINAL ANSWER" target="ALPHABET ID">
      <data key="d4">8.0</data>
      <data key="d5">The final answer is represented by the alphabet ID that corresponds to the option chosen by the student.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="ADAS" target="CHAIN-OF-THOUGHT">
      <data key="d4">6.0</data>
      <data key="d5">Chain-of-Thought is an example of a manually designed agent that can be improved through the principles of ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="COT-SC">
      <data key="d4">6.0</data>
      <data key="d5">COT-SC is an example of a manually designed agent that can benefit from the innovations proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="STEP-BACK ABSTRACTION">
      <data key="d4">6.0</data>
      <data key="d5">Step-back Abstraction is a manually designed agent that can be improved by the innovations proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="ROLE ASSIGNMENT">
      <data key="d4">6.0</data>
      <data key="d5">Role Assignment is a manually designed agent that can be enhanced through the methodologies proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d4">6.0</data>
      <data key="d5">Dynamic Role-Playing Architecture is an agent that can be optimized through the principles of ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d4">6.0</data>
      <data key="d5">Structured Multimodal Feedback Loop is an agent that can be improved by the innovations proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d4">1.0</data>
      <data key="d5">Interactive Multimodal Feedback Loop is an agent that can benefit from the advancements proposed in ADAS.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="OPRO">
      <data key="d4">7.0</data>
      <data key="d5">ADAS involves the use of OPRO to automate prompt engineering for agents, enhancing their reasoning capabilities.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="SELF-DISCOVER">
      <data key="d4">7.0</data>
      <data key="d5">ADAS incorporates Self-Discover to automate the creation of effective prompts for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="EVOAGENT">
      <data key="d4">7.0</data>
      <data key="d5">EvoAgent is part of the ADAS framework, optimizing role definitions in prompts for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENTVERSE">
      <data key="d4">7.0</data>
      <data key="d5">AgentVerse contributes to ADAS by optimizing agent roles and definitions to improve performance.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="DYLAN">
      <data key="d4">7.0</data>
      <data key="d5">DyLAN is utilized in ADAS to score response quality in agent networks and prune connections.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="DSPY">
      <data key="d4">7.0</data>
      <data key="d5">DSPy is part of ADAS, generating and optimizing nodes in agentic systems.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="GPT-SWARM">
      <data key="d4">7.0</data>
      <data key="d5">GPT-Swarm represents agentic systems in a graph format, optimizing connections as part of ADAS.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENTOPTIMIZER">
      <data key="d4">7.0</data>
      <data key="d5">AgentOptimizer is a component of ADAS that learns the tools used in agentic systems.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENT SYMBOLIC LEARNING">
      <data key="d4">7.0</data>
      <data key="d5">Agent Symbolic Learning is related to ADAS as it learns prompts, tools, and control flow in agentic systems.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="SAFETY CONSIDERATIONS">
      <data key="d4">6.0</data>
      <data key="d5">Safety considerations are crucial in the context of ADAS, especially when executing untrusted model-generated code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="ARTIFICIAL GENERAL INTELLIGENCE (AGI)">
      <data key="d4">1.0</data>
      <data key="d5">ADAS is a new area of research that could contribute to the development of Artificial General Intelligence (AGI).</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="ZHOU ET AL. (2024)">
      <data key="d4">7.0</data>
      <data key="d5">Zhou et al. (2024) contributes to ADAS by discussing Self-Discover for automating prompt creation.Zhou et al. (2024) contributes to ADAS by discussing Agent Symbolic Learning and its learning of prompts, tools, and control flow.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="KHATTAB ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Khattab et al. (2024) provides insights relevant to ADAS through the study of DSPy and its optimization of nodes.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="ZHUGE ET AL. (2024)">
      <data key="d4">6.0</data>
      <data key="d5">Zhuge et al. (2024) contributes to ADAS by discussing GPT-Swarm and its optimization of connections in agentic systems.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="FOUNDATIONAL MODELS">
      <data key="d4">8.0</data>
      <data key="d5">ADAS utilizes foundational models to create powerful algorithms for developing intelligent agents without the need for expensive hardware.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="CONSTITUTIONAL AI">
      <data key="d4">6.0</data>
      <data key="d5">ADAS aims to incorporate Constitutional AI principles to ensure the safe and ethical operation of the agents it develops.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="MULTI-OBJECTIVE SEARCH ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">Integrating multi-objective search algorithms into ADAS can improve its ability to optimize for various performance criteria simultaneously.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="EVALUATION FUNCTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Evaluation functions are critical for assessing the performance of agents created through ADAS, guiding improvements and refinements.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="HUMAN ORGANIZATIONS">
      <data key="d4">5.0</data>
      <data key="d5">Research in ADAS provides insights into how complexity arises from human organizations, influencing the design of agentic systems.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="COMPLEX DOMAINS">
      <data key="d4">1.0</data>
      <data key="d5">Exploring complex domains can enhance the capabilities of agents developed through ADAS, allowing them to perform in more intricate environments.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="YUNTAO BAI ET AL. (2022)">
      <data key="d4">5.0</data>
      <data key="d5">Yuntao Bai et al. (2022) provides insights relevant to the development of agentic systems in the context of AI feedback.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="YOSHUA BENGIO ET AL. (2024)">
      <data key="d4">5.0</data>
      <data key="d5">Yoshua Bengio et al. (2024) discusses risks that may inform the design of agentic systems in ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="N BOSTROM">
      <data key="d4">5.0</data>
      <data key="d5">N Bostrom's analysis of existential risks can provide a framework for understanding the implications of agentic systems in society.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="TRACEY CALDWELL">
      <data key="d4">5.0</data>
      <data key="d5">Tracey Caldwell's work on ethical hacking may inform the ethical considerations in the design of agentic systems.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="BANGHAO CHEN ET AL. (2023)">
      <data key="d4">6.0</data>
      <data key="d5">Banghao Chen et al. (2023) provides insights into prompt engineering that can enhance the design of agentic systems in ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="MARK CHEN ET AL. (2021)">
      <data key="d4">5.0</data>
      <data key="d5">Mark Chen et al. (2021) offers evaluations that may inform the development of agentic systems in ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="WEIZE CHEN ET AL. (2023)">
      <data key="d4">1.0</data>
      <data key="d5">Weize Chen et al. (2023) discusses multi-agent collaboration, relevant to the design of agentic systems in ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="STEP-BACK ABSTRACTION" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Step-back Abstraction is a technique used by manually designed agents to enhance their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Role Assignment is a technique used by manually designed agents to enable collaboration among modules.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="LLM-DEBATE">
      <data key="d4">8.0</data>
      <data key="d5">Role Assignment is a key component of the LLM-Debate method, where specific roles are assigned to debate modules.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="FM QUERY">
      <data key="d4">7.0</data>
      <data key="d5">FM Query is utilized in the Role Assignment technique to select roles for agents based on predefined criteria.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MMLU" target="GTP-4O-2024-05-13">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent uses GPT-4O-2024-05-13 to perform well on the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="GPT-3.5-TURBO-0125">
      <data key="d4">6.0</data>
      <data key="d5">Discovered agents and baselines are evaluated using GPT-3.5-Turbo-0125 for the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="ORCA-3">
      <data key="d4">23.0</data>
      <data key="d5">MMLU is another benchmark where Orca-3 demonstrates improved performance over Mistral-7B-Instruct.
Orca-3 shows improvement on the MMLU benchmark, indicating enhanced performance in various tasks.
MMLU benchmarks are used to evaluate Orca-3's performance in academic subjects, including mathematics, demonstrating its capabilities in complex problem-solving.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MMLU" target="EQBENCH">
      <data key="d4">7.0</data>
      <data key="d5">EQBench shows a strong correlation with MMLU, indicating that emotional intelligence is related to multitask understanding in language models.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="AGIEVAL">
      <data key="d4">6.0</data>
      <data key="d5">AGIEval assesses cognitive abilities that may overlap with the multitask understanding measured by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="ARC">
      <data key="d4">6.0</data>
      <data key="d5">ARC evaluates reasoning abilities that are essential for multitask understanding, as measured by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="BBH">
      <data key="d4">6.0</data>
      <data key="d5">BBH requires complex reasoning, which is a component of multitask understanding evaluated by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="GPQA">
      <data key="d4">6.0</data>
      <data key="d5">GPQA's challenging questions test specialized knowledge, which is part of the multitask understanding assessed by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="FOFO">
      <data key="d4">5.0</data>
      <data key="d5">FoFo's evaluation of format following may relate to the structured understanding required in MMLU assessments.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="IFEVAL">
      <data key="d4">5.0</data>
      <data key="d5">IFEval's focus on instruction-following is relevant to the comprehension skills assessed by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="MT-BENCH">
      <data key="d4">5.0</data>
      <data key="d5">MT-Bench assesses conversational competence, which may relate to the understanding required in MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="ALPACA EVAL">
      <data key="d4">5.0</data>
      <data key="d5">AlpacaEval's focus on instruction-following tasks is relevant to the multitask understanding evaluated by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="INFOBENCH">
      <data key="d4">1.0</data>
      <data key="d5">InFoBench's evaluation of instruction-following capabilities contributes to the overall understanding assessed by MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPQA" target="DAVID REIN">
      <data key="d4">8.0</data>
      <data key="d5">David Rein co-authored a paper on GPQA, contributing to the development of a benchmark for question and answer systems.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="GPQA" target="INITIAL_SOLUTIONS">
      <data key="d4">6.0</data>
      <data key="d5">GPQA is a dataset used to generate and evaluate initial solutions in the context of reasoning and problem-solving.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPQA" target="GTP-4O-2024-05-13">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent uses GPT-4O-2024-05-13 to perform well on the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="GPT-3.5-TURBO-0125">
      <data key="d4">6.0</data>
      <data key="d5">Discovered agents and baselines are evaluated using GPT-3.5-Turbo-0125 for the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="KHIZBULLIN">
      <data key="d4">6.0</data>
      <data key="d5">GPQA is a benchmark that may involve Khizbullin in testing language models' question-and-answer capabilities.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="F1 SCORE" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">F1 Score is used to evaluate the performance of state-of-the-art hand-designed agents in reading comprehension and math tasks.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">Chain-of-Thought is a baseline technique that is compared against state-of-the-art hand-designed agents to evaluate reasoning improvements.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought is a reasoning method used by manually designed agents to enhance their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="COT-SC" target="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">COT-SC is a baseline technique that is evaluated alongside state-of-the-art hand-designed agents for performance comparison.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="COT-SC" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">COT-SC is a technique used by manually designed agents to improve their performance.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="COT-SC" target="FINAL DECISION MODULE">
      <data key="d4">1.0</data>
      <data key="d5">The Final Decision Module is used in the COT-SC technique to consolidate multiple sampled answers into a final response.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="FOUNDATION MODELS" target="DISCOPOP">
      <data key="d4">8.0</data>
      <data key="d5">DiscoPOP uses Foundation Models to program loss functions for preference learning in AI training.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS" target="EUREKA">
      <data key="d4">8.0</data>
      <data key="d5">Eureka enables Foundation Models to write reward functions for reinforcement learning applications.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS" target="LANGUAGE-TO-REWARD">
      <data key="d4">1.0</data>
      <data key="d5">Language-to-reward allows Foundation Models to create reward functions for robotics reinforcement learning.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ARC" target="GPT-3.5-TURBO-0125">
      <data key="d4">6.0</data>
      <data key="d5">ARC utilizes the GPT-3.5-turbo-0125 model for evaluating discovered agents in reasoning and problem-solving tasks.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="META-LEARNING ALGORITHMS" target="MAML">
      <data key="d4">9.0</data>
      <data key="d5">MAML is a prominent example of a meta-learning algorithm that enhances learning efficiency across tasks.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-LEARNING ALGORITHMS" target="META-RL">
      <data key="d4">9.0</data>
      <data key="d5">Meta-RL is another example of a meta-learning algorithm that focuses on reinforcement learning efficiency.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LEARNING ENVIRONMENTS" target="POET">
      <data key="d4">8.0</data>
      <data key="d5">POET generates learning environments in an open-ended manner, contributing to the development of effective training settings.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AGENTVERSE" target="YUSHENG CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Yusheng Chen is a researcher involved in the development of the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="SU JINGWEI">
      <data key="d4">8.0</data>
      <data key="d5">Su Jingwei is a researcher contributing to the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="ZUO CHENG">
      <data key="d4">8.0</data>
      <data key="d5">Zuo Cheng is a researcher focused on the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="CHENFEI YUAN">
      <data key="d4">8.0</data>
      <data key="d5">Chenfei Yuan is a researcher involved in the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="CHI-MIN CHAN">
      <data key="d4">8.0</data>
      <data key="d5">Chi-Min Chan is a researcher contributing to the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="HEYANG YU">
      <data key="d4">8.0</data>
      <data key="d5">Heyang Yu is a researcher focused on the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="YI-HSIN HUNG">
      <data key="d4">8.0</data>
      <data key="d5">Yi-Hsin Hung is a researcher contributing to the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="CHEN QIAN">
      <data key="d4">8.0</data>
      <data key="d5">Chen Qian is a researcher focused on the Agentverse framework for multi-agent collaboration.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="HUMAN ORGANIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Agentic systems are closely connected to human organizations as they simulate and model human interactions and structures.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="HONG ET AL. (2023)">
      <data key="d4">7.0</data>
      <data key="d5">Hong et al. (2023) discusses the incorporation of organizational structures in agentic systems, linking them to human organizations.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="PARK ET AL. (2023)">
      <data key="d4">7.0</data>
      <data key="d5">Park et al. (2023) simulates a human town with agents, illustrating the application of agentic systems in modeling human society.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="HARRISON CHASE">
      <data key="d4">6.0</data>
      <data key="d5">Harrison Chase's exploration of agents contributes to the understanding of agentic systems in AI.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ANTHROPIC" target="CLAUDE 3">
      <data key="d4">9.0</data>
      <data key="d5">Anthropic developed Claude 3, a significant advancement in AI technology.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ANTHROPIC" target="CLAUDE 3.5 SONNET">
      <data key="d4">9.0</data>
      <data key="d5">Anthropic developed Claude 3.5 Sonnet, an iteration of their AI model series.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="WEI-LIN CHIANG" target="CHATBOT ARENA">
      <data key="d4">8.0</data>
      <data key="d5">Wei-Lin Chiang is a researcher involved in the development of the Chatbot Arena platform for evaluating language models.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="LIANMIN ZHENG" target="CHATBOT ARENA">
      <data key="d4">8.0</data>
      <data key="d5">Lianmin Zheng is a researcher contributing to the Chatbot Arena platform for evaluating language models.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YING SHENG" target="CHATBOT ARENA">
      <data key="d4">8.0</data>
      <data key="d5">Ying Sheng is a researcher focused on the Chatbot Arena platform for evaluating language models.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="ANASTASIOS NIKOLAS ANGELOPOULOS" target="CHATBOT ARENA">
      <data key="d4">8.0</data>
      <data key="d5">Anastasios Nikolas Angelopoulos is a researcher involved in the Chatbot Arena platform for evaluating language models.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="TIANLE LI" target="CHATBOT ARENA">
      <data key="d4">1.0</data>
      <data key="d5">Tianle Li is a researcher contributing to the Chatbot Arena platform for evaluating language models.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="KARL COBBE" target="TRAINING VERIFIERS">
      <data key="d4">8.0</data>
      <data key="d5">Karl Cobbe is involved in training verifiers for math word problems, contributing to advancements in this area.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="KALYANMOY DEB" target="ZHICHAO LU">
      <data key="d4">8.0</data>
      <data key="d5">Kalyanmoy Deb and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JOEL LEHMAN" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Joel Lehman is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JOEL LEHMAN" target="RUI WANG">
      <data key="d4">8.0</data>
      <data key="d5">Rui Wang and Joel Lehman co-authored a paper on open-ended coevolution in reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JOEL LEHMAN" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Joel Lehman is a co-author of the OMNI research project focused on open-endedness in models of human notions of interestingness.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JENNY ZHANG" target="MATEI ZAHARIA">
      <data key="d4">6.0</data>
      <data key="d5">Jenny Zhang and Matei Zaharia are both involved in discussions about open-endedness in AI systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JENNY ZHANG" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Jenny Zhang is a co-author of the OMNI research project focused on open-endedness in models of human notions of interestingness.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ZHICHAO LU" target="IAN WHALEN">
      <data key="d4">8.0</data>
      <data key="d5">Ian Whalen and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ZHICHAO LU" target="VISHNU BODDETI">
      <data key="d4">8.0</data>
      <data key="d5">Vishnu Boddeti and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ZHICHAO LU" target="YASHESH DHEBAR">
      <data key="d4">8.0</data>
      <data key="d5">Yashesh Dhebar and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ZHICHAO LU" target="ERIK GOODMAN">
      <data key="d4">8.0</data>
      <data key="d5">Erik Goodman and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ZHICHAO LU" target="WOLFGANG BANZHAF">
      <data key="d4">8.0</data>
      <data key="d5">Wolfgang Banzhaf and Zhichao Lu co-authored a paper on neural architecture search using genetic algorithms.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="YECHENG JASON MA" target="WILLIAM LIANG">
      <data key="d4">8.0</data>
      <data key="d5">William Liang and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="YECHENG JASON MA" target="OSBERT BASTANI">
      <data key="d4">8.0</data>
      <data key="d5">Osbert Bastani and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="YECHENG JASON MA" target="DINESH JAYARAMAN">
      <data key="d4">8.0</data>
      <data key="d5">Dinesh Jayaraman and Yecheng Jason Ma co-authored a paper on human-level reward design using large language models.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ELLIOT MEYERSON" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Elliot Meyerson is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="MARK J NELSON" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Mark J Nelson is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="HERBIE BRADLEY" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Herbie Bradley is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ADAM GAIER" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Adam Gaier is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="ARASH MORADI" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Arash Moradi is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="AMY K HOOVER" target="LANGUAGE MODEL CROSSOVER">
      <data key="d4">8.0</data>
      <data key="d5">Amy K Hoover is a co-author of a paper discussing language model crossover techniques.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="JEAN-BAPTISTE MOURET" target="ILLUMINATING SEARCH SPACES">
      <data key="d4">8.0</data>
      <data key="d5">Jean-Baptiste Mouret co-authored a paper on mapping elites to illuminate search spaces.</data>
      <data key="d6">1b1399c76420a477c0c97893d258ae69</data>
    </edge>
    <edge source="PERCY LIANG" target="COMMUNICATIVE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Percy Liang is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="PERCY LIANG" target="ALPACA EVAL">
      <data key="d4">8.0</data>
      <data key="d5">Percy Liang co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="XUECHEN LI">
      <data key="d4">8.0</data>
      <data key="d5">Xuechen Li is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="TIANYI ZHANG">
      <data key="d4">8.0</data>
      <data key="d5">Tianyi Zhang is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="YANN DUBOIS">
      <data key="d4">8.0</data>
      <data key="d5">Yann Dubois is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="ROHAN TAORI">
      <data key="d4">8.0</data>
      <data key="d5">Rohan Taori is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="ISHAAN GULRAJANI">
      <data key="d4">8.0</data>
      <data key="d5">Ishaan Gulrajani is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="CARLOS GUESTRIN">
      <data key="d4">8.0</data>
      <data key="d5">Carlos Guestrin is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COMMUNICATIVE AGENTS" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">1.0</data>
      <data key="d5">Tatsunori B. Hashimoto is involved in the development of communicative agents for exploring large language model society.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="DIRECT PREFERENCE OPTIMIZATION" target="RAFAEL RAFAILOV">
      <data key="d4">8.0</data>
      <data key="d5">Rafael Rafailov co-authored a paper on direct preference optimization, contributing to the understanding of reward models in language processing.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="QIANG WANG" target="TOOL LEARNING WITH LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Qiang Wang co-authored a survey on tool learning with large language models, contributing to the research in this area.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="JI-RONG WEN" target="MEMORY MECHANISM">
      <data key="d4">8.0</data>
      <data key="d5">Ji-Rong Wen is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="TORAN BRUCE RICHARDS" target="AUTOGPT">
      <data key="d4">9.0</data>
      <data key="d5">Toran Bruce Richards developed AutoGPT, a tool for automating tasks using language models.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="BERNARDINO ROMERA-PAREDES" target="MATHEMATICAL DISCOVERIES FROM PROGRAM SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Bernardino Romera-Paredes co-authored a paper discussing mathematical discoveries from program search with large language models.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="SANDER SCHULHOFF" target="PROMPT REPORT">
      <data key="d4">8.0</data>
      <data key="d5">Sander Schulhoff co-authored a systematic survey on prompting techniques, contributing to the understanding of effective prompts in language models.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="FREDA SHI" target="LANGUAGE AGENTS WITH VERBAL REINFORCEMENT LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">Freda Shi co-authored a paper on language agents that utilize verbal reinforcement learning techniques.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="JANE X WANG" target="LEARNING TO REINFORCEMENT LEARN">
      <data key="d4">8.0</data>
      <data key="d5">Jane X Wang co-authored a paper on learning to reinforcement learn, contributing to advancements in reinforcement learning methodologies.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="MATT BOTVINICK" target="SHAN KUMARAN">
      <data key="d4">8.0</data>
      <data key="d5">Shan Kumaran and Matt Botvinick are co-authors of a paper on reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="LEI WANG" target="LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">1.0</data>
      <data key="d5">Lei Wang co-authored a survey on large language model-based autonomous agents, contributing to the field of autonomous systems.</data>
      <data key="d6">34d0bb2211fc795fe1096442e086a2b3</data>
    </edge>
    <edge source="LEI WANG" target="CHEN MA">
      <data key="d4">8.0</data>
      <data key="d5">Lei Wang and Chen Ma are co-authors of a survey on large language model-based autonomous agents.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="CHEN MA" target="MEMORY MECHANISM">
      <data key="d4">8.0</data>
      <data key="d5">Chen Ma is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="(&quot;ENTITY&quot;" target="XUECHEN LI">
      <data key="d4">1.0</data>
      <data key="d5">PERSON</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="XU CHEN" target="MEMORY MECHANISM">
      <data key="d4">8.0</data>
      <data key="d5">Xu Chen is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="RUI WANG" target="ADITYA RAWAL">
      <data key="d4">8.0</data>
      <data key="d5">Aditya Rawal and Rui Wang co-authored a paper on enhanced open-ended reinforcement learning techniques.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="RUI WANG" target="JIALE ZHI">
      <data key="d4">8.0</data>
      <data key="d5">Jiale Zhi and Rui Wang are co-authors on research related to enhanced open-ended reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="RUI WANG" target="YULUN LI">
      <data key="d4">8.0</data>
      <data key="d5">Yulun Li and Rui Wang are co-authors on research related to open-ended reinforcement learning.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QUOC V LE" target="SELF(&quot;ENTITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">MINGCHEN ZHUGE</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="QINGYUN WU" target="GAGAN BANSAL">
      <data key="d4">8.0</data>
      <data key="d5">Qingyun Wu and Gagan Bansal are co-authors on advancements in multi-agent conversation frameworks.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QINGYUN WU" target="NIMROD GILEADI">
      <data key="d4">8.0</data>
      <data key="d5">Nimrod Gileadi and Qingyun Wu are co-authors on advancements in multi-agent conversation frameworks.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QINGYUN WU" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Qingyun Wu is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIEYU ZHANG" target="SHAOKUN ZHANG">
      <data key="d4">16.0</data>
      <data key="d5">Shaokun Zhang and Jieyu Zhang are co-authors on research related to robotic skill synthesis using language models.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JIEYU ZHANG" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Jieyu Zhang is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="SHAOKUN ZHANG" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Shaokun Zhang is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ELIEZER YUDKOWSKY" target="MATEI ZAHARIA">
      <data key="d4">6.0</data>
      <data key="d5">Eliezer Yudkowsky and Matei Zaharia are both involved in discussions about AI and its implications for global risks.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="OMNI" target="KENNETH STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Kenneth Stanley is a co-author of the OMNI research project focused on open-endedness in models of human notions of interestingness.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="BENFENG XU" target="AN YANG">
      <data key="d4">8.0</data>
      <data key="d5">Benfeng Xu and An Yang are co-authors on advancements in agentic systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="NICHOLAS FULLAGAR" target="GREGORY DARDYK">
      <data key="d4">8.0</data>
      <data key="d5">Nicholas Fullagar and Gregory Dardyk are co-authors on advancements in AI systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="NICHOLAS FULLAGAR" target="NEHA NARULA">
      <data key="d4">1.0</data>
      <data key="d5">Neha Narula and Nicholas Fullagar are co-authors on advancements in AI systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="J BRADLEY CHEN" target="ROBERT MUTH">
      <data key="d4">8.0</data>
      <data key="d5">J Bradley Chen and Robert Muth are co-authors on advancements in AI systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="TAVIS ORMANDY" target="SHIKI OKASAKA">
      <data key="d4">8.0</data>
      <data key="d5">Tavis Ormandy and Shiki Okasaka are co-authors on advancements in AI systems.</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JIALE LIU" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Jiale Liu is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="LINXIN SONG" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Linxin Song is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="CHI WANG" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Chi Wang is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="RANJAY KRISHNA" target="OFFLINE TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Ranjay Krishna is a co-author of a paper on offline training of language model agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="ZEU ZHANG">
      <data key="d4">8.0</data>
      <data key="d5">Zeyu Zhang is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="XIAOHE BO">
      <data key="d4">8.0</data>
      <data key="d5">Xiaohe Bo is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="RUI LI">
      <data key="d4">8.0</data>
      <data key="d5">Rui Li is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="QUANYU DAI">
      <data key="d4">8.0</data>
      <data key="d5">Quanyu Dai is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="JIEMING ZHU">
      <data key="d4">8.0</data>
      <data key="d5">Jieming Zhu is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MEMORY MECHANISM" target="ZHENHUA DONG">
      <data key="d4">8.0</data>
      <data key="d5">Zhenhua Dong is a co-author of a survey on the memory mechanism of large language model-based agents.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="HENG-TZE CHENG" target="SELF-DISCOVERY">
      <data key="d4">8.0</data>
      <data key="d5">Heng-Tze Cheng is a co-author of a paper on self-discovery in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="PEI ZHOU" target="SELF-DISCOVERY">
      <data key="d4">8.0</data>
      <data key="d5">Pei Zhou is a co-author of a paper on self-discovery in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JAY PUJARA" target="SELF-DISCOVERY">
      <data key="d4">8.0</data>
      <data key="d5">Jay Pujara is a co-author of a paper on self-discovery in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="XIANG REN" target="SELF-DISCOVERY">
      <data key="d4">8.0</data>
      <data key="d5">Xiang Ren is a co-author of a paper on self-discovery in large language models.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MINGCHEN ZHUGE" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Mingchen Zhuge is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="WENYI WANG" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Wenyi Wang is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="LOUIS KIRSCH" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Louis Kirsch is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="FRANCESCO FACCIO" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Francesco Faccio is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="DMITRII KHIZBULLIN" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Dmitrii Khizbullin is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="J&#220;RGEN SCHMIDHUBER" target="LANGUAGE AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">J&#252;rgen Schmidhuber is a co-author of a paper on language agents as optimizable graphs.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="LUISA ZINTGRAF">
      <data key="d4">8.0</data>
      <data key="d5">Luisa Zintgraf is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="SEBASTIAN SCHULZE">
      <data key="d4">8.0</data>
      <data key="d5">Sebastian Schulze is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="LEO FENG">
      <data key="d4">8.0</data>
      <data key="d5">Leo Feng is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="MAXIMILIAN IGL">
      <data key="d4">8.0</data>
      <data key="d5">Maximilian Igl is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="KYRIACOS SHIARLIS">
      <data key="d4">8.0</data>
      <data key="d5">Kyriacos Shiarlis is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="YARIN GAL">
      <data key="d4">8.0</data>
      <data key="d5">Yarin Gal is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="KATJA HOFMANN">
      <data key="d4">8.0</data>
      <data key="d5">Katja Hofmann is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="VARIBAD" target="SHIMON WHITESON">
      <data key="d4">1.0</data>
      <data key="d5">Shimon Whiteson is a co-author of a paper on variational Bayes-adaptive deep reinforcement learning.</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="META AGENT" target="OUTPUT INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent follows output instructions to format its responses correctly, ensuring clarity and structure.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="AGENT ARCHITECTURE">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent operates based on a specific agent architecture that defines its design and functionality.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent uses prompts to guide its output and reasoning, ensuring it follows the intended instructions.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="AGENT ARCHITECTURE" target="FORWARD FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">The forward function is a critical component of the agent architecture, defining how the agent processes tasks.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="RUNTIME ERROR" target="DEBUG_THOUGHT">
      <data key="d4">1.0</data>
      <data key="d5">When a runtime error occurs, the meta agent engages in debug_thought to analyze and resolve the issue.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FRAMEWORK CODE" target="NAMEDTUPLE INFO OBJECT">
      <data key="d4">1.0</data>
      <data key="d5">The framework code utilizes the namedtuple Info object to facilitate communication and organization of information.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FRAMEWORK CODE" target="APPENDICES">
      <data key="d4">7.0</data>
      <data key="d5">The framework code is detailed in the appendices, providing additional context and examples for implementation.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FM MODULE" target="INFO">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module utilizes the Info data structure to hold and manage task-related information for processing.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="AGENT SYSTEM">
      <data key="d4">7.0</data>
      <data key="d5">The Agent System interacts with the FM Module to process task information and implement functionalities like self-reflection.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="JSON RESPONSE">
      <data key="d4">9.0</data>
      <data key="d5">The FM Module generates a JSON response as output after processing user messages through the GPT model.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="GPT MODEL">
      <data key="d4">9.0</data>
      <data key="d5">The FM Module queries the GPT model to obtain responses based on user input and instructions.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="OUTPUT FIELDS">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module defines the output fields that are expected in the responses it generates for tasks.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module utilizes a system message to provide context for the GPT model when generating responses.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="ITERATION INDEX">
      <data key="d4">6.0</data>
      <data key="d5">The FM Module uses the iteration index to manage and track the progress of tasks across multiple iterations.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="AGENT SYSTEM" target="COT INSTRUCTION">
      <data key="d4">1.0</data>
      <data key="d5">The Agent System uses Chain-of-Thought instructions to guide the reasoning process for solving tasks.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="AGENT SYSTEM" target="TASK INFORMATION">
      <data key="d4">8.0</data>
      <data key="d5">The Agent System processes task information to derive answers or outputs based on the defined instructions.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="AGENT SYSTEM" target="RESPONSE">
      <data key="d4">1.0</data>
      <data key="d5">The Agent System generates a response based on the processed task information and instructions provided to it.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GPT MODEL" target="BACKOFF">
      <data key="d4">6.0</data>
      <data key="d5">The Backoff technique is applied when querying the GPT model to manage rate limit errors effectively.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="COT_REFLECT_INSTRUCTION" target="COT_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The cot_reflect_instruction guides the cot_module to refine answers based on previous attempts and feedback.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="COT_MODULE" target="COT_INPUTS">
      <data key="d4">8.0</data>
      <data key="d5">The cot_module processes the cot_inputs to generate thinking and answers based on the provided task information.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="CRITIC_MODULE" target="COT_INPUTS">
      <data key="d4">8.0</data>
      <data key="d5">The critic_module uses cot_inputs to provide feedback and correctness status on the answers generated by the cot_module.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="CRITIC_MODULE" target="CORRECT">
      <data key="d4">8.0</data>
      <data key="d5">The critic_module determines the correct status of the answer generated by the cot_module, indicating its accuracy.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="COT_INPUTS" target="TASK_INFO">
      <data key="d4">7.0</data>
      <data key="d5">COT_inputs include task_info as part of the data processed by the cot_module to generate answers.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC_CHALLENGE" target="EXAMPLE_INPUT_OUTPUT_GRID">
      <data key="d4">9.0</data>
      <data key="d5">The ARC challenge utilizes example input-output grids to teach the transformation rules necessary for predicting outputs.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC_CHALLENGE" target="TEST_GRID">
      <data key="d4">9.0</data>
      <data key="d5">The test grid is part of the ARC challenge, where the system must apply learned transformation rules to predict the output.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC_CHALLENGE" target="GTP-4O-2024-05-13">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4O-2024-05-13 is used by the meta agent to generate solutions for tasks in the ARC challenge.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC_CHALLENGE" target="GPT-3.5-TURBO-0125">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-Turbo-0125 is used to evaluate the performance of agents and baselines in the ARC challenge.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="GTP-4O-2024-05-13" target="INITIAL_SOLUTIONS">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4O-2024-05-13 is utilized in the evaluation of the initial solutions generated by the meta agent.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPT-3.5-TURBO-0125" target="INITIAL_SOLUTIONS">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-Turbo-125 is used for evaluating discovered agents and baselines related to the initial solutions.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INPUT_GRID" target="OUTPUT_GRID">
      <data key="d4">9.0</data>
      <data key="d5">The output_grid is derived from the input_grid by applying the transformation_rule in the ARC challenge.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="INPUT_GRID" target="TRANSFORMATION_RULE">
      <data key="d4">9.0</data>
      <data key="d5">The transformation_rule is applied to the input_grid to predict the output_grid in the ARC challenge.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="OUTPUT_GRID" target="TRANSFORMATION_RULE">
      <data key="d4">1.0</data>
      <data key="d5">The transformation_rule defines how the input_grid is transformed into the output_grid in the ARC challenge.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="STRUCTURED FEEDBACK AND ENSEMBLE AGENT" target="FM_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent utilizes FM_Module to generate initial candidate solutions for tasks.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="STRUCTURED FEEDBACK AND ENSEMBLE AGENT" target="TASKINFO">
      <data key="d4">8.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent processes TaskInfo to generate solutions based on the provided task details.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="STRUCTURED FEEDBACK AND ENSEMBLE AGENT" target="INITIAL CANDIDATE SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent generates initial candidate solutions as part of its problem-solving process.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="STRUCTURED FEEDBACK AND ENSEMBLE AGENT" target="CORRECT EXAMPLES">
      <data key="d4">7.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent considers correct examples to evaluate the success of its generated solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="STRUCTURED FEEDBACK AND ENSEMBLE AGENT" target="WRONG EXAMPLES">
      <data key="d4">1.0</data>
      <data key="d5">The Structured Feedback and Ensemble Agent analyzes wrong examples to identify areas for improvement in its solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM_MODULE" target="TASKINFO">
      <data key="d4">9.0</data>
      <data key="d5">FM_Module uses TaskInfo as input to generate candidate solutions for the agent's tasks.
The FM_Module processes TaskInfo to derive solutions for the given problems.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2,ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="DECOMPOSITION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The FM_Module includes the Decomposition Module as a key component for breaking down problems into sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="TASKINFO" target="INITIAL_SOLUTIONS">
      <data key="d4">1.0</data>
      <data key="d5">TaskInfo provides the necessary context and parameters for evaluating the initial solutions effectively.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="HUMAN-LIKE FEEDBACK MODULE" target="INITIAL_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The Human-Like Feedback Module processes the initial solutions to provide simulated human feedback on their quality.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="EXPERT ADVISORS">
      <data key="d4">8.0</data>
      <data key="d5">Expert Advisors evaluate the initial solutions and provide targeted feedback for improvement.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="REFINEMENT MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The Refinement Module iteratively refines the initial solutions based on structured feedback received from various sources.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="CORRECT_EXAMPLES">
      <data key="d4">6.0</data>
      <data key="d5">Correct Examples are identified from the initial solutions that have met the evaluation criteria successfully.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="WRONG_EXAMPLES">
      <data key="d4">6.0</data>
      <data key="d5">Wrong Examples are identified from the initial solutions that have not met the evaluation criteria, indicating failures.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINEMENT MODULE" target="FINAL DECISION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Final Decision Module uses the refined solutions to make a final decision on the best-performing code.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INDIANS" target="BAHRAIN">
      <data key="d4">8.0</data>
      <data key="d5">Indians make up a significant portion of the non-national population in Bahrain, with approximately 290,000 residing there.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="BANGLADESHIS" target="BAHRAIN">
      <data key="d4">8.0</data>
      <data key="d5">Bangladeshis make up a significant portion of the non-national population in Bahrain, with approximately 125,000 residing there.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="PAKISTANIS" target="BAHRAIN">
      <data key="d4">7.0</data>
      <data key="d5">Pakistanis make up a portion of the non-national population in Bahrain, with approximately 45,000 residing there.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="FILIPINOS" target="BAHRAIN">
      <data key="d4">7.0</data>
      <data key="d5">Filipinos make up a portion of the non-national population in Bahrain, with approximately 45,000 residing there.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="INDONESIANS" target="BAHRAIN">
      <data key="d4">1.0</data>
      <data key="d5">Indonesians make up a portion of the non-national population in Bahrain, with approximately 8,000 residing there.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DECOMPOSITION MODULE" target="SUB-PROBLEMS">
      <data key="d4">7.0</data>
      <data key="d5">The Decomposition Module generates sub-problems from a larger task for specialized experts to address.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="DECOMPOSITION MODULE" target="DECOMPOSITION INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">The Decomposition Module uses Decomposition Instruction to effectively break down problems into sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERTS" target="SUB-SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Specialized Experts provide sub-solutions for each sub-problem they are assigned to solve.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERTS" target="SUB-PROBLEM">
      <data key="d4">8.0</data>
      <data key="d5">Specialized Experts are assigned specific sub-problems to solve based on their expertise.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERTS" target="SUB-PROBLEM INSTRUCTION">
      <data key="d4">1.0</data>
      <data key="d5">Specialized Experts receive Sub-Problem Instruction to guide their problem-solving process.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="INTEGRATION MODULE" target="SUB-SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The Integration Module combines the sub-solutions into a final answer to the original problem.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="INTEGRATION MODULE" target="INTEGRATION INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">The Integration Module follows Integration Instruction to combine sub-solutions into a coherent final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VISUAL REPRESENTATION MODULE" target="CHAIN-OF-THOUGHT MODULE">
      <data key="d4">7.0</data>
      <data key="d5">The Visual Representation Module aids the Chain-of-Thought Module by providing visual aids for problem-solving.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VISUAL REPRESENTATION MODULE" target="VERIFICATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Verification Module ensures the accuracy of the visual aids created by the Visual Representation Module.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SYNTHETIC DATA">
      <data key="d4">16.0</data>
      <data key="d5">AgentInstruct is designed to create synthetic data for training language models, focusing on quality and diversity.
AgentInstruct generates synthetic data to enhance model training, addressing issues of diversity and quality in datasets.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-7B">
      <data key="d4">16.0</data>
      <data key="d5">Mistral-7B is a base model that was post-trained using synthetic data generated by AgentInstruct.
Mistral-7B has been fine-tuned using the AgentInstruct method to enhance its performance.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="GENERATIVE TEACHING">
      <data key="d4">15.0</data>
      <data key="d5">AgentInstruct is a practical implementation of the Generative Teaching methodology, aimed at creating synthetic data for AI training.
Generative Teaching is evidenced by the effectiveness of AgentInstruct in improving learning outcomes across mathematical datasets.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="RAW DOCUMENTS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct uses raw documents as seeds to generate synthetic data, enabling the creation of diverse datasets.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="AGENTIC FLOWS">
      <data key="d4">9.0</data>
      <data key="d5">AgentInstruct employs agentic flows to automate the data generation process, enhancing efficiency and diversity.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTENT TRANSFORMATION AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Agents are utilized within the AgentInstruct methodology to modify raw seeds for instruction generation.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="INSTRUCTION CREATION AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Creation Agents are part of the AgentInstruct process, generating diverse instructions from transformed seeds.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="REFINEMENT AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Refinement Agents are involved in the AgentInstruct methodology to enhance the quality and complexity of generated instructions.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="DIVERSE DATA">
      <data key="d4">9.0</data>
      <data key="d5">AgentInstruct aims to produce diverse data through its structured approach, ensuring a wide range of generated content.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="HIGH-QUALITY DATA">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct focuses on generating high-quality data by leveraging advanced models and methodologies.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3">
      <data key="d4">34.0</data>
      <data key="d5">Orca-3 is a model trained using the AgentInstruct methodology, which focuses on generating instruction data.
AgentInstruct data is used to enhance the performance of Orca-3, leading to significant improvements over baseline models.
AgentInstruct has been utilized to enhance Orca-3's proficiency across various difficulties in math, indicating a direct application of the technique.
Orca-3's performance improved significantly after being post-trained with a dataset generated by the AgentInstruct approach.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="PERFORMANCE AUGMENTATION">
      <data key="d4">1.0</data>
      <data key="d5">Performance augmentation is achieved through the integration of AgentInstruct data, enhancing the capabilities of models like Orca-3.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MATH PROBLEMS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct enhances the ability of AI models to solve math problems across various difficulty levels, indicating a direct application of the technique.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct is applied to Orca-3-7B to enhance its summarization capabilities by reducing hallucinations.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="UNSTRUCTURED DATA">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct utilizes unstructured data to create tailored datasets for model training, enhancing the learning process.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="MISTRAL-7B" target="ORCA-3">
      <data key="d4">26.0</data>
      <data key="d5">Orca-3 is the improved model resulting from the post-training of Mistral-7B with synthetic data.
Orca-3 is the finetuned version of the Mistral-7B model, demonstrating improvements in performance after training with synthetic data.
Orca-3 is a fine-tuned version of the Mistral model family, showing improved performance in specific tasks.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="MISTRAL-7B" target="SYNTHETIC DATASET">
      <data key="d4">8.0</data>
      <data key="d5">The synthetic dataset created by AgentInstruct is used to fine-tune the Mistral-7B model, enhancing its capabilities.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="MISTRAL-7B" target="LLAMA-8B-INSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">Mistral-7B is compared with LLAMA-8B-instruct to evaluate the effectiveness of instruction-tuning.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="MISTRAL-7B" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">Mistral-7B has been evaluated on the MIRAGE datasets to assess its performance in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3" target="LLAMA-8B-INSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 outperforms LLAMA-8B-Instruct in various benchmarks, demonstrating the effectiveness of the synthetic data used.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="ORCA-3" target="AGIEVAL">
      <data key="d4">24.0</data>
      <data key="d5">AGIEval is one of the benchmarks where Orca-3 shows significant improvement compared to previous models.
Orca-3 shows significant improvement on the AGIEval benchmark compared to other instruction-tuned models.
AGIEval provides performance scores for Orca-3, showcasing its effectiveness in reading comprehension and math tasks.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="BBH">
      <data key="d4">16.0</data>
      <data key="d5">BBH is a benchmark where Orca-3 outperforms previous models, indicating its enhanced capabilities.
Orca-3 shows improvement on the BBH benchmark, indicating its effectiveness in various tasks.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="ALPACA EVAL">
      <data key="d4">10.0</data>
      <data key="d5">AlpacaEval is a benchmark where Orca-3 achieves significant improvements, showcasing its effectiveness in instruction-following tasks.
Orca-3 outperforms other models on the AlpacaEval benchmark, demonstrating its instruction-tuning effectiveness.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-V0.1">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 is a finetuned version of the Mistral-7B-v0.1 model, adapted for specific tasks using the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-BENCH">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3 is evaluated using the Orca-Bench dataset to assess its performance across various skills.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="TRAINING DETAILS">
      <data key="d4">9.0</data>
      <data key="d5">Orca-3 was trained using specific training details that outline the process and parameters used during its development.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="EVALUATION RESULTS">
      <data key="d4">1.0</data>
      <data key="d5">The evaluation results provide insights into the performance of Orca-3 when tested against the Orca-Bench dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-2.5">
      <data key="d4">15.0</data>
      <data key="d5">Orca-3 is evaluated against Orca-2.5 to demonstrate its performance improvements in the Orca-Bench dataset.
Orca-3 has shown an 18% improvement over Orca 2.5 in reading comprehension tasks, indicating a direct performance comparison.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-INSTRUCT-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 is evaluated against Mistral-Instruct-7B to demonstrate its performance improvements in the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="LLAMA3-8B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 is evaluated against LLAMA3-8B to demonstrate its performance improvements in the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="GPT-3.5-TURBO">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 is evaluated against GPT-3.5-turbo to demonstrate its performance improvements in the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="PERFORMANCE COMPARISON">
      <data key="d4">1.0</data>
      <data key="d5">Performance comparison illustrates the enhancements in Orca-3's capabilities during post-training, enabled by the AgentInstruct data.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">16.0</data>
      <data key="d5">Orca-3's performance is compared to Mistral-7B-Instruct across various benchmarks, highlighting differences in capabilities.
Orca-3 has demonstrated a 21% gain in performance relative to Mistral-7B-Instruct, highlighting its advancements in AI capabilities.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="LSATS">
      <data key="d4">9.0</data>
      <data key="d5">Orca-3's performance on LSAT reading comprehension sections has been elevated to match that of GPT-4, indicating its effectiveness in tackling difficult exams.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="POST-TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Post-training is a critical phase for Orca-3, allowing it to leverage synthetic data for improved performance across benchmarks.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="ALPACA EVAL" target="XUECHEN LI">
      <data key="d4">8.0</data>
      <data key="d5">Xuechen Li co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="TIANYI ZHANG">
      <data key="d4">8.0</data>
      <data key="d5">Tianyi Zhang co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="YANN DUBOIS">
      <data key="d4">8.0</data>
      <data key="d5">Yann Dubois co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="ROHAN TAORI">
      <data key="d4">8.0</data>
      <data key="d5">Rohan Taori co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="ISHAAN GULRAJANI">
      <data key="d4">8.0</data>
      <data key="d5">Ishaan Gulrajani co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="CARLOS GUESTRIN">
      <data key="d4">8.0</data>
      <data key="d5">Carlos Guestrin co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="TATSUNORI HASHIMOTO">
      <data key="d4">8.0</data>
      <data key="d5">Tatsunori Hashimoto co-authored a paper on Alpaca Eval, an automatic evaluator for instruction-following models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACA EVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">5.0</data>
      <data key="d5">Open-ended generation tasks are evaluated using the AlpacaEval benchmark for win-rate comparisons.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="BAOLIN PENG">
      <data key="d4">8.0</data>
      <data key="d5">Baolin Peng co-authored a paper on instruction tuning with GPT-4, focusing on enhancing model performance.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="CHUNYUAN LI">
      <data key="d4">8.0</data>
      <data key="d5">Chunyuan Li co-authored a paper on instruction tuning with GPT-4, focusing on enhancing model performance.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="PENGCHENG HE">
      <data key="d4">8.0</data>
      <data key="d5">Pengcheng He co-authored a paper on instruction tuning with GPT-4, focusing on enhancing model performance.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="MICHEL GALLEY">
      <data key="d4">8.0</data>
      <data key="d5">Michel Galley co-authored a paper on instruction tuning with GPT-4, focusing on enhancing model performance.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="JIANFENG GAO">
      <data key="d4">1.0</data>
      <data key="d5">Jianfeng Gao co-authored a paper on instruction tuning with GPT-4, focusing on enhancing model performance.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="RAW ARTICLES">
      <data key="d4">8.0</data>
      <data key="d5">Agentic flows utilize raw articles as seeds to generate diverse problems through automation.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="WEB AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Web agents are utilized within agentic flows to perform automated tasks on the web, enhancing the generation process.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="OUTPUTS">
      <data key="d4">7.0</data>
      <data key="d5">Outputs are the results generated from the workflows of the agentic flows, including instructions and data summaries.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="PROBLEM GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Problem generation is a process facilitated by agentic flows to create distinct and diverse problems from raw articles.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="ARGUMENT PASSAGE GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Argument Passage Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="DEBATE PASSAGE GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Debate Passage Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="CONVERSATION PASSAGE GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Conversation Passage Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="MEETING TRANSCRIPT GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Meeting Transcript Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="POEM GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Poem Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="SATIRICAL PASSAGE GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Satirical Passage Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="INSTRUCTIONAL PASSAGE GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Instructional Passage Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="LONG TEXT GENERATOR">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Long Text Generator as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="IDENTITY AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Agentic Flows includes the Identity Agent as one of its transformation agents for reading comprehension tasks.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="LITERAL COMPREHENSION QUESTION">
      <data key="d4">6.0</data>
      <data key="d5">Agentic Flows utilizes Literal Comprehension Questions as part of its reading comprehension transformation agents.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="NUMERICAL DISCRETE REASONING">
      <data key="d4">6.0</data>
      <data key="d5">Agentic Flows utilizes Numerical Discrete Reasoning as part of its reading comprehension transformation agents.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="CRITICAL COMPREHENSION QUESTION">
      <data key="d4">6.0</data>
      <data key="d5">Agentic Flows utilizes Critical Comprehension Questions as part of its reading comprehension transformation agents.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="EVALUATIVE COMPREHENSION QUESTION">
      <data key="d4">1.0</data>
      <data key="d5">Agentic Flows utilizes Evaluative Comprehension Questions as part of its reading comprehension transformation agents.</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="RAW ARTICLES" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">Content Transformation Flow converts raw articles into an intermediate representation for instruction creation.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="SEED INSTRUCTION GENERATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow takes transformed content from the Content Transformation Flow to generate diverse instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="INTERMEDIATE REPRESENTATION">
      <data key="d4">7.0</data>
      <data key="d5">Content Transformation Flow produces an intermediate representation that simplifies the creation of tailored instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="INSTRUCTION CREATION">
      <data key="d4">1.0</data>
      <data key="d5">Instruction creation is a key outcome of the Content Transformation Flow, which simplifies the process of developing specific tasks.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="READING COMPREHENSION">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Flow aims to create materials that improve reading comprehension skills by generating diverse question types.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="ARGUMENT PASSAGE GENERATOR">
      <data key="d4">8.0</data>
      <data key="d5">The Argument Passage Generator is a component of the Content Transformation Flow, specifically designed to create argumentative passages for comprehension tasks.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="API DESCRIPTION">
      <data key="d4">9.0</data>
      <data key="d5">The Content Transformation Flow synthesizes API descriptions from source code snippets or other inputs, detailing their functionality.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="LIBRARY RECONSTRUCTION">
      <data key="d4">1.0</data>
      <data key="d5">Library Reconstruction is a specific application of the Content Transformation Flow, focusing on synthesizing API lists.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow enhances the instructions generated from the Seed Instruction Generation Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="COMPREHENSIVE TAXONOMY">
      <data key="d4">8.0</data>
      <data key="d5">The comprehensive taxonomy guides the Seed Instruction Generation Flow in creating diverse instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR AGENTS">
      <data key="d4">9.0</data>
      <data key="d5">Suggester-Editor Agents are involved in the Instruction Refinement Flow to propose and modify instructions for quality improvement.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="ITERATIVE PROCESS">
      <data key="d4">8.0</data>
      <data key="d5">The Instruction Refinement Flow employs an iterative process to enhance the quality and complexity of instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">8.0</data>
      <data key="d5">The Instruction Refinement Flow employs a Suggester-Editor pair to enhance the complexity of generated instructions.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SKILLS" target="READING COMPREHENSION">
      <data key="d4">8.0</data>
      <data key="d5">Reading comprehension is one of the skills developed through the workflows implemented in the agentic flows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SKILLS" target="TEXT MODIFICATION">
      <data key="d4">8.0</data>
      <data key="d5">Text modification is another skill targeted by the workflows in the agentic flows for enhancing content quality.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SKILLS" target="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Open domain question answering is a skill that is part of the competencies developed through the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="CONVERSATION">
      <data key="d4">6.0</data>
      <data key="d5">Conversational agents can be designed to assist in reading comprehension by engaging users in discussions about texts.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="AGENTINSTRUCT FLOWS">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct Flows are implemented to enhance reading comprehension capabilities in AI systems.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="LSAT LOGICAL REASONING">
      <data key="d4">7.0</data>
      <data key="d5">The LSAT Logical Reasoning test assesses reading comprehension and critical reasoning skills, making it relevant to the study of reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="DROPS">
      <data key="d4">9.0</data>
      <data key="d5">DROP is a benchmark for reading comprehension that requires discrete reasoning over paragraphs.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="PARAPHRASING AGENT">
      <data key="d4">1.0</data>
      <data key="d5">The paraphrasing agent is a tool used in text modification to rewrite content while maintaining its original meaning.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="ANALYTICAL REASONING" target="SKILL">
      <data key="d4">8.0</data>
      <data key="d5">Analytical reasoning is a skill that is developed through the workflows in the agentic flows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="ASSESSMENT">
      <data key="d4">7.0</data>
      <data key="d5">Multiple choice questions are a common assessment method used to evaluate skills developed through the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">1.0</data>
      <data key="d5">The GPT-4 extraction system message is used to evaluate responses to multiple choice questions.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="EVALUATION DETAILS">
      <data key="d4">8.0</data>
      <data key="d5">Evaluation details specify the methods used to assess the performance of models on multiple choice questions.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="OPEN-ENDED GENERATION SETTING">
      <data key="d4">6.0</data>
      <data key="d5">The open-ended generation setting contrasts with multiple choice questions by allowing more freedom in responses.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="DATA TO TEXT" target="PROCESS">
      <data key="d4">7.0</data>
      <data key="d5">Data-to-text processes are used to generate human-readable summaries from the outputs of the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CODING" target="SKILL">
      <data key="d4">8.0</data>
      <data key="d5">Coding is a skill that is also developed through the workflows implemented in the agentic flows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CODING" target="TEXT EXTRACTION">
      <data key="d4">6.0</data>
      <data key="d5">Coding can be involved in the development of algorithms for text extraction processes, enhancing the retrieval of relevant information.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="PROCESS">
      <data key="d4">1.0</data>
      <data key="d5">Text extraction is a process involved in retrieving relevant information from generated outputs in the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="TEXT CLASSIFICATION">
      <data key="d4">7.0</data>
      <data key="d5">Text extraction can be a preliminary step before text classification, as relevant information needs to be retrieved before categorization.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="RETRIEVAL AUGMENTED GENERATION (RAG)">
      <data key="d4">8.0</data>
      <data key="d5">RAG utilizes text extraction to retrieve relevant documents before generating responses, linking the two processes.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TRANSFORMED CONTENT" target="SEED INSTRUCTION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Flow generates diverse instructions based on the transformed content from the Content Transformation Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="ENRICO FERMI" target="FERMI PROBLEM">
      <data key="d4">7.0</data>
      <data key="d5">The Fermi problem is named after Enrico Fermi, who is known for making justified guesses to solve complex estimation problems.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CREATIVE CONTENT GENERATION" target="FEW SHOT REASONING">
      <data key="d4">5.0</data>
      <data key="d5">Few-shot reasoning can enhance creative content generation by allowing models to create original content with minimal examples.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPERURICEMIA" target="PURINE">
      <data key="d4">1.0</data>
      <data key="d5">Hyperuricemia is often caused by a diet high in purines, which can lead to elevated uric acid levels in the body.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPERURICEMIA" target="CARDIOVASCULAR DISEASE">
      <data key="d4">17.0</data>
      <data key="d5">Hyperuricemia is associated with an increased risk of cardiovascular disease, linking the two medical conditions.
Hyperuricemia is a risk factor for developing cardiovascular disease.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPERURICEMIA" target="URIC ACID">
      <data key="d4">10.0</data>
      <data key="d5">High levels of uric acid in the blood lead to hyperuricemia, which can cause various health complications.
High levels of uric acid are indicative of hyperuricemia, which can lead to health complications.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="CARDIOVASCULAR DISEASE" target="URIC ACID">
      <data key="d4">8.0</data>
      <data key="d5">Elevated uric acid levels are associated with an increased risk of cardiovascular disease.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPURICEMIA" target="URIC ACID">
      <data key="d4">8.0</data>
      <data key="d5">Hypouricemia is characterized by low levels of uric acid in the blood, indicating a potential health issue.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="URIC ACID" target="LABORATORY TESTS">
      <data key="d4">8.0</data>
      <data key="d5">Laboratory tests are used to assess uric acid levels in the blood and diagnose related conditions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY TESTS">
      <data key="d4">7.0</data>
      <data key="d5">Hypouricemia may be diagnosed through laboratory tests that measure uric acid levels.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="READING COMPREHENSION QUESTIONS" target="PASSAGE-QUESTION PAIRS">
      <data key="d4">7.0</data>
      <data key="d5">Passage-question pairs are created to evaluate understanding of reading comprehension questions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="PARAPHRASING AGENT" target="RANDOM SEED">
      <data key="d4">7.0</data>
      <data key="d5">The Paraphrasing Agent utilizes a random seed to create text modification tasks based on the seed's value.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="FINANCIALIZATION" target="SUPPLY CHAINS">
      <data key="d4">7.0</data>
      <data key="d5">Financialization influences supply chains of financial products, connecting various global locations and political projects.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="NATASCHA VAN DER ZWAN" target="RESEARCH STREAMS">
      <data key="d4">8.0</data>
      <data key="d5">Natascha van der Zwan identifies and categorizes three distinct research streams related to the concept of financialization.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SOCIAL LIFE" target="SUPPLY CHAINS">
      <data key="d4">6.0</data>
      <data key="d5">The supply chains of financial products can transform social life by altering interactions and relationships within society.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="AMERICAN ANTHROPOLOGICAL ASSOCIATION" target="SEA 2017 ANNUAL MEETING">
      <data key="d4">1.0</data>
      <data key="d5">The SEA 2017 Annual Meeting is organized by the American Anthropological Association, which facilitates professional gatherings in anthropology.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CREATE MEAL PLAN" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes creating a meal plan as one of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="UPDATE FOOD ITEM" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes updating food items as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="TRACK USER MEAL" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow encompasses tracking user meals as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="GET DIETARY RECOMMENDATIONS" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes providing dietary recommendations as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="ADD NEW FOOD ITEM" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes adding new food items as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="DELETE FOOD ITEM" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes deleting food items as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="GET USER NUTRITIONAL STATS" target="SEED INSTRUCTION CREATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Creation Flow includes retrieving user nutritional stats as part of its tasks.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="MEAL PLAN" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Day 1 is a component of the overall meal plan, detailing specific meals and their caloric values.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="MEAL PLAN" target="DAY 2">
      <data key="d4">8.0</data>
      <data key="d5">Day 2 is a component of the overall meal plan, detailing specific meals and their caloric values.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="MEAL PLAN" target="FOOD ITEMS">
      <data key="d4">8.0</data>
      <data key="d5">The meal plan consists of various food items that make up each meal, detailing what is included in the diet.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="API_CALL">
      <data key="d4">7.0</data>
      <data key="d5">The API call is the action taken to create the vegetarian meal plan based on user specifications.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="DAY 1" target="TOTAL CALORIES">
      <data key="d4">7.0</data>
      <data key="d5">Day 1 includes a total caloric breakdown for each meal, providing insight into daily energy intake.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="DAY 2" target="TOTAL CALORIES">
      <data key="d4">7.0</data>
      <data key="d5">Day 2 includes a total caloric breakdown for each meal, providing insight into daily energy intake.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="QUINOA SALAD" target="NUTRITIONAL INFORMATION">
      <data key="d4">6.0</data>
      <data key="d5">The Quinoa Salad recipe requires nutritional information to be added to the database for completeness.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="CHANA MASALA" target="NUTRITIONAL INFORMATION">
      <data key="d4">6.0</data>
      <data key="d5">The Chana Masala recipe requires nutritional information for updating in the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BUTTER CHICKEN" target="NUTRITIONAL INFORMATION">
      <data key="d4">6.0</data>
      <data key="d5">The Butter Chicken recipe requires nutritional information for removal from the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-BENCH" target="COMPLEX ODQA">
      <data key="d4">6.0</data>
      <data key="d5">The Orca-Bench dataset includes evaluations of complex questions, which are part of the Complex ODQA subset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="MULTI-TURN INTERACTION">
      <data key="d4">7.0</data>
      <data key="d5">Multi-turn interaction is a key feature in the Orca-Bench dataset, allowing for the evaluation of conversational AI models over multiple exchanges.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="EVALUATION RESULTS" target="MIRAGE DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">Evaluation results provide insights into the performance of models tested on the MIRAGE datasets.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B shows performance improvements compared to Orca-2.5, indicating a direct relationship in their development.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="ORCA-3-7B">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-turbo is compared with Orca-3-7B in summarization evaluations, establishing a relationship in performance assessment.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="MIRAGE DATASETS">
      <data key="d4">8.0</data>
      <data key="d5">GPT-3.5-Turbo has been evaluated on the MIRAGE datasets to assess its performance in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="CO-T">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-Turbo utilizes the CoT technique to enhance its reasoning capabilities in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="TEACHER RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">Student responses are evaluated against teacher responses to assess the performance of AI models in the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="SCORE NORMALIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Score normalization is applied to student responses to standardize their scores on a 0 to 10 scale for comparison.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">1.0</data>
      <data key="d5">The EQBench GPT-4 Extraction System Message is used to extract emotion scores from the student agent response based on the critique provided.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="MULTIPLE ANSWERS">
      <data key="d4">7.0</data>
      <data key="d5">The student response may include multiple answers if the student provides more than one option for the question.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="FOFO" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">1.0</data>
      <data key="d5">FoFo benchmarks assess the format-following capabilities of Mistral-7B-Instruct, indicating its applicability in real-world scenarios.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="FOFO" target="OPEN-ENDED GENERATION">
      <data key="d4">5.0</data>
      <data key="d5">Open-ended generation tasks are evaluated using the FOFO benchmark for format correctness.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="IFEVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">5.0</data>
      <data key="d5">Open-ended generation tasks are evaluated using the IFEval benchmark for adherence to instructions.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="MT-BENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">5.0</data>
      <data key="d5">Open-ended generation tasks are evaluated using the MT-Bench benchmark for response quality.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="INFOBENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">Open-ended generation tasks are evaluated using the InfoBench benchmark for instruction adherence.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT" target="MISTRAL">
      <data key="d4">7.0</data>
      <data key="d5">Mistral's improvements in reading comprehension are evaluated against the baseline of Mistral-7B-Instruct.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated against Mistral-7B-Instruct, highlighting its advancements in summarization capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ELEMENTARY MATH" target="MATH PROBLEMS">
      <data key="d4">7.0</data>
      <data key="d5">Elementary math problems are designed to assess basic mathematical skills, where AI models have shown significant improvement.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="HIGH SCHOOL MATHEMATICS" target="MATH PROBLEMS">
      <data key="d4">6.0</data>
      <data key="d5">High school mathematics problems present challenges for AI models, indicating areas where performance typically falters.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="COLLEGE MATHEMATICS" target="MATH PROBLEMS">
      <data key="d4">6.0</data>
      <data key="d5">College mathematics problems are complex and often difficult for AI models, highlighting the need for advanced reasoning capabilities.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3-7B" target="HALLUCINATION RATE">
      <data key="d4">7.0</data>
      <data key="d5">The hallucination rate is measured for Orca-3-7B, indicating its performance in generating accurate summaries.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="QUALITY SCORE">
      <data key="d4">7.0</data>
      <data key="d5">The quality score is assigned to Orca-3-7B's summarization outputs, reflecting its effectiveness in generating high-quality summaries.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="ACI-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated using the ACI-Bench dataset, linking its performance to this specific benchmark.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="INSTRUSUM">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is assessed on the InstruSum dataset, indicating its capabilities in instruction-controllable summarization.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="ORCA-SUM">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated on the Orca-Sum benchmark, which tests its summarization and data transformation abilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="MIRAGE">
      <data key="d4">1.0</data>
      <data key="d5">MIRAGE is used to assess the RAG capabilities of Orca-3-7B, linking the model to medical question answering performance.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="DATA TRANSFORMATION">
      <data key="d4">7.0</data>
      <data key="d5">Data transformation techniques are utilized in conjunction with Orca-3-7B to evaluate its ability to follow complex instructions.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-SUM" target="HUGGING FACE">
      <data key="d4">8.0</data>
      <data key="d5">The Orca-Sum benchmark utilizes datasets collected from Hugging Face, linking the platform to the evaluation process.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE DATASETS" target="ORCA-2.5-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-2.5-7B has been evaluated on the MIRAGE datasets to assess its performance in various tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE DATASETS" target="MEDMEDQA">
      <data key="d4">8.0</data>
      <data key="d5">MedMedQA is one of the datasets included in the MIRAGE collection for evaluating language models.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE DATASETS" target="USMEDMCQA">
      <data key="d4">8.0</data>
      <data key="d5">USMedMCQA is one of the datasets included in the MIRAGE collection for evaluating language models.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE DATASETS" target="PUBMEDQA">
      <data key="d4">8.0</data>
      <data key="d5">PubMedQA is one of the datasets included in the MIRAGE collection for evaluating language models.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="PUBMEDQA" target="RAG">
      <data key="d4">9.0</data>
      <data key="d5">PubMedQA serves as an effective testbed for assessing models' abilities to perform RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AZURE" target="CONTENT HARMS">
      <data key="d4">7.0</data>
      <data key="d5">Azure provides transparency notes that discuss the content harms associated with large language models, highlighting the importance of awareness and mitigation.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="CONTENT HARMS" target="CONTENT MODERATION SERVICES">
      <data key="d4">8.0</data>
      <data key="d5">Content harms can be mitigated through the use of content moderation services, which help manage harmful outputs from AI models.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="CONTENT HARMS" target="REGULATIONS AND STANDARDS">
      <data key="d4">9.0</data>
      <data key="d5">Regulations and standards are necessary to address and prevent content harms associated with AI technologies.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="CONTENT HARMS" target="HALLUCINATION">
      <data key="d4">8.0</data>
      <data key="d5">Hallucination is a specific type of content harm that can mislead users and create misinformation, necessitating caution in AI usage.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="REGULATIONS AND STANDARDS" target="RESEARCH COMMUNITY">
      <data key="d4">1.0</data>
      <data key="d5">The research community plays a vital role in advocating for better regulations and standards in AI technologies to prevent content harms.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AHMED AWADALLAH" target="ORCA 2">
      <data key="d4">8.0</data>
      <data key="d5">Ahmed Awadallah co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ARINDAM MITRA" target="ORCA 2">
      <data key="d4">8.0</data>
      <data key="d5">Arindam Mitra co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="CORBY ROSSET" target="ORCA 2">
      <data key="d4">8.0</data>
      <data key="d5">Corby Rosset co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ISAAC COWHEY" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Isaac Cowhey is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="OREN ETZIONI" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Oren Etzioni is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="TUSHAR KHOT" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Tushar Khot is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ASHISH SABHARWAL" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Ashish Sabharwal is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="CARISSA SCHOENICK" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Carissa Schoenick is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="OYVIND TAFJORD" target="AI2 REASONING CHALLENGE">
      <data key="d4">8.0</data>
      <data key="d5">Oyvind Tafjord is a contributor to the AI2 Reasoning Challenge, which focuses on question answering.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="NING DING" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Ning Ding is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="YULIN CHEN" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Yulin Chen is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="BOKAI XU" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Bokai Xu is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ZHI ZHENG" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Zhi Zheng is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="SHENGDING HU" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Shengding Hu is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ZHIYUAN LIU" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Zhiyuan Liu is involved in enhancing chat language models through high-quality instructional conversations.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ZHAOYE FEI" target="UNEARTHING DOMAIN-SPECIFIC KNOWLEDGE">
      <data key="d4">8.0</data>
      <data key="d5">Zhaoye Fei is involved in unearthing large-scale domain-specific knowledge from public corpora.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="KHIZBULLIN" target="BERNARD GHANEM">
      <data key="d4">8.0</data>
      <data key="d5">Khizbullin and Bernard Ghanem co-authored a work on communicative agents for mind exploration in large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="CAMEL">
      <data key="d4">7.0</data>
      <data key="d5">Camel is a system developed by Khizbullin for exploring large language model societies.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="COSMOPEDIA">
      <data key="d4">6.0</data>
      <data key="d5">Cosmopedia is a project that may involve Khizbullin in creating large-scale synthetic data for pre-training language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="ORCA 2">
      <data key="d4">6.0</data>
      <data key="d5">Orca 2 is a project that may involve Khizbullin in teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="ORCA-MATH">
      <data key="d4">6.0</data>
      <data key="d5">Orca-Math is a project that may involve Khizbullin in enhancing small language models' capabilities in grade school math.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="XTREMEDISTIL">
      <data key="d4">6.0</data>
      <data key="d5">Xtremedistil is a method that may involve Khizbullin in creating massive multilingual models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="DIRECT NASH OPTIMIZATION">
      <data key="d4">6.0</data>
      <data key="d5">Direct Nash Optimization is a method that may involve Khizbullin in teaching language models to self-improve.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="KHIZBULLIN" target="THE CURSE OF RECURSION">
      <data key="d4">1.0</data>
      <data key="d5">The Curse of Recursion is a phenomenon that may involve Khizbullin in understanding the effects of training on generated data.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="BERNARD GHANEM" target="CAMEL">
      <data key="d4">7.0</data>
      <data key="d5">Camel is a system co-developed by Bernard Ghanem for exploring large language model societies.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Yixin Liu co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALEXANDER R. FABBRI" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Alexander R. Fabbri co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="JIAWEN CHEN" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Jiawen Chen co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YILUN ZHAO" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Yilun Zhao co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="SIMENG HAN" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Simeng Han co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="SHAFIQ JOTY" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Shafiq Joty co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="DRAGOMIR RADEV" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Dragomir Radev co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="CHIEN-SHENG WU" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Chien-Sheng Wu co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ARMAN COHAN" target="BENCHMARKING GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Arman Cohan co-authored a paper on benchmarking generation and evaluation capabilities of large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="COSMOPEDIA" target="DANIEL VAN STRIEN">
      <data key="d4">8.0</data>
      <data key="d5">Daniel van Strien co-authored a paper on Cosmopedia, focusing on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="COSMOPEDIA" target="LOUBNA BEN ALLAL">
      <data key="d4">8.0</data>
      <data key="d5">Loubna Ben Allal co-authored a paper on Cosmopedia, focusing on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="COSMOPEDIA" target="ANTON LOZHKOV">
      <data key="d4">8.0</data>
      <data key="d5">Anton Lozhkov co-authored a paper on Cosmopedia, focusing on creating large-scale synthetic data for pre-training language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="LUCIANO DEL CORRO">
      <data key="d4">8.0</data>
      <data key="d5">Luciano Del Corro co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="SHWETI MAHAJAN">
      <data key="d4">8.0</data>
      <data key="d5">Shweti Mahajan co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="ANDRES CODAS">
      <data key="d4">8.0</data>
      <data key="d5">Andres Codas co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="CLARISSE SIMOES">
      <data key="d4">8.0</data>
      <data key="d5">Clarisse Simoes co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="SAHAJ AGARWAL">
      <data key="d4">8.0</data>
      <data key="d5">Sahaj Agarwal co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="XUXI CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Xuxi Chen co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="ANASTASIA RAZDAIBIEDINA">
      <data key="d4">8.0</data>
      <data key="d5">Anastasia Razdaibiedina co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="ERIK JONES">
      <data key="d4">8.0</data>
      <data key="d5">Erik Jones co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="KRITI AGGARWAL">
      <data key="d4">8.0</data>
      <data key="d5">Kriti Aggarwal co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="HAMID PALANGI">
      <data key="d4">8.0</data>
      <data key="d5">Hamid Palangi co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="GUOQING ZHENG">
      <data key="d4">8.0</data>
      <data key="d5">Guoqing Zheng co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ORCA 2" target="HAMED KHANPOUR">
      <data key="d4">8.0</data>
      <data key="d5">Hamed Khanpour co-authored a paper on Orca 2, focusing on teaching small language models how to reason.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="SAMUEL J. PAECH" target="EQ-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Samuel J. Paech co-authored a paper on EQ-Bench, an emotional intelligence benchmark for large language models.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="NUMERICAL DISCRETE REASONING" target="CRITICAL COMPREHENSION QUESTION">
      <data key="d4">6.0</data>
      <data key="d5">Both types of questions assess different aspects of comprehension and reasoning skills.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="CRITICAL COMPREHENSION QUESTION" target="EVALUATIVE COMPREHENSION QUESTION">
      <data key="d4">7.0</data>
      <data key="d5">Both question types require analysis of the text's arguments or themes.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="EVALUATIVE COMPREHENSION QUESTION" target="VOCABULARY AND LANGUAGE USE">
      <data key="d4">5.0</data>
      <data key="d5">Vocabulary questions can support evaluative comprehension by testing understanding of key terms.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="RELATIONSHIP COMPREHENSION QUESTION" target="SEQUENCING EVENTS">
      <data key="d4">6.0</data>
      <data key="d5">Both question types involve organizing information based on the text's content.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="STRENGTHEN" target="WEAKEN">
      <data key="d4">7.0</data>
      <data key="d5">Both types of questions focus on evaluating the strength of arguments presented in the text.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="ASSUMPTION" target="FLAW">
      <data key="d4">7.0</data>
      <data key="d5">Assumption and flaw questions both analyze the underlying logic of arguments in the text.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="FLAW" target="METHOD OF REASONING">
      <data key="d4">6.0</data>
      <data key="d5">Method of reasoning questions can help identify flaws in the argument's construction.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="INFERENCE" target="PRINCIPLE">
      <data key="d4">6.0</data>
      <data key="d5">Inference questions often rely on recognizing principles that underlie the text's arguments.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="PARAPHRASING" target="TEXT SIMPLIFICATION">
      <data key="d4">7.0</data>
      <data key="d5">Both text modification types aim to alter the original text while maintaining its meaning.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT SIMPLIFICATION" target="TEXT EXPANSION">
      <data key="d4">6.0</data>
      <data key="d5">Text expansion can complement simplification by adding detail while making it easier to understand.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT TRANSLATION" target="TEXT ANNOTATION">
      <data key="d4">5.0</data>
      <data key="d5">Both processes involve modifying text for clarity and understanding in different contexts.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="KEYWORD REPLACEMENT" target="TEXT REMOVING">
      <data key="d4">5.0</data>
      <data key="d5">Both text modification types involve altering the original text for specific purposes.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="INSTRUCTION TAXONOMY" target="TEXT MODIFICATION FLOW">
      <data key="d4">7.0</data>
      <data key="d5">The text modification flow is guided by the instruction taxonomy, which categorizes different modification techniques.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="GROUND TRUTH" target="ACCURACY SCORES">
      <data key="d4">1.0</data>
      <data key="d5">Ground truth is essential for calculating accuracy scores, as it provides the standard for comparison.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="ERROR ANALYSIS" target="FINAL VERDICT">
      <data key="d4">1.0</data>
      <data key="d5">Error analysis leads to the final verdict, determining the correctness of the student's answer based on the comparison.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="ELLIOT" target="ALEX">
      <data key="d4">8.0</data>
      <data key="d5">Elliot has confessed his feelings to Alex, who is already in a relationship, creating emotional conflict for Elliot.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ELLIOT" target="EMOTIONS">
      <data key="d4">9.0</data>
      <data key="d5">Elliot experiences a range of emotions including resignation, anger, hopefulness, and embarrassment after confessing to Alex.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ELLIOT" target="SCORES">
      <data key="d4">9.0</data>
      <data key="d5">Elliot's emotions are quantified by scores that reflect the intensity of each feeling he experiences after his confession.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMOTIONS" target="RESIGNED">
      <data key="d4">7.0</data>
      <data key="d5">Resigned is one of the emotions felt by Elliot, indicating acceptance of his situation.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMOTIONS" target="ANGRY">
      <data key="d4">6.0</data>
      <data key="d5">Angry is one of the emotions felt by Elliot, indicating frustration with himself.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMOTIONS" target="HOPEFUL">
      <data key="d4">6.0</data>
      <data key="d5">Hopeful is one of the emotions felt by Elliot, indicating a desire for a positive outcome with Alex.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMOTIONS" target="EMBARRASSED">
      <data key="d4">7.0</data>
      <data key="d5">Embarrassed is one of the emotions felt by Elliot, indicating discomfort for putting Alex in an awkward position.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="RESIGNED" target="RESIGNED SCORE">
      <data key="d4">8.0</data>
      <data key="d5">The resigned emotion is quantified by a score of 7, indicating its intensity in Elliot's emotional state.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ANGRY" target="ANGRY SCORE">
      <data key="d4">8.0</data>
      <data key="d5">The angry emotion is quantified by a score of 3, indicating its intensity in Elliot's emotional state.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HOPEFUL" target="HOPEFUL SCORE">
      <data key="d4">8.0</data>
      <data key="d5">The hopeful emotion is quantified by a score of 5, indicating its intensity in Elliot's emotional state.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMBARRASSED" target="EMBARRASSED SCORE">
      <data key="d4">1.0</data>
      <data key="d5">The embarrassed emotion is quantified by a score of 8, indicating its intensity in Elliot's emotional state.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
  </graph>
</graphml>