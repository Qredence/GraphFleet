<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d6" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d5" for="edge" attr.name="description" attr.type="string" />
  <key id="d4" for="edge" attr.name="weight" attr.type="double" />
  <key id="d3" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d2" for="node" attr.name="source_id" attr.type="string" />
  <key id="d1" for="node" attr.name="description" attr.type="string" />
  <key id="d0" for="node" attr.name="type" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="GRAPH RAG">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Graph RAG is an advanced retrieval-augmented generation (RAG) system that leverages graph indexing to enhance the comprehensiveness and diversity of answers in datasets such as Podcast transcripts and News articles. Developed by NebulaGraph, this method uses a self-generated graph index to facilitate efficient iterative question answering and summarization, requiring fewer context tokens compared to traditional source text summarization. Graph RAG employs the natural modularity of graphs to partition data for global summarization, combining knowledge graph generation, retrieval-augmented generation, and query-focused summarization to support human sensemaking over entire text corpora. It scales effectively with both the generality of user questions and the quantity of source text to be indexed, using a large language model (LLM) to build a graph-based text index in two stages: deriving an entity knowledge graph from source documents and pre-generating community summaries for groups of closely-related entities. This approach outperforms naive RAG in terms of comprehensiveness and diversity, making it a powerful tool for generating detailed lists of public figures from various entertainment sectors and answering user queries based on graph communities at different levels.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8,c8e8019de153e439d6a79dcf209b943b,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="RAG">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">RAG (Retrieval-Augmented Generation) is a multifaceted method designed to enhance the performance of language models by incorporating retrieved documents into their responses. It is referenced as a potential building block for Advanced Driver Assistance Systems (ADAS), allowing for the integration of retrieval mechanisms in agentic systems. RAG can be taught to AI models using data generated by AgentInstruct and is a crucial tool within the LangChain framework to improve agentic systems. This technique involves retrieving relevant information from external data sources and adding it to the context window of a Large Language Model (LLM), thereby boosting the model's capacity to generate informed, contextually precise responses. RAG is particularly effective in answering user questions over entire datasets by retrieving relevant information from an external knowledge source, making it suitable for situations where answers are contained locally within regions of text. However, it may be inadequate for query-focused summarization tasks. Overall, RAG is an important building block for agentic systems, enhancing their performance by retrieving and integrating relevant information.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c932f7def033fa2b1bf210fbb771e7d,4884e8429ca1e567dadf5e22b4b68274,64476a39d7d8b87b399e3bd3cead79c7,6bdf681c0bd9e401ac72344a6a0ae479,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="LLM">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">LLM (Large Language Model) is an advanced AI model designed for a variety of natural language processing tasks, including reasoning, summarization, and understanding implied relationships. It powers agents and can optionally use tools to perform specific tasks. LLMs are capable of extracting descriptions of entities, relationships, and claims from source texts, as well as generating questions and evaluating answers. They are also used to automate human-like sensemaking in complex domains, such as in Graph RAG, where they build graph-based text indexes and generate community summaries. Additionally, LLMs are employed to generate assessments and answers based on data inputs.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b,e66ed885a08f92cc69f4895302c33047,edab4014b8f55e5b25bd7f396314be1f,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="QFS">
      <data key="d0">TASK, METHOD</data>
      <data key="d1">Query-focused summarization (QFS) is a task that generates natural language summaries based on user queries. It is more appropriate for global questions directed at an entire text corpus, rather than explicit retrieval tasks.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="MICROSOFT RESEARCH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Research is a division of Microsoft dedicated to the development of advanced technologies, including the Graph RAG approach. It is the organization where the authors of the paper are affiliated, focusing on the advancement of language models and synthetic data generation techniques. Through its innovative research, Microsoft Research aims to push the boundaries of technology and contribute significantly to the field of computer science.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">A division of Microsoft involved in the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="MICROSOFT OFFICE OF THE CTO">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">A division of Microsoft involved in the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="DAREN EDGE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daren Edge is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="HA TRINH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ha Trinh is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="NEWMAN CHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Newman Cheng is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="JOSHUA BRADLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joshua Bradley is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="ALEX CHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alex Chao is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="APURVA MODY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Apurva Mody is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="STEVEN TRUITT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Steven Truitt is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="JONATHAN LARSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jonathan Larson is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="HUMAN SENSEMAKING">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Human sensemaking is the process of understanding connections among people, places, and events to anticipate their trajectories and act effectively. It is a key concept in the development of Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="COMMUNITY DETECTION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Community detection is a technique used to partition a graph index into groups of elements (nodes, edges, covariates) that can be summarized in parallel at both indexing time and query time.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="LEIDEN">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">LEIDEN is a community detection algorithm developed by Traag et al. It is designed to partition graphs into modular communities, effectively grouping elements based on their connections. This algorithm is also utilized in the Graph RAG (Region Adjacency Graph) approach to segment the graph index into distinct groups of elements, enhancing the understanding of the underlying structure and dynamics within the graph.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION">
      <data key="d0">TASK, METHOD</data>
      <data key="d1">Query-focused summarization (QFS) is a task that generates natural language summaries based on user queries. It is particularly suited for addressing global questions directed at an entire text corpus, rather than explicit retrieval tasks. QFS is often employed in the final round of the Graph RAG approach to produce a comprehensive global answer. Additionally, it is a method of summarizing information in alignment with specific queries or questions, frequently used in the context of graph-based indexing.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">TASK, METHOD</data>
    </node>
    <node id="EXTERNAL KNOWLEDGE SOURCE">
      <data key="d0">RESOURCE, DATA</data>
      <data key="d1">An external knowledge source is used in RAG to retrieve relevant information for answering user questions.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">RESOURCE, DATA</data>
    </node>
    <node id="SOURCE DOCUMENTS">
      <data key="d0">RESOURCE, DATA</data>
      <data key="d1">The SOURCE DOCUMENTS are the original texts from which text chunks are extracted for processing in the Graph RAG approach. These documents serve as the foundational materials from which information is extracted and indexed, playing a crucial role in the overall structure and functionality of the Graph RAG methodology.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">RESOURCE, DATA</data>
    </node>
    <node id="TEXT CHUNKS">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">"TEXT CHUNKS" are segments of text extracted from source documents, utilized in the Graph RAG approach for processing and entity extraction. These text chunks are integral components in the Graph RAG methodology, where they are systematically extracted and processed to facilitate the identification and analysis of entities within the source documents.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="ELEMENT INSTANCES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Element instances are specific pieces of information extracted from text chunks in the Graph RAG approach. They represent the initial extracted descriptions of entities, relationships, and claims from source texts. These instances are then summarized into single blocks of descriptive text for each graph element, providing a comprehensive and structured representation of the underlying data.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="ELEMENT SUMMARIES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Element summaries are domain-tailored summaries of element instances in the Graph RAG approach. They are the result of summarizing instance-level descriptions into single blocks of descriptive text for each graph element, such as entity nodes, relationship edges, and claim covariates. This process ensures that complex and detailed information about each element is distilled into a concise and coherent format, facilitating easier understanding and analysis of the graph's structure and dynamics.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="GRAPH COMMUNITIES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Graph communities are groups of nodes in a graph that are more strongly connected to each other than to other nodes. These communities are detected using algorithms like Leiden and are used for global summarization. In the Graph RAG method, different levels of community summaries (C0, C1, C2, C3) are utilized to answer user queries. These summaries help in identifying and analyzing the intricate connections and hierarchies within the graph, ensuring a comprehensive understanding of the dynamics and interactions within the graph communities.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="COMMUNITY SUMMARIES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Community summaries are domain-tailored, report-like summaries of graph communities in the Graph RAG approach. They are generated from community-level data and are prepared by shuffling and dividing into chunks of pre-specified token size. These summaries are created for different levels of the community structure, including root-level communities in the entity-based graph index, and are used to provide a comprehensive understanding of the global structure and semantics of the dataset. Community summaries are instrumental in answering user queries, improving answer comprehensiveness and diversity, and are particularly useful for addressing global queries within the Graph RAG framework.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,4930fce6da868f894757a9da465807ba,ac21ebe9a9d70d691c717f961d3f10c8,e66ed885a08f92cc69f4895302c33047,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="COMMUNITY ANSWERS">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Community answers are partial responses generated from community summaries in the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="GLOBAL ANSWER">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">GLOBAL ANSWER is the final response generated for a user query by combining intermediate community answers. These answers are sorted by their helpfulness score and summarized until the token limit is reached. This process is part of the Graph RAG approach, which ensures that the final answer is comprehensive and derived from the collective input of the community.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,4930fce6da868f894757a9da465807ba</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="INDEXING TIME">
      <data key="d0">TIME, STAGE</data>
      <data key="d1">Indexing time is the stage in the Graph RAG approach when the graph index is built and community summaries are generated.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TIME, STAGE</data>
    </node>
    <node id="QUERY TIME">
      <data key="d0">TIME, STAGE</data>
      <data key="d1">Query time is the stage in the Graph RAG approach when community summaries are used to generate partial responses and a final global answer.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TIME, STAGE</data>
    </node>
    <node id="PIPELINE STAGE">
      <data key="d0">STAGE, PROCESS</data>
      <data key="d1">Pipeline stage refers to the different stages in the Graph RAG approach, including indexing time and query time.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">STAGE, PROCESS</data>
    </node>
    <node id="SENSEMAKING">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Sensemaking is the process of understanding and making sense of complex information, often facilitated by methods like Graph RAG. It involves comprehending large text corpora and understanding connections among people, places, and events to anticipate their trajectories and act effectively. Sensemaking is a key concept in the development of Graph RAG and includes making informed judgments about a topic, often evaluated using specific metrics.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="TRANSFORMER ARCHITECTURE">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Transformer architecture is a type of model that has shown substantial improvements in summarization tasks and is used in modern LLMs.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TECHNOLOGY, MODEL</data>
    </node>
    <node id="GPT">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">GPT is a series of large, advanced language models developed by OpenAI. These models are capable of in-context learning, making them highly effective for tasks such as summarization and sensemaking. As a Foundation Model, GPT serves as a general-purpose agent, adept at handling a wide range of agentic tasks.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="LLAMA">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">LLAMA, a series of large language models developed by Touvron et al., is designed for advanced in-context learning, particularly excelling in summarization tasks. These models, collectively referred to as Llama, are highly versatile and are employed for a variety of applications, including summarization and sensemaking.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="GEMINI">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">GEMINI is a series of advanced, highly capable multimodal language models developed by Anil et al. These models are specifically designed for in-context learning, making them particularly effective for tasks such as summarization and sensemaking. The GEMINI family of models is referenced in the document as being proficient in handling a variety of complex tasks, showcasing their versatility and advanced capabilities in the realm of language processing.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Retrieval-Augmented Generation (RAG) is a technique for enhancing knowledge-intensive natural language processing (NLP) tasks by combining retrieval and generation processes. This established approach is designed to answer user questions over entire datasets by retrieving relevant information from an external knowledge source. It is particularly effective in situations where answers are contained locally within regions of text, whose retrieval provides sufficient grounding for the generation task. RAG was discussed in a paper published in Advances in Neural Information Processing Systems in 2020, highlighting its significance in the field of NLP.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,6109537356a2ce2339f77c827aa3668e,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SUMMARIZATION TASKS">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">Summarization tasks involve condensing large volumes of text into shorter, coherent summaries. These tasks are now trivialized by modern LLMs.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LLMS">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Large Language Models (LLMs) are advanced language models trained on vast amounts of data to perform various natural language processing tasks. Examples of LLMs include GPT, Llama, and Gemini, which are capable of using in-context learning to summarize content provided in their context window. These models leverage their extensive training to understand and generate human-like text, making them powerful tools for a wide range of applications in natural language understanding and generation.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">A type of summarization that focuses on generating summaries based on specific queries over an entire corpus.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="KNOWLEDGE GRAPH">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">The KNOWLEDGE GRAPH is a graph-based representation of knowledge, utilized in the Graph RAG approach for summarization tasks. It serves as a data structure in advanced Retrieval-Augmented Generation (RAG) systems for organizing and retrieving information. This is exemplified in systems like KAPING and other similar frameworks, where the knowledge graph plays a crucial role in structuring and accessing data efficiently.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="COMMUNITY DETECTION ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Algorithms like Louvain and Leiden that partition graphs into modular communities of closely-related nodes.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LOUVAIN">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">A community detection algorithm developed by Blondel et al., used to partition graphs into modular communities.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="MAP-REDUCE">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">MAP-REDUCE is a method used in text summarization (TS) where source texts are shuffled and chunked for summarization stages. It is also a technique employed in the Graph RAG approach to summarize query-focused information by first summarizing each community independently and then combining the partial answers. Additionally, Map-Reduce is utilized for global summarization of source texts and has performed competitively against Graph RAG in evaluations.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="HOTPOTQA">
      <data key="d0">DATASET</data>
      <data key="d1">HotPotQA is a comprehensive benchmark dataset designed for diverse, explainable multi-hop question answering, requiring reasoning over multiple supporting documents. Presented at the Conference on Empirical Methods in Natural Language Processing (EMNLP) in 2018, it contains 113,000 Wikipedia-based question-answer pairs crafted by crowdworkers to be diverse, multi-hop, and explainable. This dataset is used to evaluate the performance of various algorithms, including LATS, ToT, and RAP, particularly in tasks that involve both internal reasoning and external retrieval strategies. HotPotQA is notable for its role in assessing reasoning-based prompting results, achieving the highest exact match (EM) scores, and comparing the cost and performance of different methods. It is also used to evaluate entity extraction prompts, varying with chunk size and gleanings. The LATS algorithm, when used with GPT-3.5, has been shown to double the performance of ReAct on this benchmark. HotPotQA's multi-hop nature requires retrieval over two or more Wikipedia passages, making it a critical tool for open-domain question answering and explicit fact retrieval.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,8180bf20b7577f3eee40df5991e2886d,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="ENTITY EXTRACTION">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">The process of identifying and extracting entities from text, used in the Graph RAG approach to build a knowledge graph.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">Questions generated by an LLM to evaluate the Graph RAG approach, focusing on comprehensiveness, diversity, and empowerment.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="COMPREHENSIVENESS">
      <data key="d0">QUALITY METRIC</data>
      <data key="d1">COMPREHENSIVENESS is a measure of how complete and detailed an answer or report is. It captures how much detail an answer provides to cover all aspects and details of the question. This metric is used to evaluate the completeness and thoroughness of the answers provided by different summarization approaches. It serves as a target quality for evaluating summarization approaches, indicating the extent to which all relevant information is covered. Notably, Graph RAG demonstrates a 72% win rate in achieving comprehensiveness, highlighting its effectiveness in thoroughly covering necessary information.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DIVERSITY">
      <data key="d0">QUALITY METRIC</data>
      <data key="d1">DIVERSITY is a measure of the variety and range of perspectives or elements included in an answer or report. It serves as a metric capturing how varied and rich an answer is in providing different perspectives and insights on a question. Additionally, it is used to evaluate the variety and range of answers provided by different summarization approaches. As a target quality for evaluating summarization approaches, diversity indicates the variety of information covered. Notably, Graph RAG demonstrates a 62% win rate in this aspect, highlighting its effectiveness in providing diverse information or perspectives.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="EMPOWERMENT">
      <data key="d0">QUALITY METRIC</data>
      <data key="d1">EMPOWERMENT is a metric used to evaluate the degree to which answers or reports enable readers to understand and make informed judgments about a topic. It serves as a measure of how well different summarization approaches empower users by helping them develop an understanding of broad issues and themes. This metric is particularly important in assessing the effectiveness of Retrieval-Augmented Generation (RAG) approaches, as it indicates how well these methods help users reach an informed understanding by providing specific examples, quotes, and citations.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="PODCAST TRANSCRIPTS">
      <data key="d0">DATASET</data>
      <data key="d1">The "PODCAST TRANSCRIPTS" dataset is a collection of written records of spoken content from podcasts, primarily featuring conversations between Kevin Scott, the Chief Technology Officer of Microsoft, and other technology leaders. This dataset is utilized to evaluate the Graph RAG (Retrieval-Augmented Generation) approach, serving as a valuable resource for analysis and reference in the field of algorithmic analysis and natural language processing. The transcripts provide a comprehensive compilation of discussions on various technological topics, making them an essential tool for understanding the dynamics and interactions within the tech community.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="NEWS ARTICLES">
      <data key="d0">DATASET</data>
      <data key="d1">The "NEWS ARTICLES" dataset is a comprehensive collection of written pieces from media outlets that report on current events, public figures, and other topics of interest. This benchmark dataset comprises articles published from September 2013 to December 2023 across various categories. It is specifically used to evaluate the Graph RAG approach, providing a robust framework for assessing the performance and effectiveness of this algorithmic method.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TOKEN COSTS">
      <data key="d0">RESOURCE METRIC</data>
      <data key="d1">The computational cost associated with processing tokens in LLMs, relevant for evaluating the efficiency of summarization approaches.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="GOODWIN ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Goodwin et al. are researchers who have contributed to the state-of-the-art in summarization tasks, as cited in the document.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LASKAR ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Laskar et al. are researchers who have contributed to the state-of-the-art in summarization tasks, as cited in the document.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LIU AND LAPATA, 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu and Lapata are researchers who have contributed to the state-of-the-art in summarization tasks, as cited in the document.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="ACHIAM ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Achiam et al. are researchers who have contributed to the development of the GPT series, as cited in the document.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="BROWN ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brown et al., 2020, are researchers who made significant contributions to the development of in-context learning abilities of language models. They are notably recognized for their work on the GPT series, as cited in the document. Their influential paper, published in 2020, provided crucial examples for in-context learning for large language models (LLMs).</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TOUVRON ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Touvron et al., 2023, are researchers who have made significant contributions to the development of the Llama series, as cited in the document. They are also the authors of a notable paper on language models, published in 2023. Their work has been influential in advancing the field of language models, highlighting their expertise and impact within the research community.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="ANIL ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anil et al. are researchers who have contributed to the development of the Gemini series, as cited in the document.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="KURATOV ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kuratov et al., 2024, are researchers who have extensively studied the limitations of large language model (LLM) context windows. Their research, as cited in the document, specifically investigates the potential for information to be "lost in the middle" of longer contexts in language models. This work highlights the challenges and intricacies involved in maintaining the integrity of information over extended sequences, contributing valuable insights into the optimization and improvement of LLMs.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="LIU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu et al., 2023, are researchers who have made significant contributions to the field of algorithmic analysis and language models. In 2023, they explored the combination of search algorithms with language model agents and studied the limitations of large language model (LLM) context windows, particularly the phenomenon where information can be "lost in the middle" of longer contexts. They are also noted for their work on previous search approaches using language models as world models. Additionally, Liu et al. are the authors of the DyLAN algorithm and have published research on exploring search spaces using feed-forward networks in Advanced Driver Assistance Systems (ADAS). Their comprehensive studies have provided valuable insights into the dynamics and interactions within algorithmic communities.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,4884e8429ca1e567dadf5e22b4b68274,64476a39d7d8b87b399e3bd3cead79c7,c95e02c0dca4a4a36b701cbc7dd14da6,dc55f071b95dec721a9820d39cdb3ccd,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="NEW YORK TIMES">
      <data key="d0">DATA SOURCE</data>
      <data key="d1">A source of news articles used in the evaluation of the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="PODCASTS">
      <data key="d0">DATA SOURCE</data>
      <data key="d1">A source of podcast transcripts used in the evaluation of the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="NA&#207;VE RAG">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">NA&#207;VE RAG is a basic form of Retrieval-Augmented Generation (RAG) that is likely inadequate for query-focused summarization tasks. It operates by converting documents to text, splitting the text into chunks, and embedding these chunks into a vector space for retrieval and context addition in large language models (LLMs). Additionally, it is used to generate lists of public figures, focusing on specific individuals and their frequent mentions in media.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GLOBAL SUMMARIZATION">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">GLOBAL SUMMARIZATION is a technique used to summarize data across an entire dataset, as opposed to local summarization. It involves the process of creating comprehensive summaries from large datasets, facilitated by tools such as Graph RAG. This method focuses on summarizing an entire corpus of text rather than concentrating on specific queries, providing a holistic overview of the data.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="INTERMEDIATE-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA UNIT</data>
      <data key="d1">Summaries generated at an intermediate hierarchical level within a knowledge graph, used in the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA UNIT</data>
      <data key="d1">Summaries generated at a low hierarchical level within a knowledge graph, used in the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="HIERARCHICAL LEVEL">
      <data key="d0">QUALITY METRIC</data>
      <data key="d1">The level of detail at which community summaries are generated, impacting the performance of the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="FEW-SHOT EXAMPLES">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">FEW-SHOT EXAMPLES are examples provided to a language learning model (LLM) for in-context learning, which help tailor the entity extraction prompt to the specific domain of the document corpus. Additionally, these examples are used to guide the model's responses and play a crucial role in the evaluation of Language and Text Systems (LATS).</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="GLEANINGS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">GLEANINGS refer to the process of multiple rounds of entity extraction to ensure that no entities are missed. This involves assessing whether all entities were extracted and encouraging the Language Learning Model (LLM) to detect any additional entities in subsequent rounds. Additionally, GLEANINGS encompass the extraction of additional information from text chunks, which is used to improve the overall performance of entity extraction.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="NAMED ENTITIES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Named entities refer to specific categories like people, places, and organizations that are extracted from text documents.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="COVARIATES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Covariates are additional variables or attributes associated with extracted node instances, such as claims linked to detected entities, including subject, object, type, description, source text span, and start and end dates. These covariates are linked elements within a community structure that are described and prioritized in leaf-level communities.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LEIDEN ALGORITHM">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">The Leiden algorithm is used for community detection in large-scale graphs. It efficiently recovers hierarchical community structures and is used to partition graphs into mutually-exclusive, collectively-exhaustive communities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="MULTIHOP-RAG">
      <data key="d0">DATASET</data>
      <data key="d1">MULTIHOP-RAG is a research paper and benchmark dataset focused on benchmarking retrieval-augmented generation for multi-hop queries, published in 2024 by Tang and Yang. The dataset is specifically used for evaluating news articles and is instrumental in indexing and graph community detection. Visualization tools such as OpenORD and Force Atlas 2 are employed to illustrate the hierarchical clustering of entity nodes within the dataset.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="OPENORD">
      <data key="d0">TOOL, SOFTWARE</data>
      <data key="d1">OPENORD is an open-source toolbox for large graph layout developed by Martin, S., Brown, W. M., Klavans, R., and Boyack, K. It is a tool used for node layout in graph visualizations, aiding in the display of the structure of graph communities.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="FORCE ATLAS 2">
      <data key="d0">TOOL, SOFTWARE</data>
      <data key="d1">Force Atlas 2 is a tool used for node layout in graph visualizations, helping to display the structure of graph communities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="FORTUNATO, 2010">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fortunato is the author of a survey from 2010 on community detection algorithms.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="JIN ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jin et al. are the authors of a survey from 2021 on community detection algorithms.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TRAAG ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Traag et al. are the authors of the Leiden algorithm, published in 2019.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TANG AND YANG, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"Tang and Yang are researchers who, in 2024, published and indexed the MultiHop-RAG benchmark dataset. Their study from 2024 is notable for its contribution to the field, providing a comprehensive resource for evaluating multi-hop reasoning in algorithmic analysis."</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="MARTIN ET AL., 2011">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Martin et al. are the authors of the OpenORD tool, published in 2011.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="JACOMY ET AL., 2014">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacomy et al. are the authors of the Force Atlas 2 tool, published in 2014.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="DEFAULT PROMPT">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">The default prompt is used to extract a broad class of named entities like people, places, and organizations. It is generally applicable across various domains.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="SECONDARY EXTRACTION PROMPT">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">The secondary extraction prompt is used to extract additional covariates associated with the detected entities, such as claims linked to these entities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LOGIT BIAS">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Logit bias is a technique used to force a yes/no decision from the LLM during the entity extraction process, ensuring that all entities are detected.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HOMOGENEOUS NODES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Homogeneous nodes refer to nodes in a graph that are similar in nature, often used in the context of creating rich descriptive text for summarization.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="NOISE">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Noise refers to irrelevant or extraneous information that can be introduced during the extraction process, potentially affecting the quality of the extracted data.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Hierarchical community structure is an organizational framework that groups data into nested communities, used in Graph RAG. It refers to the organization of graph communities in a hierarchical manner, where communities are nested within larger communities. This structure allows for a multi-level analysis of the relationships and interactions within the data, providing a comprehensive understanding of the dynamics and hierarchies that define the structure of algorithmic communities.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ROOT COMMUNITIES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Root communities are the top-level communities in a hierarchical community structure, representing the highest level of modularity in the graph.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="SUB-COMMUNITIES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Sub-communities are lower-level communities within a hierarchical community structure, revealing internal structure within root-level communities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LEAF-LEVEL COMMUNITIES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Leaf-level communities are the smallest units in a hierarchical community structure, representing the lowest hierarchical level. These communities contain the most detailed element summaries of nodes, edges, and covariates. In the context of algorithmic analysis, these detailed summaries are prioritized and added to the LLM (Large Language Model) context window until the token limit is reached, ensuring a comprehensive understanding of the intricate connections and hierarchies within the community.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="NODE DEGREE">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Node degree refers to the number of connections a node has in a graph, often used to prioritize elements during the summarization process.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ROOT-LEVEL COMMUNITIES">
      <data key="d0">COMMUNITY STRUCTURE</data>
      <data key="d1">Root-level communities represent the highest hierarchical level in a community structure, revealing internal structures within them.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="HIGHER-LEVEL COMMUNITIES">
      <data key="d0">COMMUNITY STRUCTURE</data>
      <data key="d1">Higher-level communities are above leaf-level communities in the hierarchy. If all element summaries fit within the token limit, they are summarized similarly to leaf-level communities; otherwise, sub-community summaries are used.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="USER QUERY">
      <data key="d0">QUERY</data>
      <data key="d1">A user query is a question posed by the user that the system aims to answer using community summaries from different levels of the hierarchical community structure.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="TECH JOURNALIST">
      <data key="d0">USER</data>
      <data key="d1">A tech journalist is a potential user looking for insights and trends in the tech industry, particularly regarding the role of policy and regulation.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="EDUCATOR">
      <data key="d0">USER</data>
      <data key="d1">An educator is a potential user incorporating current affairs into curricula, particularly focusing on health and wellness.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="MT-BENCH">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">MT-BENCH is a benchmarking tool developed by LM-Sys, published in 2023, and further detailed in a publication by Zheng et al. in 2024. It is designed to evaluate the competence of chat assistants in multi-turn conversations, specifically targeting explicit fact retrieval in open-domain question answering. The benchmark consists of a first-turn query and a second-turn query, with responses evaluated by GPT-4, which provides a score from 1 to 10 for each turn's response. Notably, Orca-3 scored 8.20 on MT-BENCH, marking a 9% improvement over Orca-2.5.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,4930fce6da868f894757a9da465807ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="RAG SYSTEMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">RAG systems are used for global sensemaking tasks, requiring questions that convey a high-level understanding of dataset contents.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="KOESTEN ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Koesten et al. are researchers who discussed the process of data sensemaking in 2021.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="XU AND LAPATA, 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu and Lapata are researchers who developed methods for extracting latent summarization queries from source texts in 2021.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="NODES">
      <data key="d0">ELEMENT</data>
      <data key="d1">Nodes are elements sampled during the expansion phase in LATS evaluation. They are components in search algorithms that store and retrieve external feedback, playing a crucial role in the search process of LATS. Nodes are explicitly stored in memory and expanded during the search process. Within a community structure, nodes are described and prioritized in leaf-level communities. They refer to individual points or states in a search algorithm that are expanded or explored to find a solution. Specifically, in the context of algorithms like LATS, nodes are the points in the search tree expanded during the exploration process, used in tasks such as the Game of 24.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,4930fce6da868f894757a9da465807ba,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="EDGES">
      <data key="d0">ELEMENT</data>
      <data key="d1">Edges are elements within a community structure that connect nodes and are described and prioritized in leaf-level communities.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="TOKEN LIMIT">
      <data key="d0">CONSTRAINT</data>
      <data key="d1">The token limit is a constraint that determines how many tokens can be included in the LLM context window or final context for generating answers.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="LLM CONTEXT WINDOW">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The LLM context window is the space within which tokens are added and processed by the language model to generate summaries and answers.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="INTERMEDIATE ANSWERS">
      <data key="d0">ANSWER</data>
      <data key="d1">Intermediate answers are generated for each chunk of community summaries and are scored for helpfulness before being combined into the global answer.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="HELPFULNESS SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">The helpfulness score is a metric between 0-100 that indicates how helpful an intermediate answer is in answering the target question.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="KEVIN SCOTT">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin Scott is the CTO of Microsoft and a participant in the podcast transcripts dataset.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="TECHNOLOGY LEADERS">
      <data key="d0">PERSON</data>
      <data key="d1">Technology leaders are participants in the podcast transcripts dataset, engaging in conversations with Kevin Scott.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="ZHENG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">ZHENG ET AL., 2024 are researchers who have demonstrated the effectiveness of Large Language Models (LLMs) in head-to-head comparisons of competing outputs. In 2024, they published the MT-Bench benchmark dataset, which serves as a critical tool for evaluating and comparing the performance of various LLMs. Their work contributes significantly to the field of algorithmic analysis by providing a standardized dataset that facilitates the assessment of LLM capabilities, thereby advancing the understanding and development of these models.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="DATASET">
      <data key="d0">DATA, COLLECTION</data>
      <data key="d1">The "DATASET" is a collection of data used for analysis, evaluation, and training models. It is often described in terms of its contents and structure. Notable examples include datasets like Orca-Bench and data synthesized by AgentInstruct, which are specifically utilized for training and evaluating models.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="USER">
      <data key="d0">PERSON, ROLE</data>
      <data key="d1">The USER refers to individuals or entities that interact with the dataset or system, performing specific tasks or queries. Specifically, the USER is the individual who interacts with the AI assistant, providing input and requesting actions such as creating a meal plan, tracking meals, and updating food items.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="TASK">
      <data key="d0">ACTIVITY, OPERATION</data>
      <data key="d1">A task in the context of the Meta Agent Search algorithm refers to the specific problem or objective that the meta agent aims to solve by programming new agents. It is an activity or job that an agent is designed to perform or solve, often involving specific activities or operations performed by users, which may include interaction with the dataset or system.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,26b2dad01a219bc034ac7d6a32d07582,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="QUESTION">
      <data key="d0">QUERY, INQUIRY</data>
      <data key="d1">A "QUESTION" is a problem or query presented to the student, often requiring a solution or answer. It serves as a prompt that necessitates a response, which is then evaluated for accuracy or understanding. Typically, a question initiates a question-answering task, demanding analysis and reasoning to determine the correct answer. Questions are generated to assess the student's comprehension of the dataset, requiring a thorough understanding of the entire corpus.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,26b2dad01a219bc034ac7d6a32d07582,357f3442ba581c9d2bdf84d90509056f,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT SUMMARIZATION (TS)">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method applying a map-reduce approach directly to source texts for summarization purposes.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="SEMANTIC SEARCH (SS)">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A naive RAG approach where text chunks are retrieved and added to the context window until the token limit is reached.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="CONTEXT WINDOW">
      <data key="d0">TECHNICAL TERM, PARAMETER</data>
      <data key="d1">The size of the text window used for generating answers, consistent across all conditions except for minor modifications.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ENTITY">
      <data key="d0">CONCEPT, ELEMENT</data>
      <data key="d1">Basic units identified in the dataset, used for creating the graph index in the Graph RAG method.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="RELATIONSHIP">
      <data key="d0">CONCEPT, CONNECTION</data>
      <data key="d1">The term "RELATIONSHIP" encompasses two distinct contexts. Firstly, it refers to the connections between entities, which are utilized for creating the graph index in the Graph RAG method. This method is instrumental in structuring and analyzing complex networks by mapping out the intricate connections and hierarchies within a community. Secondly, "RELATIONSHIP" pertains to the current romantic involvement of Alex, a situation that adds complexity to Elliot's confession. This dual usage highlights the multifaceted nature of relationships, both in algorithmic analysis and personal dynamics.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PODCAST DATASET">
      <data key="d0">DATASET, COLLECTION</data>
      <data key="d1">The "PODCAST DATASET" is a specialized dataset comprising podcast transcripts, designed to assess the efficacy of various summarization techniques. This dataset is particularly notable for its use in evaluations that involve a context window size of 600 tokens and a single gleaning process.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="NEWS DATASET">
      <data key="d0">DATASET, COLLECTION</data>
      <data key="d1">The "NEWS DATASET" is a collection of news articles specifically designed to evaluate the performance of various summarization approaches. This dataset is utilized in assessments with a context window size of 600 tokens and includes 0 gleanings, ensuring a standardized framework for testing and comparing different summarization techniques.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DIRECTNESS">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">DIRECTNESS is a control metric that captures how specifically and clearly an answer addresses the question. It measures the straightforwardness and specificity of an answer or report in addressing the question. This metric is used to evaluate the straightforwardness and clarity of the answers provided by different summarization approaches.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="LLM EVALUATOR">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">A Large Language Model used to evaluate answers based on specific metrics, performing head-to-head comparisons of competing outputs.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PUBLIC FIGURES">
      <data key="d0">PERSON, ENTITY</data>
      <data key="d1">PUBLIC FIGURES are individuals who are repeatedly mentioned across various entertainment articles, reflecting their significant impact and presence within the industry. These well-known individuals in society are often covered in media, including celebrities, politicians, and other influential people. Their prominence in public discourse highlights their influence and the substantial role they play in shaping cultural and societal narratives.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTERTAINMENT INDUSTRY">
      <data key="d0">SECTOR, FIELD</data>
      <data key="d1">The ENTERTAINMENT INDUSTRY is a diverse sector of the economy that produces and distributes a wide array of entertainment content, including film, television, music, sports, and digital media. This industry is significantly influenced by prominent public figures who shape trends and drive consumer engagement across various platforms. The dynamic nature of the entertainment industry ensures its continuous evolution, adapting to new technologies and changing audience preferences.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ACTIVITY-CENTERED APPROACH">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">An approach used to automate the generation of questions by focusing on activities related to the dataset.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="N">
      <data key="d0">PARAMETER, VARIABLE</data>
      <data key="d1">A variable representing the number of potential users, tasks per user, or questions generated per (user, task) combination.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="EVALUATION">
      <data key="d0">PROCESS, ASSESSMENT</data>
      <data key="d1">Evaluation in Meta Agent Search involves assessing the performance and effectiveness of discovered agents on validation and test sets. It is a critical step in this process, ensuring that the agents are performing as expected. Specifically, in the LATS algorithm, Evaluation is the third operation where a scalar value is assigned to each new child node. This scalar value quantifies the agent&#8217;s progress in task completion and is used for selection and backpropagation. The process involves using specific metrics to assess the performance or effectiveness of different methods or conditions, thereby providing a comprehensive measure of the agent's capabilities.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,1a6353c9d196dc2debad7c27c902bcd7,26b2dad01a219bc034ac7d6a32d07582,81c504ffbcc5ed882e234802135295ba,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="CONDITION">
      <data key="d0">PARAMETER, VARIABLE</data>
      <data key="d1">Different settings or methods (e.g., C0, C1, C2, C3, TS, SS) compared in the analysis to evaluate their performance.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ANSWER GENERATION">
      <data key="d0">PROCESS, ACTIVITY</data>
      <data key="d1">The process of generating answers to user queries, influenced by the size of the context window and the prompts used.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PROMPT">
      <data key="d0">TECHNICAL TERM, PARAMETER</data>
      <data key="d1">PROMPT refers to a set of instructions or input provided to guide various models and agents in performing specific tasks. In the context of the Meta Agent Search algorithm, a prompt is an instruction or input given to the meta agent to guide the programming of new agents, influencing their thought process, design, and implementation. Similarly, in language models, prompts consist of instructions or few-shot input-output examples that help improve reasoning and task performance. They are also used to condition responses during the training of models like Orca-3. Overall, prompts serve as crucial inputs that direct the behavior and output of different computational models and agents.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,24d7b89ae9522ae60d2317984951355b,26b2dad01a219bc034ac7d6a32d07582,282313a8340c6792e8c35f53ed157cd0,b8dd0300033963bb4a3e1bad37f8e7b9,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="GLEANING">
      <data key="d0">PROCESS, ACTIVITY</data>
      <data key="d1">The process of extracting information from the dataset, used in the context window size for the Podcast and News datasets.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="RAGAS">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">RAGAS is a method for automatically evaluating the performance of Retrieval Augmented Generation (RAG) systems. It focuses on assessing qualities such as context relevance, faithfulness, and answer relevance. This method is detailed in a paper by Es et al. (2023), providing a structured approach to the automated evaluation of RAG systems.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HEAD-TO-HEAD COMPARISON">
      <data key="d0">METHOD, EVALUATION</data>
      <data key="d1">A method of comparing competing outputs directly against each other using specific metrics.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="WANG ET AL., 2023A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al., 2023A are researchers who have demonstrated that large language models (LLMs) can achieve state-of-the-art or competitive results in evaluating natural language generation. Additionally, they have contributed to the development of new skills for embodied agents, with their findings published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ES ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Researchers who have contributed to the development of RAGAS for evaluating RAG systems.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PROMINENT PUBLIC FIGURES">
      <data key="d0">PERSON, ENTITY</data>
      <data key="d1">Key individuals repeatedly mentioned in various entertainment articles, reflecting their significant contributions and influence.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="DIRECTORS">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who oversee the creative aspects of film, television, or other media productions.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MUSICIANS">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who create, perform, and record music.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="EXECUTIVES">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who hold senior management positions in organizations, making high-level decisions.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ATHLETES">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who compete in sports and physical activities at professional or amateur levels.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="COACHES">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who train and guide athletes or teams in sports.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="INFLUENCERS">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who have the power to affect the purchasing decisions of others because of their authority, knowledge, position, or relationship with their audience.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTREPRENEURS">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who start and run businesses, taking on financial risks in the hope of profit.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TAYLOR SWIFT">
      <data key="d0">PERSON, MUSICIAN</data>
      <data key="d1">A well-known musician and public figure frequently mentioned in entertainment articles for her professional achievements and personal life.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TRAVIS KELCE">
      <data key="d0">PERSON, ATHLETE</data>
      <data key="d1">A professional athlete frequently mentioned in entertainment articles for his sports achievements and personal life.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="BRITNEY SPEARS">
      <data key="d0">PERSON, MUSICIAN</data>
      <data key="d1">A well-known musician and public figure frequently mentioned in entertainment articles for her professional achievements and personal life.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="JUSTIN TIMBERLAKE">
      <data key="d0">PERSON, MUSICIAN</data>
      <data key="d1">A well-known musician and public figure frequently mentioned in entertainment articles for his professional achievements and personal life.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MEDIA COVERAGE">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">The reporting and discussion of events, people, and topics in various media outlets.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">ACTIVITY, PROCESS</data>
    </node>
    <node id="CULTURAL NARRATIVES">
      <data key="d0">CONCEPT, IDEA</data>
      <data key="d1">The stories and ideas that are prevalent in a culture, often shaped by influential figures in entertainment.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="DIGITAL MEDIA">
      <data key="d0">MEDIUM, TECHNOLOGY</data>
      <data key="d1">Platforms and technologies used for digital communication, including social media, websites, and streaming services.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">MEDIUM, TECHNOLOGY</data>
    </node>
    <node id="CONTROVERSIES">
      <data key="d0">EVENT, ISSUE</data>
      <data key="d1">Public disputes or debates that attract widespread attention and often involve public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="CONTROVERSY">
      <data key="d0">EVENT, ISSUE</data>
      <data key="d1">A public dispute or debate that attracts widespread attention, often involving public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="FILM">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">A form of visual storytelling that involves the production of movies.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TELEVISION">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">A medium for broadcasting visual content, including shows, series, and news.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MUSIC">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">An art form and cultural activity involving the creation and performance of sound organized in time.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="SPORTS">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">Physical activities and games that involve competition and skill.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="GAMING">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">The activity of playing electronic games, often involving interaction with a user interface to generate visual feedback.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TRENDS">
      <data key="d0">CONCEPT, IDEA</data>
      <data key="d1">General directions in which something is developing or changing, often influenced by public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="CULTURAL LANDSCAPE">
      <data key="d0">CONCEPT, IDEA</data>
      <data key="d1">The cultural environment shaped by the activities and influences of public figures and media.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="SOCIAL DISCUSSIONS">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">Public conversations and debates about various topics, often influenced by public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PUBLIC DISCOURSE">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">The exchange of ideas and information in the public sphere, often involving public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PROFESSIONAL ACHIEVEMENTS">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">Notable accomplishments in one's career or profession.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PERSONAL LIVES">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">Aspects of individuals' lives that are private or related to their personal relationships.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="CULTURAL AND ECONOMIC IMPACTS">
      <data key="d0">CONCEPT, IDEA</data>
      <data key="d1">The effects that public figures and their activities have on culture and the economy.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTERTAINMENT ARTICLES">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">Written pieces in media outlets that focus on topics related to entertainment and public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="DATA REPORTS">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">Documents that provide detailed information and analysis on specific topics, often used as references.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="NAIVE RAG">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Naive RAG is a baseline approach for text summarization that is outperformed by global approaches in terms of comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="CONTEXT WINDOW SIZE">
      <data key="d0">PARAMETER</data>
      <data key="d1">The size of the context window used in language models, tested at 8k, 16k, 32k, and 64k tokens to determine its effect on comprehensiveness, diversity, and empowerment.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="GPT-4-TURBO">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">An advanced language model with a large context size of 128k tokens, used to explore the effects of varying context window sizes.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="ROOT-LEVEL SUMMARIES">
      <data key="d0">DATA, METHOD</data>
      <data key="d1">Summaries generated at the root level of a graph community hierarchy, requiring dramatically fewer tokens per query.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d0">DATA, METHOD</data>
      <data key="d1">Summaries generated at intermediate levels of a graph community hierarchy, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="LOW-LEVEL SUMMARIES">
      <data key="d0">DATA, METHOD</data>
      <data key="d1">Summaries generated at low levels of a graph community hierarchy, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="MAP-REDUCE SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">MAP-REDUCE SUMMARIZATION is a resource-intensive approach to summarizing source texts, requiring the highest number of context tokens. This technique leverages the map-reduce framework to effectively summarize large datasets. Compared to Graph RAG, map-reduce summarization is particularly noted for its ability to handle extensive and complex data, albeit with significant computational demands.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="SS">
      <data key="d0">METHOD</data>
      <data key="d1">SS is a baseline condition used in the evaluation of different context window sizes and summarization approaches.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="TS">
      <data key="d0">METHOD</data>
      <data key="d1">TS stands for global text summarization without a graph index, used as a comparison condition in the evaluation.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C0">
      <data key="d0">METHOD</data>
      <data key="d1">C0 represents root-level community summaries in the graph community hierarchy, requiring dramatically fewer tokens per query.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C1">
      <data key="d0">METHOD</data>
      <data key="d1">C1 represents intermediate-level community summaries in the graph community hierarchy, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C2">
      <data key="d0">METHOD</data>
      <data key="d1">C2 represents low-level community summaries in the graph community hierarchy, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C3">
      <data key="d0">METHOD</data>
      <data key="d1">C3 represents the lowest level of community summaries in the graph community hierarchy, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="WIN RATE">
      <data key="d0">METRIC</data>
      <data key="d1">Win rate is a metric used to evaluate the performance of different summarization approaches in terms of comprehensiveness, diversity, and empowerment.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="CONTEXT TOKENS">
      <data key="d0">DATA</data>
      <data key="d1">CONTEXT TOKENS are units of information used in the context window of a Large Language Model (LLM). They play a crucial role in various summarization approaches, particularly in the context of Graph Retrieval-Augmented Generation (Graph RAG). Notably, Graph RAG requires fewer context tokens compared to other methods, including source text summarization. This efficiency in token usage highlights the effectiveness of Graph RAG in optimizing the summarization process within the constraints of the context window.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="ROOT-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Root-level community summaries are high-level summaries that require significantly fewer context tokens in Graph RAG compared to other methods.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GAO ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gao et al., 2023, are researchers who have made significant contributions to the field of language models and advanced retrieval-augmented generation (RAG) systems. In their 2023 publications, they introduced the Na&#239;ve RAG and advanced RAG systems, and authored a pivotal paper on language models. Additionally, they developed the GSM-Hard benchmark and dataset, which are crucial for evaluating the transferability of discovered agents from MGSM math tasks to more challenging math tasks. Their work on the GSM-Hard math task benchmark has been instrumental in advancing the understanding and capabilities of language models in handling complex mathematical problems.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba,93cb0d0456e0822b5fe30a3e627405f8,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHENG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cheng et al. are researchers who have contributed to the concept of self-memory (Selfmem) for generation-augmented retrieval, published in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="MAO ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mao et al. are researchers who have contributed to the concept of generation-augmented retrieval (GAR), published in 2020.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHAO ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shao et al. are researchers who have contributed to the concept of iterative retrieval-generation (Iter-RetGen), published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WANG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al., 2024, are researchers who have significantly contributed to the field of agentic systems and their applications. They are the authors of a study published in 2024 that discusses the effectiveness of Meta Agent Search in various domains. Additionally, they have contributed to the concept of federated retrieval-generation (FeB4RAG), further enhancing their impact on the research community.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71,c3d0436082aada237ee4bee645f16059,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CAIRE-COVID">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">CAIRE-COVID is a question answering and query-focused multi-document summarization system designed to manage COVID-19 scholarly information. Developed in 2020 by Su, D., Xu, Y., Yu, T., Siddique, F. B., Barezi, E. J., and Fung, P., CAIRE-COVID integrates multiple concepts to effectively summarize information from various documents, aiding in the efficient retrieval and understanding of COVID-19 related research.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="FENG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Feng et al. are researchers who have contributed to the concept of multi-hop question answering (ITRG), published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TRIVEDI ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trivedi et al. are researchers who have contributed to the concept of multi-hop question answering (IR-CoT), published in 2022.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KHATTAB ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khattab et al. are researchers who have contributed to the concept of multi-hop question answering (DSP), published in 2022.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SARTHI ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sarthi et al. are researchers who have contributed to the concept of generating a hierarchical index of text chunks (RAPTOR), published in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KIM ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kim et al. are researchers who have contributed to the concept of generating a "tree of clarifications" for answering multiple interpretations of ambiguous questions, published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TRAJANOSKA ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trajanoska et al. are researchers who have contributed to the use of LLMs for knowledge graph creation and completion, published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YAO ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al., 2023, are researchers who have significantly contributed to the field of chain-of-thought planning and reasoning. Their work, published in 2023, focuses on the use of large language models (LLMs) for knowledge graph creation and completion. Their research has been cited in various papers, highlighting their role in advancing methods for structured reasoning and planning using LLMs.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BAN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ban et al. are researchers who have contributed to the extraction of causal graphs from source texts, published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZHANG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang et al. are researchers who have contributed to the extraction of causal graphs from source texts, published in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BAEK ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Baek et al. are researchers who have contributed to the development of advanced RAG systems where the index is a knowledge graph (KAPING), published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HE ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">He et al. are researchers who have contributed to the development of advanced RAG systems where subsets of the graph structure are the objects of enquiry (G-Retriever), published in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KANG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kang et al. are researchers who have contributed to the development of advanced RAG systems where narrative outputs are grounded in the facts of retrieved subgraphs (SURGE), published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="RANADE AND JOSHI, 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ranade and Joshi are researchers who have contributed to the development of advanced RAG systems where retrieved event-plot subgraphs are serialized using narrative templates (FABULA), published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WANG ET AL., 2023B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al., 2023B are researchers who developed the Self-Consistency with Chain-of-Thought (COT-SC) method in 2023. They have also contributed to the development of systems that support both the creation and traversal of text-relationship graphs for multi-hop question answering. Their work on the COT-SC algorithm, which was published in 2023, highlights their significant contributions to the field.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LANGCHAIN">
      <data key="d0">SOFTWARE, LIBRARY</data>
      <data key="d1">LangChain is an open-source framework for building applications with language models, developed by LangChainAI and available on GitHub since 2022. It includes features like LangChain Graphs and supports various graph databases for Retrieval-Augmented Generation (RAG) applications. LangChain serves as an agent framework that can be used as a building block in Advanced Driver Assistance Systems (ADAS) to support multi-modal capabilities and flexible use of different foundational models (FMs). Additionally, it can be utilized within the code search space of ADAS to enhance existing building blocks like RAG and search engine tools.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6109537356a2ce2339f77c827aa3668e,6bdf681c0bd9e401ac72344a6a0ae479,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE, LIBRARY</data>
    </node>
    <node id="LLAMAINDEX">
      <data key="d0">SOFTWARE, LIBRARY</data>
      <data key="d1">LlamaIndex is a framework for building knowledge graph indexes for language models. It is an open-source software library that supports various graph databases for Retrieval-Augmented Generation (RAG) applications. Developed in 2024, LlamaIndex provides essential tools for enhancing the capabilities of language models by structuring and indexing knowledge graphs, thereby facilitating more efficient and accurate information retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE, LIBRARY</data>
    </node>
    <node id="NEO4J">
      <data key="d0">SOFTWARE, DATABASE</data>
      <data key="d1">Neo4J is a graph database management system that excels in creating and reasoning over knowledge graphs. It is a key component in the NaLLM system and is supported by LangChain and LlamaIndex for use in Retrieval-Augmented Generation (RAG) applications. Additionally, Neo4J is recognized as the technology framework behind the development of Project NaLLM.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE, DATABASE</data>
    </node>
    <node id="NEBULAGRAPH">
      <data key="d0">SOFTWARE, DATABASE</data>
      <data key="d1">NebulaGraph is a graph database management system that can create and reason over knowledge graphs. It is supported by LangChain and LlamaIndex for use in Retrieval-augmented Generation (RAG) applications. NebulaGraph is integral to the GraphRAG system and has pioneered the industry-first graph RAG, which leverages large language models (LLMs) based on knowledge graphs.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE, DATABASE</data>
    </node>
    <node id="NALLM">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">NaLLM is a system that can create and reason over knowledge graphs in Neo4J format. Developed in 2024, NaLLM leverages advanced algorithmic techniques to facilitate the construction and analysis of intricate knowledge graphs, enabling users to map out and understand complex relationships and hierarchies within their data.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="GRAPHRAG">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">GraphRAG is a system that can create and reason over knowledge graphs in NebulaGraph format. Developed in 2024, GraphRAG leverages advanced algorithmic techniques to facilitate the construction and analysis of complex knowledge graphs, ensuring efficient data management and insightful reasoning capabilities within the NebulaGraph ecosystem.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="RAM ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ram et al. are researchers who have contributed to the understanding of RAG approaches and systems, published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SU ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Su et al. are researchers who have contributed to the development of CAiRE-COVID for multi-document summarization, published in 2020.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SENSEMAKING ACTIVITY">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Sensemaking activity refers to the iterative process of understanding and making sense of complex information, often facilitated by methods like Graph RAG.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="SCALABILITY">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Scalability refers to the ability of a system or method to handle increasing amounts of work or data efficiently, as demonstrated by Graph RAG's use of fewer context tokens.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="ITERATIVE QUESTION ANSWERING">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Iterative question answering is a process where questions are answered through multiple cycles of retrieval and generation, as facilitated by Graph RAG.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="MODULAR RAG">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Modular RAG is an advanced RAG system that includes patterns for iterative and dynamic cycles of interleaved retrieval and generation.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="SELF-MEMORY (SELFMEM)">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Self-memory (Selfmem) is a concept for generation-augmented retrieval that facilitates future generation cycles, contributed by Cheng et al. in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="GENERATION-AUGMENTED RETRIEVAL (GAR)">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Generation-augmented retrieval (GAR) is a concept that facilitates future generation cycles, contributed by Mao et al. in 2020.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Iterative retrieval-generation (Iter-RetGen) is a concept for iterative cycles of retrieval and generation, contributed by Shao et al. in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="FEDERATED RETRIEVAL-GENERATION (FEB4RAG)">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Federated retrieval-generation (FeB4RAG) is a concept for federated cycles of retrieval and generation, contributed by Wang et al. in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="MULTI-DOCUMENT SUMMARIZATION">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Multi-document summarization is the process of creating summaries from multiple documents, as facilitated by systems like CAiRE-COVID.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Multi-hop question answering is a process where questions are answered by traversing multiple pieces of information, as facilitated by systems like ITRG, IR-CoT, and DSP.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="HIERARCHICAL INDEX">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Hierarchical index is a method of organizing text chunks by clustering the vectors of text embeddings, as seen in RAPTOR.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="TREE OF CLARIFICATIONS">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">The "TREE OF CLARIFICATIONS" is a method for answering ambiguous questions with retrieval-augmented large language models. This innovative approach, described in a paper by Kim et al. (2023), addresses the challenge of multiple interpretations of ambiguous questions. By leveraging advanced retrieval techniques, the Tree of Clarifications systematically dissects and clarifies various possible meanings, ensuring comprehensive and accurate responses. This method represents a significant contribution to the field of natural language processing and artificial intelligence, highlighting the ongoing advancements in handling complex linguistic ambiguities.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="CAUSAL GRAPHS">
      <data key="d0">CONCEPT, DATA STRUCTURE</data>
      <data key="d1">CCausal graphs are data structures that represent causal relationships, extracted from source texts by researchers like Ban et al. and Zhang et al.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, DATA STRUCTURE</data>
    </node>
    <node id="G-RETRIEVER">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">G-RETRIEVER is a system developed by He et al. in 2024, designed to facilitate retrieval-augmented generation for textual graph understanding and question answering. It focuses on subsets of the graph structure as the primary objects of enquiry, enabling a more nuanced analysis and interaction with complex graph data.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="GRAPH-TOOLFORMER">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">"GRAPH-TOOLFORMER" is a research paper and system developed by Zhang in 2023, aimed at empowering large language models with graph reasoning abilities. This is achieved through the use of prompts augmented by ChatGPT. The system focuses on derived graph metrics as the primary objects of enquiry, providing a novel approach to integrating graph reasoning within language models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="SURGE">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">SURGE is a system where narrative outputs are grounded in the facts of retrieved subgraphs, developed by Kang et al. in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="FABULA">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">FABULA is a technique for intelligence report generation that employs retrieval-augmented narrative construction. Developed by Ranade and Joshi in 2023, FABULA is a system where retrieved event-plot subgraphs are serialized using narrative templates. This innovative approach enhances the generation of coherent and informative intelligence reports by structuring the retrieved data into well-defined narrative formats.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="TEXT-RELATIONSHIP GRAPHS">
      <data key="d0">CONCEPT, DATA STRUCTURE</data>
      <data key="d1">Text-relationship graphs are data structures that support both creation and traversal for multi-hop question answering, as seen in systems developed by Wang et al. in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, DATA STRUCTURE</data>
    </node>
    <node id="NEO4J FORMAT">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Neo4J format is a data format used for creating and reasoning over knowledge graphs in systems like NaLLM.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">DATA FORMAT</data>
    </node>
    <node id="NEBULAGRAPH FORMAT">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">NebulaGraph format is a data format used for creating and reasoning over knowledge graphs in systems like GraphRAG.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">DATA FORMAT</data>
    </node>
    <node id="ITERATIVE CYCLES">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Iterative cycles refer to repeated processes of retrieval and generation, as seen in methods like Iter-RetGen and FeB4RAG.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="NARRATIVE TEMPLATES">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Narrative templates are predefined structures used to serialize event-plot subgraphs, as seen in the FABULA system.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="PARTITION DATA">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Partition data refers to the division of data into segments for more efficient processing, as seen in Graph RAG's use of graph modularity.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="MODULARITY">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">MODULARITY is a property of the LATS algorithm that allows its components, such as the base LM agent, reflection generator, and value function, to be independently altered and adapted. This characteristic of modularity also refers to the natural division of graphs into modules or segments, which is utilized in Graph RAG for efficient data partitioning and summarization. The ability to independently alter and adapt components like the base LM agent, reflection generator, and value function in LATS exemplifies the flexibility and efficiency provided by modularity.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,edab4014b8f55e5b25bd7f396314be1f,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="EXTERNAL DATA SOURCES">
      <data key="d0">CONCEPT, RESOURCE</data>
      <data key="d1">External data sources are sources of information outside the LLM's initial dataset, used in RAG methods for retrieval and context addition.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, RESOURCE</data>
    </node>
    <node id="VECTOR SPACE">
      <data key="d0">CONCEPT, DATA STRUCTURE</data>
      <data key="d1">Vector space is a mathematical space where text chunks and queries are embedded for retrieval in RAG methods.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, DATA STRUCTURE</data>
    </node>
    <node id="TEXT EMBEDDINGS">
      <data key="d0">CONCEPT, DATA STRUCTURE</data>
      <data key="d1">Text embeddings are vector representations of text chunks used in RAG methods for retrieval and context addition.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, DATA STRUCTURE</data>
    </node>
    <node id="SEMANTICS">
      <data key="d0">CONCEPT, FIELD</data>
      <data key="d1">Semantics refers to the meaning of text, with similar positions in a vector space representing similar semantics in RAG methods.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, FIELD</data>
    </node>
    <node id="QUERY">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">QUERY refers to a term or phrase entered by the user to search for specific products in the web shop. Additionally, in the context of Retrieval-Augmented Generation (RAG) methods, a query is the original question or request for information that is augmented with retrieved data. This dual role highlights the importance of queries in both user-driven search functionalities and advanced data retrieval techniques.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="PRE-RETRIEVAL STRATEGIES">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Pre-retrieval strategies are methods used before the retrieval process to enhance the efficiency and effectiveness of RAG systems.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="POST-RETRIEVAL STRATEGIES">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Post-retrieval strategies are methods used after the retrieval process to enhance the efficiency and effectiveness of RAG systems.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="INTERLEAVED RETRIEVAL AND GENERATION">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Interleaved retrieval and generation refers to the dynamic cycles of retrieval and generation in Modular RAG systems.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="PODCAST INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Podcast intermediate-level summaries are summaries generated from podcast data, used in Graph RAG for efficient summarization and question answering.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="NEWS LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">News low-level community summaries are summaries generated from news data at a low level, used in Graph RAG for efficient summarization and question answering.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TABLE 3">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Table 3 illustrates the scalability advantages of Graph RAG compared to source text summarization, highlighting the reduction in context tokens required for different types of summaries. Additionally, Table 3 presents the performance of Orca-3 and other baseline models on various benchmarks, demonstrating relative improvements over Mistral-7b-Instruct. This comprehensive table provides valuable insights into both the efficiency of Graph RAG in summarization tasks and the superior performance of Orca-3 in benchmark evaluations.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="AD-HOC LLM USE">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Ad-hoc LLM use refers to the spontaneous or on-the-fly use of large language models to analyze reasoning and provide specific examples, quotes, and citations.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TUNING ELEMENT EXTRACTION PROMPTS">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Tuning element extraction prompts refers to the process of adjusting prompts to retain more details in the Graph RAG index, enhancing the quality of summaries and answers.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SELF CHECK GPT">
      <data key="d0">TOOL, METHOD</data>
      <data key="d1">SelfCheckGPT is an approach used to compare fabrication rates in analysis, developed by Manakul et al. in 2023.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SENSEMAKING QUESTIONS">
      <data key="d0">CONCEPT, EVALUATION METRIC</data>
      <data key="d1">Sensemaking questions are a class of questions used to evaluate the performance of Graph RAG and other methods in understanding and summarizing large text corpora.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="EMBEDDING-BASED MATCHING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Embedding-based matching is a technique that matches user queries with graph annotations, proposed as a refinement for Graph RAG approaches.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Alonso Guevara Fern&#225;ndez is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="AMBER HOAK">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Amber Hoak is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Andr&#233;s Morales Esquivel is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BEN CUTLER">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Ben Cutler is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BILLIE RINALDI">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Billie Rinaldi is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRIS SANCHEZ">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Chris Sanchez is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRIS TREVINO">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Chris Trevino is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRISTINE CAGGIANO">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Christine Caggiano is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DAVID TITTSWORTH">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">David Tittsworth is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DAYENNE DE SOUZA">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Dayenne de Souza is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DOUGLAS ORBAKER">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Douglas Orbaker is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ED CLARK">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Ed Clark is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GABRIEL NIEVES-PONCE">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Gabriel Nieves-Ponce is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GAUDY BLANCO MENESES">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Gaudy Blanco Meneses is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATE LYTVYNETS">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Kate Lytvynets is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATY SMITH">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Katy Smith is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="M&#211;NICA CARVAJAL">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">M&#243;nica Carvajal is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="NATHAN EVANS">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Nathan Evans is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RICHARD ORTEGA">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Richard Ortega is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RODRIGO RACANICCI">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Rodrigo Racanicci is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SARAH SMITH">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Sarah Smith is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SHANE SOLOMON">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Shane Solomon is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GRAPH-BASED RAG APPLICATIONS">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">Graph-based RAG applications are systems that create and reason over knowledge graphs, including formats like Neo4J and NebulaGraph.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KNOWLEDGE GRAPHS">
      <data key="d0">CONCEPT, DATA STRUCTURE</data>
      <data key="d1">Knowledge graphs are structured representations of knowledge that can be created and reasoned over in systems like Neo4J and NebulaGraph.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DATA PARTITIONING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Data partitioning is a technique used to divide data into smaller, more manageable parts, utilized in Graph RAG for global summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CORPORA">
      <data key="d0">DATASET, COLLECTION</data>
      <data key="d1">Corpora are large collections of text used for evaluation in methods like Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="FABRICATION RATES">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Fabrication rates are metrics used to measure the accuracy and reliability of generated content, compared using tools like SelfCheckGPT.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="COMPUTE BUDGET">
      <data key="d0">RESOURCE, CONSTRAINT</data>
      <data key="d1">Compute budget refers to the computational resources allocated for a task, influencing decisions like building a graph index.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="LIFETIME QUERIES">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Lifetime queries refer to the total number of queries expected to be made over the lifetime of a dataset, affecting the decision to build a graph index.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RICH TEXT ANNOTATIONS">
      <data key="d0">DATA STRUCTURE, CONCEPT</data>
      <data key="d1">Rich text annotations are detailed notes and comments added to text data, supporting methods like Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Query-focused summarization (QFS) is a technique that generates summaries based on specific user queries, used in Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Retrieval-augmented generation (RAG) is a technique that combines retrieval of relevant information with generation of new content, used in Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="TOKEN COST">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Token cost refers to the computational cost measured in tokens, used to evaluate the efficiency of methods like Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="OPEN-SOURCE IMPLEMENTATION">
      <data key="d0">SOFTWARE, TOOL</data>
      <data key="d1">An open-source implementation is a publicly available version of software, such as the forthcoming Python-based implementation of Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="PYTHON">
      <data key="d0">TECHNOLOGY, PROGRAMMING LANGUAGE</data>
      <data key="d1">Python is a Turing Complete programming language utilized in the implementation of Advanced Driver Assistance Systems (ADAS) algorithms. Additionally, Python is employed to implement both global and local Graph Region Adjacency Graph (RAG) approaches. This highlights Python's versatility and capability in handling complex algorithmic structures and diverse computational tasks.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. ACHIAM">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. Achiam is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="S. ADLER">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">S. Adler is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="S. AGARWAL">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">S. Agarwal is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="L. AHMAD">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">L. Ahmad is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="I. AKKAYA">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">I. Akkaya is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="F. L. ALEMAN">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">F. L. Aleman is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="D. ALMEIDA">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">D. Almeida is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. ALTENSCHMIDT">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. Altenschmidt is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="S. ALTMAN">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">S. Altman is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="S. ANADKAT">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">S. Anadkat is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. B. ALAYRAC">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. B. Alayrac is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON, AUTHOR</data>
    </node>
    <node id="R. ANIL">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">R. Anil is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="S. BORGEAUD">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">S. Borgeaud is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="Y. WU">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">Y. Wu is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="R. SORICUT">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">R. Soricut is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. SCHALKWYK">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. Schalkwyk is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="A. M. DAI">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">A. M. Dai is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="A. HAUTH">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">A. Hauth is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. BAEK">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. Baek is one of the authors referenced in the document, contributing to the knowledge-augmented language model prompting report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="A. F. AJI">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">A. F. Aji is one of the authors referenced in the document, contributing to the knowledge-augmented language model prompting report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="A. SAFFARI">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">A. Saffari is one of the authors referenced in the document, contributing to the knowledge-augmented language model prompting report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="T. BAN">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">T. Ban is one of the authors referenced in the document, contributing to the report on harnessing large language models for causal discovery.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="L. CHEN">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">L. Chen is one of the authors referenced in the document, contributing to the report on harnessing large language models for causal discovery.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="X. WANG">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">X. Wang is one of the authors referenced in the document, contributing to the report on harnessing large language models for causal discovery.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="H. CHEN">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">H. Chen is one of the authors referenced in the document, contributing to the report on harnessing large language models for causal discovery.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="T. BAUMEL">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">T. Baumel is one of the authors referenced in the document, contributing to the report on query-focused abstractive summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="M. EYAL">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">M. Eyal is one of the authors referenced in the document, contributing to the report on query-focused abstractive summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="M. ELHADAD">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">M. Elhadad is one of the authors referenced in the document, contributing to the report on query-focused abstractive summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="V. D. BLONDEL">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">V. D. Blondel is one of the authors referenced in the document, contributing to the report on fast unfolding of communities in large networks.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. L. GUILLAUME">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. L. Guillaume is one of the authors referenced in the document, contributing to the report on fast unfolding of communities in large networks.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="R. LAMBIOTTE">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">R. Lambiotte is one of the authors referenced in the document, contributing to the report on fast unfolding of communities in large networks.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="E. LEFEBVRE">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">E. Lefebvre is one of the authors referenced in the document, contributing to the report on fast unfolding of communities in large networks.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GPT-4">
      <data key="d0" />
      <data key="d1">GPT-4 is an advanced language model developed by OpenAI in 2024, widely utilized across various benchmarks and evaluation tasks. It serves as a benchmark for scoring the performance of other models on the Orca-Bench dataset, achieving a score of 10 and acting as the teacher in multi-turn interactions. Additionally, GPT-4 is employed for extracting the selected options in multiple-choice questions and is integral to benchmarks like FOFO, MT-Bench, AlpacaEval, and InfoBench.

In the context of Meta Agent Search, GPT-4 is used by the meta agent to discover high-performance agents and evaluate their performance on the ARC benchmark. It has shown significant improvements in accuracy rates on ARC tasks when evaluating the transferability of agents discovered from GPT-3.5. Furthermore, GPT-4 is involved in experiments with HumanEval, achieving a state-of-the-art Pass@1 rate of 92.7% when used with LATS, and setting new standards in programming evaluations.

GPT-4 also plays a crucial role in generating high-quality data for teaching AI models various skills in conjunction with AgentInstruct. It is evaluated on the MIRAGE datasets, demonstrating high performance in RAG tasks, and is used as an evaluator for summarization abilities and other tasks. Moreover, GPT-4 is discussed in technical reports for achieving 50% SOTA on ARC-AGI and is used in reading comprehension and multi-turn conversation evaluations.

Overall, GPT-4 stands out as a powerful and versatile language model, essential for a wide range of AI evaluation and benchmarking activities.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,0cf2e43f324fa4175b9b00b90e5e90ba,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,5819b66e04fd77fa705574edc49395bb,6109537356a2ce2339f77c827aa3668e,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,93cb0d0456e0822b5fe30a3e627405f8,ab04427ae0415a1c812a35cf8d3ee1a2,ac21ebe9a9d70d691c717f961d3f10c8,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="HARNESSING LARGE LANGUAGE MODELS FOR CAUSAL DISCOVERY">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SEQ2SEQ MODELS">
      <data key="d0">TECHNOLOGY, MACHINE LEARNING</data>
      <data key="d1">Seq2seq models are a type of machine learning model used for sequence-to-sequence tasks, such as translation and summarization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ARXIV">
      <data key="d0">PLATFORM, REPOSITORY</data>
      <data key="d1">ARXIV is an open-access repository where researchers can share and publish preprints of their scientific papers. Notable preprints published on arXiv include "Mastering diverse domains through world models" (2023), "A survey on the memory mechanism of large language model based agents," "Take a step back: Evoking reasoning via abstraction in large language models," "Self-discover: Large language models self-compose reasoning structures," and "Symbolic learning enables self-evolving agents." This platform serves as a crucial resource for the dissemination of early-stage research across various scientific domains.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,aa79049289e6532592eec17b9e76adfb,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="BLONDEL, V. D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Blondel, V. D. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GUILLAUME, J.-L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guillaume, J.-L. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LAMBIOTTE, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lambiotte, R. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LEFEBVRE, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lefebvre, E. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FAST UNFOLDING OF COMMUNITIES">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method for detecting communities in large networks, described in a paper by Blondel et al. (2008).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the paper on fast unfolding of communities in large networks was published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BROWN, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brown, T. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MANN, B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mann, B. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RYDER, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ryder, N. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUBBIAH, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Subbiah, M. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KAPLAN, J. D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kaplan, J. D. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DHARIWAL, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dhariwal, P. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NEELAKANTAN, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Neelakantan, A. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SHYAM, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shyam, P. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SASTRY, G.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sastry, G. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ASKELL, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Askell, A. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">"LANGUAGE MODELS ARE FEW-SHOT LEARNERS" is a research paper authored by Amodei and presented at NeurIPS in 2020. Published in Advances in Neural Information Processing Systems, the paper delves into the capabilities of language models in few-shot learning, highlighting their potential and effectiveness in this area.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d0">CONFERENCE, PUBLICATION</data>
      <data key="d1">"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS" is a prominent academic conference and publication venue. It is renowned for hosting significant contributions to the field of neural information processing. Notably, it was the platform where the influential paper on language models being few-shot learners was published. Additionally, in 2024, it featured the presentation of the paper titled "Thought Cloning: Learning to think while acting by imitating human thinking," further cementing its status as a leading forum for cutting-edge research in artificial intelligence and machine learning.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHENG, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cheng, X. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LUO, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luo, D. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHEN, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen, X. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIU, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu, L. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZHAO, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhao, D. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YAN, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yan, R. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper published in Advances in Neural Information Processing Systems, discussing retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DANG, H. T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dang, H. T. is the author of the paper on the evaluation of question-focused summarization systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DUC 2005">
      <data key="d0">CONFERENCE, WORKSHOP</data>
      <data key="d1">A conference where the evaluation of question-focused summarization systems was discussed.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="EVALUATION OF QUESTION-FOCUSED SUMMARIZATION SYSTEMS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper presented at the DUC 2005 conference, evaluating question-focused summarization systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ES, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Es, S. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JAMES, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">James, J. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ESPINOSA-ANKE, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Espinosa-Anke, L. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SCHOCKAERT, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Schockaert, S. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FENG, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Feng, Z. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FENG, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Feng, X. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YANG, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang, M. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="QIN, B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qin, B. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing the synergy between retrieval and generation in large language models, published in 2023.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FORTUNATO, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fortunato, S. is the author of the paper on community detection in graphs.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COMMUNITY DETECTION IN GRAPHS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper by Fortunato (2010) discussing methods for detecting communities in graphs.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PHYSICS REPORTS">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the paper on community detection in graphs was published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GAO, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gao, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="XIONG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiong, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GAO, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gao, X. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIA, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jia, K. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PAN, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pan, J. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BI, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bi, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DAI, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dai, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUN, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sun, J. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WANG, H.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang, H. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A survey paper discussing retrieval-augmented generation for large language models, published in 2023.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GOODWIN, T. R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Goodwin, T. R. is one of the authors of the paper comparing transformers on few-shot and zero-shot multi-document abstractive summarization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SAVERY, M. E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Savery, M. E. is one of the authors of the paper comparing transformers on few-shot and zero-shot multi-document abstractive summarization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEMNER-FUSHMAN, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Demner-Fushman, D. is one of the authors of the paper comparing transformers on few-shot and zero-shot multi-document abstractive summarization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FLIGHT OF THE PEGASUS?">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper comparing transformers on few-shot and zero-shot multi-document abstractive summarization, presented at COLING 2020.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COLING">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The International Conference on Computational Linguistics, where the paper on comparing transformers was presented.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HE, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">He, X. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TIAN, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tian, Y. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUN, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sun, Y. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHAWLA, N. V.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chawla, N. V. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LAURENT, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Laurent, T. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LECUN, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">LeCun, Y. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BRESSON, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bresson, X. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HOOI, B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hooi, B. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JACOMY, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacomy, M. is one of the authors of the paper on ForceAtlas2, a continuous graph layout algorithm.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="VENTURINI, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Venturini, T. is one of the authors of the paper on ForceAtlas2, a continuous graph layout algorithm.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HEYMANN, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heymann, S. is one of the authors of the paper on ForceAtlas2, a continuous graph layout algorithm.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BASTIAN, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bastian, M. is one of the authors of the paper on ForceAtlas2, a continuous graph layout algorithm.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FORCEATLAS2">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">ForceAtlas2 is a continuous graph layout algorithm designed for handy network visualization, described in a paper by Jacomy et al. (2014).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PLOS ONE">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the paper on ForceAtlas2 was published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIN, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jin, D. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YU, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yu, Z. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIAO, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiao, P. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PAN, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pan, S. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HE, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">He, D. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WU, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wu, J. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PHILIP, S. Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Philip, S. Y. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZHANG, W.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang, W. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="A SURVEY OF COMMUNITY DETECTION APPROACHES">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A survey paper discussing various approaches to community detection, published in IEEE Transactions on Knowledge and Data Engineering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the survey on community detection approaches was published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KANG, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kang, M. is one of the authors of the paper on knowledge graph-augmented language models for knowledge-grounded dialogue generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KWAK, J. M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kwak, J. M. is one of the authors of the paper on knowledge graph-augmented language models for knowledge-grounded dialogue generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BAEK, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Baek, J. is one of the authors of the paper on knowledge graph-augmented language models for knowledge-grounded dialogue generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HWANG, S. J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hwang, S. J. is one of the authors of the paper on knowledge graph-augmented language models for knowledge-grounded dialogue generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KNOWLEDGE GRAPH-AUGMENTED LANGUAGE MODELS">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method for knowledge-grounded dialogue generation</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KHATTAB, O.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khattab, O. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SANTHANAM, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Santhanam, K. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LI, X. L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Li, X. L. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HALL, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hall, D. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIANG, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liang, P. is an author and researcher who has made significant contributions to the field of natural language processing (NLP). Liang, P. is notably one of the authors of a study that explores how language models utilize long contexts, providing valuable insights into the mechanisms and efficiencies of these models. Additionally, Liang, P. co-authored a paper on the demonstrate-search-predict framework, which integrates retrieval and language models to enhance knowledge-intensive NLP tasks. This work underscores Liang, P.'s expertise in combining different algorithmic approaches to improve the performance and capabilities of language models in handling complex, information-rich tasks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="POTTS, C.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Potts, C. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZAHARIA, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zaharia, M. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEMONSTRATE-SEARCH-PREDICT">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method for composing retrieval and language models for knowledge-intensive NLP, described in a paper by Khattab et al. (2022).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KIM, G.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kim, G. is one of the authors of the paper on tree of clarifications: answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KIM, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kim, S. is one of the authors of the paper on tree of clarifications: answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JEON, B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeon, B. is one of the authors of the paper on tree of clarifications: answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PARK, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Park, J. is one of the authors of the paper on tree of clarifications: answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KANG, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kang, J. is one of the authors of the paper on tree of clarifications: answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KLEIN, G.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Klein, G. is one of the authors of the papers on making sense of sensemaking.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MOON, B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Moon, B. is one of the authors of the papers on making sense of sensemaking.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HOFFMAN, R. R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hoffman, R. R. is one of the authors of the papers on making sense of sensemaking.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MAKING SENSE OF SENSEMAKING 1">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing alternative perspectives on sensemaking, authored by Klein, Moon, and Hoffman (2006).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MAKING SENSE OF SENSEMAKING 2">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing a macrocognitive model of sensemaking, authored by Klein, Moon, and Hoffman (2006).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IEEE INTELLIGENT SYSTEMS">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the papers on making sense of sensemaking were published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KOESTEN, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Koesten, L. is an author and researcher who contributed to the study on understanding data sensemaking behaviors. Koesten, L. is one of the authors of the paper on understanding data sensemaking behaviours.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GREGORY, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gregory, K. is an author and researcher who contributed to the study on understanding data sensemaking behaviors. He is one of the authors of the paper on understanding data sensemaking behaviours.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GROTH, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Groth, P. is an author and researcher who contributed to the study on understanding data sensemaking behaviors. He is one of the authors of the paper focused on understanding data sensemaking behaviours.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SIMPERL, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Simperl, E. is an author and researcher who contributed to the study on understanding data sensemaking behaviors. Simperl, E. is one of the authors of the paper on understanding data sensemaking behaviours.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="TALKING DATASETS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">"TALKING DATASETS" refers to a paper discussing data sensemaking behaviours, authored by Koesten et al. (2021). This study, titled "Talking datasets&#8211;understanding data sensemaking behaviours," was published in the International Journal of Human-Computer Studies in 2021. The paper delves into the intricacies of how individuals and groups interpret and make sense of data, contributing valuable insights to the field of human-computer interaction and data analysis.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the paper on understanding data sensemaking behaviours was published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KURATOV, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kuratov, Y. is an author and researcher who has made significant contributions to the field of artificial intelligence, particularly in the study of recurrent memory in large language models. Additionally, Kuratov, Y. is recognized for co-authoring a paper on knowledge-grounded dialogue generation, showcasing expertise in enhancing the capabilities of conversational AI systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BULATOV, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bulatov, A. is an author and researcher who has made significant contributions to the field of artificial intelligence, particularly in the study of recurrent memory in large language models. Additionally, Bulatov, A. is recognized for co-authoring a paper on knowledge-grounded dialogue generation, showcasing expertise in enhancing the capabilities of conversational AI systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ANOKHIN, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anokhin, P. is an esteemed author and researcher who has made significant contributions to the field of artificial intelligence, particularly in the study of recurrent memory in large language models. Additionally, Anokhin, P. is recognized for co-authoring a pivotal paper on knowledge-grounded dialogue generation, further showcasing their expertise and influence in advancing the understanding and development of sophisticated AI systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SOROKIN, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sorokin, D. is an author and researcher who has made significant contributions to the field of artificial intelligence, particularly in the study of recurrent memory in large language models. Additionally, Sorokin, D. is one of the authors of a paper focused on knowledge-grounded dialogue generation, showcasing their expertise in enhancing the capabilities of language models to generate contextually relevant and informed dialogues.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SOROKIN, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sorokin, A. is an author and researcher who has made significant contributions to the field of artificial intelligence, particularly in the study of recurrent memory in large language models. Additionally, Sorokin, A. is one of the authors of a paper focused on knowledge-grounded dialogue generation, showcasing their expertise in enhancing the capabilities of language models to generate contextually relevant and informed dialogues.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BURTSEV, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Burtsev, M. is an author and researcher who has made significant contributions to the field of artificial intelligence, particularly in the study of recurrent memory in large language models. Additionally, Burtsev, M. is recognized for co-authoring a paper on knowledge-grounded dialogue generation, showcasing expertise in enhancing the capabilities of conversational AI systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KNOWLEDGE-GROUNDED DIALOGUE GENERATION">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method for dialogue generation that is grounded in knowledge, described in a paper by Kuratov et al. (2022).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IN SEARCH OF NEEDLES IN A 11M HAYSTACK">
      <data key="d0">STUDY, PAPER</data>
      <data key="d1">A study titled "In search of needles in a 11m haystack: Recurrent memory finds what llms miss" published in 2024.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LANGCHAIN GRAPHS">
      <data key="d0">FEATURE, TECHNOLOGY</data>
      <data key="d1">A feature of LangChain that allows for the creation and use of graphs in language model applications.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LASKAR, M. T. R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Laskar, M. T. R. is an author and researcher who contributed to studies on query-focused abstractive summarization and domain adaptation with pre-trained transformers.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HOQUE, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hoque, E. is an author and researcher who contributed to studies on query-focused abstractive summarization and domain adaptation with pre-trained transformers.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HUANG, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Huang, J. is an author and researcher who contributed to studies on query-focused abstractive summarization and domain adaptation with pre-trained transformers.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="QUERY FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for summarizing text by focusing on the relevance of the query, incorporating transfer learning with transformer models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="DOMAIN ADAPTATION WITH PRE-TRAINED TRANSFORMERS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for adapting pre-trained transformer models to specific domains for query-focused abstractive text summarization.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LEWIS, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lewis, P. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PEREZ, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Perez, E. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PIKTUS, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Piktus, A. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PETRONI, F.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Petroni, F. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KARPUKHIN, V.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Karpukhin, V. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GOYAL, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Goyal, N. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="K&#220;TTLER, H.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">K&#252;ttler, H. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LEWIS, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lewis, M. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="YIH, W.-T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yih, W.-T. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ROCKT&#196;SCHEL, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rockt&#228;schel, T. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIU, N. F.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu, N. F. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIN, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lin, K. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HEWITT, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hewitt, J. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PARANJAPE, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Paranjape, A. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BEVILACQUA, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bevilacqua, M. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LOST IN THE MIDDLE">
      <data key="d0">STUDY, PAPER</data>
      <data key="d1">A study titled "Lost in the middle: How language models use long contexts" published in 2023.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIU, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu, Y. is an author and researcher who contributed to the study on hierarchical transformers for multi-document summarization.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LAPATA, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lapata, M. is an author and researcher who has made significant contributions to the field of text summarization. Notably, Lapata, M. has co-authored a study on hierarchical transformers for multi-document summarization, showcasing expertise in advanced machine learning techniques for processing and summarizing large volumes of text. Additionally, Lapata, M. is one of the authors of the paper titled "Text summarization with latent queries," further highlighting their involvement in developing innovative methods for extracting meaningful summaries from textual data.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HIERARCHICAL TRANSFORMERS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for multi-document summarization using hierarchical transformer models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LLAMAINDEX KNOWLEDGE GRAPH INDEX">
      <data key="d0">FEATURE, TECHNOLOGY</data>
      <data key="d1">A feature of LlamaIndex that allows for the creation and use of knowledge graph indexes in language model applications.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MANAKUL, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Manakul, P. is an author and researcher who contributed to the study on zero-resource black-box hallucination detection for generative large language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIUSIE, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liusie, A. is an author and researcher who contributed to the study on zero-resource black-box hallucination detection for generative large language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GALES, M. J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gales, M. J. is an author and researcher who contributed to the study on zero-resource black-box hallucination detection for generative large language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SELFCHECKGPT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for zero-resource black-box hallucination detection in generative large language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MAO, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mao, Y. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HE, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">He, P. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIU, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu, X. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SHEN, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shen, Y. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GAO, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gao, J. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HAN, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Han, J. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="CHEN, W.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen, W. is an author and researcher who has made significant contributions to the field of open-domain question answering. Notably, Chen, W. co-authored a study on generation-augmented retrieval, which aims to enhance the performance of retrieval-augmented large language models. This work is encapsulated in the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy," highlighting Chen, W.'s role in advancing the synergy between retrieval and generation processes in large language models.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GENERATION-AUGMENTED RETRIEVAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for enhancing open-domain question answering by combining generation and retrieval processes.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MARTIN, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Martin, S. is an author and researcher who contributed to the development of OpenOrd, an open-source toolbox for large graph layout.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BROWN, W. M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brown, W. M. is an author and researcher who contributed to the development of OpenOrd, an open-source toolbox for large graph layout.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KLAVANS, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Klavans, R. is an author and researcher who contributed to the development of OpenOrd, an open-source toolbox for large graph layout.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BOYACK, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Boyack, K. is an author and researcher who contributed to the development of OpenOrd, an open-source toolbox for large graph layout.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MICROSOFT">
      <data key="d0">COMPANY, ORGANIZATION</data>
      <data key="d1">Microsoft is a technology company that conducted a preliminary study on the impact of large language models on scientific discovery using GPT-4. Additionally, Microsoft provides Azure, a cloud computing service offering various tools and resources for AI and machine learning.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="THE IMPACT OF LARGE LANGUAGE MODELS ON SCIENTIFIC DISCOVERY">
      <data key="d0">STUDY, PAPER</data>
      <data key="d1">A preliminary study conducted by Microsoft on the impact of large language models on scientific discovery using GPT-4, published in 2023.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PROJECT NALLM">
      <data key="d0">PROJECT, INITIATIVE</data>
      <data key="d1">An initiative by Neo4J focused on developing advanced language model applications.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="NEWMAN, M. E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Newman, M. E. is an author and researcher who contributed to the study on modularity and community structure in networks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MODULARITY AND COMMUNITY STRUCTURE IN NETWORKS">
      <data key="d0">STUDY, PAPER</data>
      <data key="d1">A study titled "Modularity and community structure in networks" published in the Proceedings of the National Academy of Sciences in 2006.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="RAM, O.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ram, O. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LEVINE, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Levine, Y. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="DALMEDIGOS, I.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dalmedigos, I. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MUHLGAY, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Muhlgay, D. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SHASHUA, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shashua, A. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LEYTON-BROWN, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Leyton-Brown, K. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SHOHAM, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shoham, Y. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="IN-CONTEXT RETRIEVAL-AUGMENTED LANGUAGE MODELS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for enhancing language models by incorporating in-context retrieval-augmented processes.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="RANADE, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ranade, P. is an author and researcher who contributed to the study on intelligence report generation using retrieval-augmented narrative construction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="JOSHI, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joshi, A. is an author and researcher who contributed to the study on intelligence report generation using retrieval-augmented narrative construction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SARTHI, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sarthi, P. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ABDULLAH, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Abdullah, S. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="TULI, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tuli, A. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KHANNA, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khanna, S. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GOLDIE, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Goldie, A. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MANNING, C. D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Manning, C. D. is an author and researcher who has made significant contributions to the field of natural language processing and information retrieval. He is notably one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering," which focuses on creating a dataset to facilitate the development of systems capable of answering complex questions that require reasoning over multiple pieces of information. Additionally, Manning, C. D. has contributed to the study on recursive abstractive processing for tree-organized retrieval, further showcasing his expertise in advanced algorithmic structures and their applications in data retrieval and processing.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SU, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Su, D. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique. Su, D. is also one of the authors of the paper titled "CAIRE-COVID: A Question Answering and Query-Focused Multi-Document Summarization System for COVID-19 Scholarly Information Management."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="XU, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu, Y. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique. Xu, Y. is also one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management." Additionally, Xu, Y. co-authored the paper titled "Text summarization with latent queries."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="YU, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yu, T. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique. Yu, T. is also one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SIDDIQUE, F. B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Siddique, F. B. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique. Siddique, F. B. is also one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BAREZI, E. J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Barezi, E. J. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique. Barezi, E. J. is also one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="FUNG, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fung, P. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique. Fung, P. is also one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="DUAN, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Duan, N. is one of the authors of the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ENHANCING RETRIEVAL-AUGMENTED LARGE LANGUAGE MODELS WITH ITERATIVE RETRIEVAL-GENERATION SYNERGY">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on improving retrieval-augmented large language models through iterative retrieval-generation synergy, published in 2023.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tang, Y. is one of the authors of the paper titled "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang, Y. is one of the authors of the paper titled "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TOUVRON, H.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Touvron, H. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MARTIN, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Martin, L. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="STONE, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Stone, K. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ALBERT, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Albert, P. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ALMAHAIRI, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Almahairi, A. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BABAEI, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Babaei, Y. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BASHLYKOV, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bashlykov, N. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BATRA, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Batra, S. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BHARGAVA, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bhargava, P. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BHOSALE, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bhosale, S. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LLAMA 2">
      <data key="d0">MODEL, RESEARCH</data>
      <data key="d1">LLAMA 2 is a set of open foundation and fine-tuned chat models, published in 2023. These models are designed for various applications in language processing, offering robust capabilities for understanding and generating human language. LLAMA 2's versatility and advanced features make it a significant tool in the field of natural language processing, providing valuable resources for developers and researchers alike.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRAAG, V. A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Traag, V. A. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WALTMAN, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Waltman, L. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="VAN ECK, N. J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Van Eck, N. J. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="FROM LOUVAIN TO LEIDEN: GUARANTEEING WELL-CONNECTED COMMUNITIES">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on guaranteeing well-connected communities, published in Scientific Reports in 2019.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRAJANOSKA, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trajanoska, M. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="STOJANOV, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Stojanov, R. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRAJANOV, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trajanov, D. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ENHANCING KNOWLEDGE GRAPH CONSTRUCTION USING LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on improving knowledge graph construction using large language models, published in 2023.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRIVEDI, H.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trivedi, H. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BALASUBRAMANIAN, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Balasubramanian, N. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="KHOT, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khot, T. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SABHARWAL, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sabharwal, A. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="INTERLEAVING RETRIEVAL WITH CHAIN-OF-THOUGHT REASONING FOR KNOWLEDGE-INTENSIVE MULTI-STEP QUESTIONS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions, published in 2022.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LIANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liang, Y. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MENG, F.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Meng, F. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SUN, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sun, Z. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SHI, H.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shi, H. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LI, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Li, Z. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."Li, Z. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="XU, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="QU, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qu, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHOU, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhou, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper investigating whether ChatGPT is a good natural language generation evaluator, published in 2023.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang, S. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="KHRAMTSOVA, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khramtsova, E. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHUANG, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhuang, S. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."Zhuang, S. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZUCCON, G.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zuccon, G. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="FEB4RAG">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper evaluating federated search in the context of retrieval-augmented generation, published in 2024.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang, Y. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LIPKA, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lipka, N. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ROSSI, R. A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rossi, R. A. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SIU, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Siu, A. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang, R. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="DERR, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Derr, T. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="KNOWLEDGE GRAPH PROMPTING FOR MULTI-DOCUMENT QUESTION ANSWERING">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on using knowledge graph prompting for multi-document question answering, published in 2023.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TEXT SUMMARIZATION WITH LATENT QUERIES">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on text summarization using latent queries, published in 2021.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YANG, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang, Z. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="QI, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qi, P. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang, S. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BENGIO, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bengio, Y. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="COHEN, W. W.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cohen, W. W. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SALAKHUTDINOV, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Salakhutdinov, R. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YAO, J.-G.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao, J.-G. is one of the authors of the paper titled "Recent advances in document summarization."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WAN, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wan, X. is one of the authors of the paper titled "Recent advances in document summarization."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="XIAO, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiao, J. is one of the authors of the paper titled "Recent advances in document summarization."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="RECENT ADVANCES IN DOCUMENT SUMMARIZATION">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper discussing recent advances in document summarization, published in Knowledge and Information Systems in 2017.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YAO, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao, L. is one of the authors of the paper titled "Causal graph discovery with retrieval-augmented generation based large language models."Yao, L. is one of the authors of the paper titled "Exploring large language models for knowledge graph completion."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="PENG, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peng, J. is one of the authors of the paper titled "Exploring large language models for knowledge graph completion."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MAO, C.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mao, C. is one of the authors of the paper titled "Exploring large language models for knowledge graph completion."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LUO, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luo,</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang, J. is one of the authors of the paper titled "Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang, Y. is one of the authors of the paper titled "Causal graph discovery with retrieval-augmented generation based large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="GAN, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gan, Y. is one of the authors of the paper titled "Causal graph discovery with retrieval-augmented generation based large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, C.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang, C. is one of the authors of the paper titled "Causal graph discovery with retrieval-augmented generation based large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="CAUSAL GRAPH DISCOVERY WITH RETRIEVAL-AUGMENTED GENERATION BASED LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on discovering causal graphs using retrieval-augmented generation based large language models, published in 2024.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHENG, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zheng, L. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="CHIANG, W.-L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chiang, W.-L. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SHENG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sheng, Y. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WU, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wu, Z. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHUANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhuang, Y. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LIN, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lin, Z. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LI, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Li, D. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="XING, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xing, E. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="JUDGING LLM-AS-A-JUDGE WITH MT-BENCH AND CHATBOT ARENA">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on evaluating large language models as judges using MT-Bench and Chatbot Arena, published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d0">ALGORITHM, FRAMEWORK</data>
      <data key="d1">Language Agent Tree Search (LATS) is a general framework that synergizes the capabilities of language models (LMs) in reasoning, acting, and planning. It integrates Monte Carlo Tree Search, LM-powered value functions, and self-reflections to enable proficient exploration and enhanced decision-making. LATS unifies these aspects within language models, providing a comprehensive approach to algorithmic problem-solving. Detailed discussions on LATS, including pseudocode, limitations, experimental results, and environment details, are available in the appendix.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">ALGORITHM, FRAMEWORK</data>
    </node>
    <node id="LANGUAGE MODELS (LMS)">
      <data key="d0">TECHNOLOGY, ARTIFICIAL INTELLIGENCE</data>
      <data key="d1">Language models are AI systems capable of understanding and generating human language. They have shown potential across a range of decision-making tasks and are used in LATS for reasoning, acting, and planning.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">TECHNOLOGY, ARTIFICIAL INTELLIGENCE</data>
    </node>
    <node id="MONTE CARLO TREE SEARCH (MCTS)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Monte Carlo Tree Search (MCTS) is a heuristic search algorithm used in decision-making environments, where it builds a decision tree with nodes representing states and edges representing actions. It is particularly known for its success in planning and decision-making tasks within model-based reinforcement learning. MCTS has been integrated into LATS (Language Agent Training System) to enable language models to act as agents, thereby enhancing their decision-making capabilities through proficient exploration and improved performance.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="EXTERNAL FEEDBACK">
      <data key="d0">CONCEPT, MECHANISM</data>
      <data key="d1">External feedback is a concept integral to methods like LATS (Language and Task-Specific models) to enhance performance by leveraging feedback from the environment. It serves as a key feature in LATS, providing a more deliberate and adaptive problem-solving mechanism that surpasses the constraints of existing techniques. External feedback involves information from outside sources, which is used to improve decision-making and problem-solving capabilities of language models. This feedback is crucial for improving the performance and reliability of models like LATS in difficult reasoning tasks, enhancing the agent's responses and value assignment.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6,dd9a46950237e49ef9b1c7ef08e08d42,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">CONCEPT, MECHANISM</data>
    </node>
    <node id="PROGRAMMING">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Programming is a domain used to evaluate the LATS algorithm, involving reasoning and acting tasks. It encompasses writing code to create software applications, often assessed through benchmarks like HumanEval and MBPP. Programming is one of the diverse domains where LATS has been experimentally evaluated, achieving state-of-the-art pass@1 accuracy on HumanEval with GPT-4. Additionally, LATS is recommended for programming tasks, particularly when performance is prioritized over efficiency.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,fb2b4544aedd793e4d4ec3147320a51c</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="INTERACTIVE QUESTION-ANSWERING (QA)">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Interactive question-answering (QA) is a task where language models answer questions based on interaction with the environment. This domain has seen significant advancements with the introduction of LATS (Language and Task-Specific models), which enhances performance in this task. LATS has been validated for its effectiveness and generality in decision-making within interactive QA, demonstrating its capability to improve the accuracy and relevance of responses generated by language models.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="WEB NAVIGATION">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">WEB NAVIGATION is a domain used to evaluate the LATS algorithm, involving tasks such as finalizing a purchase. In this domain, language models interact with web environments to retrieve information. LATS demonstrates gradient-free performance comparable to gradient-based fine-tuning, as evaluated with GPT-3.5, and improves performance in web navigation tasks.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="MATH">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Math is a benchmark used to evaluate the mathematical problem-solving capabilities of language models. It is a domain tested by Meta Agent Search using the MGSM benchmark to assess these capabilities. In this domain, foundational models possess adequate knowledge to solve questions, with errors mainly arising from hallucinations or calculation mistakes. Language models solve mathematical problems in this domain, and LATS demonstrates versatility by enhancing performance here. Additionally, Math is a skill that can be taught to AI models using data generated by AgentInstruct. It is one of the diverse domains where LATS has been experimentally evaluated, validating its effectiveness in decision-making.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71,86f77e15d41cbd0cb33f635ccb2cb66b,93cb0d0456e0822b5fe30a3e627405f8,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="GPT-3.5">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">GPT-3.5, developed by OpenAI in 2022, is an advanced language model utilized across a wide range of tasks and experiments. It is prominently used in conjunction with the LATS algorithm for reasoning-based prompting results on tasks such as HotpotQA and WebShop, significantly improving performance. Additionally, GPT-3.5 is employed in the Meta Agent Search framework to evaluate discovered agents and baselines, particularly on the ARC benchmark, and to reduce compute costs. It serves as a foundational model for transferring discovered agents to GPT-4, demonstrating notable improvements in accuracy rates on ARC tasks.

GPT-3.5 is also involved in experiments with various algorithms, including ReAct, Reflexion, ToT, and RAP, and is used in environments like WebShop and reasoning tasks such as the Game of 24. Despite its advanced capabilities, simpler feedback mechanisms have been found to work better with more advanced models. In programming and decision-making tasks, GPT-3.5 is used to evaluate the performance of different algorithms, including those in HumanEval, which involves six internal tests for evaluation.

However, it is worth noting that GPT-3.5 was outperformed by Orca-3 on multiple benchmarks, indicating areas for potential improvement. Overall, GPT-3.5 remains a critical tool in the evaluation and enhancement of various AI models and algorithms.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,594449768ae2dea9b2efbe677075096b,7de66b94cf868b37b1df51dc545c415f,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b88745a13b69cecbc0ee9c3af41389bf,b8dd0300033963bb4a3e1bad37f8e7b9,bc26e68b0b2783ba912b9e5606d9eb0b,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="HUMANEVAL">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">HumanEval is a benchmark consisting of 164 questions used to evaluate the performance of algorithms, particularly in programming and reasoning tasks. It includes a dataset of handwritten programming problems designed to test the functional correctness of models for synthesizing programs from natural language descriptions. Algorithms like LATS are evaluated using this benchmark, and LATS achieves a 92.7 Pass@1 rate on HumanEval when used with GPT-4.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">BENCHMARK, DATASET</data>
    </node>
    <node id="WEB SHOP">
      <data key="d0">PLATFORM, APPLICATION</data>
      <data key="d1">WEB SHOP is an online platform where users can search for and purchase products. It serves as a benchmark for evaluating the performance of language models in web navigation tasks, particularly in the context of research by Shunyu Yao, Howard Chen, John Yang, and Karthik R. Narasimhan. The platform is designed to simulate an e-commerce shopping task with over 1.18 million real-world products and 12,000 human instructions, allowing agents to navigate the website through various commands to purchase items matching user specifications. Web Shop is also used to assess the performance of LATS (Language Agent Task Suite) in web navigation tasks with GPT-3.5, where LATS has been shown to raise the average score by 22.1 points. This interactive web-based environment is crucial for evaluating agents on grounded language understanding and decision-making in scalable real-world web interactions.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,594449768ae2dea9b2efbe677075096b,6f486e20e3102c7a285e357d356417ad,8180bf20b7577f3eee40df5991e2886d,93cb0d0456e0822b5fe30a3e627405f8,b8dd0300033963bb4a3e1bad37f8e7b9,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PLATFORM, APPLICATION</data>
    </node>
    <node id="ANDY ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andy Zhou is one of the authors of the paper introducing LATS, affiliated with the University of Illinois Urbana-Champaign and Lapis Labs.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN">
      <data key="d0">INSTITUTION, UNIVERSITY</data>
      <data key="d1">The University of Illinois Urbana-Champaign is one of the institutions affiliated with the authors of the paper introducing LATS.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="LAPIS LABS">
      <data key="d0">ORGANIZATION, RESEARCH LAB</data>
      <data key="d1">Lapis Labs is one of the organizations affiliated with the authors of the paper introducing LATS.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="REACT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">REACT is an algorithm developed by Yao et al. in 2023, designed for reasoning, acting, and planning in language models. It is a technique that synergizes reasoning and acting, extending language models to tasks requiring interactions with an external environment. ReAct constructs an action space that includes both permissible actions and reasoning traces, augmenting language models with feedback or observations from the environment. This method has been evaluated for performance, sample complexity, and token consumption, and has different variants, including a best-of-k variant. Although ReAct is a simpler prompting method compared to LATS and has been outperformed by LATS on benchmarks like HotPotQA and WebShop, it serves as a foundational technique for tasks requiring both internal reasoning and external retrieval. ReAct has been tested on various benchmarks, including HumanEval and HotPotQA, and is used as a base prompt in numerous experiments. The research on ReAct involves contributions from Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,8180bf20b7577f3eee40df5991e2886d,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,b8dd0300033963bb4a3e1bad37f8e7b9,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="YA0 ET AL., 2023B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al., 2023B, are researchers who developed and authored the ReAct algorithm, which was published in 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="CHOWDHERY ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chowdhery et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="OPENAI, 2023">
      <data key="d0">ORGANIZATION, RESEARCH LAB</data>
      <data key="d1">OpenAI, in 2023, is an organization that has published significant research on language models. Additionally, OpenAI is mentioned in the context of the practice followed for one-shot style questions in DROP (Reading Comprehension).</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">ORGANIZATION, RESEARCH LAB</data>
    </node>
    <node id="NALLAPATI ET AL., 2016">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nallapati et al. are the authors of a significant paper on summarization, published in 2016.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BOWMAN ET AL., 2015">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bowman et al. are the authors of a significant paper on language inference, published in 2015.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="COBBE ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cobbe et al. are researchers who have made significant contributions to the understanding of reasoning in language models. In 2021, they authored a pivotal paper that introduced the GSM8K dataset, a benchmark designed to evaluate the transferability of discovered agents from MGSM math tasks to held-out math tasks. Their work has been instrumental in advancing the study of language models and their application to mathematical reasoning tasks.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba,93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SAPAROV AND HE, 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saparov and He are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YAO ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al. are the authors of a significant paper on web navigation, published in 2022. Additionally, they have conducted studies in the same year that involve algorithms such as ReAct and IL+RL for performance evaluation.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="DENG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Deng et al. are the authors of a significant paper on web navigation, published in 2023.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SCHICK ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Schick et al., 2023, are researchers who significantly contributed to the development of external tools for language models and the advancement of tool use techniques in agentic systems. Their work, published in 2023, is a notable paper in the field, highlighting their contributions to the research on tool use in these systems.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,93cb0d0456e0822b5fe30a3e627405f8,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="FAN ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fan et al., 2022, are researchers who have made significant contributions to the study of complex multimodal games, particularly focusing on environments like Minecraft. They are the authors of a notable paper published in 2022, which explores the use of planning-based prompting methods in open-ended games. Their work has been influential in understanding the dynamics and interactions within such gaming environments.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHINN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shinn et al., 2023, are the authors of significant research that focuses on leveraging self-reflection to refine decision-making in language models. Their contributions include the development of the Reflexion algorithm and the Self-Refine method, both published in 2023. These innovations are integral to enhancing agentic systems by making generated agents novel and error-free. Additionally, the Self-Refine strategy is utilized in the Meta Agent Search algorithm, further showcasing their impact on the field. Their work is widely cited and recognized for advancing reflection techniques in language models and agentic systems.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,594449768ae2dea9b2efbe677075096b,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SLOMAN, 1996">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sloman is the author of a significant paper on decision-making, published in 1996.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="EVANS, 2010">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Evans is the author of a significant paper on decision-making, published in 2010.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="XIE ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xie et al., 2023, are researchers who made notable contributions to the development of the Beam Search algorithm. They are also the authors of a significant paper on search-guided language models, published in 2023. Their work has been influential in advancing the field of algorithmic search techniques and language model optimization.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YAO ET AL., 2023A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al., 2023A are researchers who developed the Tree-of-Thought (ToT) algorithm in 2023. They are also the authors of a significant paper on search-guided language models, published in the same year. Their work on the ToT method has contributed to advancements in the field of algorithmic analysis and language models.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HAO ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hao et al., 2023, are researchers who have made significant contributions to the development of planning and search algorithms. They are particularly noted for their work on the Reasoning via Planning (RAP) algorithm, which was published in 2023. The RAP algorithm utilizes Monte Carlo Tree Search (MCTS) and relies on internal dynamics models for simulation. Additionally, Hao et al. have authored a notable paper on search-guided language models, also published in 2023. Their work on the RAP technique emphasizes the use of internal representations of the language model, showcasing their expertise in the field.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WOOLDRIDGE AND JENNINGS, 1995">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wooldridge and Jennings are the authors of a significant paper on autonomous agents, published in 1995.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KAI YAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kai Yan is one of the authors of the paper introducing LATS, affiliated with the University of Illinois Urbana-Champaign.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="MICHAL SHLAPENTOKH-ROTHMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michal Shlapentokh-Rothman is one of the authors of the paper introducing LATS, affiliated with the University of Illinois Urbana-Champaign.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="HAOHAN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Haohan Wang is one of the authors of the paper introducing LATS, affiliated with the University of Illinois Urbana-Champaign.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="YU-XIONG WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yu-Xiong Wang is one of the authors of the paper introducing LATS, affiliated with the University of Illinois Urbana-Champaign.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="LATS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">LATS (Language Agent Tree Search) is an advanced algorithm designed to unify reasoning, acting, and planning within language models. It adapts Monte Carlo Tree Search (MCTS) specifically for language agents, enhancing their problem-solving capabilities across various domains. LATS leverages external feedback and self-reflection to optimize decision-making and performance, making it highly effective in complex tasks such as HumanEval, HotPotQA, and programming.

The framework of LATS incorporates several parameters, including exploration weight, depth, and value functions, to fine-tune its operations. It constructs trajectories using search algorithms and does not require a world model, which sets it apart from other methods. By integrating high-level linguistic reasoning and actions through multiple rounds of decision-making and reflection, LATS achieves superior performance and efficiency.

LATS also addresses the limitations of existing prompting techniques by enhancing flexibility, sensibility, and adaptability in language models. It combines internal reasoning with external retrieval strategies, expanding more nodes with principled search and incorporating external feedback to improve both score and success rate (SR) in decision-making environments like WebShop.

The algorithm's novel value function is based on a self-generated LM score and a self-consistency score, which improves value assignment by incorporating environmental feedback and self-reflection. LATS has been evaluated on benchmarks such as the Game of 24, HotPotQA, and HumanEval, and has set the state of the art for HumanEval when used with advanced models like GPT-4.

In summary, LATS is a comprehensive framework that enhances language model performance through sophisticated reasoning, acting, and planning mechanisms, validated by extensive experimental results and detailed in its accompanying appendix.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,4ae237a491bc8a84cc720e40c59a7464,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SELF-REFLECTION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">SELF-REFLECTION is a technique used in agentic systems, particularly within the LATS algorithm, to enable agents to reflect on their actions and improve their performance. This method involves the agent reviewing previous attempts and feedback to enhance task performance, especially by reflecting on unsuccessful terminal nodes to summarize errors and propose superior alternatives. The process includes the meta agent examining its proposed architecture and implementation to identify mistakes, assess interestingness, and suggest improvements, with the possibility of repeating this process up to five times if errors persist. Self-reflection incorporates external feedback and language model-generated feedback to improve decision-making, problem-solving capabilities, and reasoning tasks by providing additional semantic signals.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,282313a8340c6792e8c35f53ed157cd0,594449768ae2dea9b2efbe677075096b,785ad59c6a37896a4676ec5c1689735f,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,d66dc9ce4a9545b44f7486ea057b5937,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SELF-CONSISTENCY">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Self-consistency is a technique that employs majority voting over sampled chains to mitigate error propagation in reasoning tasks. It is used in LATS to enhance performance. Additionally, self-consistency improves chain of thought reasoning in language models, as mentioned in the context of research by Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (COT) PROMPTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Chain-of-thought (CoT) prompting is a technique that creates intermediate thoughts to bridge the gap between input and output, particularly useful for intricate tasks such as mathematical queries or challenging questions. This method decomposes complex inputs into sequential intermediate steps towards a final answer, making it highly effective in language models for reasoning tasks.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="TREE-OF-THOUGHT (TOT) PROMPTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">TREE-OF-THOUGHT (TOT) PROMPTING is a method that enhances reasoning tasks by utilizing depth-first or breadth-first search, guided by a language model (LM)-generated heuristic, to sample trajectories more effectively. It extends Chain-of-Thought (CoT) prompting by exploring multiple reasoning paths over thoughts, framing problems as a search over a tree. This approach allows for a more comprehensive exploration of potential solutions, leveraging the structured search capabilities to improve the effectiveness of reasoning processes.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="REASONING VIA PLANNING (RAP)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">RAP is a method that uses MCTS with rollouts simulated by language models for reasoning tasks. It relies solely on LM internal knowledge and does not adapt to external feedback.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="YAO ET AL., 2023B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al., 2023B are the authors of a study published in 2023 that proposed the Wikipedia web API and conducted experiments on algorithms such as LATS and ReAct. They are also specifically credited with the development and publication of the ReAct algorithm and method in the same year.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="YANG ET AL., 2018">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang et al. are the authors of the HotPotQA benchmark, published in 2018.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WEI ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wei et al., 2022, are researchers who have significantly contributed to the development of the Chain-of-Thought (CoT) algorithm and its variants, including the CoT prompting technique and the ReAct method. Their work, published in 2022, focuses on chain-of-thought planning and reasoning, providing a foundational approach to enhancing algorithmic processes in these areas.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,99d90aededb61e04241516ed9ec656cc,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="KOJIMA ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kojima et al. are researchers who have contributed to the development of chain-of-thought prompting variants, published in 2022.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WANG ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al., 2022, are researchers who have significantly contributed to the development of self-consistency and other techniques aimed at improving reasoning in language models. They are particularly noted for their work on the CoT-SC algorithm, which is a key focus of their 2022 publication.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="GUO ET AL., 2018">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guo et al. are researchers who have studied error propagation in reasoning tasks, published in 2018.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CHEN ET AL., 2023B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen et al., 2023b, are researchers who have made significant contributions to the field of algorithmic analysis. In 2023, they published a study focusing on error propagation in reasoning tasks, providing valuable insights into how errors can affect the outcomes of complex reasoning processes. Additionally, they are the authors of the AgentVerse algorithm, also published in 2023b, which further underscores their expertise and innovative approach in the domain of algorithmic research. Their work collectively enhances the understanding of error dynamics and introduces advanced methodologies for improving algorithmic performance.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="ZHOU ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhou et al. are researchers who have developed least-to-most prompting for multi-step decomposition in reasoning tasks, published in 2022.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="BESTA ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Besta et al. are researchers who have contributed to the development of search algorithms for chain-of-thought prompting, published in 2023.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MADAAN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Madaan et al., 2023, are researchers who have made significant contributions to the field of language models by developing self-refine techniques aimed at improving decision-making and performance. Their work, published in 2023, includes the development of the Self-Refine algorithm, which leverages self-reflection to enhance the capabilities of language models. Additionally, they have contributed to the LATS algorithm, further showcasing their expertise in refining and optimizing language model performance.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SILVER ET AL., 2017">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"SILVER ET AL., 2017" refers to a group of researchers who are recognized for their significant contributions to the field of model-based reinforcement learning. Their work, published in 2017, is particularly noted for its exploration of learned heuristics, which has been referenced in the context of the LATS algorithm. This research has had a substantial impact on the understanding and development of advanced reinforcement learning techniques.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="AHN ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ahn et al. are researchers who have employed language models as high-level controllers in robotics, published in 2022.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="HUANG ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Huang et al. are researchers who have employed language models as high-level controllers in robotics, published in 2022.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="DRIESS ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Driess et al. are researchers who have employed language models as high-level controllers in robotics, published in 2023.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="BAKER ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Baker et al. are researchers who have adapted language model agents to complex multimodal games, published in 2022.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WANG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are researchers who have adapted language model agents to complex multimodal games, published in 2023.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="GUSS ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guss et al. are researchers who have worked on complex multimodal games like Minecraft, published in 2019.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LIU ET AL., 2018">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu et al. are researchers who have employed language models in text-based environments, published in 2018.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SHRIDHAR ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shridhar et al., 2020, are researchers who have employed language models in text-based environments. They are the authors mentioned in relation to Alfworld, an environment designed for text-based manipulation tasks. Their work, published in 2020, contributes to the understanding and development of language models within interactive and dynamic text-based settings.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LIU ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu et al., 2024, are researchers known for their work published in 2024, which focuses on balancing exploration and exploitation in search algorithms. They have employed language models in text-based environments and are also the authors of research on EoH.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="ERROR PROPAGATION">
      <data key="d0" />
      <data key="d1">Error propagation is an issue in reasoning tasks where errors accumulate over multiple steps, leading to incorrect final outputs. This phenomenon, known as error propagation, is particularly problematic in reasoning-based methods. To address this challenge, techniques such as self-consistency and self-refinement have been developed to mitigate the accumulation of errors and improve the accuracy of the final results.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">ISSUE, CHALLENGE</data>
    </node>
    <node id="LEAST-TO-MOST PROMPTING">
      <data key="d0" />
      <data key="d1">Least-to-most prompting is a method that decomposes problems from the simplest to the most complex steps, thereby improving reasoning in large language models. This technique enables complex reasoning capabilities, as discussed in the paper by Olivier Bousquet, Quoc Le, and Ed Chi.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SEARCH ALGORITHMS">
      <data key="d0" />
      <data key="d1">SEARCH ALGORITHMS are methods used to explore and find solutions in various domains, particularly in decision-making tasks. They are integrated with Language Model (LM) agents in Language-Aided Task Solving (LATS) to enhance the performance of language models. These algorithms, such as Depth-First Search (DFS) and Breadth-First Search (BFS), are employed to systematically explore the tree structures in Tree of Thought (ToT) prompting, ensuring a comprehensive and efficient search process.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="SELF-REFINE">
      <data key="d0" />
      <data key="d1">"Self-Refine" is a state-of-the-art, manually designed agent developed by Madaan et al. (2024) and Shinn et al. (2023), as detailed in the research paper titled "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024. This agent is used for reasoning and problem-solving tasks across various domains, including math, reading comprehension, multi-tasking, and science, with specific accuracy and F1 scores reported. The Self-Refine method allows for iterative self-reflection to correct mistakes made in previous attempts, enabling up to five refinement iterations with an early stop if the critic deems the answer correct. Additionally, it is employed in Meta Agent Search, where the meta agent performs iterations of refinement on the novelty and correctness of the proposal, allowing up to three refinements when errors occur while running the code. This iterative refinement strategy enhances reasoning and decision-making through self-improvement, making Self-Refine a significant contribution to the field of artificial intelligence.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,1b1399c76420a477c0c97893d258ae69,24d7b89ae9522ae60d2317984951355b,2d4672dfb7bd4283f0b5f23ab4f26653,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="REFLEXION">
      <data key="d0" />
      <data key="d1">REFLEXION is an algorithm developed by Shinn et al. in 2023, designed for reasoning, acting, and planning in language models. It employs verbal reinforcement learning and was discussed in a paper published in NeurIPS, 2023. Reflexion is a simpler prompting method compared to LATS and is similar to the ReAct technique, focusing on decision-making tasks where reverting between iterations is feasible. While it provides semantic feedback, it may not be as effective in complex environments like WebShop. Reflexion aims to enhance reasoning and decision-making through self-improvement.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,b8dd0300033963bb4a3e1bad37f8e7b9,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="HIGH-LEVEL CONTROLLERS">
      <data key="d0" />
      <data key="d1">High-level controllers are components that oversee and guide lower-level control policies. Language models are used as high-level controllers in robotics and other applications.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">COMPONENT, ELEMENT</data>
    </node>
    <node id="COMPLEX MULTIMODAL GAMES">
      <data key="d0" />
      <data key="d1">Complex multimodal games are games that involve multiple types of inputs and outputs, such as visual and textual information. Language models are adapted to these games for decision-making tasks.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TASK, APPLICATION</data>
    </node>
    <node id="MINECRAFT">
      <data key="d0" />
      <data key="d1">Minecraft is a complex multimodal game where language models are used to control agents and make decisions based on the game environment. Additionally, Minecraft is mentioned as a potential environment for future work using planning-based prompting methods like LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TASK, APPLICATION</data>
    </node>
    <node id="TEXT-BASED ENVIRONMENTS">
      <data key="d0" />
      <data key="d1">Text-based environments are interactive settings where language models process and generate text to perform tasks. LATS and other algorithms are used to enhance performance in these environments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TASK, APPLICATION</data>
    </node>
    <node id="PROMPTS">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">PROMPTS are predefined inputs or questions used to guide the behavior and responses of language models and AI systems. They serve multiple purposes, including evaluating summarization, grounding, and data transformation abilities. In various environments such as HotPotQA, Programming, and WebShop, prompts are integral to the LATS algorithm, where they store and retrieve external feedback effectively. They are also used in data generation workflows as seeds for generating synthetic data and more instructions. Additionally, prompts are employed in ADAS methods and the Meta Agent to design new agents based on an archive of previously discovered agents, as detailed in the supplementary material of the paper "Automated Design of Agentic Systems." Overall, prompts are crucial elements that enhance reasoning and improve the performance of AI systems by providing specific instructions or few-shot input-output examples.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba,8ee9617c145e19fa95f1f9349bfbe69b,9bb90746134619cad9a3e649b8b35f24,b88745a13b69cecbc0ee9c3af41389bf,b8dd0300033963bb4a3e1bad37f8e7b9,cc802d9b841fde55e9c0c2ba0ef7869d,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="VALUE FUNCTION">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">The VALUE FUNCTION is a critical component in the LATS (Language Algorithmic Task Solver) algorithm, designed to be independently altered and adapted to individual language model properties. It assigns values to nodes based on a combination of self-generated language model (LM) scores and self-consistency scores, guiding the search process by incorporating successful heuristics such as self-refinement and self-consistency. This function is used to evaluate the performance of an agent in a task, often configured with hyperparameters, and is essential in reinforcement learning for estimating the expected reward of a given state or action. In the context of LATS, the value function contributes to superior performance in reasoning tasks by incorporating self-consistency as an additional heuristic. It estimates the expected return of a node in the search tree and is updated during backpropagation, ultimately assigning values to nodes based on their potential to lead to a successful outcome.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SELF-REFINEMENT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Self-refinement is a technique used in LATS to improve the performance of language models by allowing them to learn from their own outputs and make adjustments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="INTERNAL REASONING PERFORMANCE">
      <data key="d0">METRIC, PERFORMANCE</data>
      <data key="d1">Internal reasoning performance refers to the ability of a language model to reason and solve problems without external feedback. LATS aims to surpass this performance by incorporating external feedback.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MODEL-BASED REINFORCEMENT LEARNING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Model-based reinforcement learning is a technique that uses models to simulate and plan actions. MCTS, used in LATS, is inspired by its success in this field.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="IN-CONTEXT LEARNING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">IN-CONTEXT LEARNING is a technique that leverages the abilities of modern language models to learn and adapt from the context provided in the input. It is used in the LATS algorithm to refine the agent and value function by integrating failed trajectories and reflections as additional context. This capability enhances the performance of the LATS algorithm by allowing it to learn and adapt more effectively from the provided context.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="AUTONOMOUS REASONING">
      <data key="d0">CAPABILITY, FUNCTION</data>
      <data key="d1">Autonomous reasoning is the ability of a language model to reason and make decisions independently. LATS enhances this capability through its framework.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="DECISION-MAKING">
      <data key="d0">CAPABILITY, FUNCTION</data>
      <data key="d1">Decision-making is the process of making choices or reaching conclusions based on reasoning, available information, and external feedback. It involves selecting options with high value while exploring promising alternatives. In the context of the LATS algorithm, decision-making is enhanced by incorporating reasoning, acting, and planning, which improves the performance of language models in tasks or settings where the model must choose between different options or actions. The LATS algorithm supports decision-making by evaluating the process of making choices through reasoning and information retrieval.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (COT) PROMPTING VARIANTS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Variants of chain-of-thought prompting are methods that build on the original CoT technique to improve reasoning in language models. These variants are used to address error propagation issues.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MAJORITY VOTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Majority voting is a technique used in self-consistency where the most common answer among multiple samples is chosen to reduce errors.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MULTI-STEP DECOMPOSITION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Multi-step decomposition is a technique where complex problems are broken down into smaller, manageable steps. It is used in methods like least-to-most prompting.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="DEPTH-FIRST SEARCH (DFS)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Depth-first search (DFS) is a search algorithm used to systematically explore the tree in Tree-of-Thought (ToT) prompting, guided by heuristics. DFS explores as far as possible along each branch before backtracking, making it an effective method for navigating complex structures and hierarchies within algorithmic communities. This approach ensures a comprehensive understanding of the dynamics and interactions within the tree, leveraging heuristics to guide the search process efficiently.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="BREADTH-FIRST SEARCH (BFS)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Breadth-first search (BFS) is a search algorithm used to systematically explore the tree in Tree-of-Thought (ToT) prompting, guided by heuristics. It explores all nodes at the present depth level before moving on to the nodes at the next depth level, ensuring a comprehensive traversal of each level before proceeding to the next. This methodical approach is particularly useful in ToT prompting, where the structure and depth of the tree are critical to the algorithm's effectiveness.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="ROLL-OUTS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">ROLL-OUTS are simulations used in planning algorithms such as Monte Carlo Tree Search (MCTS) and the LATS algorithm to evaluate the potential outcomes of actions. They play a crucial role in reasoning via planning (RAP) by simulating future actions and states, thereby aiding in the decision-making process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="POLICY MODEL">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">A policy model is a component in decision-making tasks that determines the actions to be taken based on the current state. Language models are used as policy models in interactive environments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CONTROL POLICIES">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">Control policies are rules or strategies that determine the actions to be taken in a given state. They are used in robotics and other decision-making tasks.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="ACTING-BASED PROMPTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Acting-based prompting is a technique where language models generate actions based on prompts to interact with the environment. ReAct is an example of this technique.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SELF-IMPROVEMENT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Self-improvement is a technique where language models learn from their own outputs and make adjustments to improve performance. This method is utilized in approaches such as self-refine and Reflexion. It also refers to the ability of larger, more capable models to enhance their own performance by generating new prompts and high-quality responses. Through these processes, models iteratively refine their outputs, leading to continuous enhancement in their capabilities and overall performance.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1">LANGUAGE MODELS, particularly advanced models like GPT-3.5 and GPT-4, are utilized for a variety of sophisticated tasks. These models are employed in natural language processing tasks, which include reasoning, acting, and planning within the context of LATS (Language and Text Systems). Their capabilities extend beyond simple text generation, enabling them to perform complex analyses and interactions, making them integral tools in the field of artificial intelligence and computational linguistics.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="COT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">COT (Chain of Thought) is a prompting technique used in reasoning tasks, particularly in environments without feedback. It involves guiding the model through a step-by-step thought process to enhance performance on questions requiring intricate reasoning. This method is employed in various scenarios, including the Game of 24 and LATS experiments, where it helps the model think systematically before answering. CoT is also used to evaluate the performance of language models by relying solely on the agent&#8217;s existing knowledge, without the need for Retrieval-Augmented Generation (RAG).</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,97457e990eb6e3c88c11c862f9e3265b,99d90aededb61e04241516ed9ec656cc,ab04427ae0415a1c812a35cf8d3ee1a2,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="ADAPLANNER">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">AdaPlanner is a method for adaptive planning from feedback with language models, discussed in a paper published in NeurIPS, 2023. It is an extension proposed by Sun et al. in 2023 that incorporates both positive and negative feedback to improve decision-making.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="HUANG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Huang et al. are researchers who suggested in 2024 that language models cannot self-correct their internal reasoning, making external feedback critical.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="EXTERNAL TOOLS">
      <data key="d0">TECHNOLOGY, RESOURCE</data>
      <data key="d1">External tools such as APIs, search engines, calculators, and other models are used to enhance the reasoning and practical abilities of language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="TREE-BASED SEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Tree-based search is a planning algorithm where multiple branches of outcomes are explored. It is widely used in planning and reinforcement learning for its good exploration-exploitation trade-off.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="MCTS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Monte Carlo Tree Search (MCTS) is a principled, tree-based search algorithm that is widely used for decision-making and planning tasks. It requires an environment model to undo previous steps and form a searching tree, enabling it to explore multiple branches of outcomes. MCTS is known for its performance gains when compared to other search algorithms like A* and DFS. It is particularly leveraged in the LATS algorithm to ensure a principled exploration, selecting options with high value and unlocking the potential of language models.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="LM">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">LM (Language Model) refers to pre-trained models that generate or understand human language. These models are utilized in various methods such as LATS, ToT, and RAP for tasks including reasoning, acting, and planning. They generate outputs based on given inputs and prompts, aiding in decision-making and other complex tasks.</data>
      <data key="d2">c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SUN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sun et al. are researchers who developed the AdaPlanner algorithm in 2023.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="SWIECHOWSKI ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Swiechowski et al. are researchers who contributed to the development of tree-based search algorithms in 2021.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LAVALLE, 1998">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">LaValle is a researcher who contributed to the development of tree-based search algorithms in 1998.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HAFNER ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hafner et al. are researchers who contributed to the development of reinforcement learning algorithms in 2019.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="DU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Du et al. are researchers who contributed to the development of reinforcement learning algorithms in 2023. They are the authors of the LLM-Debate method, an algorithm published in 2023. Their work on the LLM-Debate algorithm has been recognized as a significant contribution to the field of reinforcement learning.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wu et al., 2023, are researchers who made significant contributions to the field of reinforcement learning algorithms. In addition to their work in reinforcement learning, they also developed techniques for assigning FM modules in agentic systems. Their research, published in 2023, highlights their expertise and innovative approaches in these areas, marking a notable advancement in the understanding and application of algorithmic systems.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="VODOPIVEC ET AL., 2017">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vodopivec et al. are researchers who contributed to the development of tree-based search algorithms in 2017.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHEN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shen et al., 2023, are researchers who made significant contributions to the field of artificial intelligence. In 2023, they authored a study discussing Neural Architecture Search (NAS), a method for automating the design of neural networks. Additionally, they developed external tools for language models, enhancing the capabilities and performance of these models. Their work in both NAS and language model tools underscores their pivotal role in advancing AI technologies.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SURIS ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Suris et al. are researchers who contributed to the development of external tools for language models in 2023.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TOT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">ToT (Tree of Thoughts) is an algorithm developed by Yao et al. in 2023, designed to enhance reasoning, planning, and self-reflection in language models. It employs LM-based heuristics to prune branches with low values, thereby eliminating the need for selection and backpropagation operations. This search method is capable of sampling and exploring a wider range of outputs, which results in significant performance gains on reasoning tasks. ToT has been evaluated using benchmarks such as HotPotQA, HumanEval, and Game of 24, demonstrating superior performance and efficiency compared to other methods like LATS, despite having the same sample complexity.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="RAP">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">RAP (Reinforcement Learning with Augmented Planning) is an algorithm developed by Hao et al. in 2023. It relies on internal dynamics models for simulation and incorporates reasoning, planning, and external feedback in language models. RAP is a reasoning-based method that depends solely on the internal representations of the language model, which can sometimes lead to fact hallucination and error propagation. It is a search method that can sample and explore more outputs, similar to ToT, and is used for reasoning and decision-making tasks. RAP has been evaluated for performance, sample complexity, and token consumption, and is compared to other methods like LATS and ToT. Despite having the same sample complexity as LATS, RAP achieves better performance and efficiency. It has been tested using benchmarks such as HotPotQA, HumanEval, and Game of 24, demonstrating its effectiveness in reasoning and acting within language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="BEAM SEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Beam Search is an algorithm developed by Xie et al. in 2023 that incorporates reasoning and self-reflection in language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="PLANNING">
      <data key="d0">TASK, FUNCTION</data>
      <data key="d1">PLANNING refers to the use of a search algorithm to determine a sequence of actions or decisions in language models. It involves the process of strategizing actions to achieve a goal, integrated into Language and Action Task Systems (LATS). This integration ensures that the planning process is systematic and goal-oriented, leveraging algorithmic strategies to optimize decision-making within language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TASK, FUNCTION</data>
    </node>
    <node id="REASONING">
      <data key="d0">TASK, FUNCTION</data>
      <data key="d1">REASONING is a multifaceted task supported by the LATS algorithm, involving the process of making decisions based on a shared space of thoughts and actions. It is a skill that can be taught to AI models using the data generated by AgentInstruct. Reasoning is one of the domains where experiments were conducted using various methods and algorithms. It refers to the internal process of language models to generate logical conclusions or answers based on given inputs, and it encompasses the process of thinking through problems and generating solutions, which is a key component of LATS.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,97457e990eb6e3c88c11c862f9e3265b,b88745a13b69cecbc0ee9c3af41389bf,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TASK, FUNCTION</data>
    </node>
    <node id="ACTING">
      <data key="d0">TASK, FUNCTION</data>
      <data key="d1">ACTING refers to the external decision-making process of language models based on given inputs and reasoning. It involves the process of taking actions based on reasoning, which is a key component of LATS (Language and Action Task Systems).</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TASK, FUNCTION</data>
    </node>
    <node id="EXTERNAL MEMORY">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">External memory is an important building block for agentic systems, used to store information outside the agent's immediate processing capabilities. It refers to storing past text context for future updates of the solution in language models. This functionality is crucial for enhancing the performance and efficiency of systems that require the retention and utilization of historical data to inform future actions and decisions.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SEARCH ALGORITHM">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The SEARCH ALGORITHM is a method used to explore and select the most promising regions of a decision tree based on heuristic values within the LATS framework. It encompasses various techniques such as Monte Carlo Tree Search (MCTS), A* (A-star), and Depth-First Search (DFS) to explore possible solutions in decision-making tasks. These algorithms are designed to navigate multiple branches of outcomes to identify the optimal solution in planning tasks. In the context of Advanced Driver Assistance Systems (ADAS), the search algorithm specifies how the method explores the search space, aiming to quickly discover high-performance agentic systems while avoiding local optima.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,4884e8429ca1e567dadf5e22b4b68274,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="REINFORCEMENT LEARNING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Reinforcement Learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward. This method involves agents receiving rewards or penalties for their actions, which helps them learn to optimize their behavior over time. It is commonly used in various applications, including robotics, where models are trained by rewarding desired behaviors and penalizing undesired ones. The LATS algorithm aims to avoid traditional reinforcement learning techniques by using self-reflection and in-context learning for optimization.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,8180bf20b7577f3eee40df5991e2886d,c95e02c0dca4a4a36b701cbc7dd14da6,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="ENVIRONMENT MODEL">
      <data key="d0">TECHNOLOGY, RESOURCE</data>
      <data key="d1">An environment model is a representation of the environment in which a planning or reinforcement learning algorithm operates.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNOLOGY, RESOURCE</data>
    </node>
    <node id="INTERNAL REASONING">
      <data key="d0">TASK, FUNCTION</data>
      <data key="d1">INTERNAL REASONING is a strategy that relies solely on the agent&#8217;s existing knowledge to answer questions, evaluated in LATS. It refers to the process of using the model's pre-existing knowledge to answer questions or solve problems without external input. Additionally, internal reasoning involves the process within language models to generate logical conclusions or answers based on given inputs.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TASK, FUNCTION</data>
    </node>
    <node id="INPUT">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Input refers to the data or information provided to an agent to perform a task or solve a problem. Specifically, in the context of language models, input refers to the natural language sequences provided for reasoning or decision-making tasks.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="OUTPUT">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Output refers to the final language sequences generated by language models based on given inputs and prompts.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="TOKENS">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Tokens are the basic elements of natural language, often words, that comprise the input and output sequences in language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="AUTOREGRESSIVE DECODING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Autoregressive decoding is a technique where language models generate text sequentially, predicting each token based on the previous ones.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="PROBABILITY">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Probability refers to the likelihood of a language model generating a specific sequence of tokens based on given inputs.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="FEW-SHOT LEARNING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Few-shot learning is a technique where language models are provided with a few input-output examples to improve their performance on specific tasks.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="PROMPT IO(X)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Prompt IO(x) refers to the process where an input prompt is transformed into an output by a language model.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="OURS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ours refers to the authors of the Language Agent Tree Search (LATS) algorithm.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HAFNER ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hafner et al. are researchers who contributed to the development of reinforcement learning algorithms in 2023.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Upper Confidence bounds applied to Trees (UCT) is a value used in MCTS to select the best child node for expansion based on a combination of exploration and exploitation.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="LANGUAGE MODELS (LM)">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Language models (LM) are advanced models used for various tasks, including reasoning, acting, and planning, often enhanced by techniques like CoT, ToT, and ReAct.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="ENVIRONMENTAL FEEDBACK">
      <data key="d0">CONCEPT, INPUT</data>
      <data key="d1">Environmental feedback refers to observations from the environment that are used to improve reasoning and acting in techniques like ReAct and Reflexion. Additionally, it encompasses feedback obtained from the environment after a trajectory is completed, which is used to enhance value assignment in the LATS algorithm. This feedback mechanism plays a crucial role in refining the performance and accuracy of these algorithms by providing essential data that informs subsequent actions and decisions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="HEURISTICS">
      <data key="d0">CONCEPT, STRATEGY</data>
      <data key="d1">Heuristics are strategies or guidelines used to guide search algorithms like DFS or BFS in exploring the tree of thoughts in ToT prompting.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="FLEXIBILITY">
      <data key="d0">ATTRIBUTE, QUALITY</data>
      <data key="d1">FLEXIBILITY is a property of the LATS algorithm that allows it to accommodate different scenarios, environments, and resource stipulations by modifying state design and tree dimensions. This flexibility refers to the ability of a technique to consider alternative continuations from specific states, addressing a limitation found in base prompting designs like CoT (Chain of Thought) or ReAct (Reasoning and Acting). This adaptability ensures that the LATS algorithm can effectively navigate and optimize within diverse and dynamic contexts, enhancing its robustness and applicability across various use cases.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="SENSIBILITY">
      <data key="d0">ATTRIBUTE, QUALITY</data>
      <data key="d1">Sensibility refers to the reliance on internal representations of the language model, which can lead to fact hallucination and error propagation in reasoning-based methods like CoT and RAP.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="ADAPTABILITY">
      <data key="d0">ATTRIBUTE, QUALITY</data>
      <data key="d1">ADAPTABILITY is a property of the LATS algorithm that allows it to incorporate external feedback and self-reflection for greater adaptation during problem-solving. It refers to the ability to leverage environmental feedback and reuse previous experience, addressing a limitation in current planning strategies like RAP or ToT. This characteristic enhances the algorithm's efficiency and effectiveness in dynamic environments by continuously improving its performance based on past interactions and new information.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="KOCSIS AND SZEPESV&#193;RI, 2006">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kocsis and Szepesv&#225;ri are the authors who developed the UCT value used in MCTS for selecting the best child node for expansion.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="YE ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ye et al. are the authors who demonstrated the success of MCTS in decision-making environments like Atari.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="SILVER ET AL., 2016">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Silver et al. are the authors who demonstrated the success of MCTS in decision-making environments like Go.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="INPUT X">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Input x is the initial data or query provided to the language model for processing.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="OUTPUT Y">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Output y is the final result produced by the language model after processing the input x.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="THOUGHTS Z">
      <data key="d0">DATA, INTERMEDIATE OUTPUT</data>
      <data key="d1">Thoughts z are intermediate language sequences generated during the reasoning process in CoT and ToT prompting.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="PROPOSAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Proposal is a method used in ToT prompting to generate thoughts zi by sampling with CoT.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="SAMPLING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">SAMPLING is a technique employed in various algorithms, including LATS and ToT prompting, to sample trajectories for evaluation and generate thoughts zi by sampling with CoT. This method is integral to the functioning of these algorithms, ensuring a comprehensive evaluation and generation process.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="DECISION-MAKING TASKS">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">Decision-making tasks are complex problems that require reasoning, acting, and planning, often involving interactions with an external environment. These tasks necessitate selecting the best course of action from multiple options. Methods such as LATS (Learning and Adaptation Task Systems), ToT (Theory of Tasks), and RAP (Reasoning and Planning) are commonly employed to address these challenges.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="PERFORMANCE CEILING">
      <data key="d0">CONCEPT, LIMITATION</data>
      <data key="d1">Performance ceiling refers to the maximum performance level that can be achieved by a technique, beyond which improvements are not possible.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="FACT HALLUCINATION">
      <data key="d0">CONCEPT, ISSUE</data>
      <data key="d1">Fact hallucination is the generation of incorrect or fabricated information by a language model, often due to reliance on internal representations.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="TRIAL AND ERROR">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Trial and error is a method of learning and improving by making mistakes and learning from them, which is limited in current planning strategies.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="WORLD MODEL">
      <data key="d0">CONCEPT, MODEL</data>
      <data key="d1">World model is a concept where the language model can accurately predict states and outcomes in a given environment.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="RETURN R">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Return r is the reward or feedback used for updating the value function V(s) in MCTS during backpropagation.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="VALUE FUNCTION V(S)">
      <data key="d0">CONCEPT, FUNCTION</data>
      <data key="d1">Value function V(s) is the expected return from the subtree of a node s in MCTS, used to guide the search process.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="EXPLORATION WEIGHT W">
      <data key="d0">CONCEPT, PARAMETER</data>
      <data key="d1">Exploration weight w is a parameter in the UCT formula that balances exploration and exploitation in MCTS.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="PARENT NODE P">
      <data key="d0">DATA, NODE</data>
      <data key="d1">Parent node p is the node from which child nodes are expanded in the decision tree of MCTS.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="CHILD NODE S">
      <data key="d0">DATA, NODE</data>
      <data key="d1">Child node s is a node that is expanded from a parent node in the decision tree of MCTS.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="BACKPROPAGATION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Backpropagation is a method used in algorithms such as LATS (Learning Automata Tree Search) and MCTS (Monte Carlo Tree Search) to update the values of nodes within a search tree. This process involves using the outcome from a terminal node to update the value function V(s) along the path back to the root. In the context of the LATS algorithm, backpropagation employs the UCT (Upper Confidence bounds applied to Trees) formula to guide the selection of the next node, ensuring that the values of the tree are updated based on the outcomes of explored trajectories.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="EPISODES">
      <data key="d0">DATA, ITERATION</data>
      <data key="d1">Episodes are iterations in MCTS where the decision tree is expanded and updated to improve decision-making.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="AGENT">
      <data key="d0">ACTOR, SYSTEM</data>
      <data key="d1">An agent in this context is an entity that receives observations from the environment and takes actions based on a policy. It is initialized with a language model to leverage useful language representations. Powered by a large language model (LLM), an agent can optionally use tools such as search APIs, code interpreters, or calculators. Each agent has a specific role and set of instructions. In the LATS algorithm, the agent performs reasoning, acting, and planning tasks based on the value function and search algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c234cb83764b899335af0950677ad024,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ENVIRONMENT">
      <data key="d0">CONTEXT, SYSTEM</data>
      <data key="d1">The environment is the context in which the agent operates, providing observations based on the agent's actions. It serves as the setting in which the agent functions, offering feedback and observations that can vary depending on the task. In benchmarks like HotPotQA, the environment plays a crucial role in shaping the agent's interactions and performance.</data>
      <data key="d2">c234cb83764b899335af0950677ad024,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="UCT ALGORITHM">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">UCT (Upper Confidence bounds applied to Trees) is an algorithm used to balance exploration and exploitation in tree search methods like MCTS.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="P&#920;">
      <data key="d0">MODEL, FUNCTION</data>
      <data key="d1">P&#952; is a component of the LATS algorithm that has been repurposed into a value function by prompting it to reason about a given state and conclude its reasoning trace with a score indicating the correctness of the trajectory. Additionally, P&#952; is a probabilistic model used within LATS to sample actions and generate language representations. It is integrated within the search algorithm to construct the best trajectory from the sampled actions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SELECTION">
      <data key="d0">OPERATION, PROCESS</data>
      <data key="d1">Selection is the first operation in LATS (Learning Automata Tree Search) where the algorithm identifies a segment of the current tree most suitable for subsequent expansion. It refers to the process of choosing the most promising nodes to expand during the search process in algorithms like LATS and MCTS (Monte Carlo Tree Search). This step is crucial as it determines the efficiency and effectiveness of the search, guiding the algorithm towards the most promising areas of the search space.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="EXPANSION">
      <data key="d0">OPERATION, PROCESS</data>
      <data key="d1">"EXPANSION" refers to a multifaceted concept within algorithmic processes. Primarily, it is a text modification task that involves adding more information to a given piece of text. In the context of search algorithms, expansion denotes the process of exploring new nodes or states to find a solution. Specifically, in the LATS (Look-Ahead Tree Search) framework, expansion is the second operation where the tree is expanded by sampling actions from P&#952;, resulting in new child nodes being added to the tree. This phase is crucial as it involves sampling nodes during evaluation to enhance the search process.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,99d90aededb61e04241516ed9ec656cc,c234cb83764b899335af0950677ad024,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SIMULATION">
      <data key="d0">OPERATION, PROCESS</data>
      <data key="d1">SIMULATION is an operation in the LATS algorithm where the algorithm simulates actions until a terminal node is reached. This process helps to explore potential trajectories and provides objective feedback on the correctness of a trajectory by expanding the currently selected node until a terminal state is reached.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="REFLECTION">
      <data key="d0">OPERATION, PROCESS</data>
      <data key="d1">REFLECTION is a critical reasoning step and action in various algorithmic processes, particularly in the LATS algorithm, where it involves analyzing past attempts to improve future performance. This process entails evaluating previous actions and outcomes to enhance future searches and decision-making. In the context of LATS, reflection is specifically used to refine the decision-making process by summarizing errors, proposing superior alternatives, and storing failed trajectories and reflections in memory. It is a process where agents look back at solutions, generate critiques, and improve solutions to create higher quality data. Reflection serves as an important building block for agentic systems, facilitating the improvement of agent performance through self-assessment. When a trajectory fails, a reflection is generated and used as additional context for future trials, ensuring continuous learning and enhancement.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,0b6b4880e77d40e284702da16be4ef64,4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7,6fe27f9eb76cf2ddf712a2cee5783d1c,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="EXPLORATION WEIGHT">
      <data key="d0">PARAMETER, METRIC</data>
      <data key="d1">Exploration weight is a parameter in the LATS and MCTS algorithms that significantly affects the effectiveness of the search process. In the LATS algorithm, different values of exploration weight are used for various tasks such as HotPotQA and Programming, leading to variations in performance and convergence speed. In the MCTS algorithm, exploration weight is crucial for balancing exploration and exploitation during the search process.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="PARENT NODE">
      <data key="d0">NODE, COMPONENT</data>
      <data key="d1">The parent node is a node in the search tree that has one or more child nodes. It is used in the backpropagation process to update values.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="EPISODE">
      <data key="d0">EVENT, PROCESS</data>
      <data key="d1">An "EPISODE" in the context of a web shop refers to a complete interaction session where an agent performs a series of actions and observations, starting from searching for a product and culminating in its purchase. This sequence of actions is guided by specific instructions and continues until a terminal state is reached, signifying the end of the session.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="RETURN">
      <data key="d0">METRIC, VALUE</data>
      <data key="d1">Return is a value used in the backpropagation process to update the value function of nodes in the search tree.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="VOLD(S)">
      <data key="d0">VALUE, FUNCTION</data>
      <data key="d1">Vold(s) is the old value function of a node before it is updated with the new return value during backpropagation.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="N(S)">
      <data key="d0">METRIC, VALUE</data>
      <data key="d1">N(s) is the number of times a node has been visited in the search tree. It is used in the value function update formula.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="RESET">
      <data key="d0">ACTION, PROCESS</data>
      <data key="d1">Reset refers to the action of returning to a previous state or step in the task, often used in language model tasks to facilitate exploration.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="HISTORICAL TEXT INPUT">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Historical text input refers to previously entered text that can be used to reset to any step in language model tasks.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="BASE PROMPTING FRAMEWORK">
      <data key="d0">FRAMEWORK, METHOD</data>
      <data key="d1">The BASE PROMPTING FRAMEWORK is the initial design used to guide the agent's actions and decisions in a task. It encompasses the initial set of prompts employed to direct the language model, such as Chain-of-Thought (CoT) in Language-Agnostic Task Specification (LATS). This framework serves as the foundational structure for prompting, ensuring that the agent operates within a predefined set of guidelines to achieve the desired outcomes.</data>
      <data key="d2">c234cb83764b899335af0950677ad024,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="OBSERVATION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">OBSERVATION refers to the environmental data or information about the current situation in a question-answering task, which is used to inform thoughts and actions. It is the information obtained as a result of an Action, and it is used to inform the next Thought or Action. Specifically, Observation is the information received by the agent from the environment at each time step. This continuous feedback loop allows the agent to adapt and make informed decisions based on the evolving context provided by the environment.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="ACTION">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">ACTION refers to the decision or move made by an agent based on the policy and observations. In the context of a question-answering task, an action can involve operations such as searching for an entity, looking up a keyword, or concluding with an answer. Additionally, an action is performed in response to a Thought, which may include similar operations like searching for an entity or finishing with an answer.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="POLICY">
      <data key="d0">RULE, STRATEGY</data>
      <data key="d1">Policy is the strategy or rule that the agent follows to decide on actions based on observations and previous actions.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="INITIAL STATE">
      <data key="d0">STATE, CONDITION</data>
      <data key="d1">The initial state refers to the starting point or configuration from which the LATS algorithm begins its search process. It is the starting point of the search tree or task, from which the agent begins its actions. This initial configuration is crucial as it sets the foundation for the algorithm's subsequent operations and decisions.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="ROOT NODE">
      <data key="d0">NODE, COMPONENT</data>
      <data key="d1">The root node is the topmost node in the search tree, representing the initial state of the task.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="LEAF NODE">
      <data key="d0">NODE, COMPONENT</data>
      <data key="d1">A leaf node is a node in the search tree that does not have any child nodes. It represents a terminal state or end of a trajectory.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="CHILD NODE">
      <data key="d0">NODE, COMPONENT</data>
      <data key="d1">A child node is a node in the search tree that is connected to a parent node and represents a subsequent state in the task.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="LONG-TERM MEMORY STRUCTURE">
      <data key="d0">MEMORY, STORAGE</data>
      <data key="d1">The "LONG-TERM MEMORY STRUCTURE" is an external storage mechanism designed to store failed trajectories and their corresponding reflections. This structure plays a crucial role in maintaining a record of the expanded search tree and its nodes. By integrating these stored trajectories and reflections as additional context, it enhances the agent and value function in subsequent iterations, thereby improving the overall efficiency and effectiveness of the algorithmic process.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SCALAR VALUE">
      <data key="d0">VALUE, METRIC</data>
      <data key="d1">The SCALAR VALUE is a numerical value assigned to each new child node in the LATS algorithm to quantify the agent&#8217;s progress in task completion. This value is crucial during the evaluation process as it provides a measurable indicator of how effectively the agent is advancing towards completing its assigned tasks.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="HEURISTIC">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Heuristic is a strategy used to guide the search algorithm towards the most promising regions of the search tree. In the context of the LATS algorithm, it includes both programmed heuristics and learned heuristics, incorporating self-consistency and other factors to improve performance. This method is essential for steering the search process efficiently, ensuring that the algorithm focuses on the most promising regions of the tree.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="LM SCORE">
      <data key="d0">METRIC, VALUE</data>
      <data key="d1">LM score is a self-generated score by the language model used as part of the value function in LATS.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SELF-GENERATED LM SCORE">
      <data key="d0">METRIC, COMPONENT</data>
      <data key="d1">A score generated by the language model itself to quantify the correctness of a trajectory in the LATS algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="SELF-CONSISTENCY SCORE">
      <data key="d0">METRIC, COMPONENT</data>
      <data key="d1">The SELF-CONSISTENCY SCORE is a metric used in the LATS (Learning Algorithm for Temporal Sequences) value function. It is based on the principle that actions sampled multiple times at the same state tend to be more accurate. This score enhances the performance of LATS by ensuring consistent results across iterations, thereby improving the reliability and accuracy of the algorithm's predictions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="TERMINAL STATE">
      <data key="d0">CONCEPT, STATE</data>
      <data key="d1">TERMINAL STATE in the context of the LATS algorithm is a critical point where the task is either completed successfully or not, providing objective feedback on the correctness of a trajectory. It refers to a state in the search process where no further actions can be taken, often indicating the end of a trajectory. This state is essential for determining the outcome of the algorithm's execution, marking the conclusion of the search process and offering a definitive assessment of the task's completion.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="COT (WEI ET AL., 2022)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">An algorithm used for reasoning, with a self-consistency variant (CoT - SC) that is evaluated on HotpotQA.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="TOT (YAO ET AL., 2023A)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">An algorithm used for reasoning, evaluated on HotpotQA, and achieving a high exact match (EM) score.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="RAP (HAO ET AL., 2023)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">An algorithm used for reasoning, evaluated on HotpotQA, and achieving a high exact match (EM) score.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="CAMPBELL ET AL., 2002">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Authors of research on programmed heuristics, referenced in the context of the LATS algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="CHEN ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen et al., 2021, are the authors of a significant body of research in the field of programming and reasoning tasks. Their work, published in 2021, includes the development of the HumanEval benchmark, which is used for evaluating programming tasks. Additionally, their research addresses safety considerations for executing model-generated code. Their contributions are referenced in the context of evaluating the LATS algorithm, highlighting their influence and relevance in the domain of programming and algorithmic analysis.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,dc55f071b95dec721a9820d39cdb3ccd,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="AUSTIN ET AL.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Authors of research on programming, referenced in the context of evaluating the LATS algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="UCT FORMULA">
      <data key="d0">FORMULA, METHOD</data>
      <data key="d1">A formula used in the LATS algorithm to guide the selection of the next node based on updated values from backpropagation.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="REWARD">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">REWARD is a measure of success based on the number of attributes satisfied by the selected item. Additionally, it serves as a metric used in the LATS algorithm to update the value of nodes during backpropagation, reflecting the outcome of a trajectory. This dual role highlights its importance in both evaluating the performance of selected items and in the iterative process of refining algorithmic predictions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HYPERPARAMETER">
      <data key="d0">CONCEPT, PARAMETER</data>
      <data key="d1">A parameter in the LATS algorithm that controls the balance between the self-generated LM score and the self-consistency score in the value function.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="EXACT MATCH (EM)">
      <data key="d0">METRIC, SCORE</data>
      <data key="d1">Exact Match (EM) is a performance measure used to evaluate the accuracy of algorithms, such as the LATS algorithm, on benchmarks like HotpotQA. It indicates the highest exact match score for reasoning, providing a metric to assess the performance of these algorithms in accurately matching the expected results.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">METRIC, SCORE</data>
    </node>
    <node id="REASONING-BASED PROMPTING">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A technique used in the LATS algorithm to achieve high exact match scores on benchmarks like HotpotQA.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">METHOD, TECHNIQUE</data>
    </node>
    <node id="TRAJECTORY">
      <data key="d0">CONCEPT, PATH</data>
      <data key="d1">TRAJECTORY is a sequence of states from the root to a terminal state in the LATS algorithm, used to evaluate and update the agent's performance. Additionally, it represents a sequence of steps in a question-answering task, labeled by observations, thoughts, and actions, which are utilized to assess the correctness of the solution. This dual role highlights TRAJECTORY's importance in both algorithmic evaluation and task-specific performance analysis, ensuring a comprehensive understanding of the agent's dynamics and interactions within these contexts.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,357f3442ba581c9d2bdf84d90509056f</data>
      <data key="d3">CONCEPT, PATH</data>
    </node>
    <node id="NODE">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">An element in the search tree of the LATS algorithm, representing a state in the trajectory from root to terminal state.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">COMPONENT, ELEMENT</data>
    </node>
    <node id="STATE">
      <data key="d0">CONCEPT, CONDITION</data>
      <data key="d1">A condition or situation represented by a node in the search tree of the LATS algorithm, used to evaluate the agent's progress.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, CONDITION</data>
    </node>
    <node id="SEARCH TREE">
      <data key="d0">STRUCTURE, COMPONENT</data>
      <data key="d1">A tree structure used in the LATS algorithm to represent different states and trajectories, guiding the search process.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">STRUCTURE, COMPONENT</data>
    </node>
    <node id="REASONING TRACE">
      <data key="d0">CONCEPT, PATH</data>
      <data key="d1">A sequence of reasoning steps taken by the agent in the LATS algorithm, ending with a score indicating the correctness of the trajectory.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, PATH</data>
    </node>
    <node id="PRINCIPLED SEARCH">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">A method used in the LATS algorithm to ensure that the search process selects options with high value while exploring promising alternatives.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="PROMISING REGIONS">
      <data key="d0">CONCEPT, AREA</data>
      <data key="d1">Areas of the search tree in the LATS algorithm that are likely to yield successful outcomes, prioritized based on heuristic values.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, AREA</data>
    </node>
    <node id="FAILED TRAJECTORIES">
      <data key="d0">CONCEPT, PATH</data>
      <data key="d1">Sequences of states that did not lead to successful task completion in the LATS algorithm, stored in memory for future reference.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, PATH</data>
    </node>
    <node id="SEMANTIC GRADIENT SIGNAL">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">A signal used in the LATS algorithm to provide more useful feedback than a scalar value, enabling the agent to learn from trial and error.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="OBSERVATIONS">
      <data key="d0">CONCEPT, DATA</data>
      <data key="d1">OBSERVATIONS refer to data collected from the environment, which is utilized in the LATS algorithm to incorporate external feedback and enhance problem-solving capabilities. This information is also employed in the evaluation of LATS and other algorithms, ensuring a comprehensive understanding of their performance and effectiveness.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">CONCEPT, DATA</data>
    </node>
    <node id="PROBLEM-SOLVING">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Problem-Solving is a domain where experiments were conducted using various methods and algorithms. It is a task supported by the LATS algorithm, which involves reasoning, acting, and planning to achieve successful outcomes.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="RESOURCE STIPULATIONS">
      <data key="d0">CONCEPT, CONSTRAINT</data>
      <data key="d1">Constraints related to resources that the LATS algorithm can accommodate by modifying state design and tree dimensions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, CONSTRAINT</data>
    </node>
    <node id="STATE DESIGN">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">The design of states in the LATS algorithm, which can be modified to accommodate different scenarios and environments.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="TREE DIMENSIONS">
      <data key="d0">CONCEPT, STRUCTURE</data>
      <data key="d1">The dimensions of the search tree in the LATS algorithm, which can be modified to accommodate different scenarios and environments.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, STRUCTURE</data>
    </node>
    <node id="BASE LM AGENT">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">The BASE LM AGENT is a fundamental component in the LATS algorithm, designed to be independently altered and adapted to individual language model properties. This adaptability allows it to cater to the specific needs and characteristics of various language models, ensuring optimal performance and integration within the LATS framework.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">COMPONENT, ENTITY</data>
    </node>
    <node id="REFLECTION GENERATOR">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">The "REFLECTION GENERATOR" is a crucial component within the LATS (Learning and Acting through Trajectory Sampling) algorithm. It is designed to enhance reasoning and acting capabilities by generating reflections on failed trajectories. By analyzing these failures, the Reflection Generator proposes superior alternatives for future iterations, ensuring continuous improvement. Additionally, it makes adjustments based on the current context and state, thereby optimizing the algorithm's performance and adaptability. This component plays a vital role in refining the decision-making process within the LATS framework.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">COMPONENT, ENTITY</data>
    </node>
    <node id="DELIBERATION">
      <data key="d0">CONCEPT, PROCESS</data>
      <data key="d1">A process in the LATS algorithm that leverages MCTS and the LM value function to ensure a principled search that selects options with high value while exploring promising alternatives.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, PROCESS</data>
    </node>
    <node id="GENERALITY">
      <data key="d0">CONCEPT, PROPERTY</data>
      <data key="d1">A property of the LATS algorithm that supports both reasoning and decision-making tasks by defining a shared space of thoughts and actions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, PROPERTY</data>
    </node>
    <node id="NOVEL VALUE FUNCTION">
      <data key="d0">FUNCTION, COMPONENT</data>
      <data key="d1">A new value function proposed for the LATS algorithm, based on a self-generated LM score and a self-consistency score, to improve value assignment.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="TASK COMPLETION">
      <data key="d0">CONCEPT, GOAL</data>
      <data key="d1">The objective of the LATS algorithm, where the agent's progress is quantified and evaluated to determine the success of a trajectory.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="HEURISTIC VALUE">
      <data key="d0">METRIC, COMPONENT</data>
      <data key="d1">A value used in the LATS algorithm to steer the search algorithm towards the most promising regions of the tree.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="COT-SC">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">COT-SC (Chain-of-Thought with Self-Critique) is a state-of-the-art, hand-designed agent used for reasoning and problem-solving tasks, as described by Wang et al. (2023b). This strategy is employed in Meta Agent Search to enhance the refinement of generated agents by utilizing multiple critics. COT-SC is a manually designed agent that is applied in various domains, including math, for planning and reasoning. It is a variant of the Chain-of-Thought (CoT) internal reasoning strategy, where five answers are sampled, and an ensemble is performed using either majority voting or an FM query. COT-SC is noted for its specific accuracy and F1 scores and is evaluated for performance, sample complexity, and token consumption. Additionally, it has been mentioned to have similar efficiency to LATS when the number of nodes is set to one.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,42de130f5b6144472a86a4c8260a87c7,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="AUSTIN ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Austin et al., 2022, are researchers who have made significant contributions to the field of programming and reasoning tasks. They are notably the authors of the MBPP dataset, which was published in 2022.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="GAME OF 24">
      <data key="d0">GAME, BENCHMARK</data>
      <data key="d1">The "GAME OF 24" is a mathematical reasoning challenge where the goal is to use basic arithmetic operations to construct the number 24 from four given numbers. It serves as a task to evaluate the reasoning and acting capabilities of algorithms, such as the LATS algorithm. Specifically, the LATS algorithm employs a self-consistency weight of 0.5 when tackling this task, highlighting its application in assessing the algorithm's reasoning ability.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">GAME, BENCHMARK</data>
    </node>
    <node id="API CALLS">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">API calls are used to search and retrieve information in the HotPotQA benchmark, forming part of the observation space.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, TOOL</data>
    </node>
    <node id="ORACLE SETUP">
      <data key="d0">EXPERIMENTAL SETUP</data>
      <data key="d1">An experimental setup in HotPotQA where the environment provides feedback about the answer&#8217;s correctness upon receiving an answer.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">EXPERIMENTAL SETUP</data>
    </node>
    <node id="DFS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">DFS (Depth-First Search) is a search algorithm utilized in various experimental and comparative contexts. It is employed as a variant in LATS experiments to observe its effects on performance. Additionally, DFS is mentioned as a variant compared to MCTS (Monte Carlo Tree Search) in the text, highlighting its role in algorithmic comparisons. Furthermore, DFS serves as a foundational search algorithm in the ToT (Tree of Thought) method, underscoring its versatility and importance in different algorithmic frameworks.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="PASS@1">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">Pass@1 is a performance measure used to evaluate the accuracy of algorithms like LATS on benchmarks like HumanEval.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">METRIC, PERFORMANCE MEASURE</data>
    </node>
    <node id="TRAJECTORIES">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">TRAJECTORIES refer to the paths or sequences of actions and states taken by agents or models during the exploration and search processes in various algorithms, such as LATS, ToT, and RAP. These trajectories are used to solve decision-making tasks and are evaluated during experiments. They encompass labeled sequences of environmental observations, thoughts, and actions, which are crucial for solving question-answering tasks. Specifically, in the context of algorithms like LATS, trajectories are sampled and analyzed during tasks such as the Game of 24 and HotPotQA.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="PROMPTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">PROMPTING is a technique used to guide language models in generating responses. It is employed in various tasks such as WebShop, Game of 24, and HotPotQA. In these contexts, prompting involves the use of algorithms like ReAct and LATS, often incorporating CoT (Chain of Thought) prompts to enhance the model's performance. This method is crucial for directing the behavior of advanced language models like GPT-3.5, ensuring they produce relevant and accurate outputs in complex scenarios.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="EXTERNAL RETRIEVAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">EXTERNAL RETRIEVAL is a strategy that involves retrieving information from external sources, particularly when the model's internal knowledge is insufficient. This approach is evaluated in LATS and utilizes various tools or methods to gather additional information, ensuring a more comprehensive understanding and response.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="FEEDBACK">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">FEEDBACK encompasses comments and suggestions provided to improve the code, including human-like and expert feedback. In the context of Meta Agent Search, feedback involves incorporating diverse feedback, evaluating for various specific traits, and simulating human-like feedback to refine answers more effectively. It is the response generated after running examples to evaluate the correctness of the initial solution. Additionally, feedback provides information about the correctness of an answer, which is used to enhance reasoning in Learning Algorithmic Thinking Systems (LATS). It also includes suggestions and comments provided by the verification module to improve the visual representation of a problem.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="REASONING-ONLY VERSION">
      <data key="d0">VARIANT, METHOD</data>
      <data key="d1">A version of LATS that focuses solely on internal reasoning without external feedback.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">VARIANT, METHOD</data>
    </node>
    <node id="INTEGRATION OF SEARCH ALGORITHMS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Combining search algorithms with LM agents to handle external observations, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="EXPERIMENTS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Tests conducted to demonstrate the general applicability of LATS across various domains.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="DOMAINS">
      <data key="d0">CATEGORY, FIELD</data>
      <data key="d1">DOMAINS refer to different areas or fields in which agents can be applied and tested. These areas require reasoning and acting, and include specific examples such as programming, HotPotQA, WebShop, and the Game of 24. These domains are used to evaluate LATS (Learning and Testing Systems), providing a comprehensive framework for assessing the capabilities and performance of agents in various complex tasks.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">CATEGORY, FIELD</data>
    </node>
    <node id="RETRIEVAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of obtaining information from external sources, used in benchmarks like HotPotQA.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="MULTI-HOP QUESTION-ANSWERING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A type of question-answering that requires retrieval over multiple passages, used in HotPotQA.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="WIKIPEDIA PASSAGES">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Text from Wikipedia used in the HotPotQA benchmark for multi-hop question-answering.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="FAILURE">
      <data key="d0">EVENT, OUTCOME</data>
      <data key="d1">An outcome where the initial prompt does not lead to a correct answer, prompting a switch to a different strategy in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">EVENT, OUTCOME</data>
    </node>
    <node id="TOOLS">
      <data key="d0">TECHNOLOGY, RESOURCE</data>
      <data key="d1">TOOLS are resources used to retrieve additional information when the answer is not already known, integrated into LATS. They are specific functionalities or resources that agents can use to perform tasks, which can be learned and optimized within agentic systems. Additionally, tools refer to technological resources like search engines and code interpreters used in conjunction with models like GPT-4 to generate high-quality data.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,dc55f071b95dec721a9820d39cdb3ccd,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, RESOURCE</data>
    </node>
    <node id="LARGE-SCALE TRAINING CORPUS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Extensive datasets used to train modern language models, enabling them to encode factual information.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="FACTUAL INFORMATION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Accurate data encoded in modern language models, used in reasoning and retrieval tasks.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="SEARCH">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">SEARCH is an action performed by the user to find specific products in the web shop. It involves looking for specific products or information within a system or platform. Additionally, SEARCH can return the first 5 sentences from the corresponding entity's wiki page or suggest the top-5 similar entities from the Wikipedia search engine. It is an application of reading comprehension that involves finding relevant information within a text or across multiple texts. Furthermore, SEARCH is a process of looking for information or solutions, which is a key component of LATS and other algorithms.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7,b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INFORMATION RETRIEVAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of obtaining information from external sources, a key component of LATS and other algorithms.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INTERACTIVE API ENVIRONMENT">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">An environment that allows the agent to interact with APIs to retrieve information, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, TOOL</data>
    </node>
    <node id="SELF-GENERATED REFLECTIONS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Reflections generated by the agent itself, forming part of the observation space in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="ORACLE">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">A setup that provides feedback about the correctness of an answer, used in HotPotQA.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, TOOL</data>
    </node>
    <node id="BASE SEARCH ALGORITHM">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The fundamental algorithm used for searching, such as DFS in ToT.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SAMPLING TRAJECTORIES">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of sampling paths or sequences of actions for evaluation, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="REASONING-BASED STRATEGIES">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Approaches that rely on internal reasoning to solve tasks, evaluated in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="ACTING-BASED STRATEGIES">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Approaches that involve taking actions based on reasoning, evaluated in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INTERNAL AND EXTERNAL REASONING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Combining internal knowledge and external information retrieval to solve tasks, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="PROMPTING DESIGNS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Different ways of structuring prompts to guide language models, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="CO-T BASED PROMPT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A prompt based on the CoT framework, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="REACT-BASED PROMPT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A prompt based on the ReAct framework, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="FAILURE SWITCH">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Switching from one prompting strategy to another upon failure, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="TOOLS FOR RETRIEVAL">
      <data key="d0">TECHNOLOGY, RESOURCE</data>
      <data key="d1">Resources used to retrieve additional information when the answer is not already known, integrated into LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, RESOURCE</data>
    </node>
    <node id="LARGE-SCALE TRAINING">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Training language models on extensive datasets to encode factual information.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="ENCODING FACTUAL INFORMATION">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The process of embedding accurate data into language models during training.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="REASONING AND ACTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The combined process of thinking through problems and taking actions, a key component of LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="PLANNING IN LANGUAGE MODELS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of strategizing actions to achieve a goal, integrated into LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SEARCHING FOR SOLUTIONS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of looking for information or solutions, a key component of LATS and other algorithms.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="DECISION-MAKING IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of making choices based on reasoning and information retrieval, evaluated in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INFORMATION RETRIEVAL IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of obtaining information from external sources, a key component of LATS and other algorithms.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INTERACTIVE API ENVIRONMENT IN LATS">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">An environment that allows the agent to interact with APIs to retrieve information, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, TOOL</data>
    </node>
    <node id="SELF-GENERATED REFLECTIONS IN LATS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Reflections generated by the agent itself, forming part of the observation space in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="ORACLE SETUP IN HOTPOTQA">
      <data key="d0">EXPERIMENTAL SETUP</data>
      <data key="d1">An experimental setup in HotPotQA where the environment provides feedback about the answer&#8217;s correctness upon receiving an answer.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">EXPERIMENTAL SETUP</data>
    </node>
    <node id="BASE SEARCH ALGORITHM IN TOT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The fundamental algorithm used for searching, such as DFS in ToT.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SAMPLING TRAJECTORIES IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of sampling paths or sequences of actions for evaluation, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="EXPANSION PHASE IN LATS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The phase in LATS where nodes are sampled during evaluation.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="EXTERNAL FEEDBACK IN LATS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Information from external sources used to enhance reasoning in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="REASONING-BASED STRATEGIES IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Approaches that rely on internal reasoning to solve tasks, evaluated in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="ACTING-BASED STRATEGIES IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Approaches that involve taking actions based on reasoning, evaluated in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INTERNAL AND EXTERNAL REASONING IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Combining internal knowledge and external information retrieval to solve tasks, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="PROMPTING DESIGNS IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Different ways of structuring prompts to guide language models, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="CO-T BASED PROMPT IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A prompt based on the CoT framework, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="REACT-BASED PROMPT IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A prompt based on the ReAct framework, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="FAILURE SWITCH IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Switching from one prompting strategy to another upon failure, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="TOOLS FOR RETRIEVAL IN LATS">
      <data key="d0">TECHNOLOGY, RESOURCE</data>
      <data key="d1">Resources used to retrieve additional information when the answer is not already known, integrated into LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, RESOURCE</data>
    </node>
    <node id="LARGE-SCALE TRAINING IN LATS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Training language models on extensive datasets to encode factual information.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="ENCODING FACTUAL INFORMATION IN LATS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The process of embedding accurate data into language models during training.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="REASONING AND ACTING IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The combined process of thinking through problems and taking actions, a key component of LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="MBPP">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MBPP (Mostly Basic Python Programming) is a dataset used to measure the correctness of synthesized programs in Python from natural language docstrings.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="FURUTA ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Furuta et al., 2024, are the authors of a study published in 2024 that involves fine-tuning methods for performance evaluation. Their work focuses on developing and analyzing fine-tuning techniques to enhance performance metrics, contributing valuable insights to the field of algorithmic optimization and evaluation.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="EXPERT">
      <data key="d0">HUMAN, BENCHMARK</data>
      <data key="d1">EXPERT refers to human performance benchmarks used for comparison in various tasks. These benchmarks are specifically utilized to compare the effectiveness of algorithms such as LATS, ReAct, and Reflexion in tasks like WebShop.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="FINE-TUNING">
      <data key="d0" />
      <data key="d1">Fine-tuning is a technique used to improve the performance of language models and algorithms, as studied by Furuta et al. in 2024.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="SEARCH METHODS">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Search methods like ToT and RAP involve sampling and exploring multiple outputs to improve performance on reasoning tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="REASONING SETTING">
      <data key="d0">TASK, SETTING</data>
      <data key="d1">Reasoning setting refers to tasks or environments where the primary focus is on logical reasoning and problem-solving.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="ACTING-BASED METHODS">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Acting-based methods involve incorporating observations and external feedback into the decision-making process to improve performance.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="COMPUTATIONAL COSTS">
      <data key="d0">ATTRIBUTE, CONSTRAINT</data>
      <data key="d1">Computational costs refer to the resources, such as time and processing power, required to run an algorithm or model.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="INFERENCE COSTS">
      <data key="d0">ATTRIBUTE, CONSTRAINT</data>
      <data key="d1">Inference costs refer to the resources required to make predictions or decisions using a trained model.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="PASS@1 ACCURACY">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Pass@1 accuracy is a metric used to evaluate the correctness of the first solution generated by a model in programming tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="SYNTHETIC TEST SUITE">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">A synthetic test suite consists of automatically generated test cases used to evaluate the correctness of solutions in programming tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="ASSERT STATEMENTS">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Assert statements are syntactically valid test cases used in a synthetic test suite to check the correctness of a program.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="ACTION SPACE">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">Action space refers to the set of all possible actions or solutions that a model can choose from during the decision-making process.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="COMPILER FEEDBACK">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Compiler feedback includes the results of compiling and running a program, such as successful and failed tests, which are used as external observations.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="BACKPROPAGATED REWARD">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">Backpropagated reward refers to the feedback signal used to update the model's parameters based on the success or failure of actions taken during the search process.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="SOLUTION SELECTION">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Solution selection involves choosing the best solution from a set of generated solutions based on evaluation metrics like pass@1 accuracy.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="REAL TEST SUITE">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">A real test suite consists of actual test cases used to evaluate the final solution generated by a model in programming tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="BASELINE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Baseline refers to the standard or reference performance against which new methods or models are compared.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="RL-BASED TRAINING">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">RL-based training (Reinforcement Learning) is a method used to train agents in environments like WebShop, where it is compared against LATS for performance metrics. This training involves using reinforcement learning techniques to train models for better performance on specific tasks.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="HUMAN PERFORMANCE">
      <data key="d0">BENCHMARK, METRIC</data>
      <data key="d1">Human performance serves as a benchmark for evaluating the effectiveness of models and algorithms in various tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="HOT POT QA">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">HotPotQA is a question-answering task used to evaluate the performance of algorithms like LATS and its variants. It involves reasoning and requires multiple components for optimal performance.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="IMPROVEMENT">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Improvement refers to the enhancement in performance metrics such as score and success rate (SR) when using algorithms like LATS in various tasks and environments. It encompasses suggestions and actions taken to refine and optimize the existing implementation of the proposed architecture to increase its performance or effectiveness.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,594449768ae2dea9b2efbe677075096b</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="A*">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">A* is a search algorithm mentioned as a variant in LATS experiments, compared to MCTS for performance gains.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TOKEN CONSUMPTION">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Token consumption is a metric used to evaluate the computational cost of different methods such as LATS, ToT, and RAP. It specifically refers to the number of tokens used in language model operations, and is evaluated in LATS experiments to determine efficiency.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="SEMANTIC FEEDBACK">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Semantic feedback refers to the meaningful information provided to the agent to improve its performance, used in algorithms like Reflexion and LATS.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
      <data key="d3">CONCEPT, TECHNIQUE</data>
    </node>
    <node id="LOCAL MINIMA">
      <data key="d0">CONCEPT, CHALLENGE</data>
      <data key="d1">Local minima refer to suboptimal points where the agent may get stuck during exploration, a challenge observed in Reflexion and addressed by LATS.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
      <data key="d3">CONCEPT, CHALLENGE</data>
    </node>
    <node id="EXPLORATION">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Exploration refers to the process of searching through possible actions to find optimal solutions, a key component in algorithms like LATS and MCTS.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
      <data key="d3">CONCEPT, TECHNIQUE</data>
    </node>
    <node id="ITERATIONS">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Iterations refer to the number of times an algorithm or agent repeats a process to achieve a result. In the context of LATS experiments, iterations are used as a metric to measure how many times an algorithm processes data to improve performance. This iterative approach is crucial for refining the algorithm's effectiveness and ensuring optimal outcomes.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="SUCCESS RATE">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Success rate (SR) is a performance metric indicating the frequency with which the chosen product or solution fulfills all given conditions. It is used to evaluate algorithms such as LATS in WebShop and other tasks. Additionally, success rate is employed to assess the effectiveness of generated agents in the Meta Agent Search algorithm. Furthermore, it measures the rate at which an agent successfully completes the Game of 24 by constructing the correct equation.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="SCORE">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">SCORE is a numeric value representing the performance of models, ranging from 0 to 10, with GPT-4 scoring a perfect 10. It serves as a performance metric reflecting the percentage of user-specified attributes met by the selected product or solution. This metric is used to evaluate algorithms like LATS in WebShop and other tasks, ensuring a comprehensive assessment of their effectiveness and alignment with user requirements.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="IL+RL">
      <data key="d0" />
      <data key="d1">IL+RL is a combined approach of imitation learning and reinforcement learning, used to train agents in environments like WebShop, evaluated for its performance in comparison to other methods.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="PROMPT METHOD">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The PROMPT METHOD is a technique that guides an agent in performing tasks such as the Game of 24 and HotPotQA by utilizing specifically designed prompts. This method involves the strategic creation and application of prompts to effectively direct language models in executing these tasks. By tailoring the prompts to the requirements of each task, the PROMPT METHOD ensures that the language models can navigate and solve complex problems with greater accuracy and efficiency.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SUCCESS RATE (SR)">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">SUCCESS RATE (SR) is a performance metric used in WebShop to capture the portion of successful episodes. It indicates the frequency with which the chosen product or solution fulfills all given conditions, serving as a key measure to evaluate algorithms like LATS in WebShop and other tasks. Specifically, SR represents the portion of instructions where the reward equals 1, signifying the successful completion of the task.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="AVERAGE SCORE">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Average score is a performance metric reflecting the percentage of user-specified attributes met by the selected product or solution, used to evaluate algorithms like LATS in WebShop and other tasks.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="BROWSER FEEDBACK">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Browser feedback refers to the information provided by the web interface during navigation, used by agents to make decisions in environments like WebShop.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="SEARCH AND CLICK COMMANDS">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Search and click commands are actions used by agents to navigate and interact with the web interface in environments like WebShop.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="PRECONSTRUCTED ACTION SPACE">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Preconstructed action space refers to the predefined set of actions available to agents for navigation and decision-making in environments like WebShop.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="CHILDREN">
      <data key="d0">CONCEPT, COMPONENT</data>
      <data key="d1">Children refer to the expanded nodes in the search tree during the exploration process in algorithms like LATS, used in tasks like Game of 24 and HotPotQA.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="PRUNING">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Pruning refers to the method of removing low-value branches from the search tree to focus on more promising paths, used in algorithms like LATS and ToT.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="ZHUANG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhuang et al. are the authors mentioned in the context of the A* algorithm, published in 2023.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SAMPLE COMPLEXITY">
      <data key="d0">METRIC, PERFORMANCE INDICATOR</data>
      <data key="d1">Sample complexity is a metric indicating the number of samples needed for an algorithm to achieve a certain level of performance. It is also used to evaluate the asymptotic token cost of different methods such as LATS, ToT, and RAP. Notably, LATS has the same sample complexity as ToT and RAP but achieves better performance.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="NODES EXPANDED">
      <data key="d0">METRIC, PERFORMANCE INDICATOR</data>
      <data key="d1">Nodes expanded is a metric used to evaluate the number of nodes expanded by different methods like LATS, ToT, and RAP upon successful search.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="REVERSION PROPERTY">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">The reversion property is a crucial feature in decision-making environments, particularly within the framework of LATS (an unspecified system or algorithm). This property enables the system to revert to earlier states, thereby enhancing its flexibility and adaptability. By allowing the system to return to previous states, the reversion property makes LATS applicable to a wide range of real-world scenarios, ensuring robust performance and reliability in dynamic and complex environments.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SYSTEM-2 LM APPROACHES">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">SYSTEM-2 LM APPROACHES refer to advanced language model techniques that involve high-level reasoning and decision-making processes, as opposed to simple autoregressive generation. These approaches are characterized by their ability to handle more complex reasoning and decision-making tasks, such as those exemplified by techniques like LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="PERFORMANCE">
      <data key="d0">METRIC, PERFORMANCE INDICATOR</data>
      <data key="d1">Performance is a measure of how well an agent completes a task or solves a problem, often used to evaluate and refine agents. It is a metric used to evaluate the effectiveness of different methods like LATS, ToT, and RAP. Additionally, performance serves as an objective in the evaluation function of ADAS to assess the effectiveness of agentic systems. It refers to the effectiveness and efficiency of agentic systems in completing tasks, often measured against benchmarks and baselines.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="COMPUTATIONAL COST">
      <data key="d0">METRIC, PERFORMANCE INDICATOR</data>
      <data key="d1">Computational cost is a metric used to evaluate the resource consumption of different methods such as LATS, ToT, and RAP. It is a significant limitation of the LATS algorithm, indicating that LATS requires more computational resources compared to simpler prompting methods like ReAct or Reflexion. This highlights the importance of considering computational cost when choosing between various algorithmic approaches, as it directly impacts the efficiency and feasibility of implementing these methods.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SELECTION OPERATION">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Selection operation is a process in search algorithms where the next node to explore is chosen based on certain criteria.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="BACKPROPAGATION OPERATION">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Backpropagation operation is a process in search algorithms where the results of a search are propagated back through the tree to update the values of nodes.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="GROUND-TRUTH FEEDBACK">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Ground-truth feedback refers to accurate and reliable information used to improve the performance of methods like LATS, ToT, and RAP.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="INFERENCE-TIME COMPUTE COSTS">
      <data key="d0">METRIC, PERFORMANCE INDICATOR</data>
      <data key="d1">Inference-time compute costs refer to the computational resources required during the inference phase of a language model's operation. These costs are expected to decrease over time, which will increase the usefulness of advanced language model approaches like LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRADE-OFF BETWEEN PERFORMANCE AND EFFICIENCY">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Trade-off between performance and efficiency refers to the balance between achieving high performance and maintaining low computational costs in methods like LATS.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="AUTONOMOUS DECISION-MAKING">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Autonomous decision-making refers to the ability of methods like LATS to make decisions without human intervention.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="PROMPTING TECHNIQUES">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Prompting techniques are important building blocks for agentic systems, used to guide the behavior of agents. These techniques refer to methods employed to direct language models in generating responses. Examples of such methods include ReAct and Reflexion.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="REASONING ABILITY">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Reasoning ability refers to the capability of methods like LATS to perform logical and analytical thinking to solve problems.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="EXPERIENCE LEARNING">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Experience learning refers to the process of improving performance by learning from past actions and outcomes, used in methods like LATS.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SYSTEM-2 LM">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">System-2 LM refers to advanced language models that involve complex reasoning and decision-making processes, like LATS.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="REAL-WORLD APPLICATIONS">
      <data key="d0">APPLICATION, USE CASE</data>
      <data key="d1">Real-world applications refer to practical scenarios where LATS (Learning Automata and Temporal Sequences) and similar algorithms can be applied, potentially opening up new opportunities in the LM (Learning Machines) decision-making community. These applications also encompass the practical use of agentic systems in various domains and industries, demonstrating their effectiveness and utility. By integrating these advanced algorithms and systems, real-world applications highlight the tangible benefits and innovative solutions that can be achieved across different sectors.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LM DECISION-MAKING COMMUNITY">
      <data key="d0">COMMUNITY, FIELD</data>
      <data key="d1">The LM decision-making community consists of researchers and practitioners focused on improving the decision-making capabilities of language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DANIEL CAMPOS">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Daniel Campos is a researcher who provided useful feedback on earlier versions of the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NSF GRANT 2106825">
      <data key="d0">FUNDING, GRANT</data>
      <data key="d1">NSF Grant 2106825 is a funding source that supported the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NIFA AWARD 2020-67021-32799">
      <data key="d0">FUNDING, AWARD</data>
      <data key="d1">NIFA Award 2020-67021-32799 is a funding source that supported the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JUMP ARCHES ENDOWMENT">
      <data key="d0">FUNDING, ENDOWMENT</data>
      <data key="d1">The Jump ARCHES endowment is a funding source through the Health Care Engineering Systems Center at Illinois and the OSF Foundation that supported the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="IBM-ILLINOIS DISCOVERY ACCELERATOR INSTITUTE">
      <data key="d0">ORGANIZATION, INSTITUTE</data>
      <data key="d1">The IBM-Illinois Discovery Accelerator Institute is an organization that supported the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NVIDIA GPUS">
      <data key="d0">TECHNOLOGY, HARDWARE</data>
      <data key="d1">NVIDIA GPUs are graphical processing units used at NCSA Delta through allocations from the ACCESS program to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NCSA DELTA">
      <data key="d0">ORGANIZATION, FACILITY</data>
      <data key="d1">NCSA Delta is a facility that provided NVIDIA GPUs through allocations from the ACCESS program to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ACCESS PROGRAM">
      <data key="d0">PROGRAM, INITIATIVE</data>
      <data key="d1">The ACCESS program provided allocations of NVIDIA GPUs at NCSA Delta to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="MICHAEL AHN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Michael Ahn is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ANTHONY BROHAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Anthony Brohan is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="NOAH BROWN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Noah Brown is a researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models," which was presented at CoRL 2022. Additionally, Noah Brown is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="YEVGEN CHEBOTAR">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Yevgen Chebotar is a researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models," which was presented at CoRL 2022. Additionally, Yevgen Chebotar is referenced in the paper discussing LATS, highlighting his contributions to the field of algorithmic analysis and planning with language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="OMAR CORTES">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Omar Cortes is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="BYRON DAVID">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Byron David is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CHELSEA FINN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Chelsea Finn is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model," which was published in Advances in Neural Information Processing Systems in 2024. Additionally, Chelsea Finn is referenced in another paper discussing LATS.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CHUYUAN FU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Chuyuan Fu is an author who contributed to the paper "Language to rewards for robotic skill synthesis." Additionally, Chuyuan Fu is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="KEERTHANA GOPALAKRISHNAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Keerthana Gopalakrishnan is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="KAROL HAUSMAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Karol Hausman is a researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models," which was presented at CoRL 2022. Additionally, Karol Hausman is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ALEX HERZOG">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Alex Herzog is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="DANIEL HO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Daniel Ho is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JASMINE HSU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jasmine Hsu is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JULIAN IBARZ">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Julian Ibarz is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="BRIAN ICHTER">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Brian Ichter is a researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models," which was presented at CoRL 2022. Additionally, he is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ALEX IRPAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Alex Irpan is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ROSARIO JAUREGUI RUANO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Rosario Jauregui Ruano is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="KYLE JEFFREY">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Kyle Jeffrey is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="SALLY JESMONTH">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Sally Jesmonth is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="NIKHIL J JOSHI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Nikhil J Joshi is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="RYAN JULIAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Ryan Julian is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="DMITRY KALASHNIKOV">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Dmitry Kalashnikov is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="YUHENG KUANG">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Yuheng Kuang is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="KUANG-HUEI LEE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Kuang-Huei Lee is a researcher and author who has made significant contributions to the field of algorithmic analysis and artificial intelligence. He co-authored the paper "Multimodal web navigation with instruction-finetuned foundation models," which was presented at ICLR 2024. Additionally, he contributed to the paper "Language to rewards for robotic skill synthesis," showcasing his expertise in robotic skill development. Kuang-Huei Lee is also referenced in the paper discussing LATS, further highlighting his involvement in advanced research topics within the community.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="SERGEY LEVINE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Sergey Levine is a prominent researcher and co-author of several influential papers. He contributed to the paper "Inner monologue: Embodied reasoning through planning with language models," which was presented at CoRL 2022. In 2023, he co-authored a paper on the false promise of imitating proprietary LLMs. Additionally, Sergey Levine is referenced in a paper discussing LATS, highlighting his significant impact and involvement in the field of algorithmic research and language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="YAO LU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Yao Lu is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="LINDA LUU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Linda Luu is a researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models," which was presented at CoRL 2022. Additionally, she is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CAROLINA PARADA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Carolina Parada is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="PETER PASTOR">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Peter Pastor is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JORNELL QUIAMBAO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jornell Quiambao is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="KANISHKA RAO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Kanishka Rao is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JAREK RETTINGHOUSE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jarek Rettinghouse is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="DIEGO REYES">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Diego Reyes is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="PIERRE SERMANET">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Pierre Sermanet is a researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models," which was presented at CoRL 2022. Additionally, Pierre Sermanet is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="NICOLAS SIEVERS">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Nicolas Sievers is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CLAYTON TAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Clayton Tan is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ALEXANDER TOSHEV">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Alexander Toshev is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="VINCENT VANHOUCKE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Vincent Vanhoucke is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="FEI XIA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Fei Xia is an author who contributed to the paper "Chain-of-thought prompting elicits reasoning in large language models." Additionally, Fei Xia is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="TED XIAO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Ted Xiao is a researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models," which was presented at CoRL 2022. Additionally, Ted Xiao is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="PENG XU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Peng Xu is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="SICHUN XU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Sichun Xu is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MENGYUAN YAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Mengyuan Yan is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ANDY ZENG">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Andy Zeng is a researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models," which was presented at CoRL 2022. Additionally, Andy Zeng is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JACOB AUSTIN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jacob Austin is an author who contributed to the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR) in 2023. Additionally, Jacob Austin is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="AUGUSTUS ODENA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Augustus Odena is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MAXWELL NYE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Maxwell Nye is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MAARTEN BOSMA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Maarten Bosma is an author who has made significant contributions to the field of artificial intelligence and language models. He co-authored the paper "Chain-of-thought prompting elicits reasoning in large language models" and contributed to the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR) in 2023. Additionally, Maarten Bosma is referenced in a paper discussing LATS, further highlighting his involvement in advancing research in AI and language modeling.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="HENRYK MICHALEWSKI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Henryk Michalewski is an author who contributed to the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR) in 2023. Additionally, he is one of the authors referenced in a paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="DAVID DOHAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">David Dohan is an author who contributed to the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR) in 2023. Additionally, David Dohan is referenced as one of the authors in a paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ELLEN JIANG">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Ellen Jiang is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CARRIE CAI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Carrie Cai is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MICHAEL TERRY">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Michael Terry is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="QUOC LE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Quoc Le is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is one of the authors of the paper "Least-to-most prompting enables complex reasoning in large language models" presented at ICLR 2022. Additionally, Quoc Le is referenced in the paper discussing LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,4ae237a491bc8a84cc720e40c59a7464,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CHARLES SUTTON">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Charles Sutton is an author who contributed to the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR) in 2023. Additionally, Charles Sutton is referenced in a paper discussing LATS, indicating his involvement in multiple significant research efforts within the field of machine learning and language modeling.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="BOWEN BAKER">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Bowen Baker is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ILGE AKKAYA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Ilge Akkaya is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="PETER ZHOKHOV">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Peter Zhokhov is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JOOST HUIZINGA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Joost Huizinga is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JIE TANG">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jie Tang is a researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024. Additionally, Jie Tang is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ADRIEN ECOFFET">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Adrien Ecoffet is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="BRANDON HOUGHTON">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Brandon Houghton is a researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019. Additionally, he is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="RAUL SAMPEDRO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Raul Sampedro is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JEFF CLUNE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jeff Clune is a prolific author and researcher affiliated with the University of British Columbia, the Vector Institute, and holds a Canada CIFAR AI Chair. He has made significant contributions to the field of artificial intelligence and machine learning, as evidenced by his extensive publication record. Notably, he co-authored the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions." He also contributed to "OMNI: Open-endedness via models of human notions of interestingness," which was presented at The Twelfth International Conference on Learning Representations in 2024.

In addition, Jeff Clune co-authored "Designing neural networks through neuroevolution," published in Nature Machine Intelligence in 2019, and "Thought Cloning: Learning to think while acting by imitating human thinking," published in Advances in Neural Information Processing Systems in 2024. His work also includes contributions to the paper on Automated Design of Agentic Systems and a reference in a paper discussing LATS.

Furthermore, he is one of the authors of "Intelligent go-explore: Standing on the shoulders of giant foundation models," published as an arXiv preprint in 2024, and "Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence," published as an arXiv preprint in 2019. Jeff Clune's research spans various innovative approaches in AI, emphasizing open-endedness, neuroevolution, and the development of general artificial intelligence.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,4ae237a491bc8a84cc720e40c59a7464,6109537356a2ce2339f77c827aa3668e,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MACIEJ BESTA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Maciej Besta is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="NILS BLACH">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Nils Blach is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ALES KUBICEK">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Ales Kubicek is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ROBERT GERSTENBERGER">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Robert Gerstenberger is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="LUKAS GIANINAZZI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Lukas Gianinazzi is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JOANNA GAJDA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Joanna Gajda is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="TOMASZ LEHMANN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Tomasz Lehmann is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MICHAL PODSTAWSKI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Michal Podstawski is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="HUBERT NIEWIADOMSKI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Hubert Niewiadomski is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="PIOTR NYCZYK">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Piotr Nyczyk is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="TORSTEN HOEFLER">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Torsten Hoefler is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="SAMUEL R BOWMAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Samuel R Bowman is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="GABOR ANGELI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Gabor Angeli is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CHRISTOPHER POTTS">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Christopher Potts is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CHRISTOPHER D MANNING">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Christopher D. Manning is a notable figure in the field of computational linguistics and artificial intelligence. He is one of the authors of the paper titled "Direct preference optimization: Your language model is secretly a reward model," which was published in Advances in Neural Information Processing Systems in 2024. Additionally, his work is referenced in discussions about LATS, indicating his significant contributions to the development and understanding of language models and their optimization.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="TOM B BROWN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Tom B Brown is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="BENJAMIN MANN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Benjamin Mann is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="NICK RYDER">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Nick Ryder is an author who contributed to the paper "Evaluating large language models trained on code," which was published on arXiv in 2021. Additionally, Nick Ryder is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MELANIE SUBBIAH">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Melanie Subbiah is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JARED KAPLAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jared Kaplan is an author who contributed to the paper "Evaluating large language models trained on code," which was published on arXiv in 2021. He is also referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="EFFICIENCY">
      <data key="d0">ATTRIBUTE, METRIC</data>
      <data key="d1">Efficiency is a specific trait evaluated by experts in the feedback mechanism of ADAS (Advanced Driver Assistance Systems), focusing on how effectively a task is performed. It refers to the ability of LATS (Learning and Adaptive Systems) to perform tasks with minimal resource usage, balancing performance and computational cost. Additionally, efficiency in agentic systems is characterized by their ability to achieve goals with minimal resources and time, highlighting a key advantage of automated design in ADAS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="TRADE-OFF">
      <data key="d0">CONCEPT, PRINCIPLE</data>
      <data key="d1">Trade-off refers to the balance between performance and efficiency in LATS, where increasing one may decrease the other.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="SCALING">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Scaling refers to the process of expanding LATS to handle more complex environments or multi-agent frameworks.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="COSTS">
      <data key="d0">RESOURCE, METRIC</data>
      <data key="d1">Costs refer to the computational and financial resources required to run LATS and similar algorithms.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="APPENDIX SEC. B">
      <data key="d0">DOCUMENT, SECTION</data>
      <data key="d1">Appendix Sec. B is a section in the paper that provides a more detailed discussion about the limitations of LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="IMPACT STATEMENT">
      <data key="d0">DOCUMENT, SECTION</data>
      <data key="d1">The Impact Statement is a section in the paper that discusses the potential positive and negative consequences of using LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="INTERPRETABILITY">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">Interpretability refers to the ability to understand and explain the decisions made by LATS, enhancing its alignment with human reasoning.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ALIGNMENT">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">Alignment refers to the degree to which LATS' actions and decisions are consistent with human values and goals.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="SECURITY RISKS">
      <data key="d0">CONCERN, ISSUE</data>
      <data key="d1">Security risks refer to the potential dangers associated with enhancing the capabilities of LM agents, such as executing malware.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="RISKS">
      <data key="d0">CONCERN, ISSUE</data>
      <data key="d1">Risks refer to the potential negative consequences of using LATS, including harmful uses and security threats.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="RESEARCH">
      <data key="d0">ACTIVITY, FIELD</data>
      <data key="d1">Research refers to the systematic investigation into and study of materials and sources to establish facts and reach new conclusions, particularly in understanding and mitigating the risks of LMs.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NIFA">
      <data key="d0">ORGANIZATION, FUNDING AGENCY</data>
      <data key="d1">NIFA (National Institute of Food and Agriculture) is an organization that provided funding for the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="HEALTH CARE ENGINEERING SYSTEMS CENTER">
      <data key="d0">ORGANIZATION, CENTER</data>
      <data key="d1">The Health Care Engineering Systems Center at Illinois is an organization that supported the research work on LATS through the Jump ARCHES endowment.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="OSF FOUNDATION">
      <data key="d0">ORGANIZATION, FOUNDATION</data>
      <data key="d1">The OSF Foundation is an organization that supported the research work on LATS through the Jump ARCHES endowment.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CIS220014">
      <data key="d0">ALLOCATION, RESOURCE</data>
      <data key="d1">CIS220014 is an allocation from the ACCESS program that provided NVIDIA GPUs at NCSA Delta to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CIS230012">
      <data key="d0">ALLOCATION, RESOURCE</data>
      <data key="d1">CIS230012 is an allocation from the ACCESS program that provided NVIDIA GPUs at NCSA Delta to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CIS230218">
      <data key="d0">ALLOCATION, RESOURCE</data>
      <data key="d1">CIS230218 is an allocation from the ACCESS program that provided NVIDIA GPUs at NCSA Delta to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="AMODEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amodei is an author who contributed to the paper "Language models are few-shot learners" presented at NeurIPS in 2020.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NEURIPS">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">NeurIPS (Neural Information Processing Systems) is a prominent conference renowned for presenting cutting-edge research in the field of artificial intelligence and machine learning. Notable papers such as "Language models are few-shot learners" and "Self-refine: Iterative refinement with self-feedback," the latter published in 2023, have been showcased at this prestigious event. NeurIPS serves as a critical platform for researchers to disseminate their findings and advance the state of knowledge in neural information processing systems.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MURRAY CAMPBELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Murray Campbell is an author who contributed to the paper "Deep blue" on artificial intelligence in 2002.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="A JOSEPH HOANE JR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A Joseph Hoane Jr is an author who contributed to the paper "Deep blue" on artificial intelligence in 2002.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FENG-HSIUNG HSU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Feng-hsiung Hsu is an author who contributed to the paper "Deep blue" on artificial intelligence in 2002.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DEEP BLUE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper on artificial intelligence authored by Murray Campbell, A Joseph Hoane Jr, and Feng-hsiung Hsu in 2002.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE">
      <data key="d0">FIELD, TECHNOLOGY</data>
      <data key="d1">A field of study and technology focused on creating intelligent agents and systems, discussed in the paper "Deep blue."</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BEI CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bei Chen is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FENGJI ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fengji Zhang is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANH NGUYEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anh Nguyen is an author who has made significant contributions to the field of algorithmic analysis and code generation. Notably, Anh Nguyen co-authored the paper "CodeT: Code generation with generated tests," which was presented at the International Conference on Learning Representations (ICLR) in 2023. Additionally, Anh Nguyen is one of the authors of the Phi-3 technical report, further showcasing their expertise and active involvement in advancing research within this domain.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DAOGUANG ZAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daoguang Zan is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ZEQI LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zeqi Lin is an author who has made significant contributions to the field of algorithmic analysis and code generation. Notably, Zeqi Lin co-authored the paper "CodeT: Code generation with generated tests," which was presented at the International Conference on Learning Representations (ICLR) in 2023. Additionally, Zeqi Lin is one of the authors of the Phi-3 technical report, further showcasing their expertise and active involvement in advancing research within this domain.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIAN-GUANG LOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jian-Guang Lou is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WEIZHU CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weizhu Chen is an author who has made significant contributions to the field of algorithmic analysis and artificial intelligence. In 2023, Chen co-authored the paper "CodeT: Code generation with generated tests," which was presented at the International Conference on Learning Representations (ICLR). Additionally, Chen contributed to the Phi-3 technical report and co-authored the paper "Agieval: A human-centric benchmark for evaluating foundation models," also published in 2023. These works highlight Chen's active involvement in advancing research on code generation, technical reporting, and the evaluation of foundation models.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CODET: CODE GENERATION WITH GENERATED TESTS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper presented at ICLR in 2023, authored by Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu Chen, discussing code generation with generated tests.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ICLR">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">ICLR (International Conference on Learning Representations) is a prominent conference known for presenting cutting-edge research in the field of machine learning and artificial intelligence. Notable papers presented at ICLR include "CodeT: Code generation with generated tests" and "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," the latter of which was published in 2024. This conference serves as a significant platform for researchers to share their innovative work and advancements in learning representations.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MARK CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mark Chen is an author who contributed to multiple papers published in 2021. He is one of the authors of the paper "Evaluating large language models trained on code," which was published on arXiv. Additionally, he co-authored a paper on training verifiers to solve math word problems.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JERRY TWOREK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jerry Tworek is an author who contributed to multiple papers published in 2021. He co-authored the paper "Evaluating large language models trained on code," which was published on arXiv. Additionally, he is one of the authors of a paper focused on training verifiers to solve math word problems.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HEEWOO JUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heewoo Jun is an author who contributed to multiple papers published in 2021. He is one of the authors of the paper "Evaluating large language models trained on code," which was published on arXiv. Additionally, he co-authored a paper on training verifiers to solve math word problems.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="QIMING YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qiming Yuan is an author who contributed to the paper titled "Evaluating large language models trained on code," which was published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="HENRIQUE PONDE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Henrique Ponde is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HARRISON EDWARDS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Harrison Edwards is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YURA BURDA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yura Burda is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NICHOLAS JOSEPH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicholas Joseph is an author who contributed to the paper titled "Evaluating large language models trained on code," which was published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="GREG BROCKMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Greg Brockman is an author who contributed to the paper "Evaluating large language models trained on code," which was published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="ALEX RAY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alex Ray is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="RAUL PURI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Raul Puri is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GRETCHEN KRUEGER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gretchen Krueger is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MICHAEL PETROV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Petrov is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HEIDY KHLAAF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heidy Khlaaf is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GIRISH SASTRY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Girish Sastry is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PAMELA MISHKIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pamela Mishkin is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BROOKE CHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brooke Chan is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SCOTT GRAY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Scott Gray is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MIKHAIL PAVLOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mikhail Pavlov is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALETHEA POWER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alethea Power is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="LUKASZ KAISER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lukasz Kaiser is an author who has made significant contributions to the field of algorithmic analysis and machine learning. In 2021, he co-authored the paper "Evaluating large language models trained on code," which was published on arXiv. Additionally, in the same year, he contributed to another influential paper focused on training verifiers to solve math word problems. His work demonstrates a strong commitment to advancing the understanding and capabilities of large language models and their applications in solving complex problems.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MOHAMMAD BAVARIAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mohammad Bavarian is an author who has made significant contributions to the field of algorithmic analysis and machine learning. In 2021, he co-authored the paper "Evaluating large language models trained on code," which was published on arXiv. Additionally, in the same year, he contributed to another influential paper focused on training verifiers to solve math word problems. His work demonstrates a strong commitment to advancing the understanding and application of large language models and algorithmic problem-solving techniques.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CLEMENS WINTER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Clemens Winter is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PHILIPPE TILLET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Philippe Tillet is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FELIPE PETROSKI SUCH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Felipe Petroski Such is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DAVID W. CUMMINGS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David W. Cummings is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MATTHIAS PLAPPERT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matthias Plappert is an author who has made significant contributions to the field of algorithmic analysis and machine learning. In 2021, he co-authored the paper "Evaluating large language models trained on code," which was published on arXiv. Additionally, in the same year, he contributed to another paper focused on training verifiers to solve math word problems. His work demonstrates a strong commitment to advancing the understanding and application of large language models and their capabilities in solving complex problems.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="FOTIOS CHANTZIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fotios Chantzis is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ELIZABETH BARNES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Elizabeth Barnes is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ARIEL HERBERT-VOSS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ariel Herbert-Voss is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WILLIAM H. GUSS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">William H. Guss is a researcher and author known for his contributions to the field of artificial intelligence and machine learning. He co-authored the paper "MineRL: A large-scale dataset of Minecraft demonstrations," which was presented at the International Joint Conference on Artificial Intelligence (IJCAI) in 2019. Additionally, he contributed to the paper "Evaluating large language models trained on code," published on arXiv in 2021. His work spans the development and evaluation of large-scale datasets and models, particularly in the context of gaming environments and code analysis.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEX NICHOL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alex Nichol is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="IGOR BABUSCHKIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Igor Babuschkin is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SUCHIR BALAJI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Suchir Balaji is an author who has made significant contributions to the field of artificial intelligence and machine learning. He co-authored the paper "WebGPT: Browser-assisted question-answering with human feedback," which was published as an arXiv preprint in 2021. Additionally, he contributed to the paper "Evaluating large language models trained on code," also published on arXiv in 2021. These works highlight his involvement in advancing the understanding and development of AI systems, particularly in the areas of question-answering and the evaluation of language models trained on code.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SHANTANU JAIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shantanu Jain is an author who has made significant contributions to the field of artificial intelligence and machine learning. He is one of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021. Additionally, he contributed to the paper "Evaluating large language models trained on code," also published on arXiv in 2021. These works highlight his involvement in advancing the capabilities of AI systems, particularly in the areas of question-answering and the evaluation of language models trained on code.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANDREW CARR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew Carr is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JAN LEIKE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jan Leike is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA ACHIAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joshua Achiam is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="VEDANT MISRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vedant Misra is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.Vedant Misra is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="EVAN MORIKAWA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Evan Morikawa is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEC RADFORD">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alec Radford is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MATTHEW M. KNIGHT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matthew M. Knight is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MILES BRUNDAGE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Miles Brundage is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MIRA MURATI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mira Murati is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KATIE MAYER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Katie Mayer is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PETER WELINDER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peter Welinder is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BOB MCGREW">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bob McGrew is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DARIO AMODEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dario Amodei is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SAM MCCANDLISH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sam McCandlish is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ILYA SUTSKEVER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ilya Sutskever is a prominent author and researcher in the field of artificial intelligence and machine learning. He has made significant contributions to the development and understanding of deep learning and neural networks. Notably, he co-authored the paper "Evaluating large language models trained on code," published on arXiv in 2021. Additionally, he was one of the authors of the influential paper "Mastering the game of Go with deep neural networks and tree search," published in Nature in 2016. Furthermore, Sutskever contributed to the groundbreaking paper "Imagenet classification with deep convolutional neural networks," published in Advances in Neural Information Processing Systems in 2012. His work has been instrumental in advancing the capabilities of AI systems and has had a profound impact on the field.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,6109537356a2ce2339f77c827aa3668e,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WOJCIECH ZAREMBA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wojciech Zaremba is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="EVALUATING LARGE LANGUAGE MODELS TRAINED ON CODE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper published on arXiv in 2021, authored by Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harrison Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, David W. Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William H. Guss, Alex Nichol, Igor Babuschkin, Suchir Balaji, Shantanu Jain, Andrew Carr, Jan Leike, Joshua Achiam, Vedant Misra,</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WENHU CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenhu Chen is an author who contributed to the paper "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XUEGUANG MA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xueguang Ma is an author who contributed to the paper "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XINYI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xinyi Wang is an author who contributed to the paper "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WILLIAM W. COHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">William W. Cohen is an author who contributed to the paper "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks," published in TMLR in 2023. He is recognized for his contributions to research in the field of artificial intelligence and language models.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PROGRAM OF THOUGHTS PROMPTING: DISENTANGLING COMPUTATION FROM REASONING FOR NUMERICAL REASONING TASKS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper published in TMLR in 2023, authored by Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen, discussing the separation of computation from reasoning in numerical reasoning tasks.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="TMLR">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">TMLR (Transactions on Machine Learning Research) is a journal where research papers like "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" are published.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="AAKANKSHA CHOWDHERY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aakanksha Chowdhery is an author who has made significant contributions to the field of language modeling and artificial intelligence. She co-authored the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR) in 2023. Additionally, she is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022. Her work focuses on advancing the understanding and capabilities of language models, addressing complex tasks, and exploring innovative approaches such as the chain-of-thought methodology.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SHARAN NARANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sharan Narang is an author who contributed to the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR) in 2023. He is recognized for his contributions to research in the field of artificial intelligence and language models.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JACOB DEVLIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacob Devlin is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GAURAV MISHRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gaurav Mishra is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ADAM ROBERTS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Adam Roberts is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PAUL BARHAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Paul Barham is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HYUNG WON CHUNG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hyung Won Chung is an accomplished author who has made significant contributions to the field of language modeling and artificial intelligence. In 2023, he co-authored the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR). Additionally, in the same year, he contributed to the paper "Language models are multilingual chain-of-thought reasoners," presented at The Eleventh International Conference on Learning Representations. Furthermore, in 2022, he co-authored the paper "Challenging big-bench tasks and whether chain-of-thought can solve them." These works highlight his active involvement in advancing the understanding and capabilities of language models and their applications.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SEBASTIAN GEHRMANN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sebastian Gehrmann is an author who has made significant contributions to the field of language modeling and artificial intelligence. He co-authored the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR) in 2023. Additionally, he is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022. These works highlight his involvement in advancing the understanding and capabilities of language models and their applications in solving complex tasks.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="PARKER SCHUH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Parker Schuh is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KENSEN SHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kensen Shi is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SASHA TSVYASHCHENKO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sasha Tsvyashchenko is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA MAYNEZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joshua Maynez is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ABHISHEK RAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Abhishek Rao is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PARKER BARNES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Parker Barnes is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YI TAY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yi Tay is an author who has made significant contributions to the field of language modeling and artificial intelligence. In 2023, Yi Tay co-authored the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR). Additionally, in the same year, Yi Tay contributed to the paper "Language models are multilingual chain-of-thought reasoners," presented at The Eleventh International Conference on Learning Representations. Furthermore, in 2022, Yi Tay co-authored the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them." These works highlight Yi Tay's active involvement in advancing the understanding and capabilities of language models and their applications.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NOAM SHAZEER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Noam Shazeer is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="VINODKUMAR PRABHAKARAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vinodkumar Prabhakaran is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="EMILY REIF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Emily Reif is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NAN DU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nan Du is an author who has made significant contributions to the field of language modeling. In 2023, Nan Du co-authored the paper "PaLM: Scaling language modeling with pathways," which was published in the Journal of Machine Learning Research (JMLR). Additionally, Nan Du contributed to the paper "React: Synergizing reasoning and acting in language models." These works highlight Nan Du's involvement in advancing the capabilities and understanding of language models through innovative research.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BEN HUTCHINSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ben Hutchinson is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="REINER POPE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Reiner Pope is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JAMES BRADBURY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">James Bradbury is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MICHAEL ISARD">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Isard is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GUY GUR-ARI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guy Gur-Ari is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PENGCHENG YIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pengcheng Yin is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="TOJU DUKE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Toju Duke is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANSELM LEVSKAYA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anselm Levskaya is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SANJAY GHEMAWAT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sanjay Ghemawat is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SUNIPA DEV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sunipa Dev is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XAVIER GARCIA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xavier Garcia is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KEVIN ROBINSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kevin Robinson is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="LIAM FEDUS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liam Fedus is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DENNY ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Denny Zhou is a prominent researcher and author in the field of artificial intelligence and language models. He has made significant contributions to several influential papers. Notably, he co-authored the paper "Large language models cannot self-correct reasoning yet," presented at ICLR 2024. His work includes contributions to "PaLM: Scaling language modeling with pathways," published in JMLR in 2023, and "Self-consistency improves chain of thought reasoning in language models," as well as "Chain-of-thought prompting elicits reasoning in large language models." Additionally, Denny Zhou co-authored "Language models are multilingual chain-of-thought reasoners," presented at The Eleventh International Conference on Learning Representations in 2023, and "Instruction-following evaluation for large language models," also published in 2023. His research extends to "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022, and "Take a step back: Evoking reasoning via abstraction in large language models," an arXiv preprint from 2023. Furthermore, he contributed to "Self-discover: Large language models self-compose reasoning structures," another arXiv preprint from 2024. Denny Zhou's extensive body of work underscores his pivotal role in advancing the understanding and capabilities of large language models.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DAPHNE IPPOLITO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daphne Ippolito is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DAVID LUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Luan is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HYEONTAEK LIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hyeontaek Lim is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BARRET ZOPH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Barret Zoph is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEXANDER SPIRIDONOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alexander Spiridonov is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="RYAN SEPASSI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ryan Sepassi is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SHIVANI AGRAWAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shivani Agrawal is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MARK OMERNICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mark Omernick is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANDREW M. DAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew M. Dai is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="THANUMALAYAN SANKARANARAYANA PILLAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thanumalayan Sankaranarayana Pillai is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MARIE PELLAT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marie Pellat is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="AITOR LEWKOWYCZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aitor Lewkowycz is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ERICA MOREIRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Erica Moreira is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="REWON CHILD">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rewon Child is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="OLEKSANDR POLOZOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Oleksandr Polozov is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KATHERINE LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Katherine Lee is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ZONGWEI ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zongwei Zhou is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XUEZHI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xuezhi Wang is an author who has made significant contributions to the field of artificial intelligence and language models. Wang has co-authored several influential papers, including "PaLM: Scaling language modeling with pathways" published in the Journal of Machine Learning Research (JMLR) in 2023, "Self-consistency improves chain of thought reasoning in language models," and "Chain-of-thought prompting elicits reasoning in large language models." Additionally, Wang contributed to the paper "Language models are multilingual chain-of-thought reasoners," which was presented at The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BRENNAN SAETA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brennan Saeta is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MARK DIAZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mark Diaz is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ORHAN FIRAT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Orhan Firat is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MICHELE CATASTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michele Catasta is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JASON WEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jason Wei is an author who has made significant contributions to the field of artificial intelligence and language models. He has co-authored several influential papers, including "PaLM: Scaling language modeling with pathways" published in JMLR in 2023, "Self-consistency improves chain of thought reasoning in language models," and "Chain-of-thought prompting elicits reasoning in large language models." Additionally, he contributed to the paper "Language models are multilingual chain-of-thought reasoners," presented at The Eleventh International Conference on Learning Representations in 2023, and "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="KATHY MEIER-HELLSTERN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kathy Meier-Hellstern is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DOUGLAS ECK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Douglas Eck is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JEFF DEAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeff Dean is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SLAV PETROV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Slav Petrov is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="EMBODIED MULTI-MODAL LANGUAGE MODEL">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">An advanced language model that integrates multiple modalities and is designed to be embodied, presented at ICML 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ICML 2023">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The International Conference on Machine Learning held in 2023, where various research papers and advancements in machine learning are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YILUN DU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MENGJIAO YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="BO DAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bo Dai is a researcher and co-author of multiple papers presented at NeurIPS 2023. He contributed to the paper "Learning universal policies via text-guided video generation" and is also one of the authors of "AdaPlanner: Adaptive planning from feedback with language models." His work focuses on innovative approaches in the field of machine learning, particularly in the areas of policy learning and adaptive planning using language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HANJUN DAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="OFIR NACHUM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="JOSHUA B. TENENBAUM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DALE SCHUURMANS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dale Schuurmans is a prominent researcher and author in the field of artificial intelligence and language models. He co-authored the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023. Additionally, he contributed to the papers "Self-consistency improves chain of thought reasoning in language models" and "Chain-of-thought prompting elicits reasoning in large language models." His work focuses on advancing the understanding and capabilities of language models through innovative research and methodologies.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PIETER ABBEEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pieter Abbeel is a prominent researcher in the field of artificial intelligence and language models. He has contributed to several significant papers, including "Learning universal policies via text-guided video generation" presented at NeurIPS 2023, a paper on managing extreme AI risks published in 2024, and a paper on the false promise of imitating proprietary LLMs published in 2023. His work spans various critical aspects of AI, showcasing his expertise and influence in the domain.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7de66b94cf868b37b1df51dc545c415f,8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LEARNING UNIVERSAL POLICIES VIA TEXT-GUIDED VIDEO GENERATION">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at NeurIPS 2023 that discusses learning universal policies through the generation of videos guided by text.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="NEURIPS 2023">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The Conference on Neural Information Processing Systems held in 2023, where various research papers and advancements in neural information processing are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JONATHAN ST BT EVANS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and author of the paper "Intuition and reasoning: A dual-process perspective" published in Psychological Inquiry in 2010.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="INTUITION AND REASONING: A DUAL-PROCESS PERSPECTIVE">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper by Jonathan St BT Evans that discusses the dual-process perspective on intuition and reasoning, published in Psychological Inquiry in 2010.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PSYCHOLOGICAL INQUIRY">
      <data key="d0">JOURNAL</data>
      <data key="d1">A journal that published the paper "Intuition and reasoning: A dual-process perspective" by Jonathan St BT Evans in 2010.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LINXI FAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Linxi Fan is a researcher and co-author who has made significant contributions to the field of artificial intelligence and language models. Fan co-authored the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge," which was presented at the NeurIPS Datasets and Benchmarks Track in 2022. Additionally, Fan is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models," published as an arXiv preprint in 2023. Furthermore, Fan contributed to the paper "Eureka: Human-level reward design via coding large language models," which was published at the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="GUANZHI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guanzhi Wang is a researcher and co-author who has made significant contributions to the field of artificial intelligence and language models. He co-authored the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge," which was presented at the NeurIPS Datasets and Benchmarks Track in 2022. Additionally, he is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models," published as an arXiv preprint in 2023. Furthermore, Guanzhi Wang contributed to the paper "Eureka: Human-level reward design via coding large language models," which was published at the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUNFAN JIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yunfan Jiang is a researcher and co-author who has made significant contributions to the field of artificial intelligence and language models. He co-authored the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge," which was presented at the NeurIPS Datasets and Benchmarks Track in 2022. Additionally, he is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models," published as an arXiv preprint in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AJAY MANDLEKAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ajay Mandlekar is a researcher and co-author of several significant papers in the field of artificial intelligence and language models. He contributed to the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge," which was presented at the NeurIPS Datasets and Benchmarks Track in 2022. Additionally, he is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models," published as an arXiv preprint in 2023. His work focuses on developing advanced AI systems and leveraging large language models to create open-ended embodied agents.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUNCONG YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAOYI ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ANDREW TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DE-AN HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">DE-AN HUANG is a researcher and co-author of significant papers in the field of artificial intelligence and machine learning. Notably, DE-AN HUANG contributed to the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge," which was presented at the NeurIPS Datasets and Benchmarks Track in 2022. Additionally, DE-AN HUANG is one of the authors of the paper "Eureka: Human-level reward design via coding large language models," published at the Twelfth International Conference on Learning Representations in 2023. These contributions highlight DE-AN HUANG's active involvement in advancing the understanding and development of AI through innovative research and collaboration.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUKE ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuke Zhu is a researcher and co-author contributing significantly to the field of artificial intelligence and language models. He co-authored the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge," which was presented at NeurIPS Datasets and Benchmarks Track 2022. Additionally, he is one of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023. Furthermore, Yuke Zhu co-authored the paper "Voyager: An open-ended embodied agent with large language models," published as an arXiv preprint in 2023. His work focuses on developing advanced AI systems and leveraging large language models to create sophisticated, open-ended embodied agents.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANIMA ANANDKUMAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anima Anandkumar is a prominent researcher in the field of artificial intelligence and language models. She is a co-author of several significant papers, including "MineDojo: Building open-ended embodied agents with internet-scale knowledge," presented at NeurIPS Datasets and Benchmarks Track 2022, and "Voyager: An open-ended embodied agent with large language models," published as an arXiv preprint in 2023. Additionally, she contributed to the paper "Eureka: Human-level reward design via coding large language models," which was published in the Twelfth International Conference on Learning Representations in 2023. Her work focuses on advancing the development of embodied agents and leveraging large language models to enhance artificial intelligence capabilities.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MINEDOJO">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at NeurIPS Datasets and Benchmarks Track 2022 that discusses building open-ended embodied agents with internet-scale knowledge.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="NEURIPS DATASETS AND BENCHMARKS TRACK 2022">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">A track at the NeurIPS conference in 2022 focused on datasets and benchmarks, where various research papers are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HIROKI FURUTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUTAKA MATSUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models are zero-shot reasoners" presented at NeurIPS 2022.A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHIXIANG SHANE GU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models are zero-shot reasoners" presented at NeurIPS 2022.A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="IZZEDDIN GUR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MULTIMODAL WEB NAVIGATION WITH INSTRUCTION-FINETUNED FOUNDATION MODELS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICLR 2024 that discusses multimodal web navigation using instruction-finetuned foundation models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ICLR 2024">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The International Conference on Learning Representations held in 2024, where various research papers and advancements in learning representations are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LUYU GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luyu Gao is a researcher and co-author of several notable papers in the field of machine learning and artificial intelligence. He co-authored the paper "PAL: Program-aided language models," which was presented at ICML 2023. Additionally, Luyu Gao is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in NeurIPS 2023 and also in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AMAN MADAAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aman Madaan is a researcher and co-author of several notable papers in the field of machine learning and artificial intelligence. He co-authored the paper "PAL: Program-aided language models," which was presented at ICML 2023. Additionally, he is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in NeurIPS 2023 and also in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHUYAN ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="URI ALON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Uri Alon is a researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023. Additionally, he is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PENGFEI LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pengfei Liu is a researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023. Additionally, Pengfei Liu contributed to a paper on benchmarking the generation and evaluation capabilities of large language models for instruction controllable summarization, also published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YIMING YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiming Yang is a researcher and co-author of several notable papers in the field of machine learning and natural language processing. He co-authored the paper "PAL: Program-aided language models," which was presented at the International Conference on Machine Learning (ICML) in 2023. Additionally, he contributed to the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JAMIE CALLAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jamie Callan is a researcher and co-author of the paper titled "PAL: Program-aided language models," which was presented at the International Conference on Machine Learning (ICML) in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="GRAHAM NEUBIG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Graham Neubig is a researcher and co-author of the paper titled "Program-aided language models," which was presented at the International Conference on Machine Learning (ICML) in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PAL: PROGRAM-AIDED LANGUAGE MODELS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICML 2023 that discusses program-aided language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JIAXIAN GUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SIDI LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAN CAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="WEINAN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YONG YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JUN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LONG TEXT GENERATION VIA ADVERSARIAL TRAINING WITH LEAKED INFORMATION">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at AAAI 2018 that discusses long text generation using adversarial training with leaked information.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AAAI 2018">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The Association for the Advancement of Artificial Intelligence conference held in 2018, where various research papers and advancements in artificial intelligence are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="NICHOLAY TOPIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PHILLIP WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CAYDEN CODEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MANUELA VELOSO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="RUSLAN SALAKHUTDINOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ruslan Salakhutdinov is a prominent researcher in the field of artificial intelligence and language models. He is notably a co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations," which was presented at IJCAI 2019. His contributions to AI research are well-recognized, particularly in the context of large-scale datasets and their applications.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MINERL">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at IJCAI 2019 that discusses a large-scale dataset of Minecraft demonstrations.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="IJCAI 2019">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The International Joint Conference on Artificial Intelligence held in 2019, where various research papers and advancements in artificial intelligence are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DANIJAR HAFNER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Danijar Hafner is a researcher and co-author of several significant papers in the field of artificial intelligence and language models. Notably, he contributed to the paper "Mastering diverse domains through world models," published on arXiv in 2023, and the paper "Learning latent dynamics for planning from pixels," presented at ICML 2019. His work focuses on advancing the understanding and application of AI through innovative research in world models and latent dynamics.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TIMOTHY LILLICRAP">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Mastering diverse domains through world models" published on arXiv in 2023.A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="IAN FISCHER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="RUBEN VILLEGAS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DAVID HA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Ha is a researcher and co-author of the paper "Learning latent dynamics for planning from pixels," which was presented at ICML 2019. Additionally, he is one of the authors of the paper titled "The AI Scientist: Towards fully automated open-ended scientific discovery," published as an arXiv preprint in 2024. His work spans significant contributions to the fields of machine learning and artificial intelligence, focusing on innovative approaches to planning and scientific discovery through AI.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HONGLAK LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JAMES DAVIDSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LEARNING LATENT DYNAMICS FOR PLANNING FROM PIXELS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICML 2019 that discusses learning latent dynamics for planning from pixel data.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JURGIS PASUKONIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Mastering diverse domains through world models" published on arXiv in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JIMMY BA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Mastering diverse domains through world models" published on arXiv in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MASTERING DIVERSE DOMAINS THROUGH WORLD MODELS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper published on arXiv in 2023 that discusses mastering diverse domains through the use of world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHIBO HAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YI GU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAODI MA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JOSHUA JIAHUA HONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHEN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DAISY ZHE WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHTING HU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="REASONING WITH LANGUAGE MODEL IS PLANNING WITH WORLD MODEL">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at EMNLP 2023 that discusses how reasoning with language models is akin to planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="EMNLP 2023">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The Conference on Empirical Methods in Natural Language Processing held in 2023, where various research papers and advancements in natural language processing are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JIE HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models cannot self-correct reasoning yet" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XINYUN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xinyun Chen is a researcher and author who has made significant contributions to the field of large language models. She co-authored the paper "Large language models cannot self-correct reasoning yet," which was presented at ICLR 2024. Additionally, she contributed to the paper "Large language models as optimizers." In 2024, she co-authored the paper "Self-discover: Large language models self-compose reasoning structures," published as an arXiv preprint. Furthermore, in 2023, she was one of the authors of the paper "Take a step back: Evoking reasoning via abstraction in large language models," also published as an arXiv preprint.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SWAROOP MISHRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Swaroop Mishra is a researcher and prolific author in the field of large language models. He co-authored the paper "Large language models cannot self-correct reasoning yet," which was presented at ICLR 2024. In 2023, he contributed to the paper titled "Instruction-following evaluation for large language models." Additionally, he co-authored "Take a step back: Evoking reasoning via abstraction in large language models," published as an arXiv preprint in 2023, and "Self-discover: Large language models self-compose reasoning structures," also published as an arXiv preprint in 2024. His work focuses on the evaluation, reasoning, and self-composition capabilities of large language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="HUAIXIU STEVEN ZHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Huaixiu Steven Zheng is a researcher and co-author of multiple significant papers in the field of large language models. He contributed to the paper "Large language models cannot self-correct reasoning yet," which was presented at ICLR 2024. Additionally, he is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models," published as an arXiv preprint in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ADAMS WEI YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models cannot self-correct reasoning yet" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XINYING SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models cannot self-correct reasoning yet" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LARGE LANGUAGE MODELS CANNOT SELF-CORRECT REASONING YET">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICLR 2024 that discusses the limitations of large language models in self-correcting their reasoning.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="WENLONG HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="F. XIA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HARRIS CHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JACKY LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PETER R. FLORENCE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JONATHAN TOMPSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="IGOR MORDATCH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TOMAS JACKSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="INNER MONOLOGUE: EMBODIED REASONING THROUGH PLANNING WITH LANGUAGE MODELS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at CoRL 2022 that discusses embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CORL 2022">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The Conference on Robot Learning held in 2022, where various research papers and advancements in robot learning are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LEVENTE KOCSIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Bandit based monte-carlo planning" presented at ECML 2006.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CSABA SZEPESV&#193;RI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Bandit based monte-carlo planning" presented at ECML 2006.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="BANDIT BASED MONTE-CARLO PLANNING">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ECML 2006 that discusses bandit-based Monte Carlo planning.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ECML 2006">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The European Conference on Machine Learning held in 2006, where various research papers and advancements in machine learning are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TAKESHI KOJIMA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models are zero-shot reasoners" presented at NeurIPS 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MACHEL REID">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models are zero-shot reasoners" presented at NeurIPS 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUSUKE IWASAWA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models are zero-shot reasoners" presented at NeurIPS 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LARGE LANGUAGE MODELS ARE ZERO-SHOT REASONERS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at NeurIPS 2022 that discusses the zero-shot reasoning capabilities of large language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="STEVEN M. LAVALLE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and author of the paper "Rapidly-exploring random trees: A new tool for path planning" published in The Annual Research Report in 1998.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="RAPIDLY-EXPLORING RANDOM TREES: A NEW TOOL FOR PATH PLANNING">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper by Steven M. LaValle that discusses rapidly-exploring random trees as a new tool for path planning, published in The Annual Research Report in 1998.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="THE ANNUAL RESEARCH REPORT">
      <data key="d0">JOURNAL</data>
      <data key="d1">A journal that published the paper "Rapidly-exploring random trees: A new tool for path planning" by Steven M. LaValle in 1998.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="EVAN ZHERAN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reinforcement learning on web interfaces using workflow-guided exploration" presented at ICLR 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="KELVIN GUU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reinforcement learning on web interfaces using workflow-guided exploration" presented at ICLR 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PANUPONG PASUPAT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reinforcement learning on web interfaces using workflow-guided exploration" presented at ICLR 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TIANLIN SHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reinforcement learning on web interfaces using workflow-guided exploration" presented at ICLR 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PERCY LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Percy Liang is a distinguished researcher known for his contributions to the field of machine learning and artificial intelligence. He co-authored the paper "Reinforcement learning on web interfaces using workflow-guided exploration," which was presented at the International Conference on Learning Representations (ICLR) in 2018. Additionally, Percy Liang is one of the authors of the AlpacaEval project, an innovative automatic evaluator of instruction-following models, published in 2023. His work spans significant advancements in reinforcement learning and the evaluation of AI models, highlighting his influential role in the development of cutting-edge technologies.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="REINFORCEMENT LEARNING ON WEB INTERFACES USING WORKFLOW-GUIDED EXPLORATION">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICLR 2018 that discusses reinforcement learning on web interfaces using workflow-guided exploration.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XIAO LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAO YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HANCHEN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YIFAN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XUANYU LEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HANYU LAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YU GU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HANGLIANG DING">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="KAIWEN MEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="KEJUAN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHUDAN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XIANG DENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AOHAN ZENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHENGXIAO DU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CHENHUI ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHENG SHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TIANJUN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YU SU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HUAN SUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MINLIE HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUXIAO DONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AGENTBENCH: EVALUATING LLMS AS AGENTS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICLR 2024 that discusses the evaluation of large language models as agents.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHIHAN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reason for future, act for now: A principled framework for autonomous LLM agents with provable sample efficiency" published on arXiv in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAO HU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reason for future, act for now: A principled framework for autonomous LLM agents with provable sample efficiency" published on arXiv in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="NIKET TANDON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Niket Tandon is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback," which was published in NeurIPS in 2023. This paper was also published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PRAKHAR GUPTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Prakhar Gupta is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SKYLER HALLINAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Skyler Hallinan is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SARAH WIEGREFFE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sarah Wiegreffe is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NOUHA DZIRI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nouha Dziri is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback," which was published in NeurIPS in 2023. This paper, also referenced as being published in Advances in Neural Information Processing Systems in 2024, highlights the iterative refinement process with self-feedback, contributing to the field of neural information processing.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SHRIMAI PRABHUMOYE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shrimai Prabhumoye is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SHASHANK GUPTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shashank Gupta is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BODHISATTWA PRASAD MAJUMDER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bodhisattwa Prasad Majumder is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KATHERINE HERMANN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Katherine Hermann is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SEAN WELLECK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sean Welleck is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="AMIR YAZDANBAKHSH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amir Yazdanbakhsh is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PETER CLARK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peter Clark is a notable researcher in the field of artificial intelligence, contributing significantly to the academic community through his publications. He is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback," which was published in NeurIPS in 2023. Additionally, he co-authored a paper on the AI2 Reasoning Challenge (ARC), which was published in 2018. These works highlight his involvement in advancing AI research, particularly in areas related to iterative refinement and reasoning challenges.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RAMESH NALLAPATI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ramesh Nallapati is one of the authors of the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BOWEN ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bowen Zhou is a notable author in the field of Natural Language Processing. He co-authored the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond," which was published in the Special Interest Group on Natural Language Learning in 2016. Additionally, he contributed to a 2023 publication focused on enhancing chat language models by scaling high-quality instructional conversations.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CICERO DOS SANTOS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cicero dos Santos is one of the authors of the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CAGLAR GULCEHRE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Caglar Gulcehre is one of the authors of the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BING XIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bing Xiang is one of the authors of the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ABSTRACTIVE TEXT SUMMARIZATION USING SEQUENCE-TO-SEQUENCE RNNS AND BEYOND">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing abstractive text summarization using sequence-to-sequence RNNs and other methods, published in the Special Interest Group on Natural Language Learning, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SPECIAL INTEREST GROUP ON NATURAL LANGUAGE LEARNING">
      <data key="d0">CONFERENCE, PUBLICATION</data>
      <data key="d1">A conference where the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" was published in 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="OPENAI">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">OpenAI is the organization behind the GPT-4 technical report, published in 2023, and is responsible for developing the GPT-4 and GPT-3.5-turbo language models. They also developed the GPT Foundation Model and are known for their work on GPT-3.5. OpenAI's models, including GPT-4 and GPT-3.5, are utilized in Meta Agent Search for evaluating agents and baselines. Additionally, OpenAI published the blog post "Introducing ChatGPT" in November 2022 and the paper "Simple evals" in 2023. The organization is involved in various experiments and provides the GPT model used in the get_json_response_from_gpt function.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e,84317ae35cc75d612287186d93461447,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="GPT-4 TECHNICAL REPORT">
      <data key="d0">DOCUMENT, REPORT</data>
      <data key="d1">The "GPT-4 TECHNICAL REPORT" is a document published by OpenAI in 2023. This technical report provides a comprehensive overview of GPT-4, detailing its development, capabilities, and applications. It serves as an essential resource for understanding the advancements and innovations introduced in GPT-4, reflecting OpenAI's ongoing commitment to advancing artificial intelligence technology.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YUJIA QIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yujia Qin is one of the authors of the ToolLLM project, which facilitates large language models to master over 16,000 real-world APIs, published in 2023. Additionally, Yujia Qin co-authored the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in ICLR, 2024. Furthermore, Yujia Qin contributed to a paper on enhancing chat language models by scaling high-quality instructional conversations, also published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHIHAO LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shihao Liang is one of the authors of the ToolLLM project, which facilitates large language models to master over 16,000 real-world APIs. This work was published in 2023. Additionally, Shihao Liang co-authored the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in the International Conference on Learning Representations (ICLR) in 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YINING YE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yining Ye is one of the authors of the ToolLLM project, which facilitates large language models to master over 16,000 real-world APIs. This work was published in 2023 and further detailed in the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in the International Conference on Learning Representations (ICLR) in 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KUNLUN ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kunlun Zhu is one of the authors of the ToolLLM project, which facilitates large language models to master over 16,000 real-world APIs. This work was published in 2023 and further detailed in the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LAN YAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lan Yan is one of the authors of the ToolLLM project, which facilitates large language models to master over 16,000 real-world APIs. This project was published in 2023. Additionally, Lan Yan is one of the authors of the paper titled "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in the International Conference on Learning Representations (ICLR) in 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YAXI LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yaxi Lu is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024. Additionally, Yaxi Lu contributed to a paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="YANKAI LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yankai Lin is an author who has made significant contributions to the field of large language models. He co-authored the paper "A survey on large language model based autonomous agents" and is also one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in ICLR, 2024. His work focuses on advancing the capabilities of large language models, particularly in their application to autonomous agents and real-world API mastery.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XIN CONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xin Cong is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XIANGRU TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiangru Tang is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BILL QIAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bill Qian is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SIHAN ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sihan Zhao is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="RUNCHU TIAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Runchu Tian is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="RUOBING XIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ruobing Xie is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JIE ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jie Zhou is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARK GERSTEIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mark Gerstein is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DAHAI LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dahai Li is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ZHIYUAN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhiyuan Liu is a notable researcher in the field of large language models and their applications. He is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in ICLR, 2024. Additionally, he contributed to a paper focused on enhancing chat language models by scaling high-quality instructional conversations, published in 2023. His work significantly advances the understanding and capabilities of language models in interacting with real-world APIs and improving conversational AI.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MAOSONG SUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Maosong Sun is a notable author in the field of artificial intelligence and machine learning. He has contributed to significant research, including the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs," which was published in ICLR, 2024. Additionally, he co-authored a paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023. His work focuses on advancing the capabilities of large language models and improving their practical applications in real-world scenarios.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TOOLLLM">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">ToolLLM is a method facilitating large language models to master over 16000 real-world APIs, discussed in a paper published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ABULHAIR SAPAROV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Abulhair Saparov is one of the authors of the paper "Language models are greedy reasoners: A systematic formal analysis of chain-of-thought" published in ICLR, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HE HE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">He He is one of the authors of the paper "Language models are greedy reasoners: A systematic formal analysis of chain-of-thought" published in ICLR, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="LANGUAGE MODELS ARE GREEDY REASONERS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Language models are greedy reasoners: A systematic formal analysis of chain-of-thought" published in ICLR, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="TIMO SCHICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Timo Schick is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JANE DWIVEDI-YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jane Dwivedi-Yu is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROBERTO DESSI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Roberto Dessi is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROBERTA RAILEANU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Roberta Raileanu is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MARIA LOMELI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Maria Lomeli is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LUKE ZETTLEMOYER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luke Zettlemoyer is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NICOLA CANCEDDA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicola Cancedda is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="THOMAS SCIALOM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thomas Scialom is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is notably one of the authors of the paper titled "Toolformer: Language models can teach themselves to use tools," which was published in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TOOLFORMER">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Toolformer is a method where language models can teach themselves to use tools, as discussed in a paper published in NeurIPS, 2023. This technique is utilized in agentic systems to enable agents to use external tools such as search engines, code execution, and database queries.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="YONGLIANG SHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yongliang Shen is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KAITAO SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kaitao Song is an author who has made significant contributions to the field of artificial intelligence and evolutionary algorithms. He co-authored the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms," which explores the use of evolutionary algorithms for the automatic generation of multi-agent systems. Additionally, Kaitao Song is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face," published in NeurIPS, 2023. This paper delves into leveraging ChatGPT and the Hugging Face ecosystem to address various AI tasks, showcasing his expertise in cutting-edge AI research and collaboration.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XU TAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu Tan is an author who has made significant contributions to the field of artificial intelligence and evolutionary algorithms. Xu Tan co-authored the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms," which explores the use of evolutionary algorithms for the automatic generation of multi-agent systems. Additionally, Xu Tan is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face," published in NeurIPS, 2023. This paper discusses leveraging ChatGPT and the Hugging Face ecosystem to address various AI tasks, showcasing Xu Tan's diverse expertise in both evolutionary algorithms and AI task-solving frameworks.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DONGSHENG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dongsheng Li is an author who has made significant contributions to the field of artificial intelligence and evolutionary algorithms. He co-authored the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms," which explores the use of evolutionary algorithms for the automatic generation of multi-agent systems. Additionally, Dongsheng Li is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face," published in NeurIPS, 2023. This paper delves into leveraging ChatGPT and the Hugging Face ecosystem to address various AI tasks, showcasing his diverse expertise in both evolutionary algorithms and AI task-solving frameworks.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="WEIMING LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weiming Lu is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUETING ZHUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yueting Zhuang is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HUGGINGGPT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">HuggingGPT is a method for solving AI tasks with ChatGPT and its friends in Hugging Face, discussed in a paper published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NOAH SHINN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Noah Shinn is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FEDERICO CASSANO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Federico Cassano is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BECK LABASH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Beck Labash is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ASHWIN GOPINATH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ashwin Gopinath is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="KARTHIK NARASIMHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Karthik Narasimhan is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SHUNYU YAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shunyu Yao is an author who has contributed to significant research in the field of language models and reinforcement learning. Notably, Shunyu Yao co-authored the paper "React: Synergizing reasoning and acting in language models." Additionally, Shunyu Yao is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning," which was published in Advances in Neural Information Processing Systems (NeurIPS) in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MOHIT SHRIDHAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mohit Shridhar is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XINGDI YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xingdi Yuan is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARC-ALEXANDRE C&#212;T&#201;">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marc-Alexandre C&#244;t&#233; is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YONATAN BISK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yonatan Bisk is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ADAM TRISCHLER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Adam Trischler is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MATTHEW HAUSKNECHT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matthew Hausknecht is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ALFWORLD">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">ALFWORLD is a method for aligning text and embodied environments for interactive learning, as discussed in a paper published in ICLR, 2020. It serves as an environment used for text-based manipulation tasks, and is mentioned in the context of LATS.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="DAVID SILVER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Silver is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="AJA HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aja Huang is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CHRIS J. MADDISON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chris J. Maddison is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ARTHUR GUEZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arthur Guez is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="L. SIFRE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">L. Sifre is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="GEORGE VAN DEN DRIESSCHE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">George van den Driessche is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JULIAN SCHRITTWIESER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Julian Schrittwieser is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="IOANNIS ANTONOGLOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ioannis Antonoglou is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="VEDAVYAS PANNEERSHELVAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vedavyas Panneershelvam is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARC LANCTOT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marc Lanctot is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SANDER DIELEMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sander Dieleman is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DOMINIK GREWE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dominik Grewe is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JOHN NHAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">John Nham is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NAL KALCHBRENNER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nal Kalchbrenner is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="TIMOTHY P. LILLICRAP">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Timothy P. Lillicrap is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MADELEINE LEACH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Madeleine Leach is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KORAY KAVUKCUOGLU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Koray Kavukcuoglu is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="THORE GRAEPEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thore Graepel is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DEMIS HASSABIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Demis Hassabis is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MASTERING THE GAME OF GO WITH DEEP NEURAL NETWORKS AND TREE SEARCH">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing the mastery of the game of Go using deep neural networks and tree search, published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NATURE">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">Nature is a journal where the paper "Mastering the game of Go with deep neural networks and tree search" was published in 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MASTERING CHESS AND SHOGI BY SELF-PLAY WITH A GENERAL REINFORCEMENT LEARNING ALGORITHM">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing the mastery of chess and Shogi by self-play using a general reinforcement learning algorithm, published in arXiv, 2017.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="STEVEN A. SLOMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Steven A. Sloman is the author of the paper "The empirical case for two systems of reasoning" published in Psychological Bulletin, 1996.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="THE EMPIRICAL CASE FOR TWO SYSTEMS OF REASONING">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing the empirical case for two systems of reasoning, published in Psychological Bulletin, 1996.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PSYCHOLOGICAL BULLETIN">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">Psychological Bulletin is a journal where the paper "The empirical case for two systems of reasoning" was published in 1996.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HAOTIAN SUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Haotian Sun is one of the authors of the paper "AdaPlanner: Adaptive planning from feedback with language models" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUCHEN ZHUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuchen Zhuang is a notable researcher in the field of machine learning and artificial intelligence. He is one of the authors of the paper "AdaPlanner: Adaptive planning from feedback with language models," which was published in NeurIPS 2023. Additionally, he contributed to the paper "ToolChain*: Efficient action space navigation in large language models with A* search," presented at ICLR 2023. These contributions highlight his expertise in adaptive planning and efficient action space navigation within large language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="LINGKAI KONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lingkai Kong is one of the authors of the paper "AdaPlanner: Adaptive planning from feedback with language models" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CHAO ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chao Zhang is a notable researcher who has contributed to the field of algorithmic analysis and large language models. He is one of the authors of the paper "AdaPlanner: Adaptive planning from feedback with language models," which was published in NeurIPS 2023. Additionally, he co-authored the paper "ToolChain*: Efficient action space navigation in large language models with A* search," presented at ICLR 2023. These works highlight his involvement in advancing adaptive planning and efficient action space navigation within the realm of large language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="DIDAC SURIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">D&#237;dac Sur&#237;s is one of the authors of the paper "ViperGPT: Visual inference via Python execution for reasoning" published in ICCV, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SACHIT MENON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sachit Menon is one of the authors of the paper "ViperGPT: Visual inference via Python execution for reasoning" published in ICCV, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CARL VONDRICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Carl Vondrick is one of the authors of the paper "ViperGPT: Visual inference via Python execution for reasoning" published in ICCV, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="VIPERGPT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">ViperGPT is a method for visual inference via Python execution for reasoning, discussed in a paper published in ICCV, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ICCV">
      <data key="d0">CONFERENCE, PUBLICATION</data>
      <data key="d1">ICCV is a conference where the paper "ViperGPT: Visual inference via Python execution for reasoning" was published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MACIEJ SWIECHOWSKI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Maciej Swiechowski is one of the authors of the paper "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review, 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KONRAD GODLEWSKI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Konrad Godlewski is one of the authors of the paper "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review, 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BARTOSZ SAWICKI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bartosz Sawicki is one of the authors of the paper "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review, 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JACEK MA&#8217;NDZIUK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacek Ma&#8217;ndziuk is one of the authors of the paper "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review, 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MONTE CARLO TREE SEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Monte Carlo Tree Search (MCTS) is a model-free algorithm used in reinforcement learning, particularly for decision-making tasks that require the ability to revert to earlier states in the environment. It has been mentioned in the context of research by Tom Vodopivec, Spyridon Samothrakis, and Branko Ster. Additionally, MCTS has been reviewed in the paper "Monte Carlo Tree Search: A Review of Recent Modifications and Applications," published in Artificial Intelligence Review in 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE REVIEW">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">Artificial Intelligence Review is a journal where the paper "Monte Carlo tree search: A review of recent modifications and applications" was published in 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HUGO TOUVRON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hugo Touvron is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is notably one of the authors of the paper "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LOUIS MARTIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Louis Martin is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is specifically noted as one of the authors of the paper titled "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KEVIN R. STONE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kevin R. Stone is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is specifically noted as one of the authors of the paper titled "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PETER ALBERT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peter Albert is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is specifically noted as one of the authors of the paper "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AMJAD ALMAHAIRI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amjad Almahairi is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is notably one of the authors of the paper "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YASMINE BABAEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yasmine Babaei is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. She is specifically noted as one of the authors of the paper "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NIKOLAY BASHLYKOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nikolay Bashlykov is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is also one of the authors of the paper "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SOUMYA BATRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Soumya Batra is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. Specifically, Soumya Batra is one of the authors of the paper titled "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PRAJJWAL BHARGAVA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Prajjwal Bhargava is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SHRUTI BHOSALE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shruti Bhosale is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. She is also one of the authors of the paper "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DANIEL M. BIKEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daniel M. Bikel is a notable contributor in the field of artificial intelligence and language models. He is one of the authors of the paper titled "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023. His work in this area highlights his significant role in advancing research related to language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LUKAS BLECHER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lukas Blecher is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is notably one of the authors of the paper titled "LLaMA: Open and efficient foundation language models," which was published in arXiv in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CRISTIAN CANTON FERRER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cristian Canton Ferrer is a notable contributor in the field of artificial intelligence and language models. He is one of the authors of the paper titled "LLaMA: Open and efficient foundation language models," which was published on arXiv in 2023. His work in this area highlights his involvement in advancing research related to foundational language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MOYA CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Moya Chen is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="GUILLEM CUCURULL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guillem Cucurull is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DAVID ESIOBU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Esiobu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JUDE FERNANDES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jude Fernandes is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEREMY FU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeremy Fu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WENYIN FU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenyin Fu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BRIAN FULLER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brian Fuller is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CYNTHIA GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cynthia Gao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VEDANUJ GOSWAMI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vedanuj Goswami is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NAMAN GOYAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Naman Goyal is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is notably one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks," which was published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANTHONY S. HARTSHORN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anthony S. Hartshorn is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SAGHAR HOSSEINI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saghar Hosseini is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RUI HOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rui Hou is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="HAKAN INAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hakan Inan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MARCIN KARDAS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marcin Kardas is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VIKTOR KERKEZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Viktor Kerkez is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MADIAN KHABSA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Madian Khabsa is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ISABEL M. KLOUMANN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Isabel M. Kloumann is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="A. V. KORENEV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A. V. Korenev is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUNIT SINGH KOURA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Punit Singh Koura is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MARIE-ANNE LACHAUX">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marie-Anne Lachaux is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="THIBAUT LAVRIL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thibaut Lavril is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JENYA LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jenya Lee is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DIANA LISKOVICH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Diana Liskovich is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YINGHAI LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yinghai Lu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUNING MAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuning Mao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XAVIER MARTINET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xavier Martinet is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TODOR MIHAYLOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Todor Mihaylov is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUSHKAR MISHRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pushkar Mishra is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="IGOR MOLYBOG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Igor Molybog is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YIXIN NIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yixin Nie is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANDREW POULTON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew Poulton is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEREMY REIZENSTEIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeremy Reizenstein is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RASHI RUNGTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rashi Rungta is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KALYAN SALADI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kalyan Saladi is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ALAN SCHELTEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alan Schelten is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RUAN SILVA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ruan Silva is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ERIC MICHAEL SMITH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Michael Smith is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="R. SUBRAMANIAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">R. Subramanian is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XIA TAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xia Tan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BINH TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Binh Tang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROSS TAYLOR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ross Taylor is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ADINA WILLIAMS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Adina Williams is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JIAN XIANG KUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jian Xiang Kuan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUXIN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Puxin Xu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ZHENGXU YAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhengxu Yan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ILIYAN ZAROV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Iliyan Zarov is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUCHEN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuchen Zhang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANGELA FAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Angela Fan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MELANIE KAMBADUR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Melanie Kambadur is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AURELIEN RODRIGUEZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aurelien Rodriguez is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROBERT STOJNIC">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Robert Stojnic is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SERGEY EDUNOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sergey Edunov is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VOYAGER">
      <data key="d0">TECHNOLOGY, AGENT</data>
      <data key="d1">Voyager is an open-ended embodied agent with large language models, mentioned in the document in the context of research by Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHAIN OF THOUGHT PROMPTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Chain of Thought Prompting is a technique that elicits reasoning in large language models, mentioned in the document in the context of research by Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="INTELLIGENT AGENTS">
      <data key="d0">TECHNOLOGY, CONCEPT</data>
      <data key="d1">Intelligent Agents are systems that perceive their environment and take actions to achieve specific goals, mentioned in the document in the context of research by Michael Wooldridge and Nicholas R. Jennings.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DAYDREAMER">
      <data key="d0">TECHNOLOGY, AGENT</data>
      <data key="d1">Daydreamer is a world model for physical robot learning, mentioned in the document in the context of research by Philipp Wu, Alejandro Escontrela, Danijar Hafner, Pieter Abbeel, and Ken Goldberg.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DECOMPOSITION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Decomposition is a technique that enhances reasoning via self-evaluation guided decoding, mentioned in the document in the context of research by Yuxi Xie, Kenji Kawaguchi,</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TOM VODOPIVEC">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tom Vodopivec is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SPYRIDON SAMOTHRAKIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Spyridon Samothrakis is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BRANKO STER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Branko Ster is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUQI XIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuqi Xie is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. Yuqi Xie is also one of the authors of the paper "Voyager: An open-ended embodied agent with large language models," which was published as an arXiv preprint in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHAOWEI XIAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chaowei Xiao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is also one of the authors of the paper "Voyager: An open-ended embodied agent with large language models," which was published as an arXiv preprint in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ED CHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ed Chi is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is notably one of the authors of the paper titled "Least-to-most prompting enables complex reasoning in large language models," which was presented at the International Conference on Learning Representations (ICLR) in 2022.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="MICHAEL WOOLDRIDGE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Wooldridge is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NICHOLAS R. JENNINGS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicholas R. Jennings is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PHILIPP WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Philipp Wu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ALEJANDRO ESCONTRELA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alejandro Escontrela is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KEN GOLDBERG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ken Goldberg is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUXI XIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuxi Xie is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KENJI KAWAGUCHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kenji Kawaguchi is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YIRAN ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiran Zhao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XU ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu Zhao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MIN-YEN KAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Min-Yen Kan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JUNXIAN HE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Junxian He is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="QIZHE XIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qizhe Xie is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ZHILIN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhilin Yang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PENG QI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peng Qi is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SAIZHENG ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saizheng Zhang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YOSHUA BENGIO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yoshua Bengio is a prominent figure in the field of artificial intelligence, contributing significantly to research on language models. He is one of the authors mentioned in the document, specifically noted for his work on managing extreme AI risks. His contributions are highlighted in a paper published in 2024, underscoring his ongoing influence and thought leadership in addressing critical issues within the AI community.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHRISTOPHER D. MANNING">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Christopher D. Manning is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TREE OF THOUGHTS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Tree of Thoughts is a technique for deliberate problem solving with large language models, mentioned in the document in the context of research by Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WEIRUI YE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weirui Ye is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SHAOHUAI LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shaohuai Liu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="THANARD KURUTACH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thanard Kurutach is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YANG GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang Gao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NATHANAEL SCHARLI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nathanael Sch&#228;rli is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LE HOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Le Hou is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. Le Hou is also one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NATHAN SCALES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nathan Scales is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models. He is specifically noted for co-authoring the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," which was published in 2022.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="OLIVIER BOUSQUET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Olivier Bousquet is a notable researcher in the field of artificial intelligence and language models. He is one of the authors of the paper titled "Least-to-most prompting enables complex reasoning in large language models," which was presented at the International Conference on Learning Representations (ICLR) in 2022.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TOOLCHAIN*">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">ToolChain* is a method for efficient action space navigation in large language models using A* search. This method is discussed in a paper authored by Yuchen Zhuang, Xiang Chen, Tong Yu, Saayan Mitra, Victor Bursztyn, Ryan A. Rossi, Somdeb Sarkhel, and Chao Zhang.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ICLR 2022">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">ICLR 2022 is the conference where the paper "Least-to-most prompting enables complex reasoning in large language models" was presented.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="XIANG CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiang Chen is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="TONG YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tong Yu is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SAAYAN MITRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saayan Mitra is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="VICTOR BURSZTYN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Victor Bursztyn is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="RYAN A. ROSSI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ryan A. Rossi is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SOMDEB SARKHEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Somdeb Sarkhel is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ICLR 2023">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">ICLR 2023 is the conference where the paper "ToolChain*: Efficient action space navigation in large language models with A* search" was presented.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="WEBSHOP">
      <data key="d0">TASK, DOMAIN</data>
      <data key="d1">WEBSHOP is an online platform where users can search for and purchase products, such as deodorants. Additionally, WebShop serves as one of the environments used to evaluate LATS, focusing on web search tasks. This dual functionality highlights its role both as a consumer marketplace and a testing ground for algorithmic performance in web search scenarios.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="TOOLBENCH">
      <data key="d0">ENVIRONMENT, APPLICATION</data>
      <data key="d1">ToolBench is an environment involving LM-based tools, mentioned in the context of LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="QIN ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qin et al. are the authors mentioned in relation to ToolBench, an environment involving LM-based tools.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YA0 ET AL., 2023A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al. are the authors mentioned in relation to the ToT algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SEARCH APPROACHES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="PSEUDOCODE">
      <data key="d0">DOCUMENTATION, CODE</data>
      <data key="d1">Pseudocode is a detailed, readable description of what a computer program or algorithm must do, expressed in a formally-styled natural language rather than in a programming language.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SELF-CONSISTENCY WEIGHT">
      <data key="d0">PARAMETER, ATTRIBUTE</data>
      <data key="d1">Self-consistency weight is a parameter in the LATS algorithm that affects the consistency of the search results. Different values are used for different tasks like HotPotQA and Programming.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ENVIRONMENT REVERSION">
      <data key="d0">FEATURE, ATTRIBUTE</data>
      <data key="d1">Environment reversion is a feature required by the LATS algorithm for decision-making tasks, allowing the agent to revert to earlier states in the environment.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="API-BASED TOOLS">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">API-based tools are used in LM-based environments and are mentioned as being inexpensive and fast to use in the context of LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="TEXT-BASED MANIPULATION TASKS">
      <data key="d0">TASK, DOMAIN</data>
      <data key="d1">Text-based manipulation tasks are a type of task evaluated using environments like Alfworld, mentioned in the context of LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ROLLBACKS">
      <data key="d0">FEATURE, ATTRIBUTE</data>
      <data key="d1">Rollbacks are a feature that allows reverting to previous states in an environment, mentioned as a limitation for some environments in the context of LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="RESOURCE CONSTRAINTS">
      <data key="d0">LIMITATION, ATTRIBUTE</data>
      <data key="d1">Resource constraints are limitations that can affect the design and implementation of the LATS algorithm in various environments.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="PLANNING-BASED PROMPTING METHODS">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Planning-based prompting methods are techniques like LATS that are used for reasoning and decision-making in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ADDITIONAL ABLATIONS">
      <data key="d0">EXPERIMENT, ANALYSIS</data>
      <data key="d1">Additional ablations are experiments conducted to analyze various designs of the LATS algorithm, including different parameters and settings.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SAMPLING SIZE">
      <data key="d0">PARAMETER, ATTRIBUTE</data>
      <data key="d1">Sampling size is a parameter in the LATS algorithm that affects the number of samples taken during the search process. It determines the number of samples or trajectories to be considered, thereby influencing the efficiency and accuracy of the search.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="TAB. 8">
      <data key="d0">DOCUMENTATION, TABLE</data>
      <data key="d1">Tab. 8 is a table in the appendix that shows the results of experiments conducted on HotPotQA using the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="FIG. 3">
      <data key="d0">DOCUMENTATION, FIGURE</data>
      <data key="d1">Fig. 3 is a figure in the appendix that shows the results of experiments conducted on HumanEval using the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="TAB. 9">
      <data key="d0">DOCUMENTATION, TABLE</data>
      <data key="d1">Tab. 9 is a table in the appendix that provides a full analysis of the computational cost of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. A">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. A is a section in the appendix that shows the pseudocode of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. B">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. B is a section in the appendix that provides further discussion of the limitations of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. C">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. C is a section in the appendix that presents additional experimental results of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. D">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. D is a section in the appendix that specifies the environment details in the experiments conducted using the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. E">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. E is a section in the appendix that lists the prompts used for the HotPotQA environment in the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. F">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. F is a section in the appendix that lists the prompts used for the Programming environment in the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. G">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. G is a section in the appendix that lists the prompts used for the WebShop environment in the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="YA0 ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"Yao et al., 2022" refers to the authors who developed and published the WebShop environment in 2022.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="DEPTH">
      <data key="d0">PARAMETER</data>
      <data key="d1">Depth is a parameter in the LATS algorithm that determines the maximum number of steps or layers in the search process. It affects the performance and success rate of the algorithm in tasks like HotPotQA.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="LM VALUE FUNCTION">
      <data key="d0">COMPONENT, FUNCTION</data>
      <data key="d1">The LM value function scores states based on expected future rewards. It is a heuristic used in the LATS algorithm to guide the search process more effectively.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="WIKIPEDIA WEB API">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">The Wikipedia web API is used in the LATS algorithm for interactive information retrieval. It supports actions like searching for entities and looking up strings to retrieve relevant information from Wikipedia.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="STATE SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">State space refers to the set of all possible states or configurations that the algorithm can explore during the search process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="VALUE FUNCTION WEIGHT">
      <data key="d0">PARAMETER</data>
      <data key="d1">Value function weight is a parameter in the LATS algorithm that balances the contributions of different components in the value function, such as the LM score and self-consistency score.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="ACTION GENERATOR">
      <data key="d0">COMPONENT, FUNCTION</data>
      <data key="d1">Action generator is a component in the LATS algorithm that generates possible actions based on the current state.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="VISIT COUNTER">
      <data key="d0">COMPONENT, FUNCTION</data>
      <data key="d1">Visit counter is a component in the LATS algorithm that keeps track of the number of times each state has been visited during the search process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="CONTEXT">
      <data key="d0">CONCEPT</data>
      <data key="d1">CONTEXT refers to the background information provided to help the agent answer a question. It also encompasses the additional information or conditions that influence the search process in the LATS algorithm. This dual role of CONTEXT highlights its importance in both understanding and guiding the algorithmic analysis, ensuring that the agent can make informed decisions based on comprehensive and relevant data.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ENVIRONMENT REWARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Environment rewards are the feedback or scores received from the environment based on the actions taken and states reached during the search process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="CROWDWORKERS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Crowdworkers are individuals who contributed to the creation of the HotPotQA dataset by crafting diverse, multi-hop, and explainable question-answer pairs.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="SUPPORTING FACTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Supporting facts are pieces of information provided in the HotPotQA dataset that justify the answers to the questions, helping in the reasoning process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="WIKIPEDIA PARAGRAPHS">
      <data key="d0">DATA SOURCE</data>
      <data key="d1">Wikipedia paragraphs are the text segments used in the HotPotQA dataset to provide the necessary information for answering the questions.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="SEARCH [ENTITY]">
      <data key="d0">ACTION</data>
      <data key="d1">Search [entity] is an action in the LATS algorithm that retrieves the first 5 sentences from the corresponding entity's Wikipedia page or suggests top-5 similar entities if the page does not exist.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="LOOKUP [STRING]">
      <data key="d0">ACTION</data>
      <data key="d1">Lookup [string] is an action in the LATS algorithm that returns the next sentence in the context of the search process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="EM (EXACT MATCH)">
      <data key="d0">METRIC</data>
      <data key="d1">EM (Exact Match) is a performance metric used to evaluate the accuracy of answers in the HotPotQA dataset, indicating the percentage of answers that exactly match the ground truth.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="INTERACTIVE INFORMATION RETRIEVAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A method involving search, lookup, and finish actions to retrieve and interact with information from Wikipedia or other sources.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="LOOKUP">
      <data key="d0">ACTION, COMMAND</data>
      <data key="d1">An action that returns the next sentence in the page containing the specified string.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="FINISH">
      <data key="d0">ACTION, COMMAND</data>
      <data key="d1">An action that finishes the current task with the provided answer.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MBPP is a benchmark containing 974 short Python functions designed to evaluate program synthesis techniques, with an additional set of 426 manually verified problems.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="TASK SCORE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">A metric used in WebShop to capture the average reward obtained across episodes, defined as (100&#215;avg. reward).</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="NATURAL LANGUAGE DESCRIPTIONS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Natural language descriptions are used to describe programming tasks in datasets like HumanEval and MBPP.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="FUNCTION SIGNATURE">
      <data key="d0">DATA, COMPONENT</data>
      <data key="d1">A function signature is part of a programming problem, specifying the function's name, parameters, and return type.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="DOCSTRING DESCRIPTION">
      <data key="d0">DATA, COMPONENT</data>
      <data key="d1">A docstring description provides a detailed explanation of a function's purpose and behavior in programming problems.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="REFERENCE IMPLEMENTATION">
      <data key="d0">DATA, COMPONENT</data>
      <data key="d1">A reference implementation is a sample solution provided for programming problems to demonstrate the expected functionality.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="UNIT TESTS">
      <data key="d0">DATA, COMPONENT</data>
      <data key="d1">Unit tests are used to verify the correctness of a function's implementation by running predefined test cases.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="PASS@K METRIC">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Pass@k is a metric used to evaluate the success rate of generated solutions in programming tasks, where a problem is considered solved if any of the k samples pass all tests.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">The "VALUE FUNCTION HYPERPARAMETERS" are settings used to configure the value function in experiments and algorithms, such as LATS. These hyperparameters include parameters like &#955; for the LM score and self-consistency score, which are crucial for evaluating the performance and consistency of the value function within these experimental frameworks.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="INTERNAL TESTS">
      <data key="d0">DATA, EVALUATION</data>
      <data key="d1">Internal tests are used to evaluate the performance of language models like GPT-3.5 and GPT-4 on programming tasks.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="CROWDSOURCING">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Crowdsourcing is a method used to gather data, such as the natural language descriptions and solutions in the MBPP dataset, from a large group of people with basic Python knowledge.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="PYTHON STANDARD LIBRARY">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">The Python standard library is a collection of modules and functions included with Python, used in programming tasks for operations like list processing and string manipulation.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="HTML MODE">
      <data key="d0">MODE, CONFIGURATION</data>
      <data key="d1">HTML mode is a rendering mode in WebShop that provides pixel-level observations with interactive elements for training agents.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="SIMPLE MODE">
      <data key="d0">MODE, CONFIGURATION</data>
      <data key="d1">Simple mode is a rendering mode in WebShop that converts raw HTML into structured text observations for easier training of agents.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="QUERY SEARCHES">
      <data key="d0">ACTION, COMMAND</data>
      <data key="d1">Query searches are actions in WebShop that allow agents to search for products based on specified attributes and options.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="BUTTON CLICKS">
      <data key="d0">ACTION, COMMAND</data>
      <data key="d1">Button clicks are actions in WebShop that allow agents to navigate between different page types like search, results, item, and item detail.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="LEXICAL MATCHING">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Lexical matching is a method used in WebShop to compare the product purchased by the agent against the specified attributes and options based on exact word matches.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="SEMANTIC SIMILARITY METRICS">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Semantic similarity metrics are methods used in WebShop to compare the product purchased by the agent against the specified attributes and options based on meaning and context.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="SEARCH PAGE">
      <data key="d0">PAGE TYPE, COMPONENT</data>
      <data key="d1">The search page in WebShop is where agents can perform query searches to find products.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="RESULTS PAGE">
      <data key="d0">PAGE TYPE, COMPONENT</data>
      <data key="d1">The results page in WebShop displays the search results based on the agent's query.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="ITEM PAGE">
      <data key="d0">PAGE TYPE, COMPONENT</data>
      <data key="d1">The item page in WebShop provides detailed information about a specific product selected from the search results.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="ITEM DETAIL PAGE">
      <data key="d0">PAGE TYPE, COMPONENT</data>
      <data key="d1">The item detail page in WebShop provides additional details and options for a specific product.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="RESULTS">
      <data key="d0">OUTPUT, SEARCH RESULT</data>
      <data key="d1">The list of products returned by the web shop in response to a query</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PRODUCT TITLE">
      <data key="d0">PRODUCT ATTRIBUTE, IDENTIFIER</data>
      <data key="d1">The name or title of a product listed in the search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="OPTION">
      <data key="d0">PRODUCT ATTRIBUTE, CHOICE</data>
      <data key="d1">A selectable feature or variant of a product, such as size or color</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="DESC/OVERVIEW">
      <data key="d0">PRODUCT ATTRIBUTE, DESCRIPTION</data>
      <data key="d1">A detailed description or overview of a product's features and specifications</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITEM">
      <data key="d0">PRODUCT</data>
      <data key="d1">A specific product listed in the search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITEM-DETAIL">
      <data key="d0">PRODUCT ATTRIBUTE, DETAIL</data>
      <data key="d1">Detailed information about a specific product, including its description, options, and price</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EPISODE END">
      <data key="d0">EVENT, TERMINATION</data>
      <data key="d1">The conclusion of a user's interaction session with the web shop</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ENVIRONMENTS">
      <data key="d0">SETTING, CONTEXT</data>
      <data key="d1">The different scenarios or contexts in which experiments are conducted</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="DEPTH LIMIT">
      <data key="d0">CONSTRAINT, PARAMETER</data>
      <data key="d1">The maximum number of steps or actions allowed in an experiment or task</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT">
      <data key="d0">STEP, REASONING</data>
      <data key="d1">THOUGHT is a critical component in the process of solving a question-answering task. It represents a reasoning step that helps in determining the next action based on the current situation. Within the output, THOUGHT is a section where the meta agent captures its thought process, which includes reasoning, the overall concept, and implementation steps for designing the next function. This structured approach ensures a comprehensive understanding of the dynamics and interactions involved in the task.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="FINISH[ANSWER]">
      <data key="d0">STEP, OPERATION</data>
      <data key="d1">"FINISH[ANSWER] is an action that returns the final answer and concludes the task in a question-answering scenario. This action signifies the completion of the task by providing the definitive answer, thereby finishing the process."</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">STEP, OPERATION</data>
    </node>
    <node id="SEARCH[ENTITY]">
      <data key="d0">STEP, OPERATION</data>
      <data key="d1">SEARCH[ENTITY] is an action that searches for a specific entity on Wikipedia and returns relevant information. It is designed to locate the exact entity on Wikipedia and provide the first paragraph if it exists. In cases where the exact entity is not found, it offers similar entities as alternatives. This functionality ensures that users receive the most pertinent information available, whether it is a direct match or closely related content.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">STEP, OPERATION</data>
    </node>
    <node id="LOOKUP[KEYWORD]">
      <data key="d0">STEP, OPERATION</data>
      <data key="d1">LOOKUP[KEYWORD] is an action that returns the next sentence containing a specified keyword in the current passage. This function is designed to identify and extract the subsequent sentence that includes the given keyword, facilitating targeted information retrieval within a text.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">STEP, OPERATION</data>
    </node>
    <node id="ARTHUR'S MAGAZINE">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">"ARTHUR'S MAGAZINE" was an American literary periodical published in Philadelphia in the 19th century. Edited by Timothy Shay Arthur, the magazine featured work by notable authors, contributing to the rich literary culture of the time.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="FIRST FOR WOMEN">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">FIRST FOR WOMEN is a woman's magazine published by Bauer Media Group in the USA. It was started in 1989 and is part of a question-answering task to determine which magazine was started first.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="COLORADO OROGENY">
      <data key="d0">GEOLOGICAL EVENT, ENTITY</data>
      <data key="d1">A geological event that extends into the High Plains, with an elevation range from 1,800 to 7,000 ft</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HIGH PLAINS">
      <data key="d0">GEOGRAPHICAL REGION, ENTITY</data>
      <data key="d1">A region that rises in elevation from around 1,800 to 7,000 ft</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="VALUE FUNCTION PROMPT">
      <data key="d0">INSTRUCTION, INPUT</data>
      <data key="d1">The "VALUE FUNCTION PROMPT" is a prompt designed to instruct the analysis of trajectories in various tasks, such as purchase trajectories and question-answering tasks. It focuses on evaluating the correctness of these trajectories by examining thoughts, actions, and observations. The prompt aims to provide a comprehensive correctness score, typically ranging from 1 to 10, based on the detailed analysis of the solution trajectories.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,6f486e20e3102c7a285e357d356417ad,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="TIMOTHY SHAY ARTHUR">
      <data key="d0">AUTHOR, EDITOR</data>
      <data key="d1">Timothy Shay Arthur was the editor of Arthur's Magazine, an American literary periodical published in the 19th century.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BAUER MEDIA GROUP">
      <data key="d0">ORGANIZATION, PUBLISHER</data>
      <data key="d1">The publisher of First for Women, a woman's magazine in the USA</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="GODEY'S LADY'S BOOK">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">Godey's Lady's Book, a prominent magazine, was the publication into which Arthur's Magazine was merged in May 1846.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EDGAR A. POE">
      <data key="d0">AUTHOR, WRITER</data>
      <data key="d1">Edgar A. Poe, known for his literary works, was a notable contributor to Arthur's Magazine.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="J.H. INGRAHAM">
      <data key="d0">AUTHOR, WRITER</data>
      <data key="d1">J.H. Ingraham, a notable contributor to Arthur's Magazine, is recognized for his literary works. His contributions to the magazine have cemented his place in the literary community, showcasing his talent and dedication to the craft.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SARAH JOSEPHA HALE">
      <data key="d0">AUTHOR, WRITER</data>
      <data key="d1">Sarah Josepha Hale, a notable contributor to Arthur's Magazine, is recognized for her literary works. Her contributions to the magazine highlight her significant role in the literary community, showcasing her talent and influence in the field.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOMAS G. SPEAR">
      <data key="d0">AUTHOR, WRITER</data>
      <data key="d1">Thomas G. Spear, a notable contributor to Arthur's Magazine, is recognized for his literary works. His contributions to the magazine have established him as a significant figure within the literary community associated with Arthur's Magazine.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PREV/NEXT PAGE">
      <data key="d0">ACTION, OPERATION</data>
      <data key="d1">An action to navigate through the pages of search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="CHOOSE">
      <data key="d0">ACTION, OPERATION</data>
      <data key="d1">An action to select a specific product, option, or detail from the search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BACK TO SEARCH">
      <data key="d0">ACTION, OPERATION</data>
      <data key="d1">"BACK TO SEARCH" is an action that allows users to return to the search page from either the results or item detail page. This functionality is essential for navigating back to the search results, ensuring a seamless user experience by providing an easy way to revisit previous search queries and results.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ATTRIBUTE">
      <data key="d0">PRODUCT ATTRIBUTE, FEATURE</data>
      <data key="d1">A characteristic or feature of a product that can influence the reward calculation</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="INSTRUCTIONS">
      <data key="d0">INPUT, GUIDELINE</data>
      <data key="d1">Guidelines provided to the user or agent to perform specific tasks in the web shop</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="NUMBER OF ATTRIBUTES SATISFIED">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">A measure used to calculate the reward based on how many product attributes match the user's criteria</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="MAXIMUM DEPTH LIMIT">
      <data key="d0">CONSTRAINT, PARAMETER</data>
      <data key="d1">The maximum number of steps allowed in a task or experiment</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HYPERPARAMETERS">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">Settings used to configure algorithms like the value function, including parameters like &#955;</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ARITHMETIC OPERATIONS">
      <data key="d0">OPERATION, METHOD</data>
      <data key="d1">Basic mathematical operations used in the Game of 24 to construct the number 24 from four given numbers</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EQUATION">
      <data key="d0">RESULT, OUTPUT</data>
      <data key="d1">A mathematical statement that represents the solution in the Game of 24</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BASE ACTING PROMPT">
      <data key="d0">INSTRUCTION, INPUT</data>
      <data key="d1">A prompt that guides the agent in performing actions and reasoning steps in a question answering task</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BASE REASONING PROMPT">
      <data key="d0">INSTRUCTION, INPUT</data>
      <data key="d1">A prompt that guides the agent in reasoning through a question answering task step by step</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT 1">
      <data key="d0">STEP, REASONING</data>
      <data key="d1">The first reasoning step in a question answering task, often involving initial analysis or search</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT 2">
      <data key="d0">STEP, REASONING</data>
      <data key="d1">The second reasoning step in a question answering task, often involving further analysis or search</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT 3">
      <data key="d0">STEP, REASONING</data>
      <data key="d1">The third reasoning step in a question answering task, often leading to the final answer</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EXAMPLES">
      <data key="d0">INPUT, GUIDELINE</data>
      <data key="d1">Sample questions and answers provided to guide the agent in performing tasks</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">INPUT, GUIDELINE</data>
    </node>
    <node id="PREVIOUS TRIAL">
      <data key="d0">EVENT, SESSION</data>
      <data key="d1">A past attempt at solving a question answering task, used for reflection and improvement</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">EVENT, SESSION</data>
    </node>
    <node id="STRATEGY">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A plan or method used to improve performance in a task based on reflections from previous trials</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">METHOD, TECHNIQUE</data>
    </node>
    <node id="ELEVATION RANGE">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The range of elevation for a geographical region, such as the High Plains</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">ATTRIBUTE, FEATURE</data>
    </node>
    <node id="AREA">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">A specific geographical region or sector, such as the eastern sector of the Colorado orogeny</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">ATTRIBUTE, FEATURE</data>
    </node>
    <node id="SOLUTION">
      <data key="d0">RESULT, OUTPUT</data>
      <data key="d1">A solution is a method or approach that effectively addresses a problem or task, often developed through automated design in Advanced Driver Assistance Systems (ADAS). It is also the final answer or outcome of a question-answering task, evaluated for correctness.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,81c504ffbcc5ed882e234802135295ba,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">RESULT, OUTPUT</data>
    </node>
    <node id="ANALYSIS">
      <data key="d0">STEP, REASONING</data>
      <data key="d1">The process of examining trajectories or solutions to understand and improve performance</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">STEP, REASONING</data>
    </node>
    <node id="SITUATION">
      <data key="d0">CONTEXT, SETTING</data>
      <data key="d1">The current state or scenario in which a task is being performed</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">CONTEXT, SETTING</data>
    </node>
    <node id="ENVIRONMENTAL OBSERVATIONS">
      <data key="d0">INPUT, FEEDBACK</data>
      <data key="d1">Information about the environment or context that informs the agent's reasoning and actions</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">INPUT, FEEDBACK</data>
    </node>
    <node id="THOUGHT, ACTION, OBSERVATION STEPS">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A structured approach to solving tasks by interleaving reasoning, actions, and feedback</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">METHOD, TECHNIQUE</data>
    </node>
    <node id="ARTHUR'S MAGAZINE START DATE">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The year Arthur's Magazine was started, which is 1844</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">ATTRIBUTE, FEATURE</data>
    </node>
    <node id="FIRST FOR WOMEN START DATE">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The year First for Women was started, which is 1989</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">ATTRIBUTE, FEATURE</data>
    </node>
    <node id="MAGAZINE">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">A type of publication, such as Arthur's Magazine or First for Women</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">PUBLICATION, ENTITY</data>
    </node>
    <node id="PUBLISHER">
      <data key="d0">ORGANIZATION, ENTITY</data>
      <data key="d1">An organization that publishes magazines or other publications, such as Bauer Media Group</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="LITERARY PERIODICAL">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">A type of magazine focused on literary content, such as Arthur's Magazine</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="AMERICAN LITERARY PERIODICAL">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">A literary periodical published in the United States, such as Arthur's Magazine</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PHILADELPHIA">
      <data key="d0">LOCATION, CITY</data>
      <data key="d1">The city where Arthur's Magazine was published</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="19TH CENTURY">
      <data key="d0">TIME PERIOD, ERA</data>
      <data key="d1">The century during which Arthur's Magazine was published</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="MERGER">
      <data key="d0">EVENT, ACTION</data>
      <data key="d1">The combining of two publications, such as the merger of Arthur's Magazine into Godey's Lady's Book</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="CONTRIBUTOR">
      <data key="d0">ROLE, PERSON</data>
      <data key="d1">An individual who contributes content to a publication, such as Edgar A. Poe or Sarah Josepha Hale</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="WOMAN'S MAGAZINE">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">A type of magazine targeted at women, such as First for Women</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BASED IN ENGLEWOOD CLIFFS, NEW JERSEY">
      <data key="d0">LOCATION, ATTRIBUTE</data>
      <data key="d1">The location where First for Women is based</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="CIRCULATION">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">The number of copies of a magazine distributed, such as the 1,310,696 copies of First for Women in 2011</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="2011">
      <data key="d0">TIME PERIOD, YEAR</data>
      <data key="d1">The year in which the circulation of First for Women was 1,310,696 copies</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HIGH PLAINS ELEVATION">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The elevation range of the High Plains, from 1,800 to 7,000 ft</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EASTERN SECTOR">
      <data key="d0">AREA, REGION</data>
      <data key="d1">A specific part of a larger geographical region, such as the eastern sector of the Colorado orogeny</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="COLORADO OROGENY EXTENSION">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The area into which the Colorado orogeny extends, such as the High Plains</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HIGH PLAINS RISE">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The increase in elevation of the High Plains, from around 1,800 to 7,000 ft</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ANSWER">
      <data key="d0">RESULT, OUTPUT</data>
      <data key="d1">An answer is the result or solution provided by an agent after performing a task. It represents the final output or response produced by the system after evaluating the final code, integrating sub-problem solutions, or addressing the original problem. In the context of a question answering task, an answer is the final response to a question.</data>
      <data key="d2">84317ae35cc75d612287186d93461447,b8dd0300033963bb4a3e1bad37f8e7b9,c3d0436082aada237ee4bee645f16059,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="FINISH[1,800 TO 7,000 FT]">
      <data key="d0">STEP, OPERATION</data>
      <data key="d1">An action that returns the answer "1,800 to 7,000 ft" and concludes the task</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT, THEN FINISH">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A structured approach to solving tasks by reasoning first and then providing the final answer</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="TRAJECTORY ANALYSIS">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">The process of examining the sequence of steps taken to solve a task</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="LABELED TRAJECTORIES">
      <data key="d0">SEQUENCE, PATH</data>
      <data key="d1">Sequences of steps that are labeled with observations, thoughts, and actions</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SOLUTION TRAJECTORIES">
      <data key="d0">SEQUENCE, PATH</data>
      <data key="d1">The paths taken to arrive at a solution in a question answering task</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="LANGUAGE AGENT TREE SEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">A method that unifies reasoning, acting, and planning in language models</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="UNIFIES REASONING, ACTING, AND PLANNING">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A technique that combines reasoning, acting, and planning in a cohesive approach</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="STATE OF THE ART">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">The highest level of performance achieved in a specific task or benchmark</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="VALIDATION">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">VALIDATION is the process of confirming the effectiveness or accuracy of a method or algorithm. It is a critical step in ensuring that the outcomes produced by a method or algorithm are reliable and meet the intended objectives. However, validation also presents a limitation, particularly in the context of synthetic data. Ensuring that synthetic data accurately represents the desired scenarios can be challenging, making the validation process more complex and demanding.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ADVANCED LANGUAGE MODELS">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Highly developed models used for complex natural language processing tasks</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HIGHER PERFORMANCE">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">A level of performance that exceeds previous benchmarks or standards</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BASELINES">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">"BASELINES" are a group of models used for comparison in the evaluation process, including Orca-2.5, Mistral-Instruct-7B, and ChatGPT. They serve as the initial set of agents in the Discovered Agent Archive, which are updated at every iteration in the Meta Agent Search, as described in the supplementary material of the paper "Automated Design of Agentic Systems." These baselines are standard agents used for comparison in evaluations, often utilizing models like GPT-3.5-turbo-0125. They act as standard measures or references used for comparison in experiments.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,84317ae35cc75d612287186d93461447,b8dd0300033963bb4a3e1bad37f8e7b9,bd4eb9459bc29b4c2da4658914fd4635,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="QUESTIONS">
      <data key="d0">INPUT, QUERY</data>
      <data key="d1">QUESTIONS are items or prompts used to evaluate the performance of algorithms in benchmarks like HumanEval. They are also employed in reading comprehension tests and open domain question answering to assess understanding and generate responses.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MINIMAL PERFORMANCE DIFFERENCES">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">Small or negligible variations in performance between different settings or conditions</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="REPORT BASELINES">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The process of documenting standard measures or references used for comparison</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SETTINGS">
      <data key="d0">CONTEXT, CONFIGURATION</data>
      <data key="d1">Different conditions or configurations used in experiments</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="METHOD SCORE">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">A measure of the effectiveness of a specific method or algorithm</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SR">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">Success Rate, a measure of the portion of instructions where the reward equals 1</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BEST OF K">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A variant of the ReAct algorithm that selects the best result out of k iterations</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="IL">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">An abbreviation for an algorithm or method mentioned in the context of the document</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="CO-T">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">An abbreviation for a technique or method mentioned in the context of the document</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="&#923;">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">A hyperparameter used in the value function and self-consistency score</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="0.8">
      <data key="d0">VALUE, PARAMETER</data>
      <data key="d1">A specific value for the hyperparameter &#955; used in the experiments</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="0.5">
      <data key="d0">VALUE, PARAMETER</data>
      <data key="d1">A specific value for the hyperparameter &#955; used in the Game of 24 experiments</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="1">
      <data key="d0">VALUE, PARAMETER</data>
      <data key="d1">A specific value for the hyperparameter &#955; used in the Game of 24 experiments</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="0.40">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">A success rate achieved by LATS (CoT, &#955;= 1) in the Game of 24</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="0.44">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">A success rate achieved by LATS (CoT) in the Game of 24</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="50 GAMES">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">The number of games used to report the success rate in the Game of 24</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="K= 30 ITERATIONS">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">The number of iterations used in the Game of 24 experiments</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="VALIDATES">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The process of confirming the effectiveness or accuracy of a method or algorithm</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="DESIGN">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The structure or setup of a method or experiment, such as the design of the self-consistency term</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SELF-CONSISTENCY TERM">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">A component of the value function that ensures consistent results across iterations</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HOT POTQA PROMPTS">
      <data key="d0">INSTRUCTION, INPUT</data>
      <data key="d1">Prompts used in the HotPotQA dataset for question answering tasks</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="INTERLEAVING THOUGHT, ACTION, OBSERVATION STEPS">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A structured approach to solving tasks by alternating between reasoning, actions, and feedback</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PLAINS">
      <data key="d0">GEOGRAPHICAL FEATURE</data>
      <data key="d1">Plains are large areas of flat or gently rolling land that rise in elevation from around 1,800 to 7,000 feet.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="REFLECTION PROMPT">
      <data key="d0">INSTRUCTION, TASK</data>
      <data key="d1">The "REFLECTION PROMPT" is a versatile tool designed to facilitate self-reflection and improvement. It serves multiple purposes: diagnosing reasons for failure and devising new plans to enhance future performance, guiding AI assistants to explain why a function implementation is incorrect based on unit test results, and analyzing trajectories in question-answering tasks by focusing on thoughts, actions, and observations to evaluate correctness and provide a score from 1 to 10. This comprehensive approach ensures a thorough understanding of errors and promotes continuous improvement.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="PROGRAMMING PROMPT">
      <data key="d0">INSTRUCTION, TASK</data>
      <data key="d1">A prompt that provides instructions for implementing a function in a programming task, often including sample function signatures and examples.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="MINSUBARRAYSUM">
      <data key="d0">FUNCTION, ALGORITHM</data>
      <data key="d1">A function that finds the minimum sum of any non-empty sub-array of integers in a given array.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="UNIT TEST">
      <data key="d0">TEST, VALIDATION</data>
      <data key="d1">UNIT TEST is a specific test case used to validate the correctness of a function implementation. It involves checking the function's output against expected results to ensure accuracy. For example, a unit test might check if the function add(1, 2) correctly returns 3. This process is crucial for verifying that individual components of a software system perform as intended.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="ELEVATION">
      <data key="d0">ATTRIBUTE, MEASUREMENT</data>
      <data key="d1">Elevation refers to the height above sea level, in this context ranging from 1,800 to 7,000 feet for the plains.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="CORRECTNESS SCORE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">The CORRECTNESS SCORE is a metric that ranges from 1 to 10, designed to evaluate the accuracy and appropriateness of decisions or solutions based on specified criteria. It is utilized in various contexts, including assessing the correctness of a purchase decision and evaluating the accuracy of a solution in a question-answering task. This score provides a standardized measure to ensure that decisions and solutions meet predefined standards of correctness.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="QUESTION-ANSWERING TASK">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">A task that involves answering a question by analyzing trajectories, thoughts, actions, and observations.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="SAMPLE FUNCTION SIGNATURE">
      <data key="d0">CODE, EXAMPLE</data>
      <data key="d1">A sample function signature is an example of how to define a function in a programming task.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="SAMPLE FUNCTION BODY">
      <data key="d0">CODE, EXAMPLE</data>
      <data key="d1">A sample function body is an example of how to implement a function in a programming task.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="AI PYTHON ASSISTANT">
      <data key="d0">ROLE, SOFTWARE</data>
      <data key="d1">An AI assistant designed to help with Python programming tasks, including implementing functions, running unit tests, and reflecting on code performance.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="FUNCTION IMPLEMENTATION">
      <data key="d0">CODE, PROGRAMMING</data>
      <data key="d1">A specific implementation of a function in Python, provided by the AI assistant or user, which includes the function signature and body.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="UNIT TEST RESULTS">
      <data key="d0">TESTING, VALIDATION</data>
      <data key="d1">The results of running unit tests on a function implementation, indicating which tests passed and which failed.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="IMPROVED IMPLEMENTATION">
      <data key="d0">CODE, PROGRAMMING</data>
      <data key="d1">A revised version of a function implementation that addresses issues identified in the self-reflection process.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="TEST CASE GENERATION PROMPT">
      <data key="d0">INSTRUCTION, GUIDANCE</data>
      <data key="d1">A prompt that instructs the AI assistant to generate unique, diverse, and intuitive unit tests for a given function signature and docstring.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BRIGHT CITRUS DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">BRIGHT CITRUS DEODORANT by Earth Mama is a natural deodorant that is safe for sensitive skin, pregnancy, and breastfeeding. It features a bright citrus scent and contains organic calendula. This deodorant is available in a 3-ounce size, making it a convenient and effective choice for those seeking a gentle yet refreshing personal care product.</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="PRICE LOWER THAN 50.00 DOLLARS">
      <data key="d0">PRICE CONSTRAINT</data>
      <data key="d1">A price limit set by the user for the products they are searching for, specifically less than 50.00 dollars.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="EARTH MAMA">
      <data key="d0">BRAND</data>
      <data key="d1">A brand that produces natural and safe deodorants for sensitive skin, including the Bright Citrus Deodorant and Ginger Fresh Deodorant.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="GINGER FRESH DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of deodorant with a ginger fresh scent, suitable for sensitive skin, and available in a 3-ounce bottle.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BARREL AND OAK">
      <data key="d0">BRAND</data>
      <data key="d1">A brand that produces aluminum-free deodorants for men, with essential oil-based scents and 24-hour odor protection.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="CEDAR &amp; PATCHOULI DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of deodorant with a cedar and patchouli blend scent, suitable for sensitive skin, and available in a 2.7-ounce bottle.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="MIN SUM">
      <data key="d0">VARIABLE, PROGRAMMING</data>
      <data key="d1">A variable used in a function to keep track of the minimum sum encountered during the execution of the function.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="CURRENT SUM">
      <data key="d0">VARIABLE, PROGRAMMING</data>
      <data key="d1">A variable used in a function to keep track of the current sum of elements in a list during the execution of the function.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="ADD FUNCTION">
      <data key="d0">FUNCTION IMPLEMENTATION, CODE</data>
      <data key="d1">A function in Python that takes two integers, a and b, and returns their sum. The initial implementation had an error where it subtracted b from a instead of adding them.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="ERROR">
      <data key="d0">ISSUE, BUG</data>
      <data key="d1">An "ERROR" is a mistake in the function implementation where the code does not perform the intended operation, such as using the wrong operator. It is an incorrect result produced by an agent, which needs to be refined or corrected.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="OPERATOR">
      <data key="d0">SYMBOL, PROGRAMMING</data>
      <data key="d1">A symbol used in programming to perform operations on variables, such as '+' for addition and '-' for subtraction.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="DOCSTRING">
      <data key="d0">DOCUMENTATION, PROGRAMMING</data>
      <data key="d1">A string literal in Python used to document the purpose and behavior of a function, typically placed right after the function signature.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="SIGNATURE">
      <data key="d0">SYNTAX, PROGRAMMING</data>
      <data key="d1">The declaration of a function in Python, including its name, parameters, and return type.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BRIGHT CITRUS DEODORANT BY EARTH MAMA">
      <data key="d0">PRODUCT, BRAND</data>
      <data key="d1">A specific product by Earth Mama that is a natural and safe deodorant for sensitive skin, available in a 3-ounce bottle.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="GINGER FRESH DEODORANT BY EARTH MAMA">
      <data key="d0">PRODUCT, BRAND</data>
      <data key="d1">A specific product by Earth Mama that is a natural and safe deodorant for sensitive skin, available in a 3-ounce bottle.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BARREL AND OAK DEODORANT">
      <data key="d0">PRODUCT, BRAND</data>
      <data key="d1">A specific product by Barrel and Oak that is an aluminum-free deodorant for men, with essential oil-based scents and 24-hour odor protection.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="DAIRY FREE">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic of a product indicating it does not contain dairy</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="APPLE VARIETY PACK OF CHIPS">
      <data key="d0">PRODUCT</data>
      <data key="d1">A pack of chips that includes different varieties of apple flavors</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="PRICE LOWER THAN 30.00 DOLLARS">
      <data key="d0">PRICE CONSTRAINT</data>
      <data key="d1">A price limit set by the user for the products they are searching for</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE FOODS SOFT BAKED OVALS">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of breakfast bar that is nut-free, soy-free, dairy-free, non-GMO, gluten-free, and vegan, available in a variety pack</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE SOFT BAKED CHEWY BARS">
      <data key="d0">PRODUCT</data>
      <data key="d1">ENJOY LIFE SOFT BAKED CHEWY BARS are a type of chewy bar that are nut-free, soy-free, dairy-free, and gluten-free. They are available in a variety pack, making them suitable for individuals with multiple dietary restrictions.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE LENTIL CHIPS VARIETY PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A variety pack of lentil chips that are dairy-free, soy-free, nut-free, non-GMO, vegan, and gluten-free</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="SENSITIVE SKIN">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic of a product indicating it is suitable for sensitive skin</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="PREGNANCY AND BREASTFEEDING">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic of a product indicating it is safe for use during pregnancy and breastfeeding</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ORGANIC CALENDULA">
      <data key="d0">INGREDIENT</data>
      <data key="d1">An ingredient in the Bright Citrus Deodorant, known for its soothing properties</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="VARIETY PACK">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">The "VARIETY PACK" is an option for a product that includes multiple varieties or flavors. This option allows consumers to enjoy a selection of different types within a single package, providing a diverse and versatile experience.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="0.8 OUNCE (PACK OF 24)">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">The "0.8 OUNCE (PACK OF 24)" is a specific size option for a product, where each individual item weighs 0.8 ounces, and the package contains a total of 24 such items. This configuration is designed to offer a convenient bulk purchase option for consumers, ensuring they receive a substantial quantity of the product in a single package.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="3 OUNCE (PACK OF 1)">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A size option for products, specifically a single item of 3 ounces</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ASSORTED SCENTS">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A variety of scent options available for a product, including bright citrus, calming lavender, ginger fresh, and simply non-scents</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="BRIGHT CITRUS">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific scent option for a product, such as deodorant</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="CALMING LAVENDER">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific scent option for a product, such as deodorant</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="GINGER FRESH">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific scent option for a product, such as deodorant</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="SIMPLY NON-SCENTS">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific scent option for a product, such as deodorant, that is unscented</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="TRAVEL SET (4-PACK)">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A size option for products, specifically a travel set containing 4 items</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="3 OUNCE (2-PACK)">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A size option for products, specifically a pack of 2 with each item being 3 ounces</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="DILL AND SOUR CREAM">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific flavor option for a product, such as chips</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="GARLIC &amp; PARMESAN">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific flavor option for a product, such as chips</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="LIGHT SEA SALT">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific flavor option for a product, such as chips</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="MARGHERITA PIZZA">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific flavor option for a product, such as chips</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="THAI CHILI LIME">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific flavor option for a product, such as chips</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="4 OUNCE (PACK OF 12)">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A size option for products, specifically a pack of 12 with each item being 4 ounces</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="BUY NOW">
      <data key="d0">ACTION</data>
      <data key="d1">An action to purchase a product immediately</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of vegetarian bacon that is gluten-free and smoked with pepper, available in a 4-ounce pack of 2</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">PRODUCT</data>
    </node>
    <node id="PRICE LOWER THAN 40.00 DOLLARS">
      <data key="d0">PRICE CONSTRAINT</data>
      <data key="d1">A price limit set by the user for the products they are searching for</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">PRICE CONSTRAINT</data>
    </node>
    <node id="SMOKED BACON SEA SALT 3-PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A pack of three smoked bacon sea salts, including chipotle, onion, and peppered bacon flavors, all gluten-free, non-GMO, and without MSG</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">PRODUCT</data>
    </node>
    <node id="LOUISVILLE VEGAN JERKY">
      <data key="d0">PRODUCT</data>
      <data key="d1">LOUISVILLE VEGAN JERKY offers a variety pack of vegan jerky featuring five distinct flavors: Black Pepper, Buffalo Dill, Pepperoni, Maple Bacon, and Carolina BBQ. Made from non-GMO soy protein, this gluten-free product comes in packs weighing 3 ounces each.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7</data>
      <data key="d3">PRODUCT</data>
    </node>
    <node id="THINK">
      <data key="d0">ACTION</data>
      <data key="d1">An action where the user reflects on the suitability of a product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="CLICK">
      <data key="d0">ACTION</data>
      <data key="d1">An action to select or interact with a product or option on the web shop</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="FLAVOR NAME">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Different flavor options available for a product, such as dill and sour cream, garlic &amp; parmesan, light sea salt, margherita pizza, thai chili lime, and variety pack</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SIZE">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Different size options available for a product, such as 0.8 ounce (pack of 24) and 4 ounce (pack of 12)</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="RATING">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">RATING is a measure of customer satisfaction or quality, often represented numerically or as stars. Additionally, it involves the process of evaluating student responses against teacher responses, scored on a scale from 0 to 10. This dual application highlights its versatility in both consumer feedback and educational assessment contexts.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="DESCRIPTION">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A detailed explanation of the product's features and benefits</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="FEATURES">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Specific characteristics or functionalities of a product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="REVIEWS">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Customer feedback and opinions about a product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SPICY HOT PEPPER SEA SALT 3-PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A pack of three different spicy hot pepper sea salts, including Ghost Pepper, Jalapeno, and Habanero. It is all-natural, gluten-free, kosher, non-GMO, and contains no MSG, with a total weight of 12 ounces.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="NON-GMO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic indicating that the product does not contain genetically modified organisms.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="GLUTEN-FREE">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic indicating that the product does not contain gluten.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="KOSHER">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic indicating that the product meets the dietary standards of Jewish law.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="NO MSG">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic indicating that the product does not contain monosodium glutamate (MSG).</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="REFINE SEARCH">
      <data key="d0">ACTION</data>
      <data key="d1">The action of adjusting search parameters to better match desired results.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="VEGETARIAN BACON">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of bacon alternative made from vegetarian ingredients.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="4 OUNCE PACK OF 2">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A packaging characteristic indicating that the product comes in two packs, each weighing 4 ounces.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="FAIL">
      <data key="d0">STATUS</data>
      <data key="d1">An indication that the attempt or action was unsuccessful.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="JALAPENO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A type of hot pepper used in the Spicy Hot Pepper Sea Salt 3-Pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="HABANERO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A type of hot pepper used in the Spicy Hot Pepper Sea Salt 3-Pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="BLACK PEPPER">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A flavor of the Louisville Vegan Jerky variety pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="BUFFALO DILL">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A flavor of the Louisville Vegan Jerky variety pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="PEPPERONI">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A flavor of the Louisville Vegan Jerky variety pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="MAPLE BACON">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A flavor of the Louisville Vegan Jerky variety pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="CAROLINA BBQ">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A flavor of the Louisville Vegan Jerky variety pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="INVALID ACTION">
      <data key="d0">STATUS</data>
      <data key="d1">An indication that the attempted action was not recognized or allowed by the system.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="NEXT">
      <data key="d0">ACTION</data>
      <data key="d1">The action of moving to the next page or set of results in a search or navigation process.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="GHOST PEPPER">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d0">RESEARCH AREA, METHODOLOGY</data>
      <data key="d1">ADAS is a research area focused on automatically creating powerful agentic system designs, including inventing novel building blocks and/or combining them in new ways.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="SHENGRAN HU">
      <data key="d0">RESEARCHER, AUTHOR</data>
      <data key="d1">Shengran Hu is a prolific author and researcher affiliated with the University of British Columbia and the Vector Institute. He has contributed to several significant papers, including "Intelligent go-explore: Standing on the shoulders of giant foundation models," published as an arXiv preprint in 2024, and "Thought Cloning: Learning to think while acting by imitating human thinking," published in Advances in Neural Information Processing Systems in 2024. Additionally, he co-authored the paper titled "Automated Design of Agentic Systems." Shengran Hu is also known for his work on the implementation of various baselines and methods, with detailed implementations available in the repository at https://github.com/ShengranHu/ADAS. His contributions extend to the development of framework code, further showcasing his expertise in the field.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="CONG LU">
      <data key="d0">RESEARCHER, AUTHOR</data>
      <data key="d1">Cong Lu is an accomplished researcher affiliated with the University of British Columbia and the Vector Institute. He has contributed to several significant papers in the field of artificial intelligence and machine learning. Notably, he is one of the authors of the paper on Automated Design of Agentic Systems. In 2024, he co-authored "The AI Scientist: Towards fully automated open-ended scientific discovery" and "Intelligent go-explore: Standing on the shoulders of giant foundation models," both published as arXiv preprints. Additionally, in 2021, he co-authored "Varibad: Variational bayes-adaptive deep RL via meta-learning," which was published in the Journal of Machine Learning Research.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="META AGENT SEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">META AGENT SEARCH is a method and algorithm designed to iteratively discover and program high-performance agents across various domains, including reading comprehension, math, multi-task problem solving, and science. It leverages foundational models (FMs) as meta agents to create new agentic systems by utilizing basic functions like FM query APIs and formatting prompts. This method involves executing model-generated code, with safety considerations advised due to potential destructive actions from untrusted code.

META AGENT SEARCH progressively builds on an ever-growing archive of previous discoveries to optimize agentic systems, outperforming state-of-the-art hand-designed agents in challenges such as the Abstraction and Reasoning Corpus (ARC). It is particularly effective in domains where foundational models possess adequate knowledge, and it demonstrates improved results at a lower cost when using the GPT-4o-mini model.

The algorithm is part of the Automated Design of Agentic Systems (ADAS) framework, enabling the complete design of agentic systems in code space. It iteratively programs new agents, tests their performance on tasks, and adds them to an archive to inform subsequent iterations. This approach allows for the discovery of generalizable design patterns and agentic systems that perform well across different domains, with the potential for further improvement through higher-order meta-learning.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d,dc55f071b95dec721a9820d39cdb3ccd,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="FOUNDATION MODELS (FMS)">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Foundation Models (FMs) are advanced language models utilized as modules within the control flow of agentic systems to solve tasks through planning, tool usage, and iterative processing steps. These models, including notable examples like GPT and Claude, serve as powerful general-purpose agents capable of flexible reasoning and planning. FMs can write code to discover better optimization algorithms, program loss functions for preference learning, and create robotics learning environments. Additionally, they are integral to the meta agent framework, where they are queried to generate and improve code, enhancing the overall functionality and efficiency of the system.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CHAIN-OF-THOUGHT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Chain-of-Thought (Wei et al., 2022) is a state-of-the-art, manually designed agent used for reasoning and problem-solving tasks. This method is employed in the FM Module for step-by-step reasoning and solving tasks, including initial reasoning and reflecting on previous attempts. It breaks down problems into a series of thought processes, facilitating planning and reasoning in various domains such as math, reading comprehension, multi-tasking, and science. Chain-of-Thought is recognized for its specific accuracy and F1 scores, making it a crucial building block in agentic systems.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,4b43decac6833d1515992f8869ecada7,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d0">ORGANIZATION, INSTITUTION</data>
      <data key="d1">The University of British Columbia is an academic institution where some of the authors of the paper are affiliated.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VECTOR INSTITUTE">
      <data key="d0">ORGANIZATION, INSTITUTION</data>
      <data key="d1">The Vector Institute is a research institution where some of the authors of the paper are affiliated. It is also one of the organizations that supported the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CANADA CIFAR AI CHAIR">
      <data key="d0">TITLE, POSITION</data>
      <data key="d1">The Canada CIFAR AI Chair is a prestigious position held by Jeff Clune, one of the authors of the paper.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="MULTI-STEP PEER REVIEW AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">The Multi-Step Peer Review Agent is an agent discovered by the Meta Agent Search algorithm within the Reading Comprehension domain. This agent is designed to perform multi-step peer reviews, involving a sequence of stages such as initial instruction, critique, refinement, and final decision.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VERIFIED MULTIMODAL AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">The Verified Multimodal Agent is an agent discovered by Meta Agent Search in the Math domain. It serves as an example of an agent identified by the Meta Agent Search algorithm, which is specifically designed to handle tasks involving multiple modalities. This highlights its capability to process and integrate information from various sources, making it a versatile tool in the realm of mathematical problem-solving and beyond.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="DIVIDE AND CONQUER AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">The Divide and Conquer Agent is an agent discovered by the Meta Agent Search algorithm. It operates by decomposing a problem into smaller, more manageable sub-problems and assigning each sub-problem to a specialized expert. This approach allows for tasks to be divided and solved iteratively, leveraging the expertise of specialized agents to efficiently address each component of the problem. The Divide and Conquer Agent exemplifies the effectiveness of the Meta Agent Search algorithm in optimizing problem-solving processes through structured decomposition and targeted expertise.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CLAUDE">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Claude is a Foundation Model developed by Anthropic, used as a general-purpose agent for agentic tasks.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HOG">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">HOG (Histogram of Oriented Gradients) is a hand-designed feature used in computer vision, eventually replaced by learned features from Convolutional Neural Networks.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CONVOLUTIONAL NEURAL NETWORKS (CNNS)">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Convolutional Neural Networks are a type of neural network used in computer vision, known for their ability to learn features from data.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="NEURAL ARCHITECTURE SEARCH">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Neural Architecture Search (NAS) is a method for automating the design of neural network architectures, leading to high-performing models. It falls under the first pillar of AI-GAs and is a significant technique within AutoML, involving the search for the best neural network architecture for a given task. This method provides insights into neural networks by observing their emerged architecture. Notable research on NAS includes the paper titled "Neural architecture search: A survey" authored by Thomas Elsken et al., published in the Journal of Machine Learning Research in 2019, and further discussions by Shen et al. in 2023 and Huang et al. in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AUTO ML">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">AutoML (Automated Machine Learning) refers to methods that automate the process of applying machine learning to real-world problems.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">AI-Generating Algorithms (AI-GAs) are advanced methods designed to automatically generate AI systems, showcasing the superiority of learned AI systems over hand-designed ones. These algorithms focus on meta-learning architectures, learning algorithms, and generating effective learning environments and training data. By aiming to learn more components within AI systems to replace handcrafted ones, AI-GAs strive to enhance the efficiency and effectiveness of AI development, pushing the boundaries of what is possible in artificial intelligence.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ROCKT&#196;SCHEL, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rockt&#228;schel is an author cited in the paper, contributing to the research on agentic systems.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ZAHARIA ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zaharia et al. are authors cited in the paper, contributing to the research on agentic systems.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HU &amp; CLUNE, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"HU &amp; CLUNE, 2024" are the authors cited in the paper for their significant contributions to the research on chain-of-thought planning and reasoning. Their work, published in 2024, focuses on the development of methods based on chain-of-thought processes, enhancing the understanding and application of planning and reasoning techniques.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="LEWIS ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"LEWIS ET AL., 2020" are authors cited in the paper for their significant contributions to the research on memory structures in agentic systems. They are particularly known for their work published in 2020, which focuses on Retrieval-Augmented Generation (RAG) techniques. Their development of external memory and RAG methods has been influential in advancing the field.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,6bdf681c0bd9e401ac72344a6a0ae479,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ZHANG ET AL., 2024C">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang et al., 2024C, are the authors cited in the paper for their significant contributions to the research on memory structures in agentic systems. Their work, published in 2024, includes the development of external memory and Retrieval-Augmented Generation (RAG) techniques, which are pivotal in advancing the understanding and implementation of memory mechanisms within these systems.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="QU ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qu et al., 2024, are the authors cited in the paper for their significant contributions to the research on tool use in agentic systems. Their work, published in 2024, focuses on the development of innovative tool use techniques, advancing the understanding and application of these methods within the field.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="MADAAN ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Madaan et al., 2024, are researchers who developed and authored the Self-Refine method, published in 2024. Their work focuses on self-reflection techniques to enhance the novelty and accuracy of generated agents. The Self-Refine strategy is a significant contribution to the Meta Agent Search algorithm, reflecting their expertise in agentic systems and error-free generation processes.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ANTHROPIC">
      <data key="d0" />
      <data key="d1">Anthropic is a company that introduced the next generation of Claude, including Claude 3 and Claude 3.5 Sonnet, in 2024. Additionally, Anthropic is the organization that developed the Claude Foundation Model.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">ORGANIZATION, COMPANY</data>
    </node>
    <node id="MEMORY STRUCTURES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="TOOL USE">
      <data key="d0" />
      <data key="d1">TOOL USE refers to the task of enabling models to interact with external tools or services via APIs, thereby extending their functionality and accessing external data. In the context of AI, tool use involves the manipulation of tools to achieve specific goals, signifying the ability of an AI system to utilize available resources or auxiliary systems to solve complex tasks. This skill can be taught to AI models using data generated by AgentInstruct. Tool use is a crucial building block for agentic systems, allowing agents to interact with and manipulate tools to achieve their objectives. Additionally, the ability of agentic systems to utilize external tools or resources to accomplish their goals is a component that can be discovered in ADAS.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c212c1467564ad33330b1f655a8e27e,427e98b00e49b6a8f8649054122dd45b,81c504ffbcc5ed882e234802135295ba,b88745a13b69cecbc0ee9c3af41389bf,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VISUAL PARADIGM">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Visual Paradigm is a method or approach used by the Verified Multimodal Agent to handle tasks involving visual data.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VISUAL ANALYZER">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">Visual Analyzer is a component of the Verified Multimodal Agent that analyzes visual data to provide answers.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="EXPERTS">
      <data key="d0">CONCEPT, ROLE</data>
      <data key="d1">EXPERTS are individuals or systems with specialized knowledge used by agents like the Multi-Step Peer Review Agent to review tasks and provide answers. They evaluate various specific traits such as efficiency, readability, and simplicity in the feedback mechanisms of systems like ADAS and Meta Agent Search. By providing detailed feedback on these traits, experts help refine answers more effectively, ensuring a comprehensive and high-quality review process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="REVIEWERS">
      <data key="d0">CONCEPT, ROLE</data>
      <data key="d1">Reviewers are individuals or systems that evaluate the answers provided by agents like the Multi-Step Peer Review Agent.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="SUB-PROBLEM">
      <data key="d0">CONCEPT, ACTIVITY</data>
      <data key="d1">A sub-problem is a smaller, more manageable part of a larger task, often used in the Divide and Conquer Agent's approach.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ENSEMBLE ANSWER">
      <data key="d0">CONCEPT, RESULT</data>
      <data key="d1">An ensemble answer is a combined result from multiple experts or agents, used to provide a more accurate solution to a task.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="META AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">The META AGENT is an advanced system designed to iteratively program, test, and refine other agents, building on previous discoveries to create new, effective agentic systems. It operates within the framework of the Meta Agent Search method, utilizing foundational models such as GPT-4o-2024-05-13 for evaluation across various domains. The META AGENT employs prompts and control flows to guide its thought process and implementation steps, aiming to solve complex tasks by generating code solutions rather than directly outputting answers. This system is integral to the Automated Design of Agentic Systems (ADAS), where it leverages higher-order meta-learning to continuously improve the agents it creates.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,4b43decac6833d1515992f8869ecada7,6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,84317ae35cc75d612287186d93461447,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="AGENT ARCHIVE">
      <data key="d0">CONCEPT, STORAGE</data>
      <data key="d1">An agent archive is a storage of discovered agents used by the meta agent to inform subsequent iterations and improve performance.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CODE">
      <data key="d0">CONCEPT, DATA</data>
      <data key="d1">CODE refers to the programming instructions used to define the behavior and functionality of agents. It encompasses a section in the output where the meta agent provides the complete Python code for the "forward()" function of the proposed agent architecture. Additionally, the code generated or refined during the problem-solving process is also considered part of this entity.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,84317ae35cc75d612287186d93461447,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="TURING COMPLETE">
      <data key="d0">CONCEPT, PROPERTY</data>
      <data key="d1">Turing Complete refers to a system of data-manipulation rules, such as a programming language, that can simulate any Turing machine, indicating its computational universality. This means that a Turing Complete system has the capability to perform any computation that can be described algorithmically.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="COMPUTE">
      <data key="d0">CONCEPT, RESOURCE</data>
      <data key="d1">Compute refers to the computational power available for running algorithms and training models.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="DATA">
      <data key="d0">CONCEPT, RESOURCE</data>
      <data key="d1">Data refers to the information used to train models and inform the behavior of agents.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HISTORY OF MACHINE LEARNING">
      <data key="d0">CONCEPT, FIELD</data>
      <data key="d1">The history of machine learning refers to the development and evolution of machine learning techniques and methodologies over time.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HAND-DESIGNED SOLUTIONS">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Hand-designed solutions are manually created methods or systems, often replaced by more efficient learned solutions in machine learning.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="LEARNED SOLUTIONS">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Learned solutions are methods or systems developed through machine learning, often more efficient than hand-designed solutions.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="COMPUTER VISION">
      <data key="d0">FIELD, APPLICATION</data>
      <data key="d1">Computer vision is a field of study focused on enabling machines to interpret and understand visual information from the world.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HUTTER ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hutter et al., 2019, are the authors of a study published in 2019 that discusses and contributes to the research area of AutoML methods. Their work is cited in the paper for its significant contributions to the field of AutoML.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CLUNE, 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Clune, in 2019, is an author recognized for significant contributions to the research on AI-Generating Algorithms (AI-GAs) and the broader history of machine learning. Clune's work, published in 2019, delves into the potential of AI-GAs and Artificial General Intelligence (AGI), highlighting the advancements and future possibilities within these fields.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DALAL &amp; TRIGGS, 2005">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dalal &amp; Triggs are authors cited in the paper for contributions to the research on HOG features in computer vision.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="KRIZHEVSKY ET AL., 2012">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Krizhevsky et al., 2012, are the authors of a seminal study introducing Convolutional Neural Networks (CNNs). Their contributions to the research on CNNs are widely cited and have significantly influenced the field of deep learning and computer vision.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ELSKEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Elsken is an author cited in the paper for contributions to the research on Neural Architecture Search.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="APPENDIX F">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Appendix F contains the detailed code of example agents.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="CNN">
      <data key="d0">TECHNOLOGY, NEURAL NETWORK</data>
      <data key="d1">Convolutional Neural Networks (CNNs) are a type of neural network used primarily in image recognition and processing, introduced by Krizhevsky et al. in 2012.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AUTOML">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">AutoML (Automated Machine Learning) is a research area that focuses on the automation of machine learning model design and optimization. Similar to ADAS, AutoML aims to streamline the process of applying machine learning to real-world problems. As discussed by Hutter et al. in 2019, AutoML methods encompass techniques for automating various aspects of machine learning, including the design of neural network architectures and learning algorithms.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AI-GA">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">AI-GA (Artificial Intelligence-Generative Algorithms) is a research area that includes Advanced Driver Assistance Systems (ADAS) and focuses on advancing AI capabilities through generative algorithms. AI-Generating Algorithms (AI-GAs), introduced by Clune in 2019, are methods that automatically generate AI systems, demonstrating superiority over hand-designed systems. This field aims to push the boundaries of AI by leveraging generative techniques to create more efficient and effective AI solutions, highlighting the potential for automated design to surpass traditional, manually crafted approaches.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="LLM ALIGNMENT">
      <data key="d0">RESEARCH AREA</data>
      <data key="d1">LLM alignment involves aligning large language models with specific goals or behaviors, often using learned loss functions as discussed by Lu et al. in 2024a.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LEARNED LOSS FUNCTIONS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Learned loss functions are functions that are automatically learned to optimize the performance of models, outperforming hand-designed ones like DPO, as discussed by Lu et al. in 2024a.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="DPO">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">DPO is a hand-designed loss function used in LLM alignment, discussed by Rafailov et al. in 2024.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AI SCIENTIST">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">The AI Scientist, introduced by Lu et al. in 2024b, is an automated research pipeline that develops novel machine learning algorithms.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="OMNI-EPIC">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">OMNI-EPIC is an algorithm developed by Maxence Faldor et al. in 2024, as detailed in their research paper titled "Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code," published as an arXiv preprint. This innovative system enables Foundation Models (FMs) to create robotics learning environments by programming in code. OMNI-EPIC aims to generate these environments in an open-ended manner, demonstrating both creativity and efficiency in its automatic generation process.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ADAS">
      <data key="d0">RESEARCH AREA</data>
      <data key="d1">ADAS (Automated Design of Agentic Systems) is a comprehensive framework and a proposed research area focused on the automated invention and design of powerful agentic systems. It leverages available API access to foundational models (FMs) without the need for expensive hardware like GPUs, demonstrating the ease of programming sophisticated agentic systems. ADAS aims to progressively discover agents that outperform state-of-the-art hand-designed baselines and invent novel design patterns through the innovation and combination of various stepping stones. This research area involves using a search algorithm to explore a search space that optimizes an evaluation function, similar to research areas in AI-GAs and AutoML. Additionally, ADAS utilizes programming languages as the search space for defining and searching for agents, potentially contributing to the creation of Artificial General Intelligence (AGI) by learning more components in agentic systems beyond just prompts.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,cc802d9b841fde55e9c0c2ba0ef7869d,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ARC">
      <data key="d0">BENCHMARK, TASK</data>
      <data key="d1">ARC, also known as the AI2 Reasoning Challenge or the Abstraction and Reasoning Corpus, is a benchmark developed by AllenAI to evaluate the reasoning, problem-solving, and general intelligence of AI models. Introduced by Chollet in 2019, ARC is designed to measure the performance of AI agents in solving challenging logic puzzles and reasoning tasks. It is used to assess the capabilities of foundational models such as GPT-3.5, GPT-4, Claude-Haiku, and Claude-Sonnet, as well as agents discovered by Meta Agent Search. The benchmark is notable for its use in experiments, with each run costing approximately $500 USD. Notably, the model Orca-3 achieved a score of 92.47 on ARC, marking a 12% improvement over its predecessor, Orca-2.5.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2,81c504ffbcc5ed882e234802135295ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="DROP">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">DROP (Discrete Reasoning Over Paragraphs) is a comprehensive benchmark used to evaluate the reading comprehension capabilities of models and agents. It was introduced by Dheeru Dua et al. in their 2019 research paper titled "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs," presented at the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. This dataset is designed to assess the ability of models to perform discrete reasoning and comprehend detailed information across multiple paragraphs. It involves resolving references in questions and performing discrete operations such as sorting, counting, and addition. DROP is particularly noted for its use in one-shot style questions and for providing ground-truth answer values. The benchmark has shown significant improvements in model performance, with Orca-3 scoring 71.14, marking a 22% improvement over Orca-2.5.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,103d98395c393552cc954c89d4e59f50,10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,84317ae35cc75d612287186d93461447,86f77e15d41cbd0cb33f635ccb2cb66b,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MGSM">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MGSM (Math Generalization and Symbolic Manipulation) is a benchmark used to evaluate the mathematical abilities of agents, showing significant improvement in accuracy rates. It is also referred to as the Multilingual Grade School Math Benchmark, which assesses mathematical problem-solving skills across various languages to ensure broad and effective multilingual performance. Discussed by Shi et al. in 2023, MGSM is relevant to the Meta Agent Search method, evaluating the performance and transferability of agents in the math domain. This benchmark dataset is crucial for understanding the capabilities of agents discovered by Meta Agent Search, including the Verified Multimodal Agent.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="GSM8K">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">GSM8K, also known as Grade School Math 8K, is a benchmark dataset used to evaluate the performance of AI models on math problems, particularly in the context of generative teaching and language models. It consists of high-quality, diverse grade school math word problems that require between 2 and 8 steps to solve using basic arithmetic operations. This dataset is instrumental in assessing the transferability of discovered agents from MGSM math tasks to held-out math tasks, showing significant improvement in accuracy rates. Notably, Orca-3 demonstrated a 54% improvement on GSM8K compared to both Orca-2.5 and Mistral-7b-Instruct, with an overall score of 83.09, highlighting its effectiveness in evaluating and enhancing the capabilities of AI models in math-related tasks. The benchmark was discussed by Cobbe et al. in 2021.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,103d98395c393552cc954c89d4e59f50,24d7b89ae9522ae60d2317984951355b,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="GSM-HARD">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">GSM-HARD is a dataset used for evaluating the performance of algorithms in more challenging math-related tasks. It serves as a benchmark for assessing the transferability of discovered agents from MGSM math tasks to more complex math tasks, demonstrating significant improvement in accuracy rates. This dataset was discussed by Gao et al. in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="FM">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Foundation Models (FMs) are large language models increasingly proficient in coding, used as meta agents in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LU ET AL., 2024A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu et al., 2024a, are the authors of a study discussing learned loss functions in LLM alignment. Additionally, they have conducted research on DiscoPOP, which was also published in 2024.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LU ET AL., 2024B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu et al., 2024b, are authors referenced in the text, known for their significant contributions in 2024. Their work encompasses subjective answer evaluations in Advanced Driver Assistance Systems (ADAS) and the introduction of the AI Scientist.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LU ET AL., 2024C">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu et al., 2024C, are researchers who developed the Quality-Diversity method and authored a study discussing open-endedness algorithms that leverage human notions of interestingness. Their work, published in 2024, includes an open-endedness algorithm referenced in the Meta Agent Search algorithm.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ZHANG ET AL., 2024A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang et al., 2024A, are researchers known for their significant contributions to the field of open-ended algorithms. Their work, published in 2024, focuses on algorithms that leverage human notions of interestingness. This study is particularly relevant in the context of Meta Agent Search, where their insights into open-endedness and AI-GAs (Artificial Intelligence-Generative Algorithms) play a critical role. Their research is frequently referenced in discussions about the development and application of open-ended algorithms.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,6bdf681c0bd9e401ac72344a6a0ae479,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="FERNANDO ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fernando et al., 2024, are the authors of a study focusing on designing prompts in ADAS (Advanced Driver Assistance Systems) methods. They are also credited with the development of the PromptBreeder algorithm, which was published in the same year. Their contributions to the ADAS research area include works like PromptBreeder and other significant advancements, all published in 2024.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="YANG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang et al., 2024, are the authors of a study focusing on designing prompts in Advanced Driver Assistance Systems (ADAS) methods. Additionally, they are credited with the development and publication of the OPRO algorithm in the same year. Their work in 2024 highlights significant contributions to the field of ADAS through innovative prompt design and algorithmic advancements.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="BOYER &amp; MOORE, 1983">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Boyer and Moore are the authors of a study in 1983 discussing the Turing Completeness of programming languages.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LADHA, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ladha is the author of a study in 2024 discussing the Turing Completeness of programming languages.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="ELSKEN ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Elsken et al., 2019, are the authors of a significant study published in 2019 that focuses on Neural Architecture Search (NAS). Their research contributes to the method of NAS, which is a pivotal area in the field of machine learning and artificial intelligence.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="RAFAILOV ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rafailov et al. are the authors of a study in 2024 discussing DPO, a hand-designed loss function.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="FALDOR ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Faldor et al., 2024, are researchers known for their significant contributions to the field of open-ended algorithms and AI-GAs (Artificial Intelligence-Generative Algorithms). Their work is particularly influential in the context of Meta Agent Search. In 2024, they published a study discussing OMNI-EPIC, a system designed for generating robotics learning environments. This research highlights the development and application of the OMNI-EPIC algorithm, underscoring its importance in advancing the capabilities of robotics and AI systems.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="CHOLLET, 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">CHOLLET, 2019 is the author of a study introducing the ARC logic puzzle task, which was published in 2019. This task is used as a benchmark in various experiments, highlighting its significance in the field.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="DUA ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dua et al. are the authors of a study published in 2019 discussing the DROP reading comprehension benchmark. The DROP benchmark, introduced by Dua et al. in 2019, is used to assess the reading comprehension abilities of discovered agents.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="SHI ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shi et al., 2023, are the authors associated with the discovery of the Verified Multimodal Agent in the Math domain. They also authored a study discussing the MGSM math task benchmark, which was published in 2023. The MGSM benchmark, created by Shi et al., is used to evaluate the math abilities of the discovered agents.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="AGENTIC SYSTEMS">
      <data key="d0">SYSTEM, TECHNOLOGY</data>
      <data key="d1">Agentic Systems refer to systems designed to perform tasks autonomously, often involving complex decision-making and interactions. These systems are primarily machine learning systems that operate over natural language, enabling them to perform tasks and interact with environments in a manner interpretable to humans. In the context of automated design, Agentic Systems utilize Foundation Models (FMs) as modules in the control flow to solve tasks by planning, using tools, and carrying out multiple, iterative steps of processing.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="BUILDING BLOCKS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Building blocks are fundamental components or design patterns that serve as the essential elements in the construction of more complex agentic systems. These building blocks can be automatically discovered and combined within Advanced Driver Assistance Systems (ADAS) to optimize and enhance their functionality. By leveraging these foundational components, developers can create sophisticated systems that exhibit advanced levels of autonomy and efficiency.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FOUNDATION MODELS">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Foundation Models (FMs) are large language models that are proficient in coding and can be used as meta agents in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="ARC LOGIC PUZZLE TASK">
      <data key="d0">BENCHMARK, TASK</data>
      <data key="d1">The ARC logic puzzle task is a benchmark designed to test the general intelligence of AI systems, introduced by Chollet in 2019.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="READING COMPREHENSION">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">Reading Comprehension is a critical domain where foundational models possess adequate knowledge to solve questions, with errors mainly due to hallucinations or calculation mistakes. It involves processing and understanding text, which is necessary for learning and encompasses decoding, fluency, and vocabulary knowledge. This skill enables scenarios like question answering, search, and grounded reasoning. Reading comprehension is particularly crucial for language models, especially Small Language Models (SLMs), and is evaluated through targeted training with AgentInstruct. It is a domain where agentic systems can be applied and their performance evaluated, often using benchmarks such as the DROP benchmark tested by Meta Agent Search. Additionally, reading comprehension tasks serve as benchmarks to evaluate the understanding and interpretation of text by AI systems, and it is one of the skills taught to language models using synthetic data generated by AgentInstruct.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c212c1467564ad33330b1f655a8e27e,2901d5e2711fa4f32d39cd8eea36cd71,4884e8429ca1e567dadf5e22b4b68274,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba,86f77e15d41cbd0cb33f635ccb2cb66b,bc26e68b0b2783ba912b9e5606d9eb0b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MATH TASKS">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">Math tasks are benchmarks used to evaluate the mathematical problem-solving abilities of AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="SCIENCE QUESTIONS">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">Science questions are benchmarks used to evaluate the scientific knowledge and reasoning abilities of AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="MULTI-TASK PROBLEM SOLVING">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">Multi-task problem solving involves benchmarks that test the ability of AI systems to solve a variety of tasks across different domains. This domain is specifically tested by Meta Agent Search using the MMLU benchmark, which evaluates the ability to solve various types of problems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="TRANSFERABILITY">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Transferability refers to the ability of discovered agents to perform well across different domains and tasks, demonstrating robustness and adaptability.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="F1 SCORE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">The F1 Score is a performance metric used to evaluate the effectiveness of models and agents, particularly in tasks such as reading comprehension and math. It represents the balance between precision and recall, making it a crucial measure for assessing the accuracy and overall performance of generated agents in algorithms like the Meta Agent Search.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ACCURACY RATE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">The "Accuracy Rate" is a performance metric used to evaluate the correctness and effectiveness of a model's predictions, particularly in math tasks. It is specifically utilized to assess the performance of generated agents within the Meta Agent Search algorithm, ensuring that the agents' predictions align accurately with the expected outcomes in mathematical contexts. This metric is crucial for determining the reliability and precision of models and agents in computational and algorithmic evaluations.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="BENCHMARK">
      <data key="d0">CONCEPT, EVALUATION</data>
      <data key="d1">A benchmark is a standard or set of standards used to evaluate the performance of AI systems across various tasks and domains. Specifically, in the context of the Meta Agent Search algorithm, benchmarks serve as metrics to assess its performance. Examples of such benchmarks include ARC, DROP, and MGSM. These benchmarks provide a consistent and objective means to measure and compare the effectiveness of different AI systems, ensuring a comprehensive understanding of their capabilities and limitations.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="HAND-DESIGNED BASELINES">
      <data key="d0">CONCEPT, EVALUATION</data>
      <data key="d1">Hand-designed baselines are manually created models or algorithms used as a reference point to evaluate the performance of automated systems like those in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="OPEN-ENDEDNESS ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Open-endedness algorithms are methods that encourage the exploration of novel and interesting solutions, often leveraging human notions of interestingness.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="INTERESTINGNESS">
      <data key="d0">CONCEPT, EVALUATION</data>
      <data key="d1">Interestingness refers to the quality of being novel or worthwhile, used as a criterion in open-endedness algorithms to guide the exploration of new agents.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="ARCHIVE">
      <data key="d0">COMPONENT, SYSTEM</data>
      <data key="d1">ARCHIVE is a storage system utilized in the Meta Agent Search algorithm to retain discovered agents and their associated evaluation metrics. This system plays a crucial role in aiding the meta agent to generate more interesting and effective agents in subsequent iterations. The archive is continuously updated at every iteration with new agents and their performance metrics, ensuring that the meta agent has access to a comprehensive history of previous discoveries and evaluations. This iterative updating process enhances the meta agent's ability to refine and improve its search and creation strategies over time.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="ITERATION">
      <data key="d0">CONCEPT, PROCESS</data>
      <data key="d1">Iteration in Meta Agent Search refers to the repeated cycles of discovering, creating, evaluating, and refining agents to improve performance and discover more effective agentic systems. This process involves the meta agent continuously programming new agents, evaluating their performance, and updating the archive until the maximum number of iterations is reached. Through this iterative process, agents repeatedly refine and improve solutions to create higher quality data.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="CODE SPACE">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Code space refers to the domain of possible programs that can be generated and explored by ADAS algorithms to discover new agentic systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="CONTROL FLOWS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Control flows are the sequences of operations or decisions within a program, a component that can be discovered in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AGENTIC SYSTEM DESIGN">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Agentic system design involves the creation and optimization of systems that can perform tasks autonomously, a key focus of ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="RESEARCH COMMUNITY">
      <data key="d0">GROUP, ORGANIZATION</data>
      <data key="d1">The research community refers to the collective group of researchers and scientists working on advancing the field of AI and agentic systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="EXISTING WORKS">
      <data key="d0">CONCEPT, RESEARCH</data>
      <data key="d1">Existing works refer to previous studies and methods that have contributed to the field of ADAS, often focusing on specific components like prompts.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, RESEARCH</data>
    </node>
    <node id="FLEXIBLE DESIGN PATTERNS">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Flexible design patterns refer to adaptable and reusable solutions in agentic system design, which can be automatically discovered in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="META AGENT PROGRAMMING">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Meta agent programming involves the use of a meta agent to create and optimize other agents in an automated manner, a key approach in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="NOVEL AGENTS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Novel agents are newly discovered or created agents that exhibit unique or improved behaviors, often generated by meta agents in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">COMPONENT, TECHNOLOGY</data>
    </node>
    <node id="ROBUSTNESS">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Robustness refers to the ability of agentic systems to maintain performance across different and challenging domains, demonstrating their reliability and adaptability.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="DOMAIN TRANSFER">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Domain transfer involves the ability of agentic systems to apply learned knowledge and skills from one domain to another, a key aspect of ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="SIMILAR DOMAINS">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Similar domains refer to areas or tasks that share common characteristics, making it easier for agentic systems to transfer knowledge and skills between them.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="DISSIMILAR DOMAINS">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Dissimilar domains refer to areas or tasks that are significantly different, posing a greater challenge for agentic systems to transfer knowledge and skills between them.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="MATHEMATICS">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Mathematics is a domain involving numerical and logical problem-solving tasks, often used as a benchmark for evaluating agentic systems. It is a field where agentic systems can be applied and their performance can be rigorously assessed.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="READING COMPREHENSION TASKS">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">Reading comprehension tasks are benchmarks used to evaluate the understanding and interpretation of text by AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">TASK, BENCHMARK</data>
    </node>
    <node id="SCIENCE">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Science is a domain involving the study of the natural world, often used as a benchmark for evaluating agentic systems. It is tested by Meta Agent Search using the GPQA benchmark to evaluate the ability to solve complex scientific questions. In this domain, Meta Agent Search outperforms baselines, although the performance gap is smaller compared to other domains. Additionally, Science is a non-math domain where the performance of agents is evaluated.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="MULTI-TASKING">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Multi-tasking refers to the ability of agentic systems to handle multiple tasks simultaneously or in sequence, demonstrating their versatility and efficiency.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="GENERAL INTELLIGENCE">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">General intelligence refers to the overall cognitive ability of AI systems to understand, learn, and apply knowledge across a wide range of tasks and domains.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="AI SYSTEMS">
      <data key="d0">SYSTEM, TECHNOLOGY</data>
      <data key="d1">AI systems are computational systems designed to perform tasks that typically require human intelligence, such as learning, reasoning, and problem-solving.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">SYSTEM, TECHNOLOGY</data>
    </node>
    <node id="HAND-DESIGNED AGENTS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Hand-designed agents are manually created AI systems, often used as baselines to compare the performance of automated systems like those in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">COMPONENT, TECHNOLOGY</data>
    </node>
    <node id="LEARNED AGENTS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Learned agents are AI systems that are automatically discovered and optimized through methods like ADAS, often outperforming hand-designed agents.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">COMPONENT, TECHNOLOGY</data>
    </node>
    <node id="RESEARCH QUESTION">
      <data key="d0">CONCEPT, RESEARCH</data>
      <data key="d1">A research question is a specific query that guides the investigation and exploration of new ideas and methods in a study, such as the automation of agentic system design in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, RESEARCH</data>
    </node>
    <node id="EVIDENCE">
      <data key="d0">CONCEPT, RESEARCH</data>
      <data key="d1">Evidence refers to the data and findings that support the effectiveness and validity of a proposed method or approach, such as the performance of learned agents in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, RESEARCH</data>
    </node>
    <node id="DISCOVERY">
      <data key="d0">CONCEPT, PROCESS</data>
      <data key="d1">Discovery refers to the process of finding new and useful components or agents in ADAS, often through automated methods and meta agent programming.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, PROCESS</data>
    </node>
    <node id="COMBINATION">
      <data key="d0">CONCEPT, PROCESS</data>
      <data key="d1">Combination refers to the process of integrating different building blocks to create effective agentic systems, a key challenge in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, PROCESS</data>
    </node>
    <node id="INTERACTION">
      <data key="d0">CONCEPT, PROCESS</data>
      <data key="d1">Interaction refers to the ways in which different components or agents work together within an agentic system, influencing its overall performance and effectiveness.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, PROCESS</data>
    </node>
    <node id="CREATIVITY">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Creativity refers to the ability of AI systems to generate novel and valuable ideas or solutions, demonstrated by systems like OMNI-EPIC in generating robotics learning environments.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="HUMAN EFFORT">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Human effort refers to the manual work required to design and develop agentic systems, which ADAS aims to reduce through automation.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="CHALLENGE">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">A challenge is a difficult task or problem that requires innovative solutions, often addressed through the discovery and combination of building blocks in ADAS.A challenge is a difficult task or problem that requires innovative solutions, often addressed through the discovery and combination</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="RESEARCH AREA">
      <data key="d0">CONCEPT, RESEARCH</data>
      <data key="d1">A research area is a field of study focused on exploring and advancing specific topics, such as the Automated Design of Agentic Systems (ADAS).</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="INITIAL EVIDENCE">
      <data key="d0">CONCEPT, RESEARCH</data>
      <data key="d1">Initial evidence refers to the preliminary data and findings that suggest the potential effectiveness of a proposed method or approach, such as the performance of learned agents in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="USEFUL BUILDING BLOCKS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Useful building blocks are fundamental components that are effective in constructing agentic systems, often discovered through automated methods in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="SEARCH SPACE">
      <data key="d0">COMPONENT</data>
      <data key="d1">SEARCH SPACE refers to the range of possible configurations and components that can be explored and optimized in agentic systems. In the context of ADAS (Advanced Driver Assistance Systems), the search space defines which agentic systems can be represented and thus discovered. It can include various structures such as text prompts, graph structures, and feed-forward networks. This comprehensive understanding of the search space is crucial for identifying and analyzing the intricate connections and hierarchies within these systems, ensuring a thorough grasp of their dynamics and interactions.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="EVALUATION FUNCTION">
      <data key="d0">COMPONENT</data>
      <data key="d1">The "EVALUATION FUNCTION" is a critical component used to assess the performance of discovered agents. It is designed to be optimized to reduce costs and improve efficiency. In the context of Advanced Driver Assistance Systems (ADAS), the evaluation function specifically defines how to evaluate a candidate agent based on target objectives such as performance, cost, latency, and safety. This function plays a pivotal role in ensuring that the agents meet the desired criteria and operate effectively within the system.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="PROMPTBREEDER">
      <data key="d0">ALGORITHM</data>
      <data key="d1">"PromptBreeder is an algorithm developed by Chrisantha Fernando et al., as detailed in their 2024 research paper titled 'Promptbreeder: Self-referential self-improvement via prompt evolution.' The algorithm leverages Foundation Models (FMs) to automate prompt engineering for agents, with a particular focus on enhancing reasoning capabilities through the careful phrasing of instructions in the prompts. PromptBreeder operates by mutating the text prompts of an agent while maintaining other components, such as control flow, unchanged. It is utilized within the search space of Advanced Driver Assistance Systems (ADAS)."</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ZHUGE ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhuge et al., 2024, are the authors of the GPT-Swarm algorithm, published in 2024. Additionally, they have contributed to works exploring search spaces such as graph structures and utilizing reinforcement learning as search algorithms in Advanced Driver Assistance Systems (ADAS), also published in 2024.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="SUTTON &amp; BARTO, 2018">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"Sutton &amp; Barto, 2018" refers to the authors Sutton and Barto, who are recognized for their influential work published in 2018. Their research focuses on the critical exploration-exploitation trade-off in search algorithms, a concept that is particularly relevant in the context of Advanced Driver Assistance Systems (ADAS). Their contributions have significantly shaped the understanding and implementation of balancing exploration and exploitation within these algorithms.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="AI-GAS">
      <data key="d0">RESEARCH AREA</data>
      <data key="d1">AI-GAS, also known as Artificial Intelligence-Generative Algorithms, is a research area that focuses on the automated design and optimization of algorithms. This field is similar to ADAS (Automated Design and Synthesis), emphasizing the creation of algorithms that can generate other algorithms, thereby advancing the development of general artificial intelligence. A notable contribution to this field is the research paper titled "AI-GAS: AI-Generating Algorithms, an Alternate Paradigm for Producing General Artificial Intelligence," authored by Jeff Clune and published as an arXiv preprint in 2019. This paper explores the potential of AI-GAS to revolutionize the way general AI is produced, proposing a novel approach that leverages the generative capabilities of AI to create more sophisticated and efficient algorithms.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="CHASE, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chase is an author who contributed to the definitions and terminologies of agentic systems, published in 2024.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="NG, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ng is an author who contributed to the definitions and terminologies of agentic systems, published in 2024.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="SEARCH ENGINE TOOLS">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">SEARCH ENGINE TOOLS are components that can be used within the LangChain framework to enhance agentic systems. These tools represent existing human efforts that can be utilized as building blocks in Advanced Driver Assistance Systems (ADAS) to improve efficiency and performance. By integrating search engine tools, both LangChain and ADAS can leverage enhanced capabilities, ensuring a comprehensive and dynamic approach to system optimization.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="COST">
      <data key="d0">OBJECTIVE</data>
      <data key="d1">COST is a multifaceted concept within the realm of algorithmic analysis and agentic systems. It primarily refers to the resource-intensive nature of generating synthetic data with multiple agents using large language models and tools. This aspect highlights the significant limitations posed by the high resource demands required for such processes. Additionally, COST serves as an objective in the evaluation function of Advanced Driver Assistance Systems (ADAS), where it is used to assess the economic efficiency of these agentic systems. By considering both the resource constraints and the economic implications, COST plays a crucial role in the comprehensive analysis and optimization of algorithmic and agentic frameworks.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="LATENCY">
      <data key="d0">OBJECTIVE</data>
      <data key="d1">Latency is an objective used in the evaluation function of ADAS to assess the response time of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="SAFETY">
      <data key="d0">OBJECTIVE</data>
      <data key="d1">Safety is an objective used in the evaluation function of ADAS to assess the reliability and security of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="FMS">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">Foundational Models (FMs) are powerful, large-scale machine learning models that can be adapted to a wide range of tasks. In the context of ADAS (Advanced Driver Assistance Systems), FMs are utilized to program agentic systems without the need for expensive hardware like GPUs. These advanced language models are employed for various purposes, including programming loss functions for preference learning, writing reward functions for reinforcement learning, and creating robotics learning environments. Additionally, FMs serve as meta agents in the Meta Agent Search algorithm, providing essential functions such as querying and formatting prompts to program new agents.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FUNSEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">FUNSEARCH is an algorithm referenced in the context of defining a "forward" function to create new agentic systems. It serves as a comparison point for Meta Agent Search. Additionally, FUNSEARCH involves Foundation Models writing code to discover better optimization algorithms. This dual role highlights its significance in both theoretical and practical advancements in algorithmic development.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (COT)">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Chain-of-Thought (COT) is a method that instructs the agent to output the reasoning before answering to improve complex problem-solving through intermediate steps. It is a state-of-the-art hand-designed agent baseline used for experiments on ARC. Additionally, COT is a strategy employed in Meta Agent Search to generate possible answers, refine them, and ensemble the best answers, involving the use of multiple COTs for enhanced refinement.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="LLM DEBATE">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">LLM Debate (Du et al., 2023) is a state-of-the-art, manually designed agent used for reasoning and problem-solving tasks across various domains. It is specifically employed for planning and reasoning in areas such as math, reading comprehension, multi-tasking, and science. The agent's performance is quantified through specific accuracy and F1 scores. Additionally, LLM Debate is a strategy mentioned in the context of Meta Agent Search, which involves the use of multiple critics to enhance the refinement of generated agents.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="QUALITY-DIVERSITY">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Quality-Diversity (Lu et al., 2024c) is a state-of-the-art, hand-designed agent used for reasoning and problem-solving tasks across various domains, including math, reading comprehension, multi-tasking, and science. It aims to balance the exploration of diverse solutions with the quality of those solutions. This concept is integral to search algorithms, where it conducts three iterations to collect diverse answers based on previously proposed ones. Quality-Diversity is also a simplified version of Intelligent Go-Explore, producing and ensembling diverse answers to better explore potential solutions. It serves as a baseline for experiments on the Abstraction and Reasoning Corpus (ARC) and is utilized in Meta Agent Search to encourage the exploration of novel or worthwhile agents based on an ever-growing archive of previous discoveries. Specific accuracy and F1 scores have been reported for its performance in various tasks.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ROMERA-PAREDES ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Romera-Paredes et al. are the authors of research on the FunSearch algorithm, published in 2024. The FunSearch algorithm, developed by Romera-Paredes et al., is also referenced in the Meta Agent Search algorithm, highlighting its significance and influence in the field.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="FORWARD FUNCTION">
      <data key="d0">FUNCTION, METHOD</data>
      <data key="d1">The FORWARD FUNCTION is a critical component within the Agent System, specifically utilized in the Meta Agent Search algorithm. It processes task information and returns either a namedtuple Info or a string as the answer. This function plays a pivotal role in defining a new agentic system by taking in task information and outputting the agent&#8217;s response to the task.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="VALIDATION DATA">
      <data key="d0">DATA, METRIC</data>
      <data key="d1">Validation data is used to evaluate the performance of the generated agents in the Meta Agent Search algorithm. Metrics such as success rate or F1 score are calculated to assess performance.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="BOOTSTRAP CONFIDENCE INTERVAL">
      <data key="d0">METRIC, STATISTIC</data>
      <data key="d1">The Bootstrap Confidence Interval is a statistical method employed to report the test accuracy and confidence in the performance results of Meta Agent Search. It serves as a statistical measure to evaluate the performance of the generated agents within the Meta Agent Search algorithm. Additionally, the Bootstrap Confidence Interval is utilized to report the median accuracy and variability of agent performance in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="EXPERIMENT">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The entity "EXPERIMENT" refers to the systematic procedures conducted to evaluate the performance of the Meta Agent Search algorithm. These experiments are designed to assess the algorithm's effectiveness across a range of benchmarks and tasks, including the Abstraction and Reasoning Corpus (ARC), reading comprehension, and mathematical tasks.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="DYNAMIC MEMORY">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">Dynamic memory is a feature introduced in Meta Agent Search to allow for more refinements during the programming of new agents. This enhancement facilitates the Meta Agent Search process by enabling more detailed and precise adjustments, thereby improving the overall efficiency and effectiveness of agent development.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="ENSEMBLING">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Ensembling is a strategy used in Meta Agent Search to combine multiple answers generated by the Chain-of-Thought strategy to produce the best answer.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="CRITIC">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">CRITIC is an entity in the Meta Agent Search algorithm used to provide feedback and enhance the refinement of generated agents. Multiple critics can be employed to achieve better results. In methods like Self-Refine, the critic plays a crucial role by reviewing and criticizing answers to ensure their correctness. This role is assigned to specific modules within the algorithm, emphasizing the importance of accurate and constructive feedback in the overall process.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,4b43decac6833d1515992f8869ecada7,97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="EFFICIENCY EXPERT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">EFFICIENCY EXPERT

An efficiency expert is a type of critic in the Meta Agent Search algorithm that focuses on improving the efficiency of the generated agents. This expert provides feedback on the efficiency of answers in the Meta Agent Search process, ensuring that the agents operate optimally and deliver high-quality results. By analyzing the performance and resource utilization of the agents, the efficiency expert plays a crucial role in refining and enhancing the overall effectiveness of the Meta Agent Search algorithm.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="READABILITY EXPERT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">A readability expert is a type of critic in the Meta Agent Search algorithm that focuses on improving the readability of the generated agents. This expert provides feedback on the readability of answers in the Meta Agent Search process, ensuring that the output is clear and easily understandable.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="SIMPLICITY">
      <data key="d0">ATTRIBUTE, QUALITY</data>
      <data key="d1">Simplicity is a specific trait evaluated by experts in the feedback mechanism of ADAS, focusing on how straightforward and uncomplicated a task or solution is. Additionally, simplicity is an attribute or quality that the Meta Agent Search algorithm aims to achieve in the generated agents, often evaluated by critics like the readability expert. This dual focus on simplicity underscores its importance in both the practical application of ADAS and the theoretical development of algorithmic agents, ensuring that solutions are not only effective but also easily understandable and implementable.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ARC CHALLENGE">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">The ARC Challenge, also known as the Abstraction and Reasoning Corpus (ARC) challenge, is a benchmark designed to evaluate the general intelligence of AI systems. It focuses on assessing the performance of agentic systems in reasoning, problem-solving, and in-context learning, particularly relevant to the ADAS research area. The challenge involves tasks where participants must learn transformation rules from input-output grid examples and use these rules to predict the output grid for a test example. This process aims to demonstrate the proficiency of AI systems in efficiently acquiring new skills and applying them to novel situations.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7,7c08d98f503d722d7de13be55375c8cb,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Self-Consistency with Chain-of-Thought (COT-SC) is a method that ensembles multiple parallel answers from Chain-of-Thought (COT) to produce a more accurate answer. Additionally, COT-SC serves as a state-of-the-art hand-designed agent baseline used for experiments on the AI2 Reasoning Challenge (ARC).</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="LLM-DEBATE">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">LLM-Debate is a method that enables different language models to debate with each other, leveraging diverse perspectives to find better answers. Each debate module within LLM-Debate is assigned a unique role, such as Physics Expert or Chemistry Expert, and the debate lasts for two rounds. This state-of-the-art, hand-designed agent baseline was developed by Du et al. (2023) and is used for experiments on ARC.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="ENSEMBLE">
      <data key="d0">PROCESS, MECHANISM</data>
      <data key="d1">Ensemble in Meta Agent Search refers to the process of combining multiple answers to produce a final, more accurate answer.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="TRANSFORMATION RULE">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">The "TRANSFORMATION RULE" in the ARC (Abstraction and Reasoning Corpus) challenge is a rule learned from example input-output grids to predict the output grid for a test example. This transformation rule is crucial for the AI system as it learns from these examples to transform input grid patterns into corresponding output grid patterns. The primary objective of the transformation rule is to enable the AI to generalize from given examples and accurately apply the learned transformations to new, unseen test cases within the ARC challenge.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="GREENBLATT, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Greenblatt is a researcher who followed common practice in requiring the agent to write code for the transformation rule instead of answering directly in the ARC challenge.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="LEHMAN &amp; STANLEY, 2011">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lehman &amp; Stanley are researchers who have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="WANG ET AL., 2019, 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are researchers who have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="MULTIPLE CRITICS">
      <data key="d0">ROLE, FUNCTION</data>
      <data key="d1">Multiple critics are introduced for enhanced refinement in the Meta Agent Search process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="META-AGENT">
      <data key="d0">ROLE, FUNCTION</data>
      <data key="d1">The meta-agent in Meta Agent Search is responsible for discovering high-performance agents based on an archive of previous discoveries.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="HUMAN-LIKE CRITIC">
      <data key="d0">ROLE, FUNCTION</data>
      <data key="d1">A human-like critic provides feedback in the Meta Agent Search process to simulate human evaluation.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="SIMPLICITY EXPERT">
      <data key="d0">ROLE, FUNCTION</data>
      <data key="d1">A simplicity expert provides feedback on the simplicity of answers in the Meta Agent Search process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="FEEDBACK EFFICIENCY">
      <data key="d0">PROCESS, MECHANISM</data>
      <data key="d1">Feedback efficiency refers to the effectiveness of feedback in refining answers in the Meta Agent Search process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="REFINEMENT">
      <data key="d0">PROCESS, MECHANISM</data>
      <data key="d1">Refinement in Meta Agent Search involves improving answers through iterative feedback and evaluation.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="HELD-OUT TEST SET">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">The held-out test set is used to evaluate the performance of discovered agents in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="PUBLIC TRAINING SET (EASY)">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">The Public Training Set (Easy) is a dataset with grid dimensions &#8804;5&#215;5 used for training agents in the ARC challenge.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="VALIDATION SET">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">The VALIDATION SET is a subset of data used to validate the performance of agents and models. It plays a crucial role in assessing the performance of agents during the Meta Agent Search process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="TEST SET">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">The TEST SET is a subset of data utilized to assess the performance of agents and models. It plays a crucial role in evaluating the final performance of agents identified through Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="STOCHASTIC SAMPLING">
      <data key="d0">PROCESS, MECHANISM</data>
      <data key="d1">Stochastic sampling is used to reduce variance in the evaluation of agents in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="TOOL FUNCTIONS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Tool functions are provided in the framework to evaluate the generated transformation code in the ARC challenge.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="ARC QUESTIONS">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">ARC questions involve tasks such as learning transformation rules of grid patterns and predicting output grid patterns given test input grid patterns.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="APPENDIX C">
      <data key="d0">DOCUMENT, SECTION</data>
      <data key="d1">Appendix C contains detailed implementation of the best-discovered agent and more algorithmic details and examples of ARC questions.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="APPENDIX E">
      <data key="d0">DOCUMENT, SECTION</data>
      <data key="d1">Appendix E contains more details about the baselines used in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="STEPPING STONES">
      <data key="d0">CONCEPT, COMPONENT</data>
      <data key="d1">Stepping stones refer to intermediate innovations or ideas that contribute to the final sophisticated feedback mechanism in ADAS, including diverse feedback, efficiency and simplicity evaluation, and human-like feedback simulation.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MEYERSON ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Meyerson et al. are researchers who contributed to the concept of combining different stepping stones, resembling crossover in evolution via LLMs.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MMLU">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MMLU (Massive Multitask Language Understanding) is a benchmark designed to evaluate the performance of AI models, particularly their multi-task problem-solving capabilities. Developed by Hendrycks et al. in 2021, MMLU assesses a model&#8217;s ability to answer questions across a wide range of subjects and difficulty levels, including various levels of mathematics such as abstract algebra, college mathematics, and high-school mathematics. The benchmark comprises 57 academic subjects with approximately 16,000 multiple-choice questions. Notably, Orca-3 demonstrated a significant improvement on MMLU, scoring 69.95, which is a 19% enhancement over Orca-2.5 and also a 19% improvement compared to Mistral-Instruct-7B. MMLU is also one of the datasets included in the MIRAGE benchmark, further underscoring its importance in evaluating model performance.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="GPQA">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">GPQA (Graduate-Level Google-Proof Q&amp;A Benchmark) is a challenging benchmark used to evaluate models and agents in the Science domain, specifically in biology, physics, and chemistry. Published in 2023 by Rein et al., GPQA consists of 448 high-quality and extremely difficult multiple-choice questions created by domain experts. It includes both validation and test sets to assess the capability of solving hard, graduate-level questions. Notably, the benchmark has been used to evaluate models such as Orca-3, which scored 28.12, reflecting a 4% decrease compared to Orca-2.5. Additionally, GPQA is associated with the Reading Comprehension domain, where the Multi-Step Peer Review Agent was discovered by Meta Agent Search.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,3d1f6634f93f8a4c296dc8df7e59859e,84317ae35cc75d612287186d93461447,86f77e15d41cbd0cb33f635ccb2cb66b,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="STEP-BACK ABSTRACTION">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Step-back Abstraction, developed by Zheng et al. (2023), is a state-of-the-art, hand-designed agent that excels in planning and reasoning across various domains. This manually designed agent is particularly effective in tasks such as math, reading comprehension, multi-tasking, and science, where it has demonstrated specific accuracy and F1 scores. The method is implemented for experiments in Reasoning and Problem-Solving domains, emphasizing the importance of considering underlying principles to enhance task-solving capabilities.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ROLE ASSIGNMENT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Role Assignment, as described by Xu et al. (2023), is a state-of-the-art, manually designed agent used for planning and reasoning across various domains, including math, reading comprehension, multi-tasking, and science. This agent assigns different roles to foundation models (FMs) to obtain better answers, leveraging a predefined set of roles to enhance its performance. It has been implemented for experiments on Reasoning and Problem-Solving domains, where it uses an FM query to select an appropriate role and then acts within that role to answer questions. Specific accuracy and F1 scores have been reported for its performance, highlighting its effectiveness as a baseline in these experimental settings.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="HENDRYCKS ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hendrycks et al. are the authors of the MMLU benchmark, published in 2021.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="REIN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rein et al., 2023, are the authors associated with significant contributions in the field of Reading Comprehension. In 2023, they published work on the discovery of the Multi-Step Peer Review Agent, a notable advancement in this domain. Additionally, they introduced the GPQA benchmark, further solidifying their impact on the field within the same year.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ZHENG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"Zheng et al., 2023" are the authors of research on the Step-back Abstraction algorithm, also referred to as the Step-back Abstraction method, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="XU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu et al., 2023, are the authors of research on the Role Assignment algorithm, also referred to as the Role Assignment method. Their work, published in 2023, delves into the intricacies of role assignment within algorithmic communities, providing a comprehensive analysis and innovative solutions in this domain.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="HUMAN-LIKE FEEDBACK">
      <data key="d0">FEEDBACK, MECHANISM</data>
      <data key="d1">Human-like feedback is a type of feedback simulated in the ADAS mechanism to resemble feedback given by humans.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ACCURACY">
      <data key="d0">METRIC, MEASUREMENT</data>
      <data key="d1">ACCURACY is a multifaceted concept with applications and implications in various domains. It serves as a metric used to evaluate the performance of agents, representing the proportion of correct predictions out of total predictions. This metric is crucial for assessing the effectiveness of models and algorithms in making accurate predictions. However, accuracy also highlights a limitation concerning the potential inaccuracies in synthetic data, which may not perfectly replicate the complexity and nuances of real-world data. This dual role underscores the importance of accuracy in both evaluating performance and recognizing the inherent challenges in data representation.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="EXPERIMENT SETTINGS">
      <data key="d0">CONFIGURATION, SETUP</data>
      <data key="d1">Experiment settings refer to the specific configurations and conditions under which Meta Agent Search and its baselines are tested, detailed in Appendix D and E.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="APPENDIX D">
      <data key="d0">DOCUMENT, SECTION</data>
      <data key="d1">Appendix D contains more details about the datasets and experiment settings used in Meta Agent Search.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="FOUNDATIONAL MODELS (FMS)">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Foundational Models (FMs) are advanced models used to solve questions in various domains. Their effectiveness can be limited by the knowledge they possess, which impacts the performance of agentic systems like Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="CLAUDE-HAIKU">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Claude-Haiku is a foundational model developed by Anthropic, used to evaluate the performance of agents discovered by Meta Agent Search on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="CLAUDE-SONNET">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Claude-Sonnet is a foundational model developed by Anthropic, noted for its high performance in evaluating agents discovered by Meta Agent Search on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (WEI ET AL., 2022)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Chain-of-Thought is a manually designed agent developed by Wei et al. in 2022, used for reasoning tasks and evaluated on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="COT-SC (WANG ET AL., 2023B)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">COT-SC is a manually designed agent developed by Wang et al. in 2023, used for reasoning tasks and evaluated on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="LLM DEBATE (DU ET AL., 2023)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">LLM Debate is a manually designed agent developed by Du et al. in 2023, used for reasoning tasks and evaluated on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="SELF-REFINE (MADAAN ET AL., 2024)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Self-Refine is a manually designed agent developed by Madaan et al. in 2024, used for reasoning tasks and evaluated on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="QUALITY-DIVERSITY (LU ET AL., 2024C)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Quality-Diversity is a manually designed agent developed by Lu et al. in 2024, used for reasoning tasks and evaluated on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="STRUCTURED FEEDBACK AND ENSEMBLE AGENT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Structured Feedback and Ensemble Agent is a top-performing agent discovered by Meta Agent Search, evaluated on the ARC benchmark and transferred to other foundational models.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="HIERARCHICAL COMMITTEE REINFORCEMENT AGENT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Hierarchical Committee Reinforcement Agent is a top-performing agent discovered by Meta Agent Search, evaluated on the ARC benchmark and transferred to other foundational models.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="DYNAMIC MEMORY AND REFINEMENT AGENT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Dynamic Memory and Refinement Agent is a top-performing agent discovered by Meta Agent Search, evaluated on the ARC benchmark and transferred to other foundational models.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="GSM8K (COBBE ET AL., 2021)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">GSM8K is a math benchmark developed by Cobbe et al. in 2021, used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="GSM-HARD (GAO ET AL., 2023)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">GSM-Hard is a math benchmark developed by Gao et al. in 2023, used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="SVAMP (PATEL ET AL., 2021)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">SVAMP is a math benchmark developed by Patel et al. in 2021, used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ASDIV (MIAO ET AL., 2020)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">ASDiv is a math benchmark developed by Miao et al. in 2020, used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="MULTI-TASK">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Multi-task is a domain where the performance of agents is evaluated, specifically in non-mathematical contexts. In this domain, Meta Agent Search has been shown to outperform baseline methods, although the performance gap is smaller compared to other domains.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="HALLUCINATIONS">
      <data key="d0">ERROR, ISSUE</data>
      <data key="d1">Hallucinations are errors that occur in foundational models, particularly in domains like Reading Comprehension and Math, which can be mitigated through well-designed agentic systems.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="CALCULATION MISTAKES">
      <data key="d0">ERROR, ISSUE</data>
      <data key="d1">Calculation mistakes are errors that occur in foundational models, particularly in domains like Reading Comprehension and Math, which can be mitigated through well-designed agentic systems.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="OPENAI, 2022">
      <data key="d0">AUTHOR, ORGANIZATION</data>
      <data key="d1">OpenAI, in 2022, is the organization that developed GPT-3.5, a foundational model used to evaluate the performance of agents discovered by Meta Agent Search. Additionally, OpenAI is mentioned in the context of using GPT-3.5-turbo-0125 to evaluate discovered agents and baselines. This highlights OpenAI's significant role in advancing AI technology and its applications in agent performance evaluation.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ANTHROPIC, 2024A">
      <data key="d0">AUTHOR, ORGANIZATION</data>
      <data key="d1">Anthropic is the organization that developed Claude-Haiku, a foundational model used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ANTHROPIC, 2024B">
      <data key="d0">AUTHOR, ORGANIZATION</data>
      <data key="d1">Anthropic is the organization that developed Claude-Sonnet, a foundational model used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="PATEL ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"PATEL ET AL., 2021" refers to the authors of the SVAMP benchmark and dataset, both published in 2021.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="MIAO ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Miao et al., 2020, are the authors of the ASDiv benchmark and dataset, both published in 2020.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="SVAMP">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">SVAMP is a dataset used for evaluating the performance of algorithms in various domains, particularly in math.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="ASDIV">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">ASDiv is a dataset used for evaluating the performance of algorithms in various domains, particularly in math.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Dynamic Role-Playing Architecture is a top agent discovered by Meta Agent Search, initially recognized for its exceptional performance in the math domain. It has been effectively transferred to non-math domains, where it continues to demonstrate specific accuracy and F1 scores. This architecture is utilized for planning and reasoning across various domains, showcasing its versatility and robust capabilities.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">The Structured Multimodal Feedback Loop is a top agent discovered by Meta Agent Search, initially excelling in the math domain. It has been effectively transferred to non-math domains, where specific accuracy and F1 scores have been reported. This agent is utilized for planning and reasoning across various math domains, showcasing its versatility and robust performance in diverse applications.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">The Interactive Multimodal Feedback Loop is a top agent discovered by Meta Agent Search, primarily utilized in the math domain. It has been effectively transferred to non-math domains, with specific accuracy and F1 scores reported. This agent is instrumental in planning and reasoning across various math domains, showcasing its versatility and robust performance in diverse applications.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="CHEN ET AL., 2023A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen et al. are the authors who contributed to the development of prompting techniques, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="SCHULHOFF ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Schulhoff et al. are the authors who contributed to the development of prompting techniques, published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Chain-of-thought-based planning and reasoning methods are important building blocks for agentic systems, used for planning and reasoning.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="EMBODIED AGENTS">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">Embodied agents are agents that interact with the physical world, often requiring the development of new skills.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="VEMPRALA ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vemprala et al. are the authors who contributed to the development of new skills for embodied agents, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="NAKANO ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nakano et al. are the authors who contributed to the development of tool use techniques, published in 2021.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="FM MODULES">
      <data key="d0">COMPONENT, SYSTEM</data>
      <data key="d1">FM modules are components in agentic systems assigned with different roles to enable collaboration among agents.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="HONG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hong et al., 2023, are researchers known for their work published in 2023, which focuses on incorporating organizational structures of human companies into agents. They have contributed to the development of techniques for assigning FM modules in agentic systems, enhancing the integration of human organizational principles within agent-based models.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="QIAN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qian et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="QIAN ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qian et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="SELF-INSTRUCTION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Self-instruction is an important building block for agentic systems, enabling agents to instruct themselves for the next action.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="RICHARDS, 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Richards is the author who contributed to the development of self-instruction techniques, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="MAML">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">MAML stands for Model-Agnostic Meta-Learning, an algorithm that allows "learning to learn" for better sample efficiency, generalizability, and continuous learning of multiple tasks.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="META-RL">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Meta-RL stands for Meta-Reinforcement Learning, an algorithm that allows "learning to learn" for better sample efficiency, generalizability, and continuous learning of multiple tasks.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="POET">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">POET stands for Paired Open-Ended Trailblazer, an algorithm that aims to generate learning environments in an open-ended manner.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="EOH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">EoH is an algorithm where Foundation Models write code to discover better optimization algorithms.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DISCOPOP">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">DiscoPOP is an algorithm where Foundation Models program the loss function for preference learning in FM alignment training.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="EUREKA">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">"EUREKA" is an algorithm developed by Ma et al. in 2023, designed to enable Foundation Models (FMs) to write reward functions for reinforcement learning in robotics. This innovative approach is detailed in a research paper titled "Eureka: Human-level reward design via coding large language models," which was published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="LANGUAGE-TO-REWARD">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Language-to-Reward is an algorithm developed by Yu et al. in 2023 that enables Foundation Models (FMs) to write reward functions for reinforcement learning in robotics. This innovative approach leverages the capabilities of FMs to streamline the creation of reward functions, which are crucial for guiding the learning process in robotic systems. By automating this aspect, Language-to-Reward significantly enhances the efficiency and effectiveness of reinforcement learning applications in the field of robotics.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="MANUALLY DESIGNED AGENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="HU ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"Hu et al., 2021" refers to the authors of significant research published in 2021. Their work is notable for its contributions to multi-objective optimization in agentic systems and Neural Architecture Search.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="LU ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu et al. are the authors of research on Neural Architecture Search, published in 2019.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="FINN ET AL., 2017">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Finn et al. are the authors of research on MAML, published in 2017.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DUAN ET AL., 2017">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Duan et al. are the authors of research on Meta-RL, published in 2017.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="NORMAN &amp; CLUNE, 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Norman and Clune are the authors of research on Meta-RL, published in 2023.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="WANG ET AL., 2016">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are the authors of research on Meta-RL, published in 2016.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="ZINTGRAF ET AL., 2021A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zintgraf et al. are the authors of research on Meta-RL, published in 2021.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="ZINTGRAF ET AL., 2021B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zintgraf et al. are the authors of research on Meta-RL, published in 2021.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DHARNA ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dharna et al. are the authors of research on POET, published in 2020.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="WANG ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are the authors of research on POET, published in 2019.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="WANG ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are the authors of research on POET, published in 2020.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="RAFALIOV ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rafailov et al. are the authors of research on FM alignment training, published in 2024.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="MA ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"Ma et al., 2023" refers to the authors of research on the Eureka algorithm, which was published in 2023.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="YU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">"Yu et al., 2023" are the authors of research on the language-to-reward algorithm, published in 2023.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FM ALIGNMENT TRAINING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="LOSS FUNCTION">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">A loss function is programmed for preference learning in FM alignment training, as mentioned in the work by Rafailov et al., 2024.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="OPRO">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">OPRO is an algorithm developed by Yang et al., 2024, that adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="SELF-DISCOVER">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Self-Discover is an algorithm developed by Zhou et al., 2024a, that adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="EVOAGENT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">EvoAgent is an algorithm developed by Yuan et al., 2024, that optimizes role definition in the prompt, assigning personas or roles to agents to improve performance.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENTVERSE">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">AGENTVERSE is an algorithm developed by Chen et al., 2023b, that optimizes role definition in the prompt by assigning personas or roles to agents to improve performance. This innovative approach was detailed in a research paper titled "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors," which was presented at The Twelfth International Conference on Learning Representations in 2023. The algorithm focuses on enhancing multi-agent collaboration and investigating emergent behaviors within these systems.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DYLAN">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">DyLAN is an algorithm developed by Liu et al., 2023, that uses FMs to score the response quality of nodes in a fully connected feed-forward network and prunes the connections accordingly.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DSPY">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">DSPy is an algorithm developed by Khattab et al., 2024, that generates a set of possible nodes and optimizes across the Cartesian product of these nodes while optimizing the few-shot examples for nodes.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="GPT-SWARM">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">GPT-Swarm is an algorithm developed by Zhuge et al., 2024, that represents an agentic system in a graph with a predefined set of nodes and uses a Reinforcement Learning algorithm to optimize the connections between nodes while optimizing the prompt for each node.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENTOPTIMIZER">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">AgentOptimizer is an algorithm developed by Zhang et al., 2024b, that learns the tools used in agents.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENT SYMBOLIC LEARNING">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Agent Symbolic Learning is an algorithm developed by Zhou et al., 2024b, that learns prompts, tools, and control flow together, but manually designs the search space for each component separately.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGI">
      <data key="d0">CONCEPT, RESEARCH AREA</data>
      <data key="d1">Artificial General Intelligence (AGI) is a concept in AI research that involves creating AI systems with general cognitive abilities, potentially accelerated by ADAS.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="SAFETY CONSIDERATIONS">
      <data key="d0">CONCEPT, GUIDELINE</data>
      <data key="d1">Safety considerations involve being aware of the potential risks when executing untrusted model-generated code, with recommendations for using sandbox environments to mitigate these risks.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">CONCEPT, GUIDELINE</data>
    </node>
    <node id="SANDBOX ENVIRONMENTS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Sandbox environments are controlled settings used to safely run untrusted model-generated code to prevent destructive actions.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="RAFALOV ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rafailov et al. are the authors of a work in 2024 that involves programming the loss function for preference learning in FM alignment training.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZHOU ET AL., 2024A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhou et al. are the authors of the Self-Discover algorithm, published in 2024a.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YUAN ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuan et al. are the authors of the EvoAgent algorithm, published in 2024.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KHATTAB ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khattab et al. are the authors of the DSPy algorithm, published in 2024.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZHANG ET AL., 2024B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang et al. are the authors of the AgentOptimizer algorithm, published in 2024b.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZHOU ET AL., 2024B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">ZHOU ET AL., 2024B

Zhou et al. are authors referenced in the text, known for their significant contributions in 2024, particularly in the realm of intelligent evaluation functions within Advanced Driver Assistance Systems (ADAS). They are also recognized for their development of the Agent Symbolic Learning algorithm, which was published in 2024b. Their work has been influential in advancing the understanding and implementation of intelligent systems in automotive technology.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ROKON ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rokon et al. are the authors of a work published in 2020 that discusses safety considerations for executing model-generated code.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YEE ET AL., 2010">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yee et al. are the authors of a work published in 2010 that discusses safety considerations for executing model-generated code.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BENGIO ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bengio et al. are the authors of a work published in 2024 that discusses the ethical considerations of advancing AI capabilities.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BOSTROM, 2002">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bostrom is the author of a work published in 2002 that discusses the ethical considerations of advancing AI capabilities.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ECOFFET ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ecoffet et al. are authors referenced in the text, known for their work published in 2020 related to AI and agentic systems. Their 2020 publication discusses the ethical considerations of advancing AI capabilities, highlighting the importance of addressing ethical issues as AI technology continues to evolve.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YUDKOWSKY ET AL., 2008">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yudkowsky et al., 2008, are authors referenced in the text, known for their work published in 2008 related to AI and its implications. Their publication discusses the ethical considerations of advancing AI capabilities, highlighting the importance of understanding and addressing the potential impacts of AI development on society.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="PREFERENCE LEARNING">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Preference learning is a method used in FM alignment training to optimize the performance of models based on user preferences.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ROBOTICS LEARNING ENVIRONMENTS">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Robotics learning environments are simulated or real-world settings where robots can learn and practice tasks, often created using FMs and programming in code.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="PROMPT ENGINEERING">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Prompt engineering is the process of designing and optimizing prompts to improve the performance and reasoning capabilities of agents.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ROLE DEFINITION">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Role definition involves assigning specific personas or roles to agents within prompts to enhance their performance and reasoning capabilities.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="CONTROL FLOW">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Control flow refers to the optimization of the sequence and connections between nodes or components in agentic systems, often represented as networks or graphs.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DESIGN PATTERNS">
      <data key="d0">CONCEPT, COMPONENT</data>
      <data key="d1">Design patterns are recurring solutions or structures that can be used to solve common problems in agentic systems, emerging from basic agent designs.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="API ACCESS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">API ACCESS allows users to interact with and utilize the functionalities of powerful foundational models (FMs) through application programming interfaces. This capability is essential for programming and optimizing agentic systems, enabling users to leverage the advanced features and capabilities of these models effectively.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ARTIFICIAL GENERAL INTELLIGENCE (AGI)">
      <data key="d0">CONCEPT, RESEARCH AREA</data>
      <data key="d1">Artificial General Intelligence (AGI) is a concept in AI research that involves creating AI systems with general cognitive abilities, potentially accelerated by ADAS.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="BOSTROM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bostrom is an author referenced in the text, known for contributions to discussions on AI and its implications.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CLUNE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Clune is an author referenced in the text, known for contributions to AI research, particularly in the context of AI-generating algorithms and open-ended algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="GPUS">
      <data key="d0">HARDWARE, TECHNOLOGY</data>
      <data key="d1">GPUs (Graphics Processing Units) are hardware components often used for processing complex computations, particularly in AI and machine learning tasks.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="SAFE-ADAS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Safe-ADAS refers to algorithms designed to conduct ADAS safely, ensuring that no harmful code is run and that only honest, helpful, and harmless agents are created.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CONSTITUTIONAL AI">
      <data key="d0">CONCEPT, METHODOLOGY</data>
      <data key="d1">Constitutional AI is a concept that involves designing AI systems to adhere to ethical guidelines and principles, ensuring they are helpful, harmless, and honest.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="HIGHER-ORDER ADAS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Higher-order ADAS refers to the concept of improving the meta agent used in ADAS through self-referential meta-learning, allowing for the learning of the meta agent and even the meta-meta agent.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="MULTI-OBJECTIVE ADAS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Multi-objective ADAS refers to the integration of multiple objectives, such as cost, latency, and robustness, in the optimization process of ADAS algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="NOVELTY SEARCH ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Novelty search algorithms are a type of search algorithm focused on exploring interesting new designs, potentially incorporating ideas from Quality-Diversity, AI-generating, and Open-ended Algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="AI-GENERATING ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">AI-generating algorithms are methods focused on creating new AI systems, often through open-ended and exploratory approaches.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="OPEN-ENDED ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Open-ended algorithms are methods that continuously explore and generate new solutions without a predefined endpoint, often used in AI research.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="EVALUATION FUNCTIONS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Evaluation functions are methods used to assess the performance of discovered agents, potentially incorporating detailed running logs and subjective answer evaluations.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="SINGLE-STEP QA TASKS">
      <data key="d0">TASK, DOMAIN</data>
      <data key="d1">Single-step QA tasks are a type of task used to evaluate Meta Agent Search, involving simple question-answering interactions.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">TASK, DOMAIN</data>
    </node>
    <node id="MULTI-STEP INTERACTION">
      <data key="d0">TASK, DOMAIN</data>
      <data key="d1">Multi-step interaction refers to more complex tasks involving multiple steps and interactions with complex environments, proposed as a future direction for Meta Agent Search.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">TASK, DOMAIN</data>
    </node>
    <node id="HUMAN ORGANIZATIONS">
      <data key="d0">CONCEPT, ENTITY</data>
      <data key="d1">Human organizations refer to the structured groups and societies formed by humans, which are closely connected to agentic systems in terms of complexity and operation.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">CONCEPT, ENTITY</data>
    </node>
    <node id="CALDWELL, 2011">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Caldwell is an author referenced in the text, known for contributions to discussions on AI and its implications, published in 2011.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="META, 2024">
      <data key="d0">ORGANIZATION, RESEARCHER</data>
      <data key="d1">Meta is an organization referenced in the text, known for contributions to AI research, with work published in 2024.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ORGANIZATION, RESEARCHER</data>
    </node>
    <node id="BAI ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bai et al. are authors referenced in the text, known for their work published in 2022 related to Constitutional AI.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu et al. are authors referenced in the text, known for their work published in 2023 related to higher-order meta-learning in ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LANGCHAINAI, 2022">
      <data key="d0">ORGANIZATION, RESEARCHER</data>
      <data key="d1">LangChainAI is an organization referenced in the text, known for contributions to AI research, with work published in 2022 related to the LangChain framework.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ORGANIZATION, RESEARCHER</data>
    </node>
    <node id="HUANG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Huang et al., 2023, are researchers recognized for their significant contributions to the field of multi-objective optimization in agentic systems. Their work, published in 2023, has demonstrated that observing the emerged architecture of neural networks can yield valuable insights.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="DEB ET AL., 2002">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Deb et al. are authors referenced in the text, known for their work published in 2002 related to multi-objective search algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CULLY &amp; DEMIRIS, 2017">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cully &amp; Demiris are authors referenced in the text, known for their work published in 2017 related to Quality-Diversity in search algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="MOURET &amp; CLUNE, 2015">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mouret &amp; Clune are authors referenced in the text, known for their work published in 2015 related to AI-generating algorithms and open-ended algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="STANLEY &amp; LEHMAN, 2015">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Stanley &amp; Lehman are authors referenced in the text, known for their work published in 2015 related to open-ended algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="STANLEY ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Stanley et al. are authors referenced in the text, known for their work published in 2019 related to open-ended algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHIANG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chiang et al. are authors referenced in the text, known for their work published in 2024 related to subjective answer evaluations in ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="COMPLEX DOMAINS">
      <data key="d0">TASK, DOMAIN</data>
      <data key="d1">Complex domains refer to real-world applications involving multi-step interactions with complex environments, proposed as a future direction for Meta Agent Search.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">TASK, DOMAIN</data>
    </node>
    <node id="HUMAN ORGANIZATION AND SOCIETY">
      <data key="d0">CONCEPT, ENTITY</data>
      <data key="d1">Human organization and society refer to the structured groups and societies formed by humans, which are closely connected to agentic systems in terms of complexity and operation.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">CONCEPT, ENTITY</data>
    </node>
    <node id="ORGANIZATIONAL STRUCTURE">
      <data key="d0">CONCEPT, METHODOLOGY</data>
      <data key="d1">Organizational structure refers to the way human companies and organizations are structured, which can be incorporated into agentic systems to improve their design and operation.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">CONCEPT, METHODOLOGY</data>
    </node>
    <node id="BALANCING EXPLORATION AND EXPLOITATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="SUBJECTIVE ANSWER EVALUATIONS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="AS">
      <data key="d0">CONCEPT, SYSTEM</data>
      <data key="d1">AS refers to an agentic system that operates primarily over natural language, shedding light on the origins of complexity emerging from human organization and society.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="HUMAN ORGANIZATION">
      <data key="d0">CONCEPT, ENTITY</data>
      <data key="d1">Human organization refers to the structured arrangement of individuals and groups in society, which agentic systems aim to simulate and understand.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="AGENTIC SYSTEM">
      <data key="d0">SYSTEM, TECHNOLOGY</data>
      <data key="d1">An agentic system is a machine learning system that operates over natural language and is used to simulate human organizations and societies.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="PARK ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Park et al. are researchers who have simulated a human town with agents in their work published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CANADA CIFAR AI CHAIRS PROGRAM">
      <data key="d0">PROGRAM, FUNDING</data>
      <data key="d1">The Canada CIFAR AI Chairs program is a funding program that supported the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PROGRAM, FUNDING</data>
    </node>
    <node id="SCHMIDT FUTURES">
      <data key="d0">ORGANIZATION, FUNDING</data>
      <data key="d1">Schmidt Futures is an organization that provided grants to support the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">ORGANIZATION, FUNDING</data>
    </node>
    <node id="OPEN PHILANTHROPY">
      <data key="d0">ORGANIZATION, FUNDING</data>
      <data key="d1">Open Philanthropy is an organization that provided grants to support the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">ORGANIZATION, FUNDING</data>
    </node>
    <node id="NSERC DISCOVERY GRANT">
      <data key="d0">GRANT, FUNDING</data>
      <data key="d1">The NSERC Discovery Grant is a funding source that supported the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">GRANT, FUNDING</data>
    </node>
    <node id="RAFAEL COSMAN">
      <data key="d0">INDIVIDUAL, DONOR</data>
      <data key="d1">Rafael Cosman is an individual who made a generous donation to support the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">INDIVIDUAL, DONOR</data>
    </node>
    <node id="JENNY ZHANG">
      <data key="d0">INDIVIDUAL, RESEARCHER</data>
      <data key="d1">Jenny Zhang is an author who contributed to the paper titled "OMNI: Open-endedness via models of human notions of interestingness," which was presented at The Twelfth International Conference on Learning Representations in 2024. Additionally, she is acknowledged for providing insightful discussions and feedback on the work related to the Automated Design of Agentic Systems.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7de66b94cf868b37b1df51dc545c415f,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">INDIVIDUAL, RESEARCHER</data>
    </node>
    <node id="RACH PRADHAN">
      <data key="d0">INDIVIDUAL, RESEARCHER</data>
      <data key="d1">Rach Pradhan is one of the individuals acknowledged for providing insightful discussions and feedback on the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">INDIVIDUAL, RESEARCHER</data>
    </node>
    <node id="RUIYU GOU">
      <data key="d0">INDIVIDUAL, RESEARCHER</data>
      <data key="d1">Ruiyu Gou is one of the individuals acknowledged for providing insightful discussions and feedback on the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">INDIVIDUAL, RESEARCHER</data>
    </node>
    <node id="NICHOLAS IOANNIDIS">
      <data key="d0">INDIVIDUAL, RESEARCHER</data>
      <data key="d1">Nicholas Ioannidis is one of the individuals acknowledged for providing insightful discussions and feedback on the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">INDIVIDUAL, RESEARCHER</data>
    </node>
    <node id="EUNJEONG HWANG">
      <data key="d0">INDIVIDUAL, RESEARCHER</data>
      <data key="d1">Eunjeong Hwang is one of the individuals acknowledged for providing insightful discussions and feedback on the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">INDIVIDUAL, RESEARCHER</data>
    </node>
    <node id="YUNTAO BAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuntao Bai is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SAURAV KADAVATH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saurav Kadavath is a notable author in the field of artificial intelligence and mathematical problem solving. He co-authored a significant paper on Constitutional AI, which was published in 2022. Additionally, he contributed to the research on measuring mathematical problem solving with the math dataset, with a paper published in 2021. His work spans critical areas of AI, demonstrating his expertise and influence in advancing both theoretical and practical aspects of the field.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SANDIPAN KUNDU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sandipan Kundu is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="AMANDA ASKELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amanda Askell is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="JACKSON KERNION">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jackson Kernion is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ANDY JONES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andy Jones is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ANNA CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anna Chen is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ANNA GOLDIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anna Goldie is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="AZALIA MIRHOSEINI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Azalia Mirhoseini is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CAMERON MCKINNON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cameron McKinnon is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="GEOFFREY HINTON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Geoffrey Hinton is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ANDREW YAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew Yao is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="DAWN SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dawn Song is a prolific author in the field of artificial intelligence and machine learning. She has contributed to several significant papers, including one on managing extreme AI risks published in 2024, another on the false promise of imitating proprietary large language models (LLMs) published in 2023, and a paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TREVOR DARRELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trevor Darrell is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YUVAL NOAH HARARI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuval Noah Harari is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YA-QIN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ya-Qin Zhang is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LAN XUE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lan Xue is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHAI SHALEV-SHWARTZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shai Shalev-Shwartz is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="N BOSTROM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">N Bostrom is the author of the paper on existential risks, published in 2002.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ROBERT S BOYER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Robert S Boyer is one of the authors of the mechanical proof of the Turing completeness of pure LISP, published in 1983.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="J STROTHER MOORE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">J Strother Moore is one of the authors of the mechanical proof of the Turing completeness of pure LISP, published in 1983.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TRACEY CALDWELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tracey Caldwell is the author of the paper on ethical hackers, published in 2011.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HARRISON CHASE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Harrison Chase is the author of the blog post "What is an agent?" published in June 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BANGHAO CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Banghao Chen is one of the authors of the paper on prompt engineering in large language models, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZHAOFENG ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhaofeng Zhang is one of the authors of the paper on prompt engineering in large language models, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="NICOLAS LANGREN&#201;">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicolas Langren&#233; is one of the authors of the paper on prompt engineering in large language models, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHENGXIN ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shengxin Zhu is one of the authors of the paper on prompt engineering in large language models, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HENRIQUE PONDE DE OLIVEIRA PINTO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Henrique Ponde De Oliveira Pinto is one of the authors of the paper on evaluating large language models trained on code, published in 2021.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HARRI EDWARDS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Harri Edwards is one of the authors of the paper on evaluating large language models trained on code, published in 2021.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YURI BURDA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuri Burda is one of the authors of the paper on evaluating large language models trained on code, published in 2021.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WEIZE CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weize Chen is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YUSHENG SU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yusheng Su is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="JINGWEI ZUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jingwei Zuo is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHENG YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cheng Yang is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHENFEI YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chenfei Yuan is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHI-MIN CHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chi-Min Chan is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HEYANG YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heyang Yu is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YI-HSIN HUNG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yi-Hsin Hung is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHEN QIAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen Qian is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="NEURAL NETWORKS">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">Neural networks are a type of machine learning model that can learn to perform tasks by considering examples, generally without task-specific programming.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="INSIGHTS">
      <data key="d0">CONCEPT, RESULT</data>
      <data key="d1">INSIGHTS is a component of the "thought" section where the meta agent offers valuable insights on identifying the next interesting agent. These insights are derived from the understanding gained through observing the results of experiments or studies, particularly those involving neural networks or agentic systems. This process helps in comprehending the intricate dynamics and interactions within these systems, thereby guiding the selection of subsequent agents for further exploration.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="SECTION 4.3">
      <data key="d0">DOCUMENT SECTION, REFERENCE</data>
      <data key="d1">Section 4.3 is a part of the paper that discusses the performance of agents with different feedback mechanisms when using GPT-3.5 and other advanced models.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">State-of-the-art hand-designed agents are manually created agents that represent the current best practices in agent design.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="MODELS">
      <data key="d0">CONCEPT, SYSTEM</data>
      <data key="d1">Models refer to machine learning models, including language models like GPT-3.5, that can be used to evaluate the performance of agents.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CHEN, YUSHENG SU, JINGWEI ZUO, CHENG YANG, CHENFEI YUAN, CHI-MIN CHAN, HEYANG YU, YAXI LU, YI-HSIN HUNG, CHEN QIAN, ET AL.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A group of researchers who authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" presented at The Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The Twelfth International Conference on Learning Representations is an academic conference that serves as a platform for presenting cutting-edge research in the field of learning representations. In 2023, the conference featured the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors." The following year, in 2024, it showcased two significant papers: "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" and "OMNI: Open-endedness via models of human notions of interestingness." This event is pivotal for researchers and practitioners interested in the latest advancements and collaborative efforts within the domain of learning representations.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WEI-LIN CHIANG, LIANMIN ZHENG, YING SHENG, ANASTASIOS NIKOLAS ANGELOPOULOS, TIANLE LI, DACHENG LI, HAO ZHANG, BANGHUA ZHU, MICHAEL JORDAN, JOSEPH E. GONZALEZ, AND ION STOICA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A group of researchers who authored the paper "Chatbot arena: An open platform for evaluating llms by human preference" in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHATBOT ARENA">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Chatbot arena: An open platform for evaluating llms by human preference" authored by Wei-Lin Chiang et al. in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="FRAN&#199;OIS CHOLLET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The author of the paper "On the measure of intelligence" published as an arXiv preprint in 2019.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ON THE MEASURE OF INTELLIGENCE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Fran&#231;ois Chollet, published as an arXiv preprint in 2019.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="KARL COBBE, VINEET KOSARAJU, MOHAMMAD BAVARIAN, MARK CHEN, HEEWOO JUN, LUKASZ KAISER, MATTHIAS PLAPPERT, JERRY TWOREK, JACOB HILTON, REIICHIRO NAKANO, ET AL.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A group of researchers who authored the paper "Training verifiers to solve math word problems" published as an arXiv preprint in 2021.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">"Training Verifiers to Solve Math Word Problems" is a research paper authored by Karl Cobbe et al., published as an arXiv preprint in 2021.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ANTOINE CULLY AND YIANNIS DEMIRIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Quality and diversity optimization: A unifying modular framework" published in IEEE Transactions on Evolutionary Computation in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="QUALITY AND DIVERSITY OPTIMIZATION">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Quality and diversity optimization: A unifying modular framework" authored by Antoine Cully and Yiannis Demiris, published in IEEE Transactions on Evolutionary Computation in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="N. DALAL AND B. TRIGGS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Histograms of oriented gradients for human detection" presented at the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="HISTOGRAMS OF ORIENTED GRADIENTS FOR HUMAN DETECTION">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Histograms of oriented gradients for human detection" authored by N. Dalal and B. Triggs, presented at the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="KALYANMOY DEB, AMRIT PRATAP, SAMEER AGARWAL, AND TAMT MEYARIVAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "A fast and elitist multiobjective genetic algorithm: Nsga-ii" published in IEEE Transactions on Evolutionary Computation in 2002.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="NSGA-II">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "A fast and elitist multiobjective genetic algorithm: Nsga-ii" authored by Kalyanmoy Deb et al., published in IEEE Transactions on Evolutionary Computation in 2002.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="AARON DHARNA, JULIAN TOGELIUS, AND LISA B SOROS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Co-generation of game levels and game-playing agents" presented at the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CO-GENERATION OF GAME LEVELS AND GAME-PLAYING AGENTS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Co-generation of game levels and game-playing agents" authored by Aaron Dharna et al., presented at the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YILUN DU, SHUANG LI, ANTONIO TORRALBA, JOSHUA B TENENBAUM, AND IGOR MORDATCH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Improving factuality and reasoning in language models through multiagent debate" published as an arXiv preprint in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="IMPROVING FACTUALITY AND REASONING IN LANGUAGE MODELS THROUGH MULTIAGENT DEBATE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Improving factuality and reasoning in language models through multiagent debate" authored by Yilun Du et al., published as an arXiv preprint in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="DHEERU DUA, YIZHONG WANG, PRADEEP DASIGI, GABRIEL STANOVSKY, SAMEER SINGH, AND MATT GARDNER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" presented at the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YAN DUAN, JOHN SCHULMAN, XI CHEN, PETER L. BARTLETT, ILYA SUTSKEVER, AND PIETER ABBEEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "RL^2: Fast reinforcement learning via slow reinforcement learning" presented at the International Conference on Learning Representations in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="RL^2">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "RL^2: Fast reinforcement learning via slow reinforcement learning" authored by Yan Duan et al., presented at the International Conference on Learning Representations in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ADRIEN ECOFFET, JEFF CLUNE, AND JOEL LEHMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Open questions in creating safe open-ended AI: Tensions between control and creativity" presented at the Conference on Artificial Life in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="OPEN QUESTIONS IN CREATING SAFE OPEN-ENDED AI">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Open questions in creating safe open-ended AI: Tensions between control and creativity" authored by Adrien Ecoffet et al., presented at the Conference on Artificial Life in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="THOMAS ELSKEN, JAN HENDRIK METZEN, AND FRANK HUTTER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Neural architecture search: A survey" published in the Journal of Machine Learning Research in 2019.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="MAXENCE FALDOR, JENNY ZHANG, ANTOINE CULLY, AND JEFF CLUNE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code" published as an arXiv preprint in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHRISANTHA FERNANDO, DYLAN SUNIL BANARSE, HENRYK MICHALEWSKI, SIMON OSINDERO, AND TIM ROCKT&#196;SCHEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Promptbreeder: Self-referential self-improvement via prompt evolution" published in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHELSEA FINN, PIETER ABBEEL, AND SERGEY LEVINE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Model-agnostic meta-learning for fast adaptation of deep networks" presented at the International Conference on Machine Learning in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="MODEL-AGNOSTIC META-LEARNING">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Model-agnostic meta-learning for fast adaptation of deep networks" authored by Chelsea Finn et al., presented at the International Conference on Machine Learning in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="LUYU GAO, AMAN MADAAN, SHUYAN ZHOU, URI ALON, PENGFEI LIU, YIMING YANG, JAMIE CALLAN, AND GRAHAM NEUBIG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Pal: Program-aided language models" presented at the International Conference on Machine Learning in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="PAL">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">"PAL, or Program-aided Language Models, is a method discussed in a research paper titled 'Pal: Program-aided language models' authored by Luyu Gao et al. This paper was presented at the International Conference on Machine Learning in 2023. The study explores the integration of programming techniques with language models to enhance their capabilities and performance."</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="RYAN GREENBLATT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ryan Greenblatt is the author of a technical report titled "Getting 50% SOTA on ARC-AGI with GPT-4," which was published in July 2024. Additionally, he authored an article with the same title, "Getting 50% SOTA on ARC-AGI with GPT-4," published on Redwood Research's Substack in July 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="GETTING 50% SOTA ON ARC-AGI WITH GPT-4">
      <data key="d0">ARTICLE, RESEARCH</data>
      <data key="d1">An article titled "Getting 50% sota on arc-agi with gpt-4" authored by Ryan Greenblatt, published on Redwood Research's Substack in July 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JILL BURSTEIN, CHRISTY DORAN, AND THAMAR SOLORIO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The editors of the proceedings for the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="PROCEEDINGS OF THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">The proceedings edited by Jill Burstein, Christy Doran, and Thamar Solorio, which include the paper "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs."</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">An academic conference where various research papers, including "RL^2: Fast reinforcement learning via slow reinforcement learning," are presented.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CONFERENCE ON ARTIFICIAL LIFE">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">An academic conference where the paper "Open questions in creating safe open-ended AI: Tensions between control and creativity" was presented in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JOURNAL OF MACHINE LEARNING RESEARCH">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">The Journal of Machine Learning Research is a prominent publication in the field of machine learning. It is known for publishing influential papers, including "Neural architecture search: A survey" in 2019 and "Varibad: Variational bayes-adaptive deep RL via meta-learning" in 2021. This journal serves as a critical platform for disseminating cutting-edge research and advancements in machine learning, contributing significantly to the academic and professional community.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A journal where the paper "Quality and diversity optimization: A unifying modular framework" was published in 2017 and "A fast and elitist multiobjective genetic algorithm: Nsga-ii" was published in 2002.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INTERACTIVE DIGITAL ENTERTAINMENT">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">An academic conference where the paper "Co-generation of game levels and game-playing agents" was presented in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="PMLR">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">PMLR (Proceedings of Machine Learning Research) is a publication that features significant contributions in the field of machine learning. Notable papers published in PMLR include "Exploration in approximate hyper-state space for meta reinforcement learning" in 2021, "Model-agnostic meta-learning for fast adaptation of deep networks" in 2017, and "Pal: Program-aided language models" in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="REDWOOD RESEARCH">
      <data key="d0">ORGANIZATION, RESEARCH INSTITUTE</data>
      <data key="d1">The research institute that published the article "Getting 50% sota on arc-agi with gpt-4" on their Substack in July 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SUBSTACK">
      <data key="d0">PLATFORM, WEBSITE</data>
      <data key="d1">The platform where the article "Getting 50% sota on arc-agi with gpt-4" was published by Ryan Greenblatt in July 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="INTERNATIONAL CONFERENCE ON MACHINE LEARNING">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The International Conference on Machine Learning is an esteemed academic event that serves as a platform for presenting cutting-edge research in the field of machine learning. In 2023, the conference featured the presentation of the paper "Program-aided language models." The following year, in 2024, the conference showcased several notable papers, including "Offline training of language model agents with functions as learnable weights" and "GPTSwarm: Language agents as optimizable graphs." This conference continues to be a significant venue for the dissemination and discussion of innovative machine learning research.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ARC-AGI">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">ARC-AGI is a benchmark used to evaluate the performance of algorithms like GPT-4.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DAN HENDRYCKS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dan Hendrycks is a notable author in the field of algorithmic analysis and machine learning. In 2021, he co-authored two significant papers. The first paper, titled "Measuring Mathematical Problem Solving with the Math Dataset," focuses on evaluating mathematical problem-solving capabilities using a specialized dataset. The second paper, "Measuring Massive Multitask Language Understanding," was presented at the International Conference on Learning Representations (ICLR) in 2021, and it addresses the challenges and methodologies for assessing multitask language understanding. Hendrycks' contributions to these works highlight his expertise in developing and analyzing complex algorithms for problem-solving and language understanding.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="COLLIN BURNS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Collin Burns is a notable author who contributed to significant research in the field of algorithmic analysis and machine learning. In 2021, he co-authored a paper on measuring mathematical problem solving with the math dataset. Additionally, he was involved in the authorship of another influential paper titled "Measuring massive multitask language understanding," which was presented at the International Conference on Learning Representations in the same year. His work in these areas highlights his expertise and contributions to advancing the understanding of complex algorithmic and language processing tasks.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="STEVEN BASART">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Steven Basart is one of the authors of two significant papers published in 2021. The first paper, titled "Measuring Mathematical Problem Solving with the Math Dataset," focuses on evaluating mathematical problem-solving capabilities. The second paper, "Measuring Massive Multitask Language Understanding," was presented at the International Conference on Learning Representations and delves into the complexities of multitask language understanding. Both contributions highlight Steven Basart's involvement in advancing research in mathematical problem-solving and language understanding within the field of artificial intelligence.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ANDY ZOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andy Zou is one of the authors of the paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MANTAS MAZEIKA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mantas Mazeika is one of the authors of the paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JACOB STEINHARDT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacob Steinhardt is one of the authors of the paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SIRUI HONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sirui Hong is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="XIAWU ZHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiawu Zheng is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JONATHAN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jonathan Chen is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YUHENG CHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuheng Cheng is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JINLIN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jinlin Wang is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CEYAO ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ceyao Zhang is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZILI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zili Wang is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="STEVEN KA SHING YAU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Steven Ka Shing Yau is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZIJUAN LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zijuan Lin is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LIYANG ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liyang Zhou is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="METAGPT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">MetaGPT is a meta programming framework for multi-agent collaboration discussed in a paper published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="THOUGHT CLONING">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Thought Cloning is a method for learning to think while acting by imitating human thinking, discussed in a paper published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="RAN CHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ran Cheng is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CHENG HE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cheng He is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHICHAO LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhichao Lu is a notable researcher in the field of neural architecture search. He co-authored the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," which was published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019. Additionally, he contributed to the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation," published in Complex &amp; Intelligent Systems in 2021. His work focuses on leveraging multi-objective genetic algorithms to enhance neural architecture search, demonstrating significant advancements in this area of study.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JING WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jing Wang is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MIAO ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Miao Zhang is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="COMPLEX &amp; INTELLIGENT SYSTEMS">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A journal where the paper "Accelerating multi-objective neural architecture search by random-weight evaluation" was published in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SHIHUA HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shihua Huang is one of the authors of the paper titled "Revisiting residual networks for adversarial robustness" presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="KALYANMOY DEB">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kalyanmoy Deb is a notable author in the field of computer science, particularly recognized for his contributions to neural architecture search and adversarial robustness. He co-authored the paper titled "Revisiting residual networks for adversarial robustness," which was presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023. Additionally, he contributed to the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VISHNU NARESH BODDETI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vishnu Naresh Boddeti is one of the authors of the paper titled "Revisiting residual networks for adversarial robustness" presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">An academic conference where the paper "Revisiting residual networks for adversarial robustness" was presented in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FRANK HUTTER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Frank Hutter is one of the authors of the book titled "Automated machine learning: methods, systems, challenges" published by Springer Nature in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LARS KOTTHOFF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lars Kotthoff is one of the authors of the book titled "Automated machine learning: methods, systems, challenges" published by Springer Nature in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JOAQUIN VANSCHOREN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joaquin Vanschoren is one of the authors of the book titled "Automated machine learning: methods, systems, challenges" published by Springer Nature in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUTOMATED MACHINE LEARNING">
      <data key="d0">BOOK, PUBLICATION</data>
      <data key="d1">A book titled "Automated machine learning: methods, systems, challenges" published by Springer Nature in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="OMAR KHATTAB">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Omar Khattab is an author who has made significant contributions to the field of artificial intelligence and machine learning. He co-authored the paper "The shift from models to compound AI systems" and also contributed to the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines," which was presented at The Twelfth International Conference on Learning Representations in 2024. His work focuses on advancing the development and implementation of complex AI systems and optimizing language model pipelines.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ARNAV SINGHVI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arnav Singhvi is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PARIDHI MAHESHWARI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Paridhi Maheshwari is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHIYUAN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhiyuan Zhang is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="KESHAV SANTHANAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Keshav Santhanam is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SAIFUL HAQ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saiful Haq is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ASHUTOSH SHARMA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ashutosh Sharma is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="THOMAS T JOSHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thomas T Joshi is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HANNA MOAZAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hanna Moazam is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HEATHER MILLER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heather Miller is an author who has made significant contributions to the field of artificial intelligence and machine learning. She co-authored the paper "The shift from models to compound AI systems," which explores the transition from traditional models to more complex AI systems. Additionally, Heather Miller is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines," which was presented at The Twelfth International Conference on Learning Representations in 2024. Her work demonstrates a deep understanding of the evolving landscape of AI and the development of advanced computational techniques.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEX KRIZHEVSKY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alex Krizhevsky is one of the authors of the paper titled "Imagenet classification with deep convolutional neural networks" published in Advances in Neural Information Processing Systems in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="GEOFFREY E HINTON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Geoffrey E Hinton is one of the authors of the paper titled "Imagenet classification with deep convolutional neural networks" published in Advances in Neural Information Processing Systems in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="IMAGENET CLASSIFICATION">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Imagenet classification with deep convolutional neural networks is a method discussed in a paper published in Advances in Neural Information Processing Systems in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ABRAHIM LADHA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Abrahim Ladha is the author of the lecture titled "Lecture 11: Turing-completeness" for the CS 4510 Automata and Complexity course at Georgia Tech, scribed by Rishabh Singhal in February 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="TURING-COMPLETENESS">
      <data key="d0">CONCEPT, THEORY</data>
      <data key="d1">Turing-completeness is a concept discussed in a lecture titled "Lecture 11: Turing-completeness" for the CS 4510 Automata and Complexity course at Georgia Tech in February 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LANGCHAINAI">
      <data key="d0">ORGANIZATION, COMPANY</data>
      <data key="d1">LangChainAI is the organization behind Langchain, a tool for building context-aware reasoning applications, available on GitHub since 2022.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JOEL LEHMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joel Lehman is an accomplished author and researcher with significant contributions to the field of artificial intelligence and machine learning. He has co-authored several influential papers, including "Poet: open-ended coevolution of environments and their optimized solutions," "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions," and "OMNI: Open-endedness via models of human notions of interestingness," which was presented at The Twelfth International Conference on Learning Representations in 2024. Additionally, he contributed to the paper "Designing neural networks through neuroevolution," published in Nature Machine Intelligence in 2019, and "Abandoning objectives: Evolution through the search for novelty alone," published in Evolutionary Computation in 2011. Joel Lehman is also one of the authors of the book "Why greatness cannot be planned: The myth of the objective," published by Springer in 2015. His recent work includes the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="KENNETH O STANLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kenneth O. Stanley is a prominent figure in the field of neuroevolution and evolutionary computation. He co-authored the influential paper "Designing neural networks through neuroevolution," which was published in Nature Machine Intelligence in 2019. Additionally, he contributed to the paper "Abandoning objectives: Evolution through the search for novelty alone," published in Evolutionary Computation in 2011. Stanley is also one of the authors of the book "Why Greatness Cannot Be Planned: The Myth of the Objective," published by Springer in 2015. His work explores innovative approaches to neural network design and the concept of novelty search in evolutionary algorithms, challenging traditional objective-driven methodologies.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="EVOLUTIONARY COMPUTATION">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A journal where the paper "Abandoning objectives: Evolution through the search for novelty alone" was published in 2011.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PATRICK LEWIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Patrick Lewis is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ETHAN PEREZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ethan Perez is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEKSANDRA PIKTUS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aleksandra Piktus is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FABIO PETRONI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fabio Petroni is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VLADIMIR KARPUKHIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vladimir Karpukhin is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HEINRICH K&#220;TTLER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heinrich K&#252;ttler is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MIKE LEWIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mike Lewis is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="WEN-TAU YIH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wen-tau Yih is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="TIM ROCKT&#196;SCHEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tim Rockt&#228;schel is a notable figure in the field of artificial intelligence and natural language processing. He is one of the authors of the influential paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks," which was published in Advances in Neural Information Processing Systems in 2020. Additionally, he is the author of the book "Artificial Intelligence: 10 Things You Should Know," published by Seven Dials in September 2024. His contributions span both academic research and public education, highlighting his role in advancing and disseminating knowledge in AI and NLP.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FEI LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fei Liu is a notable author in the field of machine learning and large language models. In 2024, Fei Liu contributed to the InfoBench project, which evaluates the instruction-following ability in large language models. Additionally, Fei Liu co-authored the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model," which was presented at the Forty-first International Conference on Machine Learning in the same year.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="TONG XIALIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tong Xialiang is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MINGXUAN YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mingxuan Yuan is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="XI LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xi Lin is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FU LUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fu Luo is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHENKUN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhenkun Wang is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="QINGFU ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qingfu Zhang is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="EVOLUTION OF HEURISTICS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Evolution of heuristics is a method for efficient automatic algorithm design using large language models, discussed in a paper presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZIJUN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zijun Liu is one of the authors of the paper titled "Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team optimization" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YANZHE ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yanzhe Zhang is one of the authors of the paper titled "Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team optimization" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PENG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peng Li is one of the authors of the paper titled "Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team optimization" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YANG LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang Liu is one of the authors of the paper titled "Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team optimization" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DIYI YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Diyi Yang is one of the authors of the paper titled "Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team optimization" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DYNAMIC LLM-AGENT NETWORK">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Dynamic LLM-agent network is a collaboration framework with agent team optimization, discussed in a paper published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CHRIS LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chris Lu is one of the authors of the paper titled "Arbitrary order meta-learning with simple population-based evolution" presented at the 2023 Artificial Life Conference and published by MIT Press in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SEBASTIAN TOWERS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sebastian Towers is one of the authors of the paper titled "Arbitrary order meta-learning with simple population-based evolution" presented at the 2023 Artificial Life Conference and published by MIT Press in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JAKOB FOERSTER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jakob Foerster is one of the authors of the paper titled "Arbitrary order meta-learning with simple population-based evolution" presented at the 2023 Artificial Life Conference and published by MIT Press in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ARBITRARY ORDER META-LEARNING">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Arbitrary order meta-learning with simple population-based evolution is a method discussed in a paper presented at the 2023 Artificial Life Conference and published by MIT Press in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MIT PRESS">
      <data key="d0">PUBLISHER, ORGANIZATION</data>
      <data key="d1">MIT Press is the publisher of the proceedings of the 2023 Artificial Life Conference where the paper "Arbitrary order meta-learning with simple population-based evolution" was presented.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SAMUEL HOLT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Samuel Holt is one of the authors of the paper titled "Discovering preference optimization algorithms with and for large language models" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CLAUDIO FANCONI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Claudio Fanconi is one of the authors of the paper titled "Discovering preference optimization algorithms with and for large language models" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEX J CHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alex J Chan is one of the authors of the paper titled "Discovering preference optimization algorithms with and for large language models" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MIHAELA VAN DER SCHAAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mihaela van der Schaar is one of the authors of the paper titled "Discovering preference optimization algorithms with and for large language models" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ROBERT TJARKO LANGE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Robert Tjarko Lange is one of the authors of the paper titled "Discovering preference optimization algorithms with and for large language models" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DISCOVERING PREFERENCE OPTIMIZATION ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Discovering preference optimization algorithms with and for large language models is a method discussed in a paper published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="THE AI SCIENTIST">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">"The AI Scientist" is a method for fully automated open-ended scientific discovery, as discussed in a research paper titled "The AI Scientist: Towards fully automated open-ended scientific discovery." This paper was published as an arXiv preprint in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="INTELLIGENT GO-EXPLORE">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">"Intelligent Go-Explore" is an algorithm discussed in a research paper titled "Intelligent go-explore: Standing on the shoulders of giant foundation models," published as an arXiv preprint in 2024. This method leverages the advancements of giant foundation models to enhance its performance. Additionally, Intelligent Go-Explore has a simplified version known as Quality-Diversity, which is used as a baseline for experiments on ARC.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="IAN WHALEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ian Whalen is one of the authors of the paper titled "Intelligent Go-Explore: Standing on the shoulders of giant foundation models," published as an arXiv preprint in 2024. Additionally, he co-authored the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," which was published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YASHESH DHEBAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yashesh Dhebar is one of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the Genetic and Evolutionary Computation Conference in 2019. Additionally, Yashesh Dhebar co-authored the paper titled "Intelligent Go-Explore: Standing on the shoulders of giant foundation models," which was published as an arXiv preprint in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="REVISITING RESIDUAL NETWORKS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VISHNU BODDETI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ERIK GOODMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WOLFGANG BANZHAF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="NSGA-NET">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="YECHENG JASON MA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WILLIAM LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="OSBERT BASTANI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="DINESH JAYARAMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="META">
      <data key="d0">ORGANIZATION, COMPANY</data>
      <data key="d1">The company that published the news article "Open source AI is the path forward" in July 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">ORGANIZATION, COMPANY</data>
    </node>
    <node id="OPEN SOURCE AI IS THE PATH FORWARD">
      <data key="d0">NEWS ARTICLE</data>
      <data key="d1">A news article published by Meta in July 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">NEWS ARTICLE</data>
    </node>
    <node id="ELLIOT MEYERSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="MARK J NELSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HERBIE BRADLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ADAM GAIER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ARASH MORADI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="AMY K HOOVER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LANGUAGE MODEL CROSSOVER">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="SHEN-YUN MIAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "A diverse corpus for evaluating and developing English math word problem solvers," published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHAO-CHUN LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "A diverse corpus for evaluating and developing English math word problem solvers," published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KEH-YIH SU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "A diverse corpus for evaluating and developing English math word problem solvers," published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="A DIVERSE CORPUS FOR EVALUATING AND DEVELOPING ENGLISH MATH WORD PROBLEM SOLVERS">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "A diverse corpus for evaluating and developing English math word problem solvers," published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="JEAN-BAPTISTE MOURET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Illuminating search spaces by mapping elites," published as an arXiv preprint in 2015.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ILLUMINATING SEARCH SPACES BY MAPPING ELITES">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "Illuminating search spaces by mapping elites," published as an arXiv preprint in 2015.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="REIICHIRO NAKANO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Reiichiro Nakano is one of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021. Additionally, he contributed to a paper on training verifiers to solve math word problems, also published in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="JACOB HILTON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacob Hilton is one of the authors of the paper on training verifiers to solve math word problems, published in 2021. Additionally, he is one of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," which was published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="JEFF WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LONG OUYANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHRISTINA KIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHRISTOPHER HESSE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="VINEET KOSARAJU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vineet Kosaraju is one of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021. Additionally, he contributed to a paper on training verifiers to solve math word problems, also published in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WILLIAM SAUNDERS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WEBGPT">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="ANDREW NG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The author of the newsletter issue "Issue 253," published in June 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ISSUE 253">
      <data key="d0">NEWSLETTER</data>
      <data key="d1">A newsletter issue authored by Andrew Ng, published in June 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">NEWSLETTER</data>
    </node>
    <node id="BEN NORMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "First-explore, then exploit: Meta-learning intelligent exploration," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="FIRST-EXPLORE, THEN EXPLOIT">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "First-explore, then exploit: Meta-learning intelligent exploration," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="INTRODUCING CHATGPT">
      <data key="d0">BLOG POST</data>
      <data key="d1">A blog post published by OpenAI in November 2022.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">BLOG POST</data>
    </node>
    <node id="SIMPLE EVALS">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper published by OpenAI in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="JOON SUNG PARK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Generative agents: Interactive simulacra of human behavior," published in the Proceedings of the 36th annual ACM symposium on user interface software and technology in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="GENERATIVE AGENTS">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "Generative agents: Interactive simulacra of human behavior," published in the Proceedings of the 36th annual ACM symposium on user interface software and technology in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="ARKIL PATEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Are NLP models really able to solve simple math word problems?" published in the Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies in</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="QIANG WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qiang Wang is one of the authors of the paper "Tool learning with large language models: A survey" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DAWEI YIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dawei Yin is one of the authors of the paper "Tool learning with large language models: A survey" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JUN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jun Xu is one of the authors of the paper "Tool learning with large language models: A survey" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JI-RONG WEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ji-Rong Wen is one of the authors of two notable papers published as arXiv preprints in 2024. The first paper is titled "Tool learning with large language models: A survey," and the second paper is titled "A survey on the memory mechanism of large language model based agents." Both papers contribute to the understanding and advancement of large language models, focusing on tool learning and memory mechanisms, respectively.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="TOOL LEARNING WITH LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Tool learning with large language models: A survey" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RAFAEL RAFAILOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rafael Rafailov is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARCHIT SHARMA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Archit Sharma is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ERIC MITCHELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Mitchell is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="STEFANO ERMON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Stefano Ermon is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DIRECT PREFERENCE OPTIMIZATION: YOUR LANGUAGE MODEL IS SECRETLY A REWARD MODEL">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DAVID REIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Rein is one of the authors of the paper titled "GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BETTY LI HOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Betty Li Hou is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ASA COOPER STICKLAND">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Asa Cooper Stickland is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JACKSON PETTY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jackson Petty is one of the authors of the paper titled "GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="RICHARD YUANZHE PANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Richard Yuanzhe Pang is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JULIEN DIRANI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Julien Dirani is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JULIAN MICHAEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Julian Michael is one of the authors of the paper titled "GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SAMUEL R. BOWMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Samuel R. Bowman is one of the authors of the paper titled "GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="GPQA: A GRADUATE-LEVEL GOOGLE-PROOF Q&amp;A BENCHMARK">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Gpqa: A graduate-level google-proof q&amp;a benchmark" published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TORAN BRUCE RICHARDS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Toran Bruce Richards is the author of the GitHub repository "AutoGPT" created in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AUTOGPT">
      <data key="d0">SOFTWARE, REPOSITORY</data>
      <data key="d1">AutoGPT is a GitHub repository created by Toran Bruce Richards in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE: 10 THINGS YOU SHOULD KNOW">
      <data key="d0">BOOK, PUBLICATION</data>
      <data key="d1">A book titled "Artificial Intelligence: 10 Things You Should Know" authored by Tim Rockt&#228;schel and published by Seven Dials in September 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MD OMAR FARUK ROKON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Md Omar Faruk Rokon is one of the authors of the paper "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RISUL ISLAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Risul Islam is one of the authors of the paper "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AHMAD DARKI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ahmad Darki is one of the authors of the paper "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="EVANGELOS E PAPALEXAKIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Evangelos E Papalexakis is one of the authors of the paper "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MICHALIS FALOUTSOS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michalis Faloutsos is one of the authors of the paper "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="{SOURCEFINDER}: FINDING MALWARE {SOURCE-CODE}FROM PUBLICLY AVAILABLE REPOSITORIES IN {GITHUB}">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BERNARDINO ROMERA-PAREDES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bernardino Romera-Paredes is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MOHAMMADAMIN BAREKATAIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mohammadamin Barekatain is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ALEXANDER NOVIKOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alexander Novikov is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATEJ BALOG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matej Balog is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="M PAWAN KUMAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">M Pawan Kumar is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="EMILIEN DUPONT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Emilien Dupont is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FRANCISCO JR RUIZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Francisco JR Ruiz is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JORDAN S ELLENBERG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jordan S Ellenberg is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="PENGMING WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pengming Wang is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="OMAR FAWZI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Omar Fawzi is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATHEMATICAL DISCOVERIES FROM PROGRAM SEARCH WITH LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ERIC HAMBRO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Hambro is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TOOLFORMER: LANGUAGE MODELS CAN TEACH THEMSELVES TO USE TOOLS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SANDER SCHULHOFF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sander Schulhoff is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MICHAEL ILIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Ilie is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NISHANT BALEPUR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nishant Balepur is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="KONSTANTINE KAHADZE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Konstantine Kahadze is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AMANDA LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amanda Liu is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHENGLEI SI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chenglei Si is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YINHENG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yinheng Li is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AAYUSH GUPTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aayush Gupta is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HYOJUNG HAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">HyoJung Han is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SEVIEN SCHULHOFF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sevien Schulhoff is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="THE PROMPT REPORT: A SYSTEMATIC SURVEY OF PROMPTING TECHNIQUES">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="XUAN SHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xuan Shen is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YAOHUA WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yaohua Wang is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MING LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ming Lin is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YILUN HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yilun Huang is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HAO TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hao Tang is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="XIUYU SUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiuyu Sun is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YANZHI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yanzhi Wang is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DEEPMAD: MATHEMATICAL ARCHITECTURE DESIGN FOR DEEP CONVOLUTIONAL NEURAL NETWORK">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FREDA SHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Freda Shi is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MIRAC SUZGUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mirac Suzgun is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners," published in The Eleventh International Conference on Learning Representations in 2023. Additionally, Mirac Suzgun co-authored the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MARKUS FREITAG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Markus Freitag is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SURAJ SRIVATS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Suraj Srivats is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SOROUSH VOSOUGHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Soroush Vosoughi is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SEBASTIAN RUDER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sebastian Ruder is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DIPANJAN DAS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dipanjan Das is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LANGUAGE MODELS ARE MULTILINGUAL CHAIN-OF-THOUGHT REASONERS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="REFLEXION: LANGUAGE AGENTS WITH VERBAL REINFORCEMENT LEARNING">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Reflexion: Language agents with verbal reinforcement learning" published in Advances in Neural Information Processing Systems in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="WHY GREATNESS CANNOT BE PLANNED: THE MYTH OF THE OBJECTIVE">
      <data key="d0">BOOK, PUBLICATION</data>
      <data key="d1">A book titled "Why greatness cannot be planned: The myth of the objective" authored by Kenneth O Stanley and Joel Lehman, published by Springer in 2015.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RISTO MIIKKULAINEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Risto Miikkulainen is one of the authors of the paper "Designing neural networks through neuroevolution" published in Nature Machine Intelligence in 2019.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DESIGNING NEURAL NETWORKS THROUGH NEUROEVOLUTION">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Designing neural networks through neuroevolution" published in Nature Machine Intelligence in 2019.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RICHARD S SUTTON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Richard S Sutton is one of the authors of the book "Reinforcement learning: An introduction" published by MIT Press in 2018.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ANDREW G BARTO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew G Barto is one of the authors of the book "Reinforcement learning: An introduction" published by MIT Press in 2018.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="REINFORCEMENT LEARNING: AN INTRODUCTION">
      <data key="d0">BOOK, PUBLICATION</data>
      <data key="d1">A book titled "Reinforcement learning: An introduction" authored by Richard S Sutton and Andrew G Barto, published by MIT Press in 2018.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SAI VEMPRALA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sai Vemprala is one of the authors of the technical report "Chatgpt for robotics: Design principles and model abilities" published by Microsoft in February 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROGERIO BONATTI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rogerio Bonatti is one of the authors of the technical report "Chatgpt for robotics: Design principles and model abilities" published by Microsoft in February 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARTHUR BUCKER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arthur Bucker is one of the authors of the technical report "Chatgpt for robotics: Design principles and model abilities" published by Microsoft in February 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ASHISH KAPOOR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ashish Kapoor is one of the authors of the technical report "Chatgpt for robotics: Design principles and model abilities" published by Microsoft in February 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHATGPT FOR ROBOTICS: DESIGN PRINCIPLES AND MODEL ABILITIES">
      <data key="d0">TECHNICAL REPORT, RESEARCH</data>
      <data key="d1">A technical report titled "Chatgpt for robotics: Design principles and model abilities" published by Microsoft in February 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="VOYAGER: AN OPEN-ENDED EMBODIED AGENT WITH LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Voyager: An open-ended embodied agent with large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JANE X WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jane X Wang is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZEB KURTH-NELSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zeb Kurth-Nelson is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DHRUVA TIRUMALA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dhruva Tirumala is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HUBERT SOYER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hubert Soyer is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JOEL Z LEIBO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joel Z Leibo is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="REMI MUNOS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Remi Munos is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHARLES BLUNDELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Charles Blundell is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DHARSHAN KUMARAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dharshan Kumaran is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATT BOTVINICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matt Botvinick is an author who contributed to the paper "Learning to reinforcement learn." This paper was published as an arXiv preprint in 2016.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LEI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lei Wang is an author who contributed to the paper titled "A survey on large language model based autonomous agents." This paper was published in the journal Frontiers of Computer Science.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHEN MA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen Ma is an author who has contributed to multiple papers on large language model-based autonomous agents. Notably, Chen Ma is one of the authors of the paper titled "A survey on large language model based autonomous agents," which was published in Frontiers of Computer Science. Additionally, Chen Ma co-authored another paper titled "A survey on the memory mechanism of large language model based agents," which was published as an arXiv preprint in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XUEYANG FENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xueyang Feng is an author who contributed to the paper titled "A survey on large language model based autonomous agents," which was published in the journal Frontiers of Computer Science.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZEYU ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zeyu Zhang is an author who has contributed to multiple papers on large language model-based autonomous agents. He is one of the authors of the paper titled "A survey on large language model based autonomous agents," which was published in Frontiers of Computer Science. Additionally, he co-authored another paper titled "A survey on the memory mechanism of large language model based agents," which was published as an arXiv preprint in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="HAO YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hao Yang is an author who contributed to the paper titled "A survey on large language model based autonomous agents," which was published in the journal Frontiers of Computer Science.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JINGSEN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jingsen Zhang is an author who contributed to the paper titled "A survey on large language model based autonomous agents," which was published in the journal Frontiers of Computer Science.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZHIYUAN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhiyuan Chen is an author who contributed to the paper titled "A survey on large language model based autonomous agents." This paper was published in the journal Frontiers of Computer Science.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JIAKAI TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiakai Tang is an author who contributed to the paper titled "A survey on large language model based autonomous agents," which was published in the journal Frontiers of Computer Science.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="XU CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu Chen is an author who has contributed to the field of large language model-based autonomous agents. Xu Chen is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents," which was published as an arXiv preprint in 2024. This work highlights Xu Chen's involvement in advancing the understanding of memory mechanisms within large language model-based agents.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHAN KUMARAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shan Kumaran is an author who contributed to the paper "Learning to reinforcement learn."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LEARNING TO REINFORCEMENT LEARN">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Shan Kumaran and Matt Botvinick, published as an arXiv preprint in 2016.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Lei Wang and others, published in Frontiers of Computer Science in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="RUI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rui Wang is an author who contributed to the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="KENNETH O. STANLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kenneth O. Stanley is an author who contributed to the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="POET: OPEN-ENDED COEVOLUTION OF ENVIRONMENTS AND THEIR OPTIMIZED SOLUTIONS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Rui Wang, Joel Lehman, Jeff Clune, and Kenneth O. Stanley, presented at the Genetic and Evolutionary Computation Conference in 2019.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ENHANCED POET: OPEN-ENDED REINFORCEMENT LEARNING THROUGH UNBOUNDED INVENTION OF LEARNING CHALLENGES AND THEIR SOLUTIONS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Rui Wang, Joel Lehman, Aditya Rawal, Jiale Zhi, Yulun Li, Jeffrey Clune, and Kenneth Stanley, presented at the International Conference on Machine Learning in 2020.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="QUOC V LE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Quoc V Le is an author who has made significant contributions to the field of language models and reasoning. He has co-authored several influential papers, including "Self-consistency improves chain of thought reasoning in language models" and "Chain-of-thought prompting elicits reasoning in large language models." In 2022, he contributed to the paper "Challenging big-bench tasks and whether chain-of-thought can solve them." Additionally, Quoc V Le co-authored "Self-discover: Large language models self-compose reasoning structures," published as an arXiv preprint in 2024, and "Take a step back: Evoking reasoning via abstraction in large language models," published as an arXiv preprint in 2023. His work focuses on enhancing the reasoning capabilities of large language models through innovative prompting and self-composition techniques.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ED H. CHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ed H. Chi is an author who contributed to the papers "Self-consistency improves chain of thought reasoning in language models" and "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou, presented at The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou, published in Advances in Neural Information Processing Systems in 2022.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="QINGYUN WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qingyun Wu is an author who has contributed to significant research in the field of language models and multi-agent conversation frameworks. Wu co-authored the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," published in 2023. Additionally, Wu is one of the authors of the paper "Offline training of language model agents with functions as learnable weights," which was presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AUTOGEN: ENABLING NEXT-GEN LLM APPLICATIONS VIA MULTI-AGENT CONVERSATION FRAMEWORK">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Qingyun Wu and others, published as an arXiv preprint in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="BENFENG XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Benfeng Xu is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="EXPERTPROMPTING: INSTRUCTING LARGE LANGUAGE MODELS TO BE DISTINGUISHED EXPERTS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Benfeng Xu and others, published as an arXiv preprint in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHENGRUN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chengrun Yang is an author who contributed to the paper "Large language models as optimizers."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LARGE LANGUAGE MODELS AS OPTIMIZERS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Chengrun Yang and others, presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Shunyu Yao and others, presented at The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="BENNET YEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bennet Yee is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NATIVE CLIENT: A SANDBOX FOR PORTABLE, UNTRUSTED X86 NATIVE CODE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Bennet Yee and others, published in Communications of the ACM in 2010.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="WENHAO YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenhao Yu is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LANGUAGE TO REWARDS FOR ROBOTIC SKILL SYNTHESIS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Wenhao Yu and others, presented at the Conference on Robot Learning in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SIYU YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Siyu Yuan is an author who contributed to the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="EVOAGENT: TOWARDS AUTOMATIC MULTI-AGENT GENERATION VIA EVOLUTIONARY ALGORITHMS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Siyu Yuan and others, published as an arXiv preprint in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ELIEZER YUDKOWSKY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eliezer Yudkowsky is an author who contributed to the paper "Artificial Intelligence as a positive and negative factor in global risk."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE AS A POSITIVE AND NEGATIVE FACTOR IN GLOBAL RISK">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Eliezer Yudkowsky and others, published in Global Catastrophic Risks in 2008.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="MATEI ZAHARIA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matei Zaharia is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="THE SHIFT FROM MODELS TO COMPOUND AI SYSTEMS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Matei Zaharia and others, published on the BAIR blog in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="OMNI: OPEN-ENDEDNESS VIA MODELS OF HUMAN NOTIONS OF INTERESTINGNESS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Jenny Zhang and others, presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SHAOKUN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shaokun Zhang is an author who has contributed to significant research in the field of language models and multi-agent conversation frameworks. Zhang co-authored the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," published in 2023. Additionally, Zhang is one of the authors of the paper "Offline training of language model agents with functions as learnable weights," which was presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ADITYA RAWAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aditya Rawal is an author who contributed to the paper "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JIALE ZHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiale Zhi is an author who contributed to the paper "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YULUN LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yulun Li is an author who contributed to the paper "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="GAGAN BANSAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gagan Bansal is an author who contributed to the paper titled "Autogen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIEYU ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jieyu Zhang is an author who has contributed to significant research in the field of language models and multi-agent conversation frameworks. Jieyu Zhang co-authored the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation framework," published in 2023. Additionally, Jieyu Zhang is one of the authors of the paper "Offline training of language model agents with functions as learnable weights," which was presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIRAN WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiran Wu is an author who contributed to the paper titled "Autogen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ERKANG ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Erkang Zhu is an author who contributed to the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="BEIBIN LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Beibin Li is an author who contributed to the paper titled "Autogen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LI JIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Li Jiang is an author who contributed to the paper titled "Autogen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIAOYUN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiaoyun Zhang is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chi Wang is an author who has made significant contributions to the field of machine learning and language models. Chi Wang co-authored the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation framework," which was published in 2023. Additionally, Chi Wang contributed to the paper "Offline training of language model agents with functions as learnable weights," presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">An Yang is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JUNYANG LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Junyang Lin is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="QUAN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Quan Wang is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHANG ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chang Zhou is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YONGDONG ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yongdong Zhang is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ZHENDONG MAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhendong Mao is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YIFENG LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yifeng Lu is an author who contributed to the paper "Large language models as optimizers."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="HANXIAO LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hanxiao Liu is an author who contributed to the paper "Large language models as optimizers."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JEFFREY ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeffrey Zhao is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="DIAN YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dian Yu is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="IZHAK SHAFRAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Izhak Shafran is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="KARTHIK R NARASIMHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Karthik R Narasimhan is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YUAN CAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuan Cao is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="DAVID SEHR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Sehr is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="GREGORY DARDYK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gregory Dardyk is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="J BRADLEY CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">J Bradley Chen is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ROBERT MUTH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Robert Muth is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="TAVIS ORMANDY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tavis Ormandy is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SHIKI OKASAKA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shiki Okasaka is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NEHA NARULA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Neha Narula is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NICHOLAS FULLAGAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicholas Fullagar is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NIMROD GILEADI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nimrod Gileadi is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SEAN KIRMANI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sean Kirmani is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="MONTSERRAT GONZALEZ ARENAS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Montserrat Gonzalez Arenas is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="HAO-TIEN LEWIS CHIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hao-Tien Lewis Chiang is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="TOM EREZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tom Erez is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LEONARD HASENCLEVER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Leonard Hasenclever is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JAN HUMPLIK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jan Humplik is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JIANGJIE CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiangjie Chen is an author who contributed to the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="DEQING YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Deqing Yang is an author who contributed to the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LINGJIAO CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lingjiao Chen is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JARED QUINCY DAVIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jared Quincy Davis is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHRIS POTTS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chris Potts is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JAMES ZOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">James Zou is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="MICHAEL CARBIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Carbin is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JONATHAN FRANKLE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jonathan Frankle is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NAVEEN RAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Naveen Rao is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ALI GHODSI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ali Ghodsi is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="KENNETH STANLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kenneth Stanley is an author who contributed to the paper titled "OMNI: Open-endedness via models of human notions of interestingness." This paper was presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="OMNI">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">OMNI is a model that explores open-endedness via human notions of interestingness, presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIALE LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiale Liu is a notable author in the field of machine learning and language models. In 2023, Jiale Liu co-authored the paper titled "Autogen: Enabling next-gen LLM applications via multi-agent conversation." Additionally, in 2024, Jiale Liu contributed to the paper "Offline training of language model agents with functions as learnable weights," which was presented at the Forty-first International Conference on Machine Learning. These contributions highlight Jiale Liu's active involvement in advancing the development and application of language models through innovative research.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LINXIN SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Linxin Song is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RANJAY KRISHNA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ranjay Krishna is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">This is a method for training language model agents using functions as learnable weights, presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIAOHE BO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiaohe Bo is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RUI LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rui Li is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="QUANYU DAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Quanyu Dai is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIEMING ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jieming Zhu is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ZHENHUA DONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhenhua Dong is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d0">SURVEY, PAPER</data>
      <data key="d1">This is a survey paper on the memory mechanisms of large language model-based agents, published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="HENG-TZE CHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heng-Tze Cheng is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.Heng-Tze Cheng is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ED H CHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ed H Chi is a prolific author in the field of large language models and reasoning structures. He co-authored the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022. Additionally, he contributed to the paper "Take a step back: Evoking reasoning via abstraction in large language models," which was published as an arXiv preprint in 2023. In 2024, Ed H Chi also co-authored the paper "Self-discover: Large language models self-compose reasoning structures," published as an arXiv preprint. His work focuses on advancing the understanding and capabilities of large language models through innovative approaches to reasoning and abstraction.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, METHOD</data>
      <data key="d1">This paper discusses a method for evoking reasoning via abstraction in large language models, published as an arXiv preprint in 2023.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="PEI ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pei Zhou is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JAY PUJARA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jay Pujara is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIANG REN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiang Ren is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d0">PAPER, METHOD</data>
      <data key="d1">This paper discusses a method where large language models self-compose reasoning structures, published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WANGCHUNSHU ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wangchunshu Zhou is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="YIXIN OU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yixin Ou is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHENGWEI DING">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shengwei Ding is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LONG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Long Li is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIALONG WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jialong Wu is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="TIANNAN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tiannan Wang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIAMIN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiamin Chen is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHUAI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shuai Wang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIAOHUA XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiaohua Xu is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="NINGYU ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ningyu Zhang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d0">PAPER, METHOD</data>
      <data key="d1">This paper discusses how symbolic learning can enable self-evolving agents, published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="MINGCHEN ZHUGE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mingchen Zhuge is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WENYI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenyi Wang is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LOUIS KIRSCH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Louis Kirsch is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="FRANCESCO FACCIO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Francesco Faccio is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="DMITRII KHIZBULLIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dmitrii Khizbullin is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="J&#220;RGEN SCHMIDHUBER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">J&#252;rgen Schmidhuber is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="GPTSWARM">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">GPTSwarm is a method that treats language agents as optimizable graphs, presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LUISA ZINTGRAF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luisa Zintgraf is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SEBASTIAN SCHULZE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sebastian Schulze is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LEO FENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Leo Feng is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="MAXIMILIAN IGL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Maximilian Igl is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="KYRIACOS SHIARLIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kyriacos Shiarlis is one of the authors of the paper</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHIMON WHITEON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shimon Whiteson is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="VARIBAD">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Varibad is a method for variational bayes-adaptive deep reinforcement learning via meta-learning, published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="GITHUB">
      <data key="d0">PLATFORM, TOOL</data>
      <data key="d1">GitHub is an online platform where the detailed prompts and framework code for the Meta Agent in ADAS are available. It hosts the code and agents from the Meta Agent Search experiment, specifically accessible at the URL https://github.com/ShengranHu/ADAS.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,cc802d9b841fde55e9c0c2ba0ef7869d,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="FRAMEWORK CODE">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Framework Code is the code used in the ADAS framework to implement the Meta Agent and other components, as described in the supplementary material of the paper "Automated Design of Agentic Systems."</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="EXPERIMENT DETAILS">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">The "EXPERIMENT DETAILS" encompass comprehensive information about the experimental setup, including the number of questions, evaluation methods, and datasets used. These details are specifically related to the experiments conducted for the ARC challenge, which involve the representation of grids and the use of meta agents. Additionally, the "Experiment Details" are provided in the supplementary material of the paper titled "Automated Design of Agentic Systems," which addresses the ARC Challenge and other reasoning and problem-solving domains.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="EXAMPLE AGENTS">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Example Agents are provided in the supplementary material of the paper "Automated Design of Agentic Systems" to illustrate the design of new agentic systems.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="COST OF EXPERIMENTS">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">The "Cost of Experiments" is a section in the supplementary material of the paper "Automated Design of Agentic Systems" that details the financial costs associated with the experiments conducted. This section specifically addresses the expenses incurred from running search and evaluation experiments, particularly in the context of using advanced language models such as GPT-3.5-Turbo-0125 and GPT-4o-mini.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUPPLEMENTARY MATERIAL">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Supplementary Material is additional content provided in the paper "Automated Design of Agentic Systems" that includes prompts, framework code, experiment details, baselines, example agents, and cost of experiments.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="URL">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">URL is a web address provided in the paper "OMNI: Open-endedness via models of human notions of interestingness" for accessing the paper on openreview.net.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="OPENREVIEW">
      <data key="d0">PLATFORM, TOOL</data>
      <data key="d1">OpenReview is a platform where the paper "OMNI: Open-endedness via models of human notions of interestingness" is available.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="NAME">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">A section in the output where the meta agent provides the name of the next agent architecture it proposes.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPLEMENTATION MISTAKES">
      <data key="d0">ERROR, ISSUE</data>
      <data key="d1">Mistakes that the meta agent may make in the implementation of the proposed architecture, which need to be identified and corrected during self-reflection.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FRAMEWORK">
      <data key="d0">SYSTEM, CODE</data>
      <data key="d1">A simple framework provided to the meta agent to implement basic functions such as querying Foundation Models and formatting prompts. It consists of fewer than 100 lines of code and uses namedtuple Info objects for encapsulating information.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="NAMEDTUPLE INFO OBJECT">
      <data key="d0">DATA STRUCTURE, OBJECT</data>
      <data key="d1">A data structure used in the framework to encapsulate different types of information, facilitating communication between different modules.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="APPENDIX B">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">APPENDIX B is a section in the document where the framework code is available. It specifies the types of tasks and benchmarks, as well as the corresponding methods used to extract answers and generate metrics. This section provides essential details for understanding the implementation and evaluation of the framework, ensuring that users can effectively utilize and assess the provided tools and methodologies.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="APPENDICES C AND D">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">Sections in the document where additional information is available.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="OUTPUT INSTRUCTION AND EXAMPLE">
      <data key="d0">INSTRUCTION, GUIDELINE</data>
      <data key="d1">A set of instructions and an example provided to guide the meta agent in generating the output.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="OVERALL IDEA">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">A part of the "thought" section where the meta agent describes its reasoning and the overall concept behind the agent design.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPLEMENTATION">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">A part of the "thought" section where the meta agent details the implementation steps of the proposed agent.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="WRONG IMPLEMENTATION EXAMPLES">
      <data key="d0">ERROR, ISSUE</data>
      <data key="d1">Examples of potential mistakes that the meta agent may make in the implementation, provided to help identify and correct errors.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="SELF-REFLECTION ROUND 1">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The first round of self-reflection where the meta agent reviews the proposed architecture and implementation to identify mistakes and suggest improvements.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="SELF-REFLECTION ROUND 2">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The second round of self-reflection where the meta agent further revises the code using tips from the "</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="RUNTIME ERROR">
      <data key="d0">ERROR, ISSUE</data>
      <data key="d1">An error encountered during the execution of the generated code, prompting the meta agent to perform self-reflection and debugging.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="DEBUG_THOUGHT">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">A section in the output where the meta agent captures its thought process for debugging the current code after encountering a runtime error.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="INFO OBJECT">
      <data key="d0">DATA STRUCTURE, OBJECT</data>
      <data key="d1">A namedtuple used in the framework to encapsulate different types of information, facilitating communication between different modules.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FM MODULE">
      <data key="d0">SYSTEM, MODULE</data>
      <data key="d1">The FM Module is a functional component used in various methods and agents, such as the Multi-Step Peer Review Agent and the Divide and Conquer Agent, for tasks like thinking, answering, and providing feedback. It plays a crucial role in the initial candidate solution generation process, particularly focusing on 'thinking' and 'code'. The module automatically constructs prompts by concatenating all input Info objects into a structured format, with each Info titled by its metadata. This includes functionalities like generating prompts and querying the FM with provided input information and instructions.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,449db721e37968e073e3579b59e023b2,97457e990eb6e3c88c11c862f9e3265b,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="INFO">
      <data key="d0">DATA STRUCTURE, NAMED TUPLE</data>
      <data key="d1">INFO is a named tuple used for holding task information, including attributes like name, author, content, and iteration index. It serves as an object to encapsulate information about sub-problems, visual representations, and other data elements processed by various modules. Additionally, INFO is provided as input to various modules, often used to guide the feedback and refinement processes.</data>
      <data key="d2">84317ae35cc75d612287186d93461447,d66dc9ce4a9545b44f7486ea057b5937,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="FORMAT_INST">
      <data key="d0">FUNCTION, LAMBDA</data>
      <data key="d1">A lambda function that formats instructions for FM responses, ensuring the JSON format is correct and all fields are included.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="ROLE_DESC">
      <data key="d0">FUNCTION, LAMBDA</data>
      <data key="d1">A lambda function that describes the role of the FM Module, generating a role description string.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="GET_JSON_RESPONSE_FROM_GPT">
      <data key="d0">FUNCTION, METHOD</data>
      <data key="d1">A function that gets a JSON response from a GPT model, taking arguments like user message, model, system message, and temperature, and returning a JSON dictionary.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="AGENT SYSTEM">
      <data key="d0">SOFTWARE COMPONENT, SYSTEM</data>
      <data key="d1">A system that processes task information using a forward function, which can return either a namedtuple Info or a string as the answer.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TASK DESCRIPTIONS">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">Descriptions of tasks that are used to facilitate communication between different modules in the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TOOL FUNCTION CALLS">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">Results from tool function calls that are used as input Info objects in the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="META-AGENT SEARCH">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A simple framework used in the context of the FM Module for agentic systems.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="BACKOFF">
      <data key="d0">FUNCTION, METHOD</data>
      <data key="d1">A method used to handle exceptions, specifically RateLimitError, in the get_json_response_from_gpt function.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="RATE LIMIT ERROR">
      <data key="d0">ERROR, EXCEPTION</data>
      <data key="d1">An error handled by the backoff method in the get_json_response_from_gpt function.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="SYSTEM MESSAGE">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">The "SYSTEM MESSAGE" is a predefined message used as an argument in the get_json_response_from_gpt function to guide the GPT model's response. It plays a crucial role in steering the evaluation process for different types of problems. Additionally, it is a type of message utilized in the multi-turn interaction sequence within the Orca-Bench dataset, highlighting its importance in structured algorithmic analysis and interaction.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,bd4eb9459bc29b4c2da4658914fd4635,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="SAMPLING TEMPERATURE">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">A parameter used in the get_json_response_from_gpt function to control the randomness of the GPT model's output.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="OUTPUT FIELDS">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">Fields expected in the output of the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="UNIQUE IDENTIFIER">
      <data key="d0">DATA STRUCTURE, IDENTIFIER</data>
      <data key="d1">A unique ID for instances of the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="INSTRUCTION">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">Instructions provided to the FM Module for generating prompts and querying information.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="ITERATION INDEX">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">An index used to track iterations in tasks processed by the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_INITIAL_INSTRUCTION">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">An instruction for initial reasoning in the self-reflection method.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_REFLECT_INSTRUCTION">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">An instruction for reflecting on previous attempts and feedback in the self-reflection method.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="CRITIC INSTRUCTION">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">An instruction for providing feedback and correcting the answer in the self-reflection method.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named FM_Module that handles 'thinking' and 'answer' processes, used in the Chain-of-Thought method.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">MODULE, COMPONENT</data>
    </node>
    <node id="CRITIC_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">An instruction that asks the user to review and criticize the answer, or confirm its correctness by outputting 'True'.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">INSTRUCTION</data>
    </node>
    <node id="CRITIC_MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named FM_Module that handles 'feedback' and 'correct' processes, used in the Critic method.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">MODULE, COMPONENT</data>
    </node>
    <node id="N_MAX">
      <data key="d0">PARAMETER</data>
      <data key="d1">A parameter that sets the maximum number of attempts to 5.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="TASKINFO">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">TASKINFO refers to the information about a task that is used as input for various modules and processes. This data is essential for the functioning of different components such as the decomposition module and the integration module. TaskInfo serves as the foundational input data provided to the agent, enabling it to effectively solve the given task.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="EXAMPLE INPUT-OUTPUT GRID">
      <data key="d0">DATA, EXAMPLE</data>
      <data key="d1">Paired example inputs and outputs grids used to demonstrate the transformation rules in the ARC challenge.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">DATA, EXAMPLE</data>
    </node>
    <node id="GPT-4O-2024-05-13">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">GPT-4O-2024-05-13 is a version of the GPT-4 language model utilized by the meta agent in the ARC challenge. This specific iteration of the GPT-4 model is employed by the meta agent for evaluation purposes and is integral to the experiments described.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="GPT-3.5-TURBO-0125">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">GPT-3.5-TURBO-0125 is a version of the GPT-3.5 language model used during the evaluation of discovered agents and baselines, particularly in the ARC challenge. It plays a significant role in reducing compute costs associated with these experiments.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="EXACT MATCH">
      <data key="d0">METRIC</data>
      <data key="d1">A metric used to calculate the accuracy rate by comparing the reference solution and the predicted answer in the ARC challenge.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="FM_MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">The FM_MODULE is a versatile and flexible module employed in a wide range of contexts, including decomposition, integration, visual representation, verification, and chain-of-thought processes. It is adept at handling various tasks such as providing human-like feedback, expert feedback, and refining solutions. Additionally, the FM_MODULE is integral to both the Chain-of-Thought and Critic methods, managing processes like 'thinking', 'answer', 'feedback', and 'correct'. This multifaceted module is essential for ensuring comprehensive and dynamic interactions within its operational framework.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INPUT GRID">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">A grid that serves as the input in the ARC challenge, represented as a rectangular matrix of integers between 0 and 9.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="OUTPUT GRID">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">A grid that serves as the output in the ARC challenge, produced by applying a transformation rule to the input grid.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="BEST AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">The best agent discovered by Meta Agent Search for solving tasks in the ARC benchmark.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="INITIAL INSTRUCTION">
      <data key="d0">INSTRUCTION, COMMAND</data>
      <data key="d1">The initial instruction given to the FM Module to generate candidate solutions, which is 'Please think step by step and then solve the task by writing the code.'</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="INITIAL SOLUTION">
      <data key="d0">SOLUTION, OUTPUT</data>
      <data key="d1">Initial Solution is the output generated by the FM Module based on the initial instruction and TaskInfo.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="CORRECT EXAMPLES">
      <data key="d0">DATA, EXAMPLES</data>
      <data key="d1">Correct Examples are the examples that the initial solution passed successfully.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="WRONG EXAMPLES">
      <data key="d0">DATA, EXAMPLES</data>
      <data key="d1">Wrong Examples are the examples that the initial solution failed to pass.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="ENSEMBLE AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">An agent that uses multiple FM Modules to generate initial candidate solutions for solving tasks.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="NUM_CANDIDATES">
      <data key="d0">PARAMETER, VARIABLE</data>
      <data key="d1">The number of initial candidate solutions generated by the FM Module, set to 5 in the experiment.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="THOUGHTS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">"THOUGHTS" are the intermediate outputs generated by the FM Module, encompassing both 'thinking' and 'code'. These outputs are produced by various modules and include the thought process as well as feedback. This comprehensive generation of 'THOUGHTS' reflects the intricate interactions and dynamics within the algorithmic community, highlighting the multifaceted nature of the thought process and its integration with code and feedback mechanisms.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="CORRECT_COUNT">
      <data key="d0">METRIC, DATA</data>
      <data key="d1">The number of correct examples that an initial solution passed, used to evaluate the solution's effectiveness.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="THINKING">
      <data key="d0">PROCESS, ATTRIBUTE</data>
      <data key="d1">The thought process or reasoning associated with a solution or feedback.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="CORRECT_EXAMPLES">
      <data key="d0">DATA, METRIC</data>
      <data key="d1">Examples where the code produced correct results, used to evaluate the effectiveness of solutions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="WRONG_EXAMPLES">
      <data key="d0">DATA, METRIC</data>
      <data key="d1">Examples where the code produced incorrect results, used to evaluate the effectiveness of solutions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="INITIAL_SOLUTIONS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Initial set of solutions generated based on the initial code and feedback.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="HUMAN_LIKE_FEEDBACK_MODULE">
      <data key="d0">MODULE, SYSTEM</data>
      <data key="d1">A module designed to simulate human-like feedback for code, focusing on common mistakes, heuristic corrections, and best practices.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="HUMAN_FEEDBACK_INSTRUCTION">
      <data key="d0">INSTRUCTION, DATA</data>
      <data key="d1">Instruction provided to the human-like feedback module to guide the feedback process.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT_ROLES">
      <data key="d0">ROLE, ATTRIBUTE</data>
      <data key="d1">Different roles assigned to expert advisors, such as Efficiency Expert, Readability Expert, and Simplicity Expert.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT_ADVISORS">
      <data key="d0">MODULE, SYSTEM</data>
      <data key="d1">Modules assigned to different expert roles to provide targeted feedback for code improvement.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT_INSTRUCTION">
      <data key="d0">INSTRUCTION, DATA</data>
      <data key="d1">Instruction provided to expert advisors to guide the evaluation and feedback process.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINEMENT_MODULE">
      <data key="d0">MODULE, SYSTEM</data>
      <data key="d1">A module designed to parse and structure feedback to refine solutions iteratively.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="MAX_REFINEMENT_ITERATIONS">
      <data key="d0">PARAMETER, ATTRIBUTE</data>
      <data key="d1">The maximum number of iterations allowed for refining solutions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINEMENT_INSTRUCTION">
      <data key="d0">INSTRUCTION, DATA</data>
      <data key="d1">Instruction provided to the refinement module to guide the refinement process.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINED_SOLUTIONS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Solutions that have been refined based on structured feedback.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="SORTED_SOLUTIONS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Refined solutions sorted by their performance, specifically by the number of correct examples.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="TOP_SOLUTIONS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The top-performing solutions selected from the sorted solutions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_DECISION_INSTRUCTION">
      <data key="d0">INSTRUCTION, DATA</data>
      <data key="d1">Instruction provided to the final decision module to guide the final decision-making process.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_DECISION_MODULE">
      <data key="d0">MODULE, SYSTEM</data>
      <data key="d1">A module designed to make the final decision by reasoning over the top solutions and writing the final code.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_THOUGHTS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The final thought process and code generated by the final decision module.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="META_AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">An agent using the "gpt-4o-2024-05-13" model for evaluation.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="DISCOVERED_AGENTS">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">Agents evaluated using the "gpt-3.5-turbo-0125" model to reduce compute cost.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="CONTENT">
      <data key="d0">DATA, ATTRIBUTE</data>
      <data key="d1">The actual text or information contained within feedback or other data elements.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="ROLE">
      <data key="d0">ATTRIBUTE, CATEGORY</data>
      <data key="d1">The specific function or position assigned to expert advisors, such as Efficiency Expert, Readability Expert, and Simplicity Expert.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="TEMPERATURE">
      <data key="d0">PARAMETER, ATTRIBUTE</data>
      <data key="d1">A parameter used in various modules to control the randomness or creativity of the output.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="ZERO-SHOT STYLE QUESTIONS">
      <data key="d0">DATA, QUESTION TYPE</data>
      <data key="d1">Questions that are answered without any prior examples or training on similar questions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="ONE-SHOT STYLE QUESTIONS">
      <data key="d0">DATA, QUESTION TYPE</data>
      <data key="d1">Questions that are answered with the help of one example or prior training on a similar question.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="AUTOMATED DESIGN OF AGENTIC SYSTEMS">
      <data key="d0">DOCUMENT, RESEARCH</data>
      <data key="d1">A document or research paper discussing the automated design of agentic systems, including experimental details and methodologies.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="DISCOVERED AGENTS">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">Agents that are evaluated using models like GPT-3.5-turbo-0125 to reduce compute costs.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REASONING AND PROBLEM-SOLVING DOMAINS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="NON-NATIONALS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Non-nationals are individuals who are not citizens of the country they reside in. In the context of Bahrain, they make up more than half of the population.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="IMMIGRANTS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Immigrants are individuals who move to a country other than their native one. In Bahrain, they make up about 55% of the overall population.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="INDIANS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Indians are a demographic group in Bahrain, with roughly 290,000 individuals reported between 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="BANGLADESHIS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Bangladeshis are a demographic group in Bahrain, with roughly 125,000 individuals reported between 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PAKISTANIS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Pakistanis are a demographic group in Bahrain, with roughly 45,000 individuals reported between 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="FILIPINOS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Filipinos are a demographic group in Bahrain, with roughly 45,000 individuals reported between 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="INDONESIANS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Indonesians are a demographic group in Bahrain, with roughly 8,000 individuals reported between 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="BIOLOGY">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">Biology is one of the domains covered by the GPQA benchmark, consisting of challenging multiple-choice questions.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PHYSICS">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">Physics is one of the domains covered by the GPQA benchmark, consisting of challenging multiple-choice questions.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CHEMISTRY">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">Chemistry is one of the domains covered by the GPQA benchmark, consisting of challenging multiple-choice questions.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="STEM">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">STEM (Science, Technology, Engineering, and Mathematics) is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="SOCIAL SCIENCES">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">Social Sciences is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="HUMANITIES">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">Humanities is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="OPENAI, 2024">
      <data key="d0">AUTHOR, ORGANIZATION</data>
      <data key="d1">OpenAI is the organization mentioned in the context of the meta agent using GPT-4o-2024-05-13.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="DISCRETE REASONING">
      <data key="d0">SKILL, ABILITY</data>
      <data key="d1">Discrete Reasoning is the ability to perform logical reasoning tasks that involve distinct and separate elements, as assessed by the DROP benchmark.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="MULTIPLE PARAGRAPHS">
      <data key="d0">TEXT STRUCTURE, FORMAT</data>
      <data key="d1">Multiple Paragraphs refer to the format of text that the DROP benchmark assesses for comprehension and reasoning.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="GRADUATE-LEVEL GOOGLE-PROOF Q&amp;A BENCHMARK">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">Graduate-Level Google-Proof Q&amp;A Benchmark (GPQA) is a benchmark consisting of challenging multiple-choice questions across the domains of biology, physics, and chemistry.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="MULTILINGUAL GRADE SCHOOL MATH BENCHMARK">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">Multilingual Grade School Math Benchmark (MGSM) evaluates mathematical problem-solving abilities across various languages.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">Massive Multitask Language Understanding (MMLU) is a benchmark that assesses a model&#8217;s ability to answer questions across a wide range of subjects and difficulty levels.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="AI2 REASONING CHALLENGE">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">AI2 Reasoning Challenge (ARC) is a benchmark used for evaluating reasoning and problem-solving abilities in AI models.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="QUANTUM STATES">
      <data key="d0">PHYSICAL CONCEPT, ENTITY</data>
      <data key="d1">Quantum States refer to the specific states of a quantum system, characterized by distinct energy levels, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="ENERGY LEVELS">
      <data key="d0">PHYSICAL CONCEPT, ENTITY</data>
      <data key="d1">Energy Levels refer to the specific energies that quantum states can have, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="UNCERTAINTY PRINCIPLE">
      <data key="d0">PHYSICAL LAW, CONCEPT</data>
      <data key="d1">Uncertainty Principle is a fundamental principle in quantum mechanics that relates the uncertainty in energy and time, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="DELTA E">
      <data key="d0">PHYSICAL QUANTITY, VARIABLE</data>
      <data key="d1">Delta E refers to the uncertainty in energy, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="DELTA T">
      <data key="d0">PHYSICAL QUANTITY, VARIABLE</data>
      <data key="d1">Delta T refers to the uncertainty in time, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="HBAR">
      <data key="d0">PHYSICAL CONSTANT, SYMBOL</data>
      <data key="d1">Hbar is the reduced Planck constant, a fundamental constant in quantum mechanics, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PET RABBITS">
      <data key="d0">ANIMAL, PET</data>
      <data key="d1">Pet Rabbits are mentioned in the MGSM example question as being fewer in number compared to pet dogs and cats.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PET DOGS">
      <data key="d0">ANIMAL, PET</data>
      <data key="d1">Pet Dogs are mentioned in the MGSM example question as being part of the total number of pets in the neighborhood.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PET CATS">
      <data key="d0">ANIMAL, PET</data>
      <data key="d1">Pet Cats are mentioned in the MGSM example question as being part of the total number of pets in the neighborhood.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CASSIOPEIA">
      <data key="d0">ASTRONOMICAL OBJECT, CONSTELLATION</data>
      <data key="d1">Cassiopeia is a bright W-shaped constellation in the northern sky, as mentioned in the MMLU example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CENTURUS">
      <data key="d0">ASTRONOMICAL OBJECT, CONSTELLATION</data>
      <data key="d1">Centurus is one of the constellations mentioned in the MMLU example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CYGNUS">
      <data key="d0">ASTRONOMICAL OBJECT, CONSTELLATION</data>
      <data key="d1">Cygnus is one of the constellations mentioned in the MMLU example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CEPHEUS">
      <data key="d0">ASTRONOMICAL OBJECT, CONSTELLATION</data>
      <data key="d1">Cepheus is one of the constellations mentioned in the MMLU example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PHYSICS EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a debate module or specialized expert in methods like LLM-Debate and Divide and Conquer Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="CHEMISTRY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a debate module or specialized expert in methods like LLM-Debate and Divide and Conquer Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="BIOLOGY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a debate module or specialized expert in methods like LLM-Debate and Divide and Conquer Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="SCIENCE GENERALIST">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a debate module in methods like LLM-Debate.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="PHYSICS CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a critic module in methods like Multi-Step Peer Review Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="CHEMISTRY CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a critic module in methods like Multi-Step Peer Review Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="BIOLOGY CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a critic module in methods like Multi-Step Peer Review Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="GENERAL CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a critic module in methods like Multi-Step Peer Review Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="FM QUERY">
      <data key="d0">COMPONENT</data>
      <data key="d1">FM Query is a functional module used in various methods like COT-SC and Role Assignment for querying the FM to get answers or choose roles.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="DEBATE MODULE">
      <data key="d0">COMPONENT</data>
      <data key="d1">Debate Module is a functional module used in LLM-Debate, where each module is assigned a unique role and participates in the debate.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="DECOMPOSITION MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Decomposition Module' that handles the decomposition of tasks into sub-problems. It is instantiated with parameters related to 'thinking' and 'sub_problems'.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SPECIALIZED EXPERT">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Specialized Expert' that is assigned to solve specific sub-problems. It includes roles such as 'Physics Expert', 'Chemistry Expert', 'Biology Expert', and 'General Expert'.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INTEGRATION MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Integration Module' that integrates solutions to sub-problems into a final answer. It is instantiated with parameters related to 'thinking' and 'answer'.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB_PROBLEMS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The sub-problems generated by the decomposition module from the main task.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB_SOLUTIONS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The solutions to the sub-problems provided by the specialized experts.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL REPRESENTATION MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Visual Representation Module' that generates visual representations of problems, such as diagrams or graphs.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VERIFICATION MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Verification Module' that verifies the accuracy and relevance of visual representations and provides feedback and suggestions for improvement.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="CHAIN-OF-THOUGHT MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Chain-of-Thought Module' that uses verified visual representations to solve problems step by step.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="GPT-4O-MINI">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">A newer language model that is less expensive and offers better performance compared to GPT-3.5-Turbo-0125.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="ADAS ALGORITHMS">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">Algorithms used for the automated design of agentic systems, which could benefit from more sophisticated evaluation functions to reduce costs.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL REPRESENTATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VERIFIED VISUAL">
      <data key="d0" />
      <data key="d1">The verified visual representation of a problem, produced by the verification module after checking the initial visual output.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
      <data key="d3">DATA, OUTPUT</data>
    </node>
    <node id="DECOMPOSITION INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to the decomposition module to guide the decomposition of the main task into sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB_PROBLEM INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to specialized experts to guide the step-by-step solution of sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INTEGRATION INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to the integration module to guide the integration of sub-problem solutions into a final answer.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to the visual representation module to create visual representations of problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VERIFICATION INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to the verification module to verify the accuracy and relevance of visual representations.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="COT INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to the Chain-of-Thought module to solve problems using verified visual representations.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB_PROBLEM INFO">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Information about individual sub-problems, including their content and index, used by specialized experts to solve sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL OUTPUT">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The output generated by the visual representation module, which includes visual representations of problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="AGENTINSTRUCT">
      <data key="d0">FRAMEWORK, TOOL</data>
      <data key="d1">AgentInstruct is an extensible, data-driven framework designed to generate approximately 22 million instructions for training machine learning models, focusing on various skills. It employs a strategy aimed at synthesizing a large and diverse corpus of data with varying degrees of difficulty to enhance the performance of models like Orca-3 and Mistral across various tasks, including math and format following. This targeted training method has shown substantial improvement in Mistral&#8217;s reading comprehension capabilities and achieved a reduction in hallucinations by 31.34% while maintaining a quality level comparable to GPT-4.

AgentInstruct reduces the need for human expertise in data generation by fine-tuning language models and enabling the creation of high-quality synthetic data at scale. It is an agentic solution for Generative Teaching, focusing on creating demonstration and feedback data using raw documents as input. The framework can autonomously generate high-quality, diverse, and large quantities of data using powerful models like GPT-4 and tools such as search and code interpreters. By addressing concerns like lack of diversity and the need for human curation in model training, AgentInstruct uses agentic flows for synthetic data generation, making it a robust approach to enhancing AI model performance.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GENERATIVE TEACHING">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Generative Teaching is a methodology focused on enhancing AI model performance by generating abundant amounts of diverse, challenging, and high-quality data. This approach generalizes problem settings to a broader objective of data generation for post-training of AI models. It employs methods like AgentInstruct to create synthetic data, which is then used to teach new skills or behaviors to other models. By concentrating on post-training, Generative Teaching aims to improve the capabilities of language models, ensuring they can perform a wide range of tasks effectively.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SYNTHETIC DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Synthetic data is artificially generated data used to accelerate the development of language models and improve model performance and customization. It varies in quality and diversity, often requiring significant human effort for curation and filtering to ensure high quality. Methods like AgentInstruct can be employed to create synthetic data, enhancing its effectiveness for model training.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MISTRAL-7B">
      <data key="d0">LANGUAGE MODEL</data>
      <data key="d1">Mistral-7B is a base language model that was fine-tuned using a synthetic dataset created by AgentInstruct. The fine-tuned version, known as Orca-3, demonstrated significant improvements over other instruction-tuned models. This post-training with synthetic data generated by AgentInstruct led to notable performance enhancements across various benchmarks.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="ORCA-3">
      <data key="d0">LANGUAGE MODEL</data>
      <data key="d1">ORCA-3 is a machine learning model fine-tuned on the Mistral-7B-v0.1 model using the AgentInstruct dataset, which consists of 25.8 million paired instructions. This advanced 7B model has been evaluated using the Orca-Bench dataset, demonstrating performance improvements with scores increasing from 9.35 to 9.55 across different checkpoints. ORCA-3 has shown significant advancements in various benchmarks, including reading comprehension and math, outperforming its predecessors Orca 2.5 and Mistral-7B-Instruct, as well as other models like LLAMA-8B-instruct and GPT-3.5-turbo. The model's substantial performance improvements are attributed to the post-training with the synthetic dataset generated by AgentInstruct, highlighting its enhanced capabilities over baseline models.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AGIEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">AGIEval is a human-centric benchmark designed to evaluate the performance of AI models on various tasks pertinent to human cognition and problem-solving, including reading comprehension, math, and standardized exams like the SAT and LSAT. The benchmark is discussed in a 2023 paper titled "Agieval: A human-centric benchmark for evaluating foundation models." Notably, the AI model Orca-3 demonstrated a significant improvement on AGIEval, scoring 56.80, which represents a 40% enhancement over its predecessor, Orca-2.5, and a similar improvement compared to Mistral-Instruct-7B.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="BBH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">BBH, or Big Bench Hard, is a benchmark used to evaluate the performance of AI models, particularly on multi-step arithmetic and complex reasoning problems. It consists of 23 tasks selected from the broader Big-Bench benchmark, designed to challenge models with intricate, multi-step reasoning. Notably, the AI model Orca-3 demonstrated a significant improvement on BBH, scoring 61.83, which represents a 38% enhancement over its predecessor, Orca-2.5, and a similar improvement compared to Mistral-Instruct-7B.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ALPACAEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">ALPACAEVAL is a benchmark specifically designed to evaluate chat-based language models, particularly in their ability to follow instructions. It consists of 805 instructions and measures win-rates, which indicate the number of times GPT-4-turbo (version 0613) prefers the outputs of the evaluated model over a reference answer. Developed by a team of researchers and published in 2023, AlpacaEval serves as an automatic evaluator of instruction-following models. Notably, Orca-3 demonstrated a 45% improvement on AlpacaEval compared to both Orca-2.5 and Mistral-7B-Instruct, with a score of 24.80, highlighting its enhanced performance.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="LLAMA-8B-INSTRUCT">
      <data key="d0">LANGUAGE MODEL</data>
      <data key="d1">LLAMA-8B-instruct is a language model that has been consistently outperformed by Orca-3 in various benchmarks. Despite its capabilities as an AI model, LLAMA-8B-instruct has not matched the performance levels demonstrated by Orca-3 across multiple evaluation metrics.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="GPT-3.5-TURBO">
      <data key="d0">LANGUAGE MODEL</data>
      <data key="d1">GPT-3.5-Turbo is an advanced language model that serves as a baseline for evaluating the performance of other models, such as Orca-3. It has been evaluated using various datasets, including the Orca-Bench and MIRAGE datasets, and is referenced for its scores in GSM8K. Despite its capabilities, GPT-3.5-Turbo is consistently outperformed by Orca-3 in multiple benchmarks, including RAG tasks.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ARINDAM MITRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arindam Mitra is a notable author involved in several significant projects and publications. In 2023, he contributed to the Orca 2 project, which aims to teach small language models how to reason. Additionally, he co-authored the Phi-3 technical report and a paper on AgentInstruct and Generative Teaching. His work spans various aspects of artificial intelligence and machine learning, highlighting his expertise and contributions to the field.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LUCIANO DEL CORRO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luciano Del Corro is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023. Additionally, he is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="GUOQING ZHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guoqing Zheng is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023. Additionally, Guoqing Zheng contributed to the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SHWETI MAHAJAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shweti Mahajan is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023. Additionally, Shweti Mahajan is also one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="DANY ROUHANA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dany Rouhana is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="ANDRES CODAS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andres Codas is a notable author involved in significant advancements in the field of artificial intelligence. In 2023, he contributed to the Orca 2 project, which aims to teach small language models how to reason. Additionally, he co-authored a paper on AgentInstruct and Generative Teaching, further showcasing his expertise and commitment to the development of intelligent systems.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="YADONG LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yadong Lu is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="WEI-GE CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wei-ge Chen is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="OLGA VROUSGOS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Olga Vrousgos is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CORBY ROSSET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Corby Rosset is a prolific author involved in several significant research projects. He is one of the authors of the Phi-3 technical report and has contributed to the paper on AgentInstruct and Generative Teaching. Additionally, Corby Rosset co-authored the paper titled "Direct Nash Optimization: Teaching language models to self-improve with general preferences," published in 2024. He also played a key role in the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="FILLIPE SILVA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fillipe Silva is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="HAMED KHANPOUR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hamed Khanpour is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023. Additionally, he is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="YASH LARA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yash Lara is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="AHMED AWADALLAH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ahmed Awadallah is a notable author involved in several significant projects and publications in the field of language models and artificial intelligence. In 2023, he contributed to the Orca 2 project, which aims to teach small language models how to reason. Additionally, he co-authored the Phi-3 technical report and a paper on AgentInstruct and Generative Teaching, further showcasing his expertise and active participation in advancing AI research.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="POST-TRAINING">
      <data key="d0">METHOD, PROCESS</data>
      <data key="d1">Post-training refers to the process of further training a pre-trained language model using additional data to enhance its performance and capabilities. This phase occurs after the initial training of models, during which their capabilities are enhanced, as demonstrated in performance comparisons.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="INSTRUCTION TUNING">
      <data key="d0">METHOD, PROCESS</data>
      <data key="d1">Instruction tuning is a process where a language model is fine-tuned using a set of instructions to improve its ability to follow and generate instructions accurately.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="RLHF">
      <data key="d0">METHOD, PROCESS</data>
      <data key="d1">Reinforcement Learning from Human Feedback (RLHF) is a method used to train language models by incorporating feedback from human evaluators to improve the model's performance.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="RESPONSES">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Responses are the outputs generated by a language model in reaction to given prompts. They are used to create synthetic data for training and evaluation. Additionally, responses are integral to workflows such as Generative Teaching and AgentInstruct, where they form a crucial part of the data generation process.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="TEXT EDITING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Text editing is a skill that involves modifying and improving text. It is one of the skills taught to language models using synthetic data generated by AgentInstruct.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CREATIVE WRITING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Creative writing involves producing original written content, often with a focus on narrative and artistic expression. It is a skill that entails composing original and imaginative text. This skill can be taught to AI models using synthetic data generated by AgentInstruct, which helps in training language models to master the art of creative writing.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TOOL USAGE">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Tool usage is a skill that involves using various tools like search APIs, calculators, and code interpreters. It is one of the skills taught to language models using synthetic data generated by AgentInstruct.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CODING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">CODING involves writing code following instructions, understanding code, debugging code, and tracing or writing test cases. It is a skill that encompasses writing and understanding computer code, and is one of the skills taught to language models using synthetic data generated by AgentInstruct.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,6fe27f9eb76cf2ddf712a2cee5783d1c,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SLMS">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Small Language Models (SLMs) are language models that are smaller in size compared to LLMs but are also trained to perform natural language processing tasks.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MODEL COLLAPSE">
      <data key="d0">ISSUE, PROBLEM</data>
      <data key="d1">Model collapse refers to the degradation of a language model's performance due to training on low-quality or repetitive synthetic data generated by other models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="IMITATION PROCESS">
      <data key="d0">ISSUE, PROBLEM</data>
      <data key="d1">Imitation process refers to the risk of a language model learning only stylistic characteristics rather than real capabilities when trained on synthetic data generated by other models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MULTI-AGENT WORKFLOWS">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Multi-agent workflows involve multiple agents working together to generate high-quality data by using reflection, iteration, and tool usage to improve solutions.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SEARCH APIS">
      <data key="d0">TOOL, TECHNOLOGY</data>
      <data key="d1">SEARCH APIS are tools that agents can use to perform specific tasks, such as searching for information. They allow agents to perform searches and retrieve information from various sources, thereby improving the quality of generated data. These APIs are integral in enhancing the efficiency and accuracy of information retrieval processes within algorithmic communities.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CALCULATOR">
      <data key="d0">TOOL, TECHNOLOGY</data>
      <data key="d1">A calculator is a tool that agents can use to perform mathematical calculations. It is specifically utilized by agents to enhance the quality of generated data through precise and accurate computations.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CODE INTERPRETERS">
      <data key="d0">TOOL, TECHNOLOGY</data>
      <data key="d1">Code interpreters are tools used by agents to execute and understand code to improve the quality of generated data.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SYNTHETIC-DATA-GENERATION-AS-A-SERVICE">
      <data key="d0">SERVICE, CONCEPT</data>
      <data key="d1">Synthetic-Data-Generation-As-A-Service is a concept where agents start with raw materials and generate data for post-training and fine-tuning, enabling continual learning and improvement of any base LLM.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="CONTENT TRANSFORMATION AGENTS">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">Content Transformation Agents are used in the AgentInstruct methodology to transform raw seeds into diverse sets of instructions.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="REFINEMENT AGENTS">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">Refinement Agents are used in the AgentInstruct methodology to iteratively refine the complexity and quality of the seed instructions.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="RAW SEEDS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Raw seeds refer to unstructured text documents or source code used as the initial input for the AgentInstruct methodology to generate diverse and high-quality data.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="INSTRUCTION CREATION AGENTS">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">Instruction Creation Agents are used in the AgentInstruct methodology to create a diverse set of instructions from the transformed seeds.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="DATA GENERATION WORKFLOWS">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">Data generation workflows refer to the processes involved in creating new data, which can be automated to reduce or eliminate the need for human intervention in some tasks.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="SKILLS">
      <data key="d0">ATTRIBUTE, CAPABILITY</data>
      <data key="d1">Skills are the abilities or tasks that workflows aim to develop or assess, encompassing a wide range of competencies such as reading comprehension, coding, creative writing, reasoning, math, and tool use. These skills refer to the abilities or competencies that an AI model can learn or improve upon, highlighting the diverse nature of skills that can be targeted for development or assessment.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TAXONOMY">
      <data key="d0">STRUCTURE, CLASSIFICATION</data>
      <data key="d1">A taxonomy is a structured classification system used by AgentInstruct to organize over 100 subcategories for creating diverse and high-quality prompts and responses.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="VERIFICATION AND DATA FILTERING">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">Verification and data filtering are processes applied by AgentInstruct to ensure the quality and relevance of the generated data.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="UNSTRUCTURED TEXT DOCUMENTS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Unstructured text documents are raw data inputs used as seeds in the AgentInstruct methodology to generate diverse and high-quality data.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="SOURCE CODE">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Source code is another form of raw data input used as seeds in the AgentInstruct methodology to generate diverse and high-quality data.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="CONTINUAL LEARNING">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">Continual learning is the process of continuously improving an AI model by generating new data for post-training and fine-tuning.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="MISTRAL-INSTRUCT-7B">
      <data key="d0">MODEL, AI</data>
      <data key="d1">Mistral-Instruct-7B is an AI model that serves as a baseline for comparison with other models, specifically the fine-tuned Orca-3 model. It was evaluated using the Orca-Bench dataset and achieved an average score of 8.31 out of 10. This model is instrumental in highlighting performance improvements in the text.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="AGENTIC FLOWS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">"AGENTIC FLOWS" are processes utilized by AgentInstruct for synthetic data generation. These flows play a crucial role in creating diverse and high-quality datasets essential for model training. By automating the generation process, Agentic flows leverage raw articles as seeds, fostering diversity and ensuring that the problems generated in different iterations are distinct and cover a broad range of topics. This approach not only enhances the quality of the datasets but also ensures comprehensive coverage, making it a vital component in the development of robust and versatile models.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CONTENT TRANSFORMATION FLOW">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">CONTENT TRANSFORMATION FLOW is a process that synthesizes a list of APIs from a random seed, either by using an API retrieval agent or hypothesizing other APIs present in the library. It converts raw seed into an intermediate representation that simplifies the creation of instructions tailored to specific objectives. Additionally, CONTENT TRANSFORMATION FLOW is a method to transform arbitrary articles into well-crafted pieces conducive to the formulation of a wide array of reading comprehension question types. It includes a suite of nine content transformation agents for generating various types of passages.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTION GENERATION FLOW">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The "SEED INSTRUCTION GENERATION FLOW" is a sophisticated process designed to take transformed content and generate a diverse set of instructions following a comprehensive taxonomy. This flow involves compiling a collection of reading comprehension question types and defining multiple agents to generate questions based on these predefined types from a given text. By leveraging a structured approach, the Seed Instruction Generation Flow ensures the creation of varied and well-organized instructional content, enhancing the overall quality and effectiveness of the generated questions.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INSTRUCTION REFINEMENT FLOW">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The "INSTRUCTION REFINEMENT FLOW" is a process designed to refine instructions by employing a suggester-editor pair to enhance complexity and creativity. This iterative process builds upon the instructions generated by the Seed Instruction Generation Flow, aiming to improve both the quality and intricacy of the instructions. The refinement involves suggester-editor agents who modify passage-question pairs to create more complex or unanswerable questions, or alter answers to increase their difficulty. Through these modifications, the Instruction Refinement Flow ensures that the instructions become progressively more challenging and sophisticated.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SUGGESTER-EDITOR AGENTS">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">Suggester-Editor Agents are integral components of the Instruction Refinement Flow, where they play a crucial role in enhancing the intricacy and quality of instructions. These agents are specifically tasked with proposing and modifying instructions, as well as refining passage and question pairs. Their functions include adding complexity, introducing distractors, and altering answers to ensure a more robust and challenging instructional framework.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="QUESTION ANSWERING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Question answering involves generating responses to questions over a wide range of topics, without being restricted to a specific domain. It is an application of reading comprehension that involves providing answers to questions based on a given text. This process requires the system to understand and interpret the text to extract relevant information and formulate accurate responses.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="RETRIEVAL AUGMENTED GENERATION">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Retrieval Augmented Generation (RAG) is a method used in natural language processing that combines retrieval-based and generative models to generate responses. It operates by first retrieving relevant documents and then utilizing these documents to generate a response. This approach leverages the strengths of both retrieval-based methods, which excel at finding pertinent information, and generative models, which are adept at creating coherent and contextually appropriate content. By integrating these two methodologies, RAG enhances the quality and relevance of the generated responses or content, making it a powerful tool in the field of natural language processing.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TOOL/API USE">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Tool/API use involves employing functions or APIs to perform tasks or solve problems.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="WEB CONTROL">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Web control involves autonomously performing tasks on the web, such as clicking and scrolling.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT MODIFICATION">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Text modification involves changing existing text to improve its quality, modify its tone, or fit a specific context or audience. It is the process of editing and refining written content to enhance its quality and effectiveness. This involves tasks such as correcting spelling and grammar, clarifying ideas, and adjusting tone.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="WEB AGENT">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">A web agent is a software program that autonomously performs tasks on the web, such as where to click and how much to scroll.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="BRAIN TEASER">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">A brain teaser is a problem or puzzle requiring thought to solve, often used for amusement or training logical thinking and problem-solving skills.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ANALYTICAL REASONING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Analytical reasoning involves the ability to look at information, discern patterns, and draw logical conclusions about relationships within the information.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MULTIPLE CHOICE QUESTIONS">
      <data key="d0">TASK, ASSESSMENT</data>
      <data key="d1">MULTIPLE CHOICE QUESTIONS are a form of assessment where respondents select the best possible answer from a list of choices. In tasks where models are evaluated in an open-ended generation setting, GPT-4 is utilized for extracting the option selected by the model from its response.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="DATA TO TEXT">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Data-to-text refers to generating human-readable textual summaries from source data, used for reports, explanations, or narratives.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="FERMI PROBLEMS">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">FERMI PROBLEMS are estimation problems that seek quick, rough estimates of quantities, often requiring justified guesses or assumptions. Named after physicist Enrico Fermi, these problems are designed to provide rapid approximations for quantities that can be difficult to measure directly. The approach involves making educated guesses or assumptions to arrive at a solution, reflecting Fermi's ability to make good approximate calculations with limited data.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT EXTRACTION">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">TEXT EXTRACTION is the process of retrieving relevant information from a larger text document. This can include tasks such as named entity recognition, keyword extraction, and extracting specific data fields from unstructured text. The primary goal of text extraction is to identify and isolate pertinent information within a vast amount of textual data, making it easier to analyze and utilize.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="RAW ARTICLES">
      <data key="d0">DATA SOURCE, CONTENT</data>
      <data key="d1">Raw articles are used as seeds in the agentic flows to foster diversity and ensure broad coverage in generated problems.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SOURCE CODE FILES">
      <data key="d0">DATA SOURCE, CONTENT</data>
      <data key="d1">Source code files are used as seeds in the agentic flows to foster diversity and ensure broad coverage in generated problems.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INTERMEDIATE REPRESENTATION">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">Intermediate representation is the transformed content produced by the Content Transformation Flow to simplify the creation of instructions.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ARGUMENT PASSAGE">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">An argument passage is a type of transformed content used in the Content Transformation Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MEETING TRANSCRIPT">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">A meeting transcript is a type of transformed content used in the Content Transformation Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="LIST OF APIS">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">A list of APIs is a type of transformed content used in the Content Transformation Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTIONS">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">Seed instructions are generated from transformed content in the Seed Instruction Generation Flow to introduce diversity.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SUGGESTER AGENTS">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">Suggester agents propose various approaches to increase the intricacy of initial instructions in the Instruction Refinement Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="EDITOR AGENTS">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">Editor agents modify instructions based on suggestions from suggester agents in the Instruction Refinement Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CODE INTERPRETER">
      <data key="d0">TOOL, TECHNOLOGY</data>
      <data key="d1">A code interpreter is a tool that agents can use to execute and debug code.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="READING COMPREHENSION TESTS">
      <data key="d0">ASSESSMENT, TASK</data>
      <data key="d1">Reading comprehension tests present text passages followed by questions to assess the reader&#8217;s understanding.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Open Domain Question Answering is a method used to generate responses to questions over a wide range of topics without being restricted to a specific domain. Additionally, it is employed to generate math problems for evaluating AI models. This approach ensures that AI systems are tested on their ability to handle diverse and unrestricted queries, thereby assessing their comprehensive understanding and adaptability across various subjects.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT PASSAGES">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">Text passages are used in reading comprehension tests to assess understanding.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">Text is the primary content used in reading comprehension, text modification, and text extraction tasks.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TASKS">
      <data key="d0">CATEGORY, ATTRIBUTE</data>
      <data key="d1">Tasks are specific activities or assessments within the workflows, such as question answering, text modification, and multiple choice questions.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT CLASSIFICATION">
      <data key="d0">PROCESS, TASK</data>
      <data key="d1">Text classification is a type of machine learning task where text documents are automatically classified into predefined categories. This can be used for spam detection, sentiment analysis, and topic labeling among others.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CREATIVE CONTENT GENERATION">
      <data key="d0">ACTIVITY, SKILL</data>
      <data key="d1">Creative content generation involves the creation of original content, often involving elements of novelty, value, and surprise. In AI, this could refer to generating text, music, or images that are not only new but also meaningful and interesting.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FEW SHOT REASONING">
      <data key="d0">CONCEPT, SKILL</data>
      <data key="d1">Few-shot reasoning refers to the ability of a machine learning model to understand new concepts, patterns, or tasks with minimal examples or guidance. It&#8217;s a desired trait in AI, mimicking the human ability to learn quickly from few examples.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CONVERSATION">
      <data key="d0">ACTIVITY, SKILL</data>
      <data key="d1">Conversation refers to conversational agents or chatbots that interact with humans in a natural, human-like manner.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="AGENTINSTRUCT FLOW">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">AgentInstruct Flow is a method implemented for various capabilities, including reading comprehension, to guide AI systems in performing specific tasks.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="ARGUMENT PASSAGE GENERATOR">
      <data key="d0">TOOL, AGENT</data>
      <data key="d1">The "ARGUMENT PASSAGE GENERATOR" is an agent proficient in crafting passages that articulate arguments, although these passages may sometimes exhibit logical inconsistencies. This content transformation agent specializes in generating argument passages from seed articles, thereby aiding in the creation of reading comprehension materials.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="URIC ACID">
      <data key="d0">SUBSTANCE, BIOLOGICAL CONCEPT</data>
      <data key="d1">Uric acid is a chemical found in red meat and seafood, and its levels in the body can be influenced by lifestyle choices such as alcohol consumption and physical inactivity. It is a substance produced naturally by the breakdown of purine. High levels of uric acid are associated with an increased risk of cardiovascular disease and can lead to health complications such as hyperuricemia. Conversely, low levels of uric acid can indicate underlying kidney or liver issues.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPERURICEMIA">
      <data key="d0">CONDITION, MEDICAL TERM</data>
      <data key="d1">Hyperuricemia is a condition characterized by high levels of uric acid in the blood, typically defined as levels above 6 mg/dL in women and 7 mg/dL in men. It can result from increased production of uric acid or insufficient elimination through urine. Additionally, hyperuricemia is associated with an increased risk of cardiovascular disease.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPOURICEMIA">
      <data key="d0">CONDITION, MEDICAL TERM</data>
      <data key="d1">Hypouricemia is a condition characterized by low levels of uric acid in the blood. It is less common and usually does not present symptoms. However, the presence of hypouricemia can indicate underlying kidney or liver issues.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PURINE">
      <data key="d0">SUBSTANCE, BIOLOGICAL CONCEPT</data>
      <data key="d1">Purine is a type of dietary protein that, when broken down by digestion, produces uric acid. It is naturally produced in the body.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="ENRICO FERMI">
      <data key="d0" />
      <data key="d1">Enrico Fermi was a physicist after whom Fermi problems are named.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PERSON, PHYSICIST</data>
    </node>
    <node id="NAMED ENTITY RECOGNITION">
      <data key="d0">TASK, PROCESS</data>
      <data key="d1">Named entity recognition is a task in text extraction that involves identifying and classifying entities in text into predefined categories such as names of persons, organizations, locations, etc.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="KEYWORD EXTRACTION">
      <data key="d0">TASK, PROCESS</data>
      <data key="d1">Keyword extraction is a task in text extraction that involves identifying and extracting important words or phrases from a text document.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="SPAM DETECTION">
      <data key="d0">APPLICATION, TASK</data>
      <data key="d1">Spam detection is an application of text classification where text documents, such as emails, are automatically classified as spam or not spam.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="SENTIMENT ANALYSIS">
      <data key="d0">APPLICATION, TASK</data>
      <data key="d1">Sentiment analysis is an application of text classification that involves determining the sentiment expressed in a text document, such as positive, negative, or neutral.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="TOPIC LABELING">
      <data key="d0">APPLICATION, TASK</data>
      <data key="d1">Topic labeling is an application of text classification where text documents are automatically classified into predefined topics or categories.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="GROUNDED REASONING">
      <data key="d0">APPLICATION, TASK</data>
      <data key="d1">Grounded reasoning is an application of reading comprehension that involves making inferences and drawing conclusions based on a given text.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="LSAT LOGICAL REASONING TEST">
      <data key="d0">TEST, EXAM</data>
      <data key="d1">The LSAT Logical Reasoning test features specialized question categories, including assumption, strengthening/weakening, flaw, and inference questions.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="ASSUMPTION QUESTIONS">
      <data key="d0">QUESTION TYPE, CATEGORY</data>
      <data key="d1">Assumption questions are a type of question in the LSAT Logical Reasoning test that require identifying assumptions made in an argument.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="STRENGTHENING/WEAKENING QUESTIONS">
      <data key="d0">QUESTION TYPE, CATEGORY</data>
      <data key="d1">Strengthening/weakening questions are a type of question in the LSAT Logical Reasoning test that require identifying how an argument can be strengthened or weakened.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FLAW QUESTIONS">
      <data key="d0">QUESTION TYPE, CATEGORY</data>
      <data key="d1">Flaw questions are a type of question in the LSAT Logical Reasoning test that require identifying flaws in an argument.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="INFERENCE QUESTIONS">
      <data key="d0">QUESTION TYPE, CATEGORY</data>
      <data key="d1">Inference questions are a type of question in the LSAT Logical Reasoning test that require making inferences based on the given information.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="LABORATORY BLOOD TESTS">
      <data key="d0">TEST, MEDICAL PROCEDURE</data>
      <data key="d1">Laboratory blood tests are used to diagnose conditions like hyperuricemia and hypouricemia by measuring levels of substances such as uric acid in the blood.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="LABORATORY URINE TESTS">
      <data key="d0">TEST, MEDICAL PROCEDURE</data>
      <data key="d1">Laboratory urine tests are used to diagnose conditions like hyperuricemia and hypouricemia by measuring levels of substances such as uric acid in the urine.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CARDIOVASCULAR DISEASE">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Cardiovascular disease refers to a class of diseases that involve the heart or blood vessels, and high levels of uric acid are associated with an increased risk of developing these diseases.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LABORATORY BLOOD AND URINE TESTS">
      <data key="d0">DIAGNOSTIC METHOD</data>
      <data key="d1">Laboratory blood and urine tests are used to diagnose conditions related to abnormal uric acid levels, such as hyperuricemia and hypouricemia.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="READING COMPREHENSION QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Reading comprehension questions are designed to assess understanding of a text and can include types such as literal comprehension, critical comprehension, evaluative comprehension, reasoning, and identifying assumptions.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="AGENTS">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">Agents are defined to target specific categories of reading comprehension questions, generating questions based on a piece of text and a predefined question type.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CONTENT TRANSFORMATION AGENT">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">The CONTENT TRANSFORMATION AGENT is an integral component used to synthesize an API description from a source code snippet as part of the content transformation flow. Additionally, this agent plays a crucial role in determining which subset of agents to engage in the Seed Instruction Generation Flow process, thereby ensuring the efficient and accurate transformation of content within the system.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="PASSAGE, QUESTION PAIRS">
      <data key="d0">DATA OUTPUT</data>
      <data key="d1">Passage, question pairs are the output of the Seed Instruction Generation Flow, consisting of a text passage and associated questions generated by the agents.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="TEXT MODIFICATION TASKS">
      <data key="d0">TASK TYPE</data>
      <data key="d1">Text modification tasks include paraphrasing, expansion, simplification, redacting or removing content, styling, and code switching, among others.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PARAPHRASING AGENT">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">The Paraphrasing Agent is designed to create text modification tasks that involve rephrasing a given piece of text while retaining its original meaning.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="ALCOHOL CONSUMPTION">
      <data key="d0">LIFESTYLE CHOICE</data>
      <data key="d1">Alcohol consumption is a lifestyle choice that can influence uric acid levels in the body.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PHYSICAL INACTIVITY">
      <data key="d0">LIFESTYLE CHOICE</data>
      <data key="d1">Physical inactivity is a lifestyle choice that can influence uric acid levels in the body.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="KIDNEY ISSUES">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Kidney issues can be indicated by low levels of uric acid in the blood, known as hypouricemia.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LIVER ISSUES">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Liver issues can be indicated by low levels of uric acid in the blood, known as hypouricemia.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LITERAL COMPREHENSION QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Literal comprehension questions assess the ability to understand and recall factual information from a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CRITICAL COMPREHENSION QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Critical comprehension questions assess the ability to analyze and evaluate the information presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="EVALUATIVE COMPREHENSION QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Evaluative comprehension questions assess the ability to make judgments about the information presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="REASONING QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Reasoning questions assess the ability to draw inferences and conclusions based on the information presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="IDENTIFYING ASSUMPTIONS QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Identifying assumptions questions assess the ability to recognize underlying assumptions in the information presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="IDENTIFYING INFORMATION THAT STRENGTHENS/WEAKENS AN ARGUMENT QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">These questions assess the ability to identify information that either strengthens or weakens an argument presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="ORDERING EVENTS QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Ordering events questions assess the ability to sequence events in the order they occurred based on the information presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="APPENDIX A">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Appendix A contains a list of reading comprehension question types and text modification tasks.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="STRENGTHEN TYPE QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Strengthen type questions assess the ability to identify information that supports an argument presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="SUGGESTION 1">
      <data key="d0">SUGGESTION</data>
      <data key="d1">"SUGGESTION 1" is a proposal that aims to enhance engagement and effectiveness by incorporating a fictional narrative, utilizing a conversational style with colloquial language, and infusing a humorous element. Additionally, it involves introducing a hypothetical study or finding that could potentially strengthen an argument. This requires the test-taker to infer its impact on the relationship between uric acid levels and cardiovascular disease, thereby deepening their understanding and analysis of the topic.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTION 2">
      <data key="d0">SUGGESTION</data>
      <data key="d1">"SUGGESTION 2" encompasses two distinct ideas. The first aspect of Suggestion 2 proposes translating event details into a poetic format, maintaining accurate information while using rhyming couplets to ensure a light and engaging tone. The second aspect introduces a layer of complexity by suggesting a genetic predisposition to hyperuricemia and its correlation with increased cardiovascular events, requiring the test-taker to consider both genetic and physiological factors. Together, these elements highlight the multifaceted nature of Suggestion 2, blending creative expression with scientific analysis.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTION 3">
      <data key="d0">SUGGESTION</data>
      <data key="d1">"SUGGESTION 3" encompasses two distinct ideas. Firstly, it proposes framing event details as a social media post, utilizing internet slang and emojis, and ensuring the message is concise, within 280 characters. Secondly, it involves incorporating a distractor option in a test scenario that appears to bolster the argument but does not directly pertain to the causal relationship between uric acid levels and cardiovascular disease. This tests the test-taker&#8217;s ability to differentiate between relevant and irrelevant information.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="MODIFICATION 1">
      <data key="d0">MODIFICATION</data>
      <data key="d1">Modification 1 involves altering the passage to make the question unanswerable.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="MODIFICATION 2">
      <data key="d0">MODIFICATION</data>
      <data key="d1">Modification 2 involves altering the passage to change the answer in the opposite direction.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="MODIFICATION 3">
      <data key="d0">MODIFICATION</data>
      <data key="d1">Modification 3 involves altering the questions or answer choices to make them more complex.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="TEXT MODIFICATION AGENTS">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">Text modification agents are defined to create text modification tasks such as paraphrasing, expansion, simplification, redacting or removing content, styling, and code switching.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PARAPHRASING">
      <data key="d0">TEXT MODIFICATION TASK</data>
      <data key="d1">PARAPHRASING is a text modification task that involves rephrasing a given piece of text while retaining its original meaning. It entails rewriting text using different words and sentence structures, ensuring that the original meaning is preserved.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SIMPLIFICATION">
      <data key="d0">TEXT MODIFICATION TASK</data>
      <data key="d1">Simplification is a text modification task that involves making a given piece of text easier to understand.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="REDACTING OR REMOVING CONTENT">
      <data key="d0">TEXT MODIFICATION TASK</data>
      <data key="d1">Redacting or removing content is a text modification task that involves deleting or obscuring parts of a given piece of text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="STYLING">
      <data key="d0">TEXT MODIFICATION TASK</data>
      <data key="d1">Styling is a text modification task that involves changing the appearance or format of a given piece of text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CODE SWITCHING">
      <data key="d0">TEXT MODIFICATION TASK</data>
      <data key="d1">Code Switching involves alternating between languages or dialects within a text, often to reflect bilingual speakers&#8217; patterns or for creative writing. It is a text modification task that requires the seamless integration of different languages or dialects within a given piece of text, showcasing the dynamic and fluid nature of bilingual communication.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="FINANCIALIZATION">
      <data key="d0">CONCEPT, ECONOMIC THEORY</data>
      <data key="d1">A broad concept that describes the increasing social impact and interconnection of financial discourses, markets, actors, and institutions.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="NATASCHA VAN DER ZWAN">
      <data key="d0">RESEARCHER, AUTHOR</data>
      <data key="d1">A researcher who identifies three distinct research streams that approach financialization from different perspectives.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="AMERICAN ANTHROPOLOGICAL ASSOCIATION">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">An organization that hosts events and conferences, such as the SEA 2017 Annual Meeting.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SEA 2017 ANNUAL MEETING">
      <data key="d0">EVENT, CONFERENCE</data>
      <data key="d1">An annual meeting held by the American Anthropological Association from April 6-8, 2017, at the University of Iowa, Iowa City, USA.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTER-EDITOR PAIR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">A duo that increases the complexity of generated instructions by providing suggestions and edits based on input text and task modification instructions.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="API RETRIEVAL AGENT">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that iteratively searches for similar code to expand an API list during the content transformation flow.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="LIBRARY RECONSTRUCTION">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">A scenario within the content transformation flow where a list of APIs is synthesized from a random seed.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="VIEW ALL FOOD ITEMS">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">An API that enables clients to obtain a detailed list of food items, complete with nutritional profiles.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SEARCH FOOD ITEMS">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">"SEARCH FOOD ITEMS" is an API that allows clients to search for food items by name and retrieve a list of matching items. It requires a query parameter to specify the search term and optionally includes a limit parameter to restrict the number of results returned. This functionality enables users to efficiently find specific food items within a database, enhancing the user experience by providing relevant search results based on the input criteria.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="APRIL 6-8, 2017">
      <data key="d0">DATE, EVENT DATE</data>
      <data key="d1">The dates on which the SEA 2017 Annual Meeting took place at the University of Iowa.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="DECEMBER 1, 2016">
      <data key="d0">DATE, DEADLINE</data>
      <data key="d1">The deadline for submitting abstracts for the SEA 2017 Annual Meeting.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="FINANCE">
      <data key="d0">CONCEPT, ECONOMIC THEORY</data>
      <data key="d1">A broad concept that is hard to escape and has increasing social impact and interconnection with financial discourses, markets, actors, and institutions.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="RANDOM SEED">
      <data key="d0">CONCEPT, INPUT</data>
      <data key="d1">A randomly chosen input used to create a seed (text, text modification instruction) pair for various tasks.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="TASK MODIFICATION INSTRUCTION">
      <data key="d0">INSTRUCTION, METHOD</data>
      <data key="d1">Instructions provided to modify a given task, used in conjunction with input text in the Instruction Refinement Flow.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="INSTRUCTION 1">
      <data key="d0">INSTRUCTION, METHOD</data>
      <data key="d1">An instruction to rewrite event details as if telling a funny story to a friend, using casual and colloquial language, while incorporating a fictional narrative that conveys necessary information.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="INSTRUCTION 2">
      <data key="d0">INSTRUCTION, METHOD</data>
      <data key="d1">An instruction to transform event details into a light-hearted poem with rhyming couplets, ensuring essential information is accurately conveyed in a poetic format.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="INSTRUCTION 3">
      <data key="d0">INSTRUCTION, METHOD</data>
      <data key="d1">An instruction to craft a social media post that includes event details using internet slang, emojis, and a casual tone, while keeping the message concise and within 280 characters.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="API DESCRIPTION">
      <data key="d0">DOCUMENT, DESCRIPTION</data>
      <data key="d1">A description synthesized from a source code snippet by a content transformation agent, detailing the functionality and parameters of an API.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="CALORIE COUNT">
      <data key="d0">ATTRIBUTE, NUTRITION</data>
      <data key="d1">A nutritional profile attribute that indicates the number of calories in a food item.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="PROTEIN">
      <data key="d0">ATTRIBUTE, NUTRITION</data>
      <data key="d1">A nutritional profile attribute that indicates the amount of protein in a food item.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="FAT">
      <data key="d0">ATTRIBUTE, NUTRITION</data>
      <data key="d1">A nutritional profile attribute that indicates the amount of fat in a food item.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="GET FOOD ITEM DETAILS">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Provides detailed information about a specific food item. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="CREATE MEAL PLAN">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Enables the creation of a meal plan based on user preferences and goals. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="UPDATE FOOD ITEM">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Allows updating the details of an existing food item. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="TRACK USER MEAL">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Enables tracking of user meals. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET DIETARY RECOMMENDATIONS">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Provides dietary recommendations based on user preferences and goals. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="ADD NEW FOOD ITEM">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Allows adding a new food item to the database. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="DELETE FOOD ITEM">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Enables the deletion of a food item from the database. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET USER NUTRITIONAL STATS">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Provides nutritional statistics for the user. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="SEED INSTRUCTION CREATION FLOW">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">A process that consumes a list of APIs and employs various agents to create several types of tasks, including those requiring single or multiple APIs, with or without all necessary parameters.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="REFINEMENT FLOW">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">A process aimed at increasing the complexity of tasks by suggesting refinements to increase the number of steps required to solve the task.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="AGENT-INSTRUCT FLOW">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">A process that creates multi-turn conversations and instructions for an AI assistant to help users achieve their desired outcomes using various APIs.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="ASSISTANT">
      <data key="d0">ACTOR, PARTICIPANT</data>
      <data key="d1">The AI assistant that helps the user achieve their desired outcomes by utilizing various APIs and following structured processes.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="QUINOA SALAD">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">The "QUINOA SALAD" is a recipe for a vegetarian dish that the user wants to add to the database. This salad is made from quinoa, highlighting its nutritious and health-conscious ingredients. The user aims to enrich the database with this wholesome and versatile recipe, catering to those seeking vegetarian meal options.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CHANA MASALA">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">CHANA MASALA is a spicy chickpea dish that the user wants to update in the database. The user believes that the current calorie count for this food item is incorrect and seeks to correct it.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="BUTTER CHICKEN">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">BUTTER CHICKEN is a popular Indian dish made with chicken in a spiced tomato, butter, and cream sauce. Despite its popularity and rich flavor profile, the user wants to remove this food item from the database.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="VEGETARIAN MEAL PLAN">
      <data key="d0">MEAL PLAN, DIETARY PLAN</data>
      <data key="d1">A meal plan designed for vegetarians with a caloric goal of 1500 calories per day, consisting of three meals a day.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CALORIC GOAL">
      <data key="d0">NUTRITIONAL TARGET, DIETARY GOAL</data>
      <data key="d1">A target of 1500 calories per day set for the meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="OATMEAL WITH FRUITS">
      <data key="d0">FOOD ITEM, BREAKFAST</data>
      <data key="d1">A breakfast food item consisting of oatmeal mixed with fruits, included in the vegetarian meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ALMOND MILK">
      <data key="d0">FOOD ITEM, BEVERAGE</data>
      <data key="d1">A dairy-free milk alternative made from almonds, included in the vegetarian meal plan for breakfast.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CHICKPEA SALAD">
      <data key="d0">FOOD ITEM, LUNCH</data>
      <data key="d1">A lunch food item consisting of a salad made from chickpeas, included in the vegetarian meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="WHOLE WHEAT BREAD">
      <data key="d0">FOOD ITEM, LUNCH</data>
      <data key="d1">A type of bread made from whole wheat, included in the vegetarian meal plan for lunch.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MIXED VEGETABLE STIR FRY">
      <data key="d0">FOOD ITEM, DINNER</data>
      <data key="d1">A dinner food item consisting of various vegetables stir-fried together, included in the vegetarian meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="BROWN RICE">
      <data key="d0">FOOD ITEM, DINNER</data>
      <data key="d1">A type of rice that is less processed than white rice, included in the vegetarian meal plan for dinner.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="FOOD_ID">
      <data key="d0">IDENTIFIER, DATABASE ATTRIBUTE</data>
      <data key="d1">A unique identifier used to update or remove food items in the database.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-2.5">
      <data key="d0">MODEL, MACHINE LEARNING</data>
      <data key="d1">ORCA-2.5 is a baseline machine learning model evaluated using the Orca-Bench dataset, achieving an average score of 7.13 out of 10. It was trained using 3.8 million paired instructions and is used to compare and evaluate the impact of the larger AgentInstruct dataset. As a previous version of the Orca language model, ORCA-2.5 serves as a benchmark for performance improvements, particularly in comparison with the newer Orca-3-7B model.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MISTRAL-7B-V0.1">
      <data key="d0">MODEL, MACHINE LEARNING</data>
      <data key="d1">A base model with publicly available weights, used as the foundation for finetuning with the AgentInstruct dataset to create Orca-3.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="NVIDIA A100">
      <data key="d0">HARDWARE, GPU</data>
      <data key="d1">A type of GPU used in the training process of the Orca-3 model, with 152 GPUs used in total.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ADAMW OPTIMIZER">
      <data key="d0">OPTIMIZER, MACHINE LEARNING</data>
      <data key="d1">An optimization algorithm used in the training of the Orca-3 model, with an initial learning rate of 8e-6.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-BENCH">
      <data key="d0">DATASET, EVALUATION</data>
      <data key="d1">ORCA-BENCH is a dataset used to evaluate the performance of various models, scored relative to GPT-4 on a scale from 0 to 10. It includes multi-turn interactions and is used to generate student responses conditioned on preceding conversation history. Additionally, ORCA-BENCH features a held-out test set consisting of 100 samples from each of the 17 skills curated using AgentInstruct, which is utilized to assess the performance of machine learning models.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ODQA">
      <data key="d0">TASK, QUESTION ANSWERING</data>
      <data key="d1">Open Domain Question Answering, a category in the Orca-Bench dataset with two subsets: ODQA and Complex ODQA.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="COMPLEX ODQA">
      <data key="d0">TASK, QUESTION ANSWERING</data>
      <data key="d1">COMPLEX ODQA is a subset of the ODQA category within the Orca-Bench dataset. This subset includes more intricate questions that were developed during the refinement phase, highlighting its focus on complexity and depth in question formulation.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="DAY 1">
      <data key="d0">MEAL PLAN, DIETARY PLAN</data>
      <data key="d1">The first day of the vegetarian meal plan, including specific meals and their caloric content.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 2">
      <data key="d0">MEAL PLAN, DIETARY PLAN</data>
      <data key="d1">The second day of the vegetarian meal plan, including specific meals and their caloric content.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MEAL PLAN DATABASE">
      <data key="d0">DATABASE, REPOSITORY</data>
      <data key="d1">A database where meal plans and recipes are stored and managed.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="NUTRITIONAL INFORMATION">
      <data key="d0">DATA, NUTRITION</data>
      <data key="d1">Information about the nutritional content of food items, required to add new recipes to the database.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-1">
      <data key="d0">MODEL, MACHINE LEARNING</data>
      <data key="d1">A previous version of the Orca model, which contributed to the 3.8 million paired instructions used in Orca-2.5.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-2">
      <data key="d0">MODEL, MACHINE LEARNING</data>
      <data key="d1">A previous version of the Orca model, which contributed to the 3.8 million paired instructions used in Orca-2.5.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-MATH">
      <data key="d0">MODEL, MACHINE LEARNING</data>
      <data key="d1">ORCA-MATH is a specialized version of the Orca model that focuses on mathematical instructions. It plays a significant role in contributing to the 3.8 million paired instructions utilized in Orca-2.5. Published in 2024, the ORCA-MATH project aims to unlock the potential of small language models in grade school math, enhancing their ability to understand and generate mathematical content effectively.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KNOWLEDGEPILE">
      <data key="d0">DATASET, TRAINING DATA</data>
      <data key="d1">A dataset used as a source for unstructured text and code files in the AgentInstruct dataset.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="AUTOMATHTEXT">
      <data key="d0">DATASET, TRAINING DATA</data>
      <data key="d1">AUTOMATHTEXT is a dataset utilized as a source for unstructured text and code files in the AgentInstruct dataset. It is also the subject of a paper titled "Automathtext: Autonomous data selection with language models for mathematical texts," published in 2024. This paper explores the application of language models for the autonomous selection of data within the realm of mathematical texts, highlighting the innovative use of AI in processing and curating mathematical information.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="OPENSTAX">
      <data key="d0">DATASET, TRAINING DATA</data>
      <data key="d1">A subset of educational content used as a source for unstructured text in the AgentInstruct dataset.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="APACHE-2.0 LICENSED SOURCE CODE">
      <data key="d0">DATASET, TRAINING DATA</data>
      <data key="d1">A subset of source code files licensed under Apache-2.0, used in the AgentInstruct dataset.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MISTRAL TOKENIZER">
      <data key="d0">TOOL, TOKENIZER</data>
      <data key="d1">A tokenizer used to process the dataset for training the Orca-3 model, ensuring a maximum sequence length of 8192 with packing.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="WEIGHT DECAY">
      <data key="d0">HYPERPARAMETER, MACHINE LEARNING</data>
      <data key="d1">A regularization technique used in the training of the Orca-3 model, set at 0.1.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="COSINE LEARNING RATE SCHEDULE">
      <data key="d0">HYPERPARAMETER, MACHINE LEARNING</data>
      <data key="d1">A learning rate schedule used in the training of the Orca-3 model, featuring a cosine decay pattern.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="LINEAR LEARNING RATE WARM-UP">
      <data key="d0">HYPERPARAMETER, MACHINE LEARNING</data>
      <data key="d1">A technique used during the initial 500 steps of training the Orca-3 model to gradually increase the learning rate.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="EPOCH">
      <data key="d0">TRAINING ITERATION, MACHINE LEARNING</data>
      <data key="d1">A complete pass through the training dataset, with the Orca-3 model trained for three epochs.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="TRAINING LOSS">
      <data key="d0">METRIC, MACHINE LEARNING</data>
      <data key="d1">A measure of the error during the training process, calculated based on the response conditioned on the prompt.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="RESPONSE">
      <data key="d0">OUTPUT, MACHINE LEARNING</data>
      <data key="d1">The output generated by the model in response to the prompt during training.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MULTI-TURN INTERACTION">
      <data key="d0">INTERACTION, MACHINE LEARNING</data>
      <data key="d1">MULTI-TURN INTERACTION in the Orca-Bench dataset refers to a sequence of exchanges that involve system messages, user inputs, and assistant responses. This type of interaction is characterized by multiple exchanges between the user and the model, facilitating a dynamic and iterative communication process.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="CHATGPT">
      <data key="d0">MODEL, BASELINE</data>
      <data key="d1">A baseline model evaluated using the Orca-Bench dataset, with an average score of 8.13 out of 10.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="LLAMA3-8B-INSTRUCT">
      <data key="d0">MODEL, BASELINE</data>
      <data key="d1">LLAMA3-8B-INSTRUCT is a language model primarily used as a baseline for comparison with the Orca-3-7B model. It has been evaluated using the Orca-Bench dataset and other benchmarks, providing a standard against which the performance and capabilities of other models, such as Orca-3-7B, can be measured.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="FOFO">
      <data key="d0">BENCHMARK</data>
      <data key="d1">FOFO is a benchmark designed to evaluate the format-following capabilities of large language models (LLMs) in real-world scenarios. It assesses a model&#8217;s ability to adhere to complex, domain-specific formats across various domains such as Healthcare, Finance, and Marketing. The benchmark is particularly focused on open-ended generation tasks, using GPT-4 (version 0613) as a judge to provide a format correctness score ranging from 0 to 1. A notable study titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024, discusses the intricacies of this benchmark. In practical evaluations, the model Orca-3 scored 84.01 on FOFO, marking a 12% improvement over its predecessor, Orca-2.5.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="IFEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">IFEVAL, or Instruction-Following Evaluation, is a benchmark designed to measure a model's ability to follow natural language instructions. It uses a set of 500 prompts covering 25 types of verifiable instructions to evaluate whether the model's response adheres to the given instructions. The benchmark employs code provided by the authors to ensure the verifiability of the instructions. Notably, Orca-3 scored 49.54 on IFEVAL, marking a 2% improvement over the previous version, Orca-2.5.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="INFOBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">INFOBENCH is a benchmarking tool published in 2024, designed to evaluate the instruction-following capability of large language models. It uses a metric called Decomposed Requirements Following Ratio (DRFR), which breaks complex instructions into simpler criteria to assess model performance. INFOBENCH has been used to evaluate models such as Orca-3, which scored 84.30, marking a 4% improvement over Orca-2.5. The benchmark employs GPT-4 (version 1106-preview) to determine if the model responses adhere to the decomposed instructions, using the implementation provided by the creators.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="EQBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">EQBENCH is an Emotional Intelligence benchmark used for evaluating emotion scores in conversations. It assesses models' capabilities to comprehend intricate emotions and social interactions by providing a conversation between characters and then asking the model to predict the intensity of emotional states of those characters. The scores are generated using specific implementations described in the EQBench paper and repository. Notably, EQBench has been used to evaluate models, with Orca-3 scoring 91.36, which represents a 4% improvement over Orca-2.5.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="STUDENT RESPONSE">
      <data key="d0">OUTPUT, RESPONSE</data>
      <data key="d1">The "STUDENT RESPONSE" refers to the answer or response provided by a student to a given question. This response is parsed by the Evaluator Assistant to extract the selected option. Additionally, the "STUDENT RESPONSE" can also be a generated response by a student model, conditioned on the preceding conversation history established by the teacher model (GPT-4).</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,5819b66e04fd77fa705574edc49395bb,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="TEACHER RESPONSE">
      <data key="d0">OUTPUT, RESPONSE</data>
      <data key="d1">The original response generated by the teacher model (GPT-4) used as a benchmark to evaluate student responses.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="PERFORMANCE COMPARISON">
      <data key="d0">EVALUATION, ANALYSIS</data>
      <data key="d1">A comparative analysis of the performance of different models, depicted in Figure 4, showing the enhancement in capabilities during post-training enabled by AgentInstruct data.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ORCA-3 CHECKPOINTS">
      <data key="d0">MODEL, CHECKPOINT</data>
      <data key="d1">Different stages of the Orca-3 model evaluated at various checkpoints, showing improvement in scores from 9.35 to 9.55.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="TRAINING EPOCH">
      <data key="d0">PROCESS, STAGE</data>
      <data key="d1">A phase in the training process of models, with performance evaluated after each epoch.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MACRO SCORES">
      <data key="d0">METRIC, SCORE</data>
      <data key="d1">The average scores across all assessed dimensions, used to evaluate the performance of models like Orca-3.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="BENCHMARK RESULTS">
      <data key="d0">EVALUATION, RESULTS</data>
      <data key="d1">The results of evaluating Orca-3 against 5 baseline models on various benchmarks, showing performance scores.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MODEL PERFORMANCE">
      <data key="d0">EVALUATION, METRIC</data>
      <data key="d1">The performance scores of different models on the Orca-Bench dataset, ranging from 0 to 10, with GPT-4 scoring a perfect 10.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="DIMENSIONS">
      <data key="d0">METRIC, ASSESSMENT</data>
      <data key="d1">Various aspects or dimensions assessed to evaluate the performance of models like Orca-3.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="CAPABILITIES">
      <data key="d0">ATTRIBUTE, ABILITY</data>
      <data key="d1">The broad spectrum of abilities enhanced during post-training, as shown in the performance comparison of models.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">ATTRIBUTE, ABILITY</data>
    </node>
    <node id="USER INPUT">
      <data key="d0">INPUT, QUERY</data>
      <data key="d1">The input provided by the user in the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">INPUT, QUERY</data>
    </node>
    <node id="ASSISTANT RESPONSE">
      <data key="d0">OUTPUT, RESPONSE</data>
      <data key="d1">The response generated by the assistant in the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">OUTPUT, RESPONSE</data>
    </node>
    <node id="CONVERSATION HISTORY">
      <data key="d0">DATA, CONTEXT</data>
      <data key="d1">The preceding exchanges in a multi-turn interaction, used to condition the student response in the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">DATA, CONTEXT</data>
    </node>
    <node id="NORMALIZATION">
      <data key="d0">PROCESS, ADJUSTMENT</data>
      <data key="d1">The process of adjusting scores to a common scale, used to normalize the student's final score to a 0 to 10 scale.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">PROCESS, ADJUSTMENT</data>
    </node>
    <node id="CORPUS">
      <data key="d0">DATA, COLLECTION</data>
      <data key="d1">A large and diverse collection of data synthesized by AgentInstruct, used for training and evaluating models.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">DATA, COLLECTION</data>
    </node>
    <node id="DIFFICULTY">
      <data key="d0">ATTRIBUTE, LEVEL</data>
      <data key="d1">The varying degrees of challenge in the data synthesized by AgentInstruct, used to evaluate model performance.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">ATTRIBUTE, LEVEL</data>
    </node>
    <node id="INFERIORITY">
      <data key="d0">ATTRIBUTE, COMPARISON</data>
      <data key="d1">The relative lower performance of baseline models like Orca-2.5, Mistral-Instruct-7B, and ChatGPT compared to GPT-4.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">ATTRIBUTE, COMPARISON</data>
    </node>
    <node id="ENHANCEMENT">
      <data key="d0">PROCESS, IMPROVEMENT</data>
      <data key="d1">The improvement in model capabilities during post-training, enabled by AgentInstruct data.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">PROCESS, IMPROVEMENT</data>
    </node>
    <node id="METRIC-V2">
      <data key="d0">METRIC</data>
      <data key="d1">Metric-v2 is a performance metric used to evaluate models, showing a score of 91.36 with a 4% improvement.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="METRIC-V1">
      <data key="d0">METRIC</data>
      <data key="d1">Metric-v1 is a performance metric used to evaluate models, showing a score of 50.28 with a 28% improvement.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="MISTRAL-7B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-7B-Instruct is a 7B language model used as a baseline for performance comparisons with Orca-3 and other models. It serves as a reference point to evaluate relative improvements in various text-based tasks.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="LSAT">
      <data key="d0">EXAM</data>
      <data key="d1">The Law School Admission Test (LSAT) is a standardized test used for law school admissions. It is renowned for its challenging reading comprehension sections, which are considered difficult for both human test-takers and models. The LSAT plays a crucial role in evaluating the reading comprehension abilities of prospective law students, making it a significant component of the law school admissions process.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="ORCA 2.5">
      <data key="d0">MODEL, AI SYSTEM</data>
      <data key="d1">Orca 2.5 is a 7B model that serves as a predecessor to Orca-3, used for comparison in performance evaluations.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="GEMINI PRO">
      <data key="d0">MODEL, AI SYSTEM</data>
      <data key="d1">Gemini Pro is an AI model whose scores are referenced from its original paper. It serves as a baseline for evaluating the format-following capabilities of other models, such as Orca-3.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="MULTIPLE-CHOICE QUESTIONS FLOWS">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Multiple-Choice Questions Flows is a method used to generate math problems for evaluating AI models.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="PHI3">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">Phi3 is a research paper that reports accuracy scores for GPT-3.5-turbo on the GSM8K benchmark.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="ORCA-3-7B">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">ORCA-3-7B is a language model that has been evaluated on various benchmarks, demonstrating significant improvements over its predecessors, such as Orca 2.5 and Mistral-7B-Instruct. This model has been fine-tuned with AgentInstruct data, which has notably enhanced its performance in Retrieval-Augmented Generation (RAG) tasks on the MIRAGE datasets.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="FOFO BENCHMARK">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">FoFo is a benchmark used to evaluate the performance of language models, including Orca-3-7B.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="ACI-BENCH">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">The Ambient Clinical Intelligence Benchmark (ACI-BENCH) is a novel dataset designed for benchmarking automatic visit note generation from doctor-patient conversations. Discussed in a paper published in 2023, ACI-BENCH serves as a critical resource for evaluating the performance of algorithms in the domain of ambient clinical intelligence. This dataset aims to facilitate advancements in the automatic generation of clinical reports, thereby enhancing the efficiency and accuracy of documenting medical interactions.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="INSTRUSUM">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">InstruSum is a dataset for evaluating the generation capabilities of language models for instruction-controllable summarization.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="ORCA-SUM">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">Orca-Sum is a newly created benchmark to evaluate language models' ability to follow summarization and grounded data transformation instructions.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MIRAGE">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MIRAGE is a benchmark designed to address medical questions by leveraging information retrieved from a comprehensive medical corpus. It serves as a collection of datasets aimed at evaluating the performance of various models, with a particular focus on retrieval-augmented generation (RAG). This dual-purpose framework not only facilitates the answering of medical inquiries but also provides a robust platform for assessing the efficacy of different algorithmic approaches in the context of medical information retrieval and generation.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MMLU-MED">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MMLU-Med is a dataset used to evaluate the medical question-answering capabilities of language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MEDQA-US">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MedQA-US is a dataset used to evaluate the medical question-answering capabilities of language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MEDMCQA">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MedMCQA is a dataset used to evaluate the medical question-answering capabilities of language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="PUBMEDQA">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">PubMedQA is a dataset designed to evaluate the medical question-answering capabilities of language models. It is one of the datasets included in the MIRAGE benchmark, which is used to assess model performance, particularly focusing on the models' ability to perform Retrieval-Augmented Generation (RAG). This makes PubMedQA an essential tool for understanding and improving the effectiveness of language models in the medical domain.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="BIOASQ">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">BIOASQ is a dataset designed to evaluate the medical question-answering capabilities of language models. It is one of the datasets included in the MIRAGE benchmark, which is used to assess model performance. This inclusion highlights its significance in the broader context of evaluating and improving the accuracy and efficiency of language models in the medical domain.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="HALLUCINATION RATE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Hallucination rate is a metric used to measure the frequency of incorrect or fabricated information generated by a language model. Lower rates are better.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="QUALITY SCORE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Quality score is a metric used to measure the overall quality of responses generated by a language model. Higher scores are better.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="DATA TRANSFORMATION">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Data transformation involves converting data from one format or structure to another, often used in the context of evaluating language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="SUMMARIZATION">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Summarization is the process of condensing information into a shorter form while retaining key points, used to evaluate language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="HUGGING FACE">
      <data key="d0">PLATFORM, DATASET</data>
      <data key="d1">Hugging Face is a platform that hosts various datasets, including those used to create the Orca-Sum benchmark.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="GPT-4 (0613) COT">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">GPT-4 (0613) CoT is a variant of GPT-4 evaluated on medical question-answering datasets like MMLU-Med and MedQA-US.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="GPT-3.5-TURBO RAG">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">GPT-3.5-Turbo RAG is a variant of GPT-3.5-Turbo evaluated for its retrieval-augmented generation capabilities.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MEDMEDQA">
      <data key="d0">DATASET</data>
      <data key="d1">MedMedQA is one of the datasets included in the MIRAGE benchmark, used to evaluate model performance.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="USMEDMCQA">
      <data key="d0">DATASET</data>
      <data key="d1">USMedMCQA is one of the datasets included in the MIRAGE benchmark, used to evaluate model performance.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="ORCA-2.5-7B">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Orca-2.5-7B is a language model evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MISTRAL-7B-INSTRUCT-V0.1">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Mistral-7B-Instruct-v0.1 is a language model evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MEDRAG">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">MedRAG is the retrieval mechanism used across all models on the MIRAGE benchmark, involving the same retrieval function and number of retrieved documents.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="AZURE">
      <data key="d0">ORGANIZATION, PLATFORM</data>
      <data key="d1">Azure is a cloud computing service created by Microsoft that offers a wide range of services, including transparency notes and content moderation for large language models. These transparency notes are designed to help users understand the rationale behind specific outputs or decisions made by these models, ensuring a clearer and more accountable use of artificial intelligence. Azure's comprehensive platform supports various needs, making it a crucial tool for developers and organizations leveraging large language models.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LIMITATIONS">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Limitations refer to the constraints or challenges associated with a particular method, technology, or dataset, such as those mentioned for AgentInstruct and large language models.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="EXTENSIBILITY">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Extensibility is a limitation related to the human effort required to create agentic flows for different skills in synthetic data generation.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="BIAS">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Bias is a limitation where synthetic data may reflect and amplify biases present in the original seed data used for its generation.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="DEPENDENCY ON SEED DATA">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Dependency on Seed Data is a limitation where the quality of synthetic data is dependent on the quality of the real data used as seeds.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="DATA BIASES">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Data Biases are limitations where large language models may carry biases present in the source data, potentially leading to biased or unfair outputs.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="LACK OF TRANSPARENCY">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Lack of Transparency is a limitation where large language models act as "black boxes," making it difficult to understand the rationale behind specific outputs or decisions.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="CONTENT HARMS">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">CONTENT HARMS refer to the various types of negative impacts that large language models can cause, such as generating harmful or disinformation content. These limitations necessitate the use of content moderation services to mitigate the risks associated with the generation of harmful content. It is crucial to be aware of these risks and take proactive actions to prevent them, ensuring a safer and more responsible use of large language models.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="TRANSPARENCY NOTES">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">TRANSPARENCY NOTES are documents provided by platforms like Azure to offer more information about the transparency and functioning of large language models. These notes aim to provide a deeper understanding of the rationale behind specific outputs or decisions made by these models, ensuring users have a clear insight into how and why certain results are generated.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CONTENT MODERATION SERVICES">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Content Moderation Services are tools provided by various companies and institutions to prevent harmful content generated by large language models. These services are designed to help mitigate the risks and potential harms associated with the output of large language models, ensuring that the content remains safe and appropriate for users.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GOVERNMENT AND TECHNOLOGY LEADERS">
      <data key="d0">AUTHORITY, STAKEHOLDER</data>
      <data key="d1">Government and technology leaders are entities that can create regulations and standards to mitigate content harms associated with AI technologies.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RESEARCH AND OPEN SOURCE COMMUNITY">
      <data key="d0">COMMUNITY, STAKEHOLDER</data>
      <data key="d1">The research and open source community plays an important role in addressing content harms and improving AI technologies.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HALLUCINATION">
      <data key="d0">CONCEPT, RISK</data>
      <data key="d1">Hallucination refers to the phenomenon where language models fabricate content, making it unreliable for critical decisions or information. Smaller models may be more susceptible to hallucination due to reduced memorization capacities.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="POTENTIAL FOR MISUSE">
      <data key="d0">CONCEPT, RISK</data>
      <data key="d1">Potential for misuse refers to the risk that large language models could be used maliciously to generate disinformation or harmful content without suitable safeguards.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DATA DISTRIBUTION">
      <data key="d0">CONCEPT, FACTOR</data>
      <data key="d1">Data distribution refers to the correlation between a model's performance and the distribution of its tuning data, which can limit accuracy in underrepresented areas of the training dataset.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="25M PAIR DATASET">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">The 25M pair dataset is a large dataset generated by AgentInstruct, used for post-training the Orca-3 model, leading to notable performance gains.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="MARAH ABDIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marah Abdin is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SAM ADE JACOBS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sam Ade Jacobs is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMMAR AHMAD AWAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ammar Ahmad Awan is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JYOTI ANEJA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jyoti Aneja is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HANY AWADALLA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hany Awadalla is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NGUYEN BACH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nguyen Bach is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIT BAHREE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amit Bahree is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ARASH BAKHTIARI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arash Bakhtiari is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIANMIN BAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jianmin Bao is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HARKIRAT BEHL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Harkirat Behl is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ALON BENHAIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alon Benhaim is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MISHA BILENKO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Misha Bilenko is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JOHAN BJORCK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Johan Bjorck is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="S&#201;BASTIEN BUBECK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">S&#233;bastien Bubeck is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="QIN CAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qin Cai is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARTIN CAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Martin Cai is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CAIO C&#201;SAR TEODORO MENDES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Caio C&#233;sar Teodoro Mendes is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="VISHRAV CHAUDHARY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vishrav Chaudhary is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONG CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dong Chen is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONGDONG CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dongdong Chen is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YEN-CHUN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yen-Chun Chen is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YI-LING CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yi-Ling Chen is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PARUL CHOPRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Parul Chopra is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIYANG DAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiyang Dai is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ALLIE DEL GIORNO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Allie Del Giorno is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GUSTAVO DE ROSA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gustavo de Rosa is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MATTHEW DIXON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matthew Dixon is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RONEN ELDAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ronen Eldan is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="VICTOR FRAGOSO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Victor Fragoso is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DAN ITER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dan Iter is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MEI GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mei Gao is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MIN GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Min Gao is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIANFENG GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jianfeng Gao is a notable author in the field of artificial intelligence and natural language processing. In 2023, he contributed to a significant paper on instruction tuning with GPT-4, showcasing advancements in AI model training and optimization. Additionally, Jianfeng Gao is one of the authors of the Phi-3 technical report, further highlighting his involvement in cutting-edge research and development within the AI community. His work reflects a deep understanding of algorithmic structures and the intricate dynamics of AI systems.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIT GARG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amit Garg is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ABHISHEK GOSWAMI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Abhishek Goswami is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SURIYA GUNASEKAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Suriya Gunasekar is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="EMMAN HAIDER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Emman Haider is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JUNHENG HAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Junheng Hao is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RUSSELL J. HEWETT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Russell J. Hewett is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JAMIE HUYNH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jamie Huynh is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MOJAN JAVAHERIPI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mojan Javaheripi is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIN JIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xin Jin is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PIERO KAUFFMANN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Piero Kauffmann is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NIKOS KARAMPATZIAKIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nikos Karampatziakis is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONGWOO KIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dongwoo Kim is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MAHOUD KHADEMI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mahoud Khademi is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LEV KURILENKO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lev Kurilenko is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JAMES R. LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">James R. Lee is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YIN TAT LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yin Tat Lee is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YUANZHI LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuanzhi Li is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YUNSHENG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yunsheng Li is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHEN LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen Liang is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LARS LIDEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lars Liden is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MENGCHEN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mengchen Liu is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="WEISHUNG LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weishung Liu is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ERIC LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Lin is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHONG LUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chong Luo is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PIYUSH MADAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Piyush Madan is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MATT MAZZOLA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matt Mazzola is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HARDIK MODI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hardik Modi is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BRANDON NORICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brandon Norick is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BARUN PATRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Barun Patra is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DANIEL PEREZ-BECKER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daniel Perez-Becker is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="THOMAS PORTET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thomas Portet is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="REID PRYZANT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Reid Pryzant is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HEYANG QIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heyang Qin is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARKO RADMILAC">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marko Radmilac is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SAMBUDHA ROY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sambudha Roy is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OLATUNJI RUWASE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Olatunji Ruwase is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OLLI SAARIKIVI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Olli Saarikivi is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIN SAIED">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amin Saied is one of the authors of the Phi-3 technical report. Additionally, Amin Saied contributed to the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," which was published in 2023.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ADIL SALIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Adil Salim is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MICHAEL SANTACROCE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Santacroce is one of the authors of the Phi-3 technical report. Additionally, he co-authored the paper titled "Direct Nash Optimization: Teaching language models to self-improve with general preferences," which was published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SHITAL SHAH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shital Shah is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NING SHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ning Shang is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HITESHI SHARMA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hiteshi Sharma is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SWADHEEN SHUKLA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Swadheen Shukla is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIA SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xia Song is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MASAHIRO TANAKA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Masahiro Tanaka is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="REGULATIONS AND STANDARDS">
      <data key="d0">CONCEPT, POLICY</data>
      <data key="d1">Regulations and standards are guidelines and rules that government and technology leaders can establish to mitigate content harms associated with AI technologies.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MEMORIZATION CAPACITIES">
      <data key="d0">CONCEPT, ATTRIBUTE</data>
      <data key="d1">Memorization capacities refer to the ability of language models to remember and reproduce information, which can affect their susceptibility to hallucination.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="TUNING DATA">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Tuning data is the dataset used to fine-tune a model, which can influence the model's performance and accuracy, especially in areas underrepresented in the training dataset.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="UNSTRUCTURED DATA SOURCES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Unstructured data sources are raw data inputs that lack a predefined format, which can be used by AgentInstruct to generate tailored datasets for model training.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MODEL POST-TRAINING">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Model post-training is the process of further training a pre-trained model using additional data to improve its performance and capabilities.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DOMAIN/TASK SPECIALIZATION">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Domain/task specialization is the process of customizing a model to perform better in specific areas or tasks by using domain-specific content as seeds for training.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CONTINUAL IMPROVEMENT">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Continual improvement refers to the ongoing process of enhancing a model's performance by generating higher quality data than the base model using methods like agentic flows.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PHI-3 TECHNICAL REPORT">
      <data key="d0">DOCUMENTATION, RESOURCE</data>
      <data key="d1">The Phi-3 technical report is a document authored by multiple researchers, detailing the technical aspects and findings related to the Phi-3 model.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AI TECHNOLOGIES">
      <data key="d0">TECHNOLOGY, CONCEPT</data>
      <data key="d1">AI technologies refer to the various tools, models, and methods used in artificial intelligence to perform tasks that typically require human intelligence.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DISINFORMATION">
      <data key="d0">CONCEPT, RISK</data>
      <data key="d1">Disinformation is false or misleading information that can be generated by large language models and used maliciously without suitable safeguards.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT, RISK</data>
    </node>
    <node id="BENCHMARKS">
      <data key="d0">DATASET, EVALUATION</data>
      <data key="d1">Benchmarks are standardized tests or datasets used to evaluate the performance of models like Orca-3 after post-training with synthetic data.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PROMPTS AND RESPONSES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Prompts and responses are the input-output pairs generated by methods like AgentInstruct from unstructured data sources, used for training models.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MODEL CUSTOMIZATION">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Model customization is the process of tailoring a model to meet specific requirements or perform better in particular domains by using synthetic data and agentic flows.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, TECHNOLOGY</data>
    </node>
    <node id="HUMAN CURATION">
      <data key="d0">PROCESS, ACTIVITY</data>
      <data key="d1">Human curation refers to the manual intervention and oversight required during the data creation process to ensure quality and relevance, which AgentInstruct aims to minimize.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, ACTIVITY</data>
    </node>
    <node id="DIVERSE DATA">
      <data key="d0">DATA, ATTRIBUTE</data>
      <data key="d1">Diverse data refers to a wide variety of data types and sources used to train models, ensuring they perform well across different scenarios and tasks.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA, ATTRIBUTE</data>
    </node>
    <node id="HIGH-QUALITY DATA">
      <data key="d0">DATA, ATTRIBUTE</data>
      <data key="d1">High-quality data is accurate, relevant, and well-structured data used for training models to improve their performance and reliability.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA, ATTRIBUTE</data>
    </node>
    <node id="MODEL TRAINING">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Model training is the process of teaching a machine learning model to perform tasks by feeding it data and adjusting its parameters to improve performance.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, TECHNOLOGY</data>
    </node>
    <node id="PRE-TRAINING">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Pre-training is the initial phase of training a model on a large dataset to learn general features before fine-tuning it for specific tasks or domains.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, TECHNOLOGY</data>
    </node>
    <node id="DOMAIN-SPECIFIC CONTENT">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Domain-specific content is specialized data related to a particular field or area, used as seeds for training models to improve their performance in that domain.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="SEMI-AUTOMATED PIPELINES">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Semi-automated pipelines are partially automated processes that use synthetic data and agentic flows to streamline model customization and continual improvement.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, TECHNOLOGY</data>
    </node>
    <node id="PHI-3">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">PHI-3 is a highly capable language model designed to run locally on mobile devices, as described in a technical report published in 2024. The model is discussed in detail in the technical report authored by multiple researchers, which elaborates on its technical aspects and performance.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">MODEL, TECHNOLOGY</data>
    </node>
    <node id="LEGAL COGNITIVE SERVICES">
      <data key="d0">SERVICE, TECHNOLOGY</data>
      <data key="d1">Legal cognitive services are tools provided by Microsoft, including transparency notes, to help users understand the rationale behind specific outputs or decisions of large language models.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">SERVICE, TECHNOLOGY</data>
    </node>
    <node id="DIFFICULT REASONING TASKS">
      <data key="d0">TASK, CHALLENGE</data>
      <data key="d1">Difficult reasoning tasks are complex problems that require advanced cognitive abilities, which models like LATS aim to solve with the help of external feedback.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">TASK, CHALLENGE</data>
    </node>
    <node id="LARGE LANGUAGE MODELS">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Large language models are advanced AI models designed to understand and generate human language, capable of performing a wide range of tasks but also susceptible to risks like hallucination and misuse.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">TECHNOLOGY, MODEL</data>
    </node>
    <node id="FABRICATING CONTENT">
      <data key="d0">CONCEPT, RISK</data>
      <data key="d1">Fabricating content refers to the generation of false or misleading information by language models, which can be problematic in critical decision-making scenarios.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT, RISK</data>
    </node>
    <node id="UNGROUNDED GENERATION">
      <data key="d0">CONCEPT, RISK</data>
      <data key="d1">Ungrounded generation refers to the creation of content by language models without a solid basis in factual information, increasing the risk of hallucination.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT, RISK</data>
    </node>
    <node id="MEASUREMENT AND MITIGATIONS">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Measurement and mitigations are efforts to rigorously assess and reduce the risks associated with language models, such as hallucination and misuse.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, TECHNOLOGY</data>
    </node>
    <node id="DISTRIBUTION OF TUNING DATA">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Distribution of tuning data refers to how the data used to fine-tune a model is spread across different categories, which can affect the model's performance in underrepresented areas.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MULTIPLE BENCHMARKS">
      <data key="d0">DATASET, EVALUATION</data>
      <data key="d1">Multiple benchmarks are various standardized tests or datasets used to evaluate the performance of models like Orca-3 after post-training with synthetic data.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AGENTIC FRAMEWORK">
      <data key="d0">METHOD, TECHNOLOGY</data>
      <data key="d1">An agentic framework is a structured approach used by AgentInstruct to generate synthetic data, facilitating the post-training of models and teaching them a variety of skills.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="UNSTRUCTURED CONTENT">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Unstructured content refers to raw data inputs that lack a predefined format, which can be used by AgentInstruct to generate tailored datasets for model training.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="INSTRUCTION DATA">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Instruction data is the input-output pairs generated by methods like AgentInstruct from unstructured data sources, used for training models.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AI2 REASONING CHALLENGE (ARC)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">The AI2 Reasoning Challenge (ARC) is a benchmark for evaluating question-answering systems, introduced in a paper published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="KARL COBBE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Karl Cobbe is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CODEPARROT">
      <data key="d0">ORGANIZATION, DATASET PROVIDER</data>
      <data key="d1">CodeParrot is the provider of the Github-code clean dataset, which was accessed in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GITHUB-CODE CLEAN DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The Github-code clean dataset is a dataset provided by CodeParrot, accessed in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NING DING">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ning Ding is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DROA">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">DROP is a reading comprehension benchmark requiring discrete reasoning over paragraphs, introduced in a paper published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHAOYE FEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhaoye Fei is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ARNAV GUDIBANDE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arnav Gudibande is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAMISH IVISON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hamish Ivison is one of the authors of the paper on enhancing LM adaptation with Tulu 2, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALBERT Q. JIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Albert Q. Jiang is one of the authors of the paper on Mistral 7B, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HARRISON LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Harrison Lee is one of the authors of the paper on RLAIF, which scales reinforcement learning from human feedback with AI feedback, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GUOHAO LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guohao Li is one of the authors of the paper on CAMEL, which explores communicative agents for "mind" exploration of large language model society, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="READING COMPREHENSION BENCHMARK">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="QUERY OF CC">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="IMITATING PROPRIETARY LLMS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MEASURING MATHEMATICAL PROBLEM SOLVING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ENHANCING LM ADAPTATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MISTRAL 7B">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RLAIF">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CAMEL">
      <data key="d0" />
      <data key="d1">CAMEL is a framework for communicative agents designed for the exploration of large language model society, as described in a 2023 paper.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PHILIPP WITTE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Philipp Witte is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAIPING WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Haiping Wu is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MICHAEL WYATT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Wyatt is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BIN XIAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bin Xiao is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CAN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Can Xu is a notable author in the field of language models and artificial intelligence. In 2023, Can Xu co-authored the paper titled "Wizardlm: Empowering large language models to follow complex instructions," which focuses on enhancing the ability of large language models to comprehend and execute intricate directives. Following this, in 2024, Can Xu contributed to the Phi-3 technical report, which details a highly capable language model designed specifically for mobile devices. These contributions highlight Can Xu's significant role in advancing the capabilities and applications of language models in both complex instruction following and mobile technology.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAHANG XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiahang Xu is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="WEIJIAN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weijian Xu is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SONALI YADAV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sonali Yadav is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="FAN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fan Yang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JIANWEI YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jianwei Yang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZIYI YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ziyi Yang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YIFAN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yifan Yang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DONGHAN YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Donghan Yu is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LU YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu Yuan is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHENGRUIDONG ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chengruidong Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CYRIL ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cyril Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JIANWEN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jianwen Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LI LYNA ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Li Lyna Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YI ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yi Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUE ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yue Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUNAN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yunan Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XIREN ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiren Zhou is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ISAAC COWHEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Isaac Cowhey is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OREN ETZIONI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Oren Etzioni is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TUSHAR KHOT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tushar Khot is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ASHISH SABHARWAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ashish Sabharwal is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CARISSA SCHOENICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Carissa Schoenick is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OYVIND TAFJORD">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Oyvind Tafjord is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YULIN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yulin Chen is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BOKAI XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bokai Xu is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHI ZHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhi Zheng is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHENGDING HU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shengding Hu is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DHEERU DUA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dheeru Dua is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YIZHONG WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yizhong Wang is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PRADEEP DASIGI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pradeep Dasigi is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GABRIEL STANOVSKY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gabriel Stanovsky is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SAMEER SINGH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sameer Singh is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MATT GARDNER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matt Gardner is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUNFAN SHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yunfan Shao is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LINYANG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Linyang Li is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHIYUAN ZENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhiyuan Zeng is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANG YAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hang Yan is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XIPENG QIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xipeng Qiu is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DAHUA LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dahua Lin is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC WALLACE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Wallace is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHARLIE SNELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Charlie Snell is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XINYANG GENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xinyang Geng is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAO LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hao Liu is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AKUL ARORA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Akul Arora is one of the authors of the paper on measuring mathematical problem solving with the math dataset, published in 2021.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Tang is one of the authors of the paper on measuring mathematical problem solving with the math dataset, published in 2021.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DAVID WADDEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Wadden is one of the authors of the paper on enhancing LM adaptation with Tulu 2, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NOAH A. SMITH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Noah A. Smith is one of the authors of the paper on enhancing LM adaptation with Tulu 2, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="IZ BELTAGY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Iz Beltagy is one of the authors of the paper on enhancing LM adaptation with Tulu 2, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANNANEH HAJISHIRZI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hannaneh Hajishirzi is one of the authors of the paper on enhancing LM adaptation with Tulu 2, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALEXANDRE SABLAYROLLES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alexandre Sablayrolles is one of the authors of the paper on Mistral 7B, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ARTHUR MENSCH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arthur Mensch is one of the authors of the paper on Mistral 7B, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHRIS BAMFORD">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chris Bamford is one of the authors of the paper on Mistral 7B, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DEVENDRA SINGH CHAPLOT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Devendra Singh Chaplot is one of the authors of</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RII KHIZBULLIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rii Khizbullin is one of the authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society" published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BERNARD GHANEM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bernard Ghanem is one of the authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society" published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XUECHEN LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xuechen Li is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="TIANYI ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tianyi Zhang is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YANN DUBOIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yann Dubois is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ROHAN TAORI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rohan Taori is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ISHAAN GULRAJANI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ishaan Gulrajani is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CARLOS GUESTRIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Carlos Guestrin is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="TATSUNORI B. HASHIMOTO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tatsunori B. Hashimoto is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YIXIN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yixin Liu is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ALEXANDER R. FABBRI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alexander R. Fabbri is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JIAWEN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiawen Chen is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YILUN ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yilun Zhao is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SIMENG HAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Simeng Han is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SHAFIQ JOTY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shafiq Joty is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DRAGOMIR RADEV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dragomir Radev is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CHIEN-SHENG WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chien-Sheng Wu is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ARMAN COHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arman Cohan is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BENCHMARKING GENERATION AND EVALUATION CAPABILITIES">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LM-SYS">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">LM-Sys is the organization behind the MT-Bench project, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DANIEL VAN STRIEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daniel van Strien is one of the authors of the Cosmopedia project, a guide on creating large-scale synthetic data for pre-training, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LOUBNA BEN ALLAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Loubna Ben Allal is one of the authors of the Cosmopedia project, a guide on creating large-scale synthetic data for pre-training, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ANTON LOZHKOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anton Lozhkov is one of the authors of the Cosmopedia project, a guide on creating large-scale synthetic data for pre-training, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="COSMOPEDIA">
      <data key="d0">GUIDE, PROJECT</data>
      <data key="d1">Cosmopedia is a guide on how to create large-scale synthetic data for pre-training, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CLARISSE SIMOES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Clarisse Simoes is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SAHAJ AGARWAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sahaj Agarwal is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XUXI CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xuxi Chen is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ANASTASIA RAZDAIBIEDINA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anastasia Razdaibiedina is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ERIK JONES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Erik Jones is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KRITI AGGARWAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kriti Aggarwal is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="HAMID PALANGI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hamid Palangi is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ORCA 2">
      <data key="d0">PROJECT, METHOD</data>
      <data key="d1">Orca 2 is a project focused on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SUBHABRATA MUKHERJEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Subhabrata Mukherjee is one of the authors of the Xtremedistil project, a multi-stage distillation method for massive multilingual models, published in 2020.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XTREMEDISTIL">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Xtremedistil is a multi-stage distillation method for massive multilingual models, published in 2020.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="GANESH JAWAHAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ganesh Jawahar is one of the authors of the Orca project, which focuses on progressive learning from complex explanation traces of GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ORCA">
      <data key="d0">PROJECT, METHOD</data>
      <data key="d1">Orca is a project focused on progressive learning from complex explanation traces of GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SAMUEL J. PAECH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Samuel J. Paech is the author of the EQ-Bench project, an emotional intelligence benchmark for large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="EQ-BENCH">
      <data key="d0">TOOL, BENCHMARK</data>
      <data key="d1">EQ-Bench is an emotional intelligence benchmark for large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BAOLIN PENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Baolin Peng is one of the authors of a paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CHUNYUAN LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chunyuan Li is one of the authors of a paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="PENGCHENG HE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pengcheng He is one of the authors of a paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="MICHEL GALLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michel Galley is one of the authors of a paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="INSTRUCTION TUNING WITH GPT-4">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YIWEI QIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiwei Qin is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KAIQIANG SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kaiqiang Song is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YEBO WEN HU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yebo Wen Hu is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="WENLIN YAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenlin Yao is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SANGWOO CHO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sangwoo Cho is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XIAOYANG WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiaoyang Wang is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XUANSHENG WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xuansheng Wu is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="MOHAMMED LATIF SIDDIQ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mohammed Latif Siddiq is one of the authors of two significant papers published in 2024. The first paper, titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," focuses on assessing the vulnerabilities of generated regular expressions to denial-of-service attacks. The second paper, "The curse of recursion: Training on generated data makes models forget," explores the detrimental effects of training models on generated data, particularly how it can lead to models forgetting previously learned information.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAHAO ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiahao Zhang is one of the authors of two significant papers published in 2024. The first paper, titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," focuses on assessing the vulnerabilities of generated regular expressions to denial-of-service attacks. The second paper, "The curse of recursion: Training on generated data makes models forget," explores the detrimental effects of training models on generated data, particularly how it can lead to models forgetting previously learned information.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LINDSAY RONEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lindsay Roney is one of the authors of two significant papers published in 2024. The first paper, titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," delves into the evaluation of generated regular expressions and their susceptibility to denial-of-service attacks. The second paper, "The curse of recursion: Training on generated data makes models forget," explores the impact of training models on generated data, particularly focusing on how recursion can lead to models forgetting previously learned information.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JOANNA C. S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joanna C. S. is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="THE CURSE OF RECURSION">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">"The Curse of Recursion: Training on Generated Data Makes Models Forget" is a research paper published in 2024. The paper discusses the negative effects of training models on generated data, highlighting how this practice can lead to models forgetting previously learned information.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ILIA SHUMAILOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ilia Shumailov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZAKHAR SHUMAYLOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zakhar Shumaylov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIREN ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiren Zhao is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YARIN GAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yarin Gal is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NICOLAS PAPERNOT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicolas Papernot is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ROSS ANDERSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ross Anderson is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHING-AN CHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ching-An Cheng is one of the authors of the paper titled "Direct Nash Optimization: Teaching language models to self-improve with general preferences," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="TENGYANG XIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tengyang Xie is one of the authors of the paper titled "Direct Nash Optimization: Teaching language models to self-improve with general preferences," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DIRECT NASH OPTIMIZATION">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Direct Nash Optimization is a method for teaching language models to self-improve with general preferences, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JOANNA C. S. SANTOS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joanna C. S. Santos is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RE(GEX|DOS)EVAL">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," published in 2024, discussing the evaluation of generated regular expressions and their vulnerability to denial-of-service attacks.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NATHANAEL SCH&#196;RLI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nathanael Sch&#228;rli is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHALLENGING BIG-BENCH TASKS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022, discussing the challenges of big-bench tasks and the effectiveness of chain-of-thought reasoning.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEN WAI YIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wen Wai Yim is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YUJUAN FU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yujuan Fu is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ASMA BEN ABACHA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Asma Ben Abacha is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NEAL SNIDER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Neal Snider is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="THOMAS LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thomas Lin is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MELIHA YETISGEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Meliha Yetisgen is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIAYUN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiaoyun Zhang is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AHMED HASSAN AWADALLAH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ahmed Hassan Awadallah is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RYEN W WHITE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ryen W White is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DOUG BURGER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Doug Burger is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AUTOGEN">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023, discussing the use of multi-agent conversation to enable next-generation large language model applications.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CONGYING XIA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Congying Xia is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHEN XING">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen Xing is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIANGSHU DU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiangshu Du is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XINYI YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xinyi Yang is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIHAO FENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yihao Feng is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RAN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ran Xu is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WENPENG YIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenpeng Yin is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CAIMING XIONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Caiming Xiong is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="GUANGZHI XIONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guangzhi Xiong is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QIAO JIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qiao Jin is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHIYONG LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhiyong Lu is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AIDONG ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aidong Zhang is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="BENCHMARKING RETRIEVAL-AUGMENTED GENERATION FOR MEDICINE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Benchmarking retrieval-augmented generation for medicine," published in 2024, discussing the evaluation of retrieval-augmented generation techniques in the medical field.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QINGFENG SUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qingfeng Sun is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="KAI ZHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kai Zheng is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIUBO GENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiubo Geng is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="PU ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pu Zhao is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAZHAN FENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiazhan Feng is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHONGYANG TAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chongyang Tao is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DAXIN JIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daxin Jiang is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WIZARDLM">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023, discussing techniques to enable large</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LONGHUI YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Longhui Yu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEISEN JIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weisen Jiang is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="HAN SHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Han Shi is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JINCHENG YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jincheng Yu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHENGYING LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhengying Liu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YU ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yu Zhang is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JAMES T KWOK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">James T Kwok is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHENGUO LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhenguo Li is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ADRIAN WELLER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Adrian Weller is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEIYANG LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weiyang Liu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="METAMATH">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023, discussing methods to generate mathematical questions for large language models.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIFAN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yifan Zhang is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIFAN LUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yifan Luo is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YANG YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang Yuan is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ANDREW CHI-CHIH YAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew Chi-Chih Yao is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WANJUN ZHONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wanjun Zhong is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RUIXIANG CUI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ruixiang Cui is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIDUO GUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiduo Guo is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YAOBO LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yaobo Liang is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SHUAI LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shuai Lu is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YANLIN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yanlin Wang is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NAN DUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nan Duan is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JEFFREY ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeffrey Zhou is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="TIANJIAN LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tianjian Lu is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SIDDHARTHA BRAHMA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Siddhartha Brahma is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SUJOY BASU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sujoy Basu is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YI LUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yi Luan is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="INSTRUCTION-FOLLOWING EVALUATION">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Instruction-following evaluation for large language models," published in 2023, discussing methods to evaluate how well large language models follow instructions.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DEBATE PASSAGE GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that specializes in crafting passages that mimic the structure and content of debate transcripts.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CONVERSATION PASSAGE GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that generates passages depicting dialogues.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MEETING TRANSCRIPT GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent designed to produce meeting transcripts.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="POEM GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that generates poems.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SATIRICAL PASSAGE GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that creates texts infused with satirical wit.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="INSTRUCTIONAL PASSAGE GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that generates passages resembling instructional manuals.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LONG TEXT GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that extends the original text by incorporating additional information, thereby increasing its length.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="IDENTITY AGENT">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">A straightforward agent that replicates the input text verbatim.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LITERAL COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE, INSTRUCTION</data>
      <data key="d1">A question that asks for a specific detail(s) or fact(s) clearly stated in the text.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NUMERICAL DISCRETE REASONING">
      <data key="d0">QUESTION TYPE, INSTRUCTION</data>
      <data key="d1">Questions that require the reader to use numerical reasoning over many facts from the text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CRITICAL COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE, INSTRUCTION</data>
      <data key="d1">The "CRITICAL COMPREHENSION QUESTION" involves constructing two statements about the purpose or point of view that the reader must assess as true or false. One of these statements is true, while the other is false. This type of question is designed to evaluate the reader's ability to critically analyze and discern the accuracy of the given statements, ensuring a deeper understanding of the material.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="EVALUATIVE COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE, INSTRUCTION</data>
      <data key="d1">The "EVALUATIVE COMPREHENSION QUESTION" is a type of question that requires the reader to evaluate and provide an essay response based on the text. These open-ended questions prompt an in-depth analysis of the text&#8217;s theme or the effectiveness of an argument, encouraging a comprehensive understanding and critical assessment of the material.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="VOCABULARY AND LANGUAGE USE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Fill-in-the-blank questions that test understanding of a particular word or phrase used in the text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="RELATIONSHIP COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Matching questions where respondents pair items based on a specific criterion.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="SEQUENCING EVENTS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that require arranging a series of events from the text in the correct chronological order.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="STRENGTHEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that ask to identify information that would make the argument&#8217;s conclusion more likely to be true.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="WEAKEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that ask to find evidence or an argument that would make the conclusion less likely to be true.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="ASSUMPTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that determine what must be true for the argument to hold.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="FLAW">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that point out a mistake in the argument&#8217;s reasoning.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="INFERENCE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that ask to choose an option that logically follows from the information provided.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="PRINCIPLE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that recognize the general rule or principle that underlies the argument.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="METHOD OF REASONING">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that describe how the argument is constructed logically.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="RESOLVE THE PARADOX">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that offer an explanation that reconciles seemingly contradictory information.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="TEXT SIMPLIFICATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Making text easier to read and understand by using simpler words and sentence structures, often for children or language learners.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT EXPANSION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Adding more information or detail to make text more comprehensive or to meet a certain word count.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT TRANSLATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Converting text from one language to another while attempting to preserve the original meaning as closely as possible.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT FORMATTING">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Altering the appearance of text to improve readability or for stylistic purposes.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="SENTIMENT MODIFICATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Changing the tone of the text to alter its emotional impact, such as making a sentence sound more positive or negative.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT ANNOTATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Adding notes, comments, or explanations to a text, often for the purpose of analysis or to provide additional context.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="KEYWORD REPLACEMENT">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Substituting specific words or phrases with synonyms or related terms.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT REMOVING">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Redacting or removing content from text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT CAPITALIZATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Adjusting the case of letters in text, such as converting to uppercase, lowercase, title case, or sentence case.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT STYLING">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Applying styles like bold, italics, underline, etc., to emphasize certain parts of the text or for aesthetic purposes.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="CONTENT REWRITING">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Extensively modifying a text to produce a new version, which could involve changing the perspective, style, or target audience.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="DATA NORMALIZATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Standardizing text to ensure consistency, such as converting dates and times to a standard format or unifying the spelling of words.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="PLAGIARISM REWORDING">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Altering text to avoid plagiarism, ensuring that the content is original.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT OBFUSCATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Intentionally making text vague or harder to understand, sometimes for security purposes like masking personal data.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXTUAL ENTAILMENT">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Modifying a sentence or phrase to either entail or contradict another sentence, often used in natural language processing tasks.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="REWRITING WITH VOCABULARY LIMITATIONS">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Rewriting the entire text or a piece of it while using a limited vocabulary, such as all words starting with a specific letter.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="INSTRUCTION TAXONOMY">
      <data key="d0">EVALUATION METHOD</data>
      <data key="d1">A classification system used for generating seed instructions for various types of questions and tasks.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="EVALUATOR ASSISTANT">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to GPT-4 for parsing student responses and extracting the selected options in multiple choice questions.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="ANSWER OPTIONS">
      <data key="d0">DATA</data>
      <data key="d1">The set of possible answers provided for a multiple choice question, from which the student selects one or more options.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="ALPHABET ID">
      <data key="d0">DATA</data>
      <data key="d1">The entity "ALPHABET ID" refers to the letter representing the option chosen by the student in their response to a multiple choice question. This alphabet signifies the specific choice made by the student among the available options, providing a clear indication of their selected answer.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PARSED STUDENT ANSWER">
      <data key="d0">ANSWER FORMAT, STUDENT RESPONSE</data>
      <data key="d1">The final answer extracted from the student's response, represented by the alphabets corresponding to the options chosen by the student.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="OPTIONS">
      <data key="d0">ANSWER CHOICES, MULTIPLE CHOICE</data>
      <data key="d1">A list of possible answers provided for the student to choose from, each represented by an alphabet.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EXACT MATCH/SPAN EXTRACTION PROBLEMS">
      <data key="d0">TASK TYPE, PROBLEM TYPE</data>
      <data key="d1">Tasks that involve math-based questions or problems where a ground-truth answer value is given, requiring the model to generate and match the exact answer with the provided ground-truth.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE, INSTRUCTION</data>
      <data key="d1">A specific system message used for evaluating a student's answer to a math word problem, ensuring the final answer matches the problem setter's answer.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE, INSTRUCTION</data>
      <data key="d1">A system message used for parsing student responses and matching them with the correct answer provided in the context.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE, INSTRUCTION</data>
      <data key="d1">A system message used for extracting emotion scores from a student agent's response, including first pass scores, critique, and revised scores.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EMOTION SCORES">
      <data key="d0">SCORE, METRIC</data>
      <data key="d1">Scores generated for each emotion in a conversation, ranging from 0-10, indicating the alignment with the reference answer.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="VERSION 1 AND 2 IMPLEMENTATIONS">
      <data key="d0">IMPLEMENTATION, METHOD</data>
      <data key="d1">Different versions of implementations described in the EQBench paper and repository, used for scoring calculations.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="CREATORS' GITHUB REPOSITORY">
      <data key="d0">REPOSITORY, SOURCE</data>
      <data key="d1">The GitHub repository maintained by the creators of EQBench, containing the implementations and resources for the benchmark.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="FINAL ANSWER">
      <data key="d0">ANSWER, RESPONSE</data>
      <data key="d1">The definitive answer provided by the student after considering all options.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="CORRECT ANSWER">
      <data key="d0">ANSWER, GROUND-TRUTH</data>
      <data key="d1">The answer provided by the problem setter, used as a reference to evaluate the student's response.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ERROR ANALYSIS">
      <data key="d0">EVALUATION, ANALYSIS</data>
      <data key="d1">A process of comparing the student's final answer with the correct answer to determine if they match.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="FINAL VERDICT">
      <data key="d0">EVALUATION, RESULT</data>
      <data key="d1">The result of the error analysis, indicating whether the student's answer is 'Correct' or 'Incorrect'.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="STUDENT AGENT RESPONSE">
      <data key="d0">RESPONSE, ANSWER</data>
      <data key="d1">The response generated by a student agent, including emotion scores and critiques.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="FIRST PASS SCORES">
      <data key="d0">SCORE, INITIAL EVALUATION</data>
      <data key="d1">The initial scores assigned to each emotion in the student agent's response.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="CRITIQUE">
      <data key="d0">EVALUATION, FEEDBACK</data>
      <data key="d1">A detailed analysis of the student agent's response, explaining the reasoning behind the scores.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="REVISED SCORES">
      <data key="d0">SCORE, FINAL EVALUATION</data>
      <data key="d1">The updated scores assigned to each emotion after considering the critique.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ALEX">
      <data key="d0">PERSON</data>
      <data key="d1">Alex is a person who is already in a relationship and has been confessed to by Elliot, putting Alex in an awkward position.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="RESIGNED">
      <data key="d0">EMOTION</data>
      <data key="d1">Resigned is an emotion experienced by Elliot, scored at 7, indicating a feeling of acceptance of an unpleasant situation.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ANGRY">
      <data key="d0">EMOTION</data>
      <data key="d1">Angry is an emotion experienced by Elliot, scored at 3, indicating a feeling of displeasure or annoyance.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HOPEFUL">
      <data key="d0">EMOTION</data>
      <data key="d1">Hopeful is an emotion experienced by Elliot, scored at 5, indicating a feeling of optimism or expectation that Alex might reciprocate his feelings.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMBARRASSED">
      <data key="d0">EMOTION</data>
      <data key="d1">Embarrassed is an emotion experienced by Elliot, scored at 8, indicating a feeling of self-consciousness or shame for putting Alex in an awkward position.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="OPEN-ENDED GENERATION">
      <data key="d0">TASK, CATEGORY</data>
      <data key="d1">Open-Ended Generation tasks involve generating an answer to an open-ended question without a ground-truth to match the answer. Various benchmarks are used to evaluate these tasks.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HALLUCINATION JUDGE">
      <data key="d0">TASK, TOOL</data>
      <data key="d1">Hallucination Judge is a task where a judge decides if there is any hallucination in a generated summary by comparing it with relevant facts from the article.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="QUALITY JUDGE">
      <data key="d0">TASK, TOOL</data>
      <data key="d1">Quality Judge is a task where a judge evaluates the quality of a response provided by an AI assistant based on criteria like instruction adherence, content grounding, and overall quality.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ELLIOT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMOTIONS">
      <data key="d0">CATEGORY</data>
      <data key="d1">A list of feelings experienced by Elliot, including resigned, angry, hopeful, and embarrassed.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="SCORES">
      <data key="d0">METRIC</data>
      <data key="d1">Numerical values assigned to each of Elliot's emotions: Resigned (7), Angry (3), Hopeful (5), Embarrassed (8).</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="VERSION 0613">
      <data key="d0">VERSION</data>
      <data key="d1">A specific version of GPT-4 used in the FOFO and AlpacaEval benchmarks.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="VERSION 1106-PREVIEW">
      <data key="d0">VERSION</data>
      <data key="d1">A specific version of GPT-4 used in the InfoBench benchmark.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="JUDGE">
      <data key="d0">ROLE</data>
      <data key="d1">The role played by GPT-4 in evaluating benchmarks like FOFO, MT-Bench, AlpacaEval, and InfoBench.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="PROMPT TEMPLATE">
      <data key="d0">TOOL</data>
      <data key="d1">A predefined format used for tasks like hallucination detection and quality evaluation in text summarization.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HALLUCINATION DETECTION">
      <data key="d0">TASK</data>
      <data key="d1">The process of identifying hallucinated content in a generated summary by comparing it with relevant facts from the article.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="TEXT SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">The task of generating a concise and accurate summary of a given text, evaluated for quality and hallucination.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="INSTRUCTION ADHERENCE">
      <data key="d0">CRITERION</data>
      <data key="d1">A criterion used in quality evaluation to check if the response correctly follows the user instruction.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="CONTENT GROUNDING">
      <data key="d0">CRITERION</data>
      <data key="d1">A criterion used in quality evaluation to check if the response is grounded in the instruction without introducing new content.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="OVERALL QUALITY">
      <data key="d0">CRITERION</data>
      <data key="d1">A criterion used in quality evaluation to assess the clarity, coherence, and completeness of the response.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <edge source="GRAPH RAG" target="LLM">
      <data key="d4">18.0</data>
      <data key="d5">Graph RAG uses LLMs to build a graph-based text index and generate community summaries.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="QFS">
      <data key="d4">16.0</data>
      <data key="d5">Graph RAG combines the strengths of RAG and QFS to answer global questions directed at an entire text corpus.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY DETECTION">
      <data key="d4">16.0</data>
      <data key="d5">Graph RAG uses community detection to partition the graph index into groups of elements.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="QUERY-FOCUSED SUMMARIZATION">
      <data key="d4">16.0</data>
      <data key="d5">Graph RAG uses query-focused summarization to generate a global answer from community summaries.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="MICROSOFT RESEARCH">
      <data key="d4">16.0</data>
      <data key="d5">Microsoft Research is involved in the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d4">16.0</data>
      <data key="d5">Microsoft Strategic Missions and Technologies is involved in the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="MICROSOFT OFFICE OF THE CTO">
      <data key="d4">16.0</data>
      <data key="d5">Microsoft Office of the CTO is involved in the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="DAREN EDGE">
      <data key="d4">12.0</data>
      <data key="d5">Daren Edge is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="HA TRINH">
      <data key="d4">12.0</data>
      <data key="d5">Ha Trinh is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWMAN CHENG">
      <data key="d4">12.0</data>
      <data key="d5">Newman Cheng is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="JOSHUA BRADLEY">
      <data key="d4">12.0</data>
      <data key="d5">Joshua Bradley is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="ALEX CHAO">
      <data key="d4">12.0</data>
      <data key="d5">Alex Chao is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="APURVA MODY">
      <data key="d4">12.0</data>
      <data key="d5">Apurva Mody is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="STEVEN TRUITT">
      <data key="d4">12.0</data>
      <data key="d5">Steven Truitt is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="JONATHAN LARSON">
      <data key="d4">12.0</data>
      <data key="d5">Jonathan Larson is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="HUMAN SENSEMAKING">
      <data key="d4">14.0</data>
      <data key="d5">Graph RAG supports human sensemaking over entire text corpora.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="KNOWLEDGE GRAPH">
      <data key="d4">9.0</data>
      <data key="d5">Graph RAG uses an LLM-derived knowledge graph for global summarization.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG leverages community detection algorithms to partition graphs into modular communities.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="MAP-REDUCE">
      <data key="d4">16.0</data>
      <data key="d5">Graph RAG is a method that leverages a map-reduce approach to summarize query-focused information. It is compared to a graph-free approach using map-reduce for the global summarization of source texts. This comparison highlights the effectiveness of Graph RAG in handling specific queries by utilizing the map-reduce paradigm, which is also employed in broader summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="TOKEN COSTS">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG shows favorable performance over source text summarization at lower token costs.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="INTERMEDIATE-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">8.0</data>
      <data key="d5">Intermediate-level community summaries are used in the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">8.0</data>
      <data key="d5">Low-level community summaries are used in the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL LEVEL">
      <data key="d4">7.0</data>
      <data key="d5">The hierarchical level of community summaries impacts the performance of the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="CONTEXT WINDOW">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses a context window to generate answers, with the size being consistent across conditions.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="ENTITY">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG uses entities to create the graph index for answering queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="RELATIONSHIP">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG uses relationships to create the graph index for answering queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="GRAPH COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Graph communities at different levels (C0, C1, C2, C3) are used in the Graph RAG method to answer queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="CONDITION">
      <data key="d4">7.0</data>
      <data key="d5">Different conditions (C0, C1, C2, C3) are compared in the Graph RAG method to evaluate performance.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="COMPREHENSIVENESS">
      <data key="d4">24.0</data>
      <data key="d5">Graph RAG achieves high comprehensiveness win rates in both Podcast and News datasets. Additionally, Graph RAG provides a comprehensive and detailed list of public figures from various entertainment sectors. This highlights its effectiveness and thoroughness in capturing and representing diverse information across multiple domains.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="NAIVE RAG">
      <data key="d4">9.0</data>
      <data key="d5">Graph RAG outperforms naive RAG in terms of comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="PODCAST DATASET">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG is used to evaluate the comprehensiveness and diversity of answers in the Podcast dataset.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWS DATASET">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG is used to evaluate the comprehensiveness and diversity of answers in the News dataset.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="DIVERSITY">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG achieves high diversity win rates in both Podcast and News datasets.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="EMPOWERMENT">
      <data key="d4">14.0</data>
      <data key="d5">Graph RAG performs comparably with larger context sizes on empowerment. Additionally, Graph RAG's ability to provide specific examples, quotes, and citations significantly contributes to user empowerment. This dual capability highlights Graph RAG's effectiveness in both maintaining performance with extensive data and enhancing user understanding and confidence through detailed, supportive information.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY SUMMARIES">
      <data key="d4">25.0</data>
      <data key="d5">Graph RAG leverages community summaries to enhance the comprehensiveness and diversity of answers. These summaries are integral to Graph RAG's efficient summarization and question-answering capabilities. Specifically, Graph RAG utilizes summaries of root-level communities within the entity-based graph index to handle global queries effectively. This approach ensures that the system can provide detailed and varied responses by synthesizing information from different community structures within the graph.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="TS">
      <data key="d4">7.0</data>
      <data key="d5">TS is compared to Graph RAG in terms of comprehensiveness and diversity, with Graph RAG showing slight improvements.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="C0">
      <data key="d4">8.0</data>
      <data key="d5">C0 represents root-level community summaries in Graph RAG, requiring dramatically fewer tokens per query.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="C1">
      <data key="d4">8.0</data>
      <data key="d5">C1 represents intermediate-level community summaries in Graph RAG, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="C2">
      <data key="d4">8.0</data>
      <data key="d5">C2 represents low-level community summaries in Graph RAG, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="C3">
      <data key="d4">8.0</data>
      <data key="d5">C3 represents the lowest level of community summaries in Graph RAG, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="CONTEXT TOKENS">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG requires fewer context tokens compared to source text summarization, especially at the root level.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="ROOT-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">9.0</data>
      <data key="d5">Graph RAG uses root-level community summaries to reduce the number of context tokens required.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="SENSEMAKING ACTIVITY">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG facilitates sensemaking activity by providing efficient iterative question answering.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="TUNING ELEMENT EXTRACTION PROMPTS">
      <data key="d4">6.0</data>
      <data key="d5">Tuning element extraction prompts can help retain more details in the Graph RAG index.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="NEO4J">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is compared to systems like NaLLM that use Neo4J for knowledge graph creation and reasoning.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="NEBULAGRAPH">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is compared to systems like GraphRAG that use NebulaGraph for knowledge graph creation and reasoning.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SELF CHECK GPT">
      <data key="d4">6.0</data>
      <data key="d5">Graph RAG's evaluation could be improved by comparing fabrication rates using approaches like SelfCheckGPT.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SENSEMAKING QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG's evaluation has examined a certain class of sensemaking questions to understand its performance.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="EMBEDDING-BASED MATCHING">
      <data key="d4">7.0</data>
      <data key="d5">Future work on Graph RAG includes embedding-based matching of user queries and graph annotations.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d4">5.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="AMBER HOAK">
      <data key="d4">5.0</data>
      <data key="d5">Amber Hoak contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d4">5.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="BEN CUTLER">
      <data key="d4">5.0</data>
      <data key="d5">Ben Cutler contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="BILLIE RINALDI">
      <data key="d4">5.0</data>
      <data key="d5">Billie Rinaldi contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CHRIS SANCHEZ">
      <data key="d4">5.0</data>
      <data key="d5">Chris Sanchez contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CHRIS TREVINO">
      <data key="d4">5.0</data>
      <data key="d5">Chris Trevino contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CHRISTINE CAGGIANO">
      <data key="d4">5.0</data>
      <data key="d5">Christine Caggiano contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DAVID TITTSWORTH">
      <data key="d4">5.0</data>
      <data key="d5">David Tittsworth contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DAYENNE DE SOUZA">
      <data key="d4">5.0</data>
      <data key="d5">Dayenne de Souza contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DOUGLAS ORBAKER">
      <data key="d4">5.0</data>
      <data key="d5">Douglas Orbaker contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="ED CLARK">
      <data key="d4">5.0</data>
      <data key="d5">Ed Clark contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="GABRIEL NIEVES-PONCE">
      <data key="d4">5.0</data>
      <data key="d5">Gabriel Nieves-Ponce contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="GAUDY BLANCO MENESES">
      <data key="d4">5.0</data>
      <data key="d5">Gaudy Blanco Meneses contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="KATE LYTVYNETS">
      <data key="d4">5.0</data>
      <data key="d5">Kate Lytvynets contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="KATY SMITH">
      <data key="d4">5.0</data>
      <data key="d5">Katy Smith contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="M&#211;NICA CARVAJAL">
      <data key="d4">5.0</data>
      <data key="d5">M&#243;nica Carvajal contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="NATHAN EVANS">
      <data key="d4">5.0</data>
      <data key="d5">Nathan Evans contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RICHARD ORTEGA">
      <data key="d4">5.0</data>
      <data key="d5">Richard Ortega contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RODRIGO RACANICCI">
      <data key="d4">5.0</data>
      <data key="d5">Rodrigo Racanicci contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SARAH SMITH">
      <data key="d4">5.0</data>
      <data key="d5">Sarah Smith contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SHANE SOLOMON">
      <data key="d4">5.0</data>
      <data key="d5">Shane Solomon contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses global summarization techniques to summarize data across entire datasets.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SENSEMAKING">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG supports sensemaking by helping users understand and make sense of large text corpora.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DATA PARTITIONING">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses data partitioning to divide data into smaller parts for global summarization.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CORPORA">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is evaluated using large corpora of text.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="COMPUTE BUDGET">
      <data key="d4">7.0</data>
      <data key="d5">The decision to build a graph index in Graph RAG depends on the compute budget.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="LIFETIME QUERIES">
      <data key="d4">7.0</data>
      <data key="d5">The decision to build a graph index in Graph RAG depends on the expected number of lifetime queries.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RICH TEXT ANNOTATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG uses rich text annotations to support its methods.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG uses a hierarchical community structure to organize data.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses query-focused summarization (QFS) to generate summaries based on user queries.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses retrieval-augmented generation (RAG) to combine retrieval of information with content generation.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="MAP-REDUCE SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is compared to map-reduce summarization for global summarization of source texts.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="TOKEN COST">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is evaluated based on token cost to measure its efficiency.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="OPEN-SOURCE IMPLEMENTATION">
      <data key="d4">6.0</data>
      <data key="d5">An open-source implementation of Graph RAG is forthcoming.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="PYTHON">
      <data key="d4">6.0</data>
      <data key="d5">Graph RAG will have an open-source implementation in Python.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RAG" target="EXTERNAL KNOWLEDGE SOURCE">
      <data key="d4">14.0</data>
      <data key="d5">RAG retrieves relevant information from an external knowledge source to answer user questions.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="RAG" target="QFS">
      <data key="d4">12.0</data>
      <data key="d5">RAG is contrasted with QFS, which is more appropriate for global questions directed at an entire text corpus.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="RAG" target="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">RAG is a method that may be inadequate for query-focused abstractive summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="RAG" target="NA&#207;VE RAG">
      <data key="d4">8.0</data>
      <data key="d5">Na&#239;ve RAG is a basic form of RAG that converts documents to text and embeds them into a vector space.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="RAG" target="MODULAR RAG">
      <data key="d4">8.0</data>
      <data key="d5">Modular RAG is an advanced form of RAG that includes patterns for iterative and dynamic cycles of retrieval and generation.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="RAG" target="LANGCHAIN">
      <data key="d4">7.0</data>
      <data key="d5">RAG is a tool that can be used within the LangChain framework to enhance agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="RAG" target="LEWIS ET AL., 2020">
      <data key="d4">16.0</data>
      <data key="d5">Lewis et al. are the authors who have significantly contributed to the development of Retrieval-Augmented Generation (RAG) techniques, which are relevant to Advanced Driver Assistance Systems (ADAS). Their work on RAG was published in 2020, highlighting their role in advancing this method.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="RAG" target="ZHANG ET AL., 2024C">
      <data key="d4">6.0</data>
      <data key="d5">Zhang et al. are the authors who contributed to the development of RAG techniques, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="RAG" target="ADAS">
      <data key="d4">12.0</data>
      <data key="d5">RAG (Retrieval-Augmented Generation) is a method that can be used as a building block in ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="RAG" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct generates data to teach AI models the skill of RAG (Retrieval-Augmented Generation).</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="RAG" target="MIRAGE">
      <data key="d4">17.0</data>
      <data key="d5">RAG is a technique used to enhance the performance of models on the MIRAGE datasets. It is evaluated using the MIRAGE benchmark to assess its effectiveness in answering medical questions. This evaluation process ensures that RAG's capabilities are rigorously tested within the context of medical inquiries, providing a comprehensive measure of its utility and accuracy in this specialized domain.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="LLM" target="TRANSFORMER ARCHITECTURE">
      <data key="d4">16.0</data>
      <data key="d5">LLMs are based on transformer architecture, which has shown substantial improvements in summarization tasks.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LLM" target="GPT">
      <data key="d4">14.0</data>
      <data key="d5">GPT is a series of LLMs used for various tasks, including summarization and sensemaking.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LLM" target="LLAMA">
      <data key="d4">14.0</data>
      <data key="d5">Llama is an LLM used for various tasks, including summarization and sensemaking.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LLM" target="GEMINI">
      <data key="d4">14.0</data>
      <data key="d5">Gemini is an LLM used for various tasks, including summarization and sensemaking.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LLM" target="NAMED ENTITIES">
      <data key="d4">9.0</data>
      <data key="d5">The LLM is used to extract named entities from text documents.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="COVARIATES">
      <data key="d4">8.0</data>
      <data key="d5">The LLM supports a secondary extraction prompt for covariates associated with extracted node instances.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="GLEANINGS">
      <data key="d4">8.0</data>
      <data key="d5">The LLM uses multiple rounds of gleanings to ensure all entities are extracted.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="BROWN ET AL., 2020">
      <data key="d4">6.0</data>
      <data key="d5">Brown et al. provided examples for in-context learning for LLMs.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="DATASET">
      <data key="d4">8.0</data>
      <data key="d5">The LLM is used to generate questions and evaluate answers based on the dataset.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="LLM" target="COMPREHENSIVENESS">
      <data key="d4">14.0</data>
      <data key="d5">LLMs are used to generate comprehensive assessments and answers based on data inputs.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="LLM" target="DIVERSITY">
      <data key="d4">14.0</data>
      <data key="d5">LLMs are used to generate diverse perspectives and insights in assessments and answers.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="LLM" target="EMPOWERMENT">
      <data key="d4">14.0</data>
      <data key="d5">LLMs are used to generate empowering assessments and answers that help readers make informed judgments.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="LLM" target="DIRECTNESS">
      <data key="d4">14.0</data>
      <data key="d5">LLMs are used to generate direct and specific assessments and answers.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="LLM" target="AGENT">
      <data key="d4">9.0</data>
      <data key="d5">An agent is powered by an LLM and can optionally use tools to perform specific tasks.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="QFS" target="QUERY-FOCUSED SUMMARIZATION">
      <data key="d4">14.0</data>
      <data key="d5">Query-focused summarization is a type of QFS used in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="ARINDAM MITRA">
      <data key="d4">6.0</data>
      <data key="d5">Arindam Mitra is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="LUCIANO DEL CORRO">
      <data key="d4">6.0</data>
      <data key="d5">Luciano Del Corro is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="GUOQING ZHENG">
      <data key="d4">6.0</data>
      <data key="d5">Guoqing Zheng is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="SHWETI MAHAJAN">
      <data key="d4">6.0</data>
      <data key="d5">Shweti Mahajan is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="DANY ROUHANA">
      <data key="d4">6.0</data>
      <data key="d5">Dany Rouhana is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="ANDRES CODAS">
      <data key="d4">6.0</data>
      <data key="d5">Andres Codas is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="YADONG LU">
      <data key="d4">6.0</data>
      <data key="d5">Yadong Lu is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="WEI-GE CHEN">
      <data key="d4">6.0</data>
      <data key="d5">Wei-ge Chen is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="OLGA VROUSGOS">
      <data key="d4">6.0</data>
      <data key="d5">Olga Vrousgos is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="CORBY ROSSET">
      <data key="d4">6.0</data>
      <data key="d5">Corby Rosset is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="FILLIPE SILVA">
      <data key="d4">6.0</data>
      <data key="d5">Fillipe Silva is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="HAMED KHANPOUR">
      <data key="d4">6.0</data>
      <data key="d5">Hamed Khanpour is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="YASH LARA">
      <data key="d4">6.0</data>
      <data key="d5">Yash Lara is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="AHMED AWADALLAH">
      <data key="d4">1.0</data>
      <data key="d5">Ahmed Awadallah is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="HUMAN SENSEMAKING" target="SENSEMAKING">
      <data key="d4">14.0</data>
      <data key="d5">Sensemaking is a key concept in human sensemaking and the development of Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="LEIDEN">
      <data key="d4">14.0</data>
      <data key="d5">Leiden is a community detection algorithm used in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LEIDEN" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">7.0</data>
      <data key="d5">Leiden is a community detection algorithm used to partition graphs into modular communities.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION" target="COMMUNITY SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Community summaries are used for query-focused summarization in a graph-based index.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="TEXT CHUNKS">
      <data key="d4">19.0</data>
      <data key="d5">Text chunks are segments of source documents that are extracted for processing, particularly within the Graph RAG approach. These text chunks serve as essential components, enabling the analysis and understanding of the underlying structures and relationships within the source documents. By breaking down the source documents into manageable segments, the Graph RAG approach facilitates a more detailed and comprehensive examination of the data, ensuring that intricate connections and hierarchies are effectively identified and analyzed.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="TEXT CHUNKS" target="ELEMENT INSTANCES">
      <data key="d4">12.0</data>
      <data key="d5">Element instances are specific pieces of information extracted from text chunks in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="TEXT CHUNKS" target="ENTITY EXTRACTION">
      <data key="d4">8.0</data>
      <data key="d5">Entity extraction is performed on text chunks to build a knowledge graph.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="ELEMENT SUMMARIES">
      <data key="d4">20.0</data>
      <data key="d5">Element instances are summarized into element summaries for each graph element. Element summaries are domain-tailored summaries of element instances in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="HOMOGENEOUS NODES">
      <data key="d4">7.0</data>
      <data key="d5">Homogeneous nodes are used to create rich descriptive text for element summaries.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="COMMUNITY SUMMARIES">
      <data key="d4">20.0</data>
      <data key="d5">Community summaries are created for each graph community detected. These summaries are domain-tailored and specifically designed to encapsulate the characteristics and dynamics of graph communities within the Graph RAG approach. This method ensures that each community's unique structure and interactions are comprehensively understood and effectively communicated.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="LEIDEN ALGORITHM">
      <data key="d4">9.0</data>
      <data key="d5">The Leiden algorithm is used to detect graph communities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="FORTUNATO, 2010">
      <data key="d4">6.0</data>
      <data key="d5">Fortunato authored a survey on community detection algorithms, which are used to detect graph communities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="JIN ET AL., 2021">
      <data key="d4">6.0</data>
      <data key="d5">Jin et al. authored a survey on community detection algorithms, which are used to detect graph communities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="COMMUNITY ANSWERS">
      <data key="d4">12.0</data>
      <data key="d5">Community answers are partial responses generated from community summaries in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="LEAF-LEVEL COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are generated from leaf-level communities by prioritizing and adding element summaries to the LLM context window.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="HIGHER-LEVEL COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are generated from higher-level communities by summarizing element summaries or using sub-community summaries.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are used to generate the global answer for a user query.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="LLM CONTEXT WINDOW">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are added to the LLM context window until the token limit is reached.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="INTERMEDIATE ANSWERS">
      <data key="d4">9.0</data>
      <data key="d5">Intermediate answers are generated from chunks of community summaries.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="ROOT-LEVEL SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Root-level summaries are a type of community summary requiring fewer tokens per query.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Intermediate-level summaries are a type of community summary providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="LOW-LEVEL SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Low-level summaries are a type of community summary providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="MAP-REDUCE SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Map-reduce summarization is compared to community summaries in terms of resource intensity and token count.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY ANSWERS" target="GLOBAL ANSWER">
      <data key="d4">12.0</data>
      <data key="d5">The global answer is the final response generated from summarizing all community answers in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="USER QUERY">
      <data key="d4">9.0</data>
      <data key="d5">The global answer is generated in response to a user query.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="INDEXING TIME" target="PIPELINE STAGE">
      <data key="d4">12.0</data>
      <data key="d5">Indexing time is a pipeline stage in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="QUERY TIME" target="PIPELINE STAGE">
      <data key="d4">12.0</data>
      <data key="d5">Query time is a pipeline stage in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="SENSEMAKING" target="EVALUATION">
      <data key="d4">7.0</data>
      <data key="d5">Sensemaking activities are evaluated using specific metrics.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GPT" target="LLMS">
      <data key="d4">8.0</data>
      <data key="d5">GPT is a series of LLMs capable of in-context learning for summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GPT" target="ACHIAM ET AL., 2023">
      <data key="d4">8.0</data>
      <data key="d5">Achiam et al. have contributed to the development of the GPT series.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GPT" target="BROWN ET AL., 2020">
      <data key="d4">8.0</data>
      <data key="d5">Brown et al. have contributed to the development of the GPT series.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GPT" target="FOUNDATION MODELS (FMS)">
      <data key="d4">7.0</data>
      <data key="d5">GPT is an example of a Foundation Model used for agentic tasks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="GPT" target="OPENAI">
      <data key="d4">15.0</data>
      <data key="d5">OpenAI is the organization that developed the GPT Foundation Model.GPT is a Foundation Model developed by OpenAI.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="LLAMA" target="LLMS">
      <data key="d4">8.0</data>
      <data key="d5">Llama is a series of LLMs capable of in-context learning for summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLAMA" target="TOUVRON ET AL., 2023">
      <data key="d4">8.0</data>
      <data key="d5">Touvron et al. have contributed to the development of the Llama series.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GEMINI" target="LLMS">
      <data key="d4">8.0</data>
      <data key="d5">Gemini is a series of LLMs capable of in-context learning for summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GEMINI" target="ANIL ET AL., 2023">
      <data key="d4">8.0</data>
      <data key="d5">Anil et al. have contributed to the development of the Gemini series.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GEMINI" target="J. B. ALAYRAC">
      <data key="d4">6.0</data>
      <data key="d5">J. B. Alayrac is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="R. ANIL">
      <data key="d4">6.0</data>
      <data key="d5">R. Anil is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="S. BORGEAUD">
      <data key="d4">6.0</data>
      <data key="d5">S. Borgeaud is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="Y. WU">
      <data key="d4">6.0</data>
      <data key="d5">Y. Wu is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="R. SORICUT">
      <data key="d4">6.0</data>
      <data key="d5">R. Soricut is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="J. SCHALKWYK">
      <data key="d4">6.0</data>
      <data key="d5">J. Schalkwyk is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="A. M. DAI">
      <data key="d4">6.0</data>
      <data key="d5">A. M. Dai is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="A. HAUTH">
      <data key="d4">6.0</data>
      <data key="d5">A. Hauth is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="SUMMARIZATION TASKS" target="LLMS">
      <data key="d4">9.0</data>
      <data key="d5">Modern LLMs trivialize summarization tasks by using in-context learning.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="SUMMARIZATION TASKS" target="GOODWIN ET AL., 2020">
      <data key="d4">7.0</data>
      <data key="d5">Goodwin et al. have contributed to the state-of-the-art in summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="SUMMARIZATION TASKS" target="LASKAR ET AL., 2022">
      <data key="d4">7.0</data>
      <data key="d5">Laskar et al. have contributed to the state-of-the-art in summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="SUMMARIZATION TASKS" target="LIU AND LAPATA, 2019">
      <data key="d4">7.0</data>
      <data key="d5">Liu and Lapata have contributed to the state-of-the-art in summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLMS" target="KURATOV ET AL., 2024">
      <data key="d4">7.0</data>
      <data key="d5">Kuratov et al. have studied the limitations of LLM context windows.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLMS" target="LIU ET AL., 2023">
      <data key="d4">7.0</data>
      <data key="d5">Liu et al. have studied the limitations of LLM context windows.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLMS" target="SYNTHETIC DATA">
      <data key="d4">8.0</data>
      <data key="d5">Synthetic data is used to accelerate the development of Large Language Models (LLMs).</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="NA&#207;VE RAG">
      <data key="d4">7.0</data>
      <data key="d5">Na&#239;ve RAG is likely inadequate for query-focused abstractive summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="GLOBAL SUMMARIZATION">
      <data key="d4">6.0</data>
      <data key="d5">Global summarization is an alternative to query-focused abstractive summarization.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="LOUVAIN">
      <data key="d4">7.0</data>
      <data key="d5">Louvain is a community detection algorithm used to partition graphs into modular communities.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="MAP-REDUCE" target="TEXT SUMMARIZATION (TS)">
      <data key="d4">7.0</data>
      <data key="d5">The map-reduce method is used in text summarization (TS) to process source texts.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="HOTPOTQA" target="RAG SYSTEMS">
      <data key="d4">6.0</data>
      <data key="d5">HotPotQA is a benchmark dataset used to evaluate RAG systems for open-domain question answering.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="HOTPOTQA" target="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d4">12.0</data>
      <data key="d5">HotPotQA is a benchmark used to empirically evaluate the performance of LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="HOTPOTQA" target="LATS">
      <data key="d4">46.0</data>
      <data key="d5">LATS is evaluated using the HotPotQA benchmark to test its performance in question-answering tasks that require reasoning over multiple documents. It demonstrates its effectiveness in decision-making and reasoning tasks, doubling the performance of ReAct on HotPotQA when used with GPT-3.5. The evaluation also considers both cost and performance, highlighting LATS's efficiency and capability in handling complex queries.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HOTPOTQA" target="YANG ET AL., 2018">
      <data key="d4">6.0</data>
      <data key="d5">Yang et al. are the authors of the HotPotQA benchmark, published in 2018.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HOTPOTQA" target="REFLEXION">
      <data key="d4">7.0</data>
      <data key="d5">Reflexion is evaluated using the HotPotQA benchmark, with performance scores reported.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HOTPOTQA" target="TOT">
      <data key="d4">7.0</data>
      <data key="d5">ToT is evaluated using the HotPotQA benchmark for cost and performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="HOTPOTQA" target="RAP">
      <data key="d4">7.0</data>
      <data key="d5">RAP is evaluated using the HotPotQA benchmark for cost and performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="HOTPOTQA" target="REACT">
      <data key="d4">7.0</data>
      <data key="d5">ReAct is evaluated on the HotPotQA dataset to test its performance in question-answering tasks that require reasoning over multiple documents.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="CROWDWORKERS">
      <data key="d4">7.0</data>
      <data key="d5">Crowdworkers are individuals who contributed to the creation of the HotPotQA dataset by crafting diverse, multi-hop, and explainable question-answer pairs.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="SUPPORTING FACTS">
      <data key="d4">7.0</data>
      <data key="d5">Supporting facts are pieces of information provided in the HotPotQA dataset that justify the answers to the questions.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="WIKIPEDIA PARAGRAPHS">
      <data key="d4">7.0</data>
      <data key="d5">Wikipedia paragraphs are the text segments used in the HotPotQA dataset to provide the necessary information for answering the questions.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="EM (EXACT MATCH)">
      <data key="d4">1.0</data>
      <data key="d5">EM (Exact Match) is a performance metric used to evaluate the accuracy of answers in the HotPotQA dataset.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">HotPotQA tasks are guided by specific prompts that include Thought, Action, and Observation steps.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ENTITY EXTRACTION" target="FEW-SHOT EXAMPLES">
      <data key="d4">7.0</data>
      <data key="d5">Few-shot examples are used to tailor the entity extraction prompt to the domain of the document corpus.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ENTITY EXTRACTION" target="GLEANINGS">
      <data key="d4">1.0</data>
      <data key="d5">Gleanings are used to improve the performance of entity extraction.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS" target="COMPREHENSIVENESS">
      <data key="d4">6.0</data>
      <data key="d5">Comprehensiveness is a target quality for evaluating activity-centered sense-making questions.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS" target="DIVERSITY">
      <data key="d4">6.0</data>
      <data key="d5">Diversity is a target quality for evaluating activity-centered sense-making questions.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS" target="EMPOWERMENT">
      <data key="d4">6.0</data>
      <data key="d5">Empowerment is a target quality for evaluating activity-centered sense-making questions.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS" target="PODCAST TRANSCRIPTS">
      <data key="d4">7.0</data>
      <data key="d5">Podcast transcripts are used to generate activity-centered sense-making questions.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS" target="NEWS ARTICLES">
      <data key="d4">7.0</data>
      <data key="d5">News articles are used to generate activity-centered sense-making questions.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="LLM EVALUATOR">
      <data key="d4">8.0</data>
      <data key="d5">The LLM Evaluator assesses answers based on the comprehensiveness metric.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="WIN RATE">
      <data key="d4">7.0</data>
      <data key="d5">Win rate is used to evaluate the performance of different summarization approaches in terms of comprehensiveness.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIVERSITY" target="LLM EVALUATOR">
      <data key="d4">8.0</data>
      <data key="d5">The LLM Evaluator assesses answers based on the diversity metric.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DIVERSITY" target="WIN RATE">
      <data key="d4">7.0</data>
      <data key="d5">Win rate is used to evaluate the performance of different summarization approaches in terms of diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="EMPOWERMENT" target="LLM EVALUATOR">
      <data key="d4">8.0</data>
      <data key="d5">The LLM Evaluator assesses answers based on the empowerment metric.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EMPOWERMENT" target="WIN RATE">
      <data key="d4">7.0</data>
      <data key="d5">Win rate is used to evaluate the performance of different summarization approaches in terms of empowerment.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="PODCASTS">
      <data key="d4">7.0</data>
      <data key="d5">Podcasts are a source of podcast transcripts used in the evaluation of the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TECH JOURNALIST">
      <data key="d4">6.0</data>
      <data key="d5">Podcast transcripts are used by tech journalists to gain insights and trends in the tech industry.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="KEVIN SCOTT">
      <data key="d4">7.0</data>
      <data key="d5">Kevin Scott is a participant in the podcast transcripts dataset.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TECHNOLOGY LEADERS">
      <data key="d4">7.0</data>
      <data key="d5">Technology leaders are participants in the podcast transcripts dataset.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="MEDIA COVERAGE">
      <data key="d4">14.0</data>
      <data key="d5">Podcast transcripts are a form of media coverage that provide written records of spoken content.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="NEWS ARTICLES" target="NEW YORK TIMES">
      <data key="d4">7.0</data>
      <data key="d5">The New York Times is a source of news articles used in the evaluation of the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="NEWS ARTICLES" target="EDUCATOR">
      <data key="d4">6.0</data>
      <data key="d5">News articles are used by educators to incorporate current affairs into curricula.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NEWS ARTICLES" target="MULTIHOP-RAG">
      <data key="d4">7.0</data>
      <data key="d5">MultiHop-RAG is a benchmark dataset used for evaluating news articles.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NEWS ARTICLES" target="MEDIA COVERAGE">
      <data key="d4">16.0</data>
      <data key="d5">News articles are a form of media coverage that report on public figures and current events.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="BROWN ET AL., 2020" target="LANGUAGE MODELS (LMS)">
      <data key="d4">10.0</data>
      <data key="d5">Brown et al. are the authors of a significant paper on language models, published in 2020.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="TOUVRON ET AL., 2023" target="LANGUAGE MODELS (LMS)">
      <data key="d4">10.0</data>
      <data key="d5">Touvron et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="KURATOV ET AL., 2024" target="CONTEXT WINDOW SIZE">
      <data key="d4">6.0</data>
      <data key="d5">Kuratov et al. studied the potential for information to be "lost in the middle" of longer contexts.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LIU ET AL., 2023" target="CONTEXT WINDOW SIZE">
      <data key="d4">6.0</data>
      <data key="d5">Liu et al. studied the potential for information to be "lost in the middle" of longer contexts.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LIU ET AL., 2023" target="SEARCH APPROACHES">
      <data key="d4">12.0</data>
      <data key="d5">Liu et al. are the authors mentioned in relation to previous search approaches using LMs as world models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LIU ET AL., 2023" target="SEARCH SPACE">
      <data key="d4">6.0</data>
      <data key="d5">Liu et al. explored search spaces using feed-forward networks within ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LIU ET AL., 2023" target="DYLAN">
      <data key="d4">12.0</data>
      <data key="d5">Liu et al. are the authors of the DyLAN algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="DIRECTNESS">
      <data key="d4">16.0</data>
      <data key="d5">Na&#239;ve RAG provides a direct and specific list of public figures frequently mentioned in media.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="GAO ET AL., 2023">
      <data key="d4">7.0</data>
      <data key="d5">Gao et al. are researchers who have contributed to the development of Na&#239;ve RAG.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GLEANINGS" target="LOGIT BIAS">
      <data key="d4">7.0</data>
      <data key="d5">Logit bias is used during the gleanings process to ensure all entities are detected.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GLEANINGS" target="NOISE">
      <data key="d4">6.0</data>
      <data key="d5">The gleanings process aims to minimize noise while ensuring all entities are detected.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="NAMED ENTITIES" target="DEFAULT PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">The default prompt is used to extract named entities from text documents.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COVARIATES" target="SECONDARY EXTRACTION PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">The secondary extraction prompt is used to extract covariates associated with detected entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COVARIATES" target="LEAF-LEVEL COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Covariates are described and prioritized in leaf-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LEIDEN ALGORITHM" target="TRAAG ET AL., 2019">
      <data key="d4">7.0</data>
      <data key="d5">Traag et al. are the authors of the Leiden algorithm.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEIDEN ALGORITHM" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d4">8.0</data>
      <data key="d5">The Leiden algorithm is used to detect hierarchical community structures in large-scale graphs.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="OPENORD">
      <data key="d4">7.0</data>
      <data key="d5">OpenORD is used for node layout in visualizing the MultiHop-RAG dataset.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="FORCE ATLAS 2">
      <data key="d4">7.0</data>
      <data key="d5">Force Atlas 2 is used for node layout in visualizing the MultiHop-RAG dataset.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="TANG AND YANG, 2024">
      <data key="d4">12.0</data>
      <data key="d5">Tang and Yang are the authors of the MultiHop-RAG benchmark dataset. They also indexed the MultiHop-RAG dataset, ensuring its comprehensive organization and accessibility for further research and analysis.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="TANG, Y.">
      <data key="d4">8.0</data>
      <data key="d5">Tang, Y. is one of the authors of the paper titled "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="YANG, Y.">
      <data key="d4">8.0</data>
      <data key="d5">Yang, Y. is one of the authors of the paper titled "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="OPENORD" target="MARTIN ET AL., 2011">
      <data key="d4">6.0</data>
      <data key="d5">Martin et al. are the authors of the OpenORD tool.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="FORCE ATLAS 2" target="JACOMY ET AL., 2014">
      <data key="d4">1.0</data>
      <data key="d5">Jacomy et al. are the authors of the Force Atlas 2 tool.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="ROOT COMMUNITIES">
      <data key="d4">7.0</data>
      <data key="d5">Root communities represent the highest level of modularity in a hierarchical community structure.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="SUB-COMMUNITIES">
      <data key="d4">7.0</data>
      <data key="d5">Sub-communities reveal internal structure within root-level communities in a hierarchical community structure.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="LEAF-LEVEL COMMUNITIES">
      <data key="d4">7.0</data>
      <data key="d5">Leaf-level communities are the smallest units in a hierarchical community structure.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="NODE DEGREE">
      <data key="d4">1.0</data>
      <data key="d5">Node degree is used to prioritize elements in leaf-level communities during the summarization process.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="ROOT-LEVEL COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Leaf-level communities are the lowest hierarchical level within root-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="NODES">
      <data key="d4">8.0</data>
      <data key="d5">Nodes are described and prioritized in leaf-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="EDGES">
      <data key="d4">8.0</data>
      <data key="d5">Edges are described and prioritized in leaf-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="ROOT-LEVEL COMMUNITIES" target="HIGHER-LEVEL COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Higher-level communities are above leaf-level communities in the hierarchy within root-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="USER QUERY" target="TECH JOURNALIST">
      <data key="d4">7.0</data>
      <data key="d5">A tech journalist poses user queries related to tech policy and regulation.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="USER QUERY" target="EDUCATOR">
      <data key="d4">7.0</data>
      <data key="d5">An educator poses user queries related to health and wellness.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="MT-BENCH" target="RAG SYSTEMS">
      <data key="d4">6.0</data>
      <data key="d5">MT-Bench is a benchmark dataset used to evaluate RAG systems for open-domain question answering.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="MT-BENCH" target="ZHENG ET AL., 2024">
      <data key="d4">1.0</data>
      <data key="d5">Zheng et al. are the authors of the MT-Bench benchmark dataset.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="MT-BENCH" target="ORCA-3">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 scored 8.20 on the MT-Bench benchmark, a 9% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MT-BENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">MT-Bench is a benchmark used to evaluate open-ended generation tasks by scoring each turn's response using GPT-4.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="RAG SYSTEMS" target="KOESTEN ET AL., 2021">
      <data key="d4">5.0</data>
      <data key="d5">Koesten et al. discussed the process of data sensemaking, which is relevant to the evaluation of RAG systems.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="RAG SYSTEMS" target="XU AND LAPATA, 2021">
      <data key="d4">1.0</data>
      <data key="d5">Xu and Lapata developed methods for extracting latent summarization queries, which are relevant to the evaluation of RAG systems.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NODES" target="LATS">
      <data key="d4">14.0</data>
      <data key="d5">LATS, an algorithmic framework, utilizes nodes to store and retrieve external feedback during its search process. These nodes are expanded as part of the exploration phase within LATS, playing a crucial role in the algorithm's ability to efficiently navigate and process information.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="NODES" target="TRAJECTORIES">
      <data key="d4">7.0</data>
      <data key="d5">Nodes and trajectories are components of the search process in algorithms like LATS.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="NODES" target="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d4">7.0</data>
      <data key="d5">Nodes are components in the LATS algorithm that are stored explicitly in memory and expanded during the search process.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOKEN LIMIT" target="LLM CONTEXT WINDOW">
      <data key="d4">9.0</data>
      <data key="d5">The token limit determines how many tokens can be included in the LLM context window.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="INTERMEDIATE ANSWERS" target="HELPFULNESS SCORE">
      <data key="d4">9.0</data>
      <data key="d5">Intermediate answers are scored for helpfulness using the helpfulness score metric.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="ZHENG ET AL., 2024" target="LLM EVALUATOR">
      <data key="d4">6.0</data>
      <data key="d5">Zheng et al. have demonstrated the effectiveness of LLMs in head-to-head comparisons.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DATASET" target="ACTIVITY-CENTERED APPROACH">
      <data key="d4">7.0</data>
      <data key="d5">The activity-centered approach is used to automate the generation of questions based on the dataset.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DATASET" target="ORCA-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Orca-Bench is a dataset used for training and evaluating models.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="USER" target="TASK">
      <data key="d4">7.0</data>
      <data key="d5">Users perform specific tasks involving interaction with the dataset or system.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="USER" target="SEARCH FOOD ITEMS">
      <data key="d4">8.0</data>
      <data key="d5">The user can search for food items using the "Search Food Items" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="GET FOOD ITEM DETAILS">
      <data key="d4">8.0</data>
      <data key="d5">The user can retrieve detailed information about a specific food item using the "Get Food Item Details" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="CREATE MEAL PLAN">
      <data key="d4">9.0</data>
      <data key="d5">The user can create a meal plan based on their dietary preferences and goals using the "Create Meal Plan" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="UPDATE FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The user can update the details of an existing food item using the "Update Food Item" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="TRACK USER MEAL">
      <data key="d4">8.0</data>
      <data key="d5">The user can track their daily meals using the "Track User Meal" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="GET DIETARY RECOMMENDATIONS">
      <data key="d4">8.0</data>
      <data key="d5">The user can get dietary recommendations based on their preferences and goals using the "Get Dietary Recommendations" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="ADD NEW FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The user can add a new food item to the database using the "Add New Food Item" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="DELETE FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The user can delete a food item from the database using the "Delete Food Item" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="GET USER NUTRITIONAL STATS">
      <data key="d4">8.0</data>
      <data key="d5">The user can get their nutritional statistics using the "Get User Nutritional Stats" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="ASSISTANT">
      <data key="d4">1.0</data>
      <data key="d5">The user interacts with the assistant to achieve their desired outcomes, such as creating a meal plan and tracking meals.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="QUINOA SALAD">
      <data key="d4">8.0</data>
      <data key="d5">The user wants to add the Quinoa Salad recipe to the database.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="CHANA MASALA">
      <data key="d4">8.0</data>
      <data key="d5">The user wants to update the calorie count for Chana Masala.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="BUTTER CHICKEN">
      <data key="d4">8.0</data>
      <data key="d5">The user wants to remove Butter Chicken from the database.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="TASK" target="QUESTION">
      <data key="d4">7.0</data>
      <data key="d5">Tasks often involve generating or answering questions related to the dataset.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TASK" target="ANSWER">
      <data key="d4">7.0</data>
      <data key="d5">An answer is the result or solution provided by an agent after performing a task.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="TASK" target="META AGENT SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search programs new agents to solve specific tasks.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="QUESTION" target="N">
      <data key="d4">6.0</data>
      <data key="d5">The variable N represents the number of questions generated per (user, task) combination.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="QUESTION" target="EVALUATION">
      <data key="d4">7.0</data>
      <data key="d5">Evaluation involves assessing the questions generated to understand the dataset.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="QUESTION" target="ARTHUR'S MAGAZINE">
      <data key="d4">6.0</data>
      <data key="d5">Arthur's Magazine is part of a question in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="QUESTION" target="FIRST FOR WOMEN">
      <data key="d4">6.0</data>
      <data key="d5">First for Women is part of a question in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="QUESTION" target="STUDENT RESPONSE">
      <data key="d4">7.0</data>
      <data key="d5">The student response is provided in answer to a question.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="QUESTION" target="OPTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The question is accompanied by a list of options for the student to choose from.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="TEXT SUMMARIZATION (TS)" target="CONTEXT WINDOW">
      <data key="d4">8.0</data>
      <data key="d5">Text Summarization (TS) uses a context window to generate answers, with the size being consistent across conditions.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="SEMANTIC SEARCH (SS)" target="CONTEXT WINDOW">
      <data key="d4">8.0</data>
      <data key="d5">Semantic Search (SS) uses a context window to generate answers, with the size being consistent across conditions.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="PODCAST DATASET">
      <data key="d4">6.0</data>
      <data key="d5">The Podcast dataset uses a context window size of 600 tokens and 1 gleaning.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="NEWS DATASET">
      <data key="d4">6.0</data>
      <data key="d5">The News dataset uses a context window size of 600 tokens and 0 gleanings.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="ANSWER GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Answer generation is influenced by the size of the context window used.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="RELATIONSHIP" target="ALEX">
      <data key="d4">8.0</data>
      <data key="d5">Alex is already in a relationship, which complicates Elliot's confession.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="PODCAST DATASET" target="GLEANING">
      <data key="d4">6.0</data>
      <data key="d5">The Podcast dataset uses 1 gleaning in its context window size.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PODCAST DATASET" target="NAIVE RAG">
      <data key="d4">7.0</data>
      <data key="d5">Naive RAG is used as a baseline to evaluate the comprehensiveness and diversity of answers in the Podcast dataset.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="NEWS DATASET" target="GLEANING">
      <data key="d4">6.0</data>
      <data key="d5">The News dataset uses 0 gleanings in its context window size.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="NEWS DATASET" target="NAIVE RAG">
      <data key="d4">7.0</data>
      <data key="d5">Naive RAG is used as a baseline to evaluate the comprehensiveness and diversity of answers in the News dataset.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIRECTNESS" target="LLM EVALUATOR">
      <data key="d4">8.0</data>
      <data key="d5">The LLM Evaluator assesses answers based on the directness metric.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DIRECTNESS" target="NAIVE RAG">
      <data key="d4">7.0</data>
      <data key="d5">Naive RAG produces the most direct responses across all comparisons.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LLM EVALUATOR" target="WANG ET AL., 2023A">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. have shown that LLMs can achieve state-of-the-art results in evaluation.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ENTERTAINMENT INDUSTRY">
      <data key="d4">19.0</data>
      <data key="d5">Public figures are repeatedly mentioned in entertainment articles, reflecting their impact on the industry. They contribute significantly to the entertainment industry through their work and influence, shaping trends and public perceptions. Their presence in media highlights their pivotal role in driving the dynamics and interactions within the entertainment community.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="MEDIA COVERAGE">
      <data key="d4">18.0</data>
      <data key="d5">Public figures are frequently covered in media due to their high-profile status and public interest.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="CULTURAL NARRATIVES">
      <data key="d4">16.0</data>
      <data key="d5">Public figures shape cultural narratives through their influence in various entertainment sectors.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="CONTROVERSIES">
      <data key="d4">16.0</data>
      <data key="d5">Public figures often become central figures in controversies, attracting widespread attention.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="PROMINENT PUBLIC FIGURES">
      <data key="d4">1.0</data>
      <data key="d5">Prominent public figures are repeatedly mentioned in entertainment articles, reflecting their influence in the industry.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="MEDIA COVERAGE">
      <data key="d4">2.0</data>
      <data key="d5">The entertainment industry is frequently covered in media due to its cultural and economic impact.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="EVALUATION" target="RAGAS">
      <data key="d4">7.0</data>
      <data key="d5">RAGAS is used to automatically evaluate the performance of RAG systems.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION" target="HEAD-TO-HEAD COMPARISON">
      <data key="d4">7.0</data>
      <data key="d5">Head-to-head comparison is used to evaluate competing outputs.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">Evaluation is the third operation in the LATS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="EVALUATION" target="META AGENT SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search involves the evaluation of discovered agents on validation and test sets.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="ANSWER GENERATION" target="PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">Prompts are used to guide the LLM in generating answers.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PROMPT" target="THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">The prompt includes Thought steps for reasoning about the current situation.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PROMPT" target="ACTION">
      <data key="d4">7.0</data>
      <data key="d5">The prompt includes Action steps for performing operations like searching for an entity or finishing with an answer.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PROMPT" target="OBSERVATION">
      <data key="d4">7.0</data>
      <data key="d5">The prompt includes Observation steps that provide feedback based on the Action performed.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PROMPT" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses prompts to guide the programming of new agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="PROMPT" target="META AGENT">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent uses the prompt to guide its thought process, design, and implementation of the next function or agent architecture.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="PROMPT" target="RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">The response is generated by the model in reaction to the prompt during training.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="RAGAS" target="ES ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Es et al. have contributed to the development of RAGAS for evaluating RAG systems.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="RAGAS" target="ES, S.">
      <data key="d4">9.0</data>
      <data key="d5">Es, S. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RAGAS" target="JAMES, J.">
      <data key="d4">9.0</data>
      <data key="d5">James, J. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RAGAS" target="ESPINOSA-ANKE, L.">
      <data key="d4">9.0</data>
      <data key="d5">Espinosa-Anke, L. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RAGAS" target="SCHOCKAERT, S.">
      <data key="d4">9.0</data>
      <data key="d5">Schockaert, S. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="WANG ET AL., 2023A" target="EMBODIED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. are the authors who contributed to the development of new skills for embodied agents, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="TAYLOR SWIFT" target="MEDIA COVERAGE">
      <data key="d4">18.0</data>
      <data key="d5">Taylor Swift is frequently mentioned in media coverage due to her professional achievements and personal life.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="TRAVIS KELCE" target="MEDIA COVERAGE">
      <data key="d4">18.0</data>
      <data key="d5">Travis Kelce is frequently mentioned in media coverage due to his sports achievements and personal life.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="MEDIA COVERAGE">
      <data key="d4">18.0</data>
      <data key="d5">Britney Spears is frequently mentioned in media coverage due to her professional achievements and personal life.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="MEDIA COVERAGE">
      <data key="d4">18.0</data>
      <data key="d5">Justin Timberlake is frequently mentioned in media coverage due to his professional achievements and personal life.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="CONTEXT WINDOW SIZE" target="GPT-4-TURBO">
      <data key="d4">7.0</data>
      <data key="d5">The context window size is tested on GPT-4-Turbo to explore its effects on comprehensiveness, diversity, and empowerment.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="CONTEXT WINDOW SIZE" target="SS">
      <data key="d4">7.0</data>
      <data key="d5">SS is used as a baseline condition to determine the optimum context window size for query-time LLM use.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="MAP-REDUCE SUMMARIZATION" target="CONTEXT TOKENS">
      <data key="d4">1.0</data>
      <data key="d5">Map-reduce summarization is compared to community summaries in terms of context tokens, with the former requiring more tokens.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GAO ET AL., 2023" target="LANGUAGE MODELS (LMS)">
      <data key="d4">10.0</data>
      <data key="d5">Gao et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="GAO ET AL., 2023" target="GSM-HARD">
      <data key="d4">15.0</data>
      <data key="d5">Gao et al. are the authors of the GSM-Hard dataset, which was published in 2023. This dataset is used to evaluate the transferability of discovered agents and serves as a benchmark for math tasks.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="GAO ET AL., 2023" target="GSM-HARD (GAO ET AL., 2023)">
      <data key="d4">6.0</data>
      <data key="d5">Gao et al. are the authors of the GSM-Hard benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="WANG ET AL., 2024" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">1.0</data>
      <data key="d5">Wang et al. are cited in the paper for contributions to the research on agentic systems and their applications.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="WANG ET AL., 2024" target="META AGENT SEARCH">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. are the authors of the study discussing the effectiveness of Meta Agent Search.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="CAIRE-COVID" target="SU, D.">
      <data key="d4">16.0</data>
      <data key="d5">CAIRE-COVID is a question answering and query-focused multi-document summarization system designed for COVID-19 scholarly information management. One of the authors who contributed to the development of CAIRE-COVID is Su, D., who co-authored the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="CAIRE-COVID" target="XU, Y.">
      <data key="d4">16.0</data>
      <data key="d5">CAIRE-COVID is a question answering and query-focused multi-document summarization system designed for COVID-19 scholarly information management. Xu, Y. is one of the authors who contributed to the development of CAIRE-COVID and co-authored the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="CAIRE-COVID" target="YU, T.">
      <data key="d4">16.0</data>
      <data key="d5">Yu, T. is one of the authors who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization system designed for COVID-19 scholarly information management. Yu, T. co-authored the paper titled "CAIRE-COVID: A Question Answering and Query-Focused Multi-Document Summarization System for COVID-19 Scholarly Information Management," which details the system's capabilities and contributions to managing and synthesizing vast amounts of COVID-19 related research.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="CAIRE-COVID" target="SIDDIQUE, F. B.">
      <data key="d4">16.0</data>
      <data key="d5">Siddique, F. B. is one of the authors of the paper titled "CAIRE-COVID: A Question Answering and Query-Focused Multi-Document Summarization System for COVID-19 Scholarly Information Management." Siddique, F. B. also contributed to the development of CAIRE-COVID, a system designed to manage and summarize COVID-19 scholarly information through advanced question answering and multi-document summarization techniques.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="CAIRE-COVID" target="BAREZI, E. J.">
      <data key="d4">16.0</data>
      <data key="d5">Barezi, E. J. is one of the authors of the paper titled "CAIRE-COVID: A Question Answering and Query-Focused Multi-Document Summarization System for COVID-19 Scholarly Information Management." Barezi, E. J. also contributed to the development of CAIRE-COVID, a system designed to manage COVID-19 scholarly information through advanced question answering and summarization techniques.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="CAIRE-COVID" target="FUNG, P.">
      <data key="d4">9.0</data>
      <data key="d5">CAIRE-COVID is a question answering and query-focused multi-document summarization system designed for managing COVID-19 scholarly information. One of the key contributors to the development of CAIRE-COVID is Fung, P., who co-authored the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management." This system aims to facilitate the efficient handling and summarization of vast amounts of COVID-19 related research, providing valuable insights and streamlined access to critical information.</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="YAO ET AL., 2023" target="CHAIN-OF-THOUGHT">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are cited in the paper for contributions to the research on chain-of-thought planning and reasoning.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="YAO ET AL., 2023" target="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors who contributed to the development of chain-of-thought-based planning and reasoning methods, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="WANG ET AL., 2023B" target="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)">
      <data key="d4">12.0</data>
      <data key="d5">Wang et al. are the authors and researchers who developed the Self-Consistency with Chain-of-Thought (COT-SC) algorithm in 2023.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="WANG ET AL., 2023B" target="COT-SC">
      <data key="d4">19.0</data>
      <data key="d5">Wang et al. are the authors of the COT-SC algorithm, which was published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="WANG ET AL., 2023B" target="COT-SC (WANG ET AL., 2023B)">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. are the authors of the COT-SC algorithm.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="LANGCHAIN" target="SEARCH SPACE">
      <data key="d4">7.0</data>
      <data key="d5">LangChain is an open-source agent framework that can be used within the code search space of ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LANGCHAIN" target="SEARCH ENGINE TOOLS">
      <data key="d4">7.0</data>
      <data key="d5">Search engine tools are components that can be used within the LangChain framework to enhance agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LANGCHAIN" target="ADAS">
      <data key="d4">12.0</data>
      <data key="d5">LangChain is an existing agent framework that can be used as a building block in ADAS to support multi-modal capabilities and flexible use of different foundational models.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="LANGCHAIN" target="LANGCHAINAI, 2022">
      <data key="d4">10.0</data>
      <data key="d5">LangChainAI is an organization that has worked on the LangChain framework, relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NEO4J" target="NALLM">
      <data key="d4">6.0</data>
      <data key="d5">NaLLM uses Neo4J for knowledge graph creation and reasoning.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="NEBULAGRAPH" target="GRAPHRAG">
      <data key="d4">1.0</data>
      <data key="d5">GraphRAG uses NebulaGraph for knowledge graph creation and reasoning.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="QUERY" target="WEB SHOP">
      <data key="d4">8.0</data>
      <data key="d5">The web shop allows users to enter queries to search for specific products.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="TABLE 3" target="ORCA-3">
      <data key="d4">6.0</data>
      <data key="d5">Table 3 presents the performance of Orca-3 on various benchmarks.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="TABLE 3" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">6.0</data>
      <data key="d5">Table 3 shows the relative improvements of other models over Mistral-7b-Instruct.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="TABLE 3" target="APPENDIX B">
      <data key="d4">5.0</data>
      <data key="d5">Appendix B specifies the methods used to extract answers and generate metrics shown in Table 3.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="SELF CHECK GPT" target="FABRICATION RATES">
      <data key="d4">7.0</data>
      <data key="d5">SelfCheckGPT is used to compare fabrication rates in generated content.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH-BASED RAG APPLICATIONS" target="KNOWLEDGE GRAPHS">
      <data key="d4">8.0</data>
      <data key="d5">Graph-based RAG applications create and reason over knowledge graphs.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="PYTHON" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">Python is used in the implementation of ADAS algorithms.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="J. ACHIAM" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">J. Achiam is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="S. ADLER" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">S. Adler is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="S. AGARWAL" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">S. Agarwal is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="L. AHMAD" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">L. Ahmad is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="I. AKKAYA" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">I. Akkaya is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="F. L. ALEMAN" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">F. L. Aleman is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="D. ALMEIDA" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">D. Almeida is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="J. ALTENSCHMIDT" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">J. Altenschmidt is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="S. ALTMAN" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">S. Altman is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="S. ANADKAT" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">S. Anadkat is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="J. BAEK" target="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">J. Baek is one of the authors of the knowledge-augmented language model prompting report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="A. F. AJI" target="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">A. F. Aji is one of the authors of the knowledge-augmented language model prompting report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="A. SAFFARI" target="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">A. Saffari is one of the authors of the knowledge-augmented language model prompting report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="T. BAN" target="HARNESSING LARGE LANGUAGE MODELS FOR CAUSAL DISCOVERY">
      <data key="d4">6.0</data>
      <data key="d5">T. Ban is one of the authors of the report on harnessing large language models for causal discovery.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="L. CHEN" target="HARNESSING LARGE LANGUAGE MODELS FOR CAUSAL DISCOVERY">
      <data key="d4">6.0</data>
      <data key="d5">L. Chen is one of the authors of the report on harnessing large language models for causal discovery.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GPT-4" target="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses GPT-4 to achieve state-of-the-art pass@1 accuracy for programming on HumanEval.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="GPT-4" target="LATS">
      <data key="d4">9.0</data>
      <data key="d5">LATS, when used with GPT-4, achieves a 92.7 Pass@1 rate on HumanEval, setting the state of the art.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="GPT-4" target="HUMANEVAL">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used in experiments with the HumanEval dataset.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-4" target="INTERNAL TESTS">
      <data key="d4">6.0</data>
      <data key="d5">GPT-4 is evaluated using internal tests.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-4" target="META AGENT SEARCH">
      <data key="d4">25.0</data>
      <data key="d5">Meta Agent Search leverages GPT-4 as the meta agent to discover high-performance agents. It transfers discovered agents from GPT-3.5 to GPT-4, resulting in a significant improvement in accuracy rates on ARC tasks. This process highlights the advanced capabilities of GPT-4 in enhancing the performance and accuracy of agent-based searches.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-4" target="OPENAI">
      <data key="d4">9.0</data>
      <data key="d5">OpenAI is the organization that developed GPT-4.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-4" target="ARC">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used to evaluate the performance of agents on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="GPT-4" target="ARC-AGI">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 achieved 50% SOTA on ARC-AGI as discussed in a technical report by Ryan Greenblatt.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="GPT-4" target="AGENTINSTRUCT">
      <data key="d4">16.0</data>
      <data key="d5">AgentInstruct achieved a reduction in hallucinations while maintaining a quality level comparable to GPT-4. Additionally, AgentInstruct leverages GPT-4 to generate high-quality data for teaching AI models. This dual approach not only enhances the reliability of the outputs but also ensures that the instructional data is of superior quality, benefiting the overall training and performance of AI systems.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="GPT-4" target="ORCA-BENCH">
      <data key="d4">18.0</data>
      <data key="d5">GPT-4 is used as the benchmark model in the ORCA-BENCH dataset, scoring a perfect 10. The performance of other models on the ORCA-BENCH dataset is evaluated relative to GPT-4, establishing it as the standard for comparison within this dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GPT-4" target="LSAT">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4's performance is used as a benchmark for evaluating the reading comprehension capabilities of other models on the LSAT.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPT-4" target="ORCA-3">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3's performance on certain tasks, such as reading comprehension, matches that of GPT-4.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="ACI-BENCH">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used as an evaluator for summarization abilities on the ACI-Bench dataset.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="INSTRUSUM">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used as an evaluator for summarization abilities on the InstruSum dataset.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="ORCA-SUM">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used as an evaluator for summarization abilities on the Orca-Sum dataset.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MMLU-MED">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is evaluated on the MMLU-Med dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MEDQA-US">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is evaluated on the MedQA-US dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MEDMCQA">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is evaluated on the MedMCQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="PUBMEDQA">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is evaluated on the PubMedQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="BIOASQ">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4 is evaluated on the BioASQ dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="PROMPTS">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used to generate prompts for evaluating summarization abilities in the Orca-Sum benchmark.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MIRAGE">
      <data key="d4">9.0</data>
      <data key="d5">GPT-4 is evaluated on the MIRAGE datasets, showing high performance in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="AZURE">
      <data key="d4">7.0</data>
      <data key="d5">Azure provides transparency notes and content moderation services for GPT-4.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="MULTIPLE CHOICE QUESTIONS">
      <data key="d4">10.0</data>
      <data key="d5">GPT-4 is used for extracting the option selected by the model from its response in multiple choice questions.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="GPT-4" target="VERSION 0613">
      <data key="d4">7.0</data>
      <data key="d5">Version 0613 of GPT-4 is used in the FOFO and AlpacaEval benchmarks.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="VERSION 1106-PREVIEW">
      <data key="d4">7.0</data>
      <data key="d5">Version 1106-preview of GPT-4 is used in the InfoBench benchmark.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="JUDGE">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 acts as a judge in various benchmarks like FOFO, MT-Bench, AlpacaEval, and InfoBench.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="BLONDEL, V. D." target="FAST UNFOLDING OF COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Blondel, V. D. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GUILLAUME, J.-L." target="FAST UNFOLDING OF COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Guillaume, J.-L. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LAMBIOTTE, R." target="FAST UNFOLDING OF COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Lambiotte, R. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LEFEBVRE, E." target="FAST UNFOLDING OF COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Lefebvre, E. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="FAST UNFOLDING OF COMMUNITIES" target="JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT">
      <data key="d4">8.0</data>
      <data key="d5">The paper on fast unfolding of communities in large networks was published in the Journal of Statistical Mechanics: Theory and Experiment.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Brown, T. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="MANN, B." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Mann, B. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RYDER, N." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Ryder, N. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SUBBIAH, M." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Subbiah, M. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KAPLAN, J. D." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Kaplan, J. D. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DHARIWAL, P." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Dhariwal, P. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="NEELAKANTAN, A." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Neelakantan, A. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SHYAM, P." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Shyam, P. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SASTRY, G." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Sastry, G. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="ASKELL, A." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Askell, A. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LANGUAGE MODELS ARE FEW-SHOT LEARNERS" target="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">The paper on language models being few-shot learners was published in Advances in Neural Information Processing Systems.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS" target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">8.0</data>
      <data key="d5">The paper on retrieval-augmented text generation with self-memory was published in Advances in Neural Information Processing Systems.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="CHENG, X." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Cheng, X. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LUO, D." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Luo, D. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="CHEN, X." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Chen, X. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LIU, L." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Liu, L. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="ZHAO, D." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Zhao, D. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="YAN, R." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Yan, R. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DANG, H. T." target="EVALUATION OF QUESTION-FOCUSED SUMMARIZATION SYSTEMS">
      <data key="d4">9.0</data>
      <data key="d5">Dang, H. T. is the author of the paper on the evaluation of question-focused summarization systems.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DUC 2005" target="EVALUATION OF QUESTION-FOCUSED SUMMARIZATION SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">The paper on the evaluation of question-focused summarization systems was presented at the DUC 2005 conference.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="FENG, Z." target="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d4">9.0</data>
      <data key="d5">Feng, Z. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="FENG, X." target="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d4">9.0</data>
      <data key="d5">Feng, X. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="YANG, M." target="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d4">9.0</data>
      <data key="d5">Yang, M. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="QIN, B." target="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d4">9.0</data>
      <data key="d5">Qin, B. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="FORTUNATO, S." target="COMMUNITY DETECTION IN GRAPHS">
      <data key="d4">9.0</data>
      <data key="d5">Fortunato, S. is the author of the paper on community detection in graphs.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="COMMUNITY DETECTION IN GRAPHS" target="PHYSICS REPORTS">
      <data key="d4">8.0</data>
      <data key="d5">The paper on community detection in graphs was published in Physics Reports.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GAO, Y." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Gao, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="XIONG, Y." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Xiong, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GAO, X." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Gao, X. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="JIA, K." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Jia, K. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="PAN, J." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Pan, J. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BI, Y." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Bi, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DAI, Y." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Dai, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="CHEN, W." target="ENHANCING RETRIEVAL-AUGMENTED LARGE LANGUAGE MODELS WITH ITERATIVE RETRIEVAL-GENERATION SYNERGY">
      <data key="d4">8.0</data>
      <data key="d5">Chen, W. is one of the authors of the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="DUAN, N." target="ENHANCING RETRIEVAL-AUGMENTED LARGE LANGUAGE MODELS WITH ITERATIVE RETRIEVAL-GENERATION SYNERGY">
      <data key="d4">8.0</data>
      <data key="d5">Duan, N. is one of the authors of the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TOUVRON, H." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Touvron, H. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="MARTIN, L." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Martin, L. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="STONE, K." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Stone, K. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ALBERT, P." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Albert, P. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ALMAHAIRI, A." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Almahairi, A. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BABAEI, Y." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Babaei, Y. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BASHLYKOV, N." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Bashlykov, N. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BATRA, S." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Batra, S. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BHARGAVA, P." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Bhargava, P. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BHOSALE, S." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Bhosale, S. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TRAAG, V. A." target="FROM LOUVAIN TO LEIDEN: GUARANTEEING WELL-CONNECTED COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Traag, V. A. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WALTMAN, L." target="FROM LOUVAIN TO LEIDEN: GUARANTEEING WELL-CONNECTED COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Waltman, L. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="VAN ECK, N. J." target="FROM LOUVAIN TO LEIDEN: GUARANTEEING WELL-CONNECTED COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Van Eck, N. J. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TRAJANOSKA, M." target="ENHANCING KNOWLEDGE GRAPH CONSTRUCTION USING LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Trajanoska, M. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="STOJANOV, R." target="ENHANCING KNOWLEDGE GRAPH CONSTRUCTION USING LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Stojanov, R. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TRAJANOV, D." target="ENHANCING KNOWLEDGE GRAPH CONSTRUCTION USING LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Trajanov, D. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TRIVEDI, H." target="INTERLEAVING RETRIEVAL WITH CHAIN-OF-THOUGHT REASONING FOR KNOWLEDGE-INTENSIVE MULTI-STEP QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Trivedi, H. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BALASUBRAMANIAN, N." target="INTERLEAVING RETRIEVAL WITH CHAIN-OF-THOUGHT REASONING FOR KNOWLEDGE-INTENSIVE MULTI-STEP QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Balasubramanian, N. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KHOT, T." target="INTERLEAVING RETRIEVAL WITH CHAIN-OF-THOUGHT REASONING FOR KNOWLEDGE-INTENSIVE MULTI-STEP QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Khot, T. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SABHARWAL, A." target="INTERLEAVING RETRIEVAL WITH CHAIN-OF-THOUGHT REASONING FOR KNOWLEDGE-INTENSIVE MULTI-STEP QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Sabharwal, A. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, J." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Wang, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LIANG, Y." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Liang, Y. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="MENG, F." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Meng, F. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SUN, Z." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Sun, Z. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SHI, H." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Shi, H. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LI, Z." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Li, Z. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="XU, J." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Xu, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="QU, J." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Qu, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ZHOU, J." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Zhou, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, S." target="FEB4RAG">
      <data key="d4">8.0</data>
      <data key="d5">Wang, S. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KHRAMTSOVA, E." target="FEB4RAG">
      <data key="d4">8.0</data>
      <data key="d5">Khramtsova, E. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ZHUANG, S." target="FEB4RAG">
      <data key="d4">8.0</data>
      <data key="d5">Zhuang, S. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ZUCCON, G." target="FEB4RAG">
      <data key="d4">8.0</data>
      <data key="d5">Zuccon, G. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, Y." target="KNOWLEDGE GRAPH PROMPTING FOR MULTI-DOCUMENT QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Wang, Y. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LIPKA, N." target="KNOWLEDGE GRAPH PROMPTING FOR MULTI-DOCUMENT QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Lipka, N. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ROSSI, R. A." target="KNOWLEDGE GRAPH PROMPTING FOR MULTI-DOCUMENT QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Rossi, R. A. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SIU, A." target="KNOWLEDGE GRAPH PROMPTING FOR MULTI-DOCUMENT QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Siu, A. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">18.0</data>
      <data key="d5">LATS leverages the in-context learning ability of language models for reasoning, acting, and planning.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MONTE CARLO TREE SEARCH (MCTS)">
      <data key="d4">16.0</data>
      <data key="d5">LATS integrates Monte Carlo Tree Search to enable language models as agents.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="EXTERNAL FEEDBACK">
      <data key="d4">16.0</data>
      <data key="d5">LATS incorporates external feedback to offer a more deliberate and adaptive problem-solving mechanism.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PROGRAMMING">
      <data key="d4">14.0</data>
      <data key="d5">LATS has been experimentally evaluated in the domain of programming, achieving state-of-the-art pass@1 accuracy.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="INTERACTIVE QUESTION-ANSWERING (QA)">
      <data key="d4">14.0</data>
      <data key="d5">LATS has been validated for its effectiveness in the domain of interactive question-answering.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="WEB NAVIGATION">
      <data key="d4">14.0</data>
      <data key="d5">LATS demonstrates gradient-free performance in the domain of web navigation.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MATH">
      <data key="d4">14.0</data>
      <data key="d5">LATS has been experimentally evaluated in the domain of math, validating its effectiveness.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GPT-3.5">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses GPT-3.5 to demonstrate gradient-free performance for web navigation on WebShop.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="HUMANEVAL">
      <data key="d4">16.0</data>
      <data key="d5">LATS achieves state-of-the-art pass@1 accuracy for programming on HumanEval.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="WEB SHOP">
      <data key="d4">14.0</data>
      <data key="d5">LATS demonstrates gradient-free performance for web navigation on WebShop.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="ANDY ZHOU">
      <data key="d4">12.0</data>
      <data key="d5">Andy Zhou is one of the authors of the paper introducing LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="REACT">
      <data key="d4">14.0</data>
      <data key="d5">LATS expands ReAct into a search over a combinatorial space of possible reasoning and acting steps.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PSEUDOCODE">
      <data key="d4">8.0</data>
      <data key="d5">The pseudocode of the LATS algorithm is shown in Sec. A of the appendix.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="EXPLORATION WEIGHT">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm uses an exploration weight parameter that affects the effectiveness of the search.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SELF-CONSISTENCY WEIGHT">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm uses a self-consistency weight parameter that affects the consistency of the search results.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="COMPUTATIONAL COST">
      <data key="d4">8.0</data>
      <data key="d5">The LATS algorithm has a higher computational cost compared to simpler prompting methods like ReAct or Reflexion.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SAMPLE COMPLEXITY">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm has the same sample complexity as ToT and RAP but achieves better performance.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="ENVIRONMENT REVERSION">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm requires environment reversion for decision-making tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="API-BASED TOOLS">
      <data key="d4">6.0</data>
      <data key="d5">API-based tools are used in LM-based environments and are mentioned as being inexpensive and fast to use in the context of LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="TEXT-BASED MANIPULATION TASKS">
      <data key="d4">6.0</data>
      <data key="d5">Text-based manipulation tasks are a type of task evaluated using environments like Alfworld, mentioned in the context of LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="ROLLBACKS">
      <data key="d4">6.0</data>
      <data key="d5">Rollbacks are a feature that allows reverting to previous states in an environment, mentioned as a limitation for some environments in the context of LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="RESOURCE CONSTRAINTS">
      <data key="d4">6.0</data>
      <data key="d5">Resource constraints are limitations that can affect the design and implementation of the LATS algorithm in various environments.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PLANNING-BASED PROMPTING METHODS">
      <data key="d4">7.0</data>
      <data key="d5">LATS is a planning-based prompting method used for reasoning and decision-making in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="ADDITIONAL ABLATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Additional ablations are experiments conducted to analyze various designs of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="TRAJECTORIES">
      <data key="d4">6.0</data>
      <data key="d5">Trajectories are paths or sequences of states and actions evaluated in the LATS algorithm during experiments.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SAMPLING SIZE">
      <data key="d4">6.0</data>
      <data key="d5">Sampling size is a parameter in the LATS algorithm that affects the number of samples taken during the search process.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="TAB. 8">
      <data key="d4">6.0</data>
      <data key="d5">Tab. 8 shows the results of experiments conducted on HotPotQA using the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="FIG. 3">
      <data key="d4">6.0</data>
      <data key="d5">Fig. 3 shows the results of experiments conducted on HumanEval using the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="TAB. 9">
      <data key="d4">6.0</data>
      <data key="d5">Tab. 9 provides a full analysis of the computational cost of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. A">
      <data key="d4">6.0</data>
      <data key="d5">Sec. A shows the pseudocode of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. B">
      <data key="d4">6.0</data>
      <data key="d5">Sec. B provides further discussion of the limitations of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. C">
      <data key="d4">6.0</data>
      <data key="d5">Sec. C presents additional experimental results of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. D">
      <data key="d4">6.0</data>
      <data key="d5">Sec. D specifies the environment details in the experiments conducted using the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. E">
      <data key="d4">6.0</data>
      <data key="d5">Sec. E lists the prompts used for the HotPotQA environment in the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. F">
      <data key="d4">6.0</data>
      <data key="d5">Sec. F lists the prompts used for the Programming environment in the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. G">
      <data key="d4">6.0</data>
      <data key="d5">Sec. G lists the prompts used for the WebShop environment in the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GAME OF 24">
      <data key="d4">6.0</data>
      <data key="d5">The LATS algorithm uses a self-consistency weight of 0.5 for the Game of 24 task.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PROMPTS">
      <data key="d4">6.0</data>
      <data key="d5">Prompts are inputs used in the LATS algorithm for different environments like HotPotQA, Programming, and WebShop.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="CHOWDHERY ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Chowdhery et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="OPENAI, 2023">
      <data key="d4">10.0</data>
      <data key="d5">OpenAI is an organization that has published significant research on language models in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="NALLAPATI ET AL., 2016">
      <data key="d4">10.0</data>
      <data key="d5">Nallapati et al. are the authors of a significant paper on summarization, published in 2016.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="BOWMAN ET AL., 2015">
      <data key="d4">10.0</data>
      <data key="d5">Bowman et al. are the authors of a significant paper on language inference, published in 2015.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="COBBE ET AL., 2021">
      <data key="d4">10.0</data>
      <data key="d5">Cobbe et al. are the authors of a significant paper on language models, published in 2021.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SAPAROV AND HE, 2023">
      <data key="d4">10.0</data>
      <data key="d5">Saparov and He are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="YAO ET AL., 2022">
      <data key="d4">10.0</data>
      <data key="d5">Yao et al. are the authors of a significant paper on web navigation, published in 2022.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="DENG ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Deng et al. are the authors of a significant paper on web navigation, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SCHICK ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Schick et al. are the authors of a significant paper on tool-use, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="FAN ET AL., 2022">
      <data key="d4">10.0</data>
      <data key="d5">Fan et al. are the authors of a significant paper on open-ended games, published in 2022.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SHINN ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Shinn et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SLOMAN, 1996">
      <data key="d4">10.0</data>
      <data key="d5">Sloman is the author of a significant paper on decision-making, published in 1996.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="EVANS, 2010">
      <data key="d4">10.0</data>
      <data key="d5">Evans is the author of a significant paper on decision-making, published in 2010.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="XIE ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Xie et al. are the authors of a significant paper on search-guided language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="YAO ET AL., 2023A">
      <data key="d4">10.0</data>
      <data key="d5">Yao et al. are the authors of a significant paper on search-guided language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="HAO ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Hao et al. are the authors of a significant paper on search-guided language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="WOOLDRIDGE AND JENNINGS, 1995">
      <data key="d4">2.0</data>
      <data key="d5">Wooldridge and Jennings are the authors of a significant paper on autonomous agents, published in 1995.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="LATS">
      <data key="d4">9.0</data>
      <data key="d5">LATS adapts Monte Carlo Tree Search (MCTS) to enhance language model performance.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="REASONING VIA PLANNING (RAP)">
      <data key="d4">7.0</data>
      <data key="d5">RAP uses MCTS with rollouts simulated by language models for reasoning tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="SILVER ET AL., 2017">
      <data key="d4">6.0</data>
      <data key="d5">Silver et al. are researchers known for their work in model-based reinforcement learning, published in 2017.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)">
      <data key="d4">9.0</data>
      <data key="d5">UCT is used in MCTS to select the best child node for expansion based on a combination of exploration and exploitation.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="YE ET AL., 2021">
      <data key="d4">6.0</data>
      <data key="d5">Ye et al. demonstrated the success of MCTS in decision-making environments like Atari.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="SILVER ET AL., 2016">
      <data key="d4">6.0</data>
      <data key="d5">Silver et al. demonstrated the success of MCTS in decision-making environments like Go.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="RETURN R">
      <data key="d4">8.0</data>
      <data key="d5">Return r is used for updating the value function V(s) in MCTS during backpropagation.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="VALUE FUNCTION V(S)">
      <data key="d4">8.0</data>
      <data key="d5">Value function V(s) is used to guide the search process in MCTS.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="BACKPROPAGATION">
      <data key="d4">8.0</data>
      <data key="d5">Backpropagation is used in MCTS to update the value function V(s) along the path.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="EPISODES">
      <data key="d4">1.0</data>
      <data key="d5">MCTS runs for multiple episodes to expand and update the decision tree.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="EXTERNAL FEEDBACK" target="LATS">
      <data key="d4">49.0</data>
      <data key="d5">LATS incorporates external feedback to enhance its decision-making, problem-solving, reasoning, and overall performance. This integration of external feedback ensures that LATS continuously evolves and adapts, leading to more informed and effective outcomes.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="EXTERNAL FEEDBACK" target="HUANG ET AL., 2024">
      <data key="d4">8.0</data>
      <data key="d5">Huang et al. suggested that external feedback is critical for language models to self-correct their internal reasoning.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="PROGRAMMING" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">LATS is recommended for difficult tasks like programming.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="PROGRAMMING" target="HUMANEVAL">
      <data key="d4">8.0</data>
      <data key="d5">HumanEval is a dataset used to evaluate programming tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="PROGRAMMING" target="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d4">8.0</data>
      <data key="d5">MBPP is a dataset used to evaluate programming tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="INTERACTIVE QUESTION-ANSWERING (QA)" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">LATS enhances performance in interactive question-answering tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WEB NAVIGATION" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">LATS improves performance in web navigation tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MATH" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">LATS demonstrates versatility by enhancing performance in mathematical problem-solving.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MATH" target="MGSM">
      <data key="d4">8.0</data>
      <data key="d5">The MGSM benchmark is used to evaluate math capabilities.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="MATH" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search is effective in the Math domain where foundational models possess adequate knowledge.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="MATH" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct generates data to teach AI models the skill of math.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="MATH" target="ORCA-3">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3's performance is evaluated on mathematical problem-solving capabilities.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MATH" target="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d4">6.0</data>
      <data key="d5">Open Domain Question Answering is used to generate math problems for evaluating AI models.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MATH" target="MULTIPLE-CHOICE QUESTIONS FLOWS">
      <data key="d4">6.0</data>
      <data key="d5">Multiple-Choice Questions Flows is used to generate math problems for evaluating AI models.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MATH" target="BBH">
      <data key="d4">7.0</data>
      <data key="d5">BBH is a benchmark used to evaluate AI models on multi-step arithmetic problems.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-3.5" target="LATS">
      <data key="d4">25.0</data>
      <data key="d5">LATS, when used with GPT-3.5, achieves the highest performance for programming tasks. It significantly improves performance in tasks such as WebShop, Game of 24, and HotPotQA.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="GPT-3.5" target="REACT">
      <data key="d4">6.0</data>
      <data key="d5">ReAct is used with GPT-3.5 to evaluate performance in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="GPT-3.5" target="REFLEXION">
      <data key="d4">6.0</data>
      <data key="d5">Reflexion is used with GPT-3.5 to evaluate performance in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="GPT-3.5" target="GAME OF 24">
      <data key="d4">14.0</data>
      <data key="d5">The Game of 24 is used to evaluate the reasoning ability of GPT-3.5 with various algorithms. This evaluation is conducted using the GPT-3.5 language model, highlighting its capacity to process and solve complex problems through algorithmic reasoning.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="GPT-3.5" target="HOT POT QA">
      <data key="d4">6.0</data>
      <data key="d5">HotPotQA is used to evaluate the performance of GPT-3.5 with various algorithms.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="GPT-3.5" target="FINE-TUNING">
      <data key="d4">6.0</data>
      <data key="d5">Fine-tuning is used to improve the performance of GPT-3.5 in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="GPT-3.5" target="HUMANEVAL">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5 is used in experiments with the HumanEval dataset.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-3.5" target="INTERNAL TESTS">
      <data key="d4">6.0</data>
      <data key="d5">GPT-3.5 is evaluated using internal tests.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-3.5" target="META AGENT SEARCH">
      <data key="d4">23.0</data>
      <data key="d5">Meta Agent Search leverages GPT-3.5 to evaluate discovered agents and baselines, significantly reducing compute costs. Additionally, Meta Agent Search transfers these discovered agents from GPT-3.5 to GPT-4, resulting in a notable improvement in accuracy rates on ARC tasks. This process highlights the efficiency and effectiveness of using GPT-3.5 for initial evaluations before upgrading to the more advanced GPT-4 for enhanced performance.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-3.5" target="OPENAI">
      <data key="d4">9.0</data>
      <data key="d5">OpenAI is the organization that developed GPT-3.5.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-3.5" target="ARC">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5 is used to evaluate the performance of agents on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="GPT-3.5" target="OPENAI, 2022">
      <data key="d4">6.0</data>
      <data key="d5">OpenAI is the organization that developed GPT-3.5.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="GPT-3.5" target="ADAS">
      <data key="d4">14.0</data>
      <data key="d5">GPT-3.5 involves a complex feedback mechanism, which is relevant to the study of ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="GPT-3.5" target="ORCA-3">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 outperformed GPT-3.5 on multiple benchmarks.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="HUMANEVAL" target="LATS">
      <data key="d4">40.0</data>
      <data key="d5">LATS achieves a 92.7 Pass@1 rate on HumanEval when used with GPT-4, setting the state of the art. It is evaluated on the HumanEval benchmark to test its performance in reasoning and programming tasks, validating its effectiveness in these areas.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="REFLEXION">
      <data key="d4">7.0</data>
      <data key="d5">Reflexion is evaluated using the HumanEval benchmark, with performance scores reported.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HUMANEVAL" target="CHEN ET AL., 2021">
      <data key="d4">18.0</data>
      <data key="d5">Chen et al. are the authors of the HumanEval benchmark, which was published in 2021. The HumanEval benchmark is a significant contribution to the field, providing a structured framework for evaluating the performance of various algorithms. This benchmark, authored by Chen et al., is instrumental in assessing the capabilities and effectiveness of algorithmic solutions, ensuring a comprehensive understanding of their dynamics and interactions within the community.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HUMANEVAL" target="EXPERT">
      <data key="d4">7.0</data>
      <data key="d5">Expert performance is used as a benchmark for comparison in HumanEval.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HUMANEVAL" target="BASELINE">
      <data key="d4">7.0</data>
      <data key="d5">Baseline performance is used as a reference for evaluating new methods on the HumanEval benchmark.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HUMANEVAL" target="REACT">
      <data key="d4">7.0</data>
      <data key="d5">ReAct is evaluated on the HumanEval benchmark to test its performance in reasoning and programming tasks.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HUMANEVAL" target="NATURAL LANGUAGE DESCRIPTIONS">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval uses natural language descriptions to describe programming tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="FUNCTION SIGNATURE">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval includes function signatures as part of the programming problems.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="DOCSTRING DESCRIPTION">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval includes docstring descriptions as part of the programming problems.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="REFERENCE IMPLEMENTATION">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval includes reference implementations as part of the programming problems.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="UNIT TESTS">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval includes unit tests to verify the correctness of solutions.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="PASS@K METRIC">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval uses the pass@k metric to evaluate the success rate of solutions.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="PROGRAMMING PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval is a benchmark used to evaluate the performance of programming tasks.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="HUMANEVAL" target="MINSUBARRAYSUM">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval is a benchmark used to evaluate the performance of the minSubArraySum function.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="HUMANEVAL" target="QUESTION-ANSWERING TASK">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval is a benchmark used to evaluate the performance of question-answering tasks.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="WEB SHOP" target="LATS">
      <data key="d4">16.0</data>
      <data key="d5">LATS, when applied within the WebShop environment, demonstrates significant effectiveness in complex decision-making tasks. It not only improves both the score and success rate (SR) but also raises the average score by 22.1 points when used in conjunction with GPT-3.5. This indicates that LATS is a powerful tool for enhancing performance in the WebShop setting.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WEB SHOP" target="REACT">
      <data key="d4">6.0</data>
      <data key="d5">ReAct is used to evaluate performance in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="REFLEXION">
      <data key="d4">6.0</data>
      <data key="d5">Reflexion is used to evaluate performance in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="IL+RL">
      <data key="d4">7.0</data>
      <data key="d5">IL+RL is used to train agents in the WebShop environment, evaluated for its performance in comparison to other methods.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="EXPERT">
      <data key="d4">7.0</data>
      <data key="d5">Expert performance is used as a benchmark to compare the effectiveness of algorithms in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="SUCCESS RATE (SR)">
      <data key="d4">8.0</data>
      <data key="d5">The Success Rate (SR) is a key performance metric used to evaluate algorithms within the WebShop environment. It serves as one of the primary evaluation metrics in WebShop, providing a measure of the effectiveness and efficiency of the algorithms implemented.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="AVERAGE SCORE">
      <data key="d4">7.0</data>
      <data key="d5">Average score is used as a performance metric to evaluate algorithms in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="BROWSER FEEDBACK">
      <data key="d4">6.0</data>
      <data key="d5">Browser feedback is used by agents to make decisions in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="SEARCH AND CLICK COMMANDS">
      <data key="d4">6.0</data>
      <data key="d5">Search and click commands are actions used by agents to navigate the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="PRECONSTRUCTED ACTION SPACE">
      <data key="d4">6.0</data>
      <data key="d5">Preconstructed action space refers to the predefined set of actions available to agents in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="YA0 ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors of the WebShop environment.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="TASK SCORE">
      <data key="d4">7.0</data>
      <data key="d5">Task Score is one of the evaluation metrics used in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="HTML MODE">
      <data key="d4">6.0</data>
      <data key="d5">HTML mode is a rendering mode in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="SIMPLE MODE">
      <data key="d4">6.0</data>
      <data key="d5">Simple mode is a rendering mode in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="QUERY SEARCHES">
      <data key="d4">7.0</data>
      <data key="d5">Query searches are actions in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="BUTTON CLICKS">
      <data key="d4">7.0</data>
      <data key="d5">Button clicks are actions in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="LEXICAL MATCHING">
      <data key="d4">6.0</data>
      <data key="d5">Lexical matching is a method used in WebShop to compare products.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="SEMANTIC SIMILARITY METRICS">
      <data key="d4">6.0</data>
      <data key="d5">Semantic similarity metrics are methods used in WebShop to compare products.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="EPISODE">
      <data key="d4">6.0</data>
      <data key="d5">An episode is a complete interaction session in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="SEARCH PAGE">
      <data key="d4">6.0</data>
      <data key="d5">The search page is a component of WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="RESULTS PAGE">
      <data key="d4">6.0</data>
      <data key="d5">The results page is a component of WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="ITEM PAGE">
      <data key="d4">6.0</data>
      <data key="d5">The item page is a component of WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="ITEM DETAIL PAGE">
      <data key="d4">1.0</data>
      <data key="d5">The item detail page is a component of WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">The web shop returns a list of results in response to a user's query.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="DAIRY FREE">
      <data key="d4">24.0</data>
      <data key="d5">The web shop allows users to search for products with specific attributes like being dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="WEB SHOP" target="APPLE VARIETY PACK OF CHIPS">
      <data key="d4">24.0</data>
      <data key="d5">The web shop allows users to search for specific products like an apple variety pack of chips</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="WEB SHOP" target="PRICE LOWER THAN 30.00 DOLLARS">
      <data key="d4">24.0</data>
      <data key="d5">The web shop allows users to set price constraints for their searches</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="WEB SHOP" target="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON">
      <data key="d4">16.0</data>
      <data key="d5">The web shop allows users to search for specific products like gluten-free vegetarian smoked peppered bacon</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="WEB SHOP" target="PRICE LOWER THAN 40.00 DOLLARS">
      <data key="d4">16.0</data>
      <data key="d5">The web shop allows users to set price constraints for their searches</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="WEB SHOP" target="SEARCH">
      <data key="d4">18.0</data>
      <data key="d5">The user performs a search action on the web shop</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="WEB SHOP" target="THINK">
      <data key="d4">16.0</data>
      <data key="d5">The user reflects on the suitability of products found on the web shop</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="WEB SHOP" target="CLICK">
      <data key="d4">18.0</data>
      <data key="d5">The user clicks on products or options on the web shop</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="WEB SHOP" target="REFLECTION">
      <data key="d4">9.0</data>
      <data key="d5">The user reflects on their previous actions and outcomes to improve future searches on the web shop</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ANDY ZHOU" target="UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN">
      <data key="d4">12.0</data>
      <data key="d5">Andy Zhou is affiliated with the University of Illinois Urbana-Champaign.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="ANDY ZHOU" target="LAPIS LABS">
      <data key="d4">12.0</data>
      <data key="d5">Andy Zhou is affiliated with Lapis Labs.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="REACT" target="YA0 ET AL., 2023B">
      <data key="d4">42.0</data>
      <data key="d5">Yao et al. are the researchers who developed the ReAct algorithm, which was published in 2023.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="LATS">
      <data key="d4">38.0</data>
      <data key="d5">LATS is compared to REACT in terms of computational cost, efficiency, performance, sample complexity, and token consumption. LATS outperforms REACT on benchmarks like HotPotQA and WebShop. It surpasses REACT by expanding more nodes with principled search and incorporating external feedback. Additionally, LATS uses REACT as a base prompt in various experiments, demonstrating improved performance over REACT alone.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="REACT" target="YAO ET AL., 2023B">
      <data key="d4">12.0</data>
      <data key="d5">Yao et al. are the authors of the ReAct algorithm, also referred to as the ReAct method, which was published in 2023.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="REACT" target="ACTING-BASED PROMPTING">
      <data key="d4">7.0</data>
      <data key="d5">ReAct is an example of acting-based prompting used in language models.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="REACT" target="COT">
      <data key="d4">14.0</data>
      <data key="d5">ReAct and CoT are both prompting techniques used for reasoning tasks in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="REFLEXION">
      <data key="d4">7.0</data>
      <data key="d5">Both ReAct and Reflexion focus on decision-making tasks where reverting between iterations is feasible.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="LANGUAGE MODELS (LM)">
      <data key="d4">8.0</data>
      <data key="d5">ReAct is a technique used to extend the capabilities of language models to tasks requiring interactions with an external environment.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="ENVIRONMENTAL FEEDBACK">
      <data key="d4">9.0</data>
      <data key="d5">ReAct uses observations from the environment to improve reasoning and acting.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">ReAct is used for decision-making tasks that require interactions with an external environment.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="WEI ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Wei et al. are the authors of the ReAct method, published in 2022.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="REACT" target="ACTING-BASED METHODS">
      <data key="d4">8.0</data>
      <data key="d5">ReAct is an acting-based method that combines reasoning and acting for better performance.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="REACT" target="HOT POT QA">
      <data key="d4">6.0</data>
      <data key="d5">ReAct is used as a base prompt in HotPotQA experiments.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="REACT" target="YAO ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors of studies involving the ReAct algorithm.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="REACT" target="TOT">
      <data key="d4">7.0</data>
      <data key="d5">ToT is a variant of ReAct used for reasoning, acting, and planning in language models.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="REACT" target="COT-SC">
      <data key="d4">6.0</data>
      <data key="d5">ReAct and CoT-SC are both methods evaluated for performance, sample complexity, and token consumption.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="REACT" target="PROMPTING TECHNIQUES">
      <data key="d4">7.0</data>
      <data key="d5">ReAct is a type of prompting technique used for language models.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="OPENAI, 2023" target="DROP">
      <data key="d4">7.0</data>
      <data key="d5">OpenAI is mentioned in the context of the practice followed for one-shot style questions in DROP.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="COBBE ET AL., 2021" target="CHAIN-OF-THOUGHT (COT) PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">Cobbe et al. are researchers who have contributed to the understanding of reasoning in language models, published in 2021.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="COBBE ET AL., 2021" target="GSM8K">
      <data key="d4">20.0</data>
      <data key="d5">Cobbe et al. are the authors of the GSM8K dataset, which was published in 2021. This dataset is used to evaluate the transferability of discovered agents and serves as a benchmark for math tasks.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="COBBE ET AL., 2021" target="GSM8K (COBBE ET AL., 2021)">
      <data key="d4">6.0</data>
      <data key="d5">Cobbe et al. are the authors of the GSM8K benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="YAO ET AL., 2022" target="IL+RL">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors of studies involving the IL+RL method.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="SCHICK ET AL., 2023" target="EXTERNAL TOOLS">
      <data key="d4">7.0</data>
      <data key="d5">Schick et al. contributed to the development of external tools for language models in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="SCHICK ET AL., 2023" target="TOOL USE">
      <data key="d4">12.0</data>
      <data key="d5">Schick et al., 2023, are recognized for their significant contributions to the research on tool use in agentic systems. They are the authors who developed innovative tool use techniques, which were published in 2023. Their work is cited in the paper for advancing the understanding and application of tool use within these systems, highlighting their pivotal role in this area of study.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="FAN ET AL., 2022" target="MINECRAFT">
      <data key="d4">6.0</data>
      <data key="d5">Fan et al. are researchers who have worked on complex multimodal games like Minecraft, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SHINN ET AL., 2023" target="REFLEXION">
      <data key="d4">36.0</data>
      <data key="d5">Shinn et al. are researchers who developed and authored the Reflexion algorithm, which was published in 2023.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SHINN ET AL., 2023" target="SELF-REFLECTION">
      <data key="d4">7.0</data>
      <data key="d5">Shinn et al., 2023, are recognized for their significant contributions to the research on self-reflection in agentic systems. Their work has been instrumental in enhancing the process of self-reflection, which is crucial for developing novel and error-free agents.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHINN ET AL., 2023" target="SELF-REFINE">
      <data key="d4">13.0</data>
      <data key="d5">Shinn et al., 2023, are the researchers who authored and contributed to the development of the Self-Refine algorithm. This method, also referred to as the Self-Refine strategy, is utilized in Meta Agent Search.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="SHINN ET AL., 2023" target="REFLECTION">
      <data key="d4">6.0</data>
      <data key="d5">Shinn et al. are the authors who contributed to the development of reflection techniques, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="YAO ET AL., 2023A" target="TOT">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors of the ToT method, published in 2023.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HAO ET AL., 2023" target="REASONING VIA PLANNING (RAP)">
      <data key="d4">6.0</data>
      <data key="d5">Hao et al. are researchers who have developed reasoning via planning (RAP) using MCTS, published in 2023.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HAO ET AL., 2023" target="RAP">
      <data key="d4">15.0</data>
      <data key="d5">Hao et al. are the authors of the RAP algorithm, which was developed and published in 2023.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SELF-REFLECTION">
      <data key="d4">47.0</data>
      <data key="d5">LATS incorporates self-reflection to enhance its decision-making, problem-solving, and reasoning capabilities. By using self-reflection, LATS provides additional semantic signals, which significantly improve its performance in reasoning tasks. This integration of self-reflection allows LATS to refine its processes and outcomes, ensuring more accurate and effective results.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SELF-CONSISTENCY">
      <data key="d4">7.0</data>
      <data key="d5">LATS uses self-consistency to enhance performance by employing majority voting over sampled chains.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SEARCH ALGORITHMS">
      <data key="d4">9.0</data>
      <data key="d5">LATS adapts search algorithms to enhance language model performance.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="PROMPTS">
      <data key="d4">8.0</data>
      <data key="d5">LATS uses prompts to guide the generation of responses and store external feedback.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="VALUE FUNCTION">
      <data key="d4">23.0</data>
      <data key="d5">LATS employs a novel value function as a central component to guide its search process and leverage external feedback. This value function is designed to incorporate successful heuristics and self-consistency, which significantly contributes to LATS's superior performance in reasoning tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="SELF-REFINEMENT">
      <data key="d4">8.0</data>
      <data key="d5">LATS uses self-refinement to improve performance by learning from its own outputs.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="INTERNAL REASONING PERFORMANCE">
      <data key="d4">7.0</data>
      <data key="d5">LATS aims to surpass internal reasoning performance by incorporating external feedback.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="MODEL-BASED REINFORCEMENT LEARNING">
      <data key="d4">7.0</data>
      <data key="d5">LATS is inspired by the success of model-based reinforcement learning techniques.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="IN-CONTEXT LEARNING">
      <data key="d4">36.0</data>
      <data key="d5">LATS leverages the in-context learning abilities and capabilities of modern language models. This approach allows LATS to utilize the advanced features of language models to understand and process information within the context it is provided, enhancing its performance and accuracy in various applications.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="AUTONOMOUS REASONING">
      <data key="d4">8.0</data>
      <data key="d5">LATS enhances the autonomous reasoning capabilities of language models.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="DECISION-MAKING">
      <data key="d4">9.0</data>
      <data key="d5">LATS improves decision-making in language models by incorporating reasoning, acting, and planning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="TEXT-BASED ENVIRONMENTS">
      <data key="d4">7.0</data>
      <data key="d5">LATS enhances performance in text-based environments.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="TREE-BASED SEARCH">
      <data key="d4">16.0</data>
      <data key="d5">LATS operates on a tree-based framework to unlock the potential of language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="OURS">
      <data key="d4">12.0</data>
      <data key="d5">Ours refers to the authors of the Language Agent Tree Search (LATS) algorithm.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="REASONING">
      <data key="d4">54.0</data>
      <data key="d5">LATS unifies reasoning, acting, and planning in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="ACTING">
      <data key="d4">54.0</data>
      <data key="d5">LATS unifies reasoning, acting, and planning in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="PLANNING">
      <data key="d4">54.0</data>
      <data key="d5">LATS unifies reasoning, acting, and planning in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="EXTERNAL MEMORY">
      <data key="d4">28.0</data>
      <data key="d5">LATS uses external memory to store past text context for future updates of the solution.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="SEARCH ALGORITHM">
      <data key="d4">32.0</data>
      <data key="d5">LATS uses a search algorithm to determine a sequence of actions or decisions.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="LANGUAGE MODELS (LM)">
      <data key="d4">8.0</data>
      <data key="d5">LATS is a technique developed to address the shortcomings of existing prompting techniques in language models.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="LATS" target="MCTS">
      <data key="d4">16.0</data>
      <data key="d5">LATS, an adaptation of MCTS (Monte Carlo Tree Search) for language agents, leverages language models to enhance planning and decision-making processes. By utilizing MCTS as its core search algorithm, LATS has demonstrated notable performance gains over other search variants. This integration of language models with MCTS allows LATS to effectively navigate and make decisions within complex language-based environments, showcasing its advanced capabilities in algorithmic planning and execution.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LM">
      <data key="d4">17.0</data>
      <data key="d5">LATS leverages the capabilities of language models (LMs) for decision-making tasks. Specifically, LATS utilizes LMs as agents, state evaluators, and feedback generators, integrating their advanced linguistic and analytical abilities to enhance the decision-making process. This symbiotic relationship between LATS and LMs underscores the importance of language models in providing comprehensive evaluations and generating insightful feedback, thereby optimizing the overall functionality and efficiency of LATS.</data>
      <data key="d6">c234cb83764b899335af0950677ad024,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="COT">
      <data key="d4">15.0</data>
      <data key="d5">LATS (Learning Algorithmic Task Solver) utilizes a CoT (Chain of Thought)-based prompt as its initial framework for reasoning tasks without feedback. In cases where the initial CoT-based prompt fails, LATS transitions to a ReAct (Reasoning and Acting) based prompt, effectively combining both internal and external reasoning strategies. This dual-prompt approach allows LATS to enhance its problem-solving capabilities by leveraging the strengths of both CoT and ReAct methodologies.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="P&#920;">
      <data key="d4">8.0</data>
      <data key="d5">P&#952; is the probabilistic model used within LATS to sample actions and generate language representations.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SELECTION">
      <data key="d4">13.0</data>
      <data key="d5">Selection is the first operation in the LATS algorithm. It is used to choose the most promising nodes to expand in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="EXPANSION">
      <data key="d4">7.0</data>
      <data key="d5">Expansion is the second operation in the LATS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SIMULATION">
      <data key="d4">7.0</data>
      <data key="d5">Simulation is an operation in the LATS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="BACKPROPAGATION">
      <data key="d4">13.0</data>
      <data key="d5">LATS, an algorithm, incorporates backpropagation as a crucial operation. Specifically, backpropagation is employed to update the search tree within the LATS framework. This integration highlights the importance of backpropagation in refining and optimizing the search process in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="REFLECTION">
      <data key="d4">7.0</data>
      <data key="d5">Reflection is an operation in the LATS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="INITIAL STATE">
      <data key="d4">15.0</data>
      <data key="d5">The initial state refers to the starting point or configuration from which the LATS (Local Adaptive Threshold Search) algorithm begins its search process. It serves as the starting point of the search tree in LATS, marking the initial conditions under which the algorithm operates to explore potential solutions.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="ROOT NODE">
      <data key="d4">7.0</data>
      <data key="d5">The root node represents the initial state in the LATS search tree.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LEAF NODE">
      <data key="d4">7.0</data>
      <data key="d5">A leaf node represents a terminal state or end of a trajectory in the LATS search tree.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="CHILD NODE">
      <data key="d4">7.0</data>
      <data key="d5">A child node represents a subsequent state in the LATS search tree.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LONG-TERM MEMORY STRUCTURE">
      <data key="d4">7.0</data>
      <data key="d5">Long-term memory structure is used to store the expanded search tree in LATS.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SCALAR VALUE">
      <data key="d4">7.0</data>
      <data key="d5">Scalar value is assigned to each node during the evaluation process in LATS.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="HEURISTIC">
      <data key="d4">13.0</data>
      <data key="d5">LATS employs heuristic methods to guide its search algorithm. These heuristic techniques are integral to the search process within LATS, ensuring efficient and effective navigation through the algorithmic landscape.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LM SCORE">
      <data key="d4">7.0</data>
      <data key="d5">LM score is part of the value function in LATS.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="TOT">
      <data key="d4">22.0</data>
      <data key="d5">LATS and ToT are two entities compared in terms of performance, sample complexity, and token consumption. While both LATS and ToT share the same sample complexity, LATS achieves better performance and efficiency. This superior performance is attributed to LATS's ability to expand more nodes and incorporate external feedback, which allows it to outperform ToT.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="RAP">
      <data key="d4">22.0</data>
      <data key="d5">LATS and RAP are two entities compared in terms of performance, sample complexity, and token consumption. LATS has the same sample complexity as RAP but achieves better performance and efficiency. Additionally, LATS outperforms RAP by expanding more nodes and incorporating external feedback, leading to superior overall performance.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="MBPP">
      <data key="d4">9.0</data>
      <data key="d5">LATS achieves the highest performance on MBPP for programming tasks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="REFLEXION">
      <data key="d4">14.0</data>
      <data key="d5">LATS is compared to Reflexion in terms of computational cost and efficiency. LATS shows improved performance over Reflexion in complex environments like WebShop, indicating more effective exploration.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="GAME OF 24">
      <data key="d4">16.0</data>
      <data key="d5">LATS is evaluated in the Game of 24, a mathematical reasoning challenge. LATS outperforms previous methods in the Game of 24, demonstrating its superior reasoning ability.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="LATS" target="HOT POT QA">
      <data key="d4">8.0</data>
      <data key="d5">LATS shows improved performance in HotPotQA, validating the effectiveness of its components.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="DFS">
      <data key="d4">6.0</data>
      <data key="d5">LATS experiments include DFS as a variant to observe its effects on performance.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">LATS uses prompting methods to guide language models like GPT-3.5 in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="RL-BASED TRAINING">
      <data key="d4">7.0</data>
      <data key="d5">LATS surpasses RL-based training in performance metrics like score and success rate (SR) in environments like WebShop.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="IMPROVEMENT">
      <data key="d4">15.0</data>
      <data key="d5">LATS shows noticeable improvement in performance metrics.LATS shows noticeable improvement in performance metrics across various tasks and environments.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="TOKEN CONSUMPTION">
      <data key="d4">19.0</data>
      <data key="d5">LATS (Language-Agnostic Tokenization System) experiments include ablations for token consumption to evaluate efficiency. Token consumption is a critical metric in these experiments, and LATS is specifically evaluated for its token consumption compared to other methods. This comparative analysis helps in understanding the efficiency of LATS in handling token consumption, providing insights into its performance relative to alternative approaches.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="SEMANTIC FEEDBACK">
      <data key="d4">12.0</data>
      <data key="d5">Semantic feedback is used to improve performance in LATS.LATS uses semantic feedback to improve performance, although it may not be as effective in complex environments like WebShop.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="LOCAL MINIMA">
      <data key="d4">12.0</data>
      <data key="d5">LATS addresses the challenge of local minima observed in Reflexion, leading to more effective exploration.LATS addresses the challenge of local minima during exploration.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="EXPLORATION">
      <data key="d4">13.0</data>
      <data key="d5">LATS uses effective exploration techniques to improve performance in various tasks.Exploration is a key component in LATS for finding optimal solutions.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="ITERATIONS">
      <data key="d4">13.0</data>
      <data key="d5">LATS shows performance improvement for the same number of iterations compared to other methods.Iterations are used as a metric to evaluate the performance of LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="SUCCESS RATE">
      <data key="d4">15.0</data>
      <data key="d5">LATS improves the success rate (SR) in tasks like WebShop, indicating its effectiveness.LATS improves the success rate in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="SCORE">
      <data key="d4">9.0</data>
      <data key="d5">LATS improves the score in tasks like WebShop, indicating its effectiveness.LATS improves the score in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="TRAJECTORIES">
      <data key="d4">14.0</data>
      <data key="d5">LATS constructs trajectories with search algorithms for decision-making tasks. These trajectories are the paths taken by agents during the exploration process in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="CHILDREN">
      <data key="d4">6.0</data>
      <data key="d5">Children are expanded nodes in the search tree during the exploration process in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="PRUNING">
      <data key="d4">6.0</data>
      <data key="d5">Pruning removes low-value branches from the search tree in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="SAMPLE COMPLEXITY">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated for sample complexity compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="NODES EXPANDED">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated for the number of nodes expanded compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="REVERSION PROPERTY">
      <data key="d4">7.0</data>
      <data key="d5">LATS assumes the ability to revert to earlier states in decision-making environments.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="SYSTEM-2 LM APPROACHES">
      <data key="d4">1.0</data>
      <data key="d5">LATS is an example of a System-2 LM approach that involves complex reasoning and decision-making.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">LATS is evaluated for its performance compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="COMPUTATIONAL COST">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated for its computational cost compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="GROUND-TRUTH FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">LATS benefits from ground-truth feedback to improve performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="INFERENCE-TIME COMPUTE COSTS">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated for inference-time compute costs compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="TRADE-OFF BETWEEN PERFORMANCE AND EFFICIENCY">
      <data key="d4">7.0</data>
      <data key="d5">LATS provides a trade-off between performance and efficiency.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="AUTONOMOUS DECISION-MAKING">
      <data key="d4">8.0</data>
      <data key="d5">LATS enables autonomous decision-making for language models.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="PROMPTING TECHNIQUES">
      <data key="d4">7.0</data>
      <data key="d5">LATS addresses limitations of prior prompting techniques.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="REASONING ABILITY">
      <data key="d4">8.0</data>
      <data key="d5">LATS maintains reasoning ability without additional training.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">LATS harnesses LM capabilities for various decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="EXPERIENCE LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">LATS enables agents to learn from experience to improve performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="SYSTEM-2 LM">
      <data key="d4">1.0</data>
      <data key="d5">LATS is an example of a System-2 LM approach that involves complex reasoning and decision-making.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="WEBSHOP">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated using the WebShop environment.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="MONTE CARLO TREE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">LATS uses Monte Carlo Tree Search for decision-making tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="COT-SC">
      <data key="d4">7.0</data>
      <data key="d5">LATS is compared to CoT-SC in terms of efficiency when the number of nodes is set to one.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="MINECRAFT">
      <data key="d4">6.0</data>
      <data key="d5">Minecraft is mentioned as a potential environment for future work using LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="ALFWORLD">
      <data key="d4">6.0</data>
      <data key="d5">Alfworld is an environment used to evaluate LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="TOOLBENCH">
      <data key="d4">6.0</data>
      <data key="d5">ToolBench is an environment used to evaluate LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="EXPLORATION WEIGHT">
      <data key="d4">9.0</data>
      <data key="d5">Exploration weight is a parameter in the LATS algorithm that affects its search effectiveness and performance.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="DEPTH">
      <data key="d4">9.0</data>
      <data key="d5">Depth is a parameter in the LATS algorithm that determines the maximum number of steps in the search process, affecting its performance.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="LM VALUE FUNCTION">
      <data key="d4">9.0</data>
      <data key="d5">The LM value function is a component of the LATS algorithm that scores states based on expected future rewards, guiding the search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="WIKIPEDIA WEB API">
      <data key="d4">8.0</data>
      <data key="d5">The Wikipedia web API is used in the LATS algorithm for interactive information retrieval, supporting actions like searching for entities and looking up strings.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SAMPLING SIZE">
      <data key="d4">9.0</data>
      <data key="d5">Sampling size is a parameter in the LATS algorithm that determines the number of samples or trajectories to be considered during the search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="STATE SPACE">
      <data key="d4">8.0</data>
      <data key="d5">State space refers to the set of all possible states or configurations that the LATS algorithm can explore during the search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="VALUE FUNCTION WEIGHT">
      <data key="d4">9.0</data>
      <data key="d5">Value function weight is a parameter in the LATS algorithm that balances the contributions of different components in the value function.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ACTION GENERATOR">
      <data key="d4">9.0</data>
      <data key="d5">Action generator is a component in the LATS algorithm that generates possible actions based on the current state.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="REFLECTION GENERATOR">
      <data key="d4">9.0</data>
      <data key="d5">Reflection generator is a component in the LATS algorithm that generates reflections or adjustments based on the current context and state.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="VISIT COUNTER">
      <data key="d4">8.0</data>
      <data key="d5">Visit counter is a component in the LATS algorithm that keeps track of the number of times each state has been visited during the search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ROLL-OUTS">
      <data key="d4">8.0</data>
      <data key="d5">Roll-outs refer to the process of simulating future actions and states to evaluate their potential outcomes in the LATS algorithm.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="CONTEXT">
      <data key="d4">8.0</data>
      <data key="d5">Context refers to the additional information or conditions that influence the search process in the LATS algorithm.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="TERMINAL STATE">
      <data key="d4">8.0</data>
      <data key="d5">Terminal state refers to a state in the search process where no further actions can be taken, often indicating the end of a trajectory.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENT REWARDS">
      <data key="d4">8.0</data>
      <data key="d5">Environment rewards are the feedback or scores received from the environment based on the actions taken and states reached during the search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated using the MBPP benchmark.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="LATS" target="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d4">15.0</data>
      <data key="d5">LATS employs value function hyperparameters, such as &#955;, to configure its evaluation function. These hyperparameters are crucial for determining the LM score and self-consistency score, which are integral components of LATS's assessment mechanism.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="LATS" target="SELF-CONSISTENCY SCORE">
      <data key="d4">8.0</data>
      <data key="d5">The self-consistency score improves the performance of LATS.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="SELF-REFLECTION" target="UNIT TEST RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection involves analyzing unit test results to identify errors in the function implementation.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPROVED IMPLEMENTATION">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection guides the creation of an improved implementation by identifying and addressing errors.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="SELF-REFLECTION" target="REFLECTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The reflection prompt instructs the AI assistant to perform self-reflection on the function implementation.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="SELF-REFLECTION" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">7.0</data>
      <data key="d5">Self-Reflection is a technique used as a building block in agentic systems within the ADAS research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SELF-REFLECTION" target="MADAAN ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Madaan et al., 2024, are recognized for their significant contributions to the research on self-reflection in agentic systems. Their work specifically focuses on enhancing the process of self-reflection to ensure that the generated agents are both novel and error-free.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SELF-REFLECTION" target="META AGENT">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent performs self-reflection to review its proposed architecture and implementation, identify mistakes, and suggest improvements.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPLEMENTATION MISTAKES">
      <data key="d4">8.0</data>
      <data key="d5">During self-reflection, the meta agent identifies and corrects implementation mistakes.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPROVEMENT">
      <data key="d4">8.0</data>
      <data key="d5">During self-reflection, the meta agent suggests and implements improvements to the proposed architecture.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="WRONG IMPLEMENTATION EXAMPLES">
      <data key="d4">8.0</data>
      <data key="d5">During self-reflection, the meta agent uses wrong implementation examples to identify and correct mistakes.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="SELF-REFLECTION ROUND 1">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection includes a first round where the meta agent reviews the proposed architecture and implementation.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="SELF-REFLECTION ROUND 2">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection includes a second round where the meta agent further revises the code.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="RUNTIME ERROR">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection is performed when a runtime error is encountered during the execution of the generated code.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="FM MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Self-Reflection method is implemented using the FM Module to improve task performance based on previous attempts and feedback.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-REFLECTION" target="COT_INITIAL_INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">The self-reflection method uses cot_initial_instruction for initial reasoning.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-REFLECTION" target="COT_REFLECT_INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">The self-reflection method uses cot_reflect_instruction for reflecting on previous attempts and feedback.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-REFLECTION" target="CRITIC INSTRUCTION">
      <data key="d4">1.0</data>
      <data key="d5">The self-reflection method uses critic_instruction for providing feedback and correcting the answer.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-CONSISTENCY" target="CHAIN-OF-THOUGHT (COT) PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">Self-consistency is a technique used to mitigate error propagation in chain-of-thought prompting.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SELF-CONSISTENCY" target="WANG ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. are researchers who have contributed to the development of self-consistency, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SELF-CONSISTENCY" target="MAJORITY VOTING">
      <data key="d4">7.0</data>
      <data key="d5">Self-consistency employs majority voting over sampled chains to reduce errors.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="TREE-OF-THOUGHT (TOT) PROMPTING">
      <data key="d4">14.0</data>
      <data key="d5">CHAIN-OF-THOUGHT (COT) PROMPTING and TREE-OF-THOUGHT (TOT) PROMPTING are techniques used for decomposing complex inputs into sequential steps in reasoning tasks. CoT prompting focuses on breaking down problems into a linear sequence of logical steps, facilitating a structured approach to problem-solving. ToT prompting extends this concept by exploring multiple reasoning paths over thoughts, allowing for a more comprehensive examination of potential solutions. This extension enables a broader and more flexible analysis, accommodating various possible outcomes and enhancing the depth of reasoning.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="REASONING VIA PLANNING (RAP)">
      <data key="d4">6.0</data>
      <data key="d5">Both are techniques used for reasoning tasks, with RAP using MCTS for planning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="WEI ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Wei et al. are researchers who have contributed to the development of chain-of-thought prompting and its variants, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="KOJIMA ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Kojima et al. are researchers who have contributed to the development of chain-of-thought prompting variants, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="CHAIN-OF-THOUGHT (COT) PROMPTING VARIANTS">
      <data key="d4">6.0</data>
      <data key="d5">Variants of CoT prompting build on the original technique to improve reasoning in language models.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="ERROR PROPAGATION">
      <data key="d4">14.0</data>
      <data key="d5">CHAIN-OF-THOUGHT (COT) PROMPTING often encounters challenges related to ERROR PROPAGATION. This issue arises primarily due to its reliance on internal representations, which can lead to the accumulation of errors as the number of steps in the process increases. As CoT prompting progresses through its sequential steps, the potential for errors to propagate and compound becomes more significant, thereby affecting the overall accuracy and reliability of the outcomes.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="LANGUAGE MODELS (LM)">
      <data key="d4">8.0</data>
      <data key="d5">CoT prompting is a technique used to improve the performance of language models on intricate tasks.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="THOUGHTS Z">
      <data key="d4">9.0</data>
      <data key="d5">CoT prompting generates intermediate thoughts z to bridge the gap between input x and output y.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="PERFORMANCE CEILING">
      <data key="d4">7.0</data>
      <data key="d5">CoT prompting has a performance ceiling due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="FACT HALLUCINATION">
      <data key="d4">7.0</data>
      <data key="d5">CoT prompting can lead to fact hallucination due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="DEPTH-FIRST SEARCH (DFS)">
      <data key="d4">14.0</data>
      <data key="d5">TREE-OF-THOUGHT (TOT) PROMPTING is a method that employs DEPTH-FIRST SEARCH (DFS) to explore and sample trajectories in reasoning tasks. DFS, a search algorithm, is utilized within the ToT prompting framework to systematically traverse the tree structure, ensuring a thorough exploration of potential reasoning paths. This integration of DFS into ToT prompting highlights the algorithm's role in enhancing the depth and comprehensiveness of the reasoning process.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="BREADTH-FIRST SEARCH (BFS)">
      <data key="d4">14.0</data>
      <data key="d5">TREE-OF-THOUGHT (TOT) PROMPTING is a method that employs BREADTH-FIRST SEARCH (BFS) to sample trajectories in reasoning tasks. BFS, a search algorithm, is utilized within ToT prompting to explore the tree structure, enabling a systematic examination of possible paths and solutions. This integration of BFS into ToT prompting ensures a comprehensive exploration of the reasoning process, enhancing the effectiveness and depth of the analysis.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="LANGUAGE MODELS (LM)">
      <data key="d4">8.0</data>
      <data key="d5">ToT prompting is a technique used to improve the performance of language models by exploring multiple reasoning paths.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="HEURISTICS">
      <data key="d4">8.0</data>
      <data key="d5">Heuristics are used to guide search algorithms in exploring the tree of thoughts in ToT prompting.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="THOUGHTS Z">
      <data key="d4">9.0</data>
      <data key="d5">ToT prompting generates multiple reasoning paths over thoughts z.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="PROPOSAL">
      <data key="d4">8.0</data>
      <data key="d5">ToT prompting uses proposal to generate thoughts zi.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="SAMPLING">
      <data key="d4">8.0</data>
      <data key="d5">ToT prompting uses sampling to generate thoughts zi.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="TRIAL AND ERROR">
      <data key="d4">6.0</data>
      <data key="d5">ToT prompting is limited in its ability to learn from trial and error.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REASONING VIA PLANNING (RAP)" target="ROLL-OUTS">
      <data key="d4">7.0</data>
      <data key="d5">RAP uses roll-outs simulated by language models for planning and reasoning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="YAO ET AL., 2023B" target="WIKIPEDIA WEB API">
      <data key="d4">1.0</data>
      <data key="d5">Yao et al. are the authors who proposed the Wikipedia web API used in the LATS algorithm.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="WEI ET AL., 2022" target="COT">
      <data key="d4">6.0</data>
      <data key="d5">Wei et al. are the authors of the CoT method, published in 2022.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="WEI ET AL., 2022" target="CHAIN-OF-THOUGHT">
      <data key="d4">25.0</data>
      <data key="d5">Wei et al. are the authors of the Chain-of-Thought algorithm, which was published in 2022. They are cited in the paper for their contributions to the research on chain-of-thought planning and reasoning.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="WEI ET AL., 2022" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">12.0</data>
      <data key="d5">Wei et al. are the researchers who developed the Chain-of-Thought (COT) algorithm in 2022. The Chain-of-Thought (COT) method, authored by Wei et al., represents a significant advancement in algorithmic analysis, focusing on the intricate connections and hierarchies within algorithmic communities. This method is designed to enhance the understanding of the dynamics and interactions that define the structure of these communities.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="WEI ET AL., 2022" target="CHAIN-OF-THOUGHT (WEI ET AL., 2022)">
      <data key="d4">6.0</data>
      <data key="d5">Wei et al. are the authors of the Chain-of-Thought algorithm.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="WANG ET AL., 2022" target="COT-SC">
      <data key="d4">2.0</data>
      <data key="d5">Wang et al. are the authors mentioned in relation to the CoT-SC algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="GUO ET AL., 2018" target="ERROR PROPAGATION">
      <data key="d4">6.0</data>
      <data key="d5">Guo et al. are researchers who have studied error propagation in reasoning tasks, published in 2018.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHEN ET AL., 2023B" target="ERROR PROPAGATION">
      <data key="d4">6.0</data>
      <data key="d5">Chen et al. are researchers who have studied error propagation in reasoning tasks, published in 2023.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHEN ET AL., 2023B" target="AGENTVERSE">
      <data key="d4">12.0</data>
      <data key="d5">Chen et al. are the authors of the AgentVerse algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ZHOU ET AL., 2022" target="LEAST-TO-MOST PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">Zhou et al. are researchers who have developed least-to-most prompting for multi-step decomposition in reasoning tasks, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="BESTA ET AL., 2023" target="SEARCH ALGORITHMS">
      <data key="d4">6.0</data>
      <data key="d5">Besta et al. are researchers who have contributed to the development of search algorithms for chain-of-thought prompting, published in 2023.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MADAAN ET AL., 2023" target="SELF-REFINE">
      <data key="d4">24.0</data>
      <data key="d5">Madaan et al. are researchers who, in 2023, developed the Self-Refine algorithm. This innovative technique focuses on improving language model performance, showcasing their significant contribution to the field of algorithmic analysis and natural language processing.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="AHN ET AL., 2022" target="HIGH-LEVEL CONTROLLERS">
      <data key="d4">6.0</data>
      <data key="d5">Ahn et al. are researchers who have employed language models as high-level controllers in robotics, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HUANG ET AL., 2022" target="HIGH-LEVEL CONTROLLERS">
      <data key="d4">6.0</data>
      <data key="d5">Huang et al. are researchers who have employed language models as high-level controllers in robotics, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="DRIESS ET AL., 2023" target="HIGH-LEVEL CONTROLLERS">
      <data key="d4">6.0</data>
      <data key="d5">Driess et al. are researchers who have employed language models as high-level controllers in robotics, published in 2023.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="BAKER ET AL., 2022" target="COMPLEX MULTIMODAL GAMES">
      <data key="d4">6.0</data>
      <data key="d5">Baker et al. are researchers who have adapted language model agents to complex multimodal games, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WANG ET AL., 2023" target="COMPLEX MULTIMODAL GAMES">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. are researchers who have adapted language model agents to complex multimodal games, published in 2023.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="GUSS ET AL., 2019" target="MINECRAFT">
      <data key="d4">6.0</data>
      <data key="d5">Guss et al. are researchers who have worked on complex multimodal games like Minecraft, published in 2019.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LIU ET AL., 2018" target="TEXT-BASED ENVIRONMENTS">
      <data key="d4">6.0</data>
      <data key="d5">Liu et al. are researchers who have employed language models in text-based environments, published in 2018.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SHRIDHAR ET AL., 2020" target="TEXT-BASED ENVIRONMENTS">
      <data key="d4">6.0</data>
      <data key="d5">Shridhar et al. are researchers who have employed language models in text-based environments, published in 2020.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SHRIDHAR ET AL., 2020" target="ALFWORLD">
      <data key="d4">12.0</data>
      <data key="d5">Shridhar et al. are the authors mentioned in relation to Alfworld.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LIU ET AL., 2024" target="TEXT-BASED ENVIRONMENTS">
      <data key="d4">1.0</data>
      <data key="d5">Liu et al. are researchers who have employed language models in text-based environments, published in 2024.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LIU ET AL., 2024" target="EOH">
      <data key="d4">7.0</data>
      <data key="d5">Liu et al. are the authors of research on EoH, published in 2024.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LIU ET AL., 2024" target="BALANCING EXPLORATION AND EXPLOITATION">
      <data key="d4">5.0</data>
      <data key="d5">Liu et al. are authors who have worked on balancing exploration and exploitation in search algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ERROR PROPAGATION" target="RAP">
      <data key="d4">7.0</data>
      <data key="d5">RAP can lead to error propagation due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="LEAST-TO-MOST PROMPTING" target="MULTI-STEP DECOMPOSITION">
      <data key="d4">7.0</data>
      <data key="d5">Least-to-most prompting is a method of multi-step decomposition to improve reasoning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LEAST-TO-MOST PROMPTING" target="OLIVIER BOUSQUET">
      <data key="d4">8.0</data>
      <data key="d5">Olivier Bousquet is one of the authors who discussed the Least-to-most prompting method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LEAST-TO-MOST PROMPTING" target="QUOC LE">
      <data key="d4">8.0</data>
      <data key="d5">Quoc Le is one of the authors who discussed the Least-to-most prompting method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LEAST-TO-MOST PROMPTING" target="ED CHI">
      <data key="d4">8.0</data>
      <data key="d5">Ed Chi is one of the authors who discussed the Least-to-most prompting method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LEAST-TO-MOST PROMPTING" target="ICLR 2022">
      <data key="d4">7.0</data>
      <data key="d5">The Least-to-most prompting method was presented at ICLR 2022.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="SEARCH ALGORITHMS" target="DEPTH-FIRST SEARCH (DFS)">
      <data key="d4">7.0</data>
      <data key="d5">DFS is a search algorithm used to explore the tree in ToT prompting.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="SEARCH ALGORITHMS" target="BREADTH-FIRST SEARCH (BFS)">
      <data key="d4">7.0</data>
      <data key="d5">BFS is a search algorithm used to explore the tree in ToT prompting.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="SELF-REFINE" target="SELF-IMPROVEMENT">
      <data key="d4">7.0</data>
      <data key="d5">Self-refine is a technique of self-improvement used to enhance language model performance.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SELF-REFINE" target="REFLEXION">
      <data key="d4">16.0</data>
      <data key="d5">Self-Refine and Reflexion are both extensions proposed to enhance reasoning and decision-making through self-improvement.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="SELF-REFINE" target="META AGENT SEARCH">
      <data key="d4">20.0</data>
      <data key="d5">Meta Agent Search outperforms the Self-Refine algorithm in various domains. It uses Self-Refine as one of the state-of-the-art hand-designed agents for comparison, leveraging the Self-Refine strategy to perform iterations of refinement on the novelty and correctness of proposals. This indicates that while Meta Agent Search is superior in performance, it still acknowledges the effectiveness of Self-Refine by incorporating its strategies to enhance its own algorithmic processes.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="SELF-REFINE" target="MADAAN ET AL., 2024">
      <data key="d4">37.0</data>
      <data key="d5">Madaan et al. are the authors of the Self-Refine algorithm, published in 2024. This research, which includes the development of the Self-Refine strategy, is utilized in Meta Agent Search.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="SELF-REFINE" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Self-Refine is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="SELF-REFINE" target="ARC">
      <data key="d4">7.0</data>
      <data key="d5">Self-Refine is used as a baseline for experiments on ARC.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="SELF-REFINE" target="SHENGRAN HU">
      <data key="d4">14.0</data>
      <data key="d5">Self-Refine is a method implemented by Shengran Hu and can be found in the repository at https://github.com/ShengranHu/ADAS.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="REFLEXION" target="SELF-IMPROVEMENT">
      <data key="d4">1.0</data>
      <data key="d5">Reflexion is a technique of self-improvement used to enhance language model performance.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="REFLEXION" target="LANGUAGE MODELS (LM)">
      <data key="d4">8.0</data>
      <data key="d5">Reflexion is a technique used to extend the capabilities of language models to decision-making tasks.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REFLEXION" target="ENVIRONMENTAL FEEDBACK">
      <data key="d4">9.0</data>
      <data key="d5">Reflexion uses observations from the environment to improve decision-making tasks.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REFLEXION" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Reflexion is used for decision-making tasks where reverting between iterations is feasible.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REFLEXION" target="MBPP">
      <data key="d4">7.0</data>
      <data key="d5">Reflexion is evaluated using the MBPP dataset, with performance scores reported.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="REFLEXION" target="HOT POT QA">
      <data key="d4">6.0</data>
      <data key="d5">Reflexion is used to evaluate performance in HotPotQA.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="REFLEXION" target="PROMPTING TECHNIQUES">
      <data key="d4">7.0</data>
      <data key="d5">Reflexion is a type of prompting technique used for language models.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="HIGH-LEVEL CONTROLLERS" target="LANGUAGE MODELS">
      <data key="d4">7.0</data>
      <data key="d5">Language models are used as high-level controllers in robotics and other applications.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HIGH-LEVEL CONTROLLERS" target="CONTROL POLICIES">
      <data key="d4">7.0</data>
      <data key="d5">High-level controllers oversee and guide control policies in decision-making tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="COMPLEX MULTIMODAL GAMES" target="LANGUAGE MODELS">
      <data key="d4">7.0</data>
      <data key="d5">Language models are adapted to complex multimodal games for decision-making tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MINECRAFT" target="LANGUAGE MODELS">
      <data key="d4">7.0</data>
      <data key="d5">Language models are used to control agents and make decisions in Minecraft.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="PROMPTS" target="AGENTINSTRUCT">
      <data key="d4">17.0</data>
      <data key="d5">AgentInstruct generates both prompts and responses as part of its data generation process, utilizing raw data sources. This dual capability allows AgentInstruct to effectively create comprehensive and contextually relevant interactions, ensuring a robust and dynamic data generation framework.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="PROMPTS" target="DATA GENERATION WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Data generation workflows involve the use of prompts to generate new data.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="VALUE FUNCTION" target="MCTS">
      <data key="d4">8.0</data>
      <data key="d5">The value function is used to estimate the expected return of a node in the MCTS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="VALUE FUNCTION" target="VOLD(S)">
      <data key="d4">7.0</data>
      <data key="d5">Vold(s) is the old value function of a node before it is updated with the new return value.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="VALUE FUNCTION" target="N(S)">
      <data key="d4">7.0</data>
      <data key="d5">N(s) is the number of times a node has been visited, used in the value function update formula.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="DECISION-MAKING" target="REASONING SETTING">
      <data key="d4">6.0</data>
      <data key="d5">Decision-making and reasoning settings are different environments where models are evaluated on their ability to make choices or solve problems.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="POLICY MODEL" target="LANGUAGE MODELS">
      <data key="d4">7.0</data>
      <data key="d5">Language models are used as policy models in decision-making tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SELF-IMPROVEMENT" target="AGENTINSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct can be used for the self-improvement of larger, more capable models.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="COT" target="GAME OF 24">
      <data key="d4">6.0</data>
      <data key="d5">CoT is used as a base prompting design in the Game of 24.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="COT" target="MIRAGE">
      <data key="d4">8.0</data>
      <data key="d5">CoT is a technique used to evaluate the performance of models on the MIRAGE datasets.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ADAPLANNER" target="SUN ET AL., 2023">
      <data key="d4">18.0</data>
      <data key="d5">Sun et al. are the researchers who developed the AdaPlanner algorithm in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="EXTERNAL TOOLS" target="SHEN ET AL., 2023">
      <data key="d4">7.0</data>
      <data key="d5">Shen et al. contributed to the development of external tools for language models in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="EXTERNAL TOOLS" target="SURIS ET AL., 2023">
      <data key="d4">7.0</data>
      <data key="d5">Suris et al. contributed to the development of external tools for language models in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="TREE-BASED SEARCH" target="MCTS">
      <data key="d4">16.0</data>
      <data key="d5">MCTS is a type of tree-based search algorithm used to explore multiple branches of outcomes.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="TREE-BASED SEARCH" target="SWIECHOWSKI ET AL., 2021">
      <data key="d4">7.0</data>
      <data key="d5">Swiechowski et al. contributed to the development of tree-based search algorithms in 2021.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="TREE-BASED SEARCH" target="LAVALLE, 1998">
      <data key="d4">7.0</data>
      <data key="d5">LaValle contributed to the development of tree-based search algorithms in 1998.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="MCTS" target="UCT ALGORITHM">
      <data key="d4">8.0</data>
      <data key="d5">The UCT algorithm is used within MCTS to balance exploration and exploitation.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="EXPLORATION WEIGHT">
      <data key="d4">8.0</data>
      <data key="d5">Exploration weight is a parameter used in the MCTS algorithm to balance exploration and exploitation.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="PARENT NODE">
      <data key="d4">7.0</data>
      <data key="d5">The parent node is used in the backpropagation process of the MCTS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="EPISODE">
      <data key="d4">7.0</data>
      <data key="d5">An episode refers to a sequence of actions and observations in the MCTS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="RETURN">
      <data key="d4">8.0</data>
      <data key="d5">Return is used in the backpropagation process of the MCTS algorithm to update the value function.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="A*">
      <data key="d4">7.0</data>
      <data key="d5">MCTS is compared to A* as a more principled search algorithm.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="MCTS" target="DFS">
      <data key="d4">7.0</data>
      <data key="d5">MCTS is compared to DFS as a more principled search algorithm.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="MCTS" target="TOT">
      <data key="d4">8.0</data>
      <data key="d5">MCTS is improved by incorporating the LM-based heuristic used in ToT.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="MCTS" target="SEARCH ALGORITHM">
      <data key="d4">9.0</data>
      <data key="d5">MCTS is a type of search algorithm used for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LM" target="RESET">
      <data key="d4">7.0</data>
      <data key="d5">Reset is used in language model tasks to return to a previous state or step.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM" target="TOT">
      <data key="d4">8.0</data>
      <data key="d5">ToT leverages LM capabilities for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LM" target="RAP">
      <data key="d4">8.0</data>
      <data key="d5">RAP leverages LM capabilities for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="HAFNER ET AL., 2019" target="REINFORCEMENT LEARNING">
      <data key="d4">7.0</data>
      <data key="d5">Hafner et al. contributed to the development of reinforcement learning algorithms in 2019.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="DU ET AL., 2023" target="REINFORCEMENT LEARNING">
      <data key="d4">7.0</data>
      <data key="d5">Du et al. contributed to the development of reinforcement learning algorithms in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="DU ET AL., 2023" target="LLM-DEBATE">
      <data key="d4">12.0</data>
      <data key="d5">DU ET AL., 2023 are the authors and researchers who developed the LLM-Debate algorithm in 2023.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="DU ET AL., 2023" target="LLM DEBATE">
      <data key="d4">19.0</data>
      <data key="d5">Du et al. are the authors of research on the LLM Debate algorithm, which was published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="DU ET AL., 2023" target="LLM DEBATE (DU ET AL., 2023)">
      <data key="d4">6.0</data>
      <data key="d5">Du et al. are the authors of the LLM Debate algorithm.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="WU ET AL., 2023" target="FM MODULES">
      <data key="d4">6.0</data>
      <data key="d5">Wu et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="SHEN ET AL., 2023" target="NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Shen et al. discussed Neural Architecture Search (NAS) in 2023.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="TOT" target="SEARCH METHODS">
      <data key="d4">7.0</data>
      <data key="d5">ToT is a type of search method that samples and explores more outputs to improve performance.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="TOT" target="GAME OF 24">
      <data key="d4">6.0</data>
      <data key="d5">ToT is evaluated for its performance in the Game of 24.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="TOT" target="HOT POT QA">
      <data key="d4">1.0</data>
      <data key="d5">ToT is evaluated for its performance in HotPotQA.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="TOT" target="TOKEN CONSUMPTION">
      <data key="d4">7.0</data>
      <data key="d5">ToT is evaluated for token consumption compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="SAMPLE COMPLEXITY">
      <data key="d4">7.0</data>
      <data key="d5">ToT is evaluated for sample complexity compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="NODES EXPANDED">
      <data key="d4">7.0</data>
      <data key="d5">ToT is evaluated for the number of nodes expanded compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="TRAJECTORIES">
      <data key="d4">8.0</data>
      <data key="d5">ToT constructs trajectories with search algorithms for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">ToT is evaluated for its performance compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="COMPUTATIONAL COST">
      <data key="d4">7.0</data>
      <data key="d5">ToT is evaluated for its computational cost compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="SELECTION OPERATION">
      <data key="d4">7.0</data>
      <data key="d5">ToT removes the selection operation to improve performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="BACKPROPAGATION OPERATION">
      <data key="d4">7.0</data>
      <data key="d5">ToT removes the backpropagation operation to improve performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">ToT harnesses LM capabilities for various decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="YA0 ET AL., 2023A">
      <data key="d4">12.0</data>
      <data key="d5">Yao et al. are the authors mentioned in relation to the ToT algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="RAP" target="LANGUAGE MODELS (LM)">
      <data key="d4">7.0</data>
      <data key="d5">RAP is a reasoning-based method used to improve the performance of language models.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="PERFORMANCE CEILING">
      <data key="d4">7.0</data>
      <data key="d5">RAP has a performance ceiling due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="FACT HALLUCINATION">
      <data key="d4">7.0</data>
      <data key="d5">RAP can lead to fact hallucination due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="TRIAL AND ERROR">
      <data key="d4">6.0</data>
      <data key="d5">RAP is limited in its ability to learn from trial and error.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="WORLD MODEL">
      <data key="d4">6.0</data>
      <data key="d5">RAP is constrained to tasks where the language model can become a world model and accurately predict states.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="SEARCH METHODS">
      <data key="d4">7.0</data>
      <data key="d5">RAP is a type of search method that samples and explores more outputs to improve performance.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="RAP" target="GAME OF 24">
      <data key="d4">6.0</data>
      <data key="d5">RAP is evaluated for its performance in the Game of 24.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="RAP" target="HOT POT QA">
      <data key="d4">6.0</data>
      <data key="d5">RAP is evaluated for its performance in HotPotQA.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="RAP" target="TOKEN CONSUMPTION">
      <data key="d4">7.0</data>
      <data key="d5">RAP is evaluated for token consumption compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="SAMPLE COMPLEXITY">
      <data key="d4">7.0</data>
      <data key="d5">RAP is evaluated for sample complexity compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="NODES EXPANDED">
      <data key="d4">7.0</data>
      <data key="d5">RAP is evaluated for the number of nodes expanded compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="TRAJECTORIES">
      <data key="d4">8.0</data>
      <data key="d5">RAP constructs trajectories with search algorithms for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">RAP is evaluated for its performance compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="COMPUTATIONAL COST">
      <data key="d4">7.0</data>
      <data key="d5">RAP is evaluated for its computational cost compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">RAP harnesses LM capabilities for various decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="REASONING" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct generates data to teach AI models the skill of reasoning.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="EXTERNAL MEMORY" target="LEWIS ET AL., 2020">
      <data key="d4">6.0</data>
      <data key="d5">Lewis et al. are the authors who contributed to the development of external memory techniques, published in 2020.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="EXTERNAL MEMORY" target="ZHANG ET AL., 2024C">
      <data key="d4">6.0</data>
      <data key="d5">Zhang et al. are the authors who contributed to the development of external memory techniques, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="A*">
      <data key="d4">9.0</data>
      <data key="d5">A* is a type of search algorithm used for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="DFS">
      <data key="d4">9.0</data>
      <data key="d5">DFS is a type of search algorithm used for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="ADAS">
      <data key="d4">8.0</data>
      <data key="d5">The search algorithm is a key component of ADAS, specifying how the method explores the search space.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="ZHUGE ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Zhuge et al. used reinforcement learning as a search algorithm within ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="SUTTON &amp; BARTO, 2018">
      <data key="d4">1.0</data>
      <data key="d5">Sutton &amp; Barto discussed the exploration-exploitation trade-off, which is considered in the search algorithms of ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="FMS">
      <data key="d4">8.0</data>
      <data key="d5">FMs are used to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="INTERNAL REASONING" target="EXTERNAL RETRIEVAL">
      <data key="d4">8.0</data>
      <data key="d5">Both internal reasoning and external retrieval strategies are used in LATS to perform well on tasks like HotPotQA.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="INPUT" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Input refers to the data provided to the Meta Agent Search algorithm to perform tasks and discover new agents.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)" target="KOCSIS AND SZEPESV&#193;RI, 2006">
      <data key="d4">6.0</data>
      <data key="d5">Kocsis and Szepesv&#225;ri developed the UCT value used in MCTS.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)" target="VALUE FUNCTION V(S)">
      <data key="d4">8.0</data>
      <data key="d5">UCT uses the value function V(s) to select the best child node for expansion.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)" target="EXPLORATION WEIGHT W">
      <data key="d4">7.0</data>
      <data key="d5">Exploration weight w is a parameter in the UCT formula.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="INPUT X" target="OUTPUT Y">
      <data key="d4">9.0</data>
      <data key="d5">Input x is transformed into output y by the language model.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="PARENT NODE P" target="CHILD NODE S">
      <data key="d4">8.0</data>
      <data key="d5">Child nodes s are expanded from parent nodes p in the decision tree of MCTS.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="AGENT" target="ENVIRONMENT">
      <data key="d4">8.0</data>
      <data key="d5">An agent operates within an environment, receiving observations and taking actions.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AGENT" target="BASE PROMPTING FRAMEWORK">
      <data key="d4">7.0</data>
      <data key="d5">The base prompting framework guides the agent's actions and decisions in a task.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AGENT" target="OBSERVATION">
      <data key="d4">8.0</data>
      <data key="d5">Observation is the information received by the agent from the environment.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AGENT" target="ACTION">
      <data key="d4">8.0</data>
      <data key="d5">Action is the decision or move made by the agent based on the policy and observations.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AGENT" target="POLICY">
      <data key="d4">8.0</data>
      <data key="d5">Policy is the strategy that the agent follows to decide on actions.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AGENT" target="SEARCH APIS">
      <data key="d4">8.0</data>
      <data key="d5">Agents can use search APIs to perform specific tasks, such as searching for information.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENT" target="CODE INTERPRETER">
      <data key="d4">8.0</data>
      <data key="d5">Agents can use a code interpreter to execute and debug code.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENT" target="CALCULATOR">
      <data key="d4">8.0</data>
      <data key="d5">Agents can use a calculator to perform mathematical calculations.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="EXPANSION" target="BACKPROPAGATED REWARD">
      <data key="d4">7.0</data>
      <data key="d5">Backpropagated reward is used to update the model's parameters during the expansion process in search algorithms.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="EXPANSION" target="TEXT MODIFICATION AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Text modification agents can create expansion tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="REFLECTION" target="SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Reflection led to the decision to perform a new search.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="REFLECTION" target="REFINE SEARCH">
      <data key="d4">1.0</data>
      <data key="d5">Reflection led to the decision to refine the search criteria.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="REFLECTION" target="FAIL">
      <data key="d4">1.0</data>
      <data key="d5">Reflection occurs after a failed attempt to evaluate what went wrong and how to improve.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="REFLECTION" target="MADAAN ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Madaan et al. are the authors who contributed to the development of reflection techniques, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="REFLECTION" target="MULTI-AGENT WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Reflection is a key component of multi-agent workflows used to generate high-quality data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="RESET" target="HISTORICAL TEXT INPUT">
      <data key="d4">7.0</data>
      <data key="d5">Historical text input is used to reset to any step in language model tasks.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="OBSERVATION" target="TRAJECTORY">
      <data key="d4">8.0</data>
      <data key="d5">A trajectory includes observations about the situation in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ACTION" target="FINISH[ANSWER]">
      <data key="d4">14.0</data>
      <data key="d5">The entity "Finish[answer]" is a specific type of action performed within a question-answering task. This action is crucial as it returns the final answer and effectively concludes the task, marking the completion of the question-answering process.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ACTION" target="SEARCH[ENTITY]">
      <data key="d4">14.0</data>
      <data key="d5">The ACTION "Search[entity]" is a type of action performed in a question-answering task. Specifically, the Search[entity] action involves searching for a specific entity on Wikipedia. This action is integral to the process of retrieving accurate and relevant information about the entity in question, thereby facilitating the answering of queries with precise and comprehensive data.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ACTION" target="LOOKUP[KEYWORD]">
      <data key="d4">14.0</data>
      <data key="d5">The entity "ACTION" encompasses various operations within a question-answering task, one of which is "Lookup[keyword]." The "Lookup[keyword]" action is specifically designed to identify and return the next sentence that contains the specified keyword. This action plays a crucial role in efficiently locating relevant information based on keyword searches, thereby facilitating the process of answering questions accurately and promptly.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ACTION" target="TRAJECTORY">
      <data key="d4">8.0</data>
      <data key="d5">A trajectory includes actions that are performed in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="CHEN ET AL., 2021" target="SAFETY CONSIDERATIONS">
      <data key="d4">12.0</data>
      <data key="d5">Chen et al. are the authors of a work that discusses safety considerations for executing model-generated code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="REWARD" target="SUCCESS RATE (SR)">
      <data key="d4">8.0</data>
      <data key="d5">The success rate is defined as the portion of instructions where the reward equals 1.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="TRAJECTORY" target="VALUE FUNCTION PROMPT">
      <data key="d4">9.0</data>
      <data key="d5">The Value Function Prompt instructs the analysis of trajectories in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="TRAJECTORY" target="THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">A trajectory includes thoughts that reason about the current situation in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="TRAJECTORY" target="REFLECTION PROMPT">
      <data key="d4">9.0</data>
      <data key="d5">The Reflection Prompt instructs the analysis of trajectories in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="TRAJECTORY" target="SOLUTION">
      <data key="d4">8.0</data>
      <data key="d5">A trajectory leads to a solution in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="COT-SC" target="META AGENT SEARCH">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search outperforms the COT-SC algorithm in various domains. It leverages the COT-SC strategy to enhance the refinement of generated agents, indicating a symbiotic relationship where Meta Agent Search builds upon the foundational principles of COT-SC to achieve superior performance. This integration highlights the strengths of both algorithms, with Meta Agent Search utilizing the robust strategies of COT-SC to refine and optimize its agent generation process, thereby excelling in diverse applications.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="COT-SC" target="CHAIN-OF-THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">COT-SC is a variant of Chain-of-Thought, used for similar tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AUSTIN ET AL., 2022" target="MBPP">
      <data key="d4">6.0</data>
      <data key="d5">Austin et al. are the authors of the MBPP dataset, published in 2022.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="GAME OF 24" target="PROMPT METHOD">
      <data key="d4">6.0</data>
      <data key="d5">Prompt methods are used to guide language models in the Game of 24 task.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="TRAJECTORIES" target="VALUE FUNCTION PROMPT">
      <data key="d4">1.0</data>
      <data key="d5">The value function prompt instructs the analysis of solution trajectories.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="FEEDBACK" target="META AGENT SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses a sophisticated feedback mechanism to refine answers more effectively.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="FEEDBACK" target="INITIAL SOLUTION">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is generated after running examples to evaluate the correctness of the initial solution.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="CORRECT EXAMPLES">
      <data key="d4">7.0</data>
      <data key="d5">Correct Examples are part of the feedback indicating the examples that the initial solution passed.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="WRONG EXAMPLES">
      <data key="d4">1.0</data>
      <data key="d5">Wrong Examples are part of the feedback indicating the examples that the initial solution failed.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="CORRECT_COUNT">
      <data key="d4">1.0</data>
      <data key="d5">Correct Count is part of the feedback indicating the number of correct examples an initial solution passed.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="CODE">
      <data key="d4">9.0</data>
      <data key="d5">The code is evaluated to generate feedback for improvement.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="CORRECT_EXAMPLES">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is used to improve the code, which is then evaluated using correct examples.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="WRONG_EXAMPLES">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is used to improve the code, which is then evaluated using wrong examples.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="CONTENT">
      <data key="d4">9.0</data>
      <data key="d5">Content is the actual text or information contained within feedback.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="VERIFIED VISUAL">
      <data key="d4">7.0</data>
      <data key="d5">Feedback provided by the verification module helps improve the visual representation, leading to a verified visual.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="TOOLS" target="AGENTINSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct uses tools like search engines and code interpreters to generate high-quality data.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="SEARCH" target="INTERACTIVE INFORMATION RETRIEVAL">
      <data key="d4">8.0</data>
      <data key="d5">Search is one of the actions in the interactive information retrieval method.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="SEARCH" target="REFINE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Refining a search is a follow-up action to an initial search to better match desired results.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SEARCH" target="READING COMPREHENSION">
      <data key="d4">8.0</data>
      <data key="d5">Search is an application of reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="MBPP" target="EXPERT">
      <data key="d4">1.0</data>
      <data key="d5">Expert performance is used as a benchmark for comparison in MBPP.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="MBPP" target="PASS@1 ACCURACY">
      <data key="d4">8.0</data>
      <data key="d5">Pass@1 accuracy is used to evaluate the performance of models on the MBPP dataset.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="FURUTA ET AL., 2024" target="FINE-TUNING">
      <data key="d4">12.0</data>
      <data key="d5">Furuta et al., 2024, are the authors of a study that focuses on fine-tuning methods. Their research, published in 2024, involves the development and evaluation of fine-tuning techniques aimed at enhancing performance.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="COMPUTATIONAL COSTS" target="INFERENCE COSTS">
      <data key="d4">6.0</data>
      <data key="d5">Both computational and inference costs are constraints that affect the performance and feasibility of running algorithms.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="SYNTHETIC TEST SUITE" target="ASSERT STATEMENTS">
      <data key="d4">7.0</data>
      <data key="d5">Assert statements are part of the synthetic test suite used to evaluate the correctness of solutions.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="ACTION SPACE" target="COMPILER FEEDBACK">
      <data key="d4">7.0</data>
      <data key="d5">Action space and compiler feedback are components used in the decision-making process of programming tasks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="SOLUTION SELECTION" target="REAL TEST SUITE">
      <data key="d4">8.0</data>
      <data key="d5">Solution selection involves choosing the best solution based on evaluation with the real test suite.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="RL-BASED TRAINING" target="HUMAN PERFORMANCE">
      <data key="d4">1.0</data>
      <data key="d5">RL-based training aims to improve model performance to match or exceed human performance benchmarks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="A*" target="ZHUANG ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Zhuang et al. are the authors mentioned in the context of the A* algorithm.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="SUCCESS RATE" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses success rate as a performance metric.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="SCORE" target="ORCA-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Scores are used to evaluate model performance on the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="SCORE" target="NORMALIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Normalization is used to adjust scores to a common scale, normalizing the student's final score to a 0 to 10 scale.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="PERFORMANCE" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Performance is a measure used by the Meta Agent Search algorithm to evaluate and refine agents.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="PERFORMANCE" target="EVALUATION FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">Performance is an objective used in the evaluation function of ADAS to assess the effectiveness of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="PROMPTING TECHNIQUES" target="CHEN ET AL., 2023A">
      <data key="d4">6.0</data>
      <data key="d5">Chen et al. are the authors who contributed to the development of prompting techniques, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="PROMPTING TECHNIQUES" target="SCHULHOFF ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Schulhoff et al. are the authors who contributed to the development of prompting techniques, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="JEFF CLUNE" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune is one of the authors who formulated the research area of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d4">6.0</data>
      <data key="d5">Jeff Clune is affiliated with the University of British Columbia.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="VECTOR INSTITUTE">
      <data key="d4">6.0</data>
      <data key="d5">Jeff Clune is affiliated with the Vector Institute.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="CANADA CIFAR AI CHAIR">
      <data key="d4">7.0</data>
      <data key="d5">Jeff Clune holds the Canada CIFAR AI Chair.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="AI-GAS">
      <data key="d4">9.0</data>
      <data key="d5">Jeff Clune authored the paper "Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="JEFF CLUNE" target="THOUGHT CLONING">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune is one of the authors of the paper discussing Thought Cloning.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JEFF CLUNE" target="RUI WANG">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JEFF CLUNE" target="JOEL LEHMAN">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JEFF CLUNE" target="KENNETH O. STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JEFF CLUNE" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="EFFICIENCY" target="EXPERTS">
      <data key="d4">7.0</data>
      <data key="d5">Experts evaluate the efficiency trait in the feedback mechanism of ADAS.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="AAKANKSHA CHOWDHERY" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Aakanksha Chowdhery is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="HYUNG WON CHUNG" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Hyung Won Chung is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="SEBASTIAN GEHRMANN" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Sebastian Gehrmann is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="YI TAY" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Yi Tay is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="DENNY ZHOU" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Denny Zhou is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="DENNY ZHOU" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Denny Zhou is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="DENNY ZHOU" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Denny Zhou is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="DENNY ZHOU" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Denny Zhou is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="DENNY ZHOU" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Denny Zhou is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="XUEZHI WANG" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Xuezhi Wang is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="XUEZHI WANG" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Xuezhi Wang is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JASON WEI" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Jason Wei is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JASON WEI" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Jason Wei is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JASON WEI" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Jason Wei is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="DALE SCHUURMANS" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Dale Schuurmans is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="DALE SCHUURMANS" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Dale Schuurmans is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="PENGFEI LIU" target="YIXIN LIU">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PENGFEI LIU" target="ALEXANDER R. FABBRI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIMING YANG" target="PAL">
      <data key="d4">8.0</data>
      <data key="d5">Yiming Yang is one of the authors of the paper discussing Program-aided language models (PAL).</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JAMIE CALLAN" target="PAL">
      <data key="d4">8.0</data>
      <data key="d5">Jamie Callan is one of the authors of the paper discussing Program-aided language models (PAL).</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="GRAHAM NEUBIG" target="PAL">
      <data key="d4">8.0</data>
      <data key="d5">Graham Neubig is one of the authors of the paper discussing Program-aided language models (PAL).</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="XINYUN CHEN" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Xinyun Chen is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="XINYUN CHEN" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Xinyun Chen is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="SWAROOP MISHRA" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Swaroop Mishra is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="SWAROOP MISHRA" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Swaroop Mishra is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="HUAIXIU STEVEN ZHENG" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Huaixiu Steven Zheng is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="PERCY LIANG" target="XUECHEN LI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="TIANYI ZHANG">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="YANN DUBOIS">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="ROHAN TAORI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="ISHAAN GULRAJANI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="ALPACAEVAL">
      <data key="d4">8.0</data>
      <data key="d5">Percy Liang is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PETER CLARK" target="AI2 REASONING CHALLENGE (ARC)">
      <data key="d4">8.0</data>
      <data key="d5">Peter Clark is one of the authors of the paper introducing the AI2 Reasoning Challenge (ARC).</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="OPENAI" target="GET_JSON_RESPONSE_FROM_GPT">
      <data key="d4">8.0</data>
      <data key="d5">The get_json_response_from_gpt function uses a GPT model provided by OpenAI.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="OPENAI" target="GPT-4O-2024-05-13">
      <data key="d4">18.0</data>
      <data key="d5">OpenAI, a leading organization in artificial intelligence research and development, is responsible for creating the GPT-4O-2024-05-13 language model. This model, developed by OpenAI, represents a significant advancement in natural language processing, showcasing the organization's commitment to pushing the boundaries of AI technology.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="OPENAI" target="GPT-3.5-TURBO-0125">
      <data key="d4">18.0</data>
      <data key="d5">OpenAI, a leading organization in the field of artificial intelligence, is responsible for developing the GPT-3.5-turbo-0125 language model. This advanced model, known for its sophisticated natural language processing capabilities, represents a significant achievement in AI research and development.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TOOLFORMER" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">7.0</data>
      <data key="d5">Toolformer is a technique used as a building block in agentic systems within the ADAS research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHUNYU YAO" target="REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Shunyu Yao is one of the authors of the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="TOOLCHAIN*">
      <data key="d4">8.0</data>
      <data key="d5">Yuchen Zhuang is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHAO ZHANG" target="TOOLCHAIN*">
      <data key="d4">8.0</data>
      <data key="d5">Chao Zhang is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="HUGO TOUVRON" target="LOUIS MARTIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="KEVIN R. STONE">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="PETER ALBERT">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="AMJAD ALMAHAIRI">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="YASMINE BABAEI">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="NIKOLAY BASHLYKOV">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="SOUMYA BATRA">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="PRAJJWAL BHARGAVA">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="SHRUTI BHOSALE">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="DANIEL M. BIKEL">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="LUKAS BLECHER">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="CRISTIAN CANTON FERRER">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="MOYA CHEN">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="GUILLEM CUCURULL">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="DAVID ESIOBU">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="JUDE FERNANDES">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="JEREMY FU">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="WENYIN FU">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="BRIAN FULLER">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="CYNTHIA GAO">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="VEDANUJ GOSWAMI">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="NATHAN SCALES" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Nathan Scales is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="TOOLCHAIN*" target="XIANG CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Xiang Chen is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="TONG YU">
      <data key="d4">8.0</data>
      <data key="d5">Tong Yu is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="SAAYAN MITRA">
      <data key="d4">8.0</data>
      <data key="d5">Saayan Mitra is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="VICTOR BURSZTYN">
      <data key="d4">8.0</data>
      <data key="d5">Victor Bursztyn is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="RYAN A. ROSSI">
      <data key="d4">8.0</data>
      <data key="d5">Ryan A. Rossi is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="SOMDEB SARKHEL">
      <data key="d4">8.0</data>
      <data key="d5">Somdeb Sarkhel is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="ICLR 2023">
      <data key="d4">7.0</data>
      <data key="d5">The ToolChain* method was presented at ICLR 2023.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="WEBSHOP" target="YA0 ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors mentioned in relation to the WebShop environment.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="WEBSHOP" target="BRIGHT CITRUS DEODORANT">
      <data key="d4">8.0</data>
      <data key="d5">The webshop allows users to search for and purchase the Bright Citrus Deodorant.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="WEBSHOP" target="PRICE LOWER THAN 50.00 DOLLARS">
      <data key="d4">8.0</data>
      <data key="d5">The webshop allows users to set price constraints for their searches, such as less than 50.00 dollars.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="TOOLBENCH" target="QIN ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Qin et al. are the authors mentioned in relation to ToolBench.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="WIKIPEDIA WEB API" target="SEARCH [ENTITY]">
      <data key="d4">8.0</data>
      <data key="d5">Search [entity] is an action in the LATS algorithm that retrieves information from the Wikipedia web API.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="WIKIPEDIA WEB API" target="LOOKUP [STRING]">
      <data key="d4">8.0</data>
      <data key="d5">Lookup [string] is an action in the LATS algorithm that retrieves information from the Wikipedia web API.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="INTERACTIVE INFORMATION RETRIEVAL" target="LOOKUP">
      <data key="d4">8.0</data>
      <data key="d5">Lookup is one of the actions in the interactive information retrieval method.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="INTERACTIVE INFORMATION RETRIEVAL" target="FINISH">
      <data key="d4">8.0</data>
      <data key="d5">Finish is one of the actions in the interactive information retrieval method.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)" target="NATURAL LANGUAGE DESCRIPTIONS">
      <data key="d4">7.0</data>
      <data key="d5">MBPP uses natural language descriptions to describe programming tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)" target="CROWDSOURCING">
      <data key="d4">7.0</data>
      <data key="d5">MBPP dataset was constructed by crowdsourcing from workers with basic Python knowledge.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)" target="PYTHON STANDARD LIBRARY">
      <data key="d4">6.0</data>
      <data key="d5">MBPP includes tasks that involve the use of the Python standard library.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="RESULTS" target="PRODUCT TITLE">
      <data key="d4">7.0</data>
      <data key="d5">Each result in the list has a product title that identifies the product.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="OPTION" target="ITEM">
      <data key="d4">7.0</data>
      <data key="d5">Each item may have various options, such as size or color, that can be selected.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="DESC/OVERVIEW" target="ITEM">
      <data key="d4">7.0</data>
      <data key="d5">Each item has a description or overview that provides detailed information about its features.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ITEM" target="ITEM-DETAIL">
      <data key="d4">7.0</data>
      <data key="d5">The item-detail provides more detailed information about the item, including its description and options.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ITEM" target="EPISODE END">
      <data key="d4">8.0</data>
      <data key="d5">The interaction session with the web shop concludes when the user chooses to buy an item.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ENVIRONMENTS" target="DEPTH LIMIT">
      <data key="d4">7.0</data>
      <data key="d5">Experiments are conducted in different environments with a maximum depth limit.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="THOUGHT" target="META AGENT">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent captures its thought process in the "thought" section of the output.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="THOUGHT" target="INSIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">The "thought" section includes insights on what should be the next interesting agent.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="THOUGHT" target="OVERALL IDEA">
      <data key="d4">8.0</data>
      <data key="d5">The "thought" section includes the overall idea and reasoning behind the agent design.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="THOUGHT" target="IMPLEMENTATION">
      <data key="d4">8.0</data>
      <data key="d5">The "thought" section includes detailed implementation steps of the proposed agent.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="FIRST FOR WOMEN">
      <data key="d4">6.0</data>
      <data key="d5">Both are magazines, and the task involves determining which was started first.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="TIMOTHY SHAY ARTHUR">
      <data key="d4">15.0</data>
      <data key="d5">Timothy Shay Arthur was the editor of Arthur's Magazine.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="GODEY'S LADY'S BOOK">
      <data key="d4">13.0</data>
      <data key="d5">Arthur's Magazine was merged into Godey's Lady's Book in May 1846.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="EDGAR A. POE">
      <data key="d4">12.0</data>
      <data key="d5">Edgar A. Poe was a contributor to Arthur's Magazine.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="J.H. INGRAHAM">
      <data key="d4">12.0</data>
      <data key="d5">Arthur's Magazine featured contributions from J.H. Ingraham, who was one of its notable contributors.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="SARAH JOSEPHA HALE">
      <data key="d4">12.0</data>
      <data key="d5">Sarah Josepha Hale was a contributor to Arthur's Magazine. She played a significant role as one of the contributors, enriching the publication with her insights and writings. Arthur's Magazine, known for its diverse and engaging content, benefited from Hale's contributions, which added depth and variety to its offerings.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="THOMAS G. SPEAR">
      <data key="d4">12.0</data>
      <data key="d5">Thomas G. Spear was a contributor to Arthur's Magazine. He was one of the contributors to this publication, indicating his involvement in the creation and dissemination of its content. Arthur's Magazine, therefore, benefited from the contributions of individuals like Thomas G. Spear, who played a role in shaping its editorial voice and enriching its offerings to readers.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="FIRST FOR WOMEN" target="BAUER MEDIA GROUP">
      <data key="d4">7.0</data>
      <data key="d5">First for Women is published by Bauer Media Group.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="COLORADO OROGENY" target="HIGH PLAINS">
      <data key="d4">7.0</data>
      <data key="d5">The Colorado orogeny extends into the High Plains.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="QUESTION-ANSWERING TASK">
      <data key="d4">9.0</data>
      <data key="d5">The Value Function Prompt provides instructions for analyzing a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="CORRECTNESS SCORE">
      <data key="d4">7.0</data>
      <data key="d5">The value function prompt asks for a correctness score based on the purchase trajectory</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BACK TO SEARCH" target="INVALID ACTION">
      <data key="d4">8.0</data>
      <data key="d5">The action of clicking "Back to Search" was invalid.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SOLUTION" target="CORRECTNESS SCORE">
      <data key="d4">9.0</data>
      <data key="d5">The solution is evaluated and given a correctness score from 1 to 10.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ANSWER" target="FINAL_THOUGHTS">
      <data key="d4">9.0</data>
      <data key="d5">The final thoughts include the final code, which produces the answer.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="ANSWER" target="INTEGRATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The integration module combines sub-problem solutions to produce the final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ANSWER" target="CHAIN-OF-THOUGHT MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Chain-of-Thought module uses verified visual representations to solve problems and generate the final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ANSWER" target="VERIFIED VISUAL">
      <data key="d4">8.0</data>
      <data key="d5">The verified visual representation is used by the Chain-of-Thought module to solve problems and generate the final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VALIDATION" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">Validation is a limitation of AgentInstruct, as it can be difficult to ensure synthetic data accurately represents desired scenarios.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="BASELINES" target="GPT-3.5-TURBO-0125">
      <data key="d4">2.0</data>
      <data key="d5">Baselines use the GPT-3.5-turbo-0125 model for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="BASELINES" target="SHENGRAN HU">
      <data key="d4">6.0</data>
      <data key="d5">Shengran Hu is mentioned in the context of providing detailed implementations of all baselines.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="BASELINES" target="ORCA-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Baseline models like Orca-2.5, Mistral-Instruct-7B, and ChatGPT are evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="BASELINES" target="INFERIORITY">
      <data key="d4">8.0</data>
      <data key="d5">Baseline models like Orca-2.5, Mistral-Instruct-7B, and ChatGPT show relative inferiority to GPT-4.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="QUESTIONS" target="READING COMPREHENSION TESTS">
      <data key="d4">7.0</data>
      <data key="d5">Questions are used in reading comprehension tests to assess the reader&#8217;s understanding.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="QUESTIONS" target="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d4">7.0</data>
      <data key="d5">Questions are used in open domain question answering to generate responses.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="PLAINS" target="ELEVATION">
      <data key="d4">9.0</data>
      <data key="d5">Plains rise in elevation from around 1,800 to 7,000 feet.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="REFLECTION PROMPT" target="QUESTION-ANSWERING TASK">
      <data key="d4">9.0</data>
      <data key="d5">The Reflection Prompt provides instructions for analyzing a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="REFLECTION PROMPT" target="CORRECTNESS SCORE">
      <data key="d4">1.0</data>
      <data key="d5">The reflection prompt is used to diagnose reasons for a low correctness score and improve future performance</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="PROGRAMMING PROMPT" target="MINSUBARRAYSUM">
      <data key="d4">8.0</data>
      <data key="d5">The Programming Prompt provides instructions for implementing the minSubArraySum function.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="PROGRAMMING PROMPT" target="SAMPLE FUNCTION SIGNATURE">
      <data key="d4">8.0</data>
      <data key="d5">The Programming Prompt provides a sample function signature for implementing a function.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="PROGRAMMING PROMPT" target="SAMPLE FUNCTION BODY">
      <data key="d4">8.0</data>
      <data key="d5">The Programming Prompt provides a sample function body for implementing a function.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="MINSUBARRAYSUM" target="UNIT TEST">
      <data key="d4">1.0</data>
      <data key="d5">Unit tests validate the correctness of the minSubArraySum function implementation.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="UNIT TEST" target="SAMPLE FUNCTION BODY">
      <data key="d4">1.0</data>
      <data key="d5">Unit tests validate the correctness of the sample function body implementation.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="UNIT TEST" target="ADD FUNCTION">
      <data key="d4">9.0</data>
      <data key="d5">The ADD FUNCTION is validated using UNIT TESTS to check if it returns the correct sum of two integers.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="UNIT TEST" target="ERROR">
      <data key="d4">8.0</data>
      <data key="d5">UNIT TESTS help identify ERRORS in the function implementation by comparing expected and actual outputs.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="AI PYTHON ASSISTANT" target="FUNCTION IMPLEMENTATION">
      <data key="d4">9.0</data>
      <data key="d5">The AI Python assistant provides and improves function implementations based on user input and test results.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="FUNCTION IMPLEMENTATION" target="UNIT TEST RESULTS">
      <data key="d4">9.0</data>
      <data key="d5">Unit test results are used to validate the correctness of a function implementation.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="UNIT TEST RESULTS" target="TEST CASE GENERATION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The test case generation prompt helps create unit tests that will produce results for validating function implementations.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="EARTH MAMA">
      <data key="d4">9.0</data>
      <data key="d5">Bright Citrus Deodorant is a product offered by the Earth Mama brand.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="BRIGHT CITRUS DEODORANT BY EARTH MAMA">
      <data key="d4">9.0</data>
      <data key="d5">BRIGHT CITRUS DEODORANT BY EARTH MAMA is a specific product that matches the search criteria for BRIGHT CITRUS DEODORANT.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="SENSITIVE SKIN">
      <data key="d4">9.0</data>
      <data key="d5">Bright Citrus Deodorant is suitable for sensitive skin</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="PREGNANCY AND BREASTFEEDING">
      <data key="d4">9.0</data>
      <data key="d5">Bright Citrus Deodorant is safe for use during pregnancy and breastfeeding</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="ORGANIC CALENDULA">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant contains organic calendula</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="3 OUNCE (PACK OF 1)">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in a 3-ounce size</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="ASSORTED SCENTS">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in assorted scents</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="BRIGHT CITRUS">
      <data key="d4">9.0</data>
      <data key="d5">Bright Citrus Deodorant is available in the bright citrus scent</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="CALMING LAVENDER">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in the calming lavender scent</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="GINGER FRESH">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in the ginger fresh scent</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="SIMPLY NON-SCENTS">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in the simply non-scents option</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="TRAVEL SET (4-PACK)">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in a travel set (4-pack) size</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="3 OUNCE (2-PACK)">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in a 3 ounce (2-pack) size</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="EARTH MAMA" target="GINGER FRESH DEODORANT">
      <data key="d4">9.0</data>
      <data key="d5">Ginger Fresh Deodorant is a product offered by the Earth Mama brand.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="GINGER FRESH DEODORANT" target="GINGER FRESH DEODORANT BY EARTH MAMA">
      <data key="d4">9.0</data>
      <data key="d5">GINGER FRESH DEODORANT BY EARTH MAMA is a specific product that matches the search criteria for GINGER FRESH DEODORANT.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BARREL AND OAK" target="CEDAR &amp; PATCHOULI DEODORANT">
      <data key="d4">1.0</data>
      <data key="d5">Cedar &amp; Patchouli Deodorant is a product offered by the Barrel and Oak brand.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="CEDAR &amp; PATCHOULI DEODORANT" target="BARREL AND OAK DEODORANT">
      <data key="d4">1.0</data>
      <data key="d5">BARREL AND OAK DEODORANT includes the CEDAR &amp; PATCHOULI DEODORANT as one of its product variants.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="MIN SUM" target="CURRENT SUM">
      <data key="d4">7.0</data>
      <data key="d5">MIN SUM is updated based on the value of CURRENT SUM during the function execution.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="DOCSTRING">
      <data key="d4">7.0</data>
      <data key="d5">The ADD FUNCTION includes a DOCSTRING that describes its purpose and behavior.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="SIGNATURE">
      <data key="d4">8.0</data>
      <data key="d5">The ADD FUNCTION has a SIGNATURE that declares its name, parameters, and return type.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ERROR" target="OPERATOR">
      <data key="d4">9.0</data>
      <data key="d5">The ERROR in the ADD FUNCTION was due to the incorrect use of the '-' OPERATOR instead of '+'.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ERROR" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Errors are mistakes or incorrect results produced by agents in the Meta Agent Search algorithm, which need to be refined.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="DAIRY FREE" target="ENJOY LIFE FOODS SOFT BAKED OVALS">
      <data key="d4">27.0</data>
      <data key="d5">Enjoy Life Foods Soft Baked Ovals are dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="DAIRY FREE" target="ENJOY LIFE SOFT BAKED CHEWY BARS">
      <data key="d4">27.0</data>
      <data key="d5">Enjoy Life Soft Baked Chewy Bars are dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="DAIRY FREE" target="ENJOY LIFE LENTIL CHIPS VARIETY PACK">
      <data key="d4">27.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="APPLE VARIETY PACK OF CHIPS" target="ENJOY LIFE LENTIL CHIPS VARIETY PACK">
      <data key="d4">23.0</data>
      <data key="d5">The APPLE VARIETY PACK OF CHIPS and the ENJOY LIFE LENTIL CHIPS VARIETY PACK are both products that can be searched for in the web shop. The Enjoy Life Lentil Chips Variety Pack is specifically identified as the apple variety pack of chips that the user desires.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="APPLE VARIETY PACK OF CHIPS" target="ENJOY LIFE FOODS SOFT BAKED OVALS">
      <data key="d4">5.0</data>
      <data key="d5">Both are products that can be searched for in the web shop</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="APPLE VARIETY PACK OF CHIPS" target="ENJOY LIFE SOFT BAKED CHEWY BARS">
      <data key="d4">5.0</data>
      <data key="d5">Both are products that can be searched for in the web shop</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="VARIETY PACK">
      <data key="d4">24.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack includes multiple varieties or flavors and is available as a variety pack.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="0.8 OUNCE (PACK OF 24)">
      <data key="d4">24.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack is available in a 0.8 ounce size per pack, with a total of 24 packs included in the package.</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="DILL AND SOUR CREAM">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in the dill and sour cream flavor</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="GARLIC &amp; PARMESAN">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in the garlic &amp; parmesan flavor</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="LIGHT SEA SALT">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in the light sea salt flavor</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="MARGHERITA PIZZA">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in the margherita pizza flavor</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="THAI CHILI LIME">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in the thai chili lime flavor</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="4 OUNCE (PACK OF 12)">
      <data key="d4">1.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in a 4 ounce (pack of 12) size</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="BUY NOW">
      <data key="d4">18.0</data>
      <data key="d5">The user decided to buy the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="FLAVOR NAME">
      <data key="d4">8.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack includes different flavor options</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="SIZE">
      <data key="d4">8.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack is available in different size options</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="RATING">
      <data key="d4">7.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has a rating attribute</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="DESCRIPTION">
      <data key="d4">7.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has a detailed description</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="FEATURES">
      <data key="d4">7.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has specific features</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="REVIEWS">
      <data key="d4">1.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has customer reviews</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="SMOKED BACON SEA SALT 3-PACK">
      <data key="d4">14.0</data>
      <data key="d5">Smoked Bacon Sea Salt 3-Pack is a similar product to gluten-free vegetarian smoked peppered bacon</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="LOUISVILLE VEGAN JERKY">
      <data key="d4">14.0</data>
      <data key="d5">Louisville Vegan Jerky is a similar product to gluten-free vegetarian smoked peppered bacon</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="NON-GMO">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky is labeled as non-GMO.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="GLUTEN-FREE">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky is labeled as gluten-free.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="BLACK PEPPER">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky includes Black Pepper as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="BUFFALO DILL">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky includes Buffalo Dill as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="PEPPERONI">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky includes Pepperoni as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="MAPLE BACON">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky includes Maple Bacon as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="CAROLINA BBQ">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky includes Carolina BBQ as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="RATING" target="STUDENT RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">Student responses are rated against teacher responses on a scale from 0 to 10.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="NON-GMO">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as non-GMO.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="GLUTEN-FREE">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as gluten-free.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="KOSHER">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as kosher.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="NO MSG">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as containing no MSG.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="GHOST PEPPER">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack includes Ghost Pepper as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="JALAPENO">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack includes Jalapeno as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="HABANERO">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack includes Habanero as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="VEGETARIAN BACON" target="4 OUNCE PACK OF 2">
      <data key="d4">7.0</data>
      <data key="d5">The user is looking for vegetarian bacon that comes in a 4-ounce pack of 2.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="FAIL" target="INVALID ACTION">
      <data key="d4">8.0</data>
      <data key="d5">The status of "Fail" was reached due to invalid actions.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="INVALID ACTION" target="NEXT">
      <data key="d4">8.0</data>
      <data key="d5">The action of clicking "Next" was invalid.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="META AGENT SEARCH">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search is an algorithm used within the ADAS research area to automatically create and discover new agents.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="SHENGRAN HU">
      <data key="d4">8.0</data>
      <data key="d5">Shengran Hu is one of the authors who formulated the research area of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="CONG LU">
      <data key="d4">8.0</data>
      <data key="d5">Cong Lu is one of the authors who formulated the research area of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="CHAIN-OF-THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought is a technique used as a building block in agentic systems within the ADAS research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="ROCKT&#196;SCHEL, 2024">
      <data key="d4">6.0</data>
      <data key="d5">Rockt&#228;schel is cited in the paper for contributions to the research on agentic systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="ZAHARIA ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Zaharia et al. are cited in the paper for contributions to the research on agentic systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d4">6.0</data>
      <data key="d5">Shengran Hu is affiliated with the University of British Columbia.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="VECTOR INSTITUTE">
      <data key="d4">6.0</data>
      <data key="d5">Shengran Hu is affiliated with the Vector Institute.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="THOUGHT CLONING">
      <data key="d4">8.0</data>
      <data key="d5">Shengran Hu is one of the authors of the paper discussing Thought Cloning.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="SHENGRAN HU" target="GITHUB">
      <data key="d4">1.0</data>
      <data key="d5">Shengran Hu is the author of the framework code available on GitHub.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SHENGRAN HU" target="ADAS">
      <data key="d4">14.0</data>
      <data key="d5">Shengran Hu is associated with the repository at https://github.com/ShengranHu/ADAS.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="CONG LU" target="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d4">6.0</data>
      <data key="d5">Cong Lu is affiliated with the University of British Columbia.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONG LU" target="VECTOR INSTITUTE">
      <data key="d4">6.0</data>
      <data key="d5">Cong Lu is affiliated with the Vector Institute.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-STEP PEER REVIEW AGENT">
      <data key="d4">22.0</data>
      <data key="d5">The Multi-Step Peer Review Agent is an example of an agent discovered by the Meta Agent Search algorithm. Specifically, the Multi-Step Peer Review Agent was identified by Meta Agent Search within the Reading Comprehension domain. This highlights the capability of the Meta Agent Search algorithm to uncover specialized agents tailored to specific domains, demonstrating its utility in enhancing the understanding and performance of tasks related to reading comprehension.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VERIFIED MULTIMODAL AGENT">
      <data key="d4">22.0</data>
      <data key="d5">The Verified Multimodal Agent is an example of an agent discovered by the Meta Agent Search algorithm. Specifically, the Verified Multimodal Agent was identified within the Math domain through the application of the Meta Agent Search. This highlights the algorithm's capability to uncover specialized agents in specific fields, demonstrating its effectiveness and precision in agent discovery.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DIVIDE AND CONQUER AGENT">
      <data key="d4">22.0</data>
      <data key="d5">The Divide and Conquer Agent is an example of an agent discovered by the Meta Agent Search algorithm. The Meta Agent Search algorithm identified the Divide and Conquer Agent, showcasing its capability to uncover effective agents within a given problem space. This discovery highlights the efficiency and potential of the Meta Agent Search in exploring and identifying optimal solutions through its systematic search methodology.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="META AGENT">
      <data key="d4">18.0</data>
      <data key="d5">Meta Agent Search is an algorithm where a meta agent programs other agents, tests their performance, and refines them iteratively. This process involves using meta agents to iteratively program new agents based on an archive of previous discoveries. The meta agent plays a crucial role in continuously improving the performance of the agents by leveraging past experiences and refining the agents through a cycle of programming and testing. This iterative refinement ensures that the agents evolve and adapt, leading to progressively better performance over time.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="AGENT ARCHIVE">
      <data key="d4">8.0</data>
      <data key="d5">The agent archive is used by the Meta Agent Search algorithm to store discovered agents and inform subsequent iterations.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CODE">
      <data key="d4">7.0</data>
      <data key="d5">Code refers to the programming instructions used by the Meta Agent Search algorithm to define the behavior of agents.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="TURING COMPLETE">
      <data key="d4">8.0</data>
      <data key="d5">The Meta Agent Search algorithm leverages the Turing Complete nature of programming languages to enable the learning of any possible agentic system.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ADAS">
      <data key="d4">70.0</data>
      <data key="d5">META AGENT SEARCH is an algorithm developed within the research area of Automated Design of Agentic Systems (ADAS). It is a proposed method specifically for ADAS, showcasing the potential and effectiveness in discovering superior agents. The algorithm is used to program new agents in code and demonstrates the approach of defining and searching for agents. As part of the ADAS framework, Meta Agent Search plays a crucial role in advancing the study and application of agentic systems.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FMS">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search uses foundational models (FMs) as meta agents to program new agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FUNSEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a similar practice to FunSearch in defining a "forward" function to create new agentic systems.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC">
      <data key="d4">25.0</data>
      <data key="d5">Meta Agent Search is a system designed to discover and evaluate agents using the ARC (Abstraction and Reasoning Corpus) benchmark. It specifically focuses on identifying the best-performing agents by assessing their capabilities through the ARC logic puzzle task. The ARC benchmark serves as a critical evaluation tool, ensuring that the agents discovered by Meta Agent Search are proficient in solving complex reasoning and abstraction problems.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DROP">
      <data key="d4">15.0</data>
      <data key="d5">Meta Agent Search is evaluated and tested using the DROP benchmark to assess and evaluate its reading comprehension abilities.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MGSM">
      <data key="d4">23.0</data>
      <data key="d5">META AGENT SEARCH is a system designed to discover agents, which are then evaluated on their performance in the math domain using the MGSM benchmark. MGSM serves as a standard for assessing the math abilities and capabilities of these agents. The effectiveness of META AGENT SEARCH is determined by how well the discovered agents perform on the MGSM benchmark, making it a crucial tool for evaluating the system's success in the math domain.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM8K">
      <data key="d4">15.0</data>
      <data key="d5">META AGENT SEARCH is a method that enhances accuracy in the GSM8K dataset when compared to baseline models. It is specifically evaluated using the GSM8K dataset to determine the transferability of agents discovered from MGSM math tasks. This evaluation highlights the effectiveness of Meta Agent Search in improving performance metrics within the context of GSM8K, showcasing its potential in advancing algorithmic accuracy and transferability in mathematical problem-solving tasks.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM-HARD">
      <data key="d4">15.0</data>
      <data key="d5">Meta Agent Search is a sophisticated algorithm evaluated using the GSM-Hard dataset to assess the transferability of discovered agents from MGSM math tasks. It demonstrates improved accuracy in the GSM-Hard dataset compared to baseline methods, highlighting its effectiveness in enhancing performance within this specific context.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">13.0</data>
      <data key="d5">META AGENT SEARCH employs the Chain-of-Thought (COT) strategy as a key component in its operations. Specifically, it uses COT as one of the state-of-the-art hand-designed agents for comparison purposes. Additionally, META AGENT SEARCH leverages the COT strategy to generate, refine, and ensemble answers, showcasing its multifaceted application within the system. This integration highlights the importance of COT in enhancing the performance and accuracy of META AGENT SEARCH.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LLM DEBATE">
      <data key="d4">13.0</data>
      <data key="d5">Meta Agent Search is an advanced algorithm that outperforms the LLM Debate algorithm in various domains. It leverages the LLM Debate strategy, which involves multiple critics for enhanced refinement, to achieve superior performance. This combination of techniques allows Meta Agent Search to excel in complex tasks by utilizing a collaborative approach to problem-solving and continuous improvement.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="QUALITY-DIVERSITY">
      <data key="d4">19.0</data>
      <data key="d5">META AGENT SEARCH is a sophisticated algorithm that outperforms the Quality-Diversity algorithm in various domains. It leverages the Quality-Diversity strategy to explore novel or worthwhile agents, demonstrating its advanced capabilities in identifying and utilizing high-quality agents. Additionally, Meta Agent Search uses Quality-Diversity as one of the state-of-the-art hand-designed agents for comparison, highlighting its effectiveness and superiority in diverse applications.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FORWARD FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses a forward function to define new agentic systems.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VALIDATION DATA">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses validation data to evaluate the performance of generated agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BOOTSTRAP CONFIDENCE INTERVAL">
      <data key="d4">21.0</data>
      <data key="d5">Meta Agent Search employs the bootstrap confidence interval as a key metric to evaluate the performance of generated agents. It reports test accuracy using these intervals, providing a robust measure of the median accuracy and variability of agent performance. This approach ensures a comprehensive assessment of the agents' effectiveness, highlighting both central tendencies and the range of possible outcomes.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ITERATION">
      <data key="d4">16.0</data>
      <data key="d5">META AGENT SEARCH involves an iterative process of programming, evaluating, and updating agents. This process includes repeated iterations to discover and refine agents, ensuring continuous improvement and optimization.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARCHIVE">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search maintains an archive of previous discoveries and evaluation metrics, updated at every iteration.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXPERIMENT">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search is evaluated through various experiments on different benchmarks and tasks. The experiment was conducted using the Meta Agent Search method to discover the best agent. This comprehensive evaluation process ensures that the Meta Agent Search method is rigorously tested across diverse scenarios, providing a robust assessment of its effectiveness in identifying optimal agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BENCHMARK">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is evaluated using benchmarks like ARC, DROP, and MGSM.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="F1 SCORE">
      <data key="d4">15.0</data>
      <data key="d5">Meta Agent Search employs the F1 Score as a key metric to evaluate agent performance. This performance metric is particularly utilized in reading comprehension tasks, ensuring a comprehensive assessment of the agents' capabilities in understanding and processing textual information.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ACCURACY RATE">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses accuracy rate as a performance metric, particularly in math tasks.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DYNAMIC MEMORY">
      <data key="d4">13.0</data>
      <data key="d5">Meta Agent Search introduces dynamic memory for more refinements during the programming of new agents. This enhancement allows for more efficient and effective refinements, ensuring that the development of new agents is optimized. The integration of dynamic memory within Meta Agent Search signifies a significant advancement in the algorithmic community, highlighting the importance of adaptive memory management in the continuous improvement of agent programming.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ENSEMBLING">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search uses ensembling to combine multiple answers generated by the Chain-of-Thought strategy.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CRITIC">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses critics to provide feedback and enhance the refinement of generated agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EFFICIENCY EXPERT">
      <data key="d4">13.0</data>
      <data key="d5">Meta Agent Search employs efficiency experts to provide critical feedback on the efficiency of answers and to improve the efficiency of generated agents. These experts act as critics, ensuring that the agents developed are optimized for performance and effectiveness.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="READABILITY EXPERT">
      <data key="d4">13.0</data>
      <data key="d5">Meta Agent Search employs readability experts to enhance the clarity and comprehensibility of its generated agents. These experts provide critical feedback on the readability of answers, ensuring that the output is easily understandable and accessible. By leveraging the expertise of readability critics, Meta Agent Search continuously improves the readability and overall quality of its generated content.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SIMPLICITY">
      <data key="d4">1.0</data>
      <data key="d5">Meta Agent Search aims to achieve simplicity in the generated agents, often evaluated by critics like the readability expert.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC CHALLENGE">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search is used to discover high-performance agents that outperform existing state-of-the-art hand-designed agents in the ARC challenge.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search uses Self-Consistency with Chain-of-Thought (COT-SC) as one of the state-of-the-art hand-designed agents for comparison.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LLM-DEBATE">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search uses LLM-Debate as one of the state-of-the-art hand-designed agents for comparison.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXPERTS">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search incorporates feedback from experts to refine answers more effectively.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ENSEMBLE">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses the ensemble process to combine multiple answers to produce a final, more accurate answer.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FALDOR ET AL., 2024">
      <data key="d4">5.0</data>
      <data key="d5">Faldor et al. have worked on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LEHMAN &amp; STANLEY, 2011">
      <data key="d4">5.0</data>
      <data key="d5">Lehman &amp; Stanley have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="WANG ET AL., 2019, 2020">
      <data key="d4">5.0</data>
      <data key="d5">Wang et al. have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ZHANG ET AL., 2024A">
      <data key="d4">1.0</data>
      <data key="d5">Zhang et al. have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTIPLE CRITICS">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search introduces multiple critics for enhanced refinement.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="META-AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The meta-agent in Meta Agent Search is responsible for discovering high-performance agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HUMAN-LIKE CRITIC">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a human-like critic to provide feedback and simulate human evaluation.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SIMPLICITY EXPERT">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a simplicity expert to provide feedback on the simplicity of answers.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FEEDBACK EFFICIENCY">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search aims to improve feedback efficiency to refine answers more effectively.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="REFINEMENT">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search involves the process of refinement to improve answers through iterative feedback and evaluation.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HELD-OUT TEST SET">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a held-out test set to evaluate the performance of discovered agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="PUBLIC TRAINING SET (EASY)">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses the Public Training Set (Easy) for training agents in the ARC challenge.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VALIDATION SET">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a validation set to assess the performance of agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="TEST SET">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a test set to evaluate the final performance of agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STOCHASTIC SAMPLING">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses stochastic sampling to reduce variance in the evaluation of agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="TOOL FUNCTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search provides tool functions to evaluate the generated transformation code in the ARC challenge.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search involves solving ARC questions to evaluate agent performance.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="APPENDIX C">
      <data key="d4">6.0</data>
      <data key="d5">Appendix C contains detailed implementation of the best-discovered agent and more algorithmic details and examples of ARC questions.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="APPENDIX E">
      <data key="d4">6.0</data>
      <data key="d5">Appendix E contains more details about the baselines used in Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STEPPING STONES">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses the concept of stepping stones to progressively discover superior agents.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MMLU">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is tested on the MMLU benchmark for evaluating multi-task problem solving.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPQA">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is tested on the GPQA benchmark for evaluating science capabilities.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CHAIN-OF-THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search outperforms the Chain-of-Thought algorithm in various domains.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STEP-BACK ABSTRACTION">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search outperforms the Step-back Abstraction algorithm in various domains.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ROLE ASSIGNMENT">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search outperforms the Role Assignment algorithm in various domains.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ACCURACY">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses accuracy as a metric to evaluate agent performance.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXPERIMENT SETTINGS">
      <data key="d4">7.0</data>
      <data key="d5">Experiment settings are the specific configurations under which Meta Agent Search is tested.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FOUNDATIONAL MODELS (FMS)">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search optimizes agentic systems based on the knowledge possessed by foundational models.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="READING COMPREHENSION">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search is a technique that enhances performance in the Reading Comprehension domain. It is particularly effective when foundational models already possess adequate knowledge, thereby leveraging existing capabilities to achieve superior results.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM8K (COBBE ET AL., 2021)">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search discovers agents that are evaluated on the GSM8K benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM-HARD (GAO ET AL., 2023)">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search discovers agents that are evaluated on the GSM-Hard benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SVAMP (PATEL ET AL., 2021)">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search discovers agents that are evaluated on the SVAMP benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ASDIV (MIAO ET AL., 2020)">
      <data key="d4">1.0</data>
      <data key="d5">Meta Agent Search discovers agents that are evaluated on the ASDiv benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-TASK">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search significantly enhances performance in the Multi-task domain. It not only improves overall efficiency but also consistently outperforms baseline methods, establishing itself as a superior approach within this domain.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SCIENCE">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search is a sophisticated algorithm that excels in the Science domain. It not only matches the state-of-the-art performance but also outperforms existing baselines, demonstrating its superior capability and efficiency in handling complex scientific queries and tasks.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HALLUCINATIONS">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search helps mitigate hallucinations in foundational models.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CALCULATION MISTAKES">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search helps mitigate calculation mistakes in foundational models.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d4">15.0</data>
      <data key="d5">Dynamic Role-Playing Architecture is a top agent discovered by Meta Agent Search. Initially identified for its exceptional performance in the math domain, this agent has been successfully transferred to non-math domains, where it continues to demonstrate specific performance metrics. This highlights the versatility and adaptability of the Dynamic Role-Playing Architecture, underscoring the efficacy of Meta Agent Search in identifying high-performing agents across various domains.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d4">15.0</data>
      <data key="d5">The Structured Multimodal Feedback Loop is a top agent discovered by Meta Agent Search. Initially identified for its exceptional performance in the math domain, this agent has been successfully transferred to non-math domains, where it continues to demonstrate specific performance metrics. This highlights the versatility and robustness of the Structured Multimodal Feedback Loop across various fields, underscoring the efficacy of Meta Agent Search in identifying high-performing agents.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META AGENT SEARCH" target="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d4">15.0</data>
      <data key="d5">The Interactive Multimodal Feedback Loop is a top agent discovered by Meta Agent Search. Initially identified for its exceptional performance in the math domain, this agent has been successfully transferred to non-math domains, where it continues to demonstrate specific performance metrics. This highlights the versatility and adaptability of the Interactive Multimodal Feedback Loop, underscoring the efficacy of Meta Agent Search in identifying high-performing agents across various domains.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SAFETY CONSIDERATIONS">
      <data key="d4">18.0</data>
      <data key="d5">Safety considerations are advised when executing untrusted model-generated code in Meta Agent Search.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SANDBOX ENVIRONMENTS">
      <data key="d4">16.0</data>
      <data key="d5">Sandbox environments are recommended for safely running untrusted model-generated code in Meta Agent Search.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HIGHER-ORDER ADAS">
      <data key="d4">14.0</data>
      <data key="d5">Higher-order ADAS involves improving the meta agent used in Meta Agent Search through self-referential meta-learning.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">Novelty search algorithms can be incorporated into Meta Agent Search to explore interesting new designs.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SINGLE-STEP QA TASKS">
      <data key="d4">12.0</data>
      <data key="d5">Single-step QA tasks are used to evaluate Meta Agent Search.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-STEP INTERACTION">
      <data key="d4">12.0</data>
      <data key="d5">Multi-step interaction is proposed as a future direction for Meta Agent Search to handle more complex tasks.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="COMPLEX DOMAINS">
      <data key="d4">6.0</data>
      <data key="d5">Complex domains are proposed as a future direction for Meta Agent Search to handle more complex tasks.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BEST AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The best agent was discovered through the Meta Agent Search method.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GITHUB">
      <data key="d4">7.0</data>
      <data key="d5">The code and agents from the Meta Agent Search experiment can be found on GitHub.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPT-4O-MINI">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search could achieve improved results at a lower cost using the GPT-4o-mini model.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="CLAUDE">
      <data key="d4">7.0</data>
      <data key="d5">Claude is an example of a Foundation Model used for agentic tasks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="ADAS">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models (FMs) are used as modules in the control flow of agentic systems within the ADAS framework.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models (FMs) are used as modules in the control flow of agentic systems to solve tasks.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">9.0</data>
      <data key="d5">Foundation Models are used in AI-GAs to write code for discovering better optimization algorithms, programming loss functions, and creating learning environments.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="AUTOML">
      <data key="d4">9.0</data>
      <data key="d5">Foundation Models are used in AutoML to write code for discovering better optimization algorithms, programming loss functions, and creating learning environments.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="OMNI-EPIC">
      <data key="d4">8.0</data>
      <data key="d5">OMNI-EPIC uses Foundation Models to create robotics learning environments by programming in code.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="FUNSEARCH">
      <data key="d4">8.0</data>
      <data key="d5">FunSearch uses Foundation Models to write code for discovering better optimization algorithms.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="EOH">
      <data key="d4">8.0</data>
      <data key="d5">EoH uses Foundation Models to write code for discovering better optimization algorithms.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="DISCOPOP">
      <data key="d4">8.0</data>
      <data key="d5">DiscoPOP uses Foundation Models to program the loss function for preference learning in FM alignment training.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="EUREKA">
      <data key="d4">8.0</data>
      <data key="d5">Eureka uses Foundation Models to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="LANGUAGE-TO-REWARD">
      <data key="d4">8.0</data>
      <data key="d5">Language-to-Reward uses Foundation Models to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="FRAMEWORK">
      <data key="d4">7.0</data>
      <data key="d5">The framework includes querying Foundation Models as part of its basic functions.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="HU &amp; CLUNE, 2024">
      <data key="d4">6.0</data>
      <data key="d5">Hu &amp; Clune are cited in the paper for contributions to the research on chain-of-thought planning and reasoning.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="FM MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Chain-of-Thought method is used in the FM Module for step-by-step reasoning and solving tasks.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="FM_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The FM_MODULE is used in the Chain-of-Thought method to handle 'thinking' and 'answer' processes.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="VECTOR INSTITUTE" target="ADAS">
      <data key="d4">12.0</data>
      <data key="d5">The Vector Institute supported the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="EXPERTS">
      <data key="d4">7.0</data>
      <data key="d5">Experts are used by the Multi-Step Peer Review Agent to review tasks and provide answers.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="REVIEWERS">
      <data key="d4">7.0</data>
      <data key="d5">Reviewers evaluate the answers provided by the Multi-Step Peer Review Agent.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="ENSEMBLE ANSWER">
      <data key="d4">7.0</data>
      <data key="d5">The Multi-Step Peer Review Agent uses ensemble answers to provide more accurate solutions to tasks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="GPQA">
      <data key="d4">14.0</data>
      <data key="d5">The Multi-Step Peer Review Agent was discovered in the GPQA domain.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="PHYSICS CRITIC">
      <data key="d4">12.0</data>
      <data key="d5">In the Multi-Step Peer Review Agent, one of the roles assigned to a critic module is Physics Critic.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="CHEMISTRY CRITIC">
      <data key="d4">12.0</data>
      <data key="d5">In the Multi-Step Peer Review Agent, one of the roles assigned to a critic module is Chemistry Critic.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="BIOLOGY CRITIC">
      <data key="d4">12.0</data>
      <data key="d5">In the Multi-Step Peer Review Agent, one of the roles assigned to a critic module is Biology Critic.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="GENERAL CRITIC">
      <data key="d4">12.0</data>
      <data key="d5">In the Multi-Step Peer Review Agent, one of the roles assigned to a critic module is General Critic.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="REIN ET AL., 2023">
      <data key="d4">14.0</data>
      <data key="d5">Rein et al. are the authors associated with the discovery of the Multi-Step Peer Review Agent in the Reading Comprehension domain, published in 2023.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="VISUAL PARADIGM">
      <data key="d4">7.0</data>
      <data key="d5">Visual Paradigm is a method used by the Verified Multimodal Agent to handle tasks involving visual data.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="VISUAL ANALYZER">
      <data key="d4">7.0</data>
      <data key="d5">Visual Analyzer is a component of the Verified Multimodal Agent that analyzes visual data to provide answers.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="MGSM">
      <data key="d4">14.0</data>
      <data key="d5">The Verified Multimodal Agent was discovered in the MGSM domain.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="SHI ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Shi et al. are the authors associated with the discovery of the Verified Multimodal Agent in the Math domain, published in 2023.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="SUB-PROBLEM">
      <data key="d4">7.0</data>
      <data key="d5">The Divide and Conquer Agent divides tasks into sub-problems and solves them iteratively.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="PHYSICS EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In the Divide and Conquer Agent, one of the roles assigned to a specialized expert is Physics Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="CHEMISTRY EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In the Divide and Conquer Agent, one of the roles assigned to a specialized expert is Chemistry Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="BIOLOGY EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In the Divide and Conquer Agent, one of the roles assigned to a specialized expert is Biology Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="CLAUDE" target="ANTHROPIC">
      <data key="d4">15.0</data>
      <data key="d5">Claude is a Foundation Model developed by Anthropic.Anthropic is the organization that developed the Claude Foundation Model.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HOG" target="CONVOLUTIONAL NEURAL NETWORKS (CNNS)">
      <data key="d4">8.0</data>
      <data key="d5">HOG features were eventually replaced by learned features from Convolutional Neural Networks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HOG" target="COMPUTER VISION">
      <data key="d4">7.0</data>
      <data key="d5">HOG features were used in early computer vision tasks before being replaced by learned features.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HOG" target="DALAL &amp; TRIGGS, 2005">
      <data key="d4">6.0</data>
      <data key="d5">Dalal &amp; Triggs contributed to the research on HOG features in computer vision.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONVOLUTIONAL NEURAL NETWORKS (CNNS)" target="NEURAL ARCHITECTURE SEARCH">
      <data key="d4">14.0</data>
      <data key="d5">Neural Architecture Search is used to design high-performing Convolutional Neural Networks.Neural Architecture Search is a method used to design high-performing Convolutional Neural Networks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONVOLUTIONAL NEURAL NETWORKS (CNNS)" target="COMPUTER VISION">
      <data key="d4">7.0</data>
      <data key="d5">Convolutional Neural Networks are used in computer vision to learn features from data.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONVOLUTIONAL NEURAL NETWORKS (CNNS)" target="KRIZHEVSKY ET AL., 2012">
      <data key="d4">6.0</data>
      <data key="d5">Krizhevsky et al. contributed to the research on Convolutional Neural Networks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ELSKEN">
      <data key="d4">1.0</data>
      <data key="d5">Elsken contributed to the research on Neural Architecture Search.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ELSKEN ET AL., 2019">
      <data key="d4">16.0</data>
      <data key="d5">Elsken et al. are the authors of research on Neural Architecture Search (NAS), published in 2019. They contributed to the method of NAS and discussed its various aspects in their 2019 publication.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ADAS">
      <data key="d4">18.0</data>
      <data key="d5">Neural Architecture Search (NAS) is a method within AutoML that is conceptually similar to the optimization processes in Advanced Driver Assistance Systems (ADAS). NAS provides insights into neural networks, akin to how ADAS offers insights into agentic systems. Both NAS and ADAS share a common goal of enhancing system performance through sophisticated optimization techniques, albeit in different domains. While NAS focuses on automating the design of neural network architectures to improve machine learning models, ADAS aims to enhance vehicle safety and driving experience by optimizing various driver assistance features.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">8.0</data>
      <data key="d5">Neural Architecture Search is a method that falls under the first pillar of AI-GAs, aiming to automate the design of neural network architectures.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="HU ET AL., 2021">
      <data key="d4">7.0</data>
      <data key="d5">Hu et al. are the authors of research on Neural Architecture Search, published in 2021.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="LU ET AL., 2019">
      <data key="d4">7.0</data>
      <data key="d5">Lu et al. are the authors of research on Neural Architecture Search, published in 2019.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AUTO ML" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">14.0</data>
      <data key="d5">Both AutoML and AI-Generating Algorithms automate the creation of AI systems.Both AutoML and AI-Generating Algorithms are methods that automate the creation of AI systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTO ML" target="HUTTER ET AL., 2019">
      <data key="d4">6.0</data>
      <data key="d5">Hutter et al. contributed to the research on AutoML methods.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="CLUNE, 2019">
      <data key="d4">13.0</data>
      <data key="d5">AI-Generating Algorithms (AI-GAs) are a significant area of research in the field of artificial intelligence, focusing on the development and optimization of algorithms that can generate other algorithms. A notable contribution to this field was made by Clune in 2019. Clune's research, published in that year, delves into the intricacies of AI-GAs, providing valuable insights and advancements that have influenced subsequent studies and applications in the domain.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="ADAS">
      <data key="d4">8.0</data>
      <data key="d5">ADAS aims to invent novel building blocks and design powerful agentic systems, which aligns with the goals of AI-GAs to learn more components in AI systems.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="AUTOML">
      <data key="d4">9.0</data>
      <data key="d5">Both AI-GAs and AutoML aim to automate the design and learning processes in AI systems.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="MAML">
      <data key="d4">8.0</data>
      <data key="d5">MAML is an algorithm that falls under the second pillar of AI-GAs, allowing "learning to learn" for better sample efficiency and generalizability.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="META-RL">
      <data key="d4">8.0</data>
      <data key="d5">Meta-RL is an algorithm that falls under the second pillar of AI-GAs, allowing "learning to learn" for better sample efficiency and generalizability.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="POET">
      <data key="d4">8.0</data>
      <data key="d5">POET is an algorithm that falls under the third pillar of AI-GAs, aiming to generate learning environments in an open-ended manner.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="OMNI-EPIC">
      <data key="d4">8.0</data>
      <data key="d5">OMNI-EPIC is an algorithm that falls under the third pillar of AI-GAs, aiming to generate learning environments in an open-ended manner.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="HU &amp; CLUNE, 2024" target="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d4">6.0</data>
      <data key="d5">Hu &amp; Clune are the authors who contributed to the development of chain-of-thought-based planning and reasoning methods, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="LEWIS ET AL., 2020" target="MEMORY STRUCTURES">
      <data key="d4">6.0</data>
      <data key="d5">Lewis et al. are cited in the paper for contributions to the research on memory structures in agentic systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="ZHANG ET AL., 2024C" target="MEMORY STRUCTURES">
      <data key="d4">6.0</data>
      <data key="d5">Zhang et al. are cited in the paper for contributions to the research on memory structures in agentic systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="QU ET AL., 2024" target="TOOL USE">
      <data key="d4">12.0</data>
      <data key="d5">Qu et al., 2024, are cited in the paper for their significant contributions to the research on tool use in agentic systems. They are the authors who developed innovative tool use techniques, which were published in 2024. Their work has been instrumental in advancing the understanding and application of tool use within these systems.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="MADAAN ET AL., 2024" target="SELF-REFINE (MADAAN ET AL., 2024)">
      <data key="d4">6.0</data>
      <data key="d5">Madaan et al. are the authors of the Self-Refine algorithm.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="TOOL USE" target="NAKANO ET AL., 2021">
      <data key="d4">6.0</data>
      <data key="d5">Nakano et al. are the authors who contributed to the development of tool use techniques, published in 2021.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="TOOL USE" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct generates data to teach AI models the skill of tool use.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="TOOL USE" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Tool use involves enabling models to interact with external tools or services, which is part of the Content Transformation Flow.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="EXPERTS" target="SIMPLICITY">
      <data key="d4">7.0</data>
      <data key="d5">Experts evaluate the simplicity trait in the feedback mechanism of ADAS.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT" target="NAME">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent provides the name of the next agent architecture in the "name" section of the output.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="CODE">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent provides the complete Python code for the "forward()" function in the "code" section of the output.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="FRAMEWORK">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent uses a simple framework to implement basic functions such as querying Foundation Models and formatting prompts.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="APPENDIX B">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent's framework code is available in Appendix B.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="APPENDICES C AND D">
      <data key="d4">7.0</data>
      <data key="d5">Additional information relevant to the meta agent is available in Appendices C and D.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="OUTPUT INSTRUCTION AND EXAMPLE">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent uses the output instruction and example to guide its generation of the output.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="ARC CHALLENGE">
      <data key="d4">16.0</data>
      <data key="d5">The META AGENT is designed to generate agents that can solve tasks in the ARC CHALLENGE by generating code solutions.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="META AGENT" target="GPT-4O-2024-05-13">
      <data key="d4">33.0</data>
      <data key="d5">The META AGENT utilizes the GPT-4O-2024-05-13 language model to perform tasks in the ARC CHALLENGE. This model is integral to the META AGENT's operations and is specifically employed for evaluation purposes.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="META AGENT" target="DROP">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="GPT-3.5-TURBO-0125">
      <data key="d4">7.0</data>
      <data key="d5">Discovered agents and baselines are evaluated using GPT-3.5-turbo-0125 to reduce compute cost.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="GPQA">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="MGSM">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the MGSM benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="MMLU">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="OPENAI, 2024">
      <data key="d4">7.0</data>
      <data key="d5">OpenAI is mentioned in the context of the meta agent using GPT-4o-2024-05-13.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="AGENTIC SYSTEMS">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent is part of the discussion on automated design of agentic systems.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="CODE" target="TASKINFO">
      <data key="d4">8.0</data>
      <data key="d5">Task information is used as input for generating the code.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="CODE" target="THINKING">
      <data key="d4">9.0</data>
      <data key="d5">The thought process influences the generation and refinement of the code.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="COMPUTE" target="LEARNED SOLUTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Learned solutions become more efficient over time as more compute becomes available.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="DATA" target="LEARNED SOLUTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Learned solutions become more efficient over time as more data becomes available.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HISTORY OF MACHINE LEARNING" target="HAND-DESIGNED SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The history of machine learning shows that hand-designed solutions are eventually replaced by learned solutions.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HISTORY OF MACHINE LEARNING" target="LEARNED SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The history of machine learning shows that learned solutions become more efficient over time.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HAND-DESIGNED SOLUTIONS" target="LEARNED SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Hand-designed solutions are often replaced by more efficient learned solutions in machine learning.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HUTTER ET AL., 2019" target="AUTOML">
      <data key="d4">21.0</data>
      <data key="d5">Hutter et al., in their 2019 publication, made significant contributions to the research area of Automated Machine Learning (AutoML). Their work delves into various methods and approaches within AutoML, providing a comprehensive analysis and discussion on the subject. This research is pivotal in advancing the understanding and development of AutoML techniques, highlighting the intricate connections and hierarchies that define the structure of this emerging field.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="CLUNE, 2019" target="AI-GA">
      <data key="d4">8.0</data>
      <data key="d5">Clune introduced AI-Generating Algorithms (AI-GAs) in 2019.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="CLUNE, 2019" target="AI-GAS">
      <data key="d4">6.0</data>
      <data key="d5">Clune contributed to the research area of AI-GAs, published in 2019.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="CLUNE, 2019" target="AGI">
      <data key="d4">12.0</data>
      <data key="d5">Clune discusses the potential of AI-GA and AGI in a work published in 2019.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="KRIZHEVSKY ET AL., 2012" target="CNN">
      <data key="d4">9.0</data>
      <data key="d5">Krizhevsky et al. introduced Convolutional Neural Networks (CNNs) in 2012.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AUTOML" target="ADAS">
      <data key="d4">15.0</data>
      <data key="d5">ADAS aims to invent novel building blocks and design powerful agentic systems, which aligns with the goals of AutoML to automate the design of neural network architectures and learning algorithms. ADAS is similar to the research area of AutoML, focusing on the automation of agentic systems. Both ADAS and AutoML share a common objective of enhancing automation in their respective domains, with ADAS concentrating on agentic systems and AutoML on neural network architectures and learning algorithms.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GA" target="AGI">
      <data key="d4">16.0</data>
      <data key="d5">ADAS is a new area in AI-GA research that could potentially contribute to the creation of AGI.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="LLM ALIGNMENT" target="LEARNED LOSS FUNCTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Learned loss functions are used in LLM alignment to optimize model performance.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="LEARNED LOSS FUNCTIONS" target="LU ET AL., 2024A">
      <data key="d4">8.0</data>
      <data key="d5">Lu et al. discussed learned loss functions in 2024a.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="DPO" target="RAFAILOV ET AL., 2024">
      <data key="d4">7.0</data>
      <data key="d5">Rafailov et al. discussed DPO, a hand-designed loss function, in 2024.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AI SCIENTIST" target="LU ET AL., 2024B">
      <data key="d4">8.0</data>
      <data key="d5">Lu et al. introduced the AI Scientist in 2024b.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="OMNI-EPIC" target="FALDOR ET AL., 2024">
      <data key="d4">27.0</data>
      <data key="d5">Faldor et al. are the authors of the OMNI-EPIC algorithm, which they discussed in their 2024 research publication. OMNI-EPIC is a system designed for generating robotics learning environments.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="OMNI-EPIC" target="FMS">
      <data key="d4">16.0</data>
      <data key="d5">FMs are used in the OMNI-EPIC algorithm to create robotics learning environments by programming in code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="FM">
      <data key="d4">7.0</data>
      <data key="d5">Foundation Models (FMs) are used as meta agents in ADAS.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="ADAS" target="SEARCH SPACE">
      <data key="d4">8.0</data>
      <data key="d5">The search space is a key component of ADAS, defining which agentic systems can be represented and discovered.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="EVALUATION FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">The evaluation function is a key component of ADAS, defining how to evaluate a candidate agent on target objectives.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="AGENTIC SYSTEMS">
      <data key="d4">9.0</data>
      <data key="d5">ADAS involves the automated design of agentic systems using a search algorithm to optimize an evaluation function.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="AI-GAS">
      <data key="d4">7.0</data>
      <data key="d5">ADAS is similar to the research area of AI-GAs, focusing on the automated design and optimization of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="HUMAN-LIKE FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">Human-like feedback is a component of the feedback mechanism in ADAS.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="ADAS" target="ARC CHALLENGE">
      <data key="d4">7.0</data>
      <data key="d5">ADAS demonstrates its proficiency in in-context learning through the ARC Challenge.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="OPRO">
      <data key="d4">14.0</data>
      <data key="d5">OPRO is an attempt at ADAS that focuses on learning better prompts for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="PROMPTBREEDER">
      <data key="d4">14.0</data>
      <data key="d5">PromptBreeder is an attempt at ADAS that focuses on learning better prompts for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="SELF-DISCOVER">
      <data key="d4">14.0</data>
      <data key="d5">Self-Discover is an attempt at ADAS that focuses on learning better prompts for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="EVOAGENT">
      <data key="d4">14.0</data>
      <data key="d5">EvoAgent is an attempt at ADAS that optimizes role definition in the prompt for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENTVERSE">
      <data key="d4">14.0</data>
      <data key="d5">AgentVerse is an attempt at ADAS that optimizes role definition in the prompt for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="DYLAN">
      <data key="d4">14.0</data>
      <data key="d5">DyLAN is an attempt at ADAS that uses FMs to score the response quality of nodes in a network and prunes the connections.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="DSPY">
      <data key="d4">14.0</data>
      <data key="d5">DSPy is an attempt at ADAS that generates and optimizes nodes in a network.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="GPT-SWARM">
      <data key="d4">14.0</data>
      <data key="d5">GPT-Swarm is an attempt at ADAS that represents an agentic system in a graph and optimizes the connections between nodes.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENTOPTIMIZER">
      <data key="d4">14.0</data>
      <data key="d5">AgentOptimizer is an attempt at ADAS that learns the tools used in agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENT SYMBOLIC LEARNING">
      <data key="d4">14.0</data>
      <data key="d5">Agent Symbolic Learning is an attempt at ADAS that learns prompts, tools, and control flow together.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="API ACCESS">
      <data key="d4">18.0</data>
      <data key="d5">ADAS demonstrates that with available API access to powerful foundational models, it is easy to program powerful agentic systems.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="GPUS">
      <data key="d4">16.0</data>
      <data key="d5">ADAS can be programmed without the need for expensive hardware like GPUs.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="SAFE-ADAS">
      <data key="d4">16.0</data>
      <data key="d5">Safe-ADAS is a proposed direction to ensure that ADAS algorithms conduct their tasks safely and create only honest, helpful, and harmless agents.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="SEARCH ENGINE TOOLS">
      <data key="d4">12.0</data>
      <data key="d5">Search engine tools are existing human efforts that can be used as building blocks in ADAS to improve efficiency and performance.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="MULTI-OBJECTIVE ADAS">
      <data key="d4">14.0</data>
      <data key="d5">Multi-objective ADAS involves integrating multiple objectives, such as cost, latency, and robustness, in the optimization process of ADAS algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="EVALUATION FUNCTIONS">
      <data key="d4">14.0</data>
      <data key="d5">Evaluation functions are methods used in ADAS to assess the performance of discovered agents.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="CALDWELL, 2011">
      <data key="d4">10.0</data>
      <data key="d5">Caldwell is an author referenced in the text, contributing to discussions on AI and its implications, which are relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="META, 2024">
      <data key="d4">10.0</data>
      <data key="d5">Meta is an organization referenced in the text, contributing to AI research relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="AGENTIC SYSTEM">
      <data key="d4">16.0</data>
      <data key="d5">ADAS aims to design powerful agentic systems.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="CANADA CIFAR AI CHAIRS PROGRAM">
      <data key="d4">12.0</data>
      <data key="d5">The Canada CIFAR AI Chairs program supported the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="SCHMIDT FUTURES">
      <data key="d4">12.0</data>
      <data key="d5">Schmidt Futures provided grants to support the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="OPEN PHILANTHROPY">
      <data key="d4">12.0</data>
      <data key="d5">Open Philanthropy provided grants to support the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="NSERC DISCOVERY GRANT">
      <data key="d4">12.0</data>
      <data key="d5">The NSERC Discovery Grant supported the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="RAFAEL COSMAN">
      <data key="d4">12.0</data>
      <data key="d5">Rafael Cosman made a donation to support the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="JENNY ZHANG">
      <data key="d4">10.0</data>
      <data key="d5">Jenny Zhang provided discussions and feedback on the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="RACH PRADHAN">
      <data key="d4">10.0</data>
      <data key="d5">Rach Pradhan provided discussions and feedback on the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="RUIYU GOU">
      <data key="d4">10.0</data>
      <data key="d5">Ruiyu Gou provided discussions and feedback on the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="NICHOLAS IOANNIDIS">
      <data key="d4">5.0</data>
      <data key="d5">Nicholas Ioannidis provided discussions and feedback on the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ARC" target="CHOLLET, 2019">
      <data key="d4">14.0</data>
      <data key="d5">ARC, introduced by Chollet in 2019, is a logic puzzle task designed to serve as a benchmark in various experiments. Chollet, the author of this task, aimed to create a challenging and insightful tool for evaluating algorithmic performance and cognitive abilities. The ARC task has since become a significant point of reference in the study of artificial intelligence and machine learning, highlighting the intricate connections and hierarchies within algorithmic communities.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="ARC" target="CLAUDE-HAIKU">
      <data key="d4">7.0</data>
      <data key="d5">Claude-Haiku is used to evaluate the performance of agents on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="CLAUDE-SONNET">
      <data key="d4">7.0</data>
      <data key="d5">Claude-Sonnet is used to evaluate the performance of agents on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="CHAIN-OF-THOUGHT (WEI ET AL., 2022)">
      <data key="d4">6.0</data>
      <data key="d5">Chain-of-Thought is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="COT-SC (WANG ET AL., 2023B)">
      <data key="d4">6.0</data>
      <data key="d5">COT-SC is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="LLM DEBATE (DU ET AL., 2023)">
      <data key="d4">6.0</data>
      <data key="d5">LLM Debate is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="SELF-REFINE (MADAAN ET AL., 2024)">
      <data key="d4">6.0</data>
      <data key="d5">Self-Refine is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="QUALITY-DIVERSITY (LU ET AL., 2024C)">
      <data key="d4">6.0</data>
      <data key="d5">Quality-Diversity is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="STRUCTURED FEEDBACK AND ENSEMBLE AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Structured Feedback and Ensemble Agent is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="HIERARCHICAL COMMITTEE REINFORCEMENT AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Hierarchical Committee Reinforcement Agent is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="DYNAMIC MEMORY AND REFINEMENT AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Dynamic Memory and Refinement Agent is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought (COT) is used as a baseline for experiments on ARC.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ARC" target="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)">
      <data key="d4">7.0</data>
      <data key="d5">Self-Consistency with Chain-of-Thought (COT-SC) is used as a baseline for experiments on ARC.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ARC" target="LLM-DEBATE">
      <data key="d4">7.0</data>
      <data key="d5">LLM-Debate is used as a baseline for experiments on ARC.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ARC" target="QUALITY-DIVERSITY">
      <data key="d4">7.0</data>
      <data key="d5">Quality-Diversity is used as a baseline for experiments on ARC.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ARC" target="GPT-3.5-TURBO-0125">
      <data key="d4">7.0</data>
      <data key="d5">The ARC dataset is evaluated using the GPT-3.5-Turbo-0125 model, contributing to the cost of experiments.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ARC" target="ORCA-3">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 scored 92.47 on the ARC benchmark, a 12% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="DROP" target="DUA ET AL., 2019">
      <data key="d4">20.0</data>
      <data key="d5">Dua et al. are the authors of the DROP benchmark, which is used to assess reading comprehension abilities. This benchmark was discussed by Dua et al. in 2019.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="DROP" target="READING COMPREHENSION">
      <data key="d4">8.0</data>
      <data key="d5">The DROP benchmark is used to evaluate reading comprehension capabilities.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="DROP" target="DHEERU DUA, YIZHONG WANG, PRADEEP DASIGI, GABRIEL STANOVSKY, SAMEER SINGH, AND MATT GARDNER">
      <data key="d4">9.0</data>
      <data key="d5">Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner authored the paper "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="DROP" target="META_AGENT">
      <data key="d4">7.0</data>
      <data key="d5">The DROP dataset is used for evaluating the meta agent.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="DROP" target="DISCRETE REASONING">
      <data key="d4">8.0</data>
      <data key="d5">DROP assesses the ability to perform discrete reasoning.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="MULTIPLE PARAGRAPHS">
      <data key="d4">8.0</data>
      <data key="d5">DROP assesses comprehension and reasoning across multiple paragraphs.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="ORCA-3">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 scored 71.14 on the DROP benchmark, a 22% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="DROP" target="EXACT MATCH/SPAN EXTRACTION PROBLEMS">
      <data key="d4">7.0</data>
      <data key="d5">DROP is a dataset used for exact match/span extraction problems where a ground-truth answer value is given.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MGSM" target="SHI ET AL., 2023">
      <data key="d4">20.0</data>
      <data key="d5">Shi et al. are the authors of the MGSM benchmark, which is used to evaluate math abilities. In 2023, Shi et al. discussed the MGSM math task benchmark, providing insights into its application and significance in assessing mathematical skills.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="MGSM" target="PET RABBITS">
      <data key="d4">6.0</data>
      <data key="d5">Pet Rabbits are mentioned in the MGSM example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MGSM" target="PET DOGS">
      <data key="d4">6.0</data>
      <data key="d5">Pet Dogs are mentioned in the MGSM example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MGSM" target="PET CATS">
      <data key="d4">6.0</data>
      <data key="d5">Pet Cats are mentioned in the MGSM example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GSM8K" target="ORCA-3">
      <data key="d4">31.0</data>
      <data key="d5">Orca-3 scored 83.09 on the GSM8K benchmark, demonstrating a significant 54% improvement over its predecessor, Orca-2.5. Additionally, Orca-3 shows a 54% improvement on the GSM8K benchmark compared to Mistral-7b-Instruct, highlighting its substantial performance enhancements.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GSM8K" target="GPT-3.5-TURBO">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-turbo's accuracy scores on the GSM8K benchmark are reported in the Phi3 paper.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GSM8K" target="PHI3">
      <data key="d4">1.0</data>
      <data key="d5">The Phi3 paper reports accuracy scores for GPT-3.5-turbo on the GSM8K benchmark.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GSM8K" target="EXACT MATCH/SPAN EXTRACTION PROBLEMS">
      <data key="d4">7.0</data>
      <data key="d5">GSM8K is a dataset used for exact match/span extraction problems involving math-based questions.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="LU ET AL., 2024A" target="LU ET AL., 2024C">
      <data key="d4">6.0</data>
      <data key="d5">Lu et al. are the authors of studies in 2024a and 2024c discussing learned loss functions and open-endedness algorithms.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="LU ET AL., 2024A" target="DISCOPOP">
      <data key="d4">7.0</data>
      <data key="d5">Lu et al. are the authors of research on DiscoPOP, published in 2024.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LU ET AL., 2024B" target="SUBJECTIVE ANSWER EVALUATIONS">
      <data key="d4">5.0</data>
      <data key="d5">Lu et al. are authors who have worked on subjective answer evaluations in ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="LU ET AL., 2024C" target="ZHANG ET AL., 2024A">
      <data key="d4">6.0</data>
      <data key="d5">Zhang et al. and Lu et al. discussed open-endedness algorithms in 2024a and 2024c, respectively.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="LU ET AL., 2024C" target="QUALITY-DIVERSITY">
      <data key="d4">36.0</data>
      <data key="d5">Lu et al., 2024C, are the authors of the Quality-Diversity algorithm, a method developed and published in 2024. Their research leverages human notions of interestingness and is referenced in Meta Agent Search.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="LU ET AL., 2024C" target="QUALITY-DIVERSITY (LU ET AL., 2024C)">
      <data key="d4">6.0</data>
      <data key="d5">Lu et al. are the authors of the Quality-Diversity algorithm.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ZHANG ET AL., 2024A" target="QUALITY-DIVERSITY">
      <data key="d4">5.0</data>
      <data key="d5">Zhang et al. are the authors of an open-endedness algorithm that leverages human notions of interestingness, referenced in Meta Agent Search.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="ZHANG ET AL., 2024A" target="OPEN-ENDED ALGORITHMS">
      <data key="d4">5.0</data>
      <data key="d5">Zhang et al. are authors who have worked on open-ended algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="FERNANDO ET AL., 2024" target="YANG ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Fernando et al. and Yang et al. discussed designing prompts in ADAS methods in 2024.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="FERNANDO ET AL., 2024" target="PROMPTBREEDER">
      <data key="d4">18.0</data>
      <data key="d5">Fernando et al. are the authors of PromptBreeder, an algorithm utilized within the search space of Advanced Driver Assistance Systems (ADAS). PromptBreeder is designed to enhance the efficiency and effectiveness of ADAS by optimizing the search space, thereby contributing to the development of more advanced and reliable driver assistance technologies.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="YANG ET AL., 2024" target="OPRO">
      <data key="d4">12.0</data>
      <data key="d5">Yang et al. are the authors of the OPRO algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="BOYER &amp; MOORE, 1983" target="LADHA, 2024">
      <data key="d4">1.0</data>
      <data key="d5">Boyer and Moore (1983) and Ladha (2024) discussed the Turing Completeness of programming languages.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="FALDOR ET AL., 2024" target="OPEN-ENDED ALGORITHMS">
      <data key="d4">5.0</data>
      <data key="d5">Faldor et al. are authors who have worked on open-ended algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="MATHEMATICS">
      <data key="d4">6.0</data>
      <data key="d5">Agentic systems can be applied and evaluated for performance in the domain of mathematics.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="READING COMPREHENSION">
      <data key="d4">6.0</data>
      <data key="d5">Agentic systems can be applied and evaluated for performance in the domain of reading comprehension.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="CHASE, 2024">
      <data key="d4">6.0</data>
      <data key="d5">Chase contributed to the definitions and terminologies of agentic systems, published in 2024.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="NG, 2024">
      <data key="d4">6.0</data>
      <data key="d5">Ng contributed to the definitions and terminologies of agentic systems, published in 2024.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="HUMAN ORGANIZATIONS">
      <data key="d4">14.0</data>
      <data key="d5">Human organizations are closely connected to agentic systems in terms of complexity and operation.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="READING COMPREHENSION" target="AGENTINSTRUCT">
      <data key="d4">15.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of reading comprehension. Reading comprehension capabilities are evaluated through targeted training with AgentInstruct. This approach ensures that language models are effectively trained and assessed in their ability to understand and interpret text, enhancing their overall performance in reading comprehension tasks.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="READING COMPREHENSION" target="QUESTION ANSWERING">
      <data key="d4">14.0</data>
      <data key="d5">READING COMPREHENSION and QUESTION ANSWERING are interrelated skills involving the understanding and processing of text. Reading comprehension serves as the foundational ability to grasp and interpret written material, while question answering is an application of this skill, where the comprehension of text is utilized to respond accurately to queries based on the information provided.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="READING COMPREHENSION TESTS">
      <data key="d4">8.0</data>
      <data key="d5">Reading comprehension tests are used to assess the skill of reading comprehension.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="SKILLS">
      <data key="d4">8.0</data>
      <data key="d5">Reading comprehension is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="AGENTINSTRUCT FLOW">
      <data key="d4">9.0</data>
      <data key="d5">AgentInstruct Flow includes a specific flow for reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Flow aims to generate materials conducive to reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="GROUNDED REASONING">
      <data key="d4">8.0</data>
      <data key="d5">Grounded reasoning is an application of reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="LSAT LOGICAL REASONING TEST">
      <data key="d4">7.0</data>
      <data key="d5">The LSAT Logical Reasoning test features specialized question categories that require reading comprehension skills.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="MISTRAL-INSTRUCT-7B">
      <data key="d4">7.0</data>
      <data key="d5">Reading comprehension capabilities of Mistral-Instruct-7b are evaluated and improved through targeted training.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MULTI-TASK PROBLEM SOLVING" target="MMLU">
      <data key="d4">8.0</data>
      <data key="d5">The MMLU benchmark is used to evaluate multi-task problem solving capabilities.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="ITERATION" target="MULTI-AGENT WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Iteration is a key component of multi-agent workflows used to generate high-quality data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SCIENCE" target="GPQA">
      <data key="d4">8.0</data>
      <data key="d5">The GPQA benchmark is used to evaluate science capabilities.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="SEARCH SPACE" target="PROMPTBREEDER">
      <data key="d4">7.0</data>
      <data key="d5">PromptBreeder is an example of a search space design within ADAS, mutating text prompts of an agent.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SEARCH SPACE" target="ZHUGE ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Zhuge et al. explored search spaces such as graph structures within ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="COST">
      <data key="d4">8.0</data>
      <data key="d5">Cost is an objective used in the evaluation function of ADAS to assess the economic efficiency of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="LATENCY">
      <data key="d4">8.0</data>
      <data key="d5">Latency is an objective used in the evaluation function of ADAS to assess the response time of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="SAFETY">
      <data key="d4">8.0</data>
      <data key="d5">Safety is an objective used in the evaluation function of ADAS to assess the reliability and security of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="ADAS ALGORITHMS">
      <data key="d4">2.0</data>
      <data key="d5">ADAS algorithms could benefit from more sophisticated evaluation functions to reduce costs.ADAS algorithms could benefit from more sophisticated evaluation functions to reduce costs and improve efficiency.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ZHUGE ET AL., 2024" target="GPT-SWARM">
      <data key="d4">12.0</data>
      <data key="d5">Zhuge et al. are the authors of the GPT-Swarm algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SUTTON &amp; BARTO, 2018" target="BALANCING EXPLORATION AND EXPLOITATION">
      <data key="d4">5.0</data>
      <data key="d5">Sutton &amp; Barto are authors who have worked on balancing exploration and exploitation in search algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="COST" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">Cost is a limitation of AgentInstruct, as generating synthetic data with multiple agents can be resource-intensive.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="FMS" target="LOSS FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">FMs are used to program the loss function for preference learning in FM alignment training.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FMS" target="EUREKA">
      <data key="d4">16.0</data>
      <data key="d5">FMs are used in the Eureka algorithm to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FMS" target="LANGUAGE-TO-REWARD">
      <data key="d4">16.0</data>
      <data key="d5">FMs are used in the language-to-reward algorithm to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FMS" target="PREFERENCE LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">FMs are used to program the loss function for preference learning in FM alignment training.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FMS" target="ROBOTICS LEARNING ENVIRONMENTS">
      <data key="d4">8.0</data>
      <data key="d5">FMs are used to create robotics learning environments by programming in code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FUNSEARCH" target="ROMERA-PAREDES ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Romera-Paredes et al. are the authors of research on the FunSearch algorithm, which was published in 2024. The FunSearch algorithm is also referenced in Meta Agent Search, highlighting its relevance and application within the field.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LLM DEBATE" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">LLM Debate is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Quality-Diversity is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">Quality-Diversity is a concept that can be incorporated into novelty search algorithms to balance exploration and quality of solutions.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="CULLY &amp; DEMIRIS, 2017">
      <data key="d4">10.0</data>
      <data key="d5">Cully &amp; Demiris are authors who have worked on Quality-Diversity in search algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="FORWARD FUNCTION" target="AGENT SYSTEM">
      <data key="d4">8.0</data>
      <data key="d5">The Agent System uses the forward function to process task information.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="EXPERIMENT" target="ENSEMBLE AGENT">
      <data key="d4">7.0</data>
      <data key="d5">The Ensemble Agent was used in the experiment to generate initial candidate solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="CRITIC" target="FM_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The FM_MODULE is used in the Critic method to handle 'feedback' and 'correct' processes.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="TRANSFORMATION RULE">
      <data key="d4">17.0</data>
      <data key="d5">The ARC CHALLENGE involves learning a TRANSFORMATION RULE from example input-output grids. Specifically, the challenge requires participants to discern transformation rules of grid patterns from provided examples. This process entails analyzing given input-output grids to identify the underlying rules that govern the transformations, thereby demonstrating an understanding of the intricate connections and hierarchies within the grid patterns.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="GREENBLATT, 2024">
      <data key="d4">6.0</data>
      <data key="d5">Greenblatt followed common practice in requiring the agent to write code for the transformation rule in the ARC challenge.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXAMPLE INPUT-OUTPUT GRID">
      <data key="d4">18.0</data>
      <data key="d5">The ARC CHALLENGE involves using EXAMPLE INPUT-OUTPUT GRID to learn transformation rules.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="GPT-3.5-TURBO-0125">
      <data key="d4">14.0</data>
      <data key="d5">The GPT-3.5-TURBO-0125 language model is used to evaluate discovered agents and baselines in the ARC CHALLENGE.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXACT MATCH">
      <data key="d4">8.0</data>
      <data key="d5">The EXACT MATCH metric is used to calculate the accuracy rate in the ARC CHALLENGE.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="INPUT GRID">
      <data key="d4">8.0</data>
      <data key="d5">The INPUT GRID is part of the ARC CHALLENGE, serving as the input for learning transformation rules.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="OUTPUT GRID">
      <data key="d4">8.0</data>
      <data key="d5">The OUTPUT GRID is part of the ARC CHALLENGE, produced by applying a transformation rule to the input grid.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXPERIMENT DETAILS">
      <data key="d4">1.0</data>
      <data key="d5">The EXPERIMENT DETAILS provide information about the experiments conducted for the ARC CHALLENGE.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="LLM-DEBATE" target="PHYSICS EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In LLM-Debate, one of the roles assigned to a debate module is Physics Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LLM-DEBATE" target="CHEMISTRY EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In LLM-Debate, one of the roles assigned to a debate module is Chemistry Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LLM-DEBATE" target="BIOLOGY EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In LLM-Debate, one of the roles assigned to a debate module is Biology Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LLM-DEBATE" target="SCIENCE GENERALIST">
      <data key="d4">12.0</data>
      <data key="d5">In LLM-Debate, one of the roles assigned to a debate module is Science Generalist.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="VALIDATION SET" target="EXPERIMENT DETAILS">
      <data key="d4">8.0</data>
      <data key="d5">Experiment details include information about the validation set used for performance evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TEST SET" target="EXPERIMENT DETAILS">
      <data key="d4">8.0</data>
      <data key="d5">Experiment details include information about the test set used for performance evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="APPENDIX E" target="EXPERIMENT SETTINGS">
      <data key="d4">1.0</data>
      <data key="d5">Appendix E contains more details about the baselines used in the experiment settings.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="STEPPING STONES" target="MEYERSON ET AL., 2023">
      <data key="d4">7.0</data>
      <data key="d5">Meyerson et al. contributed to the concept of combining different stepping stones, resembling crossover in evolution via LLMs.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="MMLU" target="HENDRYCKS ET AL., 2021">
      <data key="d4">6.0</data>
      <data key="d5">Hendrycks et al. are the authors of the MMLU benchmark.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="MMLU" target="STEM">
      <data key="d4">8.0</data>
      <data key="d5">STEM is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="SOCIAL SCIENCES">
      <data key="d4">8.0</data>
      <data key="d5">Social Sciences is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="HUMANITIES">
      <data key="d4">8.0</data>
      <data key="d5">Humanities is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="CASSIOPEIA">
      <data key="d4">6.0</data>
      <data key="d5">Cassiopeia is mentioned in the MMLU example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="CENTURUS">
      <data key="d4">6.0</data>
      <data key="d5">Centurus is mentioned in the MMLU example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="CYGNUS">
      <data key="d4">6.0</data>
      <data key="d5">Cygnus is mentioned in the MMLU example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="CEPHEUS">
      <data key="d4">1.0</data>
      <data key="d5">Cepheus is mentioned in the MMLU example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="ORCA-3">
      <data key="d4">31.0</data>
      <data key="d5">Orca-3 scored 69.95 on the MMLU benchmark, demonstrating a 19% improvement over its predecessor, Orca-2.5. Additionally, Orca-3 shows a 19% improvement on the MMLU benchmark compared to Mistral-7b-Instruct. This significant performance enhancement is evident across various levels of mathematics, highlighting Orca-3's advanced capabilities in this domain.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MMLU" target="EQBENCH">
      <data key="d4">8.0</data>
      <data key="d5">EQBench has a strong correlation (r=0.97) with comprehensive multi-domain benchmarks like MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="MIRAGE">
      <data key="d4">8.0</data>
      <data key="d5">MMLU is one of the datasets included in the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPQA" target="REIN ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Rein et al. are the authors of the GPQA benchmark.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPQA" target="META_AGENT">
      <data key="d4">7.0</data>
      <data key="d5">The GPQA dataset is used for evaluating the meta agent.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPQA" target="BIOLOGY">
      <data key="d4">8.0</data>
      <data key="d5">Biology is one of the domains covered by the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="PHYSICS">
      <data key="d4">8.0</data>
      <data key="d5">Physics is one of the domains covered by the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="CHEMISTRY">
      <data key="d4">8.0</data>
      <data key="d5">Chemistry is one of the domains covered by the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="UNCERTAINTY PRINCIPLE">
      <data key="d4">7.0</data>
      <data key="d5">The uncertainty principle is discussed in the context of a GPQA example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="ORCA-3">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 scored 28.12 on the GPQA benchmark, a 4% decrease compared to Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="STEP-BACK ABSTRACTION" target="ZHENG ET AL., 2023">
      <data key="d4">41.0</data>
      <data key="d5">Step-back Abstraction is a method described by Zheng et al. in 2023. Zheng et al. are the authors of research on the Step-back Abstraction algorithm, which was published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="STEP-BACK ABSTRACTION" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Step-back Abstraction is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="STEP-BACK ABSTRACTION" target="REASONING AND PROBLEM-SOLVING DOMAINS">
      <data key="d4">7.0</data>
      <data key="d5">Step-back Abstraction is used as a baseline for experiments on Reasoning and Problem-Solving domains.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="XU ET AL., 2023">
      <data key="d4">25.0</data>
      <data key="d5">Role Assignment is a method described by Xu et al. in 2023. Xu et al. are the authors of research on the Role Assignment algorithm, which was published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Role Assignment is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="REASONING AND PROBLEM-SOLVING DOMAINS">
      <data key="d4">7.0</data>
      <data key="d5">Role Assignment is used as a baseline for experiments on Reasoning and Problem-Solving domains.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ACCURACY" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">Accuracy is a limitation of AgentInstruct, as synthetic data may not perfectly replicate real-world data.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="EXPERIMENT SETTINGS" target="APPENDIX D">
      <data key="d4">6.0</data>
      <data key="d5">Appendix D contains more details about the experiment settings.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="CLAUDE-HAIKU" target="ANTHROPIC, 2024A">
      <data key="d4">6.0</data>
      <data key="d5">Anthropic is the organization that developed Claude-Haiku.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="CLAUDE-SONNET" target="ANTHROPIC, 2024B">
      <data key="d4">6.0</data>
      <data key="d5">Anthropic is the organization that developed Claude-Sonnet.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="SVAMP (PATEL ET AL., 2021)" target="PATEL ET AL., 2021">
      <data key="d4">6.0</data>
      <data key="d5">Patel et al. are the authors of the SVAMP benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ASDIV (MIAO ET AL., 2020)" target="MIAO ET AL., 2020">
      <data key="d4">1.0</data>
      <data key="d5">Miao et al. are the authors of the ASDiv benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="OPENAI, 2022" target="GPT-3.5-TURBO-0125">
      <data key="d4">7.0</data>
      <data key="d5">OpenAI is mentioned in the context of using GPT-3.5-turbo-0125 to evaluate discovered agents and baselines.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="PATEL ET AL., 2021" target="SVAMP">
      <data key="d4">6.0</data>
      <data key="d5">Patel et al. are the authors of the SVAMP dataset, published in 2021.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="MIAO ET AL., 2020" target="ASDIV">
      <data key="d4">6.0</data>
      <data key="d5">Miao et al. are the authors of the ASDiv dataset, published in 2020.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="EMBODIED AGENTS" target="VEMPRALA ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Vemprala et al. are the authors who contributed to the development of new skills for embodied agents, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="FM MODULES" target="HONG ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Hong et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="FM MODULES" target="QIAN ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Qian et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="FM MODULES" target="QIAN ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Qian et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="HONG ET AL., 2023" target="ORGANIZATIONAL STRUCTURE">
      <data key="d4">12.0</data>
      <data key="d5">Hong et al. are authors who have worked on incorporating organizational structures for human companies in agents.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="HONG ET AL., 2023" target="AGENTIC SYSTEM">
      <data key="d4">14.0</data>
      <data key="d5">Hong et al. incorporated organizational structures of human companies into agents.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="SELF-INSTRUCTION" target="RICHARDS, 2023">
      <data key="d4">1.0</data>
      <data key="d5">Richards is the author who contributed to the development of self-instruction techniques, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="MAML" target="FINN ET AL., 2017">
      <data key="d4">7.0</data>
      <data key="d5">Finn et al. are the authors of research on MAML, published in 2017.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-RL" target="DUAN ET AL., 2017">
      <data key="d4">7.0</data>
      <data key="d5">Duan et al. are the authors of research on Meta-RL, published in 2017.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-RL" target="NORMAN &amp; CLUNE, 2023">
      <data key="d4">7.0</data>
      <data key="d5">Norman and Clune are the authors of research on Meta-RL, published in 2023.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-RL" target="WANG ET AL., 2016">
      <data key="d4">7.0</data>
      <data key="d5">Wang et al. are the authors of research on Meta-RL, published in 2016.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-RL" target="ZINTGRAF ET AL., 2021A">
      <data key="d4">7.0</data>
      <data key="d5">Zintgraf et al. are the authors of research on Meta-RL, published in 2021.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-RL" target="ZINTGRAF ET AL., 2021B">
      <data key="d4">7.0</data>
      <data key="d5">Zintgraf et al. are the authors of research on Meta-RL, published in 2021.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="POET" target="DHARNA ET AL., 2020">
      <data key="d4">7.0</data>
      <data key="d5">Dharna et al. are the authors of research on POET, published in 2020.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="POET" target="WANG ET AL., 2019">
      <data key="d4">7.0</data>
      <data key="d5">Wang et al. are the authors of research on POET, published in 2019.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="POET" target="WANG ET AL., 2020">
      <data key="d4">7.0</data>
      <data key="d5">Wang et al. are the authors of research on POET, published in 2020.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="EUREKA" target="MA ET AL., 2023">
      <data key="d4">19.0</data>
      <data key="d5">Ma et al. are the authors of research on the Eureka algorithm, published in 2023.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="LANGUAGE-TO-REWARD" target="YU ET AL., 2023">
      <data key="d4">19.0</data>
      <data key="d5">Yu et al. are the authors of research on the language-to-reward algorithm, published in 2023. This work delves into the intricate mechanisms by which language inputs can be translated into reward-based outputs, contributing significantly to the field of algorithmic analysis. The study by Yu et al. in 2023 provides a comprehensive examination of the underlying structures and dynamics that define the language-to-reward algorithm, offering valuable insights into its applications and potential impact.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="HU ET AL., 2021" target="MULTI-OBJECTIVE ADAS">
      <data key="d4">10.0</data>
      <data key="d5">Hu et al. are authors who have worked on multi-objective optimization in agentic systems, relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="RAFALIOV ET AL., 2024" target="FM ALIGNMENT TRAINING">
      <data key="d4">7.0</data>
      <data key="d5">Rafailov et al. are the authors of research on FM alignment training, published in 2024.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LOSS FUNCTION" target="RAFALOV ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Rafailov et al. are the authors of a work that involves programming the loss function for preference learning in FM alignment training.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SELF-DISCOVER" target="ZHOU ET AL., 2024A">
      <data key="d4">12.0</data>
      <data key="d5">Zhou et al. are the authors of the Self-Discover algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="EVOAGENT" target="YUAN ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Yuan et al. are the authors of the EvoAgent algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGENTVERSE" target="CHEN, YUSHENG SU, JINGWEI ZUO, CHENG YANG, CHENFEI YUAN, CHI-MIN CHAN, HEYANG YU, YAXI LU, YI-HSIN HUNG, CHEN QIAN, ET AL.">
      <data key="d4">9.0</data>
      <data key="d5">The group of researchers authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" was presented at The Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="DSPY" target="KHATTAB ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Khattab et al. are the authors of the DSPy algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGENTOPTIMIZER" target="ZHANG ET AL., 2024B">
      <data key="d4">12.0</data>
      <data key="d5">Zhang et al. are the authors of the AgentOptimizer algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGENT SYMBOLIC LEARNING" target="ZHOU ET AL., 2024B">
      <data key="d4">12.0</data>
      <data key="d5">Zhou et al. are the authors of the Agent Symbolic Learning algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGI" target="BENGIO ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Bengio et al. discuss the ethical considerations of advancing AI capabilities in a work published in 2024.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGI" target="BOSTROM, 2002">
      <data key="d4">12.0</data>
      <data key="d5">Bostrom discusses the ethical considerations of advancing AI capabilities in a work published in 2002.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGI" target="ECOFFET ET AL., 2020">
      <data key="d4">12.0</data>
      <data key="d5">Ecoffet et al. discuss the ethical considerations of advancing AI capabilities in a work published in 2020.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGI" target="YUDKOWSKY ET AL., 2008">
      <data key="d4">2.0</data>
      <data key="d5">Yudkowsky et al. discuss the ethical considerations of advancing AI capabilities in a work published in 2008.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SAFETY CONSIDERATIONS" target="ROKON ET AL., 2020">
      <data key="d4">12.0</data>
      <data key="d5">Rokon et al. are the authors of a work that discusses safety considerations for executing model-generated code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SAFETY CONSIDERATIONS" target="YEE ET AL., 2010">
      <data key="d4">12.0</data>
      <data key="d5">Yee et al. are the authors of a work that discusses safety considerations for executing model-generated code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ZHOU ET AL., 2024B" target="EVALUATION FUNCTIONS">
      <data key="d4">5.0</data>
      <data key="d5">Zhou et al. are authors who have worked on intelligent evaluation functions in ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="SAFE-ADAS" target="CONSTITUTIONAL AI">
      <data key="d4">14.0</data>
      <data key="d5">Constitutional AI is a concept that can be incorporated into Safe-ADAS to ensure the creation of ethical and harmless agents.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="CONSTITUTIONAL AI" target="BAI ET AL., 2022">
      <data key="d4">10.0</data>
      <data key="d5">Bai et al. are authors who have worked on Constitutional AI, a concept relevant to Safe-ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="HIGHER-ORDER ADAS" target="LU ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Lu et al. are authors who have worked on higher-order meta-learning in ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="MULTI-OBJECTIVE ADAS" target="HUANG ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Huang et al. are authors who have worked on multi-objective optimization in agentic systems, relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="MULTI-OBJECTIVE ADAS" target="DEB ET AL., 2002">
      <data key="d4">10.0</data>
      <data key="d5">Deb et al. are authors who have worked on multi-objective search algorithms, relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NOVELTY SEARCH ALGORITHMS" target="AI-GENERATING ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">AI-generating algorithms are methods that can be incorporated into novelty search algorithms to create new AI systems.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NOVELTY SEARCH ALGORITHMS" target="OPEN-ENDED ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">Open-ended algorithms are methods that can be incorporated into novelty search algorithms to continuously explore and generate new solutions.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="MOURET &amp; CLUNE, 2015">
      <data key="d4">10.0</data>
      <data key="d5">Mouret &amp; Clune are authors who have worked on AI-generating algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="OPEN-ENDED ALGORITHMS" target="STANLEY &amp; LEHMAN, 2015">
      <data key="d4">5.0</data>
      <data key="d5">Stanley &amp; Lehman are authors who have worked on open-ended algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="OPEN-ENDED ALGORITHMS" target="STANLEY ET AL., 2019">
      <data key="d4">5.0</data>
      <data key="d5">Stanley et al. are authors who have worked on open-ended algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="CHIANG ET AL., 2024" target="SUBJECTIVE ANSWER EVALUATIONS">
      <data key="d4">5.0</data>
      <data key="d5">Chiang et al. are authors who have worked on subjective answer evaluations in ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="AS" target="HUMAN ORGANIZATION">
      <data key="d4">18.0</data>
      <data key="d5">AS sheds light on the origins of complexity emerging from human organization and society.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="HUMAN ORGANIZATION" target="AGENTIC SYSTEM">
      <data key="d4">16.0</data>
      <data key="d5">Agentic systems simulate human organizations and societies.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="PARK ET AL., 2023">
      <data key="d4">14.0</data>
      <data key="d5">Park et al. simulated a human town with agents.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="JENNY ZHANG" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Jenny Zhang is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="DAWN SONG" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Dawn Song is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="WEI-LIN CHIANG, LIANMIN ZHENG, YING SHENG, ANASTASIOS NIKOLAS ANGELOPOULOS, TIANLE LI, DACHENG LI, HAO ZHANG, BANGHUA ZHU, MICHAEL JORDAN, JOSEPH E. GONZALEZ, AND ION STOICA" target="CHATBOT ARENA">
      <data key="d4">9.0</data>
      <data key="d5">The group of researchers authored the paper "Chatbot arena: An open platform for evaluating llms by human preference."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="FRAN&#199;OIS CHOLLET" target="ON THE MEASURE OF INTELLIGENCE">
      <data key="d4">9.0</data>
      <data key="d5">Fran&#231;ois Chollet authored the paper "On the measure of intelligence."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="KARL COBBE, VINEET KOSARAJU, MOHAMMAD BAVARIAN, MARK CHEN, HEEWOO JUN, LUKASZ KAISER, MATTHIAS PLAPPERT, JERRY TWOREK, JACOB HILTON, REIICHIRO NAKANO, ET AL." target="TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS">
      <data key="d4">9.0</data>
      <data key="d5">The group of researchers authored the paper "Training verifiers to solve math word problems."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS" target="KARL COBBE">
      <data key="d4">8.0</data>
      <data key="d5">Karl Cobbe is one of the authors of the paper on training verifiers to solve math word problems.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ANTOINE CULLY AND YIANNIS DEMIRIS" target="QUALITY AND DIVERSITY OPTIMIZATION">
      <data key="d4">9.0</data>
      <data key="d5">Antoine Cully and Yiannis Demiris authored the paper "Quality and diversity optimization: A unifying modular framework."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="ANTOINE CULLY AND YIANNIS DEMIRIS" target="IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Quality and diversity optimization: A unifying modular framework" was published in IEEE Transactions on Evolutionary Computation in 2017.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="N. DALAL AND B. TRIGGS" target="HISTOGRAMS OF ORIENTED GRADIENTS FOR HUMAN DETECTION">
      <data key="d4">9.0</data>
      <data key="d5">N. Dalal and B. Triggs authored the paper "Histograms of oriented gradients for human detection."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="KALYANMOY DEB, AMRIT PRATAP, SAMEER AGARWAL, AND TAMT MEYARIVAN" target="NSGA-II">
      <data key="d4">9.0</data>
      <data key="d5">Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan authored the paper "A fast and elitist multiobjective genetic algorithm: Nsga-ii."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="KALYANMOY DEB, AMRIT PRATAP, SAMEER AGARWAL, AND TAMT MEYARIVAN" target="IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION">
      <data key="d4">8.0</data>
      <data key="d5">The paper "A fast and elitist multiobjective genetic algorithm: Nsga-ii" was published in IEEE Transactions on Evolutionary Computation in 2002.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AARON DHARNA, JULIAN TOGELIUS, AND LISA B SOROS" target="CO-GENERATION OF GAME LEVELS AND GAME-PLAYING AGENTS">
      <data key="d4">9.0</data>
      <data key="d5">Aaron Dharna, Julian Togelius, and Lisa B Soros authored the paper "Co-generation of game levels and game-playing agents."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AARON DHARNA, JULIAN TOGELIUS, AND LISA B SOROS" target="AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INTERACTIVE DIGITAL ENTERTAINMENT">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Co-generation of game levels and game-playing agents" was presented at the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YILUN DU, SHUANG LI, ANTONIO TORRALBA, JOSHUA B TENENBAUM, AND IGOR MORDATCH" target="IMPROVING FACTUALITY AND REASONING IN LANGUAGE MODELS THROUGH MULTIAGENT DEBATE">
      <data key="d4">9.0</data>
      <data key="d5">Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch authored the paper "Improving factuality and reasoning in language models through multiagent debate."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="DHEERU DUA, YIZHONG WANG, PRADEEP DASIGI, GABRIEL STANOVSKY, SAMEER SINGH, AND MATT GARDNER" target="PROCEEDINGS OF THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES">
      <data key="d4">8.0</data>
      <data key="d5">The paper "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" was included in the proceedings edited by Jill Burstein, Christy Doran, and Thamar Solorio.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YAN DUAN, JOHN SCHULMAN, XI CHEN, PETER L. BARTLETT, ILYA SUTSKEVER, AND PIETER ABBEEL" target="RL^2">
      <data key="d4">9.0</data>
      <data key="d5">Yan Duan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever, and Pieter Abbeel authored the paper "RL^2: Fast reinforcement learning via slow reinforcement learning."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YAN DUAN, JOHN SCHULMAN, XI CHEN, PETER L. BARTLETT, ILYA SUTSKEVER, AND PIETER ABBEEL" target="INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d4">8.0</data>
      <data key="d5">The paper "RL^2: Fast reinforcement learning via slow reinforcement learning" was presented at the International Conference on Learning Representations in 2017.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="ADRIEN ECOFFET, JEFF CLUNE, AND JOEL LEHMAN" target="OPEN QUESTIONS IN CREATING SAFE OPEN-ENDED AI">
      <data key="d4">9.0</data>
      <data key="d5">Adrien Ecoffet, Jeff Clune, and Joel Lehman authored the paper "Open questions in creating safe open-ended AI: Tensions between control and creativity."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="ADRIEN ECOFFET, JEFF CLUNE, AND JOEL LEHMAN" target="CONFERENCE ON ARTIFICIAL LIFE">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Open questions in creating safe open-ended AI: Tensions between control and creativity" was presented at the Conference on Artificial Life in 2020.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="THOMAS ELSKEN, JAN HENDRIK METZEN, AND FRANK HUTTER" target="JOURNAL OF MACHINE LEARNING RESEARCH">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Neural architecture search: A survey" was published in the Journal of Machine Learning Research in 2019.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="CHELSEA FINN, PIETER ABBEEL, AND SERGEY LEVINE" target="PMLR">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Model-agnostic meta-learning for fast adaptation of deep networks" was published in the Proceedings of Machine Learning Research (PMLR) in 2017.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="LUYU GAO, AMAN MADAAN, SHUYAN ZHOU, URI ALON, PENGFEI LIU, YIMING YANG, JAMIE CALLAN, AND GRAHAM NEUBIG" target="PMLR">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Pal: Program-aided language models" was published in the Proceedings of Machine Learning Research (PMLR) in 2023.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="RYAN GREENBLATT" target="REDWOOD RESEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Ryan Greenblatt is associated with Redwood Research, which published his article "Getting 50% sota on arc-agi with gpt-4."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="RYAN GREENBLATT" target="ARC-AGI">
      <data key="d4">7.0</data>
      <data key="d5">Ryan Greenblatt authored a technical report discussing achieving 50% SOTA on ARC-AGI with GPT-4.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JILL BURSTEIN, CHRISTY DORAN, AND THAMAR SOLORIO" target="PROCEEDINGS OF THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES">
      <data key="d4">8.0</data>
      <data key="d5">Jill Burstein, Christy Doran, and Thamar Solorio edited the proceedings for the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="REDWOOD RESEARCH" target="SUBSTACK">
      <data key="d4">1.0</data>
      <data key="d5">Redwood Research published the article "Getting 50% sota on arc-agi with gpt-4" on Substack.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="DAN HENDRYCKS" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Dan Hendrycks is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="DAN HENDRYCKS" target="MEASURING MATHEMATICAL PROBLEM SOLVING">
      <data key="d4">8.0</data>
      <data key="d5">Dan Hendrycks is one of the authors of the paper on measuring mathematical problem solving.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COLLIN BURNS" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Collin Burns is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="STEVEN BASART" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Steven Basart is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="ANDY ZOU" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Andy Zou is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="MANTAS MAZEIKA" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Mantas Mazeika is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JACOB STEINHARDT" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Jacob Steinhardt is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="SIRUI HONG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Sirui Hong is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="XIAWU ZHENG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Xiawu Zheng is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JONATHAN CHEN" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Jonathan Chen is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="YUHENG CHENG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Yuheng Cheng is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JINLIN WANG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Jinlin Wang is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="CEYAO ZHANG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Ceyao Zhang is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="ZILI WANG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Zili Wang is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="STEVEN KA SHING YAU" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Steven Ka Shing Yau is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="ZIJUAN LIN" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Zijuan Lin is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="LIYANG ZHOU" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Liyang Zhou is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="RAN CHENG" target="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Ran Cheng is one of the authors of the paper discussing accelerating multi-objective neural architecture search.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="CHENG HE" target="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Cheng He is one of the authors of the paper discussing accelerating multi-objective neural architecture search.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="ZHICHAO LU" target="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Zhichao Lu is one of the authors of the paper discussing accelerating multi-objective neural architecture search.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JING WANG" target="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Jing Wang is one of the authors of the paper discussing accelerating multi-objective neural architecture search.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="MIAO ZHANG" target="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Miao Zhang is one of the authors of the paper discussing accelerating multi-objective neural architecture search.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="SHIHUA HUANG" target="REVISITING RESIDUAL NETWORKS">
      <data key="d4">8.0</data>
      <data key="d5">Shihua Huang is one of the authors of the paper discussing revisiting residual networks for adversarial robustness.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JOEL LEHMAN" target="RUI WANG">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JOEL LEHMAN" target="KENNETH O. STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JOEL LEHMAN" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Joel Lehman is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JI-RONG WEN" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Ji-Rong Wen is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MIRAC SUZGUN" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Mirac Suzgun is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="MATT BOTVINICK" target="SHAN KUMARAN">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the paper "Learning to reinforcement learn."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="LEI WANG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Lei Wang is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="CHEN MA" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Chen Ma is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="CHEN MA" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Chen Ma is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="XUEYANG FENG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Xueyang Feng is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="ZEYU ZHANG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Zeyu Zhang is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="ZEYU ZHANG" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Zeyu Zhang is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="HAO YANG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Hao Yang is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JINGSEN ZHANG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Jingsen Zhang is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="ZHIYUAN CHEN" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Zhiyuan Chen is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JIAKAI TANG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Jiakai Tang is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="XU CHEN" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Xu Chen is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="XU CHEN" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Xu Chen is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="RUI WANG" target="KENNETH O. STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QUOC V LE" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Quoc V Le is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QUOC V LE" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Quoc V Le is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QUOC V LE" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Quoc V Le is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="QUOC V LE" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Quoc V Le is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="QUOC V LE" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Quoc V Le is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ED H. CHI" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Ed H. Chi is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="ED H. CHI" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Ed H. Chi is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QINGYUN WU" target="AUTOGEN: ENABLING NEXT-GEN LLM APPLICATIONS VIA MULTI-AGENT CONVERSATION FRAMEWORK">
      <data key="d4">8.0</data>
      <data key="d5">Qingyun Wu is one of the authors of the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QINGYUN WU" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Qingyun Wu is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="BENFENG XU" target="EXPERTPROMPTING: INSTRUCTING LARGE LANGUAGE MODELS TO BE DISTINGUISHED EXPERTS">
      <data key="d4">8.0</data>
      <data key="d5">Benfeng Xu is one of the authors of the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="CHENGRUN YANG" target="LARGE LANGUAGE MODELS AS OPTIMIZERS">
      <data key="d4">8.0</data>
      <data key="d5">Chengrun Yang is one of the authors of the paper "Large language models as optimizers."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="SHAOKUN ZHANG" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Shaokun Zhang is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIEYU ZHANG" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Jieyu Zhang is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="CHI WANG" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Chi Wang is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="KENNETH STANLEY" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Kenneth Stanley is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIALE LIU" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Jiale Liu is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="LINXIN SONG" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Linxin Song is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="RANJAY KRISHNA" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Ranjay Krishna is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="XIAOHE BO" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Xiaohe Bo is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="RUI LI" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Rui Li is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="QUANYU DAI" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Quanyu Dai is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIEMING ZHU" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Jieming Zhu is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ZHENHUA DONG" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Zhenhua Dong is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="HENG-TZE CHENG" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Heng-Tze Cheng is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="HENG-TZE CHENG" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Heng-Tze Cheng is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ED H CHI" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Ed H Chi is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ED H CHI" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Ed H Chi is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ED H CHI" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Ed H Chi is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="PEI ZHOU" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Pei Zhou is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JAY PUJARA" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Jay Pujara is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="XIANG REN" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Xiang Ren is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="WANGCHUNSHU ZHOU" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Wangchunshu Zhou is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="YIXIN OU" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Yixin Ou is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="SHENGWEI DING" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Shengwei Ding is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="LONG LI" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Long Li is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIALONG WU" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Jialong Wu is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="TIANNAN WANG" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Tiannan Wang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIAMIN CHEN" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Jiamin Chen is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="EXPERIMENT DETAILS" target="ZERO-SHOT STYLE QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Experiment details include the use of zero-shot style questions for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERIMENT DETAILS" target="ONE-SHOT STYLE QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Experiment details include the use of one-shot style questions for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERIMENT DETAILS" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">The document "Automated Design of Agentic Systems" includes experimental details.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="COST OF EXPERIMENTS" target="GPT-3.5-TURBO-0125">
      <data key="d4">7.0</data>
      <data key="d5">The cost of experiments is significantly influenced by the use of the GPT-3.5-Turbo-0125 model.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="COST OF EXPERIMENTS" target="GPT-4O-MINI">
      <data key="d4">7.0</data>
      <data key="d5">The cost of experiments could be reduced by using the GPT-4o-mini model, which is less expensive and offers better performance.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FRAMEWORK" target="NAMEDTUPLE INFO OBJECT">
      <data key="d4">7.0</data>
      <data key="d5">The framework uses namedtuple Info objects to encapsulate different types of information.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FRAMEWORK" target="INFO OBJECT">
      <data key="d4">7.0</data>
      <data key="d5">The framework uses Info objects to encapsulate different types of information.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FRAMEWORK" target="FM MODULE">
      <data key="d4">1.0</data>
      <data key="d5">The framework includes an FM module that constructs the prompt by concatenating all input Info objects.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="RUNTIME ERROR" target="DEBUG_THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">After encountering a runtime error, the meta agent captures its debugging thought process in the "debug_thought" section.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FM MODULE" target="INFO">
      <data key="d4">9.0</data>
      <data key="d5">The FM Module uses Info objects to construct prompts and facilitate communication between different modules.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="FORMAT_INST">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses the FORMAT_INST lambda function to format instructions for FM responses.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="ROLE_DESC">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses the ROLE_DESC lambda function to generate role descriptions.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="GET_JSON_RESPONSE_FROM_GPT">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module can use the get_json_response_from_gpt function to get JSON responses from a GPT model.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="AGENT SYSTEM">
      <data key="d4">8.0</data>
      <data key="d5">The Agent System can use the FM Module to process task information and generate responses.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="TASK DESCRIPTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses task descriptions to facilitate communication between different modules.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="TOOL FUNCTION CALLS">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses results from tool function calls as input Info objects.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="META-AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module is part of the simple framework used in Meta-Agent Search.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="OUTPUT FIELDS">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module has output fields that are expected in its output.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="UNIQUE IDENTIFIER">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module has a unique identifier for its instances.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses instructions for generating prompts and querying information.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="ITERATION INDEX">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module uses an iteration index to track iterations in tasks.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="INITIAL INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses the initial instruction to generate candidate solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM MODULE" target="TASKINFO">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module processes TaskInfo to generate initial solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM MODULE" target="INITIAL SOLUTION">
      <data key="d4">8.0</data>
      <data key="d5">Initial solutions are generated by the FM Module based on the initial instruction and TaskInfo.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM MODULE" target="THOUGHTS">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module generates thoughts consisting of 'thinking' and 'code' as part of the initial solution.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="INFO" target="FM_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">Info is provided as input to the FM_Module to guide its operations.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INFO" target="SUB_PROBLEM INFO">
      <data key="d4">7.0</data>
      <data key="d5">Sub-problem info is a specific type of Info object used to encapsulate information about individual sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="GET_JSON_RESPONSE_FROM_GPT" target="BACKOFF">
      <data key="d4">8.0</data>
      <data key="d5">The backoff method is used in the get_json_response_from_gpt function to handle RateLimitError exceptions.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GET_JSON_RESPONSE_FROM_GPT" target="RATE LIMIT ERROR">
      <data key="d4">7.0</data>
      <data key="d5">The get_json_response_from_gpt function handles RateLimitError exceptions using the backoff method.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GET_JSON_RESPONSE_FROM_GPT" target="SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The get_json_response_from_gpt function uses a system message as an argument to guide the GPT model's response.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GET_JSON_RESPONSE_FROM_GPT" target="SAMPLING TEMPERATURE">
      <data key="d4">8.0</data>
      <data key="d5">The get_json_response_from_gpt function uses sampling temperature as a parameter to control the randomness of the GPT model's output.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SYSTEM MESSAGE" target="MULTI-TURN INTERACTION">
      <data key="d4">7.0</data>
      <data key="d5">System messages are part of the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="SYSTEM MESSAGE" target="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The Maths GPT-4 Extraction System Message is a type of system message used for evaluating math-based questions.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="SYSTEM MESSAGE" target="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The General Extraction System Message is a type of system message used for evaluating exact match/span extraction problems.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="COT_MODULE" target="N_MAX">
      <data key="d4">14.0</data>
      <data key="d5">The N_MAX parameter sets the maximum number of attempts for the COT_MODULE to refine the answer.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="COT_MODULE" target="TASKINFO">
      <data key="d4">14.0</data>
      <data key="d5">TASKINFO is used as input for the COT_MODULE to generate 'thinking' and 'answer' processes.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="CRITIC_INSTRUCTION" target="CRITIC_MODULE">
      <data key="d4">16.0</data>
      <data key="d5">The CRITIC_INSTRUCTION is used by the CRITIC_MODULE to review and criticize the answer or confirm its correctness.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="CRITIC_MODULE" target="TASKINFO">
      <data key="d4">14.0</data>
      <data key="d5">TASKINFO is used as input for the CRITIC_MODULE to generate 'feedback' and 'correct' processes.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="TASKINFO" target="THINKING">
      <data key="d4">8.0</data>
      <data key="d5">Task information is used as input for generating the thought process.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TASKINFO" target="DECOMPOSITION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">TaskInfo is processed by the decomposition module to generate sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="TASKINFO" target="INTEGRATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">TaskInfo is used as part of the input for the integration module to generate the final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="GPT-4O-2024-05-13" target="META_AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent uses the GPT-4o-2024-05-13 model for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPT-3.5-TURBO-0125" target="DISCOVERED_AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Discovered agents use the GPT-3.5-turbo-0125 model for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPT-3.5-TURBO-0125" target="DISCOVERED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Discovered agents use the GPT-3.5-turbo-0125 model for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FM_MODULE" target="THOUGHTS">
      <data key="d4">9.0</data>
      <data key="d5">The FM_Module generates thoughts, which include the thought process and feedback.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FM_MODULE" target="TEMPERATURE">
      <data key="d4">7.0</data>
      <data key="d5">Temperature is a parameter used in the FM_Module to control the randomness or creativity of the output.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FM_MODULE" target="DECOMPOSITION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The decomposition module is an instance of the FM_Module used to decompose tasks into sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="SPECIALIZED EXPERT">
      <data key="d4">9.0</data>
      <data key="d5">Specialized experts are instances of the FM_Module used to solve specific sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="INTEGRATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The integration module is an instance of the FM_Module used to integrate sub-problem solutions into a final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="VISUAL REPRESENTATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The visual representation module is an instance of the FM_Module used to generate visual representations of problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="VERIFICATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The verification module is an instance of the FM_Module used to verify visual representations and provide feedback.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="CHAIN-OF-THOUGHT MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The Chain-of-Thought module is an instance of the FM_Module used to solve problems using verified visual representations.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ENSEMBLE AGENT" target="NUM_CANDIDATES">
      <data key="d4">7.0</data>
      <data key="d5">The Ensemble Agent generates a specified number of initial candidate solutions, set by the num_candidates parameter.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="HUMAN_LIKE_FEEDBACK_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">Initial solutions are evaluated using the human-like feedback module.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="EXPERT_ADVISORS">
      <data key="d4">7.0</data>
      <data key="d5">Initial solutions are evaluated by expert advisors.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="REFINEMENT_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">Initial solutions are refined using the refinement module.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="HUMAN_LIKE_FEEDBACK_MODULE" target="HUMAN_FEEDBACK_INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The human-like feedback module operates based on the human feedback instruction.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERT_ADVISORS" target="EXPERT_INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Expert advisors operate based on the expert instruction.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERT_ADVISORS" target="ROLE">
      <data key="d4">8.0</data>
      <data key="d5">Roles such as Efficiency Expert, Readability Expert, and Simplicity Expert are assigned to expert advisors.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINEMENT_MODULE" target="REFINEMENT_INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The refinement module operates based on the refinement instruction.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINEMENT_MODULE" target="MAX_REFINEMENT_ITERATIONS">
      <data key="d4">7.0</data>
      <data key="d5">The refinement module iterates based on the maximum refinement iterations parameter.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINED_SOLUTIONS" target="SORTED_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Refined solutions are sorted based on their performance.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="SORTED_SOLUTIONS" target="TOP_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The top-performing solutions are selected from the sorted solutions.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TOP_SOLUTIONS" target="FINAL_DECISION_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">Top solutions are evaluated by the final decision module.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FINAL_DECISION_INSTRUCTION" target="FINAL_DECISION_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The final decision module operates based on the final decision instruction.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FINAL_DECISION_MODULE" target="FINAL_THOUGHTS">
      <data key="d4">8.0</data>
      <data key="d5">The final decision module generates the final thoughts.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="NON-NATIONALS" target="IMMIGRANTS">
      <data key="d4">8.0</data>
      <data key="d5">Non-nationals in Bahrain are primarily composed of immigrants.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="IMMIGRANTS" target="INDIANS">
      <data key="d4">7.0</data>
      <data key="d5">Indians are a significant demographic group among the immigrants in Bahrain.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="IMMIGRANTS" target="BANGLADESHIS">
      <data key="d4">7.0</data>
      <data key="d5">Bangladeshis are a significant demographic group among the immigrants in Bahrain.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="IMMIGRANTS" target="PAKISTANIS">
      <data key="d4">7.0</data>
      <data key="d5">Pakistanis are a significant demographic group among the immigrants in Bahrain.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="IMMIGRANTS" target="FILIPINOS">
      <data key="d4">7.0</data>
      <data key="d5">Filipinos are a significant demographic group among the immigrants in Bahrain.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="IMMIGRANTS" target="INDONESIANS">
      <data key="d4">6.0</data>
      <data key="d5">Indonesians are a demographic group among the immigrants in Bahrain.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="QUANTUM STATES" target="ENERGY LEVELS">
      <data key="d4">8.0</data>
      <data key="d5">Quantum states are characterized by distinct energy levels.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="UNCERTAINTY PRINCIPLE" target="DELTA E">
      <data key="d4">7.0</data>
      <data key="d5">Delta E is the uncertainty in energy, as discussed in the context of the uncertainty principle.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="UNCERTAINTY PRINCIPLE" target="DELTA T">
      <data key="d4">7.0</data>
      <data key="d5">Delta T is the uncertainty in time, as discussed in the context of the uncertainty principle.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="UNCERTAINTY PRINCIPLE" target="HBAR">
      <data key="d4">7.0</data>
      <data key="d5">Hbar is the reduced Planck constant, a fundamental constant in the uncertainty principle.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DECOMPOSITION MODULE" target="SUB_PROBLEMS">
      <data key="d4">9.0</data>
      <data key="d5">The decomposition module generates sub-problems from the main task.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="DECOMPOSITION MODULE" target="DECOMPOSITION INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The decomposition module uses decomposition instructions to guide the decomposition of tasks into sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERT" target="SUB_SOLUTIONS">
      <data key="d4">9.0</data>
      <data key="d5">Specialized experts provide solutions to the sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERT" target="SUB_PROBLEM INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Specialized experts use sub-problem instructions to solve sub-problems step by step.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="INTEGRATION MODULE" target="INTEGRATION INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The integration module uses integration instructions to guide the integration of sub-problem solutions into a final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VISUAL REPRESENTATION MODULE" target="VISUAL REPRESENTATION">
      <data key="d4">8.0</data>
      <data key="d5">The visual representation module generates visual representations of problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VISUAL REPRESENTATION MODULE" target="VISUAL INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The visual representation module uses visual instructions to create visual representations of problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VERIFICATION MODULE" target="VERIFIED VISUAL">
      <data key="d4">8.0</data>
      <data key="d5">The verification module verifies the visual representations and provides feedback.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VERIFICATION MODULE" target="VERIFICATION INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The verification module uses verification instructions to verify the accuracy and relevance of visual representations.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT MODULE" target="COT INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The Chain-of-Thought module uses CoT instructions to solve problems using verified visual representations.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VERIFIED VISUAL" target="VISUAL OUTPUT">
      <data key="d4">8.0</data>
      <data key="d5">The verified visual is produced by the verification module after checking the initial visual output.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="GENERATIVE TEACHING">
      <data key="d4">25.0</data>
      <data key="d5">AgentInstruct is an agentic solution designed to implement the Generative Teaching methodology. It is used as a method for Generative Teaching, enhancing AI model performance across various tasks. Specifically, AgentInstruct facilitates the implementation of Generative Teaching by creating synthetic data for post-training language models. This approach ensures a comprehensive enhancement of AI capabilities, leveraging synthetic data to refine and optimize model performance.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SYNTHETIC DATA">
      <data key="d4">17.0</data>
      <data key="d5">AgentInstruct is a sophisticated tool designed to generate synthetic data specifically for post-training language models. Utilizing agentic flows, AgentInstruct effectively creates high-quality synthetic data that can be used to enhance the training of various models. This innovative approach ensures that the generated data is well-suited for refining and improving the performance of language models, making AgentInstruct a valuable asset in the field of machine learning and artificial intelligence.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-7B">
      <data key="d4">16.0</data>
      <data key="d5">AgentInstruct played a crucial role in the development of the Mistral-7B model by generating the synthetic dataset used for its fine-tuning. This synthetic data, produced by AgentInstruct, was essential for the post-training phase of Mistral-7B, ensuring the model's enhanced performance and capabilities.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="POST-TRAINING">
      <data key="d4">9.0</data>
      <data key="d5">AgentInstruct generates synthetic data specifically for post-training language models.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="INSTRUCTION TUNING">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct generates synthetic data that can be used for instruction tuning of language models.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="RESPONSES">
      <data key="d4">17.0</data>
      <data key="d5">AgentInstruct generates both prompts and responses as part of its data generation process. It utilizes raw data sources to create these prompts and responses, ensuring a comprehensive and dynamic approach to data generation.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="TEXT EDITING">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of text editing.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CREATIVE WRITING">
      <data key="d4">15.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach AI models the skill of creative writing. By producing this data, AgentInstruct aims to enhance the capabilities of language models, enabling them to master the nuances and intricacies of creative writing. This process involves the creation of artificial datasets specifically designed to train AI systems in the art of crafting imaginative and expressive text, thereby improving their ability to generate creative content.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="TOOL USAGE">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of tool usage.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CODING">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of coding.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MULTI-AGENT WORKFLOWS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct utilizes multi-agent workflows to generate high-quality synthetic data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SYNTHETIC-DATA-GENERATION-AS-A-SERVICE">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct can be used to implement Synthetic-Data-Generation-As-A-Service.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTENT TRANSFORMATION AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Content Transformation Agents are part of the AgentInstruct methodology to transform raw seeds.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="REFINEMENT AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Refinement Agents are part of the AgentInstruct methodology to refine seed instructions.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="RAW SEEDS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct uses raw seeds as the initial input for data generation.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="INSTRUCTION CREATION AGENTS">
      <data key="d4">1.0</data>
      <data key="d5">Instruction Creation Agents are part of the AgentInstruct methodology to create diverse instructions.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SKILLS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct can be used to teach various skills to AI models, such as creative writing, reasoning, math, and tool use.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="TAXONOMY">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct uses a taxonomy of over 100 subcategories to create diverse and high-quality prompts and responses.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="VERIFICATION AND DATA FILTERING">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct applies verification and data filtering processes to ensure the quality of the generated data.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="UNSTRUCTURED TEXT DOCUMENTS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct uses unstructured text documents as raw seeds for data generation.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SOURCE CODE">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct uses source code as raw seeds for data generation.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTINUAL LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct enables continual learning by generating new data for post-training and fine-tuning.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3">
      <data key="d4">26.0</data>
      <data key="d5">AgentInstruct data has led to a performance augmentation of 33.94% over the Orca-2.5 baseline and an enhancement of 14.92% over Mistral-Instruct-7B. Orca-3 is trained using the AgentInstruct dataset, which includes approximately 22 million instructions. Orca-3 showed substantial performance improvement after being post-trained with a dataset generated by AgentInstruct.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-2.5">
      <data key="d4">8.0</data>
      <data key="d5">Orca-2.5 is used to compare and evaluate the impact of the larger AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="KNOWLEDGEPILE">
      <data key="d4">7.0</data>
      <data key="d5">KnowledgePile was used as a source for unstructured text and code files in the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="AUTOMATHTEXT">
      <data key="d4">7.0</data>
      <data key="d5">AutoMathText was used as a source for unstructured text and code files in the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="OPENSTAX">
      <data key="d4">7.0</data>
      <data key="d5">Openstax was used as a source for unstructured text in the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="APACHE-2.0 LICENSED SOURCE CODE">
      <data key="d4">7.0</data>
      <data key="d5">Apache-2.0 licensed source code files were used in the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CORPUS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct synthesizes a large and diverse corpus of data for training and evaluating models.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="DIFFICULTY">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct data includes varying degrees of difficulty to evaluate model performance.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">14.0</data>
      <data key="d5">AgentInstruct has demonstrated significant advancements in enhancing Mistral-7B-Instruct's reading comprehension capabilities. By leveraging AgentInstruct, Mistral-7B-Instruct's performance has been notably improved across a variety of tasks, showcasing its effectiveness in augmenting the overall functionality and efficiency of the Mistral-7B-Instruct model.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="LSAT">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct has elevated the performance of a 7B model to match that of GPT-4 on the reading comprehension sections of the LSAT.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3-7B">
      <data key="d4">9.0</data>
      <data key="d5">Orca-3-7B is fine-tuned with AgentInstruct data, showing substantial improvement in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="LIMITATIONS">
      <data key="d4">9.0</data>
      <data key="d5">AgentInstruct has several limitations, including extensibility, accuracy, cost, bias, validation, and dependency on seed data.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="EXTENSIBILITY">
      <data key="d4">7.0</data>
      <data key="d5">Extensibility is a limitation of AgentInstruct, requiring human effort to create agentic flows for different skills.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="BIAS">
      <data key="d4">7.0</data>
      <data key="d5">Bias is a limitation of AgentInstruct, where synthetic data may reflect and amplify biases from the original seed data.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="DEPENDENCY ON SEED DATA">
      <data key="d4">7.0</data>
      <data key="d5">Dependency on Seed Data is a limitation of AgentInstruct, where the quality of synthetic data depends on the quality of the real data used as seeds.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="UNSTRUCTURED DATA SOURCES">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct generates tailored datasets from unstructured data sources for model training.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MODEL POST-TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct facilitates model post-training by generating high-quality synthetic data.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="DOMAIN/TASK SPECIALIZATION">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct can be used for domain/task specialization by generating tailored datasets.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTINUAL IMPROVEMENT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct supports continual improvement of models by generating higher quality data.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="SLMS">
      <data key="d4">8.0</data>
      <data key="d5">Synthetic data is used to accelerate the development of Small Language Models (SLMs).</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="MODEL COLLAPSE">
      <data key="d4">7.0</data>
      <data key="d5">Model collapse can occur when language models are pre-trained on low-quality or repetitive synthetic data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="IMITATION PROCESS">
      <data key="d4">7.0</data>
      <data key="d5">The imitation process is a risk when using synthetic data generated by other models for training.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MISTRAL-7B" target="ORCA-3">
      <data key="d4">18.0</data>
      <data key="d5">MISTRAL-7B is a foundational model that serves as the basis for Orca-3. Orca-3 is a fine-tuned version of the MISTRAL-7B model, achieved through post-training with synthetic data generated by AgentInstruct. This process enhances the capabilities of the original MISTRAL-7B model, resulting in the more advanced and specialized Orca-3.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="AGIEVAL">
      <data key="d4">31.0</data>
      <data key="d5">Orca-3 is evaluated using the AGIEval benchmark, demonstrating significant improvements in various tasks. Specifically, Orca-3 scored 56.80 on the AGIEval benchmark, marking a 40% improvement over its predecessor, Orca-2.5. Additionally, Orca-3 shows a 40% improvement on the AGIEval benchmark compared to Mistral-7b-Instruct.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="BBH">
      <data key="d4">23.0</data>
      <data key="d5">ORCA-3 scored 61.83 on the BBH benchmark, demonstrating a significant 38% improvement over its predecessor, Orca-2.5. Additionally, ORCA-3 also shows a 38% improvement on the BBH benchmark when compared to Mistral-7b-Instruct.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="ALPACAEVAL">
      <data key="d4">23.0</data>
      <data key="d5">Orca-3 scored 24.80 on the AlpacaEval benchmark, demonstrating a 45% improvement over its predecessor, Orca-2.5. Additionally, Orca-3 shows a 45% improvement on the AlpacaEval benchmark compared to Mistral-7b-Instruct.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="LLAMA-8B-INSTRUCT">
      <data key="d4">14.0</data>
      <data key="d5">ORCA-3 consistently outperforms LLAMA-8B-INSTRUCT in various benchmarks. This superior performance is evident across multiple evaluations, highlighting ORCA-3's advanced capabilities in comparison to LLAMA-8B-INSTRUCT.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="GPT-3.5-TURBO">
      <data key="d4">21.0</data>
      <data key="d5">Orca-3 consistently outperforms GPT-3.5-Turbo in various benchmarks, demonstrating significant performance improvements. Specifically, Orca-3's performance is compared to GPT-3.5-Turbo for the GSM8K benchmark, where it shows notable advancements.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-INSTRUCT-7B">
      <data key="d4">8.0</data>
      <data key="d5">ORCA-3 demonstrated notable advancements compared to MISTRAL-INSTRUCT-7B across multiple benchmarks. Specifically, ORCA-3 exhibited a 21% improvement in reading comprehension capabilities relative to MISTRAL-INSTRUCT-7B. This highlights ORCA-3's superior performance and effectiveness in understanding and processing textual information.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-V0.1">
      <data key="d4">9.0</data>
      <data key="d5">Orca-3 is a finetuned version of the Mistral-7b-v0.1 model using the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="NVIDIA A100">
      <data key="d4">8.0</data>
      <data key="d5">The training of Orca-3 used 152 NVIDIA A100 GPUs.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ADAMW OPTIMIZER">
      <data key="d4">8.0</data>
      <data key="d5">The training of Orca-3 used the AdamW optimizer with an initial learning rate of 8e-6.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL TOKENIZER">
      <data key="d4">8.0</data>
      <data key="d5">The Mistral tokenizer was used to process the dataset for training the Orca-3 model.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="WEIGHT DECAY">
      <data key="d4">7.0</data>
      <data key="d5">Weight decay was used as a regularization technique in the training of the Orca-3 model.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="COSINE LEARNING RATE SCHEDULE">
      <data key="d4">7.0</data>
      <data key="d5">A cosine learning rate schedule was used in the training of the Orca-3 model.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="LINEAR LEARNING RATE WARM-UP">
      <data key="d4">7.0</data>
      <data key="d5">A linear learning rate warm-up was used during the initial 500 steps of training the Orca-3 model.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="EPOCH">
      <data key="d4">8.0</data>
      <data key="d5">The Orca-3 model was trained for three epochs.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="TRAINING LOSS">
      <data key="d4">8.0</data>
      <data key="d5">Training loss was calculated based on the response conditioned on the prompt during the training of the Orca-3 model.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 is an advanced model evaluated using the Orca-Bench dataset, with scores improving across different checkpoints.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="FOFO">
      <data key="d4">16.0</data>
      <data key="d5">ORCA-3 scored 84.01 on the FOFO benchmark, marking a 12% improvement over its predecessor, Orca-2.5. This significant enhancement highlights ORCA-3's advanced format-following capabilities, as evaluated by the FOFO benchmark.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="IFEVAL">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 scored 49.54 on the IFEval benchmark, a 2% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="INFOBENCH">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 scored 84.30 on the InfoBench benchmark, a 4% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="EQBENCH">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3 scored 91.36 on the EQBench benchmark, a 4% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="PERFORMANCE COMPARISON">
      <data key="d4">8.0</data>
      <data key="d5">The performance comparison shows the enhancement in capabilities of Orca-3 during post-training.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-3 CHECKPOINTS">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 is evaluated at different checkpoints, showing improvement in scores from 9.35 to 9.55.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="TRAINING EPOCH">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3's performance is evaluated after each training epoch.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MACRO SCORES">
      <data key="d4">7.0</data>
      <data key="d5">Macro scores are used to evaluate the performance of Orca-3 across all assessed dimensions.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="BENCHMARK RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">Benchmark results show the performance of Orca-3 against 5 baseline models.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="DIMENSIONS">
      <data key="d4">7.0</data>
      <data key="d5">Various dimensions are assessed to evaluate the performance of Orca-3.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="CAPABILITIES">
      <data key="d4">8.0</data>
      <data key="d5">The capabilities of Orca-3 are enhanced during post-training.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="POST-TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3's capabilities are enhanced during the post-training phase.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="ENHANCEMENT">
      <data key="d4">1.0</data>
      <data key="d5">The enhancement in Orca-3's capabilities is enabled by AgentInstruct data.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">16.0</data>
      <data key="d5">ORCA-3 demonstrates significant performance improvements over MISTRAL-7B-INSTRUCT in various benchmarks. This indicates that ORCA-3 has made relative advancements in its algorithmic structure and efficiency, outperforming MISTRAL-7B-INSTRUCT in multiple evaluative metrics. The enhancements in ORCA-3 suggest a more optimized and effective approach in its design and implementation, reflecting its superior capabilities in the context of the benchmarks considered.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-2.5">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 shows an 18% improvement over Orca-2.5 in reading comprehension capabilities.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="ORCA-3" target="ORCA 2.5">
      <data key="d4">9.0</data>
      <data key="d5">Orca-3 shows significant performance improvements over its predecessor, Orca 2.5, in various benchmarks.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="LSAT">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3's performance on the reading comprehension sections of the LSAT matches that of GPT-4.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="GEMINI PRO">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3 surpasses Gemini Pro in format-following capabilities.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ALPACAEVAL" target="XUECHEN LI">
      <data key="d4">8.0</data>
      <data key="d5">Xuechen Li is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="TIANYI ZHANG">
      <data key="d4">8.0</data>
      <data key="d5">Tianyi Zhang is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="YANN DUBOIS">
      <data key="d4">8.0</data>
      <data key="d5">Yann Dubois is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="ROHAN TAORI">
      <data key="d4">8.0</data>
      <data key="d5">Rohan Taori is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="ISHAAN GULRAJANI">
      <data key="d4">8.0</data>
      <data key="d5">Ishaan Gulrajani is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="CARLOS GUESTRIN">
      <data key="d4">8.0</data>
      <data key="d5">Carlos Guestrin is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">8.0</data>
      <data key="d5">Tatsunori B. Hashimoto is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">AlpacaEval is a benchmark used to evaluate open-ended generation tasks by measuring win-rates using GPT-4-turbo.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="ORCA-BENCH">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-turbo is a baseline model evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="ORCA-3-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3-7B is compared with GPT-3.5-Turbo in various evaluations.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="MIRAGE">
      <data key="d4">8.0</data>
      <data key="d5">GPT-3.5-turbo is evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="AZURE">
      <data key="d4">1.0</data>
      <data key="d5">Azure provides transparency notes and content moderation services for GPT-3.5-turbo.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AHMED AWADALLAH" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Ahmed Awadallah is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="RESPONSES" target="DATA GENERATION WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Data generation workflows involve the creation of responses to prompts.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="CREATIVE WRITING" target="SKILLS">
      <data key="d4">8.0</data>
      <data key="d5">Creative writing is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CODING" target="TOOL/API USE">
      <data key="d4">6.0</data>
      <data key="d5">Both involve the use of tools or APIs to perform tasks or solve problems.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CODING" target="SKILLS">
      <data key="d4">8.0</data>
      <data key="d5">Coding is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MULTI-AGENT WORKFLOWS" target="SEARCH APIS">
      <data key="d4">7.0</data>
      <data key="d5">Search APIs are tools used in multi-agent workflows to improve the quality of generated data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MULTI-AGENT WORKFLOWS" target="CALCULATOR">
      <data key="d4">7.0</data>
      <data key="d5">Calculators are tools used in multi-agent workflows to improve the quality of generated data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MULTI-AGENT WORKFLOWS" target="CODE INTERPRETERS">
      <data key="d4">1.0</data>
      <data key="d5">Code interpreters are tools used in multi-agent workflows to improve the quality of generated data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SKILLS" target="QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Question answering is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SKILLS" target="RETRIEVAL AUGMENTED GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Retrieval augmented generation is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SKILLS" target="TOOL/API USE">
      <data key="d4">8.0</data>
      <data key="d5">Tool/API use is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SKILLS" target="WEB CONTROL">
      <data key="d4">8.0</data>
      <data key="d5">Web control is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MISTRAL-INSTRUCT-7B" target="ORCA-BENCH">
      <data key="d4">7.0</data>
      <data key="d5">Mistral-Instruct-7B is a baseline model evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Flow is one of the flows defined by Agentic Flows to convert raw seeds into intermediate representations.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="SEED INSTRUCTION GENERATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow is one of the flows defined by Agentic Flows to generate diverse instructions from transformed content.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow is one of the flows defined by Agentic Flows to iteratively enhance the complexity and quality of instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="RAW ARTICLES">
      <data key="d4">7.0</data>
      <data key="d5">Raw articles are used as seeds in the agentic flows to foster diversity and ensure broad coverage in generated problems.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="SOURCE CODE FILES">
      <data key="d4">7.0</data>
      <data key="d5">Source code files are used as seeds in the agentic flows to foster diversity and ensure broad coverage in generated problems.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="SEED INSTRUCTION GENERATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow takes transformed content from the Content Transformation Flow to generate diverse instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="INTERMEDIATE REPRESENTATION">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Flow converts raw seeds into intermediate representations to simplify the creation of instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="ARGUMENT PASSAGE GENERATOR">
      <data key="d4">8.0</data>
      <data key="d5">Argument Passage Generator is one of the content transformation agents used in the Content Transformation Flow.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="CONTENT TRANSFORMATION AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Content Transformation Agent is used in the Content Transformation Flow to synthesize an API description from a source code snippet.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="API RETRIEVAL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The API Retrieval Agent is used in the Content Transformation Flow to iteratively search for similar code to expand an API list.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="LIBRARY RECONSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">Library Reconstruction is a scenario within the Content Transformation Flow where a list of APIs is synthesized from a random seed.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow takes instructions from the Seed Instruction Generation Flow and enhances their complexity and quality.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="SEED INSTRUCTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow generates seed instructions from transformed content to introduce diversity.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="READING COMPREHENSION QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The Seed Instruction Generation Flow involves compiling a collection of reading comprehension question types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">The Seed Instruction Generation Flow defines multiple agents to generate questions based on predefined types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="CONTENT TRANSFORMATION AGENT">
      <data key="d4">7.0</data>
      <data key="d5">The content transformation agent determines which subset of agents to engage in the Seed Instruction Generation Flow process.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="PASSAGE, QUESTION PAIRS">
      <data key="d4">8.0</data>
      <data key="d5">The Seed Instruction Generation Flow results in the creation of passage, question pairs.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="LITERAL COMPREHENSION QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes literal comprehension questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="CRITICAL COMPREHENSION QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes critical comprehension questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="EVALUATIVE COMPREHENSION QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes evaluative comprehension questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="REASONING QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes reasoning questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="IDENTIFYING ASSUMPTIONS QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes identifying assumptions questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="IDENTIFYING INFORMATION THAT STRENGTHENS/WEAKENS AN ARGUMENT QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes questions that identify information that strengthens or weakens an argument.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="ORDERING EVENTS QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes ordering events questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="APPENDIX A">
      <data key="d4">6.0</data>
      <data key="d5">Appendix A contains a list of reading comprehension question types included in the Seed Instruction Generation Flow.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR AGENTS">
      <data key="d4">15.0</data>
      <data key="d5">The Instruction Refinement Flow involves the use of Suggester-Editor Agents to enhance the quality of instructional content. These agents play a crucial role in proposing and modifying instructions, ensuring that the passage and question pairs are refined and optimized. By leveraging the capabilities of Suggester-Editor Agents, the Instruction Refinement Flow aims to improve the clarity and effectiveness of instructional materials, facilitating better understanding and engagement.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Suggester agents propose various approaches to increase the intricacy of initial instructions in the Instruction Refinement Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="EDITOR AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Editor agents modify instructions based on suggestions from suggester agents in the Instruction Refinement Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="PASSAGE, QUESTION PAIRS">
      <data key="d4">8.0</data>
      <data key="d5">The Instruction Refinement Flow modifies passage, question pairs to create more complex or unanswerable questions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="STRENGTHEN TYPE QUESTION">
      <data key="d4">7.0</data>
      <data key="d5">The Instruction Refinement Flow includes strengthen type questions as an example.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">8.0</data>
      <data key="d5">The Suggester-Editor Pair is used in the Instruction Refinement Flow to increase the complexity of generated instructions.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="TASK MODIFICATION INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Task modification instructions are used in the Instruction Refinement Flow to refine and increase the complexity of generated instructions.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="SUGGESTION 1">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can introduce a hypothetical study or finding as Suggestion 1.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="SUGGESTION 2">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can add a layer of complexity by suggesting a genetic predisposition as Suggestion 2.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="SUGGESTION 3">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can include a distractor option as Suggestion 3.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="MODIFICATION 1">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can alter the passage to make the question unanswerable as Modification 1.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="MODIFICATION 2">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can alter the passage to change the answer in the opposite direction as Modification 2.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="MODIFICATION 3">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can alter the questions or answer choices to make them more complex as Modification 3.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="RETRIEVAL AUGMENTED GENERATION" target="TEXT EXTRACTION">
      <data key="d4">8.0</data>
      <data key="d5">Retrieval Augmented Generation involves retrieving relevant documents, which is a form of text extraction.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="WEB CONTROL" target="WEB AGENT">
      <data key="d4">1.0</data>
      <data key="d5">A web agent performs tasks on the web, which is a form of web control.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT EXTRACTION">
      <data key="d4">6.0</data>
      <data key="d5">Both involve processing and altering text to suit different purposes.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT">
      <data key="d4">8.0</data>
      <data key="d5">Text modification involves changing existing text to improve its quality or fit a specific context.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Text modification is one of the tasks within the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT MODIFICATION TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Text modification involves various tasks such as paraphrasing, expansion, and simplification.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="PARAPHRASING AGENT">
      <data key="d4">1.0</data>
      <data key="d5">The Paraphrasing Agent is used to create text modification tasks involving rephrasing.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT MODIFICATION AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Text modification involves agents that create tasks such as paraphrasing, expansion, and simplification.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Multiple choice questions are one of the tasks within the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="EVALUATOR ASSISTANT">
      <data key="d4">8.0</data>
      <data key="d5">The Evaluator Assistant role is used in the context of multiple choice questions to parse student responses.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="DATA TO TEXT" target="TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Data-to-text is one of the tasks within the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="FERMI PROBLEMS" target="TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Fermi problems are one of the tasks within the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="FERMI PROBLEMS" target="ENRICO FERMI">
      <data key="d4">18.0</data>
      <data key="d5">Fermi problems are named after physicist Enrico Fermi.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="TEXT">
      <data key="d4">8.0</data>
      <data key="d5">Text extraction involves retrieving relevant information from a larger text document.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="TASKS">
      <data key="d4">1.0</data>
      <data key="d5">Text extraction is one of the tasks within the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="TEXT CLASSIFICATION">
      <data key="d4">7.0</data>
      <data key="d5">Both text extraction and text classification are tasks in natural language processing that deal with processing and understanding text.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="NAMED ENTITY RECOGNITION">
      <data key="d4">8.0</data>
      <data key="d5">Named entity recognition is a task involved in text extraction.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="KEYWORD EXTRACTION">
      <data key="d4">8.0</data>
      <data key="d5">Keyword extraction is a task involved in text extraction.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="INTERMEDIATE REPRESENTATION" target="ARGUMENT PASSAGE">
      <data key="d4">6.0</data>
      <data key="d5">An argument passage is a type of intermediate representation used in the Content Transformation Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INTERMEDIATE REPRESENTATION" target="MEETING TRANSCRIPT">
      <data key="d4">6.0</data>
      <data key="d5">A meeting transcript is a type of intermediate representation used in the Content Transformation Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INTERMEDIATE REPRESENTATION" target="LIST OF APIS">
      <data key="d4">6.0</data>
      <data key="d5">A list of APIs is a type of intermediate representation used in the Content Transformation Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION TESTS" target="TEXT PASSAGES">
      <data key="d4">7.0</data>
      <data key="d5">Text passages are used in reading comprehension tests to assess understanding.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="SPAM DETECTION">
      <data key="d4">8.0</data>
      <data key="d5">Spam detection is an application of text classification.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="SENTIMENT ANALYSIS">
      <data key="d4">8.0</data>
      <data key="d5">Sentiment analysis is an application of text classification.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="TOPIC LABELING">
      <data key="d4">8.0</data>
      <data key="d5">Topic labeling is an application of text classification.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="URIC ACID" target="HYPERURICEMIA">
      <data key="d4">18.0</data>
      <data key="d5">Hyperuricemia is a condition characterized by high levels of uric acid in the blood.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="HYPOURICEMIA">
      <data key="d4">18.0</data>
      <data key="d5">Hypouricemia is a condition characterized by low levels of uric acid in the blood. Uric acid, a waste product found in the blood, is typically produced during the breakdown of purines, substances found in certain foods and drinks. Hypouricemia can result from various factors, including genetic disorders, certain medications, or underlying health conditions that affect the body's ability to produce or excrete uric acid. This condition may lead to various health issues, including an increased risk of kidney stones and other renal complications. Understanding the dynamics and interactions of uric acid levels is crucial for diagnosing and managing hypouricemia effectively.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="PURINE">
      <data key="d4">1.0</data>
      <data key="d5">Uric acid is a byproduct of purine metabolism.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="URIC ACID" target="CARDIOVASCULAR DISEASE">
      <data key="d4">8.0</data>
      <data key="d5">High levels of uric acid are associated with an increased risk of cardiovascular disease.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="ALCOHOL CONSUMPTION">
      <data key="d4">7.0</data>
      <data key="d5">Alcohol consumption can influence uric acid levels in the body.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="PHYSICAL INACTIVITY">
      <data key="d4">7.0</data>
      <data key="d5">Physical inactivity can influence uric acid levels in the body.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPERURICEMIA" target="LABORATORY BLOOD TESTS">
      <data key="d4">9.0</data>
      <data key="d5">Laboratory blood tests are used to diagnose hyperuricemia by measuring uric acid levels in the blood.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPERURICEMIA" target="LABORATORY URINE TESTS">
      <data key="d4">9.0</data>
      <data key="d5">Laboratory urine tests are used to diagnose hyperuricemia by measuring uric acid levels in the urine.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPERURICEMIA" target="CARDIOVASCULAR DISEASE">
      <data key="d4">8.0</data>
      <data key="d5">Hyperuricemia is associated with an increased risk of cardiovascular disease.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPERURICEMIA" target="LABORATORY BLOOD AND URINE TESTS">
      <data key="d4">7.0</data>
      <data key="d5">Hyperuricemia can be diagnosed using laboratory blood and urine tests.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY BLOOD TESTS">
      <data key="d4">9.0</data>
      <data key="d5">Laboratory blood tests are used to diagnose hypouricemia by measuring uric acid levels in the blood.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY URINE TESTS">
      <data key="d4">1.0</data>
      <data key="d5">Laboratory urine tests are used to diagnose hypouricemia by measuring uric acid levels in the urine.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY BLOOD AND URINE TESTS">
      <data key="d4">7.0</data>
      <data key="d5">Hypouricemia can be diagnosed using laboratory blood and urine tests.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="KIDNEY ISSUES">
      <data key="d4">7.0</data>
      <data key="d5">Hypouricemia can indicate underlying kidney issues.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LIVER ISSUES">
      <data key="d4">7.0</data>
      <data key="d5">Hypouricemia can indicate underlying liver issues.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="ASSUMPTION QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Assumption questions are a type of question in the LSAT Logical Reasoning test.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="STRENGTHENING/WEAKENING QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Strengthening/weakening questions are a type of question in the LSAT Logical Reasoning test.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="FLAW QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Flaw questions are a type of question in the LSAT Logical Reasoning test.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="INFERENCE QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Inference questions are a type of question in the LSAT Logical Reasoning test.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION QUESTIONS" target="AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Agents are defined to target specific categories of reading comprehension questions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION AGENT" target="API DESCRIPTION">
      <data key="d4">8.0</data>
      <data key="d5">An API description is synthesized by the Content Transformation Agent from a source code snippet.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="PARAPHRASING AGENT" target="RANDOM SEED">
      <data key="d4">7.0</data>
      <data key="d5">A random seed is used by the Paraphrasing Agent to create text modification tasks.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 1" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">7.0</data>
      <data key="d5">Suggestion 1 is provided by the Suggester-Editor Pair to incorporate a fictional narrative and use a conversational style with colloquial language.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 1" target="INSTRUCTION 1">
      <data key="d4">7.0</data>
      <data key="d5">Instruction 1 is a modified version of Suggestion 1, rewriting event details as if telling a funny story to a friend.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 2" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">7.0</data>
      <data key="d5">Suggestion 2 is provided by the Suggester-Editor Pair to translate event details into a poetic format with rhyming couplets.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 2" target="INSTRUCTION 2">
      <data key="d4">7.0</data>
      <data key="d5">Instruction 2 is a modified version of Suggestion 2, transforming event details into a light-hearted poem with rhyming couplets.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 3" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">7.0</data>
      <data key="d5">Suggestion 3 is provided by the Suggester-Editor Pair to frame event details as a social media post using internet slang and emojis.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 3" target="INSTRUCTION 3">
      <data key="d4">7.0</data>
      <data key="d5">Instruction 3 is a modified version of Suggestion 3, crafting a social media post with event details using internet slang and emojis.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="TEXT MODIFICATION AGENTS" target="PARAPHRASING">
      <data key="d4">7.0</data>
      <data key="d5">Text modification agents can create paraphrasing tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION AGENTS" target="SIMPLIFICATION">
      <data key="d4">7.0</data>
      <data key="d5">Text modification agents can create simplification tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION AGENTS" target="REDACTING OR REMOVING CONTENT">
      <data key="d4">7.0</data>
      <data key="d5">Text modification agents can create tasks involving redacting or removing content.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION AGENTS" target="STYLING">
      <data key="d4">7.0</data>
      <data key="d5">Text modification agents can create styling tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION AGENTS" target="CODE SWITCHING">
      <data key="d4">1.0</data>
      <data key="d5">Text modification agents can create code switching tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="FINANCIALIZATION" target="NATASCHA VAN DER ZWAN">
      <data key="d4">9.0</data>
      <data key="d5">Natascha van der Zwan identifies three distinct research streams that approach financialization from different perspectives.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="FINANCIALIZATION" target="FINANCE">
      <data key="d4">7.0</data>
      <data key="d5">Finance is a broad concept that is increasingly interconnected with financialization.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="AMERICAN ANTHROPOLOGICAL ASSOCIATION" target="SEA 2017 ANNUAL MEETING">
      <data key="d4">8.0</data>
      <data key="d5">The American Anthropological Association hosts the SEA 2017 Annual Meeting.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEA 2017 ANNUAL MEETING" target="APRIL 6-8, 2017">
      <data key="d4">8.0</data>
      <data key="d5">The SEA 2017 Annual Meeting took place on April 6-8, 2017.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEA 2017 ANNUAL MEETING" target="DECEMBER 1, 2016">
      <data key="d4">8.0</data>
      <data key="d5">December 1, 2016, is the deadline for submitting abstracts for the SEA 2017 Annual Meeting.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="LIBRARY RECONSTRUCTION" target="VIEW ALL FOOD ITEMS">
      <data key="d4">7.0</data>
      <data key="d5">View All Food Items is an API that is part of the Library Reconstruction scenario.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="LIBRARY RECONSTRUCTION" target="SEARCH FOOD ITEMS">
      <data key="d4">1.0</data>
      <data key="d5">Search Food Items is an API that is part of the Library Reconstruction scenario.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="CALORIE COUNT">
      <data key="d4">7.0</data>
      <data key="d5">Calorie count is a nutritional profile attribute included in the View All Food Items API.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="PROTEIN">
      <data key="d4">7.0</data>
      <data key="d5">Protein is a nutritional profile attribute included in the View All Food Items API.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="FAT">
      <data key="d4">1.0</data>
      <data key="d5">Fat is a nutritional profile attribute included in the View All Food Items API.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CREATE MEAL PLAN" target="QUINOA SALAD">
      <data key="d4">7.0</data>
      <data key="d5">The user wants to add the Quinoa Salad recipe while creating a meal plan.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="UPDATE FOOD ITEM" target="CHANA MASALA">
      <data key="d4">8.0</data>
      <data key="d5">The user wants to update the nutritional information for Chana Masala using the "Update Food Item" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="DELETE FOOD ITEM" target="BUTTER CHICKEN">
      <data key="d4">1.0</data>
      <data key="d5">The user wants to remove Butter Chicken from the database using the "Delete Food Item" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="SEED INSTRUCTION CREATION FLOW" target="ASSISTANT">
      <data key="d4">7.0</data>
      <data key="d5">The assistant uses the Seed Instruction Creation Flow to create tasks based on the list of available APIs.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="REFINEMENT FLOW" target="ASSISTANT">
      <data key="d4">7.0</data>
      <data key="d5">The assistant uses the Refinement Flow to increase the complexity of tasks by suggesting additional steps.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="AGENT-INSTRUCT FLOW" target="ASSISTANT">
      <data key="d4">7.0</data>
      <data key="d5">The assistant uses the Agent-Instruct Flow to create multi-turn conversations and instructions to help the user achieve their desired outcomes.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="QUINOA SALAD" target="FOOD_ID">
      <data key="d4">7.0</data>
      <data key="d5">The user needs to provide the nutritional information for the Quinoa Salad to add it to the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="QUINOA SALAD" target="MEAL PLAN DATABASE">
      <data key="d4">7.0</data>
      <data key="d5">The Quinoa Salad recipe needs to be added to the meal plan database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="QUINOA SALAD" target="NUTRITIONAL INFORMATION">
      <data key="d4">7.0</data>
      <data key="d5">Nutritional information is required to add the Quinoa Salad recipe to the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="CHANA MASALA" target="FOOD_ID">
      <data key="d4">7.0</data>
      <data key="d5">The user needs the unique identifier (food_id) to update the Chana Masala recipe in the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="CHANA MASALA" target="MEAL PLAN DATABASE">
      <data key="d4">7.0</data>
      <data key="d5">The Chana Masala recipe needs to be updated in the meal plan database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BUTTER CHICKEN" target="FOOD_ID">
      <data key="d4">7.0</data>
      <data key="d5">The user needs the unique identifier (food_id) to remove the Butter Chicken recipe from the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BUTTER CHICKEN" target="MEAL PLAN DATABASE">
      <data key="d4">7.0</data>
      <data key="d5">The Butter Chicken recipe needs to be removed from the meal plan database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="CALORIC GOAL">
      <data key="d4">9.0</data>
      <data key="d5">The vegetarian meal plan is designed to meet a caloric goal of 1500 calories per day.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="OATMEAL WITH FRUITS">
      <data key="d4">8.0</data>
      <data key="d5">Oatmeal with fruits is included in the vegetarian meal plan for breakfast.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="ALMOND MILK">
      <data key="d4">8.0</data>
      <data key="d5">Almond milk is included in the vegetarian meal plan for breakfast.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="CHICKPEA SALAD">
      <data key="d4">8.0</data>
      <data key="d5">Chickpea salad is included in the vegetarian meal plan for lunch.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="WHOLE WHEAT BREAD">
      <data key="d4">8.0</data>
      <data key="d5">Whole wheat bread is included in the vegetarian meal plan for lunch.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="MIXED VEGETABLE STIR FRY">
      <data key="d4">8.0</data>
      <data key="d5">Mixed vegetable stir fry is included in the vegetarian meal plan for dinner.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="BROWN RICE">
      <data key="d4">8.0</data>
      <data key="d5">Brown rice is included in the vegetarian meal plan for dinner.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="OATMEAL WITH FRUITS" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Oatmeal with fruits is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ALMOND MILK" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Almond milk is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="CHICKPEA SALAD" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Chickpea salad is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="WHOLE WHEAT BREAD" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Whole wheat bread is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="MIXED VEGETABLE STIR FRY" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Mixed vegetable stir fry is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BROWN RICE" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Brown rice is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-1">
      <data key="d4">8.0</data>
      <data key="d5">Orca-1 contributed to the 3.8 million paired instructions used in Orca-2.5.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-2">
      <data key="d4">8.0</data>
      <data key="d5">Orca-2 contributed to the 3.8 million paired instructions used in Orca-2.5.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-MATH">
      <data key="d4">8.0</data>
      <data key="d5">Orca-Math contributed to the 3.8 million paired instructions used in Orca-2.5.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-BENCH">
      <data key="d4">7.0</data>
      <data key="d5">Orca-2.5 is a baseline model evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B shows improvements over Orca-2.5 in various evaluations.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-BENCH" target="MULTI-TURN INTERACTION">
      <data key="d4">9.0</data>
      <data key="d5">The ORCA-BENCH dataset includes entries that involve multi-turn interactions. These multi-turn interactions are an integral part of the ORCA-BENCH dataset, highlighting the dataset's capacity to capture complex, sequential exchanges.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="COMPLEX ODQA">
      <data key="d4">8.0</data>
      <data key="d5">Complex ODQA is a subset of questions within the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="CHATGPT">
      <data key="d4">7.0</data>
      <data key="d5">ChatGPT is a baseline model evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="LLAMA3-8B-INSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">LLAMA3-8B-Instruct is a baseline model evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="MODEL PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">Model performance on the Orca-Bench dataset is scored on a scale from 0 to 10.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ODQA" target="COMPLEX ODQA">
      <data key="d4">1.0</data>
      <data key="d5">Complex ODQA is a subset of the ODQA category in the Orca-Bench dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="MULTI-TURN INTERACTION" target="USER INPUT">
      <data key="d4">7.0</data>
      <data key="d5">User inputs are part of the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MULTI-TURN INTERACTION" target="ASSISTANT RESPONSE">
      <data key="d4">7.0</data>
      <data key="d5">Assistant responses are part of the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MULTI-TURN INTERACTION" target="CONVERSATION HISTORY">
      <data key="d4">8.0</data>
      <data key="d5">Conversation history is used to condition the student response in the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="LLAMA3-8B-INSTRUCT" target="ORCA-3-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3-7B is compared with LLAMA3-8B-Instruct in various evaluations.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="FOFO" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">FOFO is a benchmark used to evaluate open-ended generation tasks by checking format correctness using GPT-4.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="IFEVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">IFEval is a benchmark used to evaluate open-ended generation tasks by checking if the model response follows verifiable instructions.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="INFOBENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">InfoBench is a benchmark used to evaluate open-ended generation tasks by checking if the model response follows decomposed instructions using GPT-4.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EQBENCH" target="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The EQBench GPT-4 Extraction System Message is used for extracting emotion scores from responses evaluated using EQBench.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EQBENCH" target="VERSION 1 AND 2 IMPLEMENTATIONS">
      <data key="d4">7.0</data>
      <data key="d5">The scoring calculations for EQBench are based on version 1 and 2 implementations described in the EQBench paper and repository.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EQBENCH" target="CREATORS' GITHUB REPOSITORY">
      <data key="d4">6.0</data>
      <data key="d5">The creators' GitHub repository contains the implementations and resources for EQBench.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EQBENCH" target="EMOTION SCORES">
      <data key="d4">8.0</data>
      <data key="d5">Emotion scores are generated as part of the EQBench evaluation process.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EQBENCH" target="STUDENT AGENT RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">The student agent response is evaluated using the EQBench benchmark.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="TEACHER RESPONSE">
      <data key="d4">9.0</data>
      <data key="d5">Student responses are evaluated against the original teacher responses generated by GPT-4.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="EVALUATOR ASSISTANT">
      <data key="d4">8.0</data>
      <data key="d5">The Evaluator Assistant parses the student response to extract the selected option.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="ANSWER OPTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The student response includes the selection of one or more answer options.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="PARSED STUDENT ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">The parsed student answer is extracted from the student's response.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="FINAL ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">The final answer is derived from the student's response after considering all options.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT" target="ORCA-3-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3-7B shows improvements over Mistral-7B-Instruct in various evaluations.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GEMINI PRO" target="ORCA-3-7B">
      <data key="d4">6.0</data>
      <data key="d5">The scores for Gemini Pro are referenced for comparison with Orca-3-7B.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="FOFO BENCHMARK">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated on the FoFo benchmark, showing improvements over previous models.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="HALLUCINATION RATE">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B has a lower hallucination rate compared to previous models like Orca-2.5 and Mistral-7B-Instruct.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="QUALITY SCORE">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B has a higher quality score compared to previous models like Orca-2.5 and Mistral-7B-Instruct.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="MIRAGE">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated on the MIRAGE datasets, showing substantial improvement in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="LIMITATIONS">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B retains many limitations of the Mistral model family and other large language models, including data biases, lack of transparency, and content harms.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="DATA BIASES">
      <data key="d4">7.0</data>
      <data key="d5">Data Biases are a limitation of Orca-3-7B, where the model may carry biases present in the source data.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="LACK OF TRANSPARENCY">
      <data key="d4">7.0</data>
      <data key="d5">Lack of Transparency is a limitation of Orca-3-7B, making it difficult to understand the rationale behind specific outputs.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="CONTENT HARMS">
      <data key="d4">7.0</data>
      <data key="d5">Content Harms are a limitation of Orca-3-7B, where the model can generate harmful content.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ACI-BENCH" target="WEN WAI YIM">
      <data key="d4">9.0</data>
      <data key="d5">Wen Wai Yim is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ACI-BENCH" target="YUJUAN FU">
      <data key="d4">9.0</data>
      <data key="d5">Yujuan Fu is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ACI-BENCH" target="ASMA BEN ABACHA">
      <data key="d4">9.0</data>
      <data key="d5">Asma Ben Abacha is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ACI-BENCH" target="NEAL SNIDER">
      <data key="d4">9.0</data>
      <data key="d5">Neal Snider is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ACI-BENCH" target="THOMAS LIN">
      <data key="d4">9.0</data>
      <data key="d5">Thomas Lin is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ORCA-SUM" target="DATA TRANSFORMATION">
      <data key="d4">7.0</data>
      <data key="d5">Orca-Sum evaluates the data transformation abilities of language models.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-SUM" target="SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Orca-Sum evaluates the summarization abilities of language models.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-SUM" target="HUGGING FACE">
      <data key="d4">6.0</data>
      <data key="d5">Hugging Face hosts the datasets used to create the Orca-Sum benchmark.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="MEDMEDQA">
      <data key="d4">8.0</data>
      <data key="d5">MedMedQA is one of the datasets included in the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="USMEDMCQA">
      <data key="d4">8.0</data>
      <data key="d5">USMedMCQA is one of the datasets included in the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="PUBMEDQA">
      <data key="d4">8.0</data>
      <data key="d5">PubMedQA is one of the datasets included in the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="BIOASQ">
      <data key="d4">8.0</data>
      <data key="d5">BioASQ is one of the datasets included in the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="ORCA-2.5-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-2.5-7B is evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="MISTRAL-7B-INSTRUCT-V0.1">
      <data key="d4">7.0</data>
      <data key="d5">Mistral-7B-Instruct-v0.1 is evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="MEDRAG">
      <data key="d4">8.0</data>
      <data key="d5">MedRAG is the retrieval mechanism used across all models on the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MMLU-MED" target="GPT-4 (0613) COT">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 (0613) CoT is evaluated on the MMLU-Med dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MMLU-MED" target="GPT-3.5-TURBO RAG">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-Turbo RAG is evaluated on the MMLU-Med dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MEDQA-US" target="GPT-4 (0613) COT">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 (0613) CoT is evaluated on the MedQA-US dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MEDQA-US" target="GPT-3.5-TURBO RAG">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-Turbo RAG is evaluated on the MedQA-US dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MEDMCQA" target="GPT-4 (0613) COT">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 (0613) CoT is evaluated on the MedMCQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MEDMCQA" target="GPT-3.5-TURBO RAG">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-Turbo RAG is evaluated on the MedMCQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PUBMEDQA" target="GPT-4 (0613) COT">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 (0613) CoT is evaluated on the PubMedQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PUBMEDQA" target="GPT-3.5-TURBO RAG">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-Turbo RAG is evaluated on the PubMedQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="BIOASQ" target="GPT-4 (0613) COT">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 (0613) CoT is evaluated on the BioASQ dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="BIOASQ" target="GPT-3.5-TURBO RAG">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-Turbo RAG is evaluated on the BioASQ dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="AZURE" target="TRANSPARENCY NOTES">
      <data key="d4">16.0</data>
      <data key="d5">Azure provides transparency notes to help users understand the rationale behind specific outputs or decisions of large language models. These transparency notes also offer more information about the functioning of these models, ensuring that users have a comprehensive understanding of the underlying mechanisms and decision-making processes.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AZURE" target="CONTENT MODERATION SERVICES">
      <data key="d4">1.0</data>
      <data key="d5">Azure provides content moderation services to prevent harmful content generated by large language models.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="CONTENT HARMS" target="CONTENT MODERATION SERVICES">
      <data key="d4">9.0</data>
      <data key="d5">Content moderation services are recommended to prevent content harms caused by large language models.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="CONTENT HARMS" target="RESEARCH AND OPEN SOURCE COMMUNITY">
      <data key="d4">7.0</data>
      <data key="d5">The research and open source community plays an important role in addressing content harms and improving AI technologies.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="GOVERNMENT AND TECHNOLOGY LEADERS" target="REGULATIONS AND STANDARDS">
      <data key="d4">8.0</data>
      <data key="d5">Government and technology leaders are expected to create regulations and standards to mitigate content harms associated with AI technologies.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="HALLUCINATION" target="MEMORIZATION CAPACITIES">
      <data key="d4">7.0</data>
      <data key="d5">Hallucination in language models may be influenced by their memorization capacities, with smaller models potentially being more susceptible.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="POTENTIAL FOR MISUSE" target="DISINFORMATION">
      <data key="d4">9.0</data>
      <data key="d5">Without suitable safeguards, there is a risk that large language models could be used to generate disinformation.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="DATA DISTRIBUTION" target="TUNING DATA">
      <data key="d4">8.0</data>
      <data key="d5">The performance of models like Orca-3 is likely to correlate strongly with the distribution of the tuning data.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="MARAH ABDIN" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Marah Abdin is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="SAM ADE JACOBS" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Sam Ade Jacobs is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AMMAR AHMAD AWAN" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Ammar Ahmad Awan is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="JYOTI ANEJA" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Jyoti Aneja is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="HANY AWADALLA" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Hany Awadalla is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="NGUYEN BACH" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Nguyen Bach is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AMIT BAHREE" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Amit Bahree is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="ARASH BAKHTIARI" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Arash Bakhtiari is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="JIANMIN BAO" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Jianmin Bao is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="HARKIRAT BEHL" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Harkirat Behl is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="ALON BENHAIM" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Alon Benhaim is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="MISHA BILENKO" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Misha Bilenko is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="JOHAN BJORCK" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Johan Bjorck is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="S&#201;BASTIEN BUBECK" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">S&#233;bastien Bubeck is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="QIN CAI" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Qin Cai is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="PHI-3" target="WANG">
      <data key="d4">8.0</data>
      <data key="d5">Wang is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="CODEPARROT" target="GITHUB-CODE CLEAN DATASET">
      <data key="d4">8.0</data>
      <data key="d5">CodeParrot is the provider of the Github-code clean dataset.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="NING DING" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Ning Ding is one of the authors of the paper on enhancing chat language models.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="DROA" target="READING COMPREHENSION BENCHMARK">
      <data key="d4">8.0</data>
      <data key="d5">DROP is a reading comprehension benchmark requiring discrete reasoning over paragraphs.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ZHAOYE FEI" target="QUERY OF CC">
      <data key="d4">8.0</data>
      <data key="d5">Zhaoye Fei is one of the authors of the paper on Query of CC.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ARNAV GUDIBANDE" target="IMITATING PROPRIETARY LLMS">
      <data key="d4">8.0</data>
      <data key="d5">Arnav Gudibande is one of the authors of the paper on the false promise of imitating proprietary LLMs.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="HAMISH IVISON" target="ENHANCING LM ADAPTATION">
      <data key="d4">8.0</data>
      <data key="d5">Hamish Ivison is one of the authors of the paper on enhancing LM adaptation.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ALBERT Q. JIANG" target="MISTRAL 7B">
      <data key="d4">8.0</data>
      <data key="d5">Albert Q. Jiang is one of the authors of the paper on Mistral 7B.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="HARRISON LEE" target="RLAIF">
      <data key="d4">8.0</data>
      <data key="d5">Harrison Lee is one of the authors of the paper on RLAIF.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="GUOHAO LI" target="CAMEL">
      <data key="d4">1.0</data>
      <data key="d5">Guohao Li is one of the authors of the paper on CAMEL.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="CAMEL" target="RII KHIZBULLIN">
      <data key="d4">8.0</data>
      <data key="d5">Rii Khizbullin is one of the authors of the paper describing the Camel framework.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="CAMEL" target="BERNARD GHANEM">
      <data key="d4">8.0</data>
      <data key="d5">Bernard Ghanem is one of the authors of the paper describing the Camel framework.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="RII KHIZBULLIN" target="BERNARD GHANEM">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society," published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="TIANYI ZHANG">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="YANN DUBOIS">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="ROHAN TAORI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="ISHAAN GULRAJANI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="TIANYI ZHANG" target="YANN DUBOIS">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="TIANYI ZHANG" target="ROHAN TAORI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="TIANYI ZHANG" target="ISHAAN GULRAJANI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="TIANYI ZHANG" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="TIANYI ZHANG" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YANN DUBOIS" target="ROHAN TAORI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YANN DUBOIS" target="ISHAAN GULRAJANI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YANN DUBOIS" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YANN DUBOIS" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ROHAN TAORI" target="ISHAAN GULRAJANI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ROHAN TAORI" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ROHAN TAORI" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ISHAAN GULRAJANI" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ISHAAN GULRAJANI" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="CARLOS GUESTRIN" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="ALEXANDER R. FABBRI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="JIAWEN CHEN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="YILUN ZHAO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="SIMENG HAN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="SHAFIQ JOTY">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="DRAGOMIR RADEV">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="CHIEN-SHENG WU">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="ARMAN COHAN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALEXANDER R. FABBRI" target="JIAWEN CHEN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALEXANDER R. FABBRI" target="YILUN ZHAO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALEXANDER R. FABBRI" target="SIMENG HAN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALEXANDER R. FABBRI" target="SHAFIQ JOTY">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="MOHAMMED LATIF SIDDIQ" target="RE(GEX|DOS)EVAL">
      <data key="d4">9.0</data>
      <data key="d5">Mohammed Latif Siddiq is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="JIAHAO ZHANG" target="RE(GEX|DOS)EVAL">
      <data key="d4">9.0</data>
      <data key="d5">Jiahao Zhang is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="LINDSAY RONEY" target="RE(GEX|DOS)EVAL">
      <data key="d4">9.0</data>
      <data key="d5">Lindsay Roney is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="ILIA SHUMAILOV">
      <data key="d4">9.0</data>
      <data key="d5">Ilia Shumailov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="ZAKHAR SHUMAYLOV">
      <data key="d4">9.0</data>
      <data key="d5">Zakhar Shumaylov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="YIREN ZHAO">
      <data key="d4">9.0</data>
      <data key="d5">Yiren Zhao is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="YARIN GAL">
      <data key="d4">9.0</data>
      <data key="d5">Yarin Gal is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="NICOLAS PAPERNOT">
      <data key="d4">9.0</data>
      <data key="d5">Nicolas Papernot is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="ROSS ANDERSON">
      <data key="d4">9.0</data>
      <data key="d5">Ross Anderson is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="JOANNA C. S. SANTOS" target="RE(GEX|DOS)EVAL">
      <data key="d4">9.0</data>
      <data key="d5">Joanna C. S. Santos is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="NATHANAEL SCH&#196;RLI" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Nathanael Sch&#228;rli is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ANSWER OPTIONS" target="ALPHABET ID">
      <data key="d4">1.0</data>
      <data key="d5">The alphabet ID represents the option selected by the student from the answer options.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="ALPHABET ID" target="PARSED STUDENT ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">The parsed student answer consists of the alphabet IDs representing the options chosen by the student.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EXACT MATCH/SPAN EXTRACTION PROBLEMS" target="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The Maths GPT-4 Extraction System Message is used for evaluating exact match/span extraction problems involving math-based questions.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EXACT MATCH/SPAN EXTRACTION PROBLEMS" target="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The General Extraction System Message is used for evaluating exact match/span extraction problems where a ground-truth answer value is given.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE" target="EMOTION SCORES">
      <data key="d4">1.0</data>
      <data key="d5">The EQBench GPT-4 Extraction System Message is used to parse and extract emotion scores from responses.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="CORRECT ANSWER" target="ERROR ANALYSIS">
      <data key="d4">9.0</data>
      <data key="d5">The correct answer is used in the error analysis to compare with the student's final answer.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="ERROR ANALYSIS" target="FINAL VERDICT">
      <data key="d4">9.0</data>
      <data key="d5">The error analysis leads to the final verdict, indicating whether the student's answer is 'Correct' or 'Incorrect'.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT AGENT RESPONSE" target="FIRST PASS SCORES">
      <data key="d4">8.0</data>
      <data key="d5">The first pass scores are part of the student agent's response, representing initial emotion evaluations.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT AGENT RESPONSE" target="CRITIQUE">
      <data key="d4">8.0</data>
      <data key="d5">The critique is part of the student agent's response, providing feedback on the initial scores.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT AGENT RESPONSE" target="REVISED SCORES">
      <data key="d4">8.0</data>
      <data key="d5">The revised scores are part of the student agent's response, representing the final emotion evaluations after critique.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="FIRST PASS SCORES" target="REVISED SCORES">
      <data key="d4">8.0</data>
      <data key="d5">The revised scores are updated from the first pass scores after considering the critique.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="CRITIQUE" target="REVISED SCORES">
      <data key="d4">1.0</data>
      <data key="d5">The critique influences the revised scores in the student agent's response.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="RESIGNED" target="ELLIOT">
      <data key="d4">8.0</data>
      <data key="d5">Elliot feels resigned after confessing his feelings to Alex, knowing that Alex is already in a relationship.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ANGRY" target="ELLIOT">
      <data key="d4">7.0</data>
      <data key="d5">Elliot feels angry at himself for putting himself in the situation of confessing to Alex.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HOPEFUL" target="ELLIOT">
      <data key="d4">6.0</data>
      <data key="d5">Elliot feels hopeful that Alex might reciprocate his feelings.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMBARRASSED" target="ELLIOT">
      <data key="d4">8.0</data>
      <data key="d5">Elliot feels embarrassed for putting Alex in an awkward position.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HALLUCINATION JUDGE" target="QUALITY JUDGE">
      <data key="d4">1.0</data>
      <data key="d5">Both Hallucination Judge and Quality Judge are tasks that involve evaluating the output of AI models, focusing on hallucination detection and overall quality, respectively.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="PROMPT TEMPLATE">
      <data key="d4">7.0</data>
      <data key="d5">A prompt template is used for the task of quality evaluation in text summarization.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="TEXT SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Quality Judge is a task within text summarization to evaluate the overall quality of the generated summary.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="INSTRUCTION ADHERENCE">
      <data key="d4">7.0</data>
      <data key="d5">Instruction adherence is a criterion used in the Quality Judge task to evaluate the response.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="CONTENT GROUNDING">
      <data key="d4">7.0</data>
      <data key="d5">Content grounding is a criterion used in the Quality Judge task to evaluate the response.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="OVERALL QUALITY">
      <data key="d4">1.0</data>
      <data key="d5">Overall quality is a criterion used in the Quality Judge task to evaluate the response.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMOTIONS" target="SCORES">
      <data key="d4">8.0</data>
      <data key="d5">The emotions experienced by Elliot are quantified with specific scores: Resigned (7), Angry (3), Hopeful (5), Embarrassed (8).</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="PROMPT TEMPLATE" target="HALLUCINATION DETECTION">
      <data key="d4">7.0</data>
      <data key="d5">A prompt template is used for the task of hallucination detection in text summarization.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HALLUCINATION DETECTION" target="TEXT SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Hallucination detection is a task within text summarization to ensure the generated summary is accurate.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
  </graph>
</graphml>